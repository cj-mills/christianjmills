---
title: Barracuda PoseNet Tutorial Pt. 4
layout: post
toc: false
description: This post covers how to process the output of the PoseNet model.
categories: [unity, tutorial]
hide: true
search_exclude: false
---

### Previous: [Part 1](https://christianjmills.com/unity/tutorial/2020/10/25/Barracuda-PoseNet-Tutorial-1.html) [Part 2](https://christianjmills.com/unity/tutorial/2020/10/25/Barracuda-PoseNet-Tutorial-2.html) [Part 2.5](https://christianjmills.com/unity/tutorial/2020/11/05/Barracuda-PoseNet-Tutorial-2-5.html) [Part 3](https://christianjmills.com/unity/tutorial/2020/11/05/Barracuda-PoseNet-Tutorial-3.html)

* [Create ProcessOutput() Method](#create-processoutput-method)
* [Calculate Scaling Values](#calculate-scaling-values)
* [Locate Key Point Indices](#locate-key-point-indices)
* [Calculate Key Point Positions](#calculate-key-point-positions)

## Create `ProcessOutput()` Method

The post processing steps will be handled in a new method called `ProcessOutput()`. The method will take in the output `Tensors` from the `predictionLayer` and the `offsetsLayer`. 

![processoutput_method_empty](\images\barracuda-posenet-tutorial\processoutput_method_empty.png)

Before filling out the function, we need to create a new constant and a new variable.

### Create `numKeypoints` Constant

The PoseNet model estimates the 2D locations of `17` key points on a human body.

| Index | Name           |
| ----- | -------------- |
| 0     | Nose           |
| 1     | Left Eye       |
| 2     | Right Eye      |
| 3     | Left Ear       |
| 4     | Right Ear      |
| 5     | Left Shoulder  |
| 6     | Right Shoulder |
| 7     | Left Elbow     |
| 8     | Right Elbow    |
| 9     | Left Wrist     |
| 10    | Right Wrist    |
| 11    | Left Hip       |
| 12    | Right Hip      |
| 13    | Left Knee      |
| 14    | Right Knee     |
| 15    | Left Ankle     |
| 16    | Right Ankle    |

Since the number of key points never changes, we'll store it in an `int` constant. Name the constant `numKeypoints` and set the value to `17`.

![numKeypoints_constant](\images\barracuda-posenet-tutorial\numKeypoints_constant.png)

### Create `keypointLocations` Variable

The processed output from the model will be stored in a new variable called `keypointLocations`. This variable will contain the `(X,Y)` coordinates for each key point. For this tutorial, the coordinates will be scaled to the original resolution of `1920x1080`.

This variable will also store the confidence values associated with the coordinates. The model predicts key point locations even when there isn't a human in the input image. In such situations, the confidence values will likely be quite low. We can decide how to handle the latest coordinates based on a confidence threshold that we pick.

There are many ways we can store this information. For simplicity, we'll stick with an array of arrays. The array will have `17` elements. Each element will contain the location information for the key point that matches their index.

![numKeyPoints_and_keypointLocations](\images\barracuda-posenet-tutorial\keypointLocations_variable.png)

### Retrieve Output Tenors

Call `ProcessOutput()` after `engine.Execute(input)` in the `Update()`  method. We'll use the [`engine.PeekOutput()`](https://docs.unity3d.com/Packages/com.unity.barracuda@1.0/api/Unity.Barracuda.IWorker.html#Unity_Barracuda_IWorker_PeekOutput_System_String_) method to get a reference to the output `Tensors` from the model. Since they are just references, we don't need to manually dispose of them.

![update_method_processoutput](\images\barracuda-posenet-tutorial\update_method_processoutput.png)

Now we can start filling out the `ProcessOutput()` method.

## Calculate Scaling Values

The heatmaps generated by the model are much smaller than the input image fed into it. We'll need to make some calculations to accurately scale the key point locations back up to the source resolution.

### Calculate Model Stride

The size of the heatmaps are dependent on both the size of the input image and a fixed integer value called the stride. The stride determines how much smaller the heatmaps will be than the input image. The model used in this tutorial has a stride of `32`. The heatmap dimensions are equal to the [ceiling](https://www.mathsisfun.com/sets/function-floor-ceiling.html) of `resolution/stride`. With our default input resolution of `360 x 360`, the size of the heatmaps are `12 x 12`.

Since we know the stride for this model, we could make it a constant value. However, calculating it is an easy way to make sure. This also makes it less of a hassle when switching between models with different stride values. 

#### Model with Different Stride Value

ResNet50 Stride 16: ([download](https://drive.google.com/file/d/1dlsWlBpjgD2AuZgi-qhZs-1IV-T98iLM/view?usp=sharing))

![stride](\images\barracuda-posenet-tutorial\stride.png)

### Calculate Image Scale

After scaling the output from the heatmaps back to the `inputImage` resolution, we'll need to scale the output up to the source resolution. We'll use the dimensions of `videoTexture` to calculate this scale.

![scale](\images\barracuda-posenet-tutorial\scale.png)

### Calculate Aspect Ratio Scale

As I noted in [Part 2](https://christianjmills.com/unity/tutorial/2020/11/04/Barracuda-PoseNet-Tutorial-2.html#resize-the-image), we need to compensate for the change in aspect ratio that results from resizing the image. We can use the dimensions of the `videoTexture` to stretch the output to the original aspect ratio. 

![unsqueezeScale](\images\barracuda-posenet-tutorial\unsqueezeScale.png)



## Locate Key Point Indices

![locateKeyPointIndex_method](\images\barracuda-posenet-tutorial\locateKeyPointIndex_method.png)



![processOutput_locateIndices](\images\barracuda-posenet-tutorial\processOutput_locateIndices.png)



### Another Way



## Calculate Key Point Positions

![calculate_position](\images\barracuda-posenet-tutorial\calculate_position.png)



### Store Key Point Positions

![store_position](\images\barracuda-posenet-tutorial\store_position_2.png)







 