<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-06-28">
<meta name="description" content="This follow-up to the fastai-to-unity tutorial covers creating a LibTorch plugin for the Unity game engine. Part 1 covers the required modifications to the original training code.">

<title>Christian Mills - How to Create a LibTorch Plugin for Unity on Windows Pt. 1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Christian Mills - How to Create a LibTorch Plugin for Unity on Windows Pt. 1">
<meta property="og:description" content="This follow-up to the fastai-to-unity tutorial covers creating a LibTorch plugin for the Unity game engine. Part 1 covers the required modifications to the original training code.">
<meta property="og:image" content="https://christianjmills.com/images/logo.png">
<meta property="og:site-name" content="Christian Mills">
<meta property="og:image:height" content="295">
<meta property="og:image:width" content="300">
<meta name="twitter:title" content="Christian Mills - How to Create a LibTorch Plugin for Unity on Windows Pt. 1">
<meta name="twitter:description" content="This follow-up to the fastai-to-unity tutorial covers creating a LibTorch plugin for the Unity game engine. Part 1 covers the required modifications to the original training code.">
<meta name="twitter:image" content="https://christianjmills.com/images/logo.png">
<meta name="twitter:creator" content="@cdotjdotmills">
<meta name="twitter:image-height" content="295">
<meta name="twitter:image-width" content="300">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Christian Mills</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cj-mills"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/cdotjdotmills"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">How to Create a LibTorch Plugin for Unity on Windows Pt. 1</h1>
  </div>

<div>
  <div class="description">
    This follow-up to the fastai-to-unity tutorial covers creating a LibTorch plugin for the Unity game engine. Part 1 covers the required modifications to the original training code.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 28, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#overview">Overview</a></li>
<li><a href="#install-dependencies">Install Dependencies</a></li>
<li><a href="#select-a-model">Select a Model</a></li>
<li><a href="#modify-transforms">Modify Transforms</a></li>
<li><a href="#define-learner">Define Learner</a></li>
<li><a href="#export-the-model">Export the Model</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>The previous <a href="../../fastai-to-unity-tutorial/part-1/">fastai-to-unity</a> tutorial series implemented a <a href="https://arxiv.org/abs/1512.03385">ResNet</a>-based image classifier in <a href="https://unity.com/">Unity</a> with the <a href="https://docs.unity3d.com/Packages/com.unity.barracuda@3.0/manual/index.html">Barracuda</a> inference library. The Barracuda library works well with the older ResNet architecture but does not support more recent ones like <a href="https://arxiv.org/abs/2201.03545">ConvNeXt</a> and <a href="https://arxiv.org/abs/2110.02178">MobileViT</a> at the time of writing.</p>
<p>This follow-up series covers using <a href="https://pytorch.org/cppdocs/installing.html">LibTorch</a>, the C++ distribution of <a href="https://pytorch.org/">PyTorch</a>, to perform inference with these newer model architectures. We’ll modify the original tutorial code and create a dynamic link library (<a href="https://docs.microsoft.com/en-us/troubleshoot/windows-client/deployment/dynamic-link-library">DLL</a>) file to access the LibTorch functionality in Unity.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><video src="./videos/libtorch-plugin-demo.mp4" class="img-fluid" controls=""><a href="./videos/libtorch-plugin-demo.mp4">Video</a></video></p>
<p></p><figcaption class="figure-caption">libtorch-plugin-demo</figcaption><p></p>
</figure>
</div>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>This post covers the required modifications to the <a href="https://github.com/cj-mills/fastai-to-unity-tutorial#training-code">original training code</a>. We’ll finetune models from the <a href="https://github.com/rwightman/pytorch-image-models">Timm library</a> on the same <a href="https://www.kaggle.com/datasets/belalelwikel/asl-and-some-words">ASL dataset</a> as the original tutorial. The Timm library provides access to a wide range of pretrained computer vision models and integrates with the <a href="https://docs.fast.ai/">fastai library</a>. Below is a link to the complete modified training code, along with links for running the notebook on Google Colab and Kaggle.</p>
<table class="table">
<thead>
<tr class="header">
<th>GitHub Repository</th>
<th>Colab</th>
<th>Kaggle</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/cj-mills/fastai-to-libtorch-to-unity-tutorial/blob/main/notebooks/Fastai-timm-to-Torchscript-Tutorial.ipynb">Jupyter Notebook</a></td>
<td><a href="https://colab.research.google.com/github/cj-mills/fastai-to-libtorch-to-unity-tutorial/blob/main/notebooks/Fastai-timm-to-Torchscript-Tutorial.ipynb">Open in Colab</a></td>
<td><a href="https://kaggle.com/kernels/welcome?src=https://github.com/cj-mills/fastai-to-libtorch-to-unity-tutorial/blob/main/notebooks/Fastai-timm-to-Torchscript-Tutorial.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" class="img-fluid" alt="Kaggle"></a></td>
</tr>
</tbody>
</table>
</section>
<section id="install-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="install-dependencies">Install Dependencies</h2>
<p>The <a href="https://pypi.org/project/timm/">pip package</a> for the Timm library is more stable than the GitHub repository but has fewer model types and pretrained weights. For example, the pip package has <a href="https://github.com/rwightman/pytorch-image-models/blob/0.5.x/timm/models/convnext.py">pretrained ConvNeXt models</a> but no MobileViT models. However, the latest GitHub version had some issues running the MobileNetV3 models at the time of writing.</p>
<p>Recent <a href="https://github.com/fastai/fastai/releases/tag/2.7.0">updates</a> to the fastai library resolve some <a href="https://benjaminwarner.dev/2022/06/14/debugging-pytorch-performance-decrease">performance issues</a> with PyTorch so let’s update that too. They also provide a new <code>ChannelsLast</code> (beta) callback that further <a href="https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html#performance-gains">improves performance</a> on modern GPUs.</p>
<p><strong>Uncomment the cell below if running on Google Colab or Kaggle</strong></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %%capture</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U torch torchvision torchaudio</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U fastai==2.7.2</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U kaggle==1.5.12</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U Pillow==9.1.0</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U timm==0.5.4 # more stable fewer models</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U git+https://github.com/rwightman/pytorch-image-models.git # more models less stable</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note for Colab:</strong> You must restart the runtime in order to use newly installed version of Pillow.</p>
<p><strong>Import all fastai computer vision functionality</strong></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Disable max rows and columns for pandas</strong></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'max_colwidth'</span>, <span class="va">None</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_rows'</span>, <span class="va">None</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="select-a-model" class="level2">
<h2 class="anchored" data-anchor-id="select-a-model">Select a Model</h2>
<p>Let’s start by selecting a model from the Timm library to finetune. The available pretrained models depend on the version of the Timm library installed.</p>
<p><strong>Import the Timm library</strong></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> timm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>timm.__version__</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'0.6.2.dev0'</code></pre>
<p><strong>Check available pretrained model types</strong></p>
<p>We can check which model types have pretrained weights using the <code>timm.list_models()</code> function.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>model_types <span class="op">=</span> <span class="bu">list</span>(<span class="bu">set</span>([model.split(<span class="st">'_'</span>)[<span class="dv">0</span>] <span class="cf">for</span> model <span class="kw">in</span> timm.list_models(pretrained<span class="op">=</span><span class="va">True</span>)]))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>model_types.sort()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(model_types)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
adv
</td>
</tr>
<tr>
<th>
1
</th>
<td>
bat
</td>
</tr>
<tr>
<th>
2
</th>
<td>
beit
</td>
</tr>
<tr>
<th>
3
</th>
<td>
botnet26t
</td>
</tr>
<tr>
<th>
4
</th>
<td>
cait
</td>
</tr>
<tr>
<th>
5
</th>
<td>
coat
</td>
</tr>
<tr>
<th>
6
</th>
<td>
convit
</td>
</tr>
<tr>
<th>
7
</th>
<td>
convmixer
</td>
</tr>
<tr>
<th>
8
</th>
<td>
convnext
</td>
</tr>
<tr>
<th>
9
</th>
<td>
crossvit
</td>
</tr>
<tr>
<th>
10
</th>
<td>
cspdarknet53
</td>
</tr>
<tr>
<th>
11
</th>
<td>
cspresnet50
</td>
</tr>
<tr>
<th>
12
</th>
<td>
cspresnext50
</td>
</tr>
<tr>
<th>
13
</th>
<td>
deit
</td>
</tr>
<tr>
<th>
14
</th>
<td>
densenet121
</td>
</tr>
<tr>
<th>
15
</th>
<td>
densenet161
</td>
</tr>
<tr>
<th>
16
</th>
<td>
densenet169
</td>
</tr>
<tr>
<th>
17
</th>
<td>
densenet201
</td>
</tr>
<tr>
<th>
18
</th>
<td>
densenetblur121d
</td>
</tr>
<tr>
<th>
19
</th>
<td>
dla102
</td>
</tr>
<tr>
<th>
20
</th>
<td>
dla102x
</td>
</tr>
<tr>
<th>
21
</th>
<td>
dla102x2
</td>
</tr>
<tr>
<th>
22
</th>
<td>
dla169
</td>
</tr>
<tr>
<th>
23
</th>
<td>
dla34
</td>
</tr>
<tr>
<th>
24
</th>
<td>
dla46
</td>
</tr>
<tr>
<th>
25
</th>
<td>
dla46x
</td>
</tr>
<tr>
<th>
26
</th>
<td>
dla60
</td>
</tr>
<tr>
<th>
27
</th>
<td>
dla60x
</td>
</tr>
<tr>
<th>
28
</th>
<td>
dm
</td>
</tr>
<tr>
<th>
29
</th>
<td>
dpn107
</td>
</tr>
<tr>
<th>
30
</th>
<td>
dpn131
</td>
</tr>
<tr>
<th>
31
</th>
<td>
dpn68
</td>
</tr>
<tr>
<th>
32
</th>
<td>
dpn68b
</td>
</tr>
<tr>
<th>
33
</th>
<td>
dpn92
</td>
</tr>
<tr>
<th>
34
</th>
<td>
dpn98
</td>
</tr>
<tr>
<th>
35
</th>
<td>
eca
</td>
</tr>
<tr>
<th>
36
</th>
<td>
ecaresnet101d
</td>
</tr>
<tr>
<th>
37
</th>
<td>
ecaresnet269d
</td>
</tr>
<tr>
<th>
38
</th>
<td>
ecaresnet26t
</td>
</tr>
<tr>
<th>
39
</th>
<td>
ecaresnet50d
</td>
</tr>
<tr>
<th>
40
</th>
<td>
ecaresnet50t
</td>
</tr>
<tr>
<th>
41
</th>
<td>
ecaresnetlight
</td>
</tr>
<tr>
<th>
42
</th>
<td>
efficientnet
</td>
</tr>
<tr>
<th>
43
</th>
<td>
efficientnetv2
</td>
</tr>
<tr>
<th>
44
</th>
<td>
ens
</td>
</tr>
<tr>
<th>
45
</th>
<td>
ese
</td>
</tr>
<tr>
<th>
46
</th>
<td>
fbnetc
</td>
</tr>
<tr>
<th>
47
</th>
<td>
fbnetv3
</td>
</tr>
<tr>
<th>
48
</th>
<td>
gc
</td>
</tr>
<tr>
<th>
49
</th>
<td>
gcresnet33ts
</td>
</tr>
<tr>
<th>
50
</th>
<td>
gcresnet50t
</td>
</tr>
<tr>
<th>
51
</th>
<td>
gcresnext26ts
</td>
</tr>
<tr>
<th>
52
</th>
<td>
gcresnext50ts
</td>
</tr>
<tr>
<th>
53
</th>
<td>
gernet
</td>
</tr>
<tr>
<th>
54
</th>
<td>
ghostnet
</td>
</tr>
<tr>
<th>
55
</th>
<td>
gluon
</td>
</tr>
<tr>
<th>
56
</th>
<td>
gmixer
</td>
</tr>
<tr>
<th>
57
</th>
<td>
gmlp
</td>
</tr>
<tr>
<th>
58
</th>
<td>
halo2botnet50ts
</td>
</tr>
<tr>
<th>
59
</th>
<td>
halonet26t
</td>
</tr>
<tr>
<th>
60
</th>
<td>
halonet50ts
</td>
</tr>
<tr>
<th>
61
</th>
<td>
haloregnetz
</td>
</tr>
<tr>
<th>
62
</th>
<td>
hardcorenas
</td>
</tr>
<tr>
<th>
63
</th>
<td>
hrnet
</td>
</tr>
<tr>
<th>
64
</th>
<td>
ig
</td>
</tr>
<tr>
<th>
65
</th>
<td>
inception
</td>
</tr>
<tr>
<th>
66
</th>
<td>
jx
</td>
</tr>
<tr>
<th>
67
</th>
<td>
lambda
</td>
</tr>
<tr>
<th>
68
</th>
<td>
lamhalobotnet50ts
</td>
</tr>
<tr>
<th>
69
</th>
<td>
lcnet
</td>
</tr>
<tr>
<th>
70
</th>
<td>
legacy
</td>
</tr>
<tr>
<th>
71
</th>
<td>
levit
</td>
</tr>
<tr>
<th>
72
</th>
<td>
mixer
</td>
</tr>
<tr>
<th>
73
</th>
<td>
mixnet
</td>
</tr>
<tr>
<th>
74
</th>
<td>
mnasnet
</td>
</tr>
<tr>
<th>
75
</th>
<td>
mobilenetv2
</td>
</tr>
<tr>
<th>
76
</th>
<td>
mobilenetv3
</td>
</tr>
<tr>
<th>
77
</th>
<td>
mobilevit
</td>
</tr>
<tr>
<th>
78
</th>
<td>
nasnetalarge
</td>
</tr>
<tr>
<th>
79
</th>
<td>
nf
</td>
</tr>
<tr>
<th>
80
</th>
<td>
nfnet
</td>
</tr>
<tr>
<th>
81
</th>
<td>
pit
</td>
</tr>
<tr>
<th>
82
</th>
<td>
pnasnet5large
</td>
</tr>
<tr>
<th>
83
</th>
<td>
poolformer
</td>
</tr>
<tr>
<th>
84
</th>
<td>
regnetv
</td>
</tr>
<tr>
<th>
85
</th>
<td>
regnetx
</td>
</tr>
<tr>
<th>
86
</th>
<td>
regnety
</td>
</tr>
<tr>
<th>
87
</th>
<td>
regnetz
</td>
</tr>
<tr>
<th>
88
</th>
<td>
repvgg
</td>
</tr>
<tr>
<th>
89
</th>
<td>
res2net101
</td>
</tr>
<tr>
<th>
90
</th>
<td>
res2net50
</td>
</tr>
<tr>
<th>
91
</th>
<td>
res2next50
</td>
</tr>
<tr>
<th>
92
</th>
<td>
resmlp
</td>
</tr>
<tr>
<th>
93
</th>
<td>
resnest101e
</td>
</tr>
<tr>
<th>
94
</th>
<td>
resnest14d
</td>
</tr>
<tr>
<th>
95
</th>
<td>
resnest200e
</td>
</tr>
<tr>
<th>
96
</th>
<td>
resnest269e
</td>
</tr>
<tr>
<th>
97
</th>
<td>
resnest26d
</td>
</tr>
<tr>
<th>
98
</th>
<td>
resnest50d
</td>
</tr>
<tr>
<th>
99
</th>
<td>
resnet101
</td>
</tr>
<tr>
<th>
100
</th>
<td>
resnet101d
</td>
</tr>
<tr>
<th>
101
</th>
<td>
resnet152
</td>
</tr>
<tr>
<th>
102
</th>
<td>
resnet152d
</td>
</tr>
<tr>
<th>
103
</th>
<td>
resnet18
</td>
</tr>
<tr>
<th>
104
</th>
<td>
resnet18d
</td>
</tr>
<tr>
<th>
105
</th>
<td>
resnet200d
</td>
</tr>
<tr>
<th>
106
</th>
<td>
resnet26
</td>
</tr>
<tr>
<th>
107
</th>
<td>
resnet26d
</td>
</tr>
<tr>
<th>
108
</th>
<td>
resnet26t
</td>
</tr>
<tr>
<th>
109
</th>
<td>
resnet32ts
</td>
</tr>
<tr>
<th>
110
</th>
<td>
resnet33ts
</td>
</tr>
<tr>
<th>
111
</th>
<td>
resnet34
</td>
</tr>
<tr>
<th>
112
</th>
<td>
resnet34d
</td>
</tr>
<tr>
<th>
113
</th>
<td>
resnet50
</td>
</tr>
<tr>
<th>
114
</th>
<td>
resnet50d
</td>
</tr>
<tr>
<th>
115
</th>
<td>
resnet51q
</td>
</tr>
<tr>
<th>
116
</th>
<td>
resnet61q
</td>
</tr>
<tr>
<th>
117
</th>
<td>
resnetblur50
</td>
</tr>
<tr>
<th>
118
</th>
<td>
resnetrs101
</td>
</tr>
<tr>
<th>
119
</th>
<td>
resnetrs152
</td>
</tr>
<tr>
<th>
120
</th>
<td>
resnetrs200
</td>
</tr>
<tr>
<th>
121
</th>
<td>
resnetrs270
</td>
</tr>
<tr>
<th>
122
</th>
<td>
resnetrs350
</td>
</tr>
<tr>
<th>
123
</th>
<td>
resnetrs420
</td>
</tr>
<tr>
<th>
124
</th>
<td>
resnetrs50
</td>
</tr>
<tr>
<th>
125
</th>
<td>
resnetv2
</td>
</tr>
<tr>
<th>
126
</th>
<td>
resnext101
</td>
</tr>
<tr>
<th>
127
</th>
<td>
resnext26ts
</td>
</tr>
<tr>
<th>
128
</th>
<td>
resnext50
</td>
</tr>
<tr>
<th>
129
</th>
<td>
resnext50d
</td>
</tr>
<tr>
<th>
130
</th>
<td>
rexnet
</td>
</tr>
<tr>
<th>
131
</th>
<td>
sebotnet33ts
</td>
</tr>
<tr>
<th>
132
</th>
<td>
sehalonet33ts
</td>
</tr>
<tr>
<th>
133
</th>
<td>
selecsls42b
</td>
</tr>
<tr>
<th>
134
</th>
<td>
selecsls60
</td>
</tr>
<tr>
<th>
135
</th>
<td>
selecsls60b
</td>
</tr>
<tr>
<th>
136
</th>
<td>
semnasnet
</td>
</tr>
<tr>
<th>
137
</th>
<td>
sequencer2d
</td>
</tr>
<tr>
<th>
138
</th>
<td>
seresnet152d
</td>
</tr>
<tr>
<th>
139
</th>
<td>
seresnet33ts
</td>
</tr>
<tr>
<th>
140
</th>
<td>
seresnet50
</td>
</tr>
<tr>
<th>
141
</th>
<td>
seresnext101
</td>
</tr>
<tr>
<th>
142
</th>
<td>
seresnext101d
</td>
</tr>
<tr>
<th>
143
</th>
<td>
seresnext26d
</td>
</tr>
<tr>
<th>
144
</th>
<td>
seresnext26t
</td>
</tr>
<tr>
<th>
145
</th>
<td>
seresnext26ts
</td>
</tr>
<tr>
<th>
146
</th>
<td>
seresnext50
</td>
</tr>
<tr>
<th>
147
</th>
<td>
seresnextaa101d
</td>
</tr>
<tr>
<th>
148
</th>
<td>
skresnet18
</td>
</tr>
<tr>
<th>
149
</th>
<td>
skresnet34
</td>
</tr>
<tr>
<th>
150
</th>
<td>
skresnext50
</td>
</tr>
<tr>
<th>
151
</th>
<td>
spnasnet
</td>
</tr>
<tr>
<th>
152
</th>
<td>
ssl
</td>
</tr>
<tr>
<th>
153
</th>
<td>
swin
</td>
</tr>
<tr>
<th>
154
</th>
<td>
swinv2
</td>
</tr>
<tr>
<th>
155
</th>
<td>
swsl
</td>
</tr>
<tr>
<th>
156
</th>
<td>
tf
</td>
</tr>
<tr>
<th>
157
</th>
<td>
tinynet
</td>
</tr>
<tr>
<th>
158
</th>
<td>
tnt
</td>
</tr>
<tr>
<th>
159
</th>
<td>
tresnet
</td>
</tr>
<tr>
<th>
160
</th>
<td>
tv
</td>
</tr>
<tr>
<th>
161
</th>
<td>
twins
</td>
</tr>
<tr>
<th>
162
</th>
<td>
vgg11
</td>
</tr>
<tr>
<th>
163
</th>
<td>
vgg13
</td>
</tr>
<tr>
<th>
164
</th>
<td>
vgg16
</td>
</tr>
<tr>
<th>
165
</th>
<td>
vgg19
</td>
</tr>
<tr>
<th>
166
</th>
<td>
visformer
</td>
</tr>
<tr>
<th>
167
</th>
<td>
vit
</td>
</tr>
<tr>
<th>
168
</th>
<td>
volo
</td>
</tr>
<tr>
<th>
169
</th>
<td>
wide
</td>
</tr>
<tr>
<th>
170
</th>
<td>
xception
</td>
</tr>
<tr>
<th>
171
</th>
<td>
xception41
</td>
</tr>
<tr>
<th>
172
</th>
<td>
xception41p
</td>
</tr>
<tr>
<th>
173
</th>
<td>
xception65
</td>
</tr>
<tr>
<th>
174
</th>
<td>
xception65p
</td>
</tr>
<tr>
<th>
175
</th>
<td>
xception71
</td>
</tr>
<tr>
<th>
176
</th>
<td>
xcit
</td>
</tr>
</tbody>

</table>
</div>
<p>Timm provides many pretrained models, but not all of them are fast enough for real-time applications. We can filter the results by providing a full or partial model name.</p>
<p><strong>Check available pretrained <a href="https://arxiv.org/abs/2201.03545">ConvNeXt</a> models</strong></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(timm.list_models(<span class="st">'convnext*'</span>, pretrained<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
convnext_base
</td>
</tr>
<tr>
<th>
1
</th>
<td>
convnext_base_384_in22ft1k
</td>
</tr>
<tr>
<th>
2
</th>
<td>
convnext_base_in22ft1k
</td>
</tr>
<tr>
<th>
3
</th>
<td>
convnext_base_in22k
</td>
</tr>
<tr>
<th>
4
</th>
<td>
convnext_large
</td>
</tr>
<tr>
<th>
5
</th>
<td>
convnext_large_384_in22ft1k
</td>
</tr>
<tr>
<th>
6
</th>
<td>
convnext_large_in22ft1k
</td>
</tr>
<tr>
<th>
7
</th>
<td>
convnext_large_in22k
</td>
</tr>
<tr>
<th>
8
</th>
<td>
convnext_small
</td>
</tr>
<tr>
<th>
9
</th>
<td>
convnext_small_384_in22ft1k
</td>
</tr>
<tr>
<th>
10
</th>
<td>
convnext_small_in22ft1k
</td>
</tr>
<tr>
<th>
11
</th>
<td>
convnext_small_in22k
</td>
</tr>
<tr>
<th>
12
</th>
<td>
convnext_tiny
</td>
</tr>
<tr>
<th>
13
</th>
<td>
convnext_tiny_384_in22ft1k
</td>
</tr>
<tr>
<th>
14
</th>
<td>
convnext_tiny_hnf
</td>
</tr>
<tr>
<th>
15
</th>
<td>
convnext_tiny_in22ft1k
</td>
</tr>
<tr>
<th>
16
</th>
<td>
convnext_tiny_in22k
</td>
</tr>
<tr>
<th>
17
</th>
<td>
convnext_xlarge_384_in22ft1k
</td>
</tr>
<tr>
<th>
18
</th>
<td>
convnext_xlarge_in22ft1k
</td>
</tr>
<tr>
<th>
19
</th>
<td>
convnext_xlarge_in22k
</td>
</tr>
</tbody>

</table>
</div>
<p>Let’s go with the <code>convnext_tiny</code> model since we want higher framerates. Each model comes with a set of default configuration parameters. We must keep track of the mean and std values used to normalize the model input. Many pretrained models use the ImageNet normalization stats, but others like MobileViT do not.</p>
<p><strong>Inspect the default configuration for the <code>convnext_tiny</code> model</strong></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> timm.models <span class="im">import</span> convnext</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>convnext_model <span class="op">=</span> <span class="st">'convnext_tiny'</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(convnext.default_cfgs[convnext_model], orient<span class="op">=</span><span class="st">'index'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x: auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
url
</th>
<td>
https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth
</td>
</tr>
<tr>
<th>
num_classes
</th>
<td>
1000
</td>
</tr>
<tr>
<th>
input_size
</th>
<td>
(3, 224, 224)
</td>
</tr>
<tr>
<th>
pool_size
</th>
<td>
(7, 7)
</td>
</tr>
<tr>
<th>
crop_pct
</th>
<td>
0.875
</td>
</tr>
<tr>
<th>
interpolation
</th>
<td>
bicubic
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
(0.485, 0.456, 0.406)
</td>
</tr>
<tr>
<th>
std
</th>
<td>
(0.229, 0.224, 0.225)
</td>
</tr>
<tr>
<th>
first_conv
</th>
<td>
stem.0
</td>
</tr>
<tr>
<th>
classifier
</th>
<td>
head.fc
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Check available pretrained <a href="https://arxiv.org/abs/1801.04381">MobileNetV2</a> models</strong></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(timm.list_models(<span class="st">'mobilenetv2*'</span>, pretrained<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
mobilenetv2_050
</td>
</tr>
<tr>
<th>
1
</th>
<td>
mobilenetv2_100
</td>
</tr>
<tr>
<th>
2
</th>
<td>
mobilenetv2_110d
</td>
</tr>
<tr>
<th>
3
</th>
<td>
mobilenetv2_120d
</td>
</tr>
<tr>
<th>
4
</th>
<td>
mobilenetv2_140
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Inspect the default configuration for the <code>mobilenetv2_050</code> model</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> timm.models <span class="im">import</span> efficientnet</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>mobilenetv2_model <span class="op">=</span> <span class="st">'mobilenetv2_050'</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(efficientnet.default_cfgs[mobilenetv2_model], orient<span class="op">=</span><span class="st">'index'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
url
</th>
<td>
https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv2_050-3d30d450.pth
</td>
</tr>
<tr>
<th>
num_classes
</th>
<td>
1000
</td>
</tr>
<tr>
<th>
input_size
</th>
<td>
(3, 224, 224)
</td>
</tr>
<tr>
<th>
pool_size
</th>
<td>
(7, 7)
</td>
</tr>
<tr>
<th>
crop_pct
</th>
<td>
0.875
</td>
</tr>
<tr>
<th>
interpolation
</th>
<td>
bicubic
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
(0.485, 0.456, 0.406)
</td>
</tr>
<tr>
<th>
std
</th>
<td>
(0.229, 0.224, 0.225)
</td>
</tr>
<tr>
<th>
first_conv
</th>
<td>
conv_stem
</td>
</tr>
<tr>
<th>
classifier
</th>
<td>
classifier
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Check available pretrained <a href="https://arxiv.org/abs/1905.02244">MobileNetV3</a> models</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(timm.list_models(<span class="st">'mobilenetv3*'</span>, pretrained<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
mobilenetv3_large_100
</td>
</tr>
<tr>
<th>
1
</th>
<td>
mobilenetv3_large_100_miil
</td>
</tr>
<tr>
<th>
2
</th>
<td>
mobilenetv3_large_100_miil_in21k
</td>
</tr>
<tr>
<th>
3
</th>
<td>
mobilenetv3_rw
</td>
</tr>
<tr>
<th>
4
</th>
<td>
mobilenetv3_small_050
</td>
</tr>
<tr>
<th>
5
</th>
<td>
mobilenetv3_small_075
</td>
</tr>
<tr>
<th>
6
</th>
<td>
mobilenetv3_small_100
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Inspect the default configuration for the <code>mobilenetv3_small_050</code> model</strong></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> timm.models <span class="im">import</span> mobilenetv3</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>mobilenetv3_model <span class="op">=</span> <span class="st">'mobilenetv3_small_050'</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(mobilenetv3.default_cfgs[mobilenetv3_model], orient<span class="op">=</span><span class="st">'index'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
url
</th>
<td>
https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv3_small_050_lambc-4b7bbe87.pth
</td>
</tr>
<tr>
<th>
num_classes
</th>
<td>
1000
</td>
</tr>
<tr>
<th>
input_size
</th>
<td>
(3, 224, 224)
</td>
</tr>
<tr>
<th>
pool_size
</th>
<td>
(7, 7)
</td>
</tr>
<tr>
<th>
crop_pct
</th>
<td>
0.875
</td>
</tr>
<tr>
<th>
interpolation
</th>
<td>
bicubic
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
(0.485, 0.456, 0.406)
</td>
</tr>
<tr>
<th>
std
</th>
<td>
(0.229, 0.224, 0.225)
</td>
</tr>
<tr>
<th>
first_conv
</th>
<td>
conv_stem
</td>
</tr>
<tr>
<th>
classifier
</th>
<td>
classifier
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Check available pretrained <a href="https://arxiv.org/abs/2110.02178">MobileViT</a> models</strong> * <strong>Note:</strong> MobileViT models are not available in timm <code>0.5.4</code></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(timm.list_models(<span class="st">'mobilevit*'</span>, pretrained<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
mobilevit_s
</td>
</tr>
<tr>
<th>
1
</th>
<td>
mobilevit_xs
</td>
</tr>
<tr>
<th>
2
</th>
<td>
mobilevit_xxs
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Inspect the default configuration for the <code>mobilevit_xxs</code> model</strong></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> timm.models <span class="im">import</span> mobilevit</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>mobilevit_model <span class="op">=</span> <span class="st">'mobilevit_xxs'</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(mobilevit.default_cfgs[mobilevit_model], orient<span class="op">=</span><span class="st">'index'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
url
</th>
<td>
https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-mvit-weights/mobilevit_xxs-ad385b40.pth
</td>
</tr>
<tr>
<th>
num_classes
</th>
<td>
1000
</td>
</tr>
<tr>
<th>
input_size
</th>
<td>
(3, 256, 256)
</td>
</tr>
<tr>
<th>
pool_size
</th>
<td>
(8, 8)
</td>
</tr>
<tr>
<th>
crop_pct
</th>
<td>
0.9
</td>
</tr>
<tr>
<th>
interpolation
</th>
<td>
bicubic
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
(0, 0, 0)
</td>
</tr>
<tr>
<th>
std
</th>
<td>
(1, 1, 1)
</td>
</tr>
<tr>
<th>
first_conv
</th>
<td>
stem.conv
</td>
</tr>
<tr>
<th>
classifier
</th>
<td>
head.fc
</td>
</tr>
<tr>
<th>
fixed_input_size
</th>
<td>
False
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Select a model</strong></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>model_type <span class="op">=</span> convnext</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> convnext_model</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># model_type = efficientnet</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># model_name = mobilenetv2_model</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># model_type = mobilenetv3</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># model_name = mobilenetv3_model</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># model_type = mobilevit</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># model_name = mobilevit_model</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After picking a model, we’ll store the related normalization stats for future use.</p>
<p><strong>Store normalization stats</strong></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> model_type.default_cfgs[model_name][<span class="st">'mean'</span>]</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> model_type.default_cfgs[model_name][<span class="st">'std'</span>]</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>mean, std</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))</code></pre>
<p><strong>Define target input dimensions</strong></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># size_1_1 = (224, 224)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># size_3_2 = (224, 336)</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># size_4_3 = (216, 288)</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>size_16_9 <span class="op">=</span> (<span class="dv">216</span>, <span class="dv">384</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># size_16_9_l = (288, 512)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>input_dims <span class="op">=</span> size_16_9</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="modify-transforms" class="level2">
<h2 class="anchored" data-anchor-id="modify-transforms">Modify Transforms</h2>
<p>We can apply the normalization stats at the end of the batch transforms.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>item_tfms <span class="op">=</span> [FlipItem(p<span class="op">=</span><span class="fl">1.0</span>), Resize(input_dims, method<span class="op">=</span>ResizeMethod.Pad, pad_mode<span class="op">=</span>PadMode.Border)]</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>batch_tfms <span class="op">=</span> [</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    Contrast(max_lighting<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    Saturation(max_lighting<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    Hue(max_hue<span class="op">=</span><span class="fl">0.05</span>),</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">*</span>aug_transforms(</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>        size<span class="op">=</span>input_dims, </span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        mult<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>        do_flip<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        flip_vert<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        max_rotate<span class="op">=</span><span class="fl">0.0</span>,</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        min_zoom<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        max_zoom<span class="op">=</span><span class="fl">1.5</span>,</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        max_lighting<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        max_warp<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        p_affine<span class="op">=</span><span class="fl">0.0</span>,</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>        pad_mode<span class="op">=</span>PadMode.Border),</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    Normalize.from_stats(mean<span class="op">=</span>mean, std<span class="op">=</span>std)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="define-learner" class="level2">
<h2 class="anchored" data-anchor-id="define-learner">Define Learner</h2>
<p>The training process is identical to the original tutorial, and we only need to pass the name of the Timm model to the <code>vision_learner</code> object.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, model_name, metrics<span class="op">=</span>metrics).to_fp16()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># learn = vision_learner(dls, model_name, metrics=metrics, cbs=[ChannelsLast]).to_fp16()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="export-the-model" class="level2">
<h2 class="anchored" data-anchor-id="export-the-model">Export the Model</h2>
<p>Once training completes, we need to convert our trained PyTorch model to a <a href="https://pytorch.org/docs/stable/jit.html">TorchScript</a> module for use in LibTorch. We do so using the <a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html"><code>torch.jit.trace()</code></a> method.</p>
<p><strong>Generate a TorchScript module using the test image</strong></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>traced_script_module <span class="op">=</span> torch.jit.trace(learn.model.cpu(), batched_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can perform inference with the TorchScript module the same way we would a PyTorch model.</p>
<p><strong>Verify the TorchScript module’s accuracy</strong></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    torchscript_preds <span class="op">=</span> traced_script_module(batched_tensor)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>learn.dls.vocab[torch.nn.functional.softmax(torchscript_preds, dim<span class="op">=</span><span class="dv">1</span>).argmax()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'J'</code></pre>
<p><strong>Define TorchScript file name</strong></p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>module_file_name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>dataset_path<span class="sc">.</span>name<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>learn<span class="sc">.</span>arch<span class="sc">}</span><span class="ss">.pt"</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>module_file_name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'asl-and-some-words-convnext_tiny.pt'</code></pre>
<p>Some models like MobileViT will require the exact input dimensions in LibTorch as was used in the <code>torch.jit.trace()</code> method. Therefore we’ll convert the PyTorch model again using the training dimensions before saving the TorchScript module to a file.</p>
<p><strong>Generate a torchscript module using the target input dimensions and save it to a file</strong></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>torch.randn(<span class="dv">1</span>, <span class="dv">3</span>, <span class="op">*</span>input_dims).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>torch.Size([1, 3, 216, 384])</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>traced_script_module <span class="op">=</span> torch.jit.trace(learn.model.cpu(), torch.randn(<span class="dv">1</span>, <span class="dv">3</span>, <span class="op">*</span>input_dims))</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>traced_script_module.save(module_file_name)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can export the normalization stats to a JSON file using the same method for the class labels. We’ll load the stats in Unity and pass them to the LibTorch plugin.</p>
<p><strong>Export model normalization stats</strong></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>normalization_stats <span class="op">=</span> {<span class="st">"mean"</span>: <span class="bu">list</span>(mean), <span class="st">"std"</span>: <span class="bu">list</span>(std)}</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>normalization_stats_file_name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>learn<span class="sc">.</span>arch<span class="sc">}</span><span class="ss">-normalization_stats.json"</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(normalization_stats_file_name, <span class="st">"w"</span>) <span class="im">as</span> write_file:</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    json.dump(normalization_stats, write_file)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>This post covered how to modify the training code from the <a href="../../fastai-to-unity-tutorial/part-1/">fastai-to-unity tutorial</a>to finetune models from the Timm library and export them as TorchScript modules. Part 2 will cover creating a dynamic link library (<a href="https://docs.microsoft.com/en-us/troubleshoot/windows-client/deployment/dynamic-link-library">DLL</a>) file in Visual Studio to perform inference with these TorchScript modules using <a href="https://pytorch.org/cppdocs/installing.html">LibTorch</a>.</p>
<p><strong>Previous:</strong> <a href="../../fastai-to-unity-tutorial/part-3/">Fastai to Unity Tutorial Pt. 3</a></p>
<p><strong>Next:</strong> <a href="../part-2/">How to Create a LibTorch Plugin for Unity on Windows Pt.2</a></p>
<p><strong>Project Resources:</strong> <a href="https://github.com/cj-mills/fastai-to-libtorch-to-unity-tutorial">GitHub Repository</a></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } 
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>