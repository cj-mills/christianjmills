<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-04-10">
<meta name="description" content="Chapter 6 covers building an encoder-decoder model to condense dialogues between several people into a crisp summary.">

<title>Christian Mills - Notes on Transformers Book Ch. 6</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Christian Mills - Notes on Transformers Book Ch. 6">
<meta property="og:description" content="Chapter 6 covers building an encoder-decoder model to condense dialogues between several people into a crisp summary.">
<meta property="og:image" content="christianjmills.com/images/logo.png">
<meta property="og:site-name" content="Christian Mills">
<meta property="og:image:height" content="295">
<meta property="og:image:width" content="300">
<meta name="twitter:title" content="Christian Mills - Notes on Transformers Book Ch. 6">
<meta name="twitter:description" content="Chapter 6 covers building an encoder-decoder model to condense dialogues between several people into a crisp summary.">
<meta name="twitter:image" content="christianjmills.com/images/logo.png">
<meta name="twitter:creator" content="@cdotjdotmills">
<meta name="twitter:image-height" content="295">
<meta name="twitter:image-width" content="300">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Christian Mills</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:christian@christianjmills.com"><i class="bi bi-envelope-fill" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cj-mills"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/cdotjdotmills"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../index.xml"><i class="bi bi-rss" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Notes on Transformers Book Ch. 6</h1>
  <div class="quarto-categories">
    <div class="quarto-category">ai</div>
    <div class="quarto-category">huggingface</div>
    <div class="quarto-category">nlp</div>
    <div class="quarto-category">notes</div>
  </div>
  </div>

<div>
  <div class="description">
    Chapter 6 covers building an encoder-decoder model to condense dialogues between several people into a crisp summary.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 10, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#project-summarize-dialogues-between-several-people">Project: Summarize Dialogues Between Several People</a></li>
<li><a href="#the-cnn/dailymail-dataset">The CNN/DailyMail Dataset</a></li>
<li><a href="#text-summarization-pipelines">Text Summarization Pipelines</a></li>
<li><a href="#comparing-different-summaries">Comparing Different Summaries</a></li>
<li><a href="#measuring-the-quality-of-generated-text">Measuring the Quality of Generated Text</a></li>
<li><a href="#evaluating-pegasus-on-the-cnndailymail-dataset">Evaluating PEGASUS on the CNN/DailyMail Dataset</a></li>
<li><a href="#training-a-summarization-model">Training a Summarization Model</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references">References</a></li>
</ul>
<hr>
<p><strong>Note:</strong> Had to update the <code>datasets</code> package to version 2.0.0.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datasets</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> accelerate</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Only print error messages</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>transformers.logging.set_verbosity_error()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>datasets.logging.set_verbosity_error()</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>transformers.__version__, datasets.__version__, accelerate.__version__</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    ('4.11.3', '2.0.0', '0.5.1')</code></pre>
<hr>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline, set_seed</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ast</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://astor.readthedocs.io/en/latest/</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> astor</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> inspect</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> textwrap</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_source(obj, exclude_doc<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get source code</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    source <span class="op">=</span> inspect.getsource(obj)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove any common leading whitespace from every line</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    cleaned_source <span class="op">=</span> textwrap.dedent(source)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Parse the source into an AST node.</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    parsed <span class="op">=</span> ast.parse(cleaned_source)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> node <span class="kw">in</span> ast.walk(parsed):</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Skip any nodes that are not class or function definitions</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(node, (ast.FunctionDef, ast.ClassDef, ast.AsyncFunctionDef)):</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> exclude_doc <span class="kw">and</span> <span class="bu">len</span>(node.body) <span class="op">&gt;</span> <span class="dv">1</span>: node.body <span class="op">=</span> node.body[<span class="dv">1</span>:]</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(astor.to_source(parsed))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li>Text summarization requires the model to understand long passages, reason about the contents, and produce fluent text that incorporates the main topics from the original document.</li>
</ul>
</section>
<section id="project-summarize-dialogues-between-several-people" class="level2">
<h2 class="anchored" data-anchor-id="project-summarize-dialogues-between-several-people">Project: Summarize Dialogues Between Several People</h2>
<ul>
<li>Text summarization requires the model to understand long passages, reason about the contents, and produce fluent text that incorporates the main topics from the original document.</li>
<li>Text summarization is a classic sequence-to-sequence task with an input text and a target text.</li>
<li>The goal is to build an encoder-decoder model to condense dialogues between several people into a crisp summary.</li>
</ul>
</section>
<section id="the-cnndailymail-dataset" class="level2">
<h2 class="anchored" data-anchor-id="the-cnndailymail-dataset">The CNN/DailyMail Dataset</h2>
<ul>
<li>The CNN/DailyMail dataset contains over 300,000 pairs of news articles and their corresponding summaries.</li>
<li>The summaries are composed of the bullet points that CNN and The Daily Mail attach to their articles.</li>
<li>The summaries are abstractive, consisting of new sentences instead of excerpts.</li>
<li><a href="https://github.com/abisee/cnn-dailymail">GitHub Repository</a></li>
<li><a href="https://huggingface.co/datasets/cnn_dailymail">Hugging Face Dataset Card</a></li>
</ul>
<hr>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Load Version 3.0.0 of the CNN/DailMail dataset</strong></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> load_dataset(<span class="st">"cnn_dailymail"</span>, version<span class="op">=</span><span class="st">"3.0.0"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Features: </span><span class="sc">{</span>dataset[<span class="st">'train'</span>]<span class="sc">.</span>column_names<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Features: ['article', 'highlights', 'id']</code></pre>
<p><strong>Note:</strong></p>
<ul>
<li>The dataset has three columns.
<ol type="1">
<li>The <code>article</code> column contains the news articles.</li>
<li>The <code>highlights</code> column contains the summaries.</li>
<li>The <code>ids</code> column uniquely identifies each article.</li>
</ol></li>
</ul>
<hr>
<p><strong>View an excerpt from an article</strong></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> dataset[<span class="st">"train"</span>][<span class="dv">1</span>]</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>article_len <span class="op">=</span> <span class="bu">len</span>(sample[<span class="st">"article"</span>])</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>highlights_len <span class="op">=</span> <span class="bu">len</span>(sample[<span class="st">"highlights"</span>])</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"""</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="ss">Article (excerpt of 500 characters, total length: </span><span class="sc">{</span>article_len<span class="sc">}</span><span class="ss">):</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="ss">"""</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sample[<span class="st">"article"</span>][:<span class="dv">500</span>])</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Summary (length: </span><span class="sc">{</span>highlights_len<span class="sc">}</span><span class="ss">):'</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sample[<span class="st">"highlights"</span>])</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">The article is </span><span class="sc">{</span>(article_len<span class="op">/</span>highlights_len)<span class="sc">:.2f}</span><span class="ss"> times longer than the summary.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>
    Article (excerpt of 500 characters, total length: 3192):
    
    (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has n
    
    Summary (length: 180):
    Usain Bolt wins third gold of world championship .
    Anchors Jamaica to 4x100m relay victory .
    Eighth gold at the championships for Bolt .
    Jamaica double up in women's 4x100m relay .
    
    The article is 17.73 times longer than the summary.</code></pre>
<p><strong>Note:</strong> * Articles can be very long compared to the target summary. * Long articles are challenging for most transformer models as their context size usually maxes out around 1,000 tokens. * A thousand tokens can contain a few paragraphs of text. * The standard workaround to this limitation is to truncate the text to the model’s context size. * This approach risks losing important information in the excluded portion of the text.</p>
<hr>
</section>
<section id="text-summarization-pipelines" class="level2">
<h2 class="anchored" data-anchor-id="text-summarization-pipelines">Text Summarization Pipelines</h2>
<p><strong>Get a 2,000 character excerpt from an article</strong></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>sample_text <span class="op">=</span> dataset[<span class="st">"train"</span>][<span class="dv">1</span>][<span class="st">"article"</span>][:<span class="dv">2000</span>]</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We'll collect the generated summaries of each model in a dictionary</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>summaries <span class="op">=</span> {}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note:</strong> It is a convention in summarization to separate sentences by a newline.</p>
<hr>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> sent_tokenize</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<section id="the-natural-language-tookit-nltk" class="level4">
<h4 class="anchored" data-anchor-id="the-natural-language-tookit-nltk">The Natural Language Tookit (NLTK)</h4>
<ul>
<li><a href="https://www.nltk.org/">Homepage</a></li>
<li>The toolkit provides easy-to-use interfaces and a suite of text processing libraries.</li>
</ul>
</section>
<section id="sent_tokenize" class="level4">
<h4 class="anchored" data-anchor-id="sent_tokenize"><code>sent_tokenize</code></h4>
<ul>
<li><a href="https://www.nltk.org/api/nltk.tokenize.html?highlight=sent_tokenize#nltk.tokenize.sent_tokenize">Documentation</a></li>
<li>Get a sentence-tokenized copy of a text.</li>
</ul>
</section>
<section id="nltk.tokenize.punkt" class="level3">
<h3 class="anchored" data-anchor-id="nltk.tokenize.punkt"><code>nltk.tokenize.punkt</code></h3>
<ul>
<li><a href="https://www.nltk.org/api/nltk.tokenize.punkt.html?highlight=punkt#module-nltk.tokenize.punkt">Documentation</a></li>
<li>The Punkt sentence tokenizer divides a text into a list of sentences.</li>
<li>An unsupervised algorithm builds a model of abbreviation words, collocations, and words that start sentences.</li>
</ul>
<p><strong>Download the Punkt package</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">"punkt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    [nltk_data] Downloading package punkt to /home/innom-dt/nltk_data...
    [nltk_data]   Package punkt is already up-to-date!

    True</code></pre>
<hr>
<p><strong>Test the sentence tokenizer</strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>string <span class="op">=</span> <span class="st">"The U.S. are a country. The U.N. is an organization."</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>sent_tokenize(string)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    ['The U.S. are a country.', 'The U.N. is an organization.']</code></pre>
<hr>
</section>
<section id="summarization-baseline" class="level3">
<h3 class="anchored" data-anchor-id="summarization-baseline">Summarization Baseline</h3>
<ul>
<li>A common baseline for summarizing news articles is to take the first three sentences of the article.</li>
</ul>
<p><strong>Define a function to extract the first three sentences from a text</strong></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> three_sentence_summary(text):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join(sent_tokenize(text)[:<span class="dv">3</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a baseline summary</strong></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>summaries[<span class="st">"baseline"</span>] <span class="op">=</span> three_sentence_summary(sample_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Set device number for Hugging Face Pipelines</strong></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 0 for the first CUDA GPU</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># -1 for CPU</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>device_num <span class="op">=</span> <span class="dv">0</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="gpt-2" class="level3">
<h3 class="anchored" data-anchor-id="gpt-2">GPT-2</h3>
<ul>
<li>We can use the GPT-2 model to generate summaries by appending “TL;DR” to the end of the input text.</li>
<li>TL;DR indicates a short version of a long post.</li>
</ul>
<hr>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline, set_seed</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<section id="textgenerationpipeline" class="level4">
<h4 class="anchored" data-anchor-id="textgenerationpipeline"><code>TextGenerationPipeline</code></h4>
<ul>
<li><a href="https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.TextGenerationPipeline">Documentation</a></li>
<li>Create a language generation pipeline that predicts the words that will follow a specified text prompt.</li>
</ul>
<p><strong>Reset random seed</strong></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a language generation pipeline using GPT-2</strong></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(<span class="st">"text-generation"</span>, model<span class="op">=</span><span class="st">"gpt2-xl"</span>, device<span class="op">=</span>device_num)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(pipe)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    transformers.pipelines.text_generation.TextGenerationPipeline</code></pre>
<hr>
<p><strong>Create a summary with the GPT-2 model</strong></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>gpt2_query <span class="op">=</span> sample_text <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">TL;DR:</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>pipe_out <span class="op">=</span> pipe(gpt2_query, max_length<span class="op">=</span><span class="dv">512</span>, clean_up_tokenization_spaces<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>summaries[<span class="st">"gpt2"</span>] <span class="op">=</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join(</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    sent_tokenize(pipe_out[<span class="dv">0</span>][<span class="st">"generated_text"</span>][<span class="bu">len</span>(gpt2_query) :]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>pipe_out[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    {'generated_text': '(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men\'s 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles. The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital. "I\'m proud of myself and I\'ll continue to work to dominate for as long as possible," Bolt said, having previously expressed his intention to carry on until the 2016 Rio Olympics. Victory was never seriously in doubt once he got the baton safely in hand from Ashmeade, while Gatlin and the United States third leg runner Rakieem Salaam had problems. Gatlin strayed out of his lane as he struggled to get full control of their baton and was never able to get on terms with Bolt. Earlier, Jamaica\'s women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their quartet recorded a championship record of 41.29 seconds, well clear of France, who crossed the line in second place in 42.73 seconds. Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover. The British quartet, who were initially fourth, were promoted to the bronze which eluded their men\'s team. Fraser-Pryce, like Bolt ag\nTL;DR:\nThe World Championships have come to a close and Usain Bolt has been crowned world champion. The Jamaica sprinter ran a lap of the track at 20.52 seconds, faster than even the world\'s best sprinter from last year -- South Korea\'s Yuna Kim, whom Bolt outscored by 0.26 seconds. It\'s his third medal in succession at the championships: 2011, 2012 and'}</code></pre>
<hr>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>summaries[<span class="st">"gpt2"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    "The World Championships have come to a close and Usain Bolt has been crowned world champion.\nThe Jamaica sprinter ran a lap of the track at 20.52 seconds, faster than even the world's best sprinter from last year -- South Korea's Yuna Kim, whom Bolt outscored by 0.26 seconds.\nIt's his third medal in succession at the championships: 2011, 2012 and"</code></pre>
<hr>
</section>
</section>
<section id="t5" class="level3">
<h3 class="anchored" data-anchor-id="t5">T5</h3>
<ul>
<li>We can perform several tasks using the text prompts from the training process.</li>
</ul>
<section id="text-to-text-prompts" class="level4">
<h4 class="anchored" data-anchor-id="text-to-text-prompts">Text-to-Text Prompts:</h4>
<ul>
<li><strong>Translation:</strong> “translate {source-language} to {target-languge}: {text}”</li>
<li><strong>Linguistic Acceptability:</strong> “cola sentence: {text}”</li>
<li><strong>Semantic Similarity:</strong> “stsb sentence 1: {text1} sentence 2: {text2}”</li>
<li><strong>Summarization:</strong> “summarize: {text}”</li>
</ul>
<p><strong>Reset random seed</strong></p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a text generation pipeline with the T5 model</strong></p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(<span class="st">"summarization"</span>, model<span class="op">=</span><span class="st">"t5-large"</span>, device<span class="op">=</span>device_num)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a summary with the T5 model</strong></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>pipe_out <span class="op">=</span> pipe(sample_text)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>summaries[<span class="st">"t5"</span>] <span class="op">=</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join(sent_tokenize(pipe_out[<span class="dv">0</span>][<span class="st">"summary_text"</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>summaries[<span class="st">"t5"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    "usain bolt wins his third gold medal of the world championships in the men's 4x100m relay .\nthe 26-year-old anchored Jamaica to victory in the event in the Russian capital .\nhe has now collected eight gold medals at the championships, equaling the record ."</code></pre>
<hr>
</section>
</section>
<section id="bart" class="level3">
<h3 class="anchored" data-anchor-id="bart">BART</h3>
<ul>
<li>The “facebook/bart-large-cnn” model checkpoint is fine-tuned specifically on the CNN/DailyMail dataset.</li>
</ul>
<p><strong>Reset random seed</strong></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a text generation pipeline with the BART model</strong></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(<span class="st">"summarization"</span>, model<span class="op">=</span><span class="st">"facebook/bart-large-cnn"</span>, device<span class="op">=</span>device_num)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a summary with the BART model</strong></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>pipe_out <span class="op">=</span> pipe(sample_text)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>summaries[<span class="st">"bart"</span>] <span class="op">=</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join(sent_tokenize(pipe_out[<span class="dv">0</span>][<span class="st">"summary_text"</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>summaries[<span class="st">"bart"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    "Usain Bolt wins his third gold of the world championships in Moscow.\nBolt anchors Jamaica to victory in the men's 4x100m relay.\nThe 26-year-old has now won eight gold medals at world championships.\nJamaica's women also win gold in the relay, beating France in the process."</code></pre>
<hr>
</section>
<section id="pegasus" class="level3">
<h3 class="anchored" data-anchor-id="pegasus">PEGASUS</h3>
<ul>
<li><a href="https://arxiv.org/abs/1912.08777">PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization</a></li>
<li>PEGASUS is an encoder-decoder transformer trained to predict masked sentences in multisentence tests.</li>
<li>The authors argue that the pretraining objective is more effective the closer is to the downstream task.</li>
<li>The authors trained PEGASUS to reconstruct sentences containing most of the content of their surrounding paragraphs in a large corpus.</li>
<li>The model has dedicated tokens for newlines, so we do not need the sent_tokenize function.</li>
</ul>
<p><strong>Reset random seed</strong></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a text generation pipeline with the PEGASUS model</strong></p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(<span class="st">"summarization"</span>, model<span class="op">=</span><span class="st">"google/pegasus-cnn_dailymail"</span>, device<span class="op">=</span>device_num)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Create a summary with the PEGASUS model</strong></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>pipe_out <span class="op">=</span> pipe(sample_text)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>summaries[<span class="st">"pegasus"</span>] <span class="op">=</span> pipe_out[<span class="dv">0</span>][<span class="st">"summary_text"</span>].replace(<span class="st">" .&lt;n&gt;"</span>, <span class="st">".</span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>summaries[<span class="st">"pegasus"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    "Usain Bolt wins third gold of world championships.\nAnchors Jamaica to victory in men's 4x100m relay.\nEighth gold at the championships for Bolt.\nJamaica also win women's 4x100m relay ."</code></pre>
<hr>
</section>
</section>
<section id="comparing-different-summaries" class="level2">
<h2 class="anchored" data-anchor-id="comparing-different-summaries">Comparing Different Summaries</h2>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"GROUND TRUTH"</span>)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dataset[<span class="st">"train"</span>][<span class="dv">1</span>][<span class="st">"highlights"</span>])</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">""</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model_name <span class="kw">in</span> summaries:</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(model_name.upper())</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(summaries[model_name])</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    GROUND TRUTH
    Usain Bolt wins third gold of world championship .
    Anchors Jamaica to 4x100m relay victory .
    Eighth gold at the championships for Bolt .
    Jamaica double up in women's 4x100m relay .
    
    BASELINE
    (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.
    The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.
    The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.
    
    GPT2
    The World Championships have come to a close and Usain Bolt has been crowned world champion.
    The Jamaica sprinter ran a lap of the track at 20.52 seconds, faster than even the world's best sprinter from last year -- South Korea's Yuna Kim, whom Bolt outscored by 0.26 seconds.
    It's his third medal in succession at the championships: 2011, 2012 and
    
    T5
    usain bolt wins his third gold medal of the world championships in the men's 4x100m relay .
    the 26-year-old anchored Jamaica to victory in the event in the Russian capital .
    he has now collected eight gold medals at the championships, equaling the record .
    
    BART
    Usain Bolt wins his third gold of the world championships in Moscow.
    Bolt anchors Jamaica to victory in the men's 4x100m relay.
    The 26-year-old has now won eight gold medals at world championships.
    Jamaica's women also win gold in the relay, beating France in the process.
    
    PEGASUS
    Usain Bolt wins third gold of world championships.
    Anchors Jamaica to victory in men's 4x100m relay.
    Eighth gold at the championships for Bolt.
    Jamaica also win women's 4x100m relay .</code></pre>
<p><strong>Note:</strong> * The summary generated by GPT-2 is quite different than the others. * GPT-2 summarizes the characters instead of the text. * The GPT-2 model often invents facts since it did not train to generate truthful summaries. * There are significant similarities between the summaries generated by the T5, BART, and PEGASUS models. * PEGASUS gets incredibly close to the ground truth summary.</p>
<hr>
</section>
<section id="measuring-the-quality-of-generated-text" class="level2">
<h2 class="anchored" data-anchor-id="measuring-the-quality-of-generated-text">Measuring the Quality of Generated Text</h2>
<ul>
<li>Conventional metrics like accuracy do not reflect the quality of the generated text.</li>
<li>The field of text-generation is still looking for better evaluation metrics.</li>
<li>The two most common metrics used to evaluate generated text are BLEU and ROUGE.</li>
<li>Human judgment is still the best measure.</li>
</ul>
<section id="bilingual-evaluation-understudy-bleu" class="level3">
<h3 class="anchored" data-anchor-id="bilingual-evaluation-understudy-bleu">Bilingual Evaluation Understudy (BLEU)</h3>
<ul>
<li><a href="https://dl.acm.org/doi/10.3115/1073083.1073135">BLEU: a method for automatic evaluation of machine translation</a></li>
<li>BLEU is a precision-based metric where we count the number of words or n-grams in the generated text that occur in the reference text and divide it by the length of the reference.</li>
<li>We only count a word as many times as it occurs in the reference text.</li>
<li>BLEU is a popular metric for tasks like machine translation where precision takes priority.</li>
<li>Given one generated sentence, <span class="math inline">\(snt\)</span>, that we to compare against a reference sentence, <span class="math inline">\(snt^{\prime}\)</span>, we extract all possible n-grams of degree <span class="math inline">\(n\)</span> and do the accounting to get the precision <span class="math inline">\(P_{n}\)</span>.</li>
</ul>
</section>
<section id="p_n-fracsum_n-gram-in-sntcount_clipn-gramsum_n-gram-in-sntprimecountn-gram" class="level3">
<h3 class="anchored" data-anchor-id="p_n-fracsum_n-gram-in-sntcount_clipn-gramsum_n-gram-in-sntprimecountn-gram"><span class="math display">\[P_{n} = \frac{\sum_{n-gram \ \in \ snt}{Count_{clip}(n-gram)}}{\sum_{n-gram \ \in \ snt^{\prime}}{Count(n-gram)}}\]</span></h3>
<ul>
<li>We clip the occurrence count of an n-gram at how many times it appears in the reference sentence to avoid repetitive generations.</li>
<li>We sum over all the examples in the corpus <span class="math inline">\(C\)</span>.</li>
</ul>
</section>
<section id="p_n-fracsum_snt-in-csum_n-gram-in-sntcount_clipn-gramsum_sntprime-in-csum_n-gram-in-sntprimecountn-gram" class="level3">
<h3 class="anchored" data-anchor-id="p_n-fracsum_snt-in-csum_n-gram-in-sntcount_clipn-gramsum_sntprime-in-csum_n-gram-in-sntprimecountn-gram"><span class="math display">\[P_{n} = \frac{\sum_{snt \ \in \ C}\sum_{n-gram \ \in \ snt}{Count_{clip}(n-gram)}}{\sum_{snt^{\prime} \ \in \ C}\sum_{n-gram \ \in \ snt^{\prime}}{Count(n-gram)}}\]</span></h3>
<ul>
<li>The precision score favors short sentences.</li>
<li>The authors of BLEU introduce a brevity penalty to account for this.</li>
</ul>
</section>
<section id="br-min-left1efrac1---ell_refell_gen-right" class="level3">
<h3 class="anchored" data-anchor-id="br-min-left1efrac1---ell_refell_gen-right"><span class="math display">\[BR = min \left(1,e^{\frac{1 - \ell_{ref}}{\ell_{gen}}} \right)\]</span></h3>
<ul>
<li>By taking the minimum, we ensure that this penalty never exceeds <span class="math inline">\(1\)</span>, and the exponential term becomes exponentially small when the length of the generated text is smaller than the reference text.</li>
<li>We don’t use recall because it would incentivize translations that used all the words from all reference texts.</li>
<li>The equation for the BLEU score:</li>
</ul>
</section>
<section id="textbleu-n-br-times-left-prodn_n1p_n-rightfrac1n" class="level3">
<h3 class="anchored" data-anchor-id="textbleu-n-br-times-left-prodn_n1p_n-rightfrac1n"><span class="math display">\[\text{BLEU-N} = BR \times \left( \prod^{N}_{n=1}{P_{n}} \right)^{\frac{1}{N}}\]</span></h3>
<ul>
<li>The last term is the geometric mean of the modified precision up to n-gram <span class="math inline">\(N\)</span>.</li>
<li>The BLEU score does not account for synonyms and uses fragile heuristics.</li>
<li><a href="https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213">Evaluating Text Output in NLP: BLEU at your own risk</a>
<ul>
<li>This post provides an exposition of BLEU’s flaws.</li>
</ul></li>
<li>The default BLEU metric expects tokenized text, leading to varying results for different tokenization methods.</li>
<li>The SacreBLEU metric internalizes the tokenization step and is the preferred benchmarking metric.</li>
</ul>
<hr>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_metric</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<section id="load_metric" class="level4">
<h4 class="anchored" data-anchor-id="load_metric"><code>load_metric</code></h4>
<ul>
<li><a href="https://huggingface.co/docs/datasets/v2.0.0/en/package_reference/loading_methods#datasets.load_metric">Documentation</a></li>
<li>Load a <code>datasets.Metric</code></li>
</ul>
<p><strong>Load the SacreBLEU metric</strong></p>
<div class="sourceCode" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>bleu_metric <span class="op">=</span> load_metric(<span class="st">"sacrebleu"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>bleu_metric.codebase_urls</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    ['https://github.com/mjpost/sacreBLEU']</code></pre>
<hr>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>bleu_metric</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Metric(name: "sacrebleu", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, usage: """
    Produces BLEU scores along with its sufficient statistics
    from a source against one or more references.
    
    Args:
        predictions: The system stream (a sequence of segments).
        references: A list of one or more reference streams (each a sequence of segments).
        smooth_method: The smoothing method to use. (Default: 'exp').
        smooth_value: The smoothing value. Only valid for 'floor' and 'add-k'. (Defaults: floor: 0.1, add-k: 1).
        tokenize: Tokenization method to use for BLEU. If not provided, defaults to 'zh' for Chinese, 'ja-mecab' for
            Japanese and '13a' (mteval) otherwise.
        lowercase: Lowercase the data. If True, enables case-insensitivity. (Default: False).
        force: Insist that your tokenized input is actually detokenized.
    
    Returns:
        'score': BLEU score,
        'counts': Counts,
        'totals': Totals,
        'precisions': Precisions,
        'bp': Brevity penalty,
        'sys_len': predictions length,
        'ref_len': reference length,
    
    Examples:
    
        &gt;&gt;&gt; predictions = ["hello there general kenobi", "foo bar foobar"]
        &gt;&gt;&gt; references = [["hello there general kenobi", "hello there !"], ["foo bar foobar", "foo bar foobar"]]
        &gt;&gt;&gt; sacrebleu = datasets.load_metric("sacrebleu")
        &gt;&gt;&gt; results = sacrebleu.compute(predictions=predictions, references=references)
        &gt;&gt;&gt; print(list(results.keys()))
        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']
        &gt;&gt;&gt; print(round(results["score"], 1))
        100.0
    """, stored examples: 0)</code></pre>
<p><strong>Note:</strong></p>
<ul>
<li>The bleu_metric object is an instance of the <a href="https://huggingface.co/docs/datasets/v2.0.0/en/package_reference/main_classes#datasets.Metric">Metric</a> class and works as an aggregator.</li>
<li>Add single instances with the <code>add()</code> method or whole batches via <code>add_batch()</code>.</li>
<li>Call the <code>compute()</code> method to calculate the metric.</li>
</ul>
<hr>
<div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Add a single prediction and refernce to the metric’s stack</strong></p>
<div class="sourceCode" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>bleu_metric.add(prediction<span class="op">=</span><span class="st">"the the the the the the"</span>, reference<span class="op">=</span>[<span class="st">"the cat is on the mat"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Compute the metrics with very differnt sentences</strong></p>
<div class="sourceCode" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> bleu_metric.compute(smooth_method<span class="op">=</span><span class="st">"floor"</span>, smooth_value<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"precisions"</span>] <span class="op">=</span> [np.<span class="bu">round</span>(p, <span class="dv">2</span>) <span class="cf">for</span> p <span class="kw">in</span> results[<span class="st">"precisions"</span>]]</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(results, orient<span class="op">=</span><span class="st">"index"</span>, columns<span class="op">=</span>[<span class="st">"Value"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
Value
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
score
</th>
<td>
0.0
</td>
</tr>
<tr>
<th>
counts
</th>
<td>
[2, 0, 0, 0]
</td>
</tr>
<tr>
<th>
totals
</th>
<td>
[6, 5, 4, 3]
</td>
</tr>
<tr>
<th>
precisions
</th>
<td>
[33.33, 0.0, 0.0, 0.0]
</td>
</tr>
<tr>
<th>
bp
</th>
<td>
1.0
</td>
</tr>
<tr>
<th>
sys_len
</th>
<td>
6
</td>
</tr>
<tr>
<th>
ref_len
</th>
<td>
6
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>The precision of the 1-gram is 2/6 since the word “the” appears twice in the reference text.</li>
<li>The BLEU score also works if there are multiple reference translations.</li>
<li>BLEU integrates methods to modify the precision calculation to make the metric smoother for zero counts in the n-grams.</li>
</ul>
<hr>
<p><strong>Compute the metrics with very similar sentences</strong></p>
<div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>bleu_metric.add(prediction<span class="op">=</span><span class="st">"the cat is on mat"</span>, reference<span class="op">=</span>[<span class="st">"the cat is on the mat"</span>])</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> bleu_metric.compute(smooth_method<span class="op">=</span><span class="st">"floor"</span>, smooth_value<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"precisions"</span>] <span class="op">=</span> [np.<span class="bu">round</span>(p, <span class="dv">2</span>) <span class="cf">for</span> p <span class="kw">in</span> results[<span class="st">"precisions"</span>]]</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(results, orient<span class="op">=</span><span class="st">"index"</span>, columns<span class="op">=</span>[<span class="st">"Value"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
Value
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
score
</th>
<td>
57.893007
</td>
</tr>
<tr>
<th>
counts
</th>
<td>
[5, 3, 2, 1]
</td>
</tr>
<tr>
<th>
totals
</th>
<td>
[5, 4, 3, 2]
</td>
</tr>
<tr>
<th>
precisions
</th>
<td>
[100.0, 75.0, 66.67, 50.0]
</td>
</tr>
<tr>
<th>
bp
</th>
<td>
0.818731
</td>
</tr>
<tr>
<th>
sys_len
</th>
<td>
5
</td>
</tr>
<tr>
<th>
ref_len
</th>
<td>
6
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>The precision scores are much better.</li>
<li>The 1-grams in the prediction all match.</li>
</ul>
<hr>
</section>
</section>
<section id="rouge" class="level3">
<h3 class="anchored" data-anchor-id="rouge">ROUGE</h3>
<ul>
<li><a href="https://aclanthology.org/W04-1013.pdf">ROUGE: A Package for Automatic Evaluation of Summaries</a></li>
<li>The ROUGE score targets applications like summarization, where high recall is more important than precision alone.</li>
<li>We check how many n-grams in the reference text also occur in the generated text.</li>
</ul>
</section>
<section id="textrouge-n-fracsum_sntprime-in-csum_n-gram-in-sntprimecount_matchn-gramsum_sntprime-in-csum_n-gram-in-sntprimecountn-gram" class="level3">
<h3 class="anchored" data-anchor-id="textrouge-n-fracsum_sntprime-in-csum_n-gram-in-sntprimecount_matchn-gramsum_sntprime-in-csum_n-gram-in-sntprimecountn-gram"><span class="math display">\[\text{ROUGE-N} = \frac{\sum_{snt^{\prime} \ \in \ C}\sum_{n-gram \ \in \ snt^{\prime}}{Count_{match}(n-gram)}}{\sum_{snt^{\prime} \ \in \ C}\sum_{n-gram \ \in \ snt^{\prime}}{Count(n-gram)}}\]</span></h3>
<ul>
<li>There is a separate score to measure the longest common substring (LCS) called ROUGE-L.</li>
<li>We can calculate the LCS for any pair of strings.</li>
<li>We need to normalize the LCS value when comparing two samples of different lengths.</li>
</ul>
</section>
<section id="f_lcs-fracleft-1-beta2-rightr_lcsp_lcsr_lcs-beta-p_lcs-text-where-beta-fracp_lcsr_lcs" class="level3">
<h3 class="anchored" data-anchor-id="f_lcs-fracleft-1-beta2-rightr_lcsp_lcsr_lcs-beta-p_lcs-text-where-beta-fracp_lcsr_lcs"><span class="math display">\[F_{LCS} = \frac{\left( 1 + \beta^{2} \right)R_{LCS}P_{LCS}}{R_{LCS} + \beta P_{LCS}} \text{, where } \beta = \frac{P_{LCS}}{R_{LCS}}\]</span></h3>
<ul>
<li>The Hugging Face Datasets implementation calculates two variants of ROUGE.</li>
<li>ROUGE-L calculates the score per sentence and averages it for the summaries.</li>
<li>ROUGE-Lsum calculates the score per sentence directly over the whole summary.</li>
</ul>
<hr>
<div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>rouge_metric <span class="op">=</span> load_metric(<span class="st">"rouge"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>rouge_metric.codebase_urls</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    ['https://github.com/google-research/google-research/tree/master/rouge']</code></pre>
<hr>
<div class="sourceCode" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>rouge_metric</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Metric(name: "rouge", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}, usage: """
    Calculates average rouge scores for a list of hypotheses and references
    Args:
        predictions: list of predictions to score. Each predictions
            should be a string with tokens separated by spaces.
        references: list of reference for each prediction. Each
            reference should be a string with tokens separated by spaces.
        rouge_types: A list of rouge types to calculate.
            Valid names:
            `"rouge{n}"` (e.g. `"rouge1"`, `"rouge2"`) where: {n} is the n-gram based scoring,
            `"rougeL"`: Longest common subsequence based scoring.
            `"rougeLSum"`: rougeLsum splits text using `"
    "`.
            See details in https://github.com/huggingface/datasets/issues/617
        use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.
        use_agregator: Return aggregates if this is set to True
    Returns:
        rouge1: rouge_1 (precision, recall, f1),
        rouge2: rouge_2 (precision, recall, f1),
        rougeL: rouge_l (precision, recall, f1),
        rougeLsum: rouge_lsum (precision, recall, f1)
    Examples:
    
        &gt;&gt;&gt; rouge = datasets.load_metric('rouge')
        &gt;&gt;&gt; predictions = ["hello there", "general kenobi"]
        &gt;&gt;&gt; references = ["hello there", "general kenobi"]
        &gt;&gt;&gt; results = rouge.compute(predictions=predictions, references=references)
        &gt;&gt;&gt; print(list(results.keys()))
        ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']
        &gt;&gt;&gt; print(results["rouge1"])
        AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))
        &gt;&gt;&gt; print(results["rouge1"].mid.fmeasure)
        1.0
    """, stored examples: 0)</code></pre>
<hr>
<p><strong>Apply the ROUGE score to the generated summaries</strong></p>
<div class="sourceCode" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>reference <span class="op">=</span> dataset[<span class="st">"train"</span>][<span class="dv">1</span>][<span class="st">"highlights"</span>]</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>records <span class="op">=</span> []</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>rouge_names <span class="op">=</span> [<span class="st">"rouge1"</span>, <span class="st">"rouge2"</span>, <span class="st">"rougeL"</span>, <span class="st">"rougeLsum"</span>]</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model_name <span class="kw">in</span> summaries:</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>    rouge_metric.add(prediction<span class="op">=</span>summaries[model_name], reference<span class="op">=</span>reference)</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> rouge_metric.compute()</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>    rouge_dict <span class="op">=</span> <span class="bu">dict</span>((rn, score[rn].mid.fmeasure) <span class="cf">for</span> rn <span class="kw">in</span> rouge_names)</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>    records.append(rouge_dict)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_records(records, index<span class="op">=</span>summaries.keys())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
rouge1
</th>
<th>
rouge2
</th>
<th>
rougeL
</th>
<th>
rougeLsum
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
baseline
</th>
<td>
0.303571
</td>
<td>
0.090909
</td>
<td>
0.214286
</td>
<td>
0.232143
</td>
</tr>
<tr>
<th>
gpt2
</th>
<td>
0.276596
</td>
<td>
0.065217
</td>
<td>
0.170213
</td>
<td>
0.276596
</td>
</tr>
<tr>
<th>
t5
</th>
<td>
0.486486
</td>
<td>
0.222222
</td>
<td>
0.378378
</td>
<td>
0.486486
</td>
</tr>
<tr>
<th>
bart
</th>
<td>
0.582278
</td>
<td>
0.207792
</td>
<td>
0.455696
</td>
<td>
0.506329
</td>
</tr>
<tr>
<th>
pegasus
</th>
<td>
0.866667
</td>
<td>
0.655172
</td>
<td>
0.800000
</td>
<td>
0.833333
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>The ROUGE metric in the Hugging Face Datasets library also calculates confidence intervals.
<ul>
<li>We can access the average value in the <code>mid</code> attribute and the interval with the <code>low</code> and <code>high</code>.</li>
</ul></li>
<li>GPT-2 is the only model not explicitly trained to summarize, and it performs the worst.</li>
<li>The first-three-sentence baseline performs better than the GPT-2 model.</li>
<li>PEGASUS performs the best by a wide margin.</li>
</ul>
<hr>
</section>
</section>
<section id="evaluating-pegasus-on-the-cnndailymail-dataset" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-pegasus-on-the-cnndailymail-dataset">Evaluating PEGASUS on the CNN/DailyMail Dataset</h2>
<div class="sourceCode" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset, load_metric</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSeq2SeqLM, AutoTokenizer</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> load_dataset(<span class="st">"cnn_dailymail"</span>, version<span class="op">=</span><span class="st">"3.0.0"</span>)</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>rouge_metric <span class="op">=</span> load_metric(<span class="st">"rouge"</span>, cache_dir<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>rouge_names <span class="op">=</span> [<span class="st">"rouge1"</span>, <span class="st">"rouge2"</span>, <span class="st">"rougeL"</span>, <span class="st">"rougeLsum"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Define a function to evaluate the three-sentence baseline</strong></p>
<div class="sourceCode" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_summaries_baseline(dataset, metric,</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>                                column_text<span class="op">=</span><span class="st">"article"</span>, </span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>                                column_summary<span class="op">=</span><span class="st">"highlights"</span>):</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>    summaries <span class="op">=</span> [three_sentence_summary(text) <span class="cf">for</span> text <span class="kw">in</span> dataset[column_text]]</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>    metric.add_batch(predictions<span class="op">=</span>summaries,</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>                     references<span class="op">=</span>dataset[column_summary])    </span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> metric.compute()</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Evaluate the baseline summary on the test set</strong></p>
<div class="sourceCode" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Only use 1,000 samples</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>test_sampled <span class="op">=</span> dataset[<span class="st">"test"</span>].shuffle(seed<span class="op">=</span><span class="dv">42</span>).select(<span class="bu">range</span>(<span class="dv">1000</span>))</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> evaluate_summaries_baseline(test_sampled, rouge_metric)</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>rouge_dict <span class="op">=</span> <span class="bu">dict</span>((rn, score[rn].mid.fmeasure) <span class="cf">for</span> rn <span class="kw">in</span> rouge_names)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(rouge_dict, orient<span class="op">=</span><span class="st">"index"</span>, columns<span class="op">=</span>[<span class="st">"baseline"</span>]).T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
rouge1
</th>
<th>
rouge2
</th>
<th>
rougeL
</th>
<th>
rougeLsum
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
baseline
</th>
<td>
0.388071
</td>
<td>
0.170554
</td>
<td>
0.247146
</td>
<td>
0.354972
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<div class="sourceCode" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Set compute device</strong></p>
<div class="sourceCode" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Define a function to split the dataset into smaller batches</strong></p>
<div class="sourceCode" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> chunks(list_of_elements, batch_size):</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Yield successive batch-sized chunks from list_of_elements."""</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(list_of_elements), batch_size):</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> list_of_elements[i : i <span class="op">+</span> batch_size]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Define a function to evalue the PEGASUS model</strong></p>
<div class="sourceCode" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_summaries_pegasus(dataset, metric, model, tokenizer, </span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>                               batch_size<span class="op">=</span><span class="dv">16</span>, device<span class="op">=</span>device, </span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>                               column_text<span class="op">=</span><span class="st">"article"</span>, </span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>                               column_summary<span class="op">=</span><span class="st">"highlights"</span>):</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    article_batches <span class="op">=</span> <span class="bu">list</span>(chunks(dataset[column_text], batch_size))</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>    target_batches <span class="op">=</span> <span class="bu">list</span>(chunks(dataset[column_summary], batch_size))</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> article_batch, target_batch <span class="kw">in</span> tqdm(</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">zip</span>(article_batches, target_batches), total<span class="op">=</span><span class="bu">len</span>(article_batches)):</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> tokenizer(article_batch, max_length<span class="op">=</span><span class="dv">1024</span>,  truncation<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>                        padding<span class="op">=</span><span class="st">"max_length"</span>, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>        summaries <span class="op">=</span> model.generate(input_ids<span class="op">=</span>inputs[<span class="st">"input_ids"</span>].to(device),</span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>                         attention_mask<span class="op">=</span>inputs[<span class="st">"attention_mask"</span>].to(device), </span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>                         length_penalty<span class="op">=</span><span class="fl">0.8</span>, num_beams<span class="op">=</span><span class="dv">8</span>, max_length<span class="op">=</span><span class="dv">128</span>)</span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>        decoded_summaries <span class="op">=</span> [tokenizer.decode(s, skip_special_tokens<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a>                                clean_up_tokenization_spaces<span class="op">=</span><span class="va">True</span>) </span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a>               <span class="cf">for</span> s <span class="kw">in</span> summaries]</span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a>        decoded_summaries <span class="op">=</span> [d.replace(<span class="st">"&lt;n&gt;"</span>, <span class="st">" "</span>) <span class="cf">for</span> d <span class="kw">in</span> decoded_summaries]</span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a>        metric.add_batch(predictions<span class="op">=</span>decoded_summaries, references<span class="op">=</span>target_batch)</span>
<span id="cb69-23"><a href="#cb69-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb69-24"><a href="#cb69-24" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> metric.compute()</span>
<span id="cb69-25"><a href="#cb69-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Free unoccupied cached memory</strong></p>
<div class="sourceCode" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> <span class="va">None</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>torch.cuda.empty_cache()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Load a pretrained PEGASUS model for sequence-to-sequence tasks</strong></p>
<div class="sourceCode" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>model_ckpt <span class="op">=</span> <span class="st">"google/pegasus-cnn_dailymail"</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_ckpt)</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Evaluate the PEGASUS model on the test set</strong></p>
<div class="sourceCode" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> evaluate_summaries_pegasus(test_sampled, rouge_metric, </span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>                                   model, tokenizer, batch_size<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>rouge_dict <span class="op">=</span> <span class="bu">dict</span>((rn, score[rn].mid.fmeasure) <span class="cf">for</span> rn <span class="kw">in</span> rouge_names)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(rouge_dict, index<span class="op">=</span>[<span class="st">"pegasus"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
rouge1
</th>
<th>
rouge2
</th>
<th>
rougeL
</th>
<th>
rougeLsum
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
pegasus
</th>
<td>
0.427195
</td>
<td>
0.207378
</td>
<td>
0.305054
</td>
<td>
0.36919
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>The loss is independent of the decoding strategy.</li>
<li>The ROUGE score is highly dependent on the decoding strategy.</li>
<li>ROUGE and BLEU correlate better with human judgment than loss or accuracy.</li>
</ul>
<hr>
</section>
<section id="training-a-summarization-model" class="level2">
<h2 class="anchored" data-anchor-id="training-a-summarization-model">Training a Summarization Model</h2>
<section id="the-samsum-dataset" class="level3">
<h3 class="anchored" data-anchor-id="the-samsum-dataset">The SAMSum Dataset</h3>
<ul>
<li><a href="https://huggingface.co/datasets/samsum">Hugging Face Dataset Card</a></li>
<li>The SAMSum dataset contains about 16k messenger-like conversations with summaries.</li>
<li>These dialogues could represent the interactions between a customer and the support center in an enterprise setting.
<ul>
<li>Generating accurate summaries can help improve customer service and detect common patterns among customer requests.</li>
</ul></li>
</ul>
<p><strong>Load the SAMSum dataset</strong></p>
<div class="sourceCode" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>dataset_samsum <span class="op">=</span> load_dataset(<span class="st">"samsum"</span>)</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>split_lengths <span class="op">=</span> [<span class="bu">len</span>(dataset_samsum[split])<span class="cf">for</span> split <span class="kw">in</span> dataset_samsum]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>View sample from dataset</strong></p>
<div class="sourceCode" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Split lengths: </span><span class="sc">{</span>split_lengths<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Features: </span><span class="sc">{</span>dataset_samsum[<span class="st">'train'</span>]<span class="sc">.</span>column_names<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Dialogue:"</span>)</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dataset_samsum[<span class="st">"test"</span>][<span class="dv">0</span>][<span class="st">"dialogue"</span>])</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Summary:"</span>)</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dataset_samsum[<span class="st">"test"</span>][<span class="dv">0</span>][<span class="st">"summary"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Split lengths: [14732, 819, 818]
    Features: ['id', 'dialogue', 'summary']
    
    Dialogue:
    Hannah: Hey, do you have Betty's number?
    Amanda: Lemme check
    Hannah: &lt;file_gif&gt;
    Amanda: Sorry, can't find it.
    Amanda: Ask Larry
    Amanda: He called her last time we were at the park together
    Hannah: I don't know him well
    Hannah: &lt;file_gif&gt;
    Amanda: Don't be shy, he's very nice
    Hannah: If you say so..
    Hannah: I'd rather you texted him
    Amanda: Just text him 🙂
    Hannah: Urgh.. Alright
    Hannah: Bye
    Amanda: Bye bye
    
    Summary:
    Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.</code></pre>
<p><strong>Note:</strong> The dialogues resemble a typical chat application, including emojis and placeholders for GIFs.</p>
<hr>
</section>
<section id="evaluating-pegasus-on-samsum" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-pegasus-on-samsum">Evaluating PEGASUS on SAMSum</h3>
<p><strong>Free unoccupied cached memory</strong></p>
<div class="sourceCode" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>torch.cuda.empty_cache()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Reset random seed</strong></p>
<div class="sourceCode" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a text generation pipeline with the PEGASUS model</strong></p>
<div class="sourceCode" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(<span class="st">"summarization"</span>, model<span class="op">=</span><span class="st">"google/pegasus-cnn_dailymail"</span>, device<span class="op">=</span>device_num)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>pipe_out <span class="op">=</span> pipe(dataset_samsum[<span class="st">"test"</span>][<span class="dv">0</span>][<span class="st">"dialogue"</span>])</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Summary:"</span>)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pipe_out[<span class="dv">0</span>][<span class="st">"summary_text"</span>].replace(<span class="st">" .&lt;n&gt;"</span>, <span class="st">".</span><span class="ch">\n</span><span class="st">"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Summary:
    Amanda: Ask Larry Amanda: He called her last time we were at the park together.
    Hannah: I'd rather you texted him.
    Amanda: Just text him .</code></pre>
<p><strong>Note:</strong></p>
<ul>
<li>The model tries to summarize by extracting the key sentences from the dialogue.</li>
<li>The summaries in SAMSum are more abstract.</li>
</ul>
<hr>
<p><strong>Reset random seed</strong></p>
<div class="sourceCode" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Free unoccupied cached memory</strong></p>
<div class="sourceCode" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> <span class="va">None</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>torch.cuda.empty_cache()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Load a pretrained PEGASUS model for sequence-to-sequence tasks</strong></p>
<div class="sourceCode" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>model_ckpt <span class="op">=</span> <span class="st">"google/pegasus-cnn_dailymail"</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_ckpt)</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Run the full ROUGE evaluation on the test set</strong></p>
<div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> evaluate_summaries_pegasus(dataset_samsum[<span class="st">"test"</span>], rouge_metric, model,</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>                                   tokenizer, column_text<span class="op">=</span><span class="st">"dialogue"</span>,</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>                                   column_summary<span class="op">=</span><span class="st">"summary"</span>, batch_size<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>rouge_dict <span class="op">=</span> <span class="bu">dict</span>((rn, score[rn].mid.fmeasure) <span class="cf">for</span> rn <span class="kw">in</span> rouge_names)</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(rouge_dict, index<span class="op">=</span>[<span class="st">"pegasus"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
rouge1
</th>
<th>
rouge2
</th>
<th>
rougeL
</th>
<th>
rougeLsum
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
pegasus
</th>
<td>
0.296091
</td>
<td>
0.087493
</td>
<td>
0.229237
</td>
<td>
0.229642
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong> The results are not great since the SAMSum dataset is quite different from the CNN/DailyMail dataset.</p>
<hr>
</section>
<section id="fine-tuning-pegasus" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-pegasus">Fine-Tuning PEGASUS</h3>
<p><strong>Examine the length distribution of the input and output</strong></p>
<div class="sourceCode" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>d_len <span class="op">=</span> [<span class="bu">len</span>(tokenizer.encode(s)) <span class="cf">for</span> s <span class="kw">in</span> dataset_samsum[<span class="st">"train"</span>][<span class="st">"dialogue"</span>]]</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>s_len <span class="op">=</span> [<span class="bu">len</span>(tokenizer.encode(s)) <span class="cf">for</span> s <span class="kw">in</span> dataset_samsum[<span class="st">"train"</span>][<span class="st">"summary"</span>]]</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="fl">3.5</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].hist(d_len, bins<span class="op">=</span><span class="dv">20</span>, color<span class="op">=</span><span class="st">"C0"</span>, edgecolor<span class="op">=</span><span class="st">"C0"</span>)</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"Dialogue Token Length"</span>)</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">"Length"</span>)</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">"Count"</span>)</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].hist(s_len, bins<span class="op">=</span><span class="dv">20</span>, color<span class="op">=</span><span class="st">"C0"</span>, edgecolor<span class="op">=</span><span class="st">"C0"</span>)</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">"Summary Token Length"</span>)</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">"Length"</span>)</span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_144_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>Most dialogues are shorter than the CNN/DailyMail articles, with 100-200 tokens per dialogue.</li>
<li>The summaries are also much short, with around 20-40 tokens.</li>
</ul>
<hr>
<p><strong>Define a function to tokenize the SAMSum dataset</strong></p>
<div class="sourceCode" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_examples_to_features(example_batch):</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>    input_encodings <span class="op">=</span> tokenizer(example_batch[<span class="st">"dialogue"</span>], max_length<span class="op">=</span><span class="dv">1024</span>,</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>                                truncation<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Temporarily set the tokenizer for the decoder</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> tokenizer.as_target_tokenizer():</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>        target_encodings <span class="op">=</span> tokenizer(example_batch[<span class="st">"summary"</span>], max_length<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>                                     truncation<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"input_ids"</span>: input_encodings[<span class="st">"input_ids"</span>],</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">"attention_mask"</span>: input_encodings[<span class="st">"attention_mask"</span>],</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>            <span class="st">"labels"</span>: target_encodings[<span class="st">"input_ids"</span>]}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note:</strong> Some models require special tokens in the decoder inputs.</p>
<hr>
<p><strong>Tokenize the dataset</strong></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>dataset_samsum_pt <span class="op">=</span> dataset_samsum.<span class="bu">map</span>(convert_examples_to_features, </span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>                                       batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> [<span class="st">"input_ids"</span>, <span class="st">"labels"</span>, <span class="st">"attention_mask"</span>]</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>dataset_samsum_pt.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">"torch"</span>, columns<span class="op">=</span>columns)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a data collator</strong></p>
<ul>
<li>The Trainer object calls a data collator before feeding the batch through the model.</li>
<li>The data collator for summarization tasks needs to stack the inputs and prepare the targets for the decoder.</li>
<li>It is common to apply teacher forcing in the decoder in a sequence-to-sequence setup.
<ul>
<li>Teacher forcing involves feeding the decoder input tokens that consist of the labels shifted by one in addition to * the encoder output.</li>
<li>The decoder gets the ground truth shifted by one as input when making predictions.</li>
<li>We shift by one, so the decoder only sees the previous ground truth labels and not the current or future ones.</li>
<li>The decoder already has masked self-attention that masks all inputs at present and in the future.</li>
</ul></li>
</ul>
<p><strong>Visualize shifting the decoder input by one</strong></p>
<div class="sourceCode" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> [<span class="st">'PAD'</span>,<span class="st">'Transformers'</span>, <span class="st">'are'</span>, <span class="st">'awesome'</span>, <span class="st">'for'</span>, <span class="st">'text'</span>, <span class="st">'summarization'</span>]</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> []</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(text)<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>    rows.append({<span class="st">'step'</span>: i<span class="op">+</span><span class="dv">1</span>, <span class="st">'decoder_input'</span>: text[:i<span class="op">+</span><span class="dv">1</span>], <span class="st">'label'</span>: text[i<span class="op">+</span><span class="dv">1</span>]})</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(rows).set_index(<span class="st">'step'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
decoder_input
</th>
<th>
label
</th>
</tr>
<tr>
<th>
step
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
[PAD]
</td>
<td>
Transformers
</td>
</tr>
<tr>
<th>
2
</th>
<td>
[PAD, Transformers]
</td>
<td>
are
</td>
</tr>
<tr>
<th>
3
</th>
<td>
[PAD, Transformers, are]
</td>
<td>
awesome
</td>
</tr>
<tr>
<th>
4
</th>
<td>
[PAD, Transformers, are, awesome]
</td>
<td>
for
</td>
</tr>
<tr>
<th>
5
</th>
<td>
[PAD, Transformers, are, awesome, for]
</td>
<td>
text
</td>
</tr>
<tr>
<th>
6
</th>
<td>
[PAD, Transformers, are, awesome, for, text]
</td>
<td>
summarization
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<div class="sourceCode" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> DataCollatorForSeq2Seq</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<section id="datacollatorforseq2seq" class="level4">
<h4 class="anchored" data-anchor-id="datacollatorforseq2seq"><code>DataCollatorForSeq2Seq</code></h4>
<ul>
<li><a href="https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorForSeq2Seq">Documentation</a></li>
<li>Create a data collator for language modeling.</li>
<li>The data collator dynamically pads inputs to the maximum length of a batch.</li>
</ul>
<hr>
<div class="sourceCode" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>print_source(DataCollatorForSeq2Seq)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    @dataclass
    class DataCollatorForSeq2Seq:
        tokenizer: PreTrainedTokenizerBase
        model: Optional[Any] = None
        padding: Union[bool, str, PaddingStrategy] = True
        max_length: Optional[int] = None
        pad_to_multiple_of: Optional[int] = None
        label_pad_token_id: int = -100
        return_tensors: str = 'pt'
    
        def __call__(self, features, return_tensors=None):
            if return_tensors is None:
                return_tensors = self.return_tensors
            labels = [feature['labels'] for feature in features
                ] if 'labels' in features[0].keys() else None
            if labels is not None:
                max_label_length = max(len(l) for l in labels)
                padding_side = self.tokenizer.padding_side
                for feature in features:
                    remainder = [self.label_pad_token_id] * (max_label_length -
                        len(feature['labels']))
                    if isinstance(feature['labels'], list):
                        feature['labels'] = (feature['labels'] + remainder if 
                            padding_side == 'right' else remainder + feature[
                            'labels'])
                    elif padding_side == 'right':
                        feature['labels'] = np.concatenate([feature['labels'],
                            remainder]).astype(np.int64)
                    else:
                        feature['labels'] = np.concatenate([remainder, feature[
                            'labels']]).astype(np.int64)
            features = self.tokenizer.pad(features, padding=self.padding,
                max_length=self.max_length, pad_to_multiple_of=self.
                pad_to_multiple_of, return_tensors=return_tensors)
            if self.model is not None and hasattr(self.model,
                'prepare_decoder_input_ids_from_labels'):
                decoder_input_ids = (self.model.
                    prepare_decoder_input_ids_from_labels(labels=features[
                    'labels']))
                features['decoder_input_ids'] = decoder_input_ids
            return features</code></pre>
<hr>
<p><strong>Initialize the data collator</strong></p>
<div class="sourceCode" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>seq2seq_data_collator <span class="op">=</span> DataCollatorForSeq2Seq(tokenizer, model<span class="op">=</span>model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> TrainingArguments, Trainer</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Prepare training arguments</strong></p>
<div class="sourceCode" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">'pegasus-samsum'</span>, num_train_epochs<span class="op">=</span><span class="dv">1</span>, warmup_steps<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">1</span>, per_device_eval_batch_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>, logging_steps<span class="op">=</span><span class="dv">10</span>, push_to_hub<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">'steps'</span>, eval_steps<span class="op">=</span><span class="dv">500</span>, save_steps<span class="op">=</span><span class="fl">1e6</span>,</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">16</span>, fp16<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    PyTorch: setting up devices
    The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).</code></pre>
<hr>
<p><strong>Disable Tokenizers Parallelism</strong></p>
<div class="sourceCode" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>env TOKENIZERS_PARALLELISM<span class="op">=</span>false</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    env: TOKENIZERS_PARALLELISM=false</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> huggingface_hub <span class="im">import</span> notebook_login</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Log into Hugging Face account</strong></p>
<div class="sourceCode" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>notebook_login()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Login successful
    Your token has been saved to /home/innom-dt/.huggingface/token</code></pre>
<hr>
<p><strong>Free unoccupied cached memory</strong></p>
<div class="sourceCode" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> <span class="va">None</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>torch.cuda.empty_cache()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Initialize the Trainer object</strong></p>
<div class="sourceCode" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(model<span class="op">=</span>model, args<span class="op">=</span>training_args,</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>                  tokenizer<span class="op">=</span>tokenizer, data_collator<span class="op">=</span>seq2seq_data_collator,</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>                  train_dataset<span class="op">=</span>dataset_samsum_pt[<span class="st">"train"</span>], </span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>                  eval_dataset<span class="op">=</span>dataset_samsum_pt[<span class="st">"validation"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Note:</strong> Had to add the following workaround.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>old_collator <span class="op">=</span> trainer.data_collator</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>trainer.data_collator <span class="op">=</span> <span class="kw">lambda</span> data: <span class="bu">dict</span>(old_collator(data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Run the training loop and evaluate the trained model</strong></p>
<div class="sourceCode" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> evaluate_summaries_pegasus(</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>    dataset_samsum[<span class="st">"test"</span>], rouge_metric, trainer.model, tokenizer,</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">2</span>, column_text<span class="op">=</span><span class="st">"dialogue"</span>, column_summary<span class="op">=</span><span class="st">"summary"</span>)</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>rouge_dict <span class="op">=</span> <span class="bu">dict</span>((rn, score[rn].mid.fmeasure) <span class="cf">for</span> rn <span class="kw">in</span> rouge_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    The following columns in the training set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: summary, dialogue, id.
    ***** Running training *****
      Num examples = 14732
      Num Epochs = 1
      Instantaneous batch size per device = 1
      Total train batch size (w. parallel, distributed &amp; accumulation) = 16
      Gradient Accumulation steps = 16
      Total optimization steps = 920</code></pre>
<pre><code>100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [05:03&lt;00:00,  1.35it/s]</code></pre>
<hr>
<div class="sourceCode" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(rouge_dict, index<span class="op">=</span>[<span class="ss">f"pegasus"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
rouge1
</th>
<th>
rouge2
</th>
<th>
rougeL
</th>
<th>
rougeLsum
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
pegasus
</th>
<td>
0.424058
</td>
<td>
0.191855
</td>
<td>
0.333271
</td>
<td>
0.333591
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong> The ROUGE scores are significantly better than the model without fine-tuning.</p>
<hr>
<p><strong>Push the final model to the Hugging Face Hub</strong></p>
<div class="sourceCode" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>trainer.push_to_hub(<span class="st">"Training complete!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Saving model checkpoint to pegasus-samsum
    Configuration saved in pegasus-samsum/config.json
    Model weights saved in pegasus-samsum/pytorch_model.bin
    tokenizer config file saved in pegasus-samsum/tokenizer_config.json
    Special tokens file saved in pegasus-samsum/special_tokens_map.json


    'https://huggingface.co/cj-mills/pegasus-samsum/commit/696c3fca143486ed2288d90c06dd93257cb42c0f'</code></pre>
<hr>
</section>
</section>
<section id="evaluate-generations-as-part-of-the-training-loop" class="level3">
<h3 class="anchored" data-anchor-id="evaluate-generations-as-part-of-the-training-loop">Evaluate Generations as Part of the Training Loop</h3>
<hr>
<div class="sourceCode" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> Seq2SeqTrainingArguments, Seq2SeqTrainer</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>seq2seq_training_args <span class="op">=</span> Seq2SeqTrainingArguments(</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">'pegasus-samsum'</span>, num_train_epochs<span class="op">=</span><span class="dv">1</span>, warmup_steps<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">1</span>, per_device_eval_batch_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>, logging_steps<span class="op">=</span><span class="dv">10</span>, push_to_hub<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">'steps'</span>, eval_steps<span class="op">=</span><span class="dv">500</span>, save_steps<span class="op">=</span><span class="fl">1e6</span>,</span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">16</span>, fp16<span class="op">=</span><span class="va">True</span>, predict_with_generate<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    PyTorch: setting up devices
    The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).</code></pre>
<hr>
<div class="sourceCode" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>seq2seq_trainer <span class="op">=</span> Seq2SeqTrainer(model<span class="op">=</span>model, args<span class="op">=</span>seq2seq_training_args,</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>                  tokenizer<span class="op">=</span>tokenizer, data_collator<span class="op">=</span>seq2seq_data_collator,</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>                  train_dataset<span class="op">=</span>dataset_samsum_pt[<span class="st">"train"</span>], </span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>                  eval_dataset<span class="op">=</span>dataset_samsum_pt[<span class="st">"validation"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    /media/innom-dt/Samsung_T3/Projects/Current_Projects/nlp-with-transformers-book/notebooks/pegasus-samsum is already a clone of https://huggingface.co/cj-mills/pegasus-samsum. Make sure you pull the latest changes with `repo.git_pull()`.
    Using amp fp16 backend</code></pre>
<hr>
<p><strong>Note:</strong> Had to add the following workaround.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>old_collator <span class="op">=</span> seq2seq_trainer.data_collator</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>seq2seq_trainer.data_collator <span class="op">=</span> <span class="kw">lambda</span> data: <span class="bu">dict</span>(old_collator(data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>seq2seq_trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    The following columns in the training set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: summary, dialogue, id.
    ***** Running training *****
      Num examples = 14732
      Num Epochs = 1
      Instantaneous batch size per device = 1
      Total train batch size (w. parallel, distributed &amp; accumulation) = 16
      Gradient Accumulation steps = 16
      Total optimization steps = 920</code></pre>
<hr>
<div class="sourceCode" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>seq2seq_score <span class="op">=</span> evaluate_summaries_pegasus(</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>    dataset_samsum[<span class="st">"test"</span>], rouge_metric, seq2seq_trainer.model, tokenizer,</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">2</span>, column_text<span class="op">=</span><span class="st">"dialogue"</span>, column_summary<span class="op">=</span><span class="st">"summary"</span>)</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a>seq2seq_rouge_dict <span class="op">=</span> <span class="bu">dict</span>((rn, score[rn].mid.fmeasure) <span class="cf">for</span> rn <span class="kw">in</span> rouge_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(seq2seq_rouge_dict, index<span class="op">=</span>[<span class="ss">f"pegasus"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
rouge1
</th>
<th>
rouge2
</th>
<th>
rougeL
</th>
<th>
rougeLsum
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
pegasus
</th>
<td>
0.424058
</td>
<td>
0.191855
</td>
<td>
0.333271
</td>
<td>
0.333591
</td>
</tr>
</tbody>

</table>
</div>
<hr>
</section>
<section id="generating-dialogue-summaries" class="level3">
<h3 class="anchored" data-anchor-id="generating-dialogue-summaries">Generating Dialogue Summaries</h3>
<div class="sourceCode" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>gen_kwargs <span class="op">=</span> {<span class="st">"length_penalty"</span>: <span class="fl">0.8</span>, <span class="st">"num_beams"</span>:<span class="dv">8</span>, <span class="st">"max_length"</span>: <span class="dv">128</span>}</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>sample_text <span class="op">=</span> dataset_samsum[<span class="st">"test"</span>][<span class="dv">0</span>][<span class="st">"dialogue"</span>]</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>reference <span class="op">=</span> dataset_samsum[<span class="st">"test"</span>][<span class="dv">0</span>][<span class="st">"summary"</span>]</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up a pipeline with the uploaded model</span></span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(<span class="st">"summarization"</span>, model<span class="op">=</span><span class="st">"cj-mills/pegasus-samsum"</span>)</span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Dialogue:"</span>)</span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sample_text)</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Reference Summary:"</span>)</span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(reference)</span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Model Summary:"</span>)</span>
<span id="cb120-12"><a href="#cb120-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pipe(sample_text, <span class="op">**</span>gen_kwargs)[<span class="dv">0</span>][<span class="st">"summary_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Dialogue:
    Hannah: Hey, do you have Betty's number?
    Amanda: Lemme check
    Hannah: &lt;file_gif&gt;
    Amanda: Sorry, can't find it.
    Amanda: Ask Larry
    Amanda: He called her last time we were at the park together
    Hannah: I don't know him well
    Hannah: &lt;file_gif&gt;
    Amanda: Don't be shy, he's very nice
    Hannah: If you say so..
    Hannah: I'd rather you texted him
    Amanda: Just text him 🙂
    Hannah: Urgh.. Alright
    Hannah: Bye
    Amanda: Bye bye
    
    Reference Summary:
    Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.
    
    Model Summary:
    Amanda can't find Betty's number. Larry called Betty the last time they were at the park together. Hannah wants Amanda to text him instead.</code></pre>
<p><strong>Note:</strong> The model learned to synthesize the dialogue into a summary without extracting existing passages.</p>
<hr>
<p><strong>Test the fine-tuned model on custom input</strong></p>
<div class="sourceCode" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>custom_dialogue <span class="op">=</span> <span class="st">"""</span><span class="ch">\</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a><span class="st">Thom: Hi guys, have you heard of transformers?</span></span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a><span class="st">Lewis: Yes, I used them recently!</span></span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a><span class="st">Leandro: Indeed, there is a great library by Hugging Face.</span></span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a><span class="st">Thom: I know, I helped build it ;)</span></span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a><span class="st">Lewis: Cool, maybe we should write a book about it. What do you think?</span></span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a><span class="st">Leandro: Great idea, how hard can it be?!</span></span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true" tabindex="-1"></a><span class="st">Thom: I am in!</span></span>
<span id="cb122-9"><a href="#cb122-9" aria-hidden="true" tabindex="-1"></a><span class="st">Lewis: Awesome, let's do it together!</span></span>
<span id="cb122-10"><a href="#cb122-10" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb122-11"><a href="#cb122-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pipe(custom_dialogue, <span class="op">**</span>gen_kwargs)[<span class="dv">0</span>][<span class="st">"summary_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Thom, Lewis and Leandro are going to write a book about transformers. Thom helped build a library by Hugging Face. They are going to do it together.</code></pre>
<p><strong>Note:</strong> The model generated a coherent summary and synthesized the third and fourth lines into a logical combination.</p>
<hr>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<ul>
<li>It is still an open question regarding the best way to summarize texts longer than the model’s content size.</li>
<li><a href="https://arxiv.org/abs/2109.10862">Recursively Summarizing Books with Human Feedback</a>
<ul>
<li>OpenAI scaled summarization by applying the model recursively to long documents and using human feedback.</li>
</ul></li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://transformersbook.com/">Natural Language Processing with Transformers Book</a></li>
<li><a href="https://github.com/nlp-with-transformers/notebooks">The Transformers book GitHub Repository</a></li>
</ul>
<p><strong>Previous:</strong> <a href="../chapter-5/">Notes on Transformers Book Ch. 5</a></p>
<p><strong>Next:</strong> <a href="../chapter-7/">Notes on Transformers Book Ch. 7</a></p>
<!-- Cloudflare Web Analytics -->
<script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;56b8d2f624604c4891327b3c0d9f6703&quot;}"></script>
<!-- End Cloudflare Web Analytics -->


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } 
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="cj-mills/christianjmills" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">
        <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2022, Christian J. Mills
  </li>  
</ul>
      </div>
  </div>
</footer>



</body></html>