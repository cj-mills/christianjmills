<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-07-17">
<meta name="description" content="This follow-up to the fastai-to-unity tutorial covers creating an OpenVINO plugin for the Unity game engine. Part 1 covers the required modifications to the original training code.">

<title>Christian Mills - How to Create an OpenVINO Plugin for Unity on Windows Pt. 1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Christian Mills - How to Create an OpenVINO Plugin for Unity on Windows Pt. 1">
<meta property="og:description" content="This follow-up to the fastai-to-unity tutorial covers creating an OpenVINO plugin for the Unity game engine. Part 1 covers the required modifications to the original training code.">
<meta property="og:image" content="https://christianjmills.com/images/logo.png">
<meta property="og:site-name" content="Christian Mills">
<meta property="og:image:height" content="295">
<meta property="og:image:width" content="300">
<meta name="twitter:title" content="Christian Mills - How to Create an OpenVINO Plugin for Unity on Windows Pt. 1">
<meta name="twitter:description" content="This follow-up to the fastai-to-unity tutorial covers creating an OpenVINO plugin for the Unity game engine. Part 1 covers the required modifications to the original training code.">
<meta name="twitter:image" content="https://christianjmills.com/images/logo.png">
<meta name="twitter:creator" content="@cdotjdotmills">
<meta name="twitter:image-height" content="295">
<meta name="twitter:image-width" content="300">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Christian Mills</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cj-mills"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/cdotjdotmills"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../index.xml"><i class="bi bi-rss" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">How to Create an OpenVINO Plugin for Unity on Windows Pt. 1</h1>
  </div>

<div>
  <div class="description">
    This follow-up to the fastai-to-unity tutorial covers creating an OpenVINO plugin for the Unity game engine. Part 1 covers the required modifications to the original training code.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 17, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#overview">Overview</a></li>
<li><a href="#install-dependencies">Install Dependencies</a></li>
<li><a href="#select-a-model">Select a Model</a></li>
<li><a href="#modify-transforms">Modify Transforms</a></li>
<li><a href="#define-learner">Define Learner</a></li>
<li><a href="#export-the-model">Export the Model</a></li>
<li><a href="#benchmark-openvino-inference">Benchmark OpenVINO Inference</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>This tutorial is a follow-up to the <a href="../../fastai-to-unity-tutorial/part-1">fastai-to-unity</a> tutorial series and covers using <a href="https://docs.openvino.ai/latest/index.html">OpenVINO</a>, an open-source toolkit for optimizing model inference, instead of Unity’s Barracuda library. OpenVINO enables significantly faster CPU inference than Barracuda and supports more model types. It also supports GPU inference for integrated and discrete Intel GPUs and will be able to leverage the AI hardware acceleration available in Intel’s upcoming ARC GPUs.</p>
<p>We’ll modify the <a href="https://github.com/cj-mills/fastai-to-unity-tutorial">original tutorial code</a> and create a dynamic link library (<a href="https://docs.microsoft.com/en-us/troubleshoot/windows-client/deployment/dynamic-link-library">DLL</a>) file to access the OpenVINO functionality in Unity.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><video src="./videos/openvino-plugin-demo.mp4" class="img-fluid" controls=""><a href="./videos/openvino-plugin-demo.mp4">Video</a></video></p>
<p></p><figcaption class="figure-caption">openvino-plugin-demo</figcaption><p></p>
</figure>
</div>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>This post covers the required modifications to the <a href="https://github.com/cj-mills/fastai-to-unity-tutorial#training-code">original training code</a>. We’ll finetune models from the <a href="https://github.com/rwightman/pytorch-image-models">Timm library</a> on the same <a href="https://www.kaggle.com/datasets/belalelwikel/asl-and-some-words">ASL dataset</a> as the original tutorial, just like in this <a href="../../fastai-libtorch-unity-tutorial/part-1/">previous follow-up</a>. Below is a link to the complete modified training code, along with links for running the notebook on Google Colab and Kaggle.</p>
<table class="table">
<thead>
<tr class="header">
<th>GitHub Repository</th>
<th>Colab</th>
<th>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kaggle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/cj-mills/fastai-to-openvino-to-unity-tutorial/blob/main/notebooks/Fastai-timm-to-OpenVINO-Tutorial.ipynb">Jupyter Notebook</a></td>
<td><a href="https://colab.research.google.com/github/cj-mills/fastai-to-openvino-to-unity-tutorial/blob/main/notebooks/Fastai-timm-to-OpenVINO-Tutorial.ipynb">Open in Colab</a></td>
<td><a href="https://kaggle.com/kernels/welcome?src=https://github.com/cj-mills/fastai-to-openvino-to-unity-tutorial/blob/main/notebooks/Fastai-timm-to-OpenVINO-Tutorial.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Kaggle"></a></td>
</tr>
</tbody>
</table>
</section>
<section id="install-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="install-dependencies">Install Dependencies</h2>
<p>The <a href="https://pypi.org/project/timm/">pip package</a> for the Timm library is generally more stable than the GitHub repository but may have fewer model types and pretrained weights. However, the latest pip version had some issues running the MobileNetV3 models at the time of writing. Downgrade to version <code>0.5.4</code> to use those models.</p>
<p>Recent <a href="https://github.com/fastai/fastai/releases/tag/2.7.0">updates</a> to the fastai library resolve some <a href="https://benjaminwarner.dev/2022/06/14/debugging-pytorch-performance-decrease">performance issues</a> with PyTorch so let’s update that too.</p>
<p>We need to install the <a href="https://pypi.org/project/openvino-dev/"><code>openvino-dev</code></a> pip package to convert trained models to OpenVINO’s <a href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_IR_and_opsets.html">Intermediate Representation</a> (IR) format.</p>
<p><strong>Uncomment the cell below if running on Google Colab or Kaggle</strong></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %%capture</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U torch torchvision torchaudio</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U fastai==2.7.6</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U kaggle==1.5.12</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U Pillow==9.1.0</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U timm==0.6.5 # more stable fewer models</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># # !pip3 install -U git+https://github.com/rwightman/pytorch-image-models.git # more models less stable</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install openvino-dev==2022.1.0 </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note for Colab:</strong> You must restart the runtime in order to use newly installed version of Pillow.</p>
<p><strong>Import all fastai computer vision functionality</strong></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> fastai</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>fastai.__version__</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'2.7.6'</code></pre>
<p><strong>Disable max rows and columns for pandas</strong></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'max_colwidth'</span>, <span class="va">None</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_rows'</span>, <span class="va">None</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="select-a-model" class="level2">
<h2 class="anchored" data-anchor-id="select-a-model">Select a Model</h2>
<p>Let’s start by selecting a model from the Timm library to finetune. The available pretrained models depend on the version of the Timm library installed.</p>
<p><strong>Import the Timm library</strong></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> timm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>timm.__version__</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'0.6.5'</code></pre>
<p><strong>Check available pretrained model types</strong></p>
<p>We can check which model types have pretrained weights using the <code>timm.list_models()</code> function.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>model_types <span class="op">=</span> <span class="bu">list</span>(<span class="bu">set</span>([model.split(<span class="st">'_'</span>)[<span class="dv">0</span>] <span class="cf">for</span> model <span class="kw">in</span> timm.list_models(pretrained<span class="op">=</span><span class="va">True</span>)]))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>model_types.sort()</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(model_types)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
adv
</td>
</tr>
<tr>
<th>
1
</th>
<td>
bat
</td>
</tr>
<tr>
<th>
2
</th>
<td>
beit
</td>
</tr>
<tr>
<th>
3
</th>
<td>
botnet26t
</td>
</tr>
<tr>
<th>
4
</th>
<td>
cait
</td>
</tr>
<tr>
<th>
5
</th>
<td>
coat
</td>
</tr>
<tr>
<th>
6
</th>
<td>
convit
</td>
</tr>
<tr>
<th>
7
</th>
<td>
convmixer
</td>
</tr>
<tr>
<th>
8
</th>
<td>
convnext
</td>
</tr>
<tr>
<th>
9
</th>
<td>
crossvit
</td>
</tr>
<tr>
<th>
10
</th>
<td>
cs3darknet
</td>
</tr>
<tr>
<th>
11
</th>
<td>
cspdarknet53
</td>
</tr>
<tr>
<th>
12
</th>
<td>
cspresnet50
</td>
</tr>
<tr>
<th>
13
</th>
<td>
cspresnext50
</td>
</tr>
<tr>
<th>
14
</th>
<td>
darknet53
</td>
</tr>
<tr>
<th>
15
</th>
<td>
deit
</td>
</tr>
<tr>
<th>
16
</th>
<td>
deit3
</td>
</tr>
<tr>
<th>
17
</th>
<td>
densenet121
</td>
</tr>
<tr>
<th>
18
</th>
<td>
densenet161
</td>
</tr>
<tr>
<th>
19
</th>
<td>
densenet169
</td>
</tr>
<tr>
<th>
20
</th>
<td>
densenet201
</td>
</tr>
<tr>
<th>
21
</th>
<td>
densenetblur121d
</td>
</tr>
<tr>
<th>
22
</th>
<td>
dla102
</td>
</tr>
<tr>
<th>
23
</th>
<td>
dla102x
</td>
</tr>
<tr>
<th>
24
</th>
<td>
dla102x2
</td>
</tr>
<tr>
<th>
25
</th>
<td>
dla169
</td>
</tr>
<tr>
<th>
26
</th>
<td>
dla34
</td>
</tr>
<tr>
<th>
27
</th>
<td>
dla46
</td>
</tr>
<tr>
<th>
28
</th>
<td>
dla46x
</td>
</tr>
<tr>
<th>
29
</th>
<td>
dla60
</td>
</tr>
<tr>
<th>
30
</th>
<td>
dla60x
</td>
</tr>
<tr>
<th>
31
</th>
<td>
dm
</td>
</tr>
<tr>
<th>
32
</th>
<td>
dpn107
</td>
</tr>
<tr>
<th>
33
</th>
<td>
dpn131
</td>
</tr>
<tr>
<th>
34
</th>
<td>
dpn68
</td>
</tr>
<tr>
<th>
35
</th>
<td>
dpn68b
</td>
</tr>
<tr>
<th>
36
</th>
<td>
dpn92
</td>
</tr>
<tr>
<th>
37
</th>
<td>
dpn98
</td>
</tr>
<tr>
<th>
38
</th>
<td>
eca
</td>
</tr>
<tr>
<th>
39
</th>
<td>
ecaresnet101d
</td>
</tr>
<tr>
<th>
40
</th>
<td>
ecaresnet269d
</td>
</tr>
<tr>
<th>
41
</th>
<td>
ecaresnet26t
</td>
</tr>
<tr>
<th>
42
</th>
<td>
ecaresnet50d
</td>
</tr>
<tr>
<th>
43
</th>
<td>
ecaresnet50t
</td>
</tr>
<tr>
<th>
44
</th>
<td>
ecaresnetlight
</td>
</tr>
<tr>
<th>
45
</th>
<td>
edgenext
</td>
</tr>
<tr>
<th>
46
</th>
<td>
efficientnet
</td>
</tr>
<tr>
<th>
47
</th>
<td>
efficientnetv2
</td>
</tr>
<tr>
<th>
48
</th>
<td>
ens
</td>
</tr>
<tr>
<th>
49
</th>
<td>
ese
</td>
</tr>
<tr>
<th>
50
</th>
<td>
fbnetc
</td>
</tr>
<tr>
<th>
51
</th>
<td>
fbnetv3
</td>
</tr>
<tr>
<th>
52
</th>
<td>
gc
</td>
</tr>
<tr>
<th>
53
</th>
<td>
gcresnet33ts
</td>
</tr>
<tr>
<th>
54
</th>
<td>
gcresnet50t
</td>
</tr>
<tr>
<th>
55
</th>
<td>
gcresnext26ts
</td>
</tr>
<tr>
<th>
56
</th>
<td>
gcresnext50ts
</td>
</tr>
<tr>
<th>
57
</th>
<td>
gernet
</td>
</tr>
<tr>
<th>
58
</th>
<td>
ghostnet
</td>
</tr>
<tr>
<th>
59
</th>
<td>
gluon
</td>
</tr>
<tr>
<th>
60
</th>
<td>
gmixer
</td>
</tr>
<tr>
<th>
61
</th>
<td>
gmlp
</td>
</tr>
<tr>
<th>
62
</th>
<td>
halo2botnet50ts
</td>
</tr>
<tr>
<th>
63
</th>
<td>
halonet26t
</td>
</tr>
<tr>
<th>
64
</th>
<td>
halonet50ts
</td>
</tr>
<tr>
<th>
65
</th>
<td>
haloregnetz
</td>
</tr>
<tr>
<th>
66
</th>
<td>
hardcorenas
</td>
</tr>
<tr>
<th>
67
</th>
<td>
hrnet
</td>
</tr>
<tr>
<th>
68
</th>
<td>
ig
</td>
</tr>
<tr>
<th>
69
</th>
<td>
inception
</td>
</tr>
<tr>
<th>
70
</th>
<td>
jx
</td>
</tr>
<tr>
<th>
71
</th>
<td>
lambda
</td>
</tr>
<tr>
<th>
72
</th>
<td>
lamhalobotnet50ts
</td>
</tr>
<tr>
<th>
73
</th>
<td>
lcnet
</td>
</tr>
<tr>
<th>
74
</th>
<td>
legacy
</td>
</tr>
<tr>
<th>
75
</th>
<td>
levit
</td>
</tr>
<tr>
<th>
76
</th>
<td>
mixer
</td>
</tr>
<tr>
<th>
77
</th>
<td>
mixnet
</td>
</tr>
<tr>
<th>
78
</th>
<td>
mnasnet
</td>
</tr>
<tr>
<th>
79
</th>
<td>
mobilenetv2
</td>
</tr>
<tr>
<th>
80
</th>
<td>
mobilenetv3
</td>
</tr>
<tr>
<th>
81
</th>
<td>
mobilevit
</td>
</tr>
<tr>
<th>
82
</th>
<td>
mobilevitv2
</td>
</tr>
<tr>
<th>
83
</th>
<td>
nasnetalarge
</td>
</tr>
<tr>
<th>
84
</th>
<td>
nf
</td>
</tr>
<tr>
<th>
85
</th>
<td>
nfnet
</td>
</tr>
<tr>
<th>
86
</th>
<td>
pit
</td>
</tr>
<tr>
<th>
87
</th>
<td>
pnasnet5large
</td>
</tr>
<tr>
<th>
88
</th>
<td>
poolformer
</td>
</tr>
<tr>
<th>
89
</th>
<td>
regnetv
</td>
</tr>
<tr>
<th>
90
</th>
<td>
regnetx
</td>
</tr>
<tr>
<th>
91
</th>
<td>
regnety
</td>
</tr>
<tr>
<th>
92
</th>
<td>
regnetz
</td>
</tr>
<tr>
<th>
93
</th>
<td>
repvgg
</td>
</tr>
<tr>
<th>
94
</th>
<td>
res2net101
</td>
</tr>
<tr>
<th>
95
</th>
<td>
res2net50
</td>
</tr>
<tr>
<th>
96
</th>
<td>
res2next50
</td>
</tr>
<tr>
<th>
97
</th>
<td>
resmlp
</td>
</tr>
<tr>
<th>
98
</th>
<td>
resnest101e
</td>
</tr>
<tr>
<th>
99
</th>
<td>
resnest14d
</td>
</tr>
<tr>
<th>
100
</th>
<td>
resnest200e
</td>
</tr>
<tr>
<th>
101
</th>
<td>
resnest269e
</td>
</tr>
<tr>
<th>
102
</th>
<td>
resnest26d
</td>
</tr>
<tr>
<th>
103
</th>
<td>
resnest50d
</td>
</tr>
<tr>
<th>
104
</th>
<td>
resnet101
</td>
</tr>
<tr>
<th>
105
</th>
<td>
resnet101d
</td>
</tr>
<tr>
<th>
106
</th>
<td>
resnet10t
</td>
</tr>
<tr>
<th>
107
</th>
<td>
resnet14t
</td>
</tr>
<tr>
<th>
108
</th>
<td>
resnet152
</td>
</tr>
<tr>
<th>
109
</th>
<td>
resnet152d
</td>
</tr>
<tr>
<th>
110
</th>
<td>
resnet18
</td>
</tr>
<tr>
<th>
111
</th>
<td>
resnet18d
</td>
</tr>
<tr>
<th>
112
</th>
<td>
resnet200d
</td>
</tr>
<tr>
<th>
113
</th>
<td>
resnet26
</td>
</tr>
<tr>
<th>
114
</th>
<td>
resnet26d
</td>
</tr>
<tr>
<th>
115
</th>
<td>
resnet26t
</td>
</tr>
<tr>
<th>
116
</th>
<td>
resnet32ts
</td>
</tr>
<tr>
<th>
117
</th>
<td>
resnet33ts
</td>
</tr>
<tr>
<th>
118
</th>
<td>
resnet34
</td>
</tr>
<tr>
<th>
119
</th>
<td>
resnet34d
</td>
</tr>
<tr>
<th>
120
</th>
<td>
resnet50
</td>
</tr>
<tr>
<th>
121
</th>
<td>
resnet50d
</td>
</tr>
<tr>
<th>
122
</th>
<td>
resnet51q
</td>
</tr>
<tr>
<th>
123
</th>
<td>
resnet61q
</td>
</tr>
<tr>
<th>
124
</th>
<td>
resnetaa50
</td>
</tr>
<tr>
<th>
125
</th>
<td>
resnetblur50
</td>
</tr>
<tr>
<th>
126
</th>
<td>
resnetrs101
</td>
</tr>
<tr>
<th>
127
</th>
<td>
resnetrs152
</td>
</tr>
<tr>
<th>
128
</th>
<td>
resnetrs200
</td>
</tr>
<tr>
<th>
129
</th>
<td>
resnetrs270
</td>
</tr>
<tr>
<th>
130
</th>
<td>
resnetrs350
</td>
</tr>
<tr>
<th>
131
</th>
<td>
resnetrs420
</td>
</tr>
<tr>
<th>
132
</th>
<td>
resnetrs50
</td>
</tr>
<tr>
<th>
133
</th>
<td>
resnetv2
</td>
</tr>
<tr>
<th>
134
</th>
<td>
resnext101
</td>
</tr>
<tr>
<th>
135
</th>
<td>
resnext26ts
</td>
</tr>
<tr>
<th>
136
</th>
<td>
resnext50
</td>
</tr>
<tr>
<th>
137
</th>
<td>
resnext50d
</td>
</tr>
<tr>
<th>
138
</th>
<td>
rexnet
</td>
</tr>
<tr>
<th>
139
</th>
<td>
sebotnet33ts
</td>
</tr>
<tr>
<th>
140
</th>
<td>
sehalonet33ts
</td>
</tr>
<tr>
<th>
141
</th>
<td>
selecsls42b
</td>
</tr>
<tr>
<th>
142
</th>
<td>
selecsls60
</td>
</tr>
<tr>
<th>
143
</th>
<td>
selecsls60b
</td>
</tr>
<tr>
<th>
144
</th>
<td>
semnasnet
</td>
</tr>
<tr>
<th>
145
</th>
<td>
sequencer2d
</td>
</tr>
<tr>
<th>
146
</th>
<td>
seresnet152d
</td>
</tr>
<tr>
<th>
147
</th>
<td>
seresnet33ts
</td>
</tr>
<tr>
<th>
148
</th>
<td>
seresnet50
</td>
</tr>
<tr>
<th>
149
</th>
<td>
seresnext101
</td>
</tr>
<tr>
<th>
150
</th>
<td>
seresnext101d
</td>
</tr>
<tr>
<th>
151
</th>
<td>
seresnext26d
</td>
</tr>
<tr>
<th>
152
</th>
<td>
seresnext26t
</td>
</tr>
<tr>
<th>
153
</th>
<td>
seresnext26ts
</td>
</tr>
<tr>
<th>
154
</th>
<td>
seresnext50
</td>
</tr>
<tr>
<th>
155
</th>
<td>
seresnextaa101d
</td>
</tr>
<tr>
<th>
156
</th>
<td>
skresnet18
</td>
</tr>
<tr>
<th>
157
</th>
<td>
skresnet34
</td>
</tr>
<tr>
<th>
158
</th>
<td>
skresnext50
</td>
</tr>
<tr>
<th>
159
</th>
<td>
spnasnet
</td>
</tr>
<tr>
<th>
160
</th>
<td>
ssl
</td>
</tr>
<tr>
<th>
161
</th>
<td>
swin
</td>
</tr>
<tr>
<th>
162
</th>
<td>
swinv2
</td>
</tr>
<tr>
<th>
163
</th>
<td>
swsl
</td>
</tr>
<tr>
<th>
164
</th>
<td>
tf
</td>
</tr>
<tr>
<th>
165
</th>
<td>
tinynet
</td>
</tr>
<tr>
<th>
166
</th>
<td>
tnt
</td>
</tr>
<tr>
<th>
167
</th>
<td>
tresnet
</td>
</tr>
<tr>
<th>
168
</th>
<td>
tv
</td>
</tr>
<tr>
<th>
169
</th>
<td>
twins
</td>
</tr>
<tr>
<th>
170
</th>
<td>
vgg11
</td>
</tr>
<tr>
<th>
171
</th>
<td>
vgg13
</td>
</tr>
<tr>
<th>
172
</th>
<td>
vgg16
</td>
</tr>
<tr>
<th>
173
</th>
<td>
vgg19
</td>
</tr>
<tr>
<th>
174
</th>
<td>
visformer
</td>
</tr>
<tr>
<th>
175
</th>
<td>
vit
</td>
</tr>
<tr>
<th>
176
</th>
<td>
volo
</td>
</tr>
<tr>
<th>
177
</th>
<td>
wide
</td>
</tr>
<tr>
<th>
178
</th>
<td>
xception
</td>
</tr>
<tr>
<th>
179
</th>
<td>
xception41
</td>
</tr>
<tr>
<th>
180
</th>
<td>
xception41p
</td>
</tr>
<tr>
<th>
181
</th>
<td>
xception65
</td>
</tr>
<tr>
<th>
182
</th>
<td>
xception65p
</td>
</tr>
<tr>
<th>
183
</th>
<td>
xception71
</td>
</tr>
<tr>
<th>
184
</th>
<td>
xcit
</td>
</tr>
</tbody>

</table>
</div>
<p>Timm provides many pretrained models, but not all of them are fast enough for real-time applications. We can filter the results by providing a full or partial model name.</p>
<p><strong>Check available pretrained <a href="https://arxiv.org/abs/2201.03545">ConvNeXt</a> models</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(timm.list_models(<span class="st">'convnext*'</span>, pretrained<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
convnext_base
</td>
</tr>
<tr>
<th>
1
</th>
<td>
convnext_base_384_in22ft1k
</td>
</tr>
<tr>
<th>
2
</th>
<td>
convnext_base_in22ft1k
</td>
</tr>
<tr>
<th>
3
</th>
<td>
convnext_base_in22k
</td>
</tr>
<tr>
<th>
4
</th>
<td>
convnext_large
</td>
</tr>
<tr>
<th>
5
</th>
<td>
convnext_large_384_in22ft1k
</td>
</tr>
<tr>
<th>
6
</th>
<td>
convnext_large_in22ft1k
</td>
</tr>
<tr>
<th>
7
</th>
<td>
convnext_large_in22k
</td>
</tr>
<tr>
<th>
8
</th>
<td>
convnext_small
</td>
</tr>
<tr>
<th>
9
</th>
<td>
convnext_small_384_in22ft1k
</td>
</tr>
<tr>
<th>
10
</th>
<td>
convnext_small_in22ft1k
</td>
</tr>
<tr>
<th>
11
</th>
<td>
convnext_small_in22k
</td>
</tr>
<tr>
<th>
12
</th>
<td>
convnext_tiny
</td>
</tr>
<tr>
<th>
13
</th>
<td>
convnext_tiny_384_in22ft1k
</td>
</tr>
<tr>
<th>
14
</th>
<td>
convnext_tiny_hnf
</td>
</tr>
<tr>
<th>
15
</th>
<td>
convnext_tiny_in22ft1k
</td>
</tr>
<tr>
<th>
16
</th>
<td>
convnext_tiny_in22k
</td>
</tr>
<tr>
<th>
17
</th>
<td>
convnext_xlarge_384_in22ft1k
</td>
</tr>
<tr>
<th>
18
</th>
<td>
convnext_xlarge_in22ft1k
</td>
</tr>
<tr>
<th>
19
</th>
<td>
convnext_xlarge_in22k
</td>
</tr>
</tbody>

</table>
</div>
<p>Let’s go with the <code>convnext_tiny</code> model since we want higher framerates. Each model comes with a set of default configuration parameters. We must keep track of the mean and std values used to normalize the model input.</p>
<p><strong>Inspect the default configuration for the <code>convnext_tiny</code> model</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> timm.models <span class="im">import</span> convnext</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>convnext_model <span class="op">=</span> <span class="st">'convnext_tiny'</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(convnext.default_cfgs[convnext_model], orient<span class="op">=</span><span class="st">'index'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
url
</th>
<td>
https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth
</td>
</tr>
<tr>
<th>
num_classes
</th>
<td>
1000
</td>
</tr>
<tr>
<th>
input_size
</th>
<td>
(3, 224, 224)
</td>
</tr>
<tr>
<th>
pool_size
</th>
<td>
(7, 7)
</td>
</tr>
<tr>
<th>
crop_pct
</th>
<td>
0.875
</td>
</tr>
<tr>
<th>
interpolation
</th>
<td>
bicubic
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
(0.485, 0.456, 0.406)
</td>
</tr>
<tr>
<th>
std
</th>
<td>
(0.229, 0.224, 0.225)
</td>
</tr>
<tr>
<th>
first_conv
</th>
<td>
stem.0
</td>
</tr>
<tr>
<th>
classifier
</th>
<td>
head.fc
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Check available pretrained <a href="https://arxiv.org/abs/1801.04381">MobileNetV2</a> models</strong></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(timm.list_models(<span class="st">'mobilenetv2*'</span>, pretrained<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
mobilenetv2_050
</td>
</tr>
<tr>
<th>
1
</th>
<td>
mobilenetv2_100
</td>
</tr>
<tr>
<th>
2
</th>
<td>
mobilenetv2_110d
</td>
</tr>
<tr>
<th>
3
</th>
<td>
mobilenetv2_120d
</td>
</tr>
<tr>
<th>
4
</th>
<td>
mobilenetv2_140
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Inspect the default configuration for the <code>mobilenetv2_100</code> model</strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> timm.models <span class="im">import</span> efficientnet</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>mobilenetv2_model <span class="op">=</span> <span class="st">'mobilenetv2_100'</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(efficientnet.default_cfgs[mobilenetv2_model], orient<span class="op">=</span><span class="st">'index'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
url
</th>
<td>
https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv2_100_ra-b33bc2c4.pth
</td>
</tr>
<tr>
<th>
num_classes
</th>
<td>
1000
</td>
</tr>
<tr>
<th>
input_size
</th>
<td>
(3, 224, 224)
</td>
</tr>
<tr>
<th>
pool_size
</th>
<td>
(7, 7)
</td>
</tr>
<tr>
<th>
crop_pct
</th>
<td>
0.875
</td>
</tr>
<tr>
<th>
interpolation
</th>
<td>
bicubic
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
(0.485, 0.456, 0.406)
</td>
</tr>
<tr>
<th>
std
</th>
<td>
(0.229, 0.224, 0.225)
</td>
</tr>
<tr>
<th>
first_conv
</th>
<td>
conv_stem
</td>
</tr>
<tr>
<th>
classifier
</th>
<td>
classifier
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Check available pretrained <a href="">ResNet</a> models</strong></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(timm.list_models(<span class="st">'resnet*'</span>, pretrained<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
resnet10t
</td>
</tr>
<tr>
<th>
1
</th>
<td>
resnet14t
</td>
</tr>
<tr>
<th>
2
</th>
<td>
resnet18
</td>
</tr>
<tr>
<th>
3
</th>
<td>
resnet18d
</td>
</tr>
<tr>
<th>
4
</th>
<td>
resnet26
</td>
</tr>
<tr>
<th>
5
</th>
<td>
resnet26d
</td>
</tr>
<tr>
<th>
6
</th>
<td>
resnet26t
</td>
</tr>
<tr>
<th>
7
</th>
<td>
resnet32ts
</td>
</tr>
<tr>
<th>
8
</th>
<td>
resnet33ts
</td>
</tr>
<tr>
<th>
9
</th>
<td>
resnet34
</td>
</tr>
<tr>
<th>
10
</th>
<td>
resnet34d
</td>
</tr>
<tr>
<th>
11
</th>
<td>
resnet50
</td>
</tr>
<tr>
<th>
12
</th>
<td>
resnet50_gn
</td>
</tr>
<tr>
<th>
13
</th>
<td>
resnet50d
</td>
</tr>
<tr>
<th>
14
</th>
<td>
resnet51q
</td>
</tr>
<tr>
<th>
15
</th>
<td>
resnet61q
</td>
</tr>
<tr>
<th>
16
</th>
<td>
resnet101
</td>
</tr>
<tr>
<th>
17
</th>
<td>
resnet101d
</td>
</tr>
<tr>
<th>
18
</th>
<td>
resnet152
</td>
</tr>
<tr>
<th>
19
</th>
<td>
resnet152d
</td>
</tr>
<tr>
<th>
20
</th>
<td>
resnet200d
</td>
</tr>
<tr>
<th>
21
</th>
<td>
resnetaa50
</td>
</tr>
<tr>
<th>
22
</th>
<td>
resnetblur50
</td>
</tr>
<tr>
<th>
23
</th>
<td>
resnetrs50
</td>
</tr>
<tr>
<th>
24
</th>
<td>
resnetrs101
</td>
</tr>
<tr>
<th>
25
</th>
<td>
resnetrs152
</td>
</tr>
<tr>
<th>
26
</th>
<td>
resnetrs200
</td>
</tr>
<tr>
<th>
27
</th>
<td>
resnetrs270
</td>
</tr>
<tr>
<th>
28
</th>
<td>
resnetrs350
</td>
</tr>
<tr>
<th>
29
</th>
<td>
resnetrs420
</td>
</tr>
<tr>
<th>
30
</th>
<td>
resnetv2_50
</td>
</tr>
<tr>
<th>
31
</th>
<td>
resnetv2_50d_evos
</td>
</tr>
<tr>
<th>
32
</th>
<td>
resnetv2_50d_gn
</td>
</tr>
<tr>
<th>
33
</th>
<td>
resnetv2_50x1_bit_distilled
</td>
</tr>
<tr>
<th>
34
</th>
<td>
resnetv2_50x1_bitm
</td>
</tr>
<tr>
<th>
35
</th>
<td>
resnetv2_50x1_bitm_in21k
</td>
</tr>
<tr>
<th>
36
</th>
<td>
resnetv2_50x3_bitm
</td>
</tr>
<tr>
<th>
37
</th>
<td>
resnetv2_50x3_bitm_in21k
</td>
</tr>
<tr>
<th>
38
</th>
<td>
resnetv2_101
</td>
</tr>
<tr>
<th>
39
</th>
<td>
resnetv2_101x1_bitm
</td>
</tr>
<tr>
<th>
40
</th>
<td>
resnetv2_101x1_bitm_in21k
</td>
</tr>
<tr>
<th>
41
</th>
<td>
resnetv2_101x3_bitm
</td>
</tr>
<tr>
<th>
42
</th>
<td>
resnetv2_101x3_bitm_in21k
</td>
</tr>
<tr>
<th>
43
</th>
<td>
resnetv2_152x2_bit_teacher
</td>
</tr>
<tr>
<th>
44
</th>
<td>
resnetv2_152x2_bit_teacher_384
</td>
</tr>
<tr>
<th>
45
</th>
<td>
resnetv2_152x2_bitm
</td>
</tr>
<tr>
<th>
46
</th>
<td>
resnetv2_152x2_bitm_in21k
</td>
</tr>
<tr>
<th>
47
</th>
<td>
resnetv2_152x4_bitm
</td>
</tr>
<tr>
<th>
48
</th>
<td>
resnetv2_152x4_bitm_in21k
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Inspect the default configuration for the <code>resnet10t</code> model</strong></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> timm.models <span class="im">import</span> resnet</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>resnet_model <span class="op">=</span> <span class="st">'resnet10t'</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(resnet.default_cfgs[resnet_model], orient<span class="op">=</span><span class="st">'index'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:600px">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
url
</th>
<td>
https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet10t_176_c3-f3215ab1.pth
</td>
</tr>
<tr>
<th>
num_classes
</th>
<td>
1000
</td>
</tr>
<tr>
<th>
input_size
</th>
<td>
(3, 176, 176)
</td>
</tr>
<tr>
<th>
pool_size
</th>
<td>
(6, 6)
</td>
</tr>
<tr>
<th>
crop_pct
</th>
<td>
0.875
</td>
</tr>
<tr>
<th>
interpolation
</th>
<td>
bilinear
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
(0.485, 0.456, 0.406)
</td>
</tr>
<tr>
<th>
std
</th>
<td>
(0.229, 0.224, 0.225)
</td>
</tr>
<tr>
<th>
first_conv
</th>
<td>
conv1.0
</td>
</tr>
<tr>
<th>
classifier
</th>
<td>
fc
</td>
</tr>
<tr>
<th>
test_crop_pct
</th>
<td>
0.95
</td>
</tr>
<tr>
<th>
test_input_size
</th>
<td>
(3, 224, 224)
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Select a model</strong></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># model_type = convnext</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># model_name = convnext_model</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># model_type = efficientnet</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># model_name = mobilenetv2_model</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>model_type <span class="op">=</span> resnet</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> resnet_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Store normalization stats</strong></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> model_type.default_cfgs[model_name][<span class="st">'mean'</span>]</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> model_type.default_cfgs[model_name][<span class="st">'std'</span>]</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>mean, std</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))</code></pre>
</section>
<section id="modify-transforms" class="level2">
<h2 class="anchored" data-anchor-id="modify-transforms">Modify Transforms</h2>
<p>We can apply the normalization stats at the end of the batch transforms.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>item_tfms <span class="op">=</span> [FlipItem(p<span class="op">=</span><span class="fl">1.0</span>), Resize(input_dims, method<span class="op">=</span>ResizeMethod.Pad, pad_mode<span class="op">=</span>PadMode.Border)]</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>batch_tfms <span class="op">=</span> [</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    Contrast(max_lighting<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    Saturation(max_lighting<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    Hue(max_hue<span class="op">=</span><span class="fl">0.05</span>),</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">*</span>aug_transforms(</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>        size<span class="op">=</span>input_dims, </span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        mult<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        do_flip<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        flip_vert<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        max_rotate<span class="op">=</span><span class="fl">0.0</span>,</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        min_zoom<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        max_zoom<span class="op">=</span><span class="fl">1.5</span>,</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        max_lighting<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>        max_warp<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>        p_affine<span class="op">=</span><span class="fl">0.0</span>,</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>        pad_mode<span class="op">=</span>PadMode.Border),</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    Normalize.from_stats(mean<span class="op">=</span>mean, std<span class="op">=</span>std)</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="define-learner" class="level2">
<h2 class="anchored" data-anchor-id="define-learner">Define Learner</h2>
<p>The training process is identical to the original tutorial, and we only need to pass the name of the Timm model to the <code>vision_learner</code> object.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, model_name, metrics<span class="op">=</span>metrics).to_fp16()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="export-the-model" class="level2">
<h2 class="anchored" data-anchor-id="export-the-model">Export the Model</h2>
<p>The OpenVINO model conversion script does not support PyTorch models, so we need to export the trained model to ONNX. We can then convert the ONNX model to OpenVINO’s IR format.</p>
<p><strong>Define ONNX file name</strong></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>onnx_file_name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>dataset_path<span class="sc">.</span>name<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>learn<span class="sc">.</span>arch<span class="sc">}</span><span class="ss">.onnx"</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>onnx_file_name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'asl-and-some-words-resnet10t.onnx'</code></pre>
<p><strong>Export trained model to ONNX</strong></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>torch.onnx.export(learn.model.cpu(),</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>                  batched_tensor,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                  onnx_file_name,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>                  export_params<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>                  opset_version<span class="op">=</span><span class="dv">11</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>                  do_constant_folding<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>                  input_names <span class="op">=</span> [<span class="st">'input'</span>],</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>                  output_names <span class="op">=</span> [<span class="st">'output'</span>],</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>                  dynamic_axes<span class="op">=</span>{<span class="st">'input'</span>: {<span class="dv">2</span> : <span class="st">'height'</span>, <span class="dv">3</span> : <span class="st">'width'</span>}}</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>                 )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now we can define the argument for OpenVINO’s model conversion script.</p>
<p><strong>Import OpenVINO Dependencies</strong></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Markdown, display</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openvino.runtime <span class="im">import</span> Core</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define export directory</strong></p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> Path(<span class="st">'./'</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>output_dir</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Path('.')</code></pre>
<p><strong>Define path for OpenVINO IR xml model file</strong></p>
<p>The conversion script generates an XML containing information about the model architecture and a BIN file that stores the trained weights. We need both files to perform inference. OpenVINO uses the same name for the BIN file as provided for the XML file.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>ir_path <span class="op">=</span> Path(<span class="ss">f"</span><span class="sc">{</span>onnx_file_name<span class="sc">.</span>split(<span class="st">'.'</span>)[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">.xml"</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>ir_path</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Path('asl-and-some-words-resnet10t.xml')</code></pre>
<p><strong>Define arguments for model conversion script</strong></p>
<p>OpenVINO provides the option to include the normalization stats in the IR model. That way, we don’t need to account for different normalization stats when performing inference with multiple models. We can also convert the model to FP16 precision to reduce file size and improve inference speed.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct the command for Model Optimizer</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>mo_command <span class="op">=</span> <span class="ss">f"""mo</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --input_model "</span><span class="sc">{</span>onnx_file_name<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --input_shape "[1,3, </span><span class="sc">{</span>input_dims[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>input_dims[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">]"</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --mean_values="</span><span class="sc">{</span>mean<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --scale_values="</span><span class="sc">{</span>std<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --data_type FP16</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --output_dir "</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="ss">                 """</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>mo_command <span class="op">=</span> <span class="st">" "</span>.join(mo_command.split())</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model Optimizer command to convert the ONNX model to OpenVINO:"</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>display(Markdown(<span class="ss">f"`</span><span class="sc">{</span>mo_command<span class="sc">}</span><span class="ss">`"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Model Optimizer command to convert the ONNX model to OpenVINO:</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mo</span> <span class="at">--input_model</span> <span class="st">"asl-and-some-words-resnet10t.onnx"</span> <span class="at">--input_shape</span> <span class="st">"[1,3, 216, 384]"</span> <span class="at">--mean_values</span><span class="op">=</span><span class="st">"(0.485, 0.456, 0.406)"</span> <span class="at">--scale_values</span><span class="op">=</span><span class="st">"(0.229, 0.224, 0.225)"</span> <span class="at">--data_type</span> FP16 <span class="at">--output_dir</span> <span class="st">"."</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Convert ONNX model to OpenVINO IR</strong></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> ir_path.exists():</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Exporting ONNX model to IR... This may take a few minutes."</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    mo_result <span class="op">=</span> <span class="op">%</span>sx $mo_command</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join(mo_result))</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"IR model </span><span class="sc">{</span>ir_path<span class="sc">}</span><span class="ss"> already exists."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Exporting ONNX model to IR... This may take a few minutes.
    Model Optimizer arguments:
    Common parameters:
        - Path to the Input Model:  /media/innom-dt/Samsung_T3/My_Environments/jupyter-notebooks/openvino/asl-and-some-words-resnet10t.onnx
        - Path for generated IR:    /media/innom-dt/Samsung_T3/My_Environments/jupyter-notebooks/openvino/.
        - IR output name:   asl-and-some-words-resnet10t
        - Log level:    ERROR
        - Batch:    Not specified, inherited from the model
        - Input layers:     Not specified, inherited from the model
        - Output layers:    Not specified, inherited from the model
        - Input shapes:     [1,3, 216, 384]
        - Source layout:    Not specified
        - Target layout:    Not specified
        - Layout:   Not specified
        - Mean values:  (0.485, 0.456, 0.406)
        - Scale values:     (0.229, 0.224, 0.225)
        - Scale factor:     Not specified
        - Precision of IR:  FP16
        - Enable fusing:    True
        - User transformations:     Not specified
        - Reverse input channels:   False
        - Enable IR generation for fixed input shape:   False
        - Use the transformations config file:  None
    Advanced parameters:
        - Force the usage of legacy Frontend of Model Optimizer for model conversion into IR:   False
        - Force the usage of new Frontend of Model Optimizer for model conversion into IR:  False
    OpenVINO runtime found in:  /home/innom-dt/mambaforge/envs/fastai-openvino/lib/python3.9/site-packages/openvino
    OpenVINO runtime version:   2022.1.0-7019-cdb9bec7210-releases/2022/1
    Model Optimizer version:    2022.1.0-7019-cdb9bec7210-releases/2022/1
    [ WARNING ]  
    Detected not satisfied dependencies:
        numpy: installed: 1.23.0, required: &lt; 1.20
    
    Please install required versions of components or run pip installation
    pip install openvino-dev
    [ SUCCESS ] Generated IR version 11 model.
    [ SUCCESS ] XML file: /media/innom-dt/Samsung_T3/My_Environments/jupyter-notebooks/openvino/asl-and-some-words-resnet10t.xml
    [ SUCCESS ] BIN file: /media/innom-dt/Samsung_T3/My_Environments/jupyter-notebooks/openvino/asl-and-some-words-resnet10t.bin
    [ SUCCESS ] Total execution time: 0.43 seconds. 
    [ SUCCESS ] Memory consumed: 123 MB. 
    It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&amp;source=prod&amp;campid=ww_2022_bu_IOTG_OpenVINO-2022-1&amp;content=upg_all&amp;medium=organic or on the GitHub*
    [ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
    Find more information about API v2.0 and IR v11 at https://docs.openvino.ai</code></pre>
</section>
<section id="benchmark-openvino-inference" class="level2">
<h2 class="anchored" data-anchor-id="benchmark-openvino-inference">Benchmark OpenVINO Inference</h2>
<p>Now we can compare inference speed between OpenVINO and PyTorch. OpenVINO supports inference with ONNX models in addition to its IR format.</p>
<p><strong>Get available OpenVINO compute devices</strong></p>
<p>OpenVINO does not support GPU inference with non-Intel GPUs.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>devices <span class="op">=</span> ie.available_devices</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> device <span class="kw">in</span> devices:</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    device_name <span class="op">=</span> ie.get_property(device_name<span class="op">=</span>device, name<span class="op">=</span><span class="st">"FULL_DEVICE_NAME"</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>device_name<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>CPU: 11th Gen Intel(R) Core(TM) i7-11700K @ 3.60GHz</code></pre>
<p><strong>Create normalized input for ONNX model</strong></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>normalized_input_image <span class="op">=</span> batched_tensor.cpu().detach().numpy()</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>normalized_input_image.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>(1, 3, 224, 224)</code></pre>
<p><strong>Test ONNX model using OpenVINO</strong></p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load network to Inference Engine</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>ie <span class="op">=</span> Core()</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>model_onnx <span class="op">=</span> ie.read_model(model<span class="op">=</span>onnx_file_name)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>compiled_model_onnx <span class="op">=</span> ie.compile_model(model<span class="op">=</span>model_onnx, device_name<span class="op">=</span><span class="st">"CPU"</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>input_layer_onnx <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(compiled_model_onnx.inputs))</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>output_layer_onnx <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(compiled_model_onnx.outputs))</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Run inference on the input image</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>res_onnx <span class="op">=</span> compiled_model_onnx(inputs<span class="op">=</span>[normalized_input_image])[output_layer_onnx]</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>learn.dls.vocab[np.argmax(res_onnx)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'J'</code></pre>
<p><strong>Benchmark ONNX model CPU inference speed</strong></p>
<div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>timeit</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>compiled_model_onnx(inputs<span class="op">=</span>[normalized_input_image])[output_layer_onnx]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>3.62 ms ± 61.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</code></pre>
<p><strong>Prepare input image for OpenVINO IR model</strong></p>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>input_image <span class="op">=</span> scaled_tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>input_image.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>torch.Size([1, 3, 224, 224])</code></pre>
<p><strong>Test OpenVINO IR model</strong></p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the network in Inference Engine</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>ie <span class="op">=</span> Core()</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>model_ir <span class="op">=</span> ie.read_model(model<span class="op">=</span>ir_path)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>model_ir.reshape(input_image.shape)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>compiled_model_ir <span class="op">=</span> ie.compile_model(model<span class="op">=</span>model_ir, device_name<span class="op">=</span><span class="st">"CPU"</span>)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get input and output layers</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>input_layer_ir <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(compiled_model_ir.inputs))</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>output_layer_ir <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(compiled_model_ir.outputs))</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Run inference on the input image</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>res_ir <span class="op">=</span> compiled_model_ir([input_image])[output_layer_ir]</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>learn.dls.vocab[np.argmax(res_ir)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'J'</code></pre>
<p><strong>Benchmark OpenVINO IR model CPU inference speed</strong></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>timeit</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>compiled_model_ir([input_image])[output_layer_ir]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>3.39 ms ± 84.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</code></pre>
<p><strong>Note:</strong> The IR model is slightly faster than the ONNX model and half the file size.</p>
<p><strong>Benchmark PyTorch model GPU inference speed</strong></p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>timeit</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): preds <span class="op">=</span> learn.model.cuda()(batched_tensor.cuda())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>1.81 ms ± 5.52 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</code></pre>
<p>PyTorch inference with a Titan RTX is still faster than OpenVINO inference with an i7-11700K for a ResNet10 model. However, OpenVINO CPU inference is often faster when using models optimized for mobile devices, like MobileNet.</p>
<p><strong>Benchmark PyTorch model CPU inference speed</strong></p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>timeit</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): preds <span class="op">=</span> learn.model.cpu()(batched_tensor.cpu())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>8.94 ms ± 52.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</code></pre>
<p>OpenVINO is easily faster than PyTorch for CPU inference.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>This post covered how to modify the training code from the <a href="../../fastai-to-unity-tutorial/part-1">fastai-to-unity tutorial</a>to finetune models from the Timm library and export them as OpenVINO IR models. Part 2 will cover creating a dynamic link library (<a href="https://docs.microsoft.com/en-us/troubleshoot/windows-client/deployment/dynamic-link-library">DLL</a>) file in Visual Studio to perform inference with these models using <a href="https://docs.openvino.ai/latest/index.html">OpenVINO</a>.</p>
<p><strong>Previous:</strong> <a href="../../fastai-to-unity-tutorial/part-3/">Fastai to Unity Tutorial Pt. 3</a></p>
<p><strong>Next:</strong> <a href="../part-2/">How to Create an OpenVINO Plugin for Unity on Windows Pt. 2</a></p>
<p><strong>Project Resources:</strong> <a href="https://github.com/cj-mills/fastai-to-openvino-to-unity-tutorial">GitHub Repository</a></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } 
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>