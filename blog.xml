<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Christian Mills</title>
<link>https://christianjmills.com/blog.html</link>
<atom:link href="https://christianjmills.com/blog.xml" rel="self" type="application/rss+xml"/>
<description>This is Christian Mills&#39; personal Blog.</description>
<image>
<url>https://christianjmills.com/images/logo.png</url>
<title>Christian Mills</title>
<link>https://christianjmills.com/blog.html</link>
<height>144</height>
<width>144</width>
</image>
<generator>quarto-1.4.555</generator>
<lastBuildDate>Sun, 25 Aug 2024 07:00:00 GMT</lastBuildDate>
<item>
  <title>Office Hours 7: Replicate</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-007/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<section id="what-would-replicate-like-to-see-students-push-on-the-platform" class="level3">
<h3 class="anchored" data-anchor-id="what-would-replicate-like-to-see-students-push-on-the-platform">What would Replicate like to see students push on the platform?</h3>
<ul>
<li><strong>Fine-tuned models that serve useful or interesting purposes:</strong>
<ul>
<li>Replicate encourages the development of fine-tuned models, particularly for fun and interesting applications, similar to the existing image generation community.</li>
</ul></li>
<li><strong>Focus on language model applications and community experiences:</strong>
<ul>
<li>Replicate aims to foster a similar community experience for language models, acknowledging the challenge of making business-oriented language model applications as engaging as visually-driven applications like emoji generation.</li>
</ul></li>
<li><strong>Building sophisticated chains of operations with language models:</strong>
<ul>
<li>Replicate encourages the creation of application layers on top of language models, such as chaining prompts together or performing operations across different models, leveraging Replicate’s capability to make queries within models.</li>
</ul></li>
</ul>
</section>
<section id="how-enterprise-ready-is-replicate" class="level3">
<h3 class="anchored" data-anchor-id="how-enterprise-ready-is-replicate">How enterprise-ready is Replicate?</h3>
<ul>
<li><strong>Working towards enterprise readiness, but not fully there yet:</strong>
<ul>
<li>Replicate is actively working on enterprise-ready features but hasn’t achieved complete enterprise readiness.</li>
</ul></li>
<li><strong>Flexible control over data retention available:</strong>
<ul>
<li>Replicate offers flexible data retention control and is open to discussing specific data concerns with users.</li>
</ul></li>
<li><strong>Recommendation to engage in discussions via Replicate Discord:</strong>
<ul>
<li>For detailed conversations about specific requirements, reaching out via the Replicate Discord channel is recommended.</li>
</ul></li>
</ul>
</section>
<section id="how-to-push-an-open-source-function-calling-model-compatible-with-the-openai-api" class="level3">
<h3 class="anchored" data-anchor-id="how-to-push-an-open-source-function-calling-model-compatible-with-the-openai-api">How to push an open-source function-calling model compatible with the OpenAI API?</h3>
<ul>
<li><strong>Replicate’s OpenAI-compatible API and its limitations:</strong>
<ul>
<li>Replicate offers an alternative API compatible with OpenAI, but it’s currently available for a limited set of language models.</li>
<li>Replicate is exploring broader rollout of this functionality.</li>
<li>Building a completely OpenAI-compatible predictor isn’t currently possible due to limitations in supporting certain input types like lists and lists of dictionaries.</li>
</ul></li>
<li><strong>Implementing function calling with COG’s current input types:</strong>
<ul>
<li>Workarounds exist for implementing function calling using COG’s supported input types.</li>
</ul></li>
<li><strong>Upcoming updates to COG to facilitate application development:</strong>
<ul>
<li>Replicate is actively working on updates to COG that will simplify the creation of predictors and applications, making it easier to leverage these capabilities.</li>
</ul></li>
</ul>
</section>
<section id="examples-of-desired-llm-application-layers-on-replicate" class="level3">
<h3 class="anchored" data-anchor-id="examples-of-desired-llm-application-layers-on-replicate">Examples of desired LLM application layers on Replicate</h3>
<ul>
<li><strong>Examples of web scraping and potential for complex operations within predictors:</strong>
<ul>
<li>Replicate has seen examples of users implementing tasks like web scraping using Replicate models.</li>
<li>Replicate emphasizes the platform’s ability to handle arbitrary code within predictors, enabling complex operations beyond simple model inference.</li>
</ul></li>
<li><strong>Upcoming updates to COG to facilitate application development:</strong>
<ul>
<li>COG will undergo updates to make building applications within Replicate more intuitive and accessible.</li>
</ul></li>
<li><strong>Introduction of secrets to enable secure access to credentials:</strong>
<ul>
<li>Recent introduction of secrets in Replicate allows for securely storing and using sensitive information within models, such as API keys for interacting with other services.</li>
</ul></li>
</ul>
</section>
<section id="replicates-approach-to-logging-and-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="replicates-approach-to-logging-and-evaluation">Replicate’s approach to logging and evaluation</h3>
<ul>
<li><strong>Logging inputs, outputs, and printed logs within the predict function:</strong>
<ul>
<li>Replicate logs input parameters (including defaults), outputs, and anything printed to the logs from within the <code>predict</code> function.</li>
</ul></li>
<li><strong>Permalink access to prediction data, including logs and metadata:</strong>
<ul>
<li>Each prediction on Replicate has a unique permalink providing access to comprehensive logs, inputs, outputs, and metadata, which is particularly valuable for debugging and collaboration.</li>
</ul></li>
<li><strong>Data retention policy and encryption practices:</strong>
<ul>
<li>Replicate retains prediction data for a specific duration (exact interval not specified) and offers variable retention options based on user needs.</li>
<li>Stored data is encrypted.</li>
</ul></li>
<li><strong>API availability for querying prediction data using prediction identifiers:</strong>
<ul>
<li>An API endpoint allows retrieval of prediction data (inputs, outputs, logs) using prediction identifiers.</li>
<li>Bulk endpoints for querying logs across predictions within a time range are currently not available but are under consideration.</li>
</ul></li>
</ul>
</section>
<section id="privacy-and-legal-concerns-when-fine-tuning-sdxl-with-personal-images" class="level3">
<h3 class="anchored" data-anchor-id="privacy-and-legal-concerns-when-fine-tuning-sdxl-with-personal-images">Privacy and legal concerns when fine-tuning SDXL with personal images</h3>
<ul>
<li><strong>Data retention policy and encryption practices:</strong>
<ul>
<li>While Replicate encrypts and doesn’t share user data, users concerned about the storage duration of personal images should exercise caution.</li>
</ul></li>
<li><strong>Adherence to U.S. law and regulations:</strong>
<ul>
<li>Replicate operates in compliance with U.S. laws and regulations, and any activities violating those are discouraged.</li>
</ul></li>
</ul>
</section>
<section id="evaluating-model-performance-over-time-and-understanding-user-behavior" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-model-performance-over-time-and-understanding-user-behavior">Evaluating model performance over time and understanding user behavior</h3>
<ul>
<li>Replicate acknowledges the importance of evaluating model performance over time and understanding user behavior but hasn’t implemented extensive mechanisms for this.</li>
<li><strong>Current focus on performance and reliability:</strong>
<ul>
<li>Replicate’s primary focus has been on ensuring system performance and reliability.</li>
</ul></li>
<li><strong>Interest in understanding user intent and usage patterns:</strong>
<ul>
<li>There’s growing interest in analyzing user intent and usage patterns to enhance the platform’s capabilities and optimize performance.</li>
</ul></li>
<li><strong>Potential for using EDA (Exploratory Data Analysis) and log data:</strong>
<ul>
<li>Replicate recognizes the potential of leveraging EDA techniques and log data to gain insights into user behavior and model usage.</li>
</ul></li>
</ul>
</section>
<section id="user-feedback-mechanisms-and-logging" class="level3">
<h3 class="anchored" data-anchor-id="user-feedback-mechanisms-and-logging">User feedback mechanisms and logging</h3>
<ul>
<li><strong>Consideration of thumbs-up/thumbs-down feedback mechanism:</strong>
<ul>
<li>Replicate has considered implementing a thumbs-up/thumbs-down feedback mechanism, potentially as an annotation feature.</li>
</ul></li>
<li><strong>Potential for annotation mechanisms to associate feedback with predictions:</strong>
<ul>
<li>Replicate is exploring annotation mechanisms that would enable associating feedback or other information with specific predictions, allowing for retrospective analysis and evaluation.</li>
</ul></li>
<li><strong>Client-side logging of prediction IDs and feedback as a workaround:</strong>
<ul>
<li>As a workaround, users can log prediction IDs and feedback on the client side, storing this data in their own databases.</li>
</ul></li>
<li><strong>Focus on core platform functionality and potential integration with other tools:</strong>
<ul>
<li>Replicate carefully considers which features to prioritize within the platform and aims to integrate well with other tools that may offer specialized functionality, such as observability platforms for language models.</li>
</ul></li>
</ul>
</section>
<section id="building-paid-applications-on-replicate-and-revenue-sharing" class="level3">
<h3 class="anchored" data-anchor-id="building-paid-applications-on-replicate-and-revenue-sharing">Building paid applications on Replicate and revenue sharing</h3>
<ul>
<li><strong>Lack of built-in billing patterns but potential for implementing custom solutions:</strong>
<ul>
<li>Replicate doesn’t currently offer built-in billing mechanisms within models.</li>
</ul></li>
<li><strong>Interest in revenue sharing as a model for incentivizing collaboration:</strong>
<ul>
<li>Replicate is actively exploring revenue-sharing models to incentivize collaboration and reward creators for building valuable models on the platform.</li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-007/</guid>
  <pubDate>Sun, 25 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Notes on Weapons of Mass Instruction: A Schoolteacher’s Journey Through the Dark World of Compulsory Schooling</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/weapons-of-mass-instruction-book-notes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
These notes are part of the following collection:
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="../../series/notes/education-notes.html"><strong>Education</strong></a></p>
</div>
</div>
<ul>
<li>Prologue: Against School<br>
</li>
<li>Chapter 1: Everything You Know About Schools Is Wrong<br>
</li>
<li>Chapter 2: Walkabout, London<br>
</li>
<li>Chapter 3: Fat Stanley and the Lancaster Amish<br>
</li>
<li>Chapter 4: David Sarnoff’s Classroom<br>
</li>
<li>Chapter 5. Hector Isn’t the Problem<br>
</li>
<li>Chapter 6: The Camino de Santiago<br>
</li>
<li>Chapter 7: Weapons of Mass Instruction<br>
</li>
<li>Chapter 8: What is Education?<br>
</li>
<li>Chapter 9: A Letter to My Granddaughter About Dartmouth<br>
</li>
<li>Chapter 10: Incident at Highland High</li>
<li>Afterword: Invitation to an Open Conspiracy</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Book Links:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Book Links:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://newsociety.com/books/w/weapons-of-mass-instruction">Publisher Page</a></li>
</ul>
</div>
</div>
<section id="prologue-against-school" class="level2">
<h2 class="anchored" data-anchor-id="prologue-against-school">Prologue: Against School</h2>
<section id="boredom-and-childishness-in-school" class="level3">
<h3 class="anchored" data-anchor-id="boredom-and-childishness-in-school">Boredom and Childishness in School</h3>
<ul>
<li>Gatto, a teacher for 30 years, observed pervasive boredom in schools, among both students and teachers.</li>
<li><strong>Students</strong> found schoolwork meaningless and dull, desiring more engaging and practical learning experiences.</li>
<li><strong>Teachers</strong>, equally bored, often blamed students’ lack of motivation and the rigid school structures.</li>
<li>Gatto argues that this widespread boredom is a systemic issue, not simply a matter of individual fault.</li>
</ul>
</section>
<section id="personal-experiences-and-observations" class="level3">
<h3 class="anchored" data-anchor-id="personal-experiences-and-observations">Personal Experiences and Observations</h3>
<ul>
<li>At age 7, Gatto complained of boredom to his grandfather
<ul>
<li><strong>Grandfather’s response:</strong>
<ul>
<li>Hit him on the head</li>
<li>Forbade use of the term “boredom” in his presence</li>
<li>Taught that boredom is one’s own fault</li>
<li>Obligation to amuse and instruct oneself</li>
<li>People who don’t understand this are childish and untrustworthy</li>
</ul></li>
<li>This lesson cured Gatto of boredom permanently</li>
</ul></li>
<li>Despite attempting to instill this lesson in his students, Gatto found it challenging to combat the ingrained belief that boredom is inherent to the classroom.</li>
<li>His efforts to break free from conventional teaching methods were met with resistance and even retaliation from the school system.</li>
<li>This experience solidified Gatto’s view of schools as “factories of childishness”, suppressing natural curiosity and a thirst for knowledge.</li>
</ul>
</section>
<section id="a-better-way-to-learn" class="level3">
<h3 class="anchored" data-anchor-id="a-better-way-to-learn">A Better Way to Learn</h3>
<ul>
<li>Gatto believes a more effective and engaging education is possible.</li>
<li>He proposes a system that:
<ul>
<li>Offers flexibility in time, curriculum, and assessment.</li>
<li>Connects students with knowledgeable and passionate mentors.</li>
<li>Grants students autonomy and encourages risk-taking.</li>
</ul></li>
</ul>
</section>
<section id="questioning-the-necessity-of-school" class="level3">
<h3 class="anchored" data-anchor-id="questioning-the-necessity-of-school">Questioning the Necessity of School</h3>
<ul>
<li>Gatto challenges the assumption that the current compulsory schooling system is necessary.</li>
<li>He questions the effectiveness of the traditional 12-year model, citing examples of successful individuals throughout history who thrived without formal schooling:
<ul>
<li>George Washington</li>
<li>Benjamin Franklin</li>
<li>Thomas Jefferson</li>
<li>Abraham Lincoln</li>
<li>Admiral Farragut</li>
<li>Thomas Edison</li>
<li>Andrew Carnegie</li>
<li>John D. Rockefeller</li>
<li>Herman Melville</li>
<li>Mark Twain</li>
<li>Joseph Conrad</li>
<li>Margaret Mead</li>
<li>Ariel Durant (married at 15, co-authored a multi-volume world history)</li>
</ul></li>
<li>He argues that equating success solely with formal schooling is a misconception.</li>
</ul>
</section>
<section id="the-true-purpose-of-public-schools" class="level3">
<h3 class="anchored" data-anchor-id="the-true-purpose-of-public-schools">The True Purpose of Public Schools</h3>
<ul>
<li>Gatto proposes that the real purpose of compulsory schooling deviates significantly from the commonly stated goals of creating good people, good citizens, and fostering individual potential.</li>
<li>He argues that the current system, with roots in 19th-century Prussia, aims to:
<ul>
<li>Create a manageable and obedient workforce.</li>
<li>Suppress dissent and originality.</li>
<li>Condition students into becoming unquestioning consumers.</li>
</ul></li>
</ul>
<section id="evidence-and-support" class="level4">
<h4 class="anchored" data-anchor-id="evidence-and-support">Evidence and Support</h4>
<ul>
<li><strong>H.L. Mencken (The American Mercury, April 1924):</strong> Argued that public education’s true aim is to standardize citizens, stifle dissent, and discourage independent thought.</li>
<li><strong>Historical Precedence:</strong> Gatto points to the Prussian education system as the model for the American system, designed to produce a compliant populace and workforce.
<ul>
<li><strong>William James:</strong> Alluded to the Prussian influence on American schools.</li>
<li><strong>Orestes Brownson:</strong> Denounced the “Prussianization” of American schools in the 1840s.</li>
<li><strong>Horace Mann (1853):</strong> In his seventh annual report to the Massachusetts Board of Education, he advocated for adopting the Prussian model.</li>
</ul></li>
<li><strong>Alexander Inglis (Principles of Secondary Education, 1918):</strong> Outlined six basic functions of compulsory schooling, revealing its intention to mold students into obedient and standardized citizens, categorize them for predetermined social roles, and perpetuate a system that benefits the ruling class.
<ol type="1">
<li><strong>Adjustive or Adaptive Function:</strong> Condition students to blindly obey authority.</li>
<li><strong>Integrating Function:</strong> Promote conformity and predictability.</li>
<li><strong>Diagnostic and Directive Function:</strong> Determine and assign social roles.</li>
<li><strong>Differentiating Function:</strong> Train students according to their designated roles.</li>
<li><strong>Selective Function:</strong> Identify and weed out the “unfit” through grades and placement.</li>
<li><strong>Propedeutic Function:</strong> Cultivate an elite group to manage the system.</li>
</ol></li>
</ul>
</section>
</section>
<section id="the-role-of-influential-figures" class="level3">
<h3 class="anchored" data-anchor-id="the-role-of-influential-figures">The Role of Influential Figures</h3>
<ul>
<li><strong>James Bryant Conant (President of Harvard, influential figure in 20th-century education):</strong>
<ul>
<li>Advocated for standardized testing and large, impersonal high schools.</li>
<li>In his essay <em>The Child, the Parent, and the State</em> (1959), he acknowledged a deliberate “revolution” in schooling between 1905 and 1930.</li>
</ul></li>
<li><strong>Promoters of Mandatory Schooling:</strong>
<ul>
<li><strong>George Peabody:</strong> Financier who supported mandatory schooling in the South, likely understanding its role in creating a compliant workforce and consumer base.</li>
<li><strong>Andrew Carnegie and John D. Rockefeller:</strong> Industrialists who recognized the economic benefits of a mass-educated, consumerist society.</li>
</ul></li>
<li><strong>Elwood P. Cumberley (Public Education in the United States, 1934):</strong>
<ul>
<li>Described schools as “factories” shaping children according to predetermined specifications.</li>
<li>Highlighted how mandatory schooling extended childhood and promoted consumerism.</li>
</ul></li>
<li><strong>Woodrow Wilson (President of Princeton University, 1909):</strong> Advocated for different education systems for different classes, limiting opportunities for the lower classes.
<ul>
<li><blockquote class="blockquote">
<p>“We want one class of persons to have a liberal education, and we want another class of persons, a very much larger class of necessity in every society, to forego the privileges of a liberal education and fit themselves to perform specific difficult manual tasks.”</p>
</blockquote></li>
</ul></li>
</ul>
</section>
<section id="the-consequences-a-nation-of-childish-consumers" class="level3">
<h3 class="anchored" data-anchor-id="the-consequences-a-nation-of-childish-consumers">The Consequences: A Nation of Childish Consumers</h3>
<ul>
<li>Gatto contends that the current education system has created a society of perpetual children, characterized by:
<ul>
<li>A diminished capacity for critical thinking and independent judgment.</li>
<li>A reliance on external validation and entertainment.</li>
<li>A susceptibility to manipulation by marketing and political rhetoric.</li>
<li>A willingness to accept superficial explanations and avoid challenging questions.</li>
</ul></li>
</ul>
</section>
<section id="a-call-to-action-reclaiming-education" class="level3">
<h3 class="anchored" data-anchor-id="a-call-to-action-reclaiming-education">A Call to Action: Reclaiming Education</h3>
<ul>
<li>Gatto urges parents to recognize the true nature of the school system and take control of their children’s education.</li>
<li>He encourages parents to:
<ul>
<li>Foster critical thinking, independence, and a love of learning.</li>
<li>Provide a rich and challenging curriculum that schools often neglect.</li>
<li>Encourage solitude and introspection to develop inner strength and self-reliance.</li>
<li>Resist the pressure to conform to a system that prioritizes obedience over true intellectual development.</li>
</ul></li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<ul>
<li>Gatto believes that true genius is commonplace but suppressed by a system designed to limit potential.</li>
<li>He concludes with the message: Empower children to become leaders, adventurers, and lifelong learners.</li>
</ul>
</section>
</section>
<section id="chapter-1-everything-you-know-about-schools-is-wrong" class="level2">
<h2 class="anchored" data-anchor-id="chapter-1-everything-you-know-about-schools-is-wrong">Chapter 1: Everything You Know About Schools Is Wrong</h2>
<section id="the-illusion-of-school-reform" class="level3">
<h3 class="anchored" data-anchor-id="the-illusion-of-school-reform">The Illusion of School Reform</h3>
<ul>
<li>In 1909, a factory inspector surveyed 500 children working in 20 factories and discovered that 412 of them preferred the terrible factory conditions to returning to school.
<ul>
<li>Source: Helen Todd, “Why Children Work,” <em>McClure’s Magazine</em>, April 1913.</li>
<li><strong>Archive:</strong> <a href="https://uofi.app.box.com/s/agtvym7n0hvf4qw2dr5d24txsgwrgc42">Why Children Work: The Children’s Answer By Helen M. Todd</a></li>
<li>Helen Todd received various reasons from children for favoring factory work, including:
<ol type="1">
<li><strong>Monetary Factors:</strong>
<ul>
<li>Being paid for the factory work they do.</li>
<li>The ability to support their families financially, afford more food, shoes for babies, and other basic needs.</li>
</ul></li>
<li><strong>Difficulty and Relevance of Schoolwork:</strong>
<ul>
<li>Perceived difficulty in understanding schoolwork compared to factory work.</li>
<li>Learning being perceived as hard.</li>
<li>Some children feeling unable to learn.</li>
<li>Perception that school education is not relevant to their ability to earn.</li>
</ul></li>
<li><strong>The Environment at School and Factory:</strong>
<ul>
<li>Preference for the factory environment as there is less judgment compared to school.</li>
<li>The factory environment doesn’t involve name-calling or bullying as in school.</li>
<li>They can avoid the corporal punishment experienced at school for:
<ul>
<li>Failure to learn</li>
<li>Whispering</li>
<li>Having string in their pocket</li>
<li>Squeaky seats</li>
<li>Late arrival</li>
<li>Forgetting pages of the book</li>
</ul></li>
</ul></li>
</ol></li>
</ul></li>
<li>Professor Arthur Calhoun’s 1919 book, <em>Social History of the Family</em>, announced a profound shift occurring in America’s schools, with children being transferred from their families to the custody of community experts. (page 175)
<ul>
<li><strong>Smithsonian Archive:</strong> <a href="https://library.si.edu/digital-library/book/socialhistoryof02calh">A Social History of the American Family From Colonial Times to the Present Volume 3</a></li>
</ul></li>
<li>Calhoun believed this change fulfilled the utopian dream of Darwin and Galton: scientific population control through public education to prevent the “unfit” from reproducing. (page 331)</li>
<li>This agenda, implemented without public oversight, raised concerns about an “invisible government” controlling schools.</li>
<li>Mayor John Hyland of New York City, in 1922, claimed that the city’s schools had been “seized by tentacles of an invisible government,” echoing British Prime Minister Benjamin Disraeli’s earlier pronouncements about a secretive ruling power.</li>
<li>Hyland specifically identified the Rockefeller Foundation as the controlling force in education.</li>
<li>By 1928, <em>A Sociological Philosophy of Education</em> asserted that teachers were responsible for “running not merely schools, but the world.”
<ul>
<li><strong>Book:</strong> <a href="https://books.googleusercontent.com/books/content?req=AKW5QafjppMzEtdAqelLkYKjXw1x-F2OLHg2Pe90zK_uc-9EEus2N4IEzEg_ZLII7r0kPvIE2hhmKdK91b0Yv1U9sMmHEC1zPqIwlHpXNr1-xqTfeZFT20rnIgjy9c7yEHg90_ntnPsCKE9kl5Eu-tEuC0r8Pyv28sE8v9Oa0A0IGTTLtsz0a2mXSfhx1VeZwIr9cPnvBkDsW-11pIKaNB3UPZisouDw-LPKXxnqQ3G_yvwY0KK48KlRdephQfBjnOin6pWrXLljwVceTIFBfRmRaqpgvmrNh0XpdgwcQecg5qcdHY6nGQw">A Sociological Philosophy of Education by Ross Lee Finney</a></li>
</ul></li>
<li>Edward Thorndyke, a professor at the Rockefeller-funded Columbia Teachers College and the founder of educational psychology, declared in 1929 that “academic subjects are of little value.”</li>
<li>His colleague, William Kilpatrick, argued in his book <em>Education and the Social Crisis</em> that child-rearing should be controlled by experts, as family was a “retrograde institution.”</li>
</ul>
<section id="the-control-of-human-behavior" class="level4">
<h4 class="anchored" data-anchor-id="the-control-of-human-behavior">The Control of Human Behavior</h4>
<ul>
<li>On April 11, 1933, Max Mason, president of the Rockefeller Foundation, unveiled a national program, supported by the foundation, to control human behavior, with schools playing a central role.
<ul>
<li><strong>Report:</strong> <a href="https://www.rockefellerfoundation.org/wp-content/uploads/Annual-Report-1933-1.pdf">The Rockefeller Foundation Annual Report (1933)</a></li>
<li><strong>Book Chaper:</strong> <a href="https://www.dianebpaul.com/uploads/2/3/2/9/23295024/rockefeller_foundation.pdf">DB Paul, The Rockefeller Foundation and the Origins of Behavioral Genetics. In K Benson, et al., eds., The Expansion of American Biology (New Brunswick, NJ: Rutgers Univ. Press, 1991), 263-283.</a></li>
</ul></li>
<li>Influenced by Eastern European geneticist Max Muller, the Rockefeller Foundation invested heavily in controlling human evolution.</li>
<li>Muller’s research on mutations in fruit flies using X-rays suggested the possibility of scientifically controlling all life.</li>
<li>Like Darwin and Galton before him, Muller believed that planned human breeding was the key to a utopian society.</li>
<li>His ideas were embraced by prominent scientists and powerful economic interests.</li>
<li>Muller, who later won the Nobel Prize, outlined his plan in a 1,500-word manifesto signed by 22 renowned American and British biologists.</li>
<li>The manifesto advocated for state intervention to separate “worthwhile breeding stock” from the “evolutionary dead-end material.”</li>
<li>This manifesto, advocating for eugenics, marked a shift from private discussions in the 1870s to public discourse, at least among influential figures.</li>
<li>F. Scott Fitzgerald’s novel <em>The Great Gatsby</em> alludes to this movement away from democratic egalitarian ideals.</li>
</ul>
</section>
<section id="the-post-war-transformation-of-schools" class="level4">
<h4 class="anchored" data-anchor-id="the-post-war-transformation-of-schools">The Post-War Transformation of Schools</h4>
<ul>
<li>World War II drove the eugenics movement underground, but it continued to advance.</li>
<li>After the war, a battle erupted within education between traditionalists advocating for basic literacy and numeracy skills and proponents of a more scientific and socially engineered approach, primarily funded by corporate foundations like Carnegie and Rockefeller.</li>
<li>Two congressional investigations, in 1915 and 1959, concluded that school policy was being shaped by corporate interests without public oversight, but these reports were largely ignored.</li>
<li>Between 1967 and 1974, teacher training underwent a radical transformation driven by private foundations, universities, think tanks, government agencies, and corporations.</li>
<li>This transformation was coordinated through the U.S. Office of Education and key state education departments.</li>
</ul>
<section id="three-milestones-of-the-transformation" class="level5">
<h5 class="anchored" data-anchor-id="three-milestones-of-the-transformation">Three Milestones of the Transformation:</h5>
<ol type="1">
<li><strong>Designing Education for the Future:</strong> A government-led futurology project that redefined education as a means to achieve national economic and social goals, sidelining personal development. State education agencies were tasked with enforcing compliance with federal directives.
<ul>
<li><strong>Education Resources Information Center:</strong> <a href="https://eric.ed.gov/?id=ED018008">Designing Education for the Future: An Eight-State Project</a></li>
</ul></li>
<li><strong>The Behavioral Science Teacher Education Project (BSTEP):</strong> A project outlining government plans to use schools for social engineering, including manipulating public opinion, experimenting with chemicals on minors (foreshadowing the use of drugs like Ritalin and Adderall), and creating a society where a small elite holds all the power.
<ul>
<li><strong>Feasibility Study:</strong> <a href="https://eric.ed.gov/?id=ED041868">Behavioral Science Teacher Education Program. Final Report</a></li>
</ul></li>
<li><strong>Benjamin Bloom’s Taxonomy of Educational Objectives:</strong> A comprehensive manual classifying educational goals based on how they shape students’ actions, thoughts, and feelings. This work, reminiscent of totalitarian regimes, aimed to control students’ beliefs and behaviors, “remediating” any “improper attitudes” they bring from home.
<ul>
<li><strong>Book:</strong> <a href="https://web.archive.org/web/20201212072520id_/https://www.uky.edu/~rsand1/china2018/texts/Bloom%20et%20al%20-Taxonomy%20of%20Educational%20Objectives.pdf">Taxonomy of Educational Objectives, Handbook 1: Cognitive Domain</a></li>
</ul></li>
</ol>
</section>
</section>
<section id="teachers-as-therapists" class="level4">
<h4 class="anchored" data-anchor-id="teachers-as-therapists">Teachers as Therapists</h4>
<ul>
<li>In the mid-to-late 1960s, school violence and chaos surged following a Ford Foundation policy requiring schools to adopt due process procedures for disciplining students.</li>
<li>This policy, intended to mirror the court system, rendered teachers and administrators powerless to maintain order effectively.</li>
<li>The slow and deliberate nature of due process proved inadequate in addressing immediate student misconduct.</li>
<li>Deprived of traditional disciplinary methods, classrooms descended into chaos, with students realizing that teachers were unable to intervene effectively.</li>
<li>The Behavioral Science Teacher Education Project, coinciding with this period of heightened violence, called for training teachers as “therapist,” tasked with applying social psychology principles to manage student behavior.</li>
<li>This shift redefined both curriculum and teaching, prioritizing psychological manipulation over academic instruction.</li>
</ul>
</section>
</section>
<section id="the-hidden-history-of-school-funding" class="level3">
<h3 class="anchored" data-anchor-id="the-hidden-history-of-school-funding">The Hidden History of School Funding</h3>
<ul>
<li>From 1896 to 1920, private industrialists and financiers, through their foundations, heavily funded university positions, research, and school administration, surpassing government spending on education.</li>
<li>Two individuals alone, Andrew Carnegie and John D. Rockefeller, outspent the government on education as late as 1915.</li>
<li>This privately driven system of education was established without public input or awareness.</li>
<li>The motives behind this funding were complex, but the Rockefeller General Education Board’s stated mission provides insight.</li>
<li>In their 1906 document <em>Occasional Letter No.&nbsp;1</em>, the board stated:
<ul>
<li><blockquote class="blockquote">
<p>“In our dreams, people yield themselves with perfect docility to our molding hands. The present educational conventions of intellectual and moral education fade from our minds, and unhampered by tradition we work our own goodwill upon a grateful and responsive folk. We shall not try to make these people or any of their children into philosophers or men of learning or men of science. We have not to raise up from among them authors, educators, poets, or men of letters. We shall not search for embryo great artists, painters, musicians, nor lawyers, doctors, preachers, politicians, statesmen, of whom we have ample supply. The task we set before ourselves is very simple. We will organize children and teach them to do in a perfect way the things their fathers and mothers are doing in an imperfect way.”</p>
</blockquote></li>
<li><strong>Book:</strong> <a href="https://www.loc.gov/resource/gdcmassbookdig.countryschooloft00gates/?st=pdf&amp;pdfPage=1">The country school of to-morrow</a></li>
</ul></li>
<li>This statement reveals a desire for obedience over intellect, aiming to create a workforce that conforms rather than innovates.</li>
<li>The “we” in this statement refers to the powerful elite shaping the education system.</li>
</ul>
</section>
<section id="the-decline-of-literacy" class="level3">
<h3 class="anchored" data-anchor-id="the-decline-of-literacy">The Decline of Literacy</h3>
<section id="military-literacy-data" class="level4">
<h4 class="anchored" data-anchor-id="military-literacy-data">Military Literacy Data:</h4>
<ul>
<li>At the start of World War II, millions of men underwent academic testing for military service.</li>
<li>From 1942 to 1944, 18 million men were tested, with 96% deemed literate enough (possessing a fourth-grade reading level) to serve as soldiers, a slight decline from the 98% literacy rate a decade earlier.</li>
<li>However, by the Korean War in the early 1950s, 600,000 men were rejected, and the literacy rate had plummeted to 81%, despite these men having more years of schooling and supposedly better teachers and materials.</li>
<li>By the Vietnam War in the mid-1960s, the illiteracy rate had skyrocketed to 27%, with only 73% possessing basic literacy skills, and many of those struggling to comprehend even a newspaper.</li>
</ul>
</section>
<section id="the-literacy-gap-widens" class="level4">
<h4 class="anchored" data-anchor-id="the-literacy-gap-widens">The Literacy Gap Widens:</h4>
<ul>
<li>In 1940, the literacy rate was 96% for whites and 80% for blacks.</li>
<li>Six decades later, despite a 350% increase in education spending, the Adult Literacy Survey and the National Assessment of Educational Progress reported a staggering 40% illiteracy rate among blacks and 17% among whites.</li>
<li>Charles Murray and Richard Herrnstein’s controversial book <em>The Bell Curve</em> attributed this disparity to genetics, arguing that intelligence is hereditary.</li>
<li>However, this theory is challenged by data from South Africa, where black violence rates were significantly lower than in the U.S. despite similar population sizes, and Jamaica, which boasts a 98.5% literacy rate, surpassing that of American whites.</li>
</ul>
</section>
<section id="a-shift-in-reading-instruction" class="level4">
<h4 class="anchored" data-anchor-id="a-shift-in-reading-instruction">A Shift in Reading Instruction:</h4>
<ul>
<li>During World War II, American schools transitioned from phonics-based reading instruction to “whole word” methods that relied on memorization and guessing, a change detrimental to those without prior literacy exposure.</li>
<li>While white families often maintained traditional reading practices at home, providing a safety net, black families, historically denied access to literacy during slavery and Jim Crow, lacked this advantage.</li>
<li>The Army, alarmed by the declining literacy rates, investigated the issue in 1952 and discovered that the problem lay in flawed reading instruction methods.</li>
<li>However, despite this finding, the necessary changes were not implemented.</li>
</ul>
</section>
<section id="dumbing-down-the-curriculum" class="level4">
<h4 class="anchored" data-anchor-id="dumbing-down-the-curriculum">Dumbing Down the Curriculum:</h4>
<ul>
<li>In 1995, a student teacher in Minneapolis wrote a letter to the editor of the <em>Star Tribune</em> expressing concern over the drastically lowered academic standards.</li>
<li>She compared the fifth-grade reading list from 1882, which included works by Shakespeare, Thoreau, and Twain, to the limited vocabulary expected of fifth-graders in 1995.</li>
</ul>
</section>
</section>
<section id="the-hegelian-influence-on-american-education" class="level3">
<h3 class="anchored" data-anchor-id="the-hegelian-influence-on-american-education">The Hegelian Influence on American Education</h3>
<ul>
<li>William Torrey Harris, U.S. Commissioner of Education from 1889 to 1906, played a pivotal role in shaping American education.</li>
<li>A prominent Hegelian philosopher and editor of the <em>Journal of Speculative Philosophy</em>, Harris standardized and Germanized the U.S. education system.</li>
<li>Contrary to his portrayal as a defender of classical education, Harris held radical views, believing that children were property of the state.</li>
<li>A close friend of Andrew Carnegie, Harris shared Carnegie’s vision of a society where work and education were intertwined from cradle to grave.</li>
<li>Hegel, a Prussian philosopher whose ideas influenced both Karl Marx and J.P. Morgan, taught that history could be manipulated by creating crises to justify centralized control.</li>
<li>Harris and his associates, known as the St.&nbsp;Louis Hegelians, aimed to create a utopian society by ending dissent and establishing a rigid social order.</li>
</ul>
<section id="the-goal-psychological-alienation" class="level4">
<h4 class="anchored" data-anchor-id="the-goal-psychological-alienation">The Goal: Psychological Alienation</h4>
<ul>
<li>Harris believed that achieving this utopian vision required psychologically alienating children from their families, traditions, religions, and cultures, leaving the state as the sole authority.</li>
<li>In his 1906 work <em>The Philosophy of Education</em>, Harris wrote:
<ul>
<li><blockquote class="blockquote">
<p>“Ninety-nine students out of a hundred are automata, careful to walk in prescribed paths, careful to follow the prescribed custom. This is not an accident but the result of substantial education which, scientifically defined, is the subsumption of the individual.”</p>
</blockquote></li>
</ul></li>
<li>He further argued that:
<ul>
<li><blockquote class="blockquote">
<p>“The great purpose of school, self-alienation, can be realized better in dark, airless, ugly places. It is to master the physical self, to transcend the beauty of nature. School should develop the power to withdraw from the external world.”</p>
</blockquote></li>
</ul></li>
<li>Harris saw self-alienation as essential for preparing individuals for a life of mindless labor in an industrial capitalist society, where personal fulfillment is secondary to economic productivity.</li>
<li>This system encourages conformity and discourages critical thinking, creating a workforce that is easily controlled.</li>
</ul>
</section>
</section>
<section id="the-fourth-purpose-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-fourth-purpose-of-schooling">The Fourth Purpose of Schooling</h3>
<ul>
<li>As the original goals of education were eroded, a new purpose emerged: to mold children into human resources for the corporate economy.</li>
<li>This shift aligned with the interests of those in power, who saw public education as a tool for social control and economic gain.</li>
</ul>
<section id="benefits-of-schooling-for-elites" class="level4">
<h4 class="anchored" data-anchor-id="benefits-of-schooling-for-elites">Benefits of Schooling for Elites:</h4>
<ul>
<li><strong>Job Creation:</strong> Education became a massive jobs program, expanding and contracting with employment needs.</li>
<li><strong>Ideological Control:</strong> Schools provided a means to instill loyalty to specific ideas and attitudes, ensuring a compliant workforce.</li>
<li><strong>Tax Revenue Diversion:</strong> Education served as a mechanism to collect taxes under the guise of benefiting children while channeling funds to politically connected interests.</li>
</ul>
</section>
<section id="the-erosion-of-american-ingenuity" class="level4">
<h4 class="anchored" data-anchor-id="the-erosion-of-american-ingenuity">The Erosion of American Ingenuity:</h4>
<ul>
<li>Forced schooling marked a departure from America’s early open-source learning environment, which fostered self-reliance, ingenuity, and entrepreneurial spirit.</li>
<li>This shift from production to consumption, from active to passive learning, stifled innovation and creativity.</li>
<li>By the late 19th century, education was viewed as a branch of industry, with students as products to be shaped for the workforce.</li>
<li>In a 1909 speech to businessmen, Woodrow Wilson stated:
<ul>
<li><blockquote class="blockquote">
<p>“We want one class to have a liberal education. We want another class, a very much larger class of necessity, to forego the privilege of a liberal education and fit themselves to perform specific, difficult manual tasks.”</p>
</blockquote></li>
</ul></li>
<li>This statement reveals the intention to create a two-tiered system, reserving true education for the elite and relegating the masses to vocational training.</li>
</ul>
</section>
<section id="the-education-trust" class="level4">
<h4 class="anchored" data-anchor-id="the-education-trust">The Education Trust:</h4>
<ul>
<li>By 1917, the “Education Trust,” a group representing Rockefeller, Carnegie, Harvard, Stanford, the University of Chicago, and the National Education Association, controlled most major school administration positions nationwide.</li>
<li>British evolutionist Benjamin Kidd wrote in 1918 that the primary goal of this group was to instill “the ideal of subordination” in the young.</li>
</ul>
</section>
</section>
<section id="the-spectre-of-overproduction" class="level3">
<h3 class="anchored" data-anchor-id="the-spectre-of-overproduction">The Spectre of Overproduction</h3>
<ul>
<li>One significant factor driving the push for forced schooling was the fear of “overproduction,” a concept still relevant today, often referred to as “overcapacity.”</li>
<li>Overproduction occurs when the supply of goods and services exceeds demand, leading to falling prices and economic instability.</li>
<li>In the 19th century, America’s independent and resourceful population, fueled by an open-source learning environment and a culture of innovation, frequently led to overproduction.</li>
<li>This worried investors and industrialists, who sought ways to control the economy and ensure a stable market for their products.</li>
</ul>
<section id="schooling-as-a-solution" class="level4">
<h4 class="anchored" data-anchor-id="schooling-as-a-solution">Schooling as a Solution:</h4>
<ul>
<li>Forced schooling offered a way to manage overproduction by:
<ul>
<li>Shifting the population’s focus from production to consumption.</li>
<li>Instilling habits and attitudes of obedience and conformity.</li>
<li>Creating a workforce that was less self-sufficient and more reliant on wage labor.</li>
</ul></li>
</ul>
</section>
<section id="the-corruption-of-education-by-business-values" class="level4">
<h4 class="anchored" data-anchor-id="the-corruption-of-education-by-business-values">The Corruption of Education by Business Values:</h4>
<ul>
<li>The infusion of business values into education has corrupted its true purpose.</li>
<li>Instead of fostering critical thinking, creativity, and a love of learning, schools have become instruments for producing a compliant and predictable workforce.</li>
</ul>
</section>
</section>
<section id="conclusion-reclaiming-the-promise-of-education" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-reclaiming-the-promise-of-education">Conclusion: Reclaiming the Promise of Education</h3>
<ul>
<li>For the first two centuries of its existence, America thrived on a decentralized and individualized approach to education.</li>
<li>The forced schooling model, imposed upon us in the late 19th and early 20th centuries, has stifled innovation, widened social divisions, and undermined the very principles of a free and democratic society.</li>
<li>It is time to challenge the status quo and reclaim the true promise of education: to empower individuals, cultivate critical thinking, and foster a lifelong love of learning.</li>
</ul>
</section>
</section>
<section id="chapter-2-walkabout-london" class="level2">
<h2 class="anchored" data-anchor-id="chapter-2-walkabout-london">Chapter 2: Walkabout, London</h2>
<section id="authors-note" class="level3">
<h3 class="anchored" data-anchor-id="authors-note">Author’s Note</h3>
<ul>
<li>Gatto has given ~1500 speeches in his career.</li>
<li>Only two speeches provoked angry responses:
<ul>
<li>One from the son of a famous economist.</li>
<li>Another from a famous stock speculator.</li>
</ul></li>
<li>This chapter will argue that <strong>open-source education</strong> (free-form) is superior to <strong>rule-driven, standardized schooling</strong> (testable).</li>
<li>This argument is what angered the two audience members mentioned above.</li>
</ul>
</section>
<section id="uncle-buds-miracle-a-case-for-open-source-learning" class="level3">
<h3 class="anchored" data-anchor-id="uncle-buds-miracle-a-case-for-open-source-learning">Uncle Bud’s Miracle: A Case for Open-Source Learning</h3>
<ul>
<li>Gatto’s uncle, <strong>Bud Zimmer</strong>, was a high school dropout who became a successful manager at a Rockwell plant.</li>
<li>Despite lacking a college degree, Bud managed a large workforce, including Harvard graduates.</li>
<li>Bud’s experience demonstrates that <strong>schooling does not equal education</strong>.</li>
<li>Bud had a <strong>superb education</strong> gained through real-world experiences, despite lacking formal schooling.</li>
</ul>
</section>
<section id="open-source-success-stories-challenging-conventional-wisdom" class="level3">
<h3 class="anchored" data-anchor-id="open-source-success-stories-challenging-conventional-wisdom">Open-Source Success Stories: Challenging Conventional Wisdom</h3>
<p>This section highlights individuals who achieved success through open-source learning, defying the notion that formal education is a prerequisite for success.</p>
<section id="jonathan-goodwin" class="level4">
<h4 class="anchored" data-anchor-id="jonathan-goodwin">Jonathan Goodwin</h4>
<ul>
<li><strong>Source:</strong> <em>Fast Company</em> magazine, November 2007 cover story</li>
<li>Junior high school dropout featured on the cover of Fast Company magazine.</li>
<li>Learned through experiences at a local garage (“That was my school”).</li>
<li>Identified a market opportunity in fuel-efficient car conversions.</li>
<li>Built a successful business charging up to $25,000 per conversion.</li>
<li>Became self-reliant and financially successful before reaching voting age.</li>
</ul>
</section>
<section id="historical-comparisons" class="level4">
<h4 class="anchored" data-anchor-id="historical-comparisons">Historical Comparisons:</h4>
<ul>
<li><strong>David Farragut</strong>: Became a US Navy captain at age 12.</li>
<li><strong>George Washington</strong>: Dropped out of school at age 12.</li>
<li><strong>Thomas Jefferson</strong>: Managed a plantation and 250 employees by age 12.</li>
</ul>
</section>
<section id="danica-patrick" class="level4">
<h4 class="anchored" data-anchor-id="danica-patrick">Danica Patrick</h4>
<ul>
<li>First woman to win a major IndyCar race.</li>
<li>Dropped out of high school at 16 to pursue racing.</li>
<li>Demonstrates the power of “finding something you love and following through with it.”</li>
</ul>
</section>
<section id="nick-schulman" class="level4">
<h4 class="anchored" data-anchor-id="nick-schulman">Nick Schulman</h4>
<ul>
<li><strong>Source:</strong> <em>New York Post</em>, February 28, 2008</li>
<li>Dropped out of school to play pool and computer games.</li>
<li>Became a professional poker player, winning $2 million at age 21.</li>
<li>Planned to enroll in college to study philosophy after achieving financial success.</li>
</ul>
</section>
<section id="diablo-cody" class="level4">
<h4 class="anchored" data-anchor-id="diablo-cody">Diablo Cody</h4>
<ul>
<li>Worked as a stripper and blogger before becoming a successful screenwriter.</li>
<li>Won an Oscar for Best Screenplay for the movie “Juno”.</li>
<li>Her path exemplifies open-source learning through “experimentation and personal feedback loops.”</li>
</ul>
</section>
</section>
<section id="defining-open-source-learning" class="level3">
<h3 class="anchored" data-anchor-id="defining-open-source-learning">Defining Open-Source Learning</h3>
<ul>
<li><strong>Open-source learning</strong> recognizes any experience as a potential starting point for self-mastery.</li>
<li>It emphasizes personalized learning pathways and values all individuals as potential teachers.</li>
<li><strong>Key characteristics</strong>:
<ul>
<li>Teaching is a function, not a profession.</li>
<li>Students choose their teachers.</li>
<li>No need for licenses to teach.</li>
<li>Students are active initiators of their learning.</li>
<li>Embraces the unpredictable nature of life and learning.</li>
</ul></li>
</ul>
</section>
<section id="the-case-of-shen-wenrong-and-the-phoenix-steel-plant" class="level3">
<h3 class="anchored" data-anchor-id="the-case-of-shen-wenrong-and-the-phoenix-steel-plant">The Case of Shen Wenrong and the Phoenix Steel Plant</h3>
<ul>
<li>A team of Chinese peasants, led by Shen Wenrong, dismantled and relocated a massive steel plant from Germany to China.</li>
<li>They completed the project in one year, three times faster than German experts estimated.</li>
<li>Shen lacked formal education, using intuition and practical knowledge to overcome challenges.</li>
<li>This story challenges the assumption that specialists are always necessary for complex tasks.</li>
<li>It highlights the resourcefulness and ingenuity of ordinary individuals when empowered.</li>
</ul>
</section>
<section id="sir-richard-branson-and-the-power-of-early-independence" class="level3">
<h3 class="anchored" data-anchor-id="sir-richard-branson-and-the-power-of-early-independence">Sir Richard Branson and the Power of Early Independence</h3>
<ul>
<li>Billionaire entrepreneur who dropped out of high school.</li>
<li>Credits his mother for fostering his independence from a young age.</li>
<li>At age four, his mother left him miles from home and instructed him to find his way back.</li>
<li>This experience instilled self-reliance and problem-solving skills.</li>
</ul>
<section id="early-learning" class="level4">
<h4 class="anchored" data-anchor-id="early-learning">Early Learning:</h4>
<ul>
<li><strong>Glenn Doman</strong>:
<ul>
<li>Advocates for early childhood learning, including reading and math.</li>
<li>Believes children are capable of learning complex concepts at a young age.</li>
<li>Challenges the traditional notion of age-appropriate learning.</li>
<li><strong>Book:</strong> <a href="https://www.gentlerevolution.com/products/how-to-teach-your-baby-to-read-40th-anniversary">How To Teach Your Baby To Read</a></li>
</ul></li>
</ul>
</section>
</section>
<section id="challenging-traditional-education-narratives" class="level3">
<h3 class="anchored" data-anchor-id="challenging-traditional-education-narratives">Challenging Traditional Education Narratives</h3>
<ul>
<li>Gatto questions why formal education seems less important for success in earlier eras.</li>
<li>He cites examples of highly successful individuals with limited formal education:
<ul>
<li><strong>Abraham Lincoln</strong></li>
<li><strong>George Washington</strong></li>
<li><strong>Andrew Carnegie</strong></li>
<li><strong>John D. Rockefeller</strong></li>
</ul></li>
</ul>
<section id="the-human-genome-project-a-case-for-unconventional-learning" class="level4">
<h4 class="anchored" data-anchor-id="the-human-genome-project-a-case-for-unconventional-learning">The Human Genome Project: A Case for Unconventional Learning</h4>
<ul>
<li>Led by:
<ul>
<li><strong>Craig Venter</strong>: A former surfer and “horrible student”.</li>
<li><strong>Francis Collins</strong>: Homeschooled and self-directed learner.</li>
</ul></li>
<li>Their success challenges the notion that a rigid, standardized education is necessary for scientific achievement.</li>
</ul>
</section>
<section id="marilee-jones-the-torch-singer-at-mit" class="level4">
<h4 class="anchored" data-anchor-id="marilee-jones-the-torch-singer-at-mit">Marilee Jones: The Torch Singer at MIT</h4>
<ul>
<li>MIT’s admissions director fired for lying about her college degrees.</li>
<li>She had been a nightclub singer before her successful career at MIT.</li>
<li>Gatto questions the logic of valuing credentials over demonstrated competence.</li>
</ul>
</section>
</section>
<section id="ingvar-kamprad-and-the-triumph-over-dyslexia" class="level3">
<h3 class="anchored" data-anchor-id="ingvar-kamprad-and-the-triumph-over-dyslexia">Ingvar Kamprad and the Triumph Over Dyslexia</h3>
<ul>
<li>Founder of IKEA, a global furniture empire.</li>
<li>Diagnosed with dyslexia and considered “unintelligent” by school officials.</li>
<li>Started his entrepreneurial journey selling fish from a bicycle.</li>
<li>His success demonstrates that traditional measures of intelligence do not predict entrepreneurial success.</li>
</ul>
</section>
<section id="charles-webb-from-the-graduate-to-migrant-worker" class="level3">
<h3 class="anchored" data-anchor-id="charles-webb-from-the-graduate-to-migrant-worker">Charles Webb: From “The Graduate” to Migrant Worker</h3>
<ul>
<li>Author of “The Graduate,” a successful novel and film.</li>
<li>Rejected a life of wealth and fame to become a migrant fruit picker.</li>
<li>His story challenges the societal definition of success and fulfillment.</li>
</ul>
</section>
<section id="reframing-the-dropout-narrative" class="level3">
<h3 class="anchored" data-anchor-id="reframing-the-dropout-narrative">Reframing the Dropout Narrative</h3>
<ul>
<li>Gatto argues that dropouts should be viewed as a valuable resource, not failures.</li>
<li>He sees them as individuals who resist conformity and possess untapped potential.</li>
<li>He questions why so many young people find school unbearable.</li>
<li>He suggests that traditional education might be failing to engage students in meaningful ways.</li>
</ul>
<section id="the-international-happiness-survey" class="level4">
<h4 class="anchored" data-anchor-id="the-international-happiness-survey">The International Happiness Survey:</h4>
<ul>
<li>The United States consistently ranks as “mediocre” in happiness.</li>
<li>Gatto questions whether the emphasis on degrees and elite colleges contributes to this dissatisfaction.</li>
</ul>
</section>
<section id="challenging-assumptions" class="level4">
<h4 class="anchored" data-anchor-id="challenging-assumptions">Challenging Assumptions:</h4>
<ul>
<li>Gatto challenges the assumption that formal education is the only path to success and fulfillment.</li>
<li>He encourages readers to question the status quo and consider alternative perspectives on learning and achievement.</li>
</ul>
</section>
</section>
<section id="john-kanzius-the-cancer-patient-turned-inventor" class="level3">
<h3 class="anchored" data-anchor-id="john-kanzius-the-cancer-patient-turned-inventor">John Kanzius: The Cancer Patient Turned Inventor</h3>
<ul>
<li><strong>Source:</strong> <em>60 Minutes</em> television show, April 13, 2008</li>
<li>Developed a revolutionary cancer treatment using radio waves.</li>
<li>Had no formal scientific training.</li>
<li>His discovery challenges the assumption that major breakthroughs come from within the scientific establishment.</li>
</ul>
</section>
<section id="open-source-learning-a-threat-to-the-status-quo" class="level3">
<h3 class="anchored" data-anchor-id="open-source-learning-a-threat-to-the-status-quo">Open-Source Learning: A Threat to the Status Quo</h3>
<ul>
<li>Gatto argues that open-source learning fosters independent thinking and self-reliance.</li>
<li>He believes these qualities are undesirable to those in power who benefit from conformity and obedience.</li>
</ul>
<section id="the-artificial-extension-of-childhood" class="level4">
<h4 class="anchored" data-anchor-id="the-artificial-extension-of-childhood">The Artificial Extension of Childhood:</h4>
<ul>
<li>Gatto argues that modern society has artificially extended childhood through compulsory schooling.</li>
<li>He believes this delays the transition to adulthood and hinders the development of self-reliance.</li>
</ul>
</section>
<section id="historical-perspective" class="level4">
<h4 class="anchored" data-anchor-id="historical-perspective">Historical Perspective:</h4>
<ul>
<li>In early America, children contributed to society from a young age.</li>
<li>The concept of adolescence as a distinct life stage was largely absent.</li>
<li>Gatto suggests that this early exposure to real-world experiences fostered self-reliance and ingenuity.</li>
</ul>
</section>
</section>
<section id="the-rise-of-industrial-values-and-the-decline-of-open-source-learning" class="level3">
<h3 class="anchored" data-anchor-id="the-rise-of-industrial-values-and-the-decline-of-open-source-learning">The Rise of Industrial Values and the Decline of Open-Source Learning</h3>
<ul>
<li>Gatto argues that the Civil War marked a turning point in American history, shifting the focus from individual liberty to industrial efficiency.</li>
<li>This shift led to the rise of:
<ul>
<li>Factories</li>
<li>Licensing laws</li>
<li>Government intervention</li>
<li>Compulsory schooling</li>
</ul></li>
</ul>
<section id="the-role-of-compulsory-schooling" class="level4">
<h4 class="anchored" data-anchor-id="the-role-of-compulsory-schooling">The Role of Compulsory Schooling:</h4>
<ul>
<li>Gatto sees compulsory schooling as a tool for:
<ul>
<li>Breaking up families</li>
<li>Creating a compliant workforce</li>
<li>Marginalizing independent thinking</li>
</ul></li>
</ul>
</section>
<section id="andrew-carnegie" class="level4">
<h4 class="anchored" data-anchor-id="andrew-carnegie">Andrew Carnegie:</h4>
<ul>
<li>Industrialist who recognized the drawbacks of compulsory schooling.</li>
<li>He acknowledged that it would hinder some talented individuals.</li>
<li>He believed the trade-off was acceptable for social stability and economic growth.</li>
</ul>
</section>
<section id="william-torrey-harris" class="level4">
<h4 class="anchored" data-anchor-id="william-torrey-harris">William Torrey Harris:</h4>
<ul>
<li>America’s first National Commissioner of Education.</li>
<li>Believed that schooling should teach “self-alienation” to benefit the state and corporations.</li>
<li>Advocated for dark, airless classrooms to suppress individuality.</li>
</ul>
</section>
</section>
<section id="the-consequences-of-a-rule-based-society" class="level3">
<h3 class="anchored" data-anchor-id="the-consequences-of-a-rule-based-society">The Consequences of a Rule-Based Society</h3>
<ul>
<li>Gatto argues that excessive regulation stifles creativity and innovation.</li>
<li>He believes that a society focused on control and compliance becomes stagnant and vulnerable.</li>
</ul>
<section id="the-decline-of-american-innovation" class="level4">
<h4 class="anchored" data-anchor-id="the-decline-of-american-innovation">The Decline of American Innovation:</h4>
<ul>
<li>Gatto links the decline in patent applications to the rise of compulsory schooling.</li>
<li>He suggests that standardized education stifles the imagination and discourages risk-taking.</li>
</ul>
</section>
<section id="the-importance-of-dialectical-thinking" class="level4">
<h4 class="anchored" data-anchor-id="the-importance-of-dialectical-thinking">The Importance of Dialectical Thinking:</h4>
<ul>
<li>Gatto advocates for dialectical thinking, which emphasizes critical questioning and the examination of multiple perspectives.</li>
<li>He believes that schooling has suppressed this type of thinking, making society less adaptable and innovative.</li>
</ul>
</section>
<section id="the-illusion-of-a-free-market" class="level4">
<h4 class="anchored" data-anchor-id="the-illusion-of-a-free-market">The Illusion of a Free Market:</h4>
<ul>
<li>Gatto argues that the United States is no longer a true free-market economy.</li>
<li>He points to corporate welfare, a bloated military, and government bailouts as evidence.</li>
<li>He suggests that this system benefits a select few at the expense of the many.</li>
</ul>
</section>
<section id="the-dangers-of-mass-mindedness" class="level4">
<h4 class="anchored" data-anchor-id="the-dangers-of-mass-mindedness">The Dangers of Mass-Mindedness:</h4>
<ul>
<li>Gatto argues that centralized economies require a compliant and uncritical populace.</li>
<li>He believes that schooling is designed to create this type of “mass mind” through:
<ul>
<li>Habit training</li>
</ul></li>
<li>Obedience to authority</li>
<li>Suppression of independent thought</li>
</ul>
</section>
<section id="from-self-sufficiency-to-consumption" class="level4">
<h4 class="anchored" data-anchor-id="from-self-sufficiency-to-consumption">From Self-Sufficiency to Consumption:</h4>
<ul>
<li>Colonial America valued self-sufficiency and personal production.</li>
<li>Gatto argues that schooling has shifted the focus to consumption, creating a society dependent on corporations and government.</li>
</ul>
</section>
<section id="the-invention-of-adolescence" class="level4">
<h4 class="anchored" data-anchor-id="the-invention-of-adolescence">The Invention of Adolescence:</h4>
<ul>
<li>G. Stanley Hall, a psychologist trained in Germany, popularized the concept of adolescence.</li>
<li>He characterized it as a dangerous and irrational stage requiring control and intervention.</li>
<li>Gatto believes this invention served to justify the expansion of schooling and the control of young people.</li>
</ul>
</section>
<section id="the-suppression-of-argument-and-dissent" class="level4">
<h4 class="anchored" data-anchor-id="the-suppression-of-argument-and-dissent">The Suppression of Argument and Dissent:</h4>
<ul>
<li>The founding fathers designed the US government to encourage debate and dissent.</li>
<li>Gatto argues that schooling has suppressed these essential elements of democracy, creating a more compliant and manageable citizenry.</li>
</ul>
</section>
</section>
<section id="the-failure-of-expertise-and-the-rise-of-the-insurgency" class="level3">
<h3 class="anchored" data-anchor-id="the-failure-of-expertise-and-the-rise-of-the-insurgency">The Failure of Expertise and the Rise of the Insurgency</h3>
<ul>
<li>Gatto argues that the current system, based on expertise and control, is failing.</li>
<li>He sees evidence of this failure in:
<ul>
<li>Economic instability</li>
<li>Declining innovation</li>
<li>Social unrest</li>
</ul></li>
</ul>
<section id="the-rise-of-the-insurgency" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-the-insurgency">The Rise of the Insurgency:</h4>
<ul>
<li>Gatto sees hope in the growing movement of people rejecting the status quo.</li>
<li>He points to:
<ul>
<li>Homeschooling</li>
<li>The internet</li>
<li>Alternative forms of education</li>
</ul></li>
<li>Acts of civil disobedience</li>
</ul>
</section>
<section id="st.-pauls-message-for-modern-times" class="level4">
<h4 class="anchored" data-anchor-id="st.-pauls-message-for-modern-times">St.&nbsp;Paul’s Message for Modern Times:</h4>
<ul>
<li>Gatto draws parallels between the early Christian church and the current education reform movement.</li>
<li>He highlights St.&nbsp;Paul’s message of rejecting rigid rules and embracing adaptability.</li>
<li>He believes that education should be tailored to individual needs, not standardized for the masses.</li>
</ul>
</section>
</section>
<section id="the-high-cost-of-professionalism" class="level3">
<h3 class="anchored" data-anchor-id="the-high-cost-of-professionalism">The High Cost of Professionalism</h3>
<ul>
<li>Gatto argues that professionalism, while promoting expertise, comes at a high cost.</li>
<li>He believes it leads to:
<ul>
<li>Social stratification</li>
<li>Decreased empathy</li>
<li>A focus on status over service</li>
</ul></li>
</ul>
</section>
<section id="the-school-to-prison-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="the-school-to-prison-pipeline">The School-to-Prison Pipeline</h3>
<ul>
<li>The United States has a higher incarceration rate than any other country, including China.</li>
<li>Gatto argues that the emphasis on obedience and compliance in schools contributes to this problem.</li>
<li>He sees a direct link between the zero-tolerance policies in schools and the mass incarceration crisis.</li>
</ul>
</section>
<section id="the-unsustainability-of-the-school-bubble" class="level3">
<h3 class="anchored" data-anchor-id="the-unsustainability-of-the-school-bubble">The Unsustainability of the School Bubble</h3>
<ul>
<li>Gatto argues that the current education system is unsustainable, comparing it to a bubble on the verge of bursting.</li>
<li>He points to:
<ul>
<li>Rising costs</li>
<li>Declining returns on investment</li>
<li>A disconnect between what is taught in schools and the skills needed in the real world</li>
</ul></li>
</ul>
<section id="the-need-for-a-new-direction" class="level4">
<h4 class="anchored" data-anchor-id="the-need-for-a-new-direction">The Need for a New Direction:</h4>
<ul>
<li>Gatto calls for a radical shift away from the current education paradigm.</li>
<li>He believes that a return to open-source learning, emphasizing:
<ul>
<li>Self-reliance</li>
<li>Creativity</li>
<li>Critical thinking</li>
<li>Real-world problem-solving</li>
</ul></li>
</ul>
</section>
</section>
<section id="personal-reflections-the-monongahela-walkabout" class="level3">
<h3 class="anchored" data-anchor-id="personal-reflections-the-monongahela-walkabout">Personal Reflections: The Monongahela Walkabout</h3>
<ul>
<li>Gatto shares a personal story about nightly walks he took with his mother and sister during his childhood.</li>
<li>He describes these walks as his most profound educational experiences, filled with:
<ul>
<li>Family connection</li>
<li>Real-world observation</li>
<li>Meaningful conversations</li>
<li>Encounters with life and death</li>
</ul></li>
</ul>
<section id="the-power-of-open-source-learning" class="level4">
<h4 class="anchored" data-anchor-id="the-power-of-open-source-learning">The Power of Open-Source Learning:</h4>
<ul>
<li>Gatto contrasts the richness of his childhood walks with the sterility of his formal education.</li>
<li>He argues that the most powerful learning happens through direct experience and personal connection, not through standardized curricula and assessments.</li>
</ul>
</section>
</section>
<section id="conclusion-a-call-to-action" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-a-call-to-action">Conclusion: A Call to Action</h3>
<ul>
<li>Gatto urges readers to reject the limitations of the current education system and embrace the power of open-source learning.</li>
<li>He calls for a return to the values of:
<ul>
<li>Self-reliance</li>
<li>Innovation</li>
<li>Community</li>
<li>Personal fulfillment</li>
</ul></li>
</ul>
<section id="a-time-for-courage" class="level4">
<h4 class="anchored" data-anchor-id="a-time-for-courage">A Time for Courage:</h4>
<ul>
<li>Gatto acknowledges that this transformation will require courage and a willingness to challenge the status quo.</li>
<li>He believes that the future of society depends on it.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-3-fat-stanley-and-the-lancaster-amish" class="level2">
<h2 class="anchored" data-anchor-id="chapter-3-fat-stanley-and-the-lancaster-amish">Chapter 3: Fat Stanley and the Lancaster Amish</h2>
<section id="schooling-vs.-education" class="level3">
<h3 class="anchored" data-anchor-id="schooling-vs.-education">Schooling vs.&nbsp;Education</h3>
<ul>
<li>Gatto believes criticism is crucial for personal growth.
<ul>
<li>Recounts a family member’s boastful statement, “I don’t take criticism well,” highlighting its self-destructive nature.</li>
</ul></li>
<li>Distinguishes between <strong>schooling</strong> and <strong>education</strong>:
<ul>
<li><strong>Schooling:</strong>
<ul>
<li>Focuses on habit formation and attitude training.</li>
<li>Imposed externally, prioritizing someone else’s agenda.</li>
<li>Often perceived as unpleasant due to its mind-control aspect.</li>
</ul></li>
<li><strong>Education:</strong>
<ul>
<li>Prioritizes self-mastery and self-enlargement.</li>
<li>Leads to self-transcendence, opening possibilities for exploration and understanding.</li>
<li>While schooling and education can intersect, schooling often overshadows individual growth.</li>
</ul></li>
</ul></li>
<li>Lack of schooling can be compensated for, but lack of education leads to exploitation and failure.</li>
<li>Cites examples of successful individuals with limited formal schooling:
<ul>
<li><strong>Mary Shelley:</strong> Wrote <em>Frankenstein</em> at 18, now considered a literary masterpiece.</li>
<li><strong>William Shakespeare:</strong> Achieved iconic status despite minimal classroom time and book ownership.</li>
</ul></li>
<li>Attributes success to self-initiated education:
<ul>
<li>Built on broad experience, introspection, focus, curiosity, patience, observation, risk-taking, and learning from mistakes.</li>
</ul></li>
</ul>
</section>
<section id="fat-stanleys-story" class="level3">
<h3 class="anchored" data-anchor-id="fat-stanleys-story">Fat Stanley’s Story</h3>
<ul>
<li>Introduces <strong>Fat Stanley</strong>, a student who rarely attended school.
<ul>
<li>Stanley possessed a pragmatic approach to life, choosing to learn practical skills over attending school.</li>
</ul></li>
<li>Stanley’s alternative education:
<ul>
<li>Worked with five aunts and uncles in their businesses, bartering labor for knowledge.</li>
<li>Gained real-world experience in floristry, furniture building, deli operation, restaurant management, and delivery services.</li>
<li>Believed in self-sufficiency and learning by doing.</li>
</ul></li>
<li>Stanley’s perspective on education:
<ul>
<li><blockquote class="blockquote">
<p>“This way I get a chance to see how the different businesses work. You tell me what books I have to read and I’ll read them, but I don’t have time to waste in school unless I want to end up like you, working for somebody else.”</p>
</blockquote></li>
</ul></li>
<li>Gatto, recognizing the value of Stanley’s education, covered for his absences.</li>
<li>Key takeaway from Stanley:
<ul>
<li>Traditional schooling doesn’t always align with how children learn best.</li>
<li>Self-direction and real-world experience are crucial.</li>
</ul></li>
</ul>
</section>
<section id="school-as-a-conditioning-laboratory" class="level3">
<h3 class="anchored" data-anchor-id="school-as-a-conditioning-laboratory">School as a Conditioning Laboratory</h3>
<ul>
<li>Teaches conformity, obedience, and acceptance of limitations.</li>
<li>Prepares individuals for a system that demands replaceable workers, not self-directed individuals.</li>
<li><strong>H.H. Goddard (Princeton psychology chair):</strong> Called government schooling the “perfect organization of the hive,” using standardized tests to highlight the supposed “biological inferiority” of the lower classes and discourage their reproduction.</li>
<li><strong>Special education:</strong> Continues this function of public humiliation and labeling.</li>
</ul>
</section>
<section id="schooling-in-service-of-capital" class="level3">
<h3 class="anchored" data-anchor-id="schooling-in-service-of-capital">Schooling in Service of Capital</h3>
<ul>
<li><strong>Department of Superintendents of the National Education Association (1930):</strong> Declared the main purpose of schooling to be the “effective use of capital.”</li>
<li><strong>Effective capital:</strong> Requires eager consumers and minimal public resistance, achieved by hindering critical thinking.</li>
<li><strong>Fabian socialism:</strong> Aims to achieve similar goals through seemingly benevolent means like the welfare state.</li>
<li><strong>Result:</strong> Concentration of wealth, declining working-class wages, and increased dependence on the system.
<ul>
<li>John Hopkins University Press book “Fat and Mean” (1996) findings:
<ul>
<li>No growth in real spendable working class wages for 30 years (1960s-1990s)</li>
<li>Purchasing power increased for top 20%, declined for the rest</li>
<li>1995 working couple’s purchasing power only 8% greater than single working man in 1905</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="the-amish-model" class="level3">
<h3 class="anchored" data-anchor-id="the-amish-model">The Amish Model</h3>
<ul>
<li>Contrasts the values of the <strong>Old Order Amish</strong> with modern society:
<ul>
<li>Amish prioritize competence, self-reliance, dependability, honesty, neighborliness, compassion, piety, and community.</li>
<li>Modern society encourages consumerism, novelty, and a constant desire for “something completely different.”</li>
</ul></li>
<li><strong>The Amish approach to education:</strong>
<ul>
<li>Focuses on practical skills, entrepreneurship, and community contribution.</li>
<li>Values craftsmanship, a strong work ethic, and family involvement.</li>
</ul></li>
<li><strong>Amish economic success:</strong>
<ul>
<li>Built on small businesses and farms.</li>
<li>Thrives despite limited formal education and reliance on traditional methods.</li>
</ul></li>
<li><strong>Amish values in action:</strong>
<ul>
<li>Known for being good neighbors and volunteering in their communities.</li>
<li>Often care for disadvantaged children and those with disabilities.</li>
<li>Employ sustainable farming practices that have gained international recognition.</li>
</ul></li>
</ul>
</section>
<section id="yoder-v.-wisconsin-1976" class="level3">
<h3 class="anchored" data-anchor-id="yoder-v.-wisconsin-1976">Yoder v. Wisconsin (1976)</h3>
<ul>
<li><strong>Issue:</strong> Wisconsin sought to force Amish compliance with secular school laws.</li>
<li><strong>Amish argument:</strong>
<ul>
<li>Disrupts the social fabric of their community and family life.</li>
<li>Separates learning from real-world experience.</li>
<li>Promotes competition and humiliation.</li>
<li>Undermines their religious beliefs and values.</li>
</ul></li>
<li><strong>Amish demands for compromise:</strong>
<ol type="1">
<li>Schools within walking distance.</li>
<li>Small school sizes with consistent teachers.</li>
<li>Shorter school year (eight months).</li>
<li>Parental control over important decisions.</li>
<li>Teachers who understand and respect Amish values.</li>
<li>Emphasis on the distinction between wisdom and academic knowledge.</li>
<li>Practical internships and apprenticeships.</li>
</ol></li>
</ul>
</section>
<section id="lessons-from-stanley-and-the-amish" class="level3">
<h3 class="anchored" data-anchor-id="lessons-from-stanley-and-the-amish">Lessons from Stanley and the Amish</h3>
<ul>
<li><strong>Reject the myth of “mass man”:</strong> Recognize and celebrate individual uniqueness.</li>
<li><strong>Abandon the notion of inherent inferiority:</strong> Trust in the capacity of ordinary people to govern themselves.</li>
<li><strong>Honor individual freedom:</strong> Uphold the right to live according to one’s own values, even if it challenges corporate interests.</li>
</ul>
</section>
</section>
<section id="chapter-4-david-sarnoffs-classroom" class="level2">
<h2 class="anchored" data-anchor-id="chapter-4-david-sarnoffs-classroom">Chapter 4: David Sarnoff’s Classroom</h2>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<ul>
<li>Gatto, a teacher with nearly three decades of experience in District 3, addresses this letter to Murray, an assistant principal in the same district.</li>
<li>The letter criticizes the state of education in District 3, particularly the policies that hinder critical thinking and meaningful learning.</li>
<li>Gatto draws a parallel between the successful self-education of David Sarnoff and the shortcomings of the current education system.</li>
</ul>
</section>
<section id="the-nine-qualities-of-successful-adaptation" class="level3">
<h3 class="anchored" data-anchor-id="the-nine-qualities-of-successful-adaptation">The Nine Qualities of Successful Adaptation</h3>
<ul>
<li>Gatto presents nine qualities deemed essential for success in the evolving world of work, as identified in a brochure found at Harvard University:
<ul>
<li>The ability to ask hard questions of data, regardless of the source.</li>
<li>The ability to define problems independently, without relying solely on official definitions.</li>
<li>The ability to sift through irrelevant information and extract useful insights.</li>
<li>The ability to conceptualize.</li>
<li>The ability to reorganize information to gain new perspectives.</li>
<li>The possession of a mind capable of navigating different modes of thought: deductive, inductive, heuristic, and intuitive.</li>
<li>Proficiency in collaboration with partners or teams.</li>
<li>Skill in discussing issues, problems, or techniques.</li>
<li>Skill in rhetoric, effectively persuading others of your viewpoint.</li>
</ul></li>
</ul>
</section>
<section id="the-failure-of-district-3" class="level3">
<h3 class="anchored" data-anchor-id="the-failure-of-district-3">The Failure of District 3</h3>
<ul>
<li>Gatto argues that District 3, despite being located in a wealthy and resourceful area, fails to prioritize the nine qualities mentioned above.</li>
<li>Gatto criticizes the district’s abandonment of practical skills training, such as shop, cooking, and arts programs.</li>
<li>Gatto contends that the district’s emphasis on standardized protocols and fear of deviation stifles creativity and effective teaching.</li>
</ul>
</section>
<section id="david-sarnoffs-school-the-streets" class="level3">
<h3 class="anchored" data-anchor-id="david-sarnoffs-school-the-streets">David Sarnoff’s School: The Streets</h3>
<ul>
<li>Gatto contrasts the limitations of District 3 with the real-world education of David Sarnoff, who rose from poverty to become president of RCA.</li>
<li>Sarnoff’s story highlights the importance of self-teaching, initiative, and real-world experience:
<ul>
<li>At age nine, Sarnoff taught himself English in five months to support his family as a newsboy.</li>
<li>At fourteen, he managed his own newsstand.</li>
<li>He secured a job at Marconi Wireless through sheer initiative, bypassing a long line of applicants.</li>
<li>He taught himself telegraphy, which proved crucial for his career advancement.</li>
</ul></li>
<li>Gatto emphasizes that Sarnoff’s success stemmed from opportunities to think critically, take initiative, and contribute to his community at a young age.</li>
</ul>
</section>
<section id="the-mask-of-school-reform" class="level3">
<h3 class="anchored" data-anchor-id="the-mask-of-school-reform">The Mask of School Reform</h3>
<ul>
<li>Gatto recounts a visit to a well-regarded alternative public school in East Harlem, founded by Debbie Meyer.</li>
<li>Despite its positive reputation, Gatto found the school limited by bureaucratic constraints, mistrust of children and teachers, and an overemphasis on standardized testing.</li>
<li>Gatto criticizes the school’s community service program, which mandates only two hours per week, as a trivialization of the service ideal.</li>
</ul>
</section>
<section id="the-commissioners-report" class="level3">
<h3 class="anchored" data-anchor-id="the-commissioners-report">The Commissioner’s Report</h3>
<ul>
<li>Gatto cites a report by the State Commission of Education that ranked District 3 last out of 736 school districts in key academic areas.</li>
<li>Gatto expresses dismay at the district’s poor performance despite its affluent location and access to resources.</li>
<li>Gatto criticizes the high teacher turnover rate (22%) as a symptom of a flawed system.</li>
<li>Gatto argues that a caste system exists within the district, where favored teachers receive preferential treatment in exchange for loyalty, while others are burdened with difficult workloads and eventually leave.</li>
<li>Gatto contends that the district’s policies, rather than improving education, contribute to a decline in student abilities and character development.</li>
</ul>
</section>
<section id="destructive-policies" class="level3">
<h3 class="anchored" data-anchor-id="destructive-policies">Destructive Policies</h3>
<ul>
<li>Gatto identifies two specific policies that have harmed education in District 3:
<ul>
<li>The decision to tolerate disruptive classroom behavior, based on the flawed premise that frustration leads to low self-esteem. This policy, according to Gatto, has led to a decline in classroom order and hindered learning for all students.</li>
<li>The recruitment of disruptive students from other districts to inflate enrollment numbers. This policy, implemented without consulting parents or teachers, further exacerbated classroom management issues.</li>
</ul></li>
</ul>
</section>
<section id="the-illusion-of-high-expectations" class="level3">
<h3 class="anchored" data-anchor-id="the-illusion-of-high-expectations">The Illusion of High Expectations</h3>
<ul>
<li>Gatto argues that the district’s claims of high expectations are hollow and not reflected in actual practices.</li>
<li>Gatto observes that changing superintendents has had little impact on the quality of education, as they all operate within the same flawed system.</li>
</ul>
</section>
<section id="school-as-narcotic" class="level3">
<h3 class="anchored" data-anchor-id="school-as-narcotic">School as Narcotic</h3>
<ul>
<li>Gatto contends that the current education system, rather than fostering critical thinking and engagement, creates passive and addicted individuals.</li>
<li>Gatto criticizes the overemphasis on standardized testing and rote memorization, which fails to equip students with a deep understanding of the past or the ability to envision the future.</li>
<li>Gatto uses the example of Vietnam’s history, often misrepresented in textbooks, to illustrate the prevalence of misinformation in education.
<ul>
<li><blockquote class="blockquote">
<p>“Every single secondary school student in New York City is taught that North and South Vietnam are one country, divided, and all their teachers believe that too. But the truth is that for thousands of years, they were three countries, and only forced together for a short time under French domination. The civilization of the two northern countries, Annam and Tonkin, derives largely from China. The culture of South Vietnam, a country known as Champa, comes, like that of Cambodia, from India. The two regions have been fighting for nearly 2,000 years”</p>
</blockquote></li>
</ul></li>
<li>Gatto expresses concern about the amount of time children spend passively consuming entertainment instead of actively exploring, playing, and pursuing personal growth.</li>
</ul>
</section>
<section id="conclusion-1" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-1">Conclusion</h3>
<ul>
<li>Gatto concludes by expressing his intention to circulate the letter to the new school board in the hope of prompting reflection and change, though he remains skeptical about the likelihood of meaningful reform.</li>
<li>Gatto believes that the current education system is fundamentally flawed and requires a radical overhaul to effectively prepare students for the challenges of the future.</li>
</ul>
</section>
</section>
<section id="chapter-5.-hector-isnt-the-problem" class="level2">
<h2 class="anchored" data-anchor-id="chapter-5.-hector-isnt-the-problem">Chapter 5. Hector Isn’t the Problem</h2>
<section id="i-quit" class="level3">
<h3 class="anchored" data-anchor-id="i-quit">I Quit</h3>
<section id="a-teachers-disillusionment" class="level4">
<h4 class="anchored" data-anchor-id="a-teachers-disillusionment">A Teacher’s Disillusionment</h4>
<ul>
<li>Gatto, a 30-year veteran schoolteacher in Manhattan’s Community School District 3, describes his extensive experience and accomplishments:
<ul>
<li>Taught in all five district secondary schools.</li>
<li>Faced repeated attempts by administrations to remove him.</li>
<li>Received two suspensions for insubordination.</li>
<li>Experienced covert termination while on medical leave.</li>
<li>Served as a lecturer at CUNY’s education department for five years, consistently ranking first in student faculty ratings.</li>
<li>Spearheaded the most successful permanent school fundraiser in NYC history.</li>
<li>Guided an eighth-grade class in completing 30,000 hours of community service.</li>
<li>Established a student-run food cooperative.</li>
<li>Secured over 1,000 apprenticeships for students.</li>
<li>Oversaw the collection of thousands of books for student libraries.</li>
<li>Produced four talking job dictionaries for the blind.</li>
<li>Wrote two student musicals.</li>
<li>Implemented numerous initiatives to connect students with the wider world.</li>
<li>Was named New York State Teacher of the Year.</li>
</ul></li>
<li>Despite these achievements, Gatto reached a breaking point and decided to quit teaching.</li>
</ul>
</section>
<section id="i-quit-i-think" class="level4">
<h4 class="anchored" data-anchor-id="i-quit-i-think">“I Quit, I Think”</h4>
<ul>
<li>Gatto wrote an essay titled “I Quit, I Think” for the Wall Street Journal, explaining his decision to leave teaching despite having no financial safety net.</li>
<li>The essay read:
<ul>
<li><blockquote class="blockquote">
<p>“Government schooling is the most radical adventure in history. It kills the family by monopolizing the best times of childhood and by teaching disrespect for home and parents. The whole blueprint of school procedure is Egyptian, not Greek or Roman. It grows from the theological idea that human value is a scarce thing, represented symbolically by the narrow peak of a pyramid. That idea passed into American history through the Puritans. It found its scientific presentation in the bell curve, along which talent supposedly apportions itself by some iron law of biology. It’s a religious notion, and school is its church. I offer rituals to keep heresy at bay. I provide documentation to justify the heavenly pyramid. Socrates foresaw that if teaching became a formal profession, something like this would happen. Professional interest is served by making what is easy to do seem hard, by subordinating the laity to the priesthood. School is too vital a jobs project, contract giver, and protector of the social order, to allow itself to be reformed. It has political allies to guard its marches. That’s why reforms come and go without altering much. Even reformers can’t imagine school being much different. David learns to read at age four. Rachel at age nine. In normal development, when both are thirteen, you can’t tell which one learned first. The five-year spread means nothing at all. But in school, I label Rachel learning disabled and slow David down a bit, too. For a paycheck, I teach David to depend on me to tell him when to go and stop. He won’t outgrow that dependency. I identify Rachel as discount merchandise, special education fodder. She’ll be locked in her place forever. In 30 years of teaching kids, rich and poor, I almost never met a learning disabled child. Hardly ever met a gifted and talented one either. Like all school categories, these are sacred myths created by human imagination. They derive from questionable values that we never examine because they preserve the temple of schooling. That’s the secret behind short answer tests, bells, uniform time blocks, age grading, standardization, and all the rest of the school religion punishing our nation. There isn’t a right way to become educated. There are as many ways as there are fingerprints. We don’t need state-certified teachers to make education happen. Certification probably guarantees it won’t. How much more evidence is necessary? Good schools don’t need more money or a longer year. They need real free market choices. Variety that speaks to every need and runs risks We don’t need a national curriculum or national testing either Both initiatives arise from ignorance of how people learn Or deliberate indifference to it I can’t teach this way any longer If you hear of a job where I don’t have to hurt kids to make a living Let me know Come fall, I’ll be looking for work”</p>
</blockquote></li>
</ul></li>
<li>Gatto submitted the essay in March and forgot about it, caught up in his internal struggle.</li>
<li>On July 5, 1991, he officially resigned.</li>
<li>Twenty days later, the Wall Street Journal published his essay.</li>
</ul>
</section>
<section id="reflections-on-a-broken-system" class="level4">
<h4 class="anchored" data-anchor-id="reflections-on-a-broken-system">Reflections on a Broken System</h4>
<ul>
<li>Looking back, Gatto struggles to reconcile his rewarding career with the realization that he participated in a system he views as harmful.</li>
<li>He questions how centralized schooling, which he sees as an “indoctrinating and sorting machine,” is allowed to exist.</li>
<li>Gatto asserts that school is essentially a religion, and without understanding its “holy mission,” one will misinterpret its workings as stemming from stupidity, greed, or class warfare.</li>
<li>He argues that while those factors are present, they are not the driving force; even without them, school would function similarly.</li>
</ul>
</section>
<section id="the-myth-of-mass-dumbness" class="level4">
<h4 class="anchored" data-anchor-id="the-myth-of-mass-dumbness">The Myth of Mass Dumbness</h4>
<ul>
<li>Gatto contends that modern schooling teaches “dumbness,” transforming ignorance into “permanent mathematical categories of relative stupidity” like “gifted and talented,” “mainstream,” and “special ed.”</li>
<li>He believes these categories are used to ration learning, benefiting the system and social order rather than individual students.</li>
<li>This “new dumbness,” he argues, is particularly harmful to middle and upper-middle-class children, who are already pressured to conform.</li>
<li>These students, despite their degrees and credentials, often lack true understanding and are vulnerable to life’s challenges.</li>
<li>Quoting English historian Alan Bullock, Gatto states, “evil is a state of incompetence,” implying that the school system has fostered widespread evil.</li>
<li>He argues that students “dumbed down” by schooling lose the ability to think independently and constantly seek external validation.</li>
<li>Gatto challenges the notion that “dumbness” is an inherent trait requiring extensive intervention and control.</li>
<li>He proposes that “mass dumbness” is a fabricated concept, not a reflection of reality.</li>
</ul>
</section>
<section id="introducing-hector" class="level4">
<h4 class="anchored" data-anchor-id="introducing-hector">Introducing Hector</h4>
<ul>
<li>Gatto introduces Hector Rodriguez, a 13-year-old student he encountered while teaching.</li>
<li>Hector is described as small, olive-skinned, with large black eyes.</li>
<li>Gatto first truly <em>saw</em> Hector at a skating rink, where the boy was attempting to bypass the gate despite having a paid ticket.</li>
<li>Hector, it turned out, was conducting an experiment to see if he could outsmart the turnstile.</li>
<li>This incident sparked Gatto’s curiosity about Hector.</li>
</ul>
</section>
<section id="hectors-outlaw-record" class="level4">
<h4 class="anchored" data-anchor-id="hectors-outlaw-record">Hector’s “Outlaw” Record</h4>
<ul>
<li>Examining Hector’s school records, Gatto discovered a history of minor infractions that painted the boy as a troublemaker.</li>
<li>These incidents, while insignificant in the past, now contributed to a narrative that labeled Hector as a problem.</li>
<li>Hector attended one of the lowest-rated schools in New York State, placed in a low-ranking class within his grade.</li>
<li>Gatto criticizes the rigid five-tier academic ranking system (Gifted and Talented Honors, Gifted and Talented, Special Progress, Mainstream, and Special Ed) that labeled and segregated students.</li>
<li>He notes the financial incentive for schools to identify students as needing Special Ed services, creating a perverse motivation to overdiagnose.</li>
<li>Hector, labeled “Mainstream D,” narrowly avoided the stigma of Special Ed.</li>
<li>His standardized test scores placed him far behind his peers.</li>
</ul>
</section>
<section id="hectors-crimes" class="level4">
<h4 class="anchored" data-anchor-id="hectors-crimes">Hector’s “Crimes”</h4>
<ul>
<li>Shortly after the skating rink incident, Hector was caught at a nearby elementary school with a fake gun.</li>
<li>He had been dismissed for Christmas vacation and went to his former school with the intention of encouraging the younger students to leave with him.</li>
<li>Gatto learned of this incident from the school principal, who blamed him for Hector’s actions.</li>
</ul>
</section>
<section id="a-year-later" class="level4">
<h4 class="anchored" data-anchor-id="a-year-later">A Year Later</h4>
<ul>
<li>A year later, Hector, now a high school freshman, was failing all his classes and facing truancy charges.</li>
<li>Gatto highlights how school records presented a damning picture of Hector: poor, small, minority, ignored, “dumb,” disruptive, and a failure.</li>
<li>He challenges the reader to see Hector beyond these labels, questioning the system’s tendency to categorize and predict a child’s future based on limited information.</li>
</ul>
</section>
<section id="the-real-problem" class="level4">
<h4 class="anchored" data-anchor-id="the-real-problem">The Real Problem</h4>
<ul>
<li>Gatto argues that Hector, and millions of children like him, are not the problem with modern schooling.</li>
<li>He proposes that the perception of these children as problems is the true issue.</li>
<li>Forced schooling, he believes, was designed to control and subdue children deemed different or disruptive.</li>
<li>He criticizes the “religious zeal” of those who believe that civilization depends on suppressing the “irrational, unpredictable impulses of human nature.”</li>
</ul>
</section>
</section>
</section>
<section id="chapter-6-the-camino-de-santiago" class="level2">
<h2 class="anchored" data-anchor-id="chapter-6-the-camino-de-santiago">Chapter 6: The Camino de Santiago</h2>
<section id="the-problem-media-addiction-and-its-effects" class="level3">
<h3 class="anchored" data-anchor-id="the-problem-media-addiction-and-its-effects">The Problem: Media Addiction and Its Effects</h3>
<ul>
<li>As a teacher, Gatto observed that children who watched excessive television exhibited negative behavioral patterns:
<ul>
<li>Irresponsibility</li>
<li>Childishness</li>
<li>Dishonesty</li>
<li>Malice towards peers</li>
<li>Lack of purpose</li>
</ul></li>
<li>Gatto believes overexposure to media:
<ul>
<li>Stifles children’s ability to develop integrity and maturity</li>
<li>Inhibits their capacity for original thought and creativity</li>
<li>Mirrors the negative effects of traditional schooling by suppressing their spirits</li>
</ul></li>
<li>Computers, while potentially offering interactivity, often worsen the issue:
<ul>
<li>Many users engage in passive activities like watching pornography or playing games against computers</li>
<li>The internet, without discipline, easily enables passive consumption</li>
</ul></li>
<li>Preaching against media proves ineffective as children’s minds become desensitized to the message.</li>
</ul>
</section>
<section id="the-hypothesis-restoring-natural-feedback-loops" class="level3">
<h3 class="anchored" data-anchor-id="the-hypothesis-restoring-natural-feedback-loops">The Hypothesis: Restoring Natural Feedback Loops</h3>
<ul>
<li>Gatto theorizes that the solution lies in encouraging physical activity and real-world experiences.</li>
<li>Excessive media consumption disrupts natural feedback loops crucial for learning and growth.</li>
<li>Examples of feedback loops in action:
<ul>
<li>Learning to sail: Beginners learn from their mistakes through the immediate feedback of the boat’s movement.</li>
<li>Mastering speech: Practice and feedback are essential for developing complex language skills.</li>
</ul></li>
<li>Bureaucracies, like school systems, often fail due to their inability to respond effectively to feedback.
<ul>
<li>Rigid rules and resistance to input from parents, teachers, students, and external sources hinder growth.</li>
</ul></li>
<li>Gatto observed that rigidly structured schooling limits opportunities for students to learn through feedback.</li>
<li>Restoring natural feedback loops through real-world experiences was hypothesized to mitigate the negative effects of media overconsumption.</li>
</ul>
</section>
<section id="the-guerrilla-curriculum-action-and-experience" class="level3">
<h3 class="anchored" data-anchor-id="the-guerrilla-curriculum-action-and-experience">The Guerrilla Curriculum: Action and Experience</h3>
<ul>
<li>Gatto’s alternative curriculum aimed to combat inactivity and lack of feedback in children’s lives.</li>
<li>The goal was to encourage activities that fostered direct engagement with reality.</li>
<li>Gatto believed the problem stemmed from the replacement of real experiences with simulated ones.</li>
<li>The curriculum emphasized:
<ul>
<li><strong>Face-to-face interaction:</strong> Encouraging real-life engagement over screen-mediated experiences</li>
<li><strong>Active participation:</strong> Shifting children from passive spectators to active participants in their own lives</li>
</ul></li>
<li>Parents were enlisted as co-conspirators in this endeavor.</li>
</ul>
<section id="the-camino-de-santiago-inspiration" class="level4">
<h4 class="anchored" data-anchor-id="the-camino-de-santiago-inspiration">The Camino de Santiago Inspiration</h4>
<ul>
<li>The Camino de Santiago, a medieval pilgrimage route in Spain, served as a model.</li>
<li>Modern pilgrims undertake this journey for:
<ul>
<li>Self-discovery</li>
<li>Self-reliance</li>
<li>Connection with nature</li>
<li>Reflection and cultural immersion</li>
</ul></li>
<li>Gatto saw parallels between the pilgrims’ journeys and the need to reconnect children with themselves and the real world.</li>
</ul>
</section>
<section id="new-york-city-as-a-classroom" class="level4">
<h4 class="anchored" data-anchor-id="new-york-city-as-a-classroom">New York City as a Classroom</h4>
<ul>
<li>Students embarked on solo expeditions throughout New York City:
<ul>
<li>Walking the circumference of Manhattan</li>
<li>Exploring and profiling different neighborhoods</li>
<li>Mapping Central Park and other landmarks</li>
<li>Investigating government institutions</li>
</ul></li>
<li>These expeditions involved:
<ul>
<li>Observation</li>
<li>Analysis</li>
<li>Research</li>
<li>Documentation through guide pamphlets and presentations</li>
</ul></li>
<li>Students were encouraged to explore their interests independently, taking time away from school with parental support.</li>
</ul>
</section>
<section id="a-visitors-key-to-iceland-a-model-for-exploration" class="level4">
<h4 class="anchored" data-anchor-id="a-visitors-key-to-iceland-a-model-for-exploration">A Visitor’s Key to Iceland: A Model for Exploration</h4>
<ul>
<li>Inspired by “A Visitor’s Key to Iceland,” a guidebook detailing the country’s history and landscape, students created their own guides:
<ul>
<li>Identifying safe havens for playing hooky</li>
<li>Mapping and reviewing pizzerias</li>
<li>Analyzing brownstone architecture</li>
<li>Documenting and comparing neighborhood swimming pools</li>
</ul></li>
<li>These projects combined:
<ul>
<li>Exploration</li>
<li>Observation</li>
<li>Research</li>
<li>Analysis</li>
<li>Writing</li>
</ul></li>
</ul>
</section>
<section id="results-and-observations" class="level4">
<h4 class="anchored" data-anchor-id="results-and-observations">Results and Observations</h4>
<ul>
<li>As students engaged in real-world experiences, the allure of screens diminished.</li>
<li>Active participation proved more rewarding than passive observation.</li>
<li>Combining real-world experiences with intellectual work stimulated growth and development.</li>
<li>Gatto observed significant positive changes in students’ behavior and character.</li>
</ul>
</section>
</section>
<section id="the-importance-of-challenge-and-purpose" class="level3">
<h3 class="anchored" data-anchor-id="the-importance-of-challenge-and-purpose">The Importance of Challenge and Purpose</h3>
<ul>
<li>Embracing challenges is crucial for self-mastery and competence.</li>
<li>Gatto emphasizes that this approach is not complicated and requires no special talent or resources.</li>
<li>The primary obstacles are:
<ul>
<li>Resistance from traditional school systems</li>
<li>Societal emphasis on control over learning</li>
</ul></li>
<li>In a supportive environment, fostering growth in children would be effortless.</li>
</ul>
</section>
<section id="conclusion-reclaiming-real-life" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-reclaiming-real-life">Conclusion: Reclaiming Real Life</h3>
<ul>
<li>Gatto received accolades for the students’ achievements, despite the school system’s ignorance of the methods.</li>
<li>The message is clear:
<ul>
<li>Prioritize children’s needs over institutional demands.</li>
<li>Encourage real-world experiences.</li>
<li>Foster self-discovery and purpose.</li>
</ul></li>
<li>Every child deserves their own “Camino de Santiago” experience.</li>
<li>If institutions fail to provide this, parents must take responsibility.</li>
</ul>
</section>
<section id="a-call-to-action-disconnect-to-reconnect" class="level3">
<h3 class="anchored" data-anchor-id="a-call-to-action-disconnect-to-reconnect">A Call to Action: Disconnect to Reconnect</h3>
<ul>
<li>Modern society, driven by technology and institutionalization, has detached children from real-life experiences.</li>
<li>This detachment leads to negative consequences:
<ul>
<li>Anger</li>
<li>Fear</li>
<li>Lack of compassion</li>
<li>Incompleteness</li>
</ul></li>
<li>Restoring real-world experiences is crucial for healthy development.</li>
<li>The solution is simple:
<ul>
<li>Reduce screen time.</li>
<li>Encourage engagement with the real world.</li>
</ul></li>
<li>Show, don’t tell, the value of real-life experiences.</li>
</ul>
</section>
<section id="the-challenge-of-technology" class="level3">
<h3 class="anchored" data-anchor-id="the-challenge-of-technology">The Challenge of Technology</h3>
<ul>
<li>While acknowledging the benefits of technology, Gatto expresses concerns about its potential to hinder human development.</li>
<li>The key is to harness technology’s power without becoming enslaved by it.</li>
</ul>
</section>
<section id="a-vision-for-the-future" class="level3">
<h3 class="anchored" data-anchor-id="a-vision-for-the-future">A Vision for the Future</h3>
<ul>
<li>Gatto proposes a radical shift in education:
<ul>
<li>Reduce high school by two years.</li>
<li>Use the saved resources to fund personal “Camino de Santiago” experiences for all students.</li>
</ul></li>
<li>These journeys need not be as extreme as those of George Mee or Tania Abe, but should offer significant personal growth opportunities.</li>
</ul>
</section>
<section id="final-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h3>
<ul>
<li>We all have a limited time on earth.</li>
<li>We must prioritize real-life experiences, challenges, and personal growth.</li>
<li>Break free from media addiction and reconnect with the world.</li>
<li>Embrace responsibility, purpose, and active citizenship.</li>
<li>Develop your heart, mind, and spirit through real-world engagement.</li>
<li>Resist the allure of the spectator’s life and become an active participant in your own story.</li>
</ul>
</section>
</section>
<section id="chapter-7-weapons-of-mass-instruction" class="level2">
<h2 class="anchored" data-anchor-id="chapter-7-weapons-of-mass-instruction">Chapter 7: Weapons of Mass Instruction</h2>
<section id="the-crisis-in-education" class="level3">
<h3 class="anchored" data-anchor-id="the-crisis-in-education">The Crisis in Education</h3>
<ul>
<li>Only <strong>31%</strong> of college-educated Americans can fully comprehend a newspaper story, down from <strong>40%</strong> a decade ago.
<ul>
<li><em>Source: National Commission on the Future of Higher Education, August 2006</em></li>
</ul></li>
<li><strong>35%</strong> of young people regret their university experience and don’t consider the time and money invested worth it.
<ul>
<li>Over half of those surveyed said they learned nothing of use.</li>
<li><em>Source: Wilson Quarterly, Autumn, 2006</em></li>
</ul></li>
</ul>
</section>
<section id="school-as-a-hostile-environment" class="level3">
<h3 class="anchored" data-anchor-id="school-as-a-hostile-environment">School as a Hostile Environment</h3>
<section id="a-moral-odor" class="level4">
<h4 class="anchored" data-anchor-id="a-moral-odor">A Moral Odor</h4>
<ul>
<li><strong>Jacques Lusserin</strong>, a blind French teenager who led an underground resistance group during World War II, described his early schooling as a “moral disaster” in his autobiography, <em>And Then There Was Light</em>.
<ul>
<li>Lusserin: “There is such a thing as moral odor, and that was the case at school. A group of human beings that stay in one room by compulsion begins to smell.”</li>
<li>He argued that the suppressed anger, stifled independence, and frustrated curiosity of children create a toxic environment.</li>
<li>Lusserin’s ability to commit violence shortly after leaving school, where real moral questions were absent, raises concerns about the moral education provided by schools.</li>
<li><strong>“We become what we behold. It’s something to remember, Columbine.”</strong></li>
</ul></li>
</ul>
</section>
<section id="school-as-a-weapon" class="level4">
<h4 class="anchored" data-anchor-id="school-as-a-weapon">School as a Weapon</h4>
<ul>
<li>Historical accounts of schooling are overwhelmingly negative, raising questions about its effectiveness and purpose.</li>
<li>School weakens family relationships and disconnects individuals from themselves.</li>
<li>The emphasis on winning over learning is pervasive, leading to scandals where even elite students lack fundamental knowledge.</li>
<li>Gatto questions the practice of entrusting children to strangers for instruction in an unknown curriculum.</li>
<li>Examples of school’s negative portrayal in culture:
<ul>
<li>Horace’s ode contemplating the torments of schooling.</li>
<li>Mosaics in Pompeii depicting harsh school discipline.</li>
<li>Washington Irving’s <em>The Legend of Sleepy Hollow</em> celebrating a triumph over an unbearable schoolmaster.</li>
<li>The World War I song “School Days” linking learning to corporal punishment.</li>
<li>The film <em>Teaching Miss Tingle</em> about a teacher kidnapped and tortured by her students.</li>
<li>Websites dedicated to disrupting school routines.</li>
</ul></li>
<li>Conversely, people rarely attribute their success to their school years.</li>
<li>Gatto argues that school inflicts damage through its punitive machinery.</li>
</ul>
</section>
</section>
<section id="a-teachers-perspective" class="level3">
<h3 class="anchored" data-anchor-id="a-teachers-perspective">A Teacher’s Perspective</h3>
<section id="a-personal-formula" class="level4">
<h4 class="anchored" data-anchor-id="a-personal-formula">A Personal Formula</h4>
<ul>
<li><p>Gatto, a teacher with 30 years of experience, realized early on that school diminished intellectual power, creativity, and character.</p></li>
<li><p>He felt like a guard in a penitentiary, enforcing rules and procedures that stifled learning.</p></li>
<li><p>Inspired by Lusserin’s resistance, Gatto developed a formula to counter the negative effects of school:</p>
<ol type="1">
<li><strong>Personalized Student Biographies:</strong> Compile detailed profiles of each student, gathering information from family, friends, and anyone who could provide insights into their lives, experiences, and aspirations.</li>
<li><strong>Wishes and Weaknesses:</strong> Ask each student to list three things they want to learn and three weaknesses they want to overcome.</li>
</ol>
<ul>
<li>This approach provided personalized learning goals and addressed individual needs.</li>
</ul></li>
<li><p>Gatto implemented this program without administrative approval, relying on parent support and a willingness to break rules.</p></li>
<li><p>This student-centered approach led to increased motivation, effort, and engagement.</p></li>
</ul>
</section>
<section id="research-and-experimentation" class="level4">
<h4 class="anchored" data-anchor-id="research-and-experimentation">Research and Experimentation</h4>
<ul>
<li>Gatto embarked on extensive research to understand the origins, evolution, and pervasiveness of the current school system.</li>
<li>His research culminated in a book, <em>The Underground History of American Education</em>, which a major publisher refused to publish, fearing it would offend powerful interests.</li>
<li>Alongside research, Gatto conducted extensive fieldwork in New York City, engaging in:
<ul>
<li>Infiltrating public meetings, hearings, and workplaces to observe and challenge conventional thinking.</li>
<li>Conducting public opinion polls on various subjects.</li>
<li>Organizing traveling dramatic troops to perform in schools and public spaces, promoting independent thinking, self-reliance, and creative expression.</li>
</ul></li>
<li>These experiences highlighted the barriers schooling creates, limiting intellectual and behavioral development.</li>
</ul>
</section>
<section id="bad-intentions" class="level4">
<h4 class="anchored" data-anchor-id="bad-intentions">Bad Intentions</h4>
<ul>
<li>Gatto argues that the failures of schooling, particularly in language proficiency, are not accidental but rather the result of deliberate policies and practices.</li>
<li>He contends that the system is designed to maintain its integrity and resist change, prioritizing self-preservation over student growth.</li>
<li>This resistance to feedback and deviation from established norms is compared to medieval guilds that suppressed innovation and punished independent practitioners.</li>
<li>Gatto cites Robert Michel’s study of bureaucracies, which concluded that their primary mission is self-preservation, often at the expense of their stated goals.</li>
<li>He argues that school, like other American institutions, employs a system of managed illusions to maintain control and public compliance.</li>
<li>Examples of such illusions include:
<ul>
<li>An economy based on financial trickery and bubbles, propped up by manufactured wars.</li>
<li>Entertainment industries designed to distract and pacify the population.</li>
</ul></li>
</ul>
</section>
<section id="deliberate-deprivations" class="level4">
<h4 class="anchored" data-anchor-id="deliberate-deprivations">Deliberate Deprivations</h4>
<ul>
<li>Adam Smith, in <em>The Wealth of Nations</em>, distinguished between education and schooling, arguing that education was necessary to compensate for the damaging effects of capitalism.</li>
<li>Smith believed that capitalism’s artificial environments fostered:
<ol type="1">
<li>Cowardice</li>
<li>Stupidity</li>
<li>Sluggishness</li>
<li>Indifference to anything but basic needs</li>
</ol></li>
<li>He argued that only education could heal the wounds inflicted by capitalism on individuals and communities.</li>
<li>Smith believed that all children possess the potential for intellectual growth but are deliberately deprived of opportunities for thought and speculation.</li>
<li>This deprivation, he argued, leads to intellectual and moral deformities, hindering judgment and critical thinking.</li>
<li>Gatto’s curriculum aimed to counteract these negative effects by fostering independence, critical thinking, and self-directed learning.</li>
<li>He argues that the difference between “bright” and “stupid” students is largely a result of deliberate deprivation, not inherent ability.</li>
</ul>
</section>
<section id="the-house-of-mirrors" class="level4">
<h4 class="anchored" data-anchor-id="the-house-of-mirrors">The House of Mirrors</h4>
<ul>
<li>William Playfair, Adam Smith’s publisher, criticized Smith’s belief in universal education, arguing that it threatened the existing social order.</li>
<li>Playfair believed that widespread knowledge would empower the lower classes and undermine the privileges of the elite.</li>
<li>He coined the phrase “a little knowledge is a dangerous thing,” arguing that too much knowledge would make the masses ungovernable.</li>
<li>Playfair advocated for a system of schooling that instilled deference, envy, and mistrust of self, ensuring the stability of capitalism.</li>
<li>This philosophy, known in ancient China as “The Policy of Keeping People Dumb,” emphasizes control through ignorance.</li>
<li>Gatto argues that modern leaders, while less overt, continue to employ this strategy of managed ignorance.</li>
</ul>
</section>
</section>
<section id="the-illusion-of-choice" class="level3">
<h3 class="anchored" data-anchor-id="the-illusion-of-choice">The Illusion of Choice</h3>
<section id="the-lincoln-elective-program" class="level4">
<h4 class="anchored" data-anchor-id="the-lincoln-elective-program">The Lincoln Elective Program</h4>
<ul>
<li>Gatto recounts his experience at Lincoln Academy, a public junior high school in a wealthy, intellectually vibrant area of Manhattan.</li>
<li>Despite its privileged location, the school was plagued by violence, apathy, and a sense of despair.</li>
<li>Gatto criticizes the school district’s reliance on superficial reforms and partnerships with prestigious institutions, which failed to address the underlying problems.</li>
<li>He describes the implementation of an elective program intended to give students a voice in their education.</li>
<li>However, Gatto discovered that the students in his elective class had been assigned to it against their will, highlighting the illusory nature of choice within the system.</li>
</ul>
</section>
<section id="contempt" class="level4">
<h4 class="anchored" data-anchor-id="contempt">Contempt</h4>
<ul>
<li>A 2005 Indiana University study found that school-based anti-smoking programs, despite significant funding, were universally ineffective.</li>
<li>The study’s lead author, Dr.&nbsp;Sarah Wee, suggested that any program administered through schools might inherently induce contempt in students.</li>
<li>This finding raises concerns about the credibility and effectiveness of any school-based initiative.</li>
<li>Gatto recounts the story of Roger Gaufrin, the sole survivor of a Nazi massacre in a French village during World War II.</li>
<li>Gaufrin’s survival was attributed to his defiance of his teachers’ instructions, which were based on German orders.</li>
<li>This example highlights the potential life-saving consequences of questioning authority and the dangers of blind obedience.</li>
</ul>
</section>
<section id="irrelevance" class="level4">
<h4 class="anchored" data-anchor-id="irrelevance">Irrelevance</h4>
<ul>
<li>Gatto argues that the irrelevance of school curricula contributes to the widespread contempt for education.</li>
<li>Students recognize that school prioritizes the interests of others (teachers, administrators, politicians) over their own needs and aspirations.</li>
<li>The political nature of schooling results in the omission of any information that might challenge the status quo or the beliefs of those in power.</li>
<li>This censorship creates a gulf between the idealized rhetoric of education and the reality of its practice.</li>
</ul>
</section>
<section id="the-australian-example" class="level4">
<h4 class="anchored" data-anchor-id="the-australian-example">The Australian Example</h4>
<ul>
<li>Gatto uses the example of Australia’s environmental policies to illustrate the deliberate exclusion of critical information from school curricula.</li>
<li>Despite the fragility of Australia’s ecosystem and the importance of environmental issues, schools avoid addressing the negative consequences of policies that prioritize powerful industries (e.g., sheep farming) over the long-term health of the environment and the economy.</li>
<li>This example demonstrates how political and economic interests shape educational content, often to the detriment of students’ understanding of real-world issues.</li>
</ul>
</section>
<section id="social-engineering" class="level4">
<h4 class="anchored" data-anchor-id="social-engineering">Social Engineering</h4>
<ul>
<li>Gatto argues that the rise of social media and the internet has weakened the power of traditional schooling as a tool of social control.</li>
<li>These platforms allow individuals to connect, share information, and challenge official narratives, bypassing the gatekeepers of knowledge.</li>
<li>The internet empowers individuals to verify information, fostering critical thinking and challenging Gattoity of experts.</li>
<li>This shift challenges the traditional model of mass schooling, which relies on centralized control and a passive audience.</li>
</ul>
</section>
<section id="living-by-omission" class="level4">
<h4 class="anchored" data-anchor-id="living-by-omission">Living by Omission</h4>
<ul>
<li>Gatto shares an email exchange with Bruno, a college student in Portugal, who questions the dominance of Darwin’s theory of evolution over Wallace’s alternative perspective.</li>
<li>Gatto uses this example to illustrate how the omission of crucial information can shape our understanding of history and science.</li>
<li>He argues that Darwin’s social standing, wealth, and connections, along with the alignment of his theory with the prevailing political ideology, contributed to his success.</li>
<li>Conversely, Wallace’s humble background, radical political views, and emphasis on cooperation over competition led to his marginalization.</li>
<li>Gatto highlights the importance of considering the social and political contexts in which scientific theories are developed and promoted.</li>
</ul>
</section>
<section id="building-bombs" class="level4">
<h4 class="anchored" data-anchor-id="building-bombs">Building Bombs</h4>
<ul>
<li>Gatto points out that less than a century ago, information on making explosives was readily available and considered essential knowledge for self-reliance and, in extreme cases, defending liberty.</li>
<li>He questions why this information is now considered dangerous and restricted, suggesting that governments have sought to monopolize the means of force.</li>
<li>Gatto cites Carol Quigley, a Georgetown professor and former tutor to President Clinton, who argued that an armed citizenry is essential for protecting individual rights and preventing tyranny.</li>
<li>He connects this historical context to the role of schooling, suggesting that the suppression of such knowledge reflects a broader trend of disempowering individuals and consolidating power in the hands of the state.</li>
</ul>
</section>
<section id="the-decisive-ratio" class="level4">
<h4 class="anchored" data-anchor-id="the-decisive-ratio">The Decisive Ratio</h4>
<ul>
<li>Gatto argues that factory-style schooling has shifted the balance of power in society, creating a small class of rulers and a large mass of the ruled.</li>
<li>He contends that students sense this disempowerment, contributing to their hatred of school.</li>
</ul>
</section>
<section id="physical-ugliness" class="level4">
<h4 class="anchored" data-anchor-id="physical-ugliness">Physical Ugliness</h4>
<ul>
<li>Gatto argues that school, through its emphasis on conformity, immobility, and unhealthy habits, contributes to physical and psychological ugliness.</li>
<li>He asserts that physical appearance is a significant factor in elite university admissions, with attractive, athletic, and outgoing candidates given preferential treatment.</li>
<li>This preference for certain physical traits, he argues, reflects a form of social Darwinism, where success is linked to superficial qualities rather than intellect or character.</li>
<li>Gatto criticizes the school system’s role in promoting unhealthy habits, such as prolonged sitting, poor nutrition, and lack of physical activity, which contribute to obesity, illness, and low self-esteem.</li>
<li>He questions why schools are not held accountable for the physical and psychological harm inflicted on students through these practices.</li>
</ul>
</section>
<section id="irrelevance-revisited" class="level4">
<h4 class="anchored" data-anchor-id="irrelevance-revisited">Irrelevance Revisited</h4>
<ul>
<li>Gatto revisits the issue of curriculum irrelevance, citing Langdon Winner’s book <em>Autonomous Technology</em>, which argues that modern society is characterized by a profound disconnect between individuals and the technologies they depend on.</li>
<li>Winner contends that people are unable to understand, explain, or control the complex systems that shape their lives, leading to a state of dependence and bewilderment.</li>
<li>Gatto argues that school, rather than equipping students with the skills and knowledge to navigate this complexity, reinforces conformity, obedience, and a reliance on external authorities.</li>
<li>He criticizes the emphasis on winning over learning, arguing that it undermines genuine intellectual development and critical thinking.</li>
</ul>
</section>
<section id="reaching-the-winners-circle" class="level4">
<h4 class="anchored" data-anchor-id="reaching-the-winners-circle">Reaching the Winner’s Circle</h4>
<ul>
<li>Gatto cites observations from Paul Gauguin and Aldous Huxley, both products of elite education, who lamented the irrelevance of their schooling and its failure to prepare them for the realities of life.</li>
<li>He highlights Seymour Papert’s argument that learning should be as natural and effortless as a child learning to talk, suggesting that traditional schooling is an unnecessary and often counterproductive imposition.</li>
<li>Gatto points to the growing homeschooling movement and the increasing dropout rates as evidence of a growing dissatisfaction with the current system.</li>
<li>He concludes by emphasizing that true education requires questioning assumptions, challenging authority, and engaging in independent thought, qualities discouraged by the traditional school system.</li>
</ul>
</section>
</section>
<section id="the-irrelevant-curriculum" class="level3">
<h3 class="anchored" data-anchor-id="the-irrelevant-curriculum">The Irrelevant Curriculum</h3>
<ul>
<li>The content offered in schools is radically irrelevant to the real world.</li>
<li>This raises the question of whether this irrelevance is intentional or due to incompetence.</li>
</ul>
</section>
<section id="questioning-the-intent" class="level3">
<h3 class="anchored" data-anchor-id="questioning-the-intent">Questioning the Intent</h3>
<ul>
<li>Local school officials may genuinely be confused about the purpose of education, but the system they operate within prevents significant change.</li>
<li>However, the possibility of a darker intent at higher levels of policy cannot be ignored.</li>
<li>Schooling, in its current form, clearly benefits certain powerful groups in society.</li>
<li>This raises the possibility that these groups are using institutional schooling for social engineering.</li>
</ul>
</section>
<section id="walter-lippmanns-indictment-of-modern-education" class="level3">
<h3 class="anchored" data-anchor-id="walter-lippmanns-indictment-of-modern-education">Walter Lippmann’s Indictment of Modern Education</h3>
<ul>
<li><p>In a 1940 speech, journalist and political philosopher Walter Lippmann argued that modern education was destroying Western civilization.</p>
<ul>
<li><blockquote class="blockquote">
<p>“During the past 40 or 50 years, those who are responsible for education have progressively removed from the curriculum the Western culture which produced the modern democratic state. The schools and colleges have therefore been sending out into the world men who no longer understand the creative principle of the society in which they must live.” - <strong>Walter Lippmann, 1940 speech to the Association for the Advancement of Science</strong></p>
</blockquote></li>
</ul></li>
<li><p>Lippmann believed that by removing Western culture from the curriculum, schools were depriving students of the “premises, the rationale, the logic, the methods, the values of the deposited wisdom which are the genius of the development of Western civilization.”</p></li>
</ul>
</section>
<section id="dr.-carol-quigleys-suppressed-history" class="level3">
<h3 class="anchored" data-anchor-id="dr.-carol-quigleys-suppressed-history">Dr.&nbsp;Carol Quigley’s Suppressed History</h3>
<ul>
<li>Georgetown University scholar Dr.&nbsp;Carol Quigley explored the motives and methods behind the removal of Western culture from education in his 1966 book, <em>Tragedy and Hope: A History of the World in Our Time</em>.</li>
<li>The book was so controversial that the publisher destroyed the printing plates after the first run of 2,000 copies and refused to reprint it despite strong demand.</li>
<li>Dr.&nbsp;Quigley was told that the book was met with public indifference, but thousands of bootleg copies have circulated since.</li>
<li><strong>Note:</strong> Some later printings of the book may have been altered. It is recommended to seek out older versions.</li>
<li>Dr.&nbsp;Quigley was President Bill Clinton’s personal tutor at Georgetown.</li>
</ul>
</section>
<section id="scientific-management-and-the-suppression-of-individuality" class="level3">
<h3 class="anchored" data-anchor-id="scientific-management-and-the-suppression-of-individuality">Scientific Management and the Suppression of Individuality</h3>
<ul>
<li>Scientific management, a system developed by efficiency expert Frederick Taylor, prioritizes subordination and predictability above all else.</li>
<li>This system views educated and principled individuals as rogue elements that threaten its order.</li>
<li><strong>The ideal hireling in a system of scientific management is:</strong>
<ul>
<li>Reflexively obedient</li>
<li>Cheerfully enthusiastic about following orders</li>
<li>Eager to please</li>
</ul></li>
<li>Training for this type of worker begins in first grade with the word “don’t.”</li>
</ul>
</section>
<section id="the-dont-drill" class="level3">
<h3 class="anchored" data-anchor-id="the-dont-drill">The “Don’t” Drill</h3>
<ul>
<li>Primary school, instead of being a time for exploration and self-discovery, becomes an exercise in limitation.</li>
<li>Children are bombarded with “don’ts,” suppressing their natural curiosity and desire for autonomy.</li>
<li><strong>Examples of “don’ts” in school:</strong>
<ul>
<li>Don’t run.</li>
<li>Don’t talk.</li>
<li>Don’t climb trees.</li>
<li>Don’t play rough.</li>
<li>Don’t talk unless you raise your hand.</li>
<li>Don’t fidget.</li>
<li>Don’t get out of your seat.</li>
<li>Don’t stare out the window.</li>
<li>Don’t take your shoes off.</li>
<li>Don’t eat or drink in class.</li>
<li>Don’t laugh.</li>
<li>Don’t take too long.</li>
<li>Don’t read ahead.</li>
<li>Don’t go off the path.</li>
<li>Don’t say “I’m bored.”</li>
<li>Don’t mix with the older kids.</li>
<li>Don’t complain.</li>
<li>Don’t bring toys.</li>
</ul></li>
<li><strong>Implicit “don’ts”:</strong>
<ul>
<li>Don’t have your own ideas.</li>
<li>Don’t show initiative.</li>
<li>Don’t be independent.</li>
<li>Don’t make your own choices.</li>
<li>Don’t take responsibility for your own learning.</li>
</ul></li>
<li>This constant negativity leads to indifference and a desire for escapism through things like violence, cruelty, and drugs.</li>
</ul>
</section>
<section id="the-perils-of-field-trips" class="level3">
<h3 class="anchored" data-anchor-id="the-perils-of-field-trips">The Perils of Field Trips</h3>
<ul>
<li>A permission form from Queen Elizabeth Junior and Senior High School in Calgary, Canada, illustrates how schools discourage direct experience.</li>
<li>The form lists a litany of potential hazards students might encounter on a museum trip, including:
<ul>
<li>Motion sickness</li>
<li>Injuries from sudden acceleration or deceleration</li>
<li>Tripping hazards</li>
<li>Overheating</li>
<li>Objects coming through windows</li>
<li>Allergic reactions</li>
<li>Dehydration</li>
<li>Extreme weather conditions</li>
<li>Attacks from wild animals</li>
<li>Foodborne illnesses</li>
<li>Electrical storms</li>
<li>Landslides</li>
<li>Pinching</li>
<li>Collapsing exhibits</li>
</ul></li>
<li>This type of risk aversion creates a culture of fear and discourages exploration.</li>
</ul>
</section>
<section id="collectivization-and-the-lowest-common-denominator" class="level3">
<h3 class="anchored" data-anchor-id="collectivization-and-the-lowest-common-denominator">Collectivization and the Lowest Common Denominator</h3>
<ul>
<li>Following the Prussian model, modern schools treat children as categories rather than individuals.</li>
<li>This collectivist approach leads to a focus on averages and the lowest common denominator, hindering the progress of individual students.</li>
<li>Gatto uses the example of the New York City mayor’s attempt to improve the school system by lowering standards for everyone. Despite a 79% increase in spending and the hiring of 5,000 new teachers, the results were negligible.</li>
</ul>
</section>
<section id="the-connected-mind" class="level3">
<h3 class="anchored" data-anchor-id="the-connected-mind">The Connected Mind</h3>
<ul>
<li>The educated mind is a connected mind, linked to:
<ul>
<li>Different human styles</li>
<li>Complex experiences</li>
<li>A wide range of intellectual ideas</li>
<li>Itself (self-knowledge)</li>
</ul></li>
<li>School, however, disconnects children from these vital connections.</li>
</ul>
</section>
<section id="the-talking-choo-choo-syndrome" class="level3">
<h3 class="anchored" data-anchor-id="the-talking-choo-choo-syndrome">The Talking Choo-Choo Syndrome</h3>
<ul>
<li>Gatto recounts an experience reviewing a curriculum for a chain of private schools.</li>
<li>While impressed with the schools’ overall environment, Gatto was troubled by:
<ul>
<li>The lack of student voice in discussions about their own education</li>
<li>The use of a simplified, “baudelarized” version of Homer’s <em>Odyssey</em></li>
</ul></li>
<li>This encounter led to a discussion about the “talking choo-choo” syndrome in education: the use of childish methods and materials to teach even older students.</li>
<li>This approach, Gatto argues, is a form of “German disease” that artificially extends childhood and hinders the development of critical thinking skills.</li>
<li><strong>Examples of “talking choo-choos”:</strong>
<ul>
<li>Slasher films</li>
<li>Pornography</li>
<li>Fast food</li>
<li>Tabloid news</li>
</ul></li>
<li>These things create a “perverse hunger” for simplification and instant gratification that is difficult to overcome.</li>
</ul>
</section>
<section id="beatrix-potter-and-the-importance-of-darkness" class="level3">
<h3 class="anchored" data-anchor-id="beatrix-potter-and-the-importance-of-darkness">Beatrix Potter and the Importance of Darkness</h3>
<ul>
<li>Children’s author Beatrix Potter serves as a counter-example to the “talking choo-choo” approach.</li>
<li>Potter’s stories, while featuring talking animals, are not afraid to address dark and complex themes like death, evil, and cruelty.</li>
<li>Gatto argues that children are drawn to Potter’s work because it reflects the realities of life, both good and bad.</li>
</ul>
</section>
<section id="alina-del-don-and-the-rejection-of-training-wheels" class="level3">
<h3 class="anchored" data-anchor-id="alina-del-don-and-the-rejection-of-training-wheels">Alina Del Don and the Rejection of Training Wheels</h3>
<ul>
<li>Alina Del Don, a star basketball player, demonstrated remarkable independence and problem-solving skills at the age of three by removing the training wheels from her bike without assistance.</li>
<li>This anecdote highlights the importance of allowing children to take risks and solve problems independently.</li>
<li>Gatto suggests that schools should abandon the “training wheels” approach and encourage students to embrace challenges.</li>
</ul>
</section>
<section id="the-importance-of-treating-children-as-adults" class="level3">
<h3 class="anchored" data-anchor-id="the-importance-of-treating-children-as-adults">The Importance of Treating Children as Adults</h3>
<ul>
<li>Gatto advocates for treating children as adults, even from a young age.</li>
<li>This includes:
<ul>
<li>Not shielding them from the realities of life, such as family finances</li>
<li>Recognizing and nurturing their inherent intelligence and capabilities</li>
<li>Encouraging self-sufficiency and responsibility</li>
</ul></li>
<li>Gatto believes that the concept of “adolescence” is a manufactured construct designed to extend childhood and maintain control over young people.</li>
</ul>
</section>
<section id="john-latsis-a-self-made-success-story" class="level3">
<h3 class="anchored" data-anchor-id="john-latsis-a-self-made-success-story">John Latsis: A Self-Made Success Story</h3>
<ul>
<li>John Latsis, a Greek shipping magnate, achieved extraordinary success despite having no formal education.</li>
<li>Latsis began working as a laborer at age 12 and eventually built a massive business empire through hard work, determination, and a willingness to learn.</li>
<li>Gatto contrasts Latsis’s story with the experiences of highly educated but unfulfilled young professionals, highlighting the limitations of a purely academic approach to success.</li>
</ul>
</section>
<section id="tanya-eby-and-george-meehan-unschooled-triumphs" class="level3">
<h3 class="anchored" data-anchor-id="tanya-eby-and-george-meehan-unschooled-triumphs">Tanya Eby and George Meehan: Unschooled Triumphs</h3>
<ul>
<li>Tanya Eby, a high school dropout, became the first woman to circumnavigate the globe solo at the age of 18.</li>
<li>George Meehan, with only a third-grade education, completed the longest walk in human history, traveling from the tip of South America to Point Barrow, Alaska.</li>
<li>These stories demonstrate the extraordinary capabilities of unschooled individuals and challenge the notion that formal education is essential for achievement.</li>
</ul>
</section>
<section id="the-trapped-flea-principle" class="level3">
<h3 class="anchored" data-anchor-id="the-trapped-flea-principle">The Trapped Flea Principle</h3>
<ul>
<li>Gatto recounts a story shared by Andrew Hsu, an eleven-year-old homeschooler who won the Washington State Science and Engineering Fair, about the method used to train fleas.</li>
<li>The story illustrates how repeatedly limiting a flea’s ability to jump eventually conditions it to accept a lower ceiling, even when the lid is removed.</li>
<li>Gatto connects this to schooling, arguing that the constant imposition of rules, limitations, and low expectations ultimately conditions students to accept a diminished sense of their own potential.</li>
</ul>
</section>
<section id="how-to-drive-a-horse-slightly-insane" class="level3">
<h3 class="anchored" data-anchor-id="how-to-drive-a-horse-slightly-insane">How to Drive a Horse Slightly Insane</h3>
<ul>
<li>Gatto draws parallels between techniques used to break the spirit of horses and the practices employed in traditional schooling.</li>
<li>He cites an article from the Equine Mental Health Association, which warns against isolating horses, restricting their movement, and depriving them of mental stimulation, arguing that these practices can lead to psychological problems.</li>
<li>He argues that schools, by their very nature, replicate these harmful conditions, producing graduates who are passive, dependent, and ill-equipped to thrive in the real world.</li>
</ul>
</section>
<section id="the-cauldron-of-broken-time" class="level3">
<h3 class="anchored" data-anchor-id="the-cauldron-of-broken-time">The Cauldron of Broken Time</h3>
<ul>
<li>Schools operate on a highly structured schedule that fragments time and hinders deep thinking.</li>
<li>Constant interruptions and a lack of uninterrupted time make it difficult for students to synthesize information, form their own conclusions, and engage in meaningful learning.</li>
<li>Gatto argues that this “cauldron of broken time” is a deliberate tactic to prevent students from developing independent thought.</li>
</ul>
</section>
<section id="conclusion-2" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-2">Conclusion</h3>
<ul>
<li>Gatto urges readers to continue questioning the true purpose of compulsory schooling and to seek out alternative paths to knowledge and fulfillment.</li>
</ul>
</section>
</section>
<section id="chapter-8-what-is-education" class="level2">
<h2 class="anchored" data-anchor-id="chapter-8-what-is-education">Chapter 8: What is Education?</h2>
<section id="kants-questions-in-the-epic-of-europe" class="level3">
<h3 class="anchored" data-anchor-id="kants-questions-in-the-epic-of-europe">Kant’s Questions in the Epic of Europe</h3>
<ul>
<li>German philosopher Immanuel Kant posed four fundamental questions in education:
<ul>
<li>What can I know?</li>
<li>What may I hope?</li>
<li>What ought I to do?</li>
<li>What is man?</li>
</ul></li>
<li>Ironically, the German education system that emerged stifled philosophical curiosity and spread globally.</li>
<li>American compulsory schooling, heavily influenced by the German model, is not a homegrown product and doesn’t primarily focus on transmitting basic skills.
<ul>
<li><strong>Reference:</strong> <a href="https://www.loc.gov/item/06017777/">Horace Mann’s Seventh Letter to the Boston School Committee</a></li>
</ul></li>
<li>Grappling with Kant’s questions is crucial for developing a meaningful curriculum.</li>
<li>Neglecting this responsibility leads to education serving someone else’s agenda, hindering personal growth.</li>
<li>True education transcends material pursuits and focuses on deeper understanding.</li>
<li>Defining education can be elusive, but recognizing its essence is possible.</li>
</ul>
</section>
<section id="three-probes-into-the-mystery-of-education" class="level3">
<h3 class="anchored" data-anchor-id="three-probes-into-the-mystery-of-education">Three Probes into the Mystery of Education</h3>
<section id="james-salters-perspective" class="level4">
<h4 class="anchored" data-anchor-id="james-salters-perspective">James Salter’s Perspective</h4>
<ul>
<li>Travel writer James Salter found that Europe provided a unique education.
<ul>
<li><blockquote class="blockquote">
<p>“The thing it finally gave me was education, not the lessons of school but something more elevated, a view of how to endure, how to have leisure, food, love, and conversation, how to look at nakedness, architecture, streets, all new, and seeking to be thought of in a different way.” - <strong>James Salter</strong></p>
</blockquote></li>
</ul></li>
<li>Europe’s historical depth humbled him, highlighting the limitations of formal schooling.
<ul>
<li><blockquote class="blockquote">
<p>“In Europe the shadow of history falls upon you and, knowing none of it, you realize suddenly how small you are. To know nothing is to have done nothing. To remember only yourself is like worshipping a dust moat.” - <strong>James Salter</strong></p>
</blockquote></li>
</ul></li>
<li>Salter viewed Europe as a vast classroom beyond traditional boundaries.
<ul>
<li><blockquote class="blockquote">
<p>“Europe is on the order of an immense and unfathomable classroom beyond catalog or description.” - <strong>James Salter</strong></p>
</blockquote></li>
</ul></li>
</ul>
</section>
<section id="testimony-to-the-u.s.-senate-committee-on-labor-and-human-relations-october-23-1991" class="level4">
<h4 class="anchored" data-anchor-id="testimony-to-the-u.s.-senate-committee-on-labor-and-human-relations-october-23-1991">Testimony to the U.S. Senate Committee on Labor and Human Relations (October 23, 1991)</h4>
<ul>
<li><strong>Fear of Stagnation:</strong> Gatto expressed concern that schools in 2000 would resemble those of 1990 and 1890, indicating a lack of progress.</li>
<li><strong>Historical Contrast:</strong>
<ul>
<li>Education in 1790 America differed significantly:
<ul>
<li>Schooling was voluntary and shorter in duration.</li>
<li>It didn’t dominate a child’s time or interfere with family life.</li>
<li>Indoctrination was less prevalent.</li>
<li>Literacy rates were higher in some cases, like Massachusetts, compared to the compulsory system.</li>
</ul></li>
</ul></li>
<li><strong>Barriers to Change:</strong>
<ul>
<li>Political systems often hinder educational reform due to vested interests.</li>
<li>Schools represent lucrative contracts and job opportunities, creating resistance to change.</li>
</ul></li>
<li><strong>Hope for the Future:</strong>
<ul>
<li>A nationwide debate on the definition of an educated person is necessary.</li>
<li>This definition should outline valuable human competencies that schools must foster.</li>
</ul></li>
<li><strong>Characteristics of Educated Individuals:</strong>
<ul>
<li>Comfortable with solitude and time management.</li>
<li>Capable of forming healthy relationships.</li>
<li>Aware of their mortality and the importance of lifelong learning.</li>
<li>Possess a strong sense of personal values while respecting diverse perspectives.</li>
<li>Creative, resourceful, and adaptable.</li>
<li>Understand the balance between material wealth and intangible values like love, curiosity, reverence, and empathy.</li>
<li>Seek variety and balance it with home and responsibilities.</li>
</ul></li>
<li><strong>A Curriculum for Life:</strong>
<ul>
<li>Education should address fundamental life passages:
<ul>
<li><strong>Birth and Self-Discovery:</strong> Understanding one’s origins, family, and cultural influences.</li>
<li><strong>The Physical World:</strong> Exploration and analysis of the natural environment.</li>
<li><strong>Human Relationships:</strong> Navigating the complexities of family, friendships, love, and community.</li>
<li><strong>Vocation:</strong> Finding purpose and contributing to society through work.</li>
<li><strong>Maturity and Independence:</strong> Embracing the responsibilities of adulthood.</li>
<li><strong>Death and Legacy:</strong> Contemplating mortality and leaving a positive impact on future generations.</li>
</ul></li>
</ul></li>
<li><strong>Breaking Free from Institutional Confinement:</strong>
<ul>
<li>Education should extend beyond the confines of traditional schools.</li>
<li>It should occur in diverse settings, embracing the richness of real-world experiences.</li>
</ul></li>
<li><strong>The Perils of Standardized Testing:</strong>
<ul>
<li>Standardized tests prioritize scores over genuine learning and personal growth.</li>
<li>They fail to accurately predict real-world success.</li>
<li>High test scores are often achieved through memorization and test-taking strategies rather than deep understanding.</li>
<li>Testing promotes dishonesty and a narrow focus on specific skills.</li>
<li>It creates unnecessary anxiety and pressure on students.</li>
</ul></li>
<li><strong>The Example of Reading:</strong>
<ul>
<li>Learning to read is relatively simple when approached naturally.</li>
<li>Traditional methods often create aversion to reading by emphasizing pressure, ranking, and standardized assessments.</li>
</ul></li>
<li><strong>A Vision for a New School:</strong>
<ul>
<li>Decentralized and accessible learning opportunities in various locations.</li>
<li>Open to all individuals, regardless of age or background.</li>
<li>Utilizing technology and the internet to facilitate learning.</li>
<li>Empowering individuals to take control of their education.</li>
<li>Shifting funding and control away from centralized institutions.</li>
</ul></li>
<li><strong>Embracing Flexibility:</strong>
<ul>
<li>Flexible schedules, learning environments, and study options to accommodate individual needs and learning styles.</li>
</ul></li>
<li><strong>The Power of Imagination:</strong>
<ul>
<li>Nurturing imagination is crucial for innovation and progress.</li>
<li>Standardized testing stifles creativity and independent thinking.</li>
</ul></li>
<li><strong>Less is More:</strong>
<ul>
<li>Effective education often requires less formal schooling, personnel, and materials.</li>
<li>It emphasizes real-world experiences and community involvement.</li>
</ul></li>
<li><strong>Bottom-Up Reform:</strong>
<ul>
<li>Meaningful change is more likely to originate from individuals and communities than from top-down mandates.</li>
<li>Parents, students, and teachers must challenge the status quo and seek alternative approaches.</li>
</ul></li>
<li><strong>Challenging Conventional Wisdom:</strong>
<ul>
<li>Gatto challenges the notion that a more complex world necessitates more schooling and testing.</li>
<li>He argues that real-world learning often occurs outside of formal educational settings.</li>
</ul></li>
<li><strong>The Analogy of Driving:</strong>
<ul>
<li>Learning to drive is a complex skill acquired through experience and practice, not formal schooling.</li>
<li>Similarly, many essential life skills are learned through self-directed exploration and real-world challenges.</li>
</ul></li>
<li><strong>A Call to Action:</strong>
<ul>
<li>Gatto urges readers to question the prevailing educational paradigm and seek alternatives that prioritize genuine learning, personal growth, and a fulfilling life.</li>
</ul></li>
</ul>
</section>
<section id="a-free-verse-for-christina" class="level4">
<h4 class="anchored" data-anchor-id="a-free-verse-for-christina">A Free Verse for Christina</h4>
<ul>
<li>Education should foster individuality.</li>
<li>It should equip students with courage, guiding principles, and resilience in the face of adversity.</li>
<li>It should instill a love for life and a deep understanding of its meaning.</li>
<li>Education should guide individuals toward discovering what truly matters and how to live and die with purpose.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-9-a-letter-to-my-granddaughter-about-dartmouth" class="level2">
<h2 class="anchored" data-anchor-id="chapter-9-a-letter-to-my-granddaughter-about-dartmouth">Chapter 9: A Letter to My Granddaughter About Dartmouth</h2>
<section id="family-matters" class="level3">
<h3 class="anchored" data-anchor-id="family-matters">Family Matters</h3>
<ul>
<li>Gatto’s granddaughter, Christina, is a “boat rocker” like her ancestors.
<ul>
<li>She rode her bike on Fifth Avenue in defiance of a city ban.</li>
<li>She was captain of a national champion debating team.</li>
<li>She legally changed her name from Gudrun to Christina.</li>
</ul></li>
<li>Gatto’s wife, Janet, comes from a long line of “contrarians.”
<ul>
<li>Her clan was outlawed by the British Crown.</li>
<li>Her great-great-grandmother wore a top hat.</li>
<li>Rob Roy, the famous outlaw, claimed her clan as his own.</li>
</ul></li>
<li>Gatto and Janet were married in a Buddhist temple near Columbia University in New York City.
<ul>
<li>They were married there because they were both unemployed and broke, and the Buddhists offered the service for free.</li>
<li>Janet was pregnant with Gatto’s mother at the time.</li>
</ul></li>
<li>Gatto’s family on his father’s side, were Italian.
<ul>
<li>His great-great-grandfather, Giovanni, was a Presbyterian, journalist, and Freemason.</li>
<li>Giovanni was forced to leave Italy because of his beliefs.</li>
<li>Giovanni’s wife, Lucrezia, lost her inheritance and title for marrying him.</li>
<li>The Gatos moved to Pittsburgh and thrived for a while.
<ul>
<li>Andrew Mellon hired Giovanni to oversee the foreign exchange division of Mellon Bank.</li>
<li>They were hosts to the famous tenor, Caruso.</li>
</ul></li>
<li>Giovanni died at 49 from an extravagant lifestyle.
<ul>
<li>He was the Grand Venerable of the Masonic Order for Pennsylvania at the time.</li>
<li>He was buried in an unmarked grave by Lucrezia because he had a mistress.</li>
</ul></li>
</ul></li>
<li>Gatto’s family on his mother’s side, the Zimmers, were from the river town of Monongahela.
<ul>
<li>His great-grandfather, Harry Taylor Zimmer, was the town printer and a traveling circus owner.</li>
<li>Harry was a staunch Republican in a predominantly Democratic town.</li>
<li>Harry’s son, Bud, was a World War II veteran who became a successful businessman.</li>
</ul></li>
</ul>
</section>
<section id="dartmouth-college" class="level3">
<h3 class="anchored" data-anchor-id="dartmouth-college">Dartmouth College</h3>
<ul>
<li>Gatto advises his granddaughter to think carefully about attending Dartmouth or any elite college.
<ul>
<li>He believes these institutions promote an illusion of social privilege.</li>
<li>He argues that true success comes from within, not from attending a prestigious school.</li>
</ul></li>
<li>Gatto believes that American society has become obsessed with the idea that elite colleges hold the key to a successful life.
<ul>
<li>He sees this as a form of brainwashing that benefits the system, not the individual.</li>
<li>He encourages his granddaughter to reject this belief and forge her own path.</li>
</ul></li>
<li>Provides examples of successful individuals without prestigious education:
<ul>
<li>Hot dog vendor earning more than NYC mayor and US president combined</li>
<li>Pet sitter as socially useful profession</li>
</ul></li>
<li>He emphasizes the importance of finding work that is both personally fulfilling and adds value to society.</li>
<li>Gatto acknowledges the importance of education but believes that true learning happens outside the classroom.
<ul>
<li>He provides eight “yardsticks” for measuring real education:
<ol type="1">
<li><strong>Self-knowledge:</strong> Understanding one’s own character, strengths, and weaknesses.</li>
<li><strong>Observation:</strong> Developing sharp observational skills and the ability to analyze information objectively.</li>
<li><strong>Feedback:</strong> Being receptive to criticism and using it to improve oneself.</li>
<li><strong>Analysis:</strong> Breaking down complex problems into smaller, more manageable parts.</li>
<li><strong>Mirroring:</strong> Being able to understand and empathize with others, even those who are different from oneself.</li>
<li><strong>Expression:</strong> Communicating effectively both verbally and in writing.</li>
<li><strong>Judgment:</strong> Evaluating information critically and discerning truth from falsehood.</li>
<li><strong>Adding Value:</strong> Contributing positively to every interaction and group one is a part of.</li>
</ol></li>
</ul></li>
</ul>
</section>
<section id="a-nation-trapped-in-a-labyrinth" class="level3">
<h3 class="anchored" data-anchor-id="a-nation-trapped-in-a-labyrinth">A Nation Trapped in a Labyrinth</h3>
<ul>
<li>Both Gatto’s granddaughter and the nation are trapped in a system created by previous generations.
<ul>
<li>This system is beyond the reach of traditional schooling to fix.</li>
</ul></li>
<li><strong>Social unrest</strong> and a <strong>loss of faith</strong> in American leadership are prevalent due to a <strong>unilateral reorganization of work</strong>.
<ul>
<li>This reorganization is orchestrated by <strong>large employers</strong> who hold significant influence over the government.</li>
<li><strong>Elite universities</strong> like Harvard and Dartmouth are complicit in designing and promoting this system.</li>
</ul></li>
<li>This new work structure prioritizes corporate profits over the well-being of workers.
<ul>
<li><strong>Exportation of American jobs</strong> and <strong>importation of foreign workers</strong> are used to maximize profits.</li>
<li><strong>Multi-billionaires</strong> like Bill Gates are at the forefront of this movement.</li>
</ul></li>
<li><strong>Contingent labor</strong> is another symptom of this system.
<ul>
<li>Companies hire temporary workers to avoid providing benefits and job security.</li>
<li>This creates a <strong>national proletariat</strong> with no stability, unable to plan for the future.</li>
</ul></li>
<li><strong>Lean production</strong>, another harmful idea stemming from this system, further dehumanizes workers.
<ul>
<li><strong>Compassion</strong> is absent as companies prioritize squeezing maximum output from a bare-bones workforce.</li>
</ul></li>
<li>This reorganization of work has led to the widening <strong>gap between the rich and poor</strong> in America.
<ul>
<li>The middle class is eroding, the working class is suffering, and the safety net for the poor is gone.</li>
</ul></li>
<li>Gatto believes that <strong>political action</strong>, not education, is the only way to combat these systemic issues.</li>
</ul>
</section>
<section id="the-new-atlantis" class="level3">
<h3 class="anchored" data-anchor-id="the-new-atlantis">The New Atlantis</h3>
<ul>
<li>Gatto argues that modern colleges have become training grounds for corporate and government work, rather than places of true learning.
<ul>
<li>He believes this transformation began after World War II and was influenced by Francis Bacon’s utopian work, <em>The New Atlantis</em>.</li>
</ul></li>
<li>According to Gatto, Bacon’s vision of a world university promotes social control and reinforces existing power structures.
<ul>
<li>He argues that this model has led to increased surveillance, the suppression of dissent, and the erosion of traditional values.</li>
</ul></li>
<li>Gatto criticizes the “lean production” model of modern workplaces, which he believes prioritizes efficiency over compassion and has contributed to the growing gap between the rich and the poor.</li>
<li>He concludes by emphasizing the need for political action to address the social and economic problems facing the United States.
<ul>
<li>He believes that education alone is not enough to solve these problems and that systemic change is necessary.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-10-incident-at-highland-high" class="level2">
<h2 class="anchored" data-anchor-id="chapter-10-incident-at-highland-high">Chapter 10: Incident at Highland High</h2>
<section id="the-illusion-of-education" class="level3">
<h3 class="anchored" data-anchor-id="the-illusion-of-education">The Illusion of Education</h3>
<ul>
<li>Gatto reflects on the concept of pedagogy and its influence on his life, suggesting that it has turned individuals into characters in someone else’s script.</li>
<li>He urges readers to question their own schooling experiences and the price paid for them.</li>
<li>Gatto argues that schooling creates illusions of education and its influence continues long after formal education ends.</li>
</ul>
</section>
<section id="schooling-vs.-education-a-critical-examination" class="level3">
<h3 class="anchored" data-anchor-id="schooling-vs.-education-a-critical-examination">Schooling vs.&nbsp;Education: A Critical Examination</h3>
<ul>
<li>Schooling, once a limited activity in colonial America, has become an increasingly pervasive force in modern society.</li>
<li>Gatto criticizes the notion of “lifelong learning” as “lifelong schooling,” arguing that more schooling is not the solution to societal problems.</li>
<li>He contends that schooling undermines alternative avenues of development, such as family, church, tradition, and individual sovereignty.</li>
<li>Gatto emphasizes the importance of distinguishing between schooling and education, providing a framework for understanding their fundamental differences.</li>
</ul>
<section id="key-distinctions" class="level4">
<h4 class="anchored" data-anchor-id="key-distinctions">Key Distinctions</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 41%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Schooling</th>
<th>Education</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Organization</strong></td>
<td>Command and control from external authorities</td>
<td>Self-organized from within the individual</td>
</tr>
<tr class="even">
<td><strong>Learning Sources</strong></td>
<td>Disconnects individuals from other primary sources of learning for administrative efficiency</td>
<td>Provides diverse and interconnected learning opportunities</td>
</tr>
<tr class="odd">
<td><strong>Nature of Learning</strong></td>
<td>Emphasizes rules and conformity</td>
<td>Values resourcefulness, self-sufficiency, and invention through unpredictable experiences</td>
</tr>
<tr class="even">
<td><strong>Feedback Mechanisms</strong></td>
<td>Relies on external rules and directions</td>
<td>Cultivates internal feedback loops for self-correction and independence</td>
</tr>
<tr class="odd">
<td><strong>Focus</strong></td>
<td>Prioritizes subject knowledge and specialization</td>
<td>Embraces broad contexts and interdisciplinary thinking</td>
</tr>
<tr class="even">
<td><strong>Outcomes</strong></td>
<td>Aims to produce clerks and specialists</td>
<td>Fosters critical thinking, intellectual curiosity, and a spirit of inquiry</td>
</tr>
<tr class="odd">
<td><strong>Role of Memory</strong></td>
<td>Dominant element, often hindering independent thought</td>
<td>Less emphasis on memorization, prioritizing synthesis and argumentation</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="the-dark-side-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-dark-side-of-schooling">The Dark Side of Schooling</h3>
<ul>
<li>Gatto argues that schooling can have detrimental effects on individuals and society.</li>
<li>He cites the International Happiness Survey, which identifies good relationships, health, and satisfying work as essential for happiness.</li>
<li>Schooling, he contends, often undermines these factors by:
<ul>
<li>Creating environments that hinder the development of healthy habits.</li>
<li>Limiting opportunities for meaningful relationships.</li>
<li>Perpetuating class prejudice through tracking systems.</li>
<li>Failing to engage students with their own compelling questions.</li>
</ul></li>
</ul>
</section>
<section id="unmasking-the-hidden-agenda" class="level3">
<h3 class="anchored" data-anchor-id="unmasking-the-hidden-agenda">Unmasking the Hidden Agenda</h3>
<ul>
<li>Gatto challenges readers to consider whether the shortcomings of schooling are merely accidental or the result of a deliberate, hidden agenda.</li>
<li>He proposes that a “dark matter,” a powerful but invisible force, is at work within the institution of schooling.</li>
<li>He suggests that true school reform is impossible without exposing and dismantling this hidden agenda, which operates beyond public scrutiny.</li>
<li>Gatto concludes by urging readers to investigate these issues themselves, emphasizing that they must reach their own conclusions to protect themselves and their families.</li>
</ul>
</section>
<section id="a-call-to-action" class="level3">
<h3 class="anchored" data-anchor-id="a-call-to-action">A Call to Action</h3>
<ul>
<li>Gatto’s analysis of schooling serves as a call to action for readers to:
<ul>
<li>Critically examine their own experiences with schooling.</li>
<li>Recognize the limitations and potential harms of traditional education systems.</li>
<li>Seek alternative paths to learning and personal growth.</li>
<li>Challenge the status quo and advocate for meaningful education reform.</li>
</ul></li>
</ul>
</section>
<section id="incident-at-nuremberg" class="level3">
<h3 class="anchored" data-anchor-id="incident-at-nuremberg">Incident at Nuremberg</h3>
<ul>
<li><strong>Date:</strong> January 29, 2008</li>
<li><strong>Location:</strong> Nuremberg, Germany</li>
<li><strong>Incident:</strong> 16-year-old Melissa Busekros was forcibly removed from her home by 15 police officers and city officials.
<ul>
<li><strong>Her crime:</strong> homeschooling.</li>
<li>Melissa was placed under psychiatric investigation.</li>
</ul></li>
<li><strong>Author’s Response and Historical Context:</strong>
<ul>
<li>Gatto, upon hearing of the incident, wrote to the German ambassador in Washington expressing his disgust and inquiring why Germany still enforces a homeschooling ban enacted by the Nazi government in 1937.</li>
<li>Gatto highlights the irony of Germany’s stance, given that 2.5 to 3 million American students are homeschooled, including prominent figures like the head of the Human Genome Project.</li>
</ul></li>
<li><strong>Court Order and Interrogation:</strong>
<ul>
<li>Gatto criticizes the court order authorizing Melissa’s apprehension, which allowed the use of force and deemed police intervention necessary despite no history suggesting such measures were warranted.</li>
<li>Melissa endured a 240-minute interrogation at a psychiatric clinic, focusing on her reasons for homeschooling.</li>
<li>The interrogation concluded that Melissa suffered from “school phobia,” a diagnosis Gatto deems pseudoscientific.</li>
</ul></li>
<li><strong>Justification for Intervention:</strong>
<ul>
<li>Based on the “school phobia” diagnosis, authorities declared an emergency, claiming Melissa’s development was delayed by a year and that immediate separation from her family was necessary.</li>
<li>Gatto questions the reasoning, philosophy, and values behind this action, deeming it illogical and extreme.</li>
</ul></li>
<li><strong>Police Raid and Official Statements:</strong>
<ul>
<li>Two days after the interrogation, 15 police officers, accompanied by a judge and state youth staff, raided the Busekros home.</li>
<li>Gatto sarcastically questions whether media reporters were present to document the event.</li>
<li>The court absolved Gattoities of responsibility, attributing the forced escort to the parents’ “illegal conduct” of homeschooling.</li>
<li>The German Education Authority stated it would not recognize homeschooling and would act “proportionately” to enforce this stance.</li>
</ul></li>
<li><strong>Author’s Concerns and Historical Parallels:</strong>
<ul>
<li>Gatto criticizes the excessive police presence as disproportionate to the situation.</li>
<li>He expresses concern over the Education Authority’s statement about bringing the family’s “convictions” in line, drawing parallels to Germany’s dark history of persecution during the witch hunts and Nazi era.</li>
<li>Gatto, with German ancestry, expresses alarm at what he perceives as a resurgence of “German madness” symbolized by the treatment of Melissa.</li>
</ul></li>
</ul>
</section>
<section id="systemic-issues-in-german-education" class="level3">
<h3 class="anchored" data-anchor-id="systemic-issues-in-german-education">Systemic Issues in German Education</h3>
<ul>
<li><strong>Influence of Compulsory Schooling:</strong>
<ul>
<li>Gatto cites prominent Germans like Erich Maria Remarque and Dietrich Bonhoeffer, who attributed Germany’s history of war and violence to its education system.</li>
<li>He argues that Germany’s obsession with system and order, stemming from compulsory schooling, has created a culture of obedience and conformity at the expense of individual liberty and creativity.</li>
</ul></li>
<li><strong>Economic Consequences:</strong>
<ul>
<li>Gatto contends that Germany’s rigid education system stifles innovation and economic competitiveness, citing the example of ThyssenKrupp’s Phoenix steel plant debacle.</li>
<li>He contrasts this with the flexibility and resourcefulness of Chinese workers, many of whom were homeschooled, who efficiently relocated and revitalized the Phoenix plant.</li>
</ul></li>
<li><strong>Lack of Response and Author’s Conclusion:</strong>
<ul>
<li>Gatto reveals he received no response to his letter from the German ambassador.</li>
<li>He concludes that the incident exposes a bureaucratic mindset unable to address legitimate concerns about individual rights and educational freedom.</li>
</ul></li>
</ul>
</section>
<section id="incident-at-highland-high" class="level3">
<h3 class="anchored" data-anchor-id="incident-at-highland-high">Incident at Highland High</h3>
<ul>
<li><strong>Date:</strong> March 25, 2004</li>
<li><strong>Location:</strong> Highland High School in Rockland County, New York</li>
<li><strong>Incident:</strong> Gatto was invited to speak at Highland High but his talk was interrupted by police, called by the superintendent, who deemed it inflammatory.</li>
<li><strong>Invitation to Speak:</strong>
<ul>
<li>Gatto was invited to speak by school board member John Jankowicz.</li>
<li>Jankowicz, concerned about the negative effects of the school’s “Germanized” education system, sought Gatto’s perspective.</li>
</ul></li>
<li><strong>Observations of Highland High:</strong>
<ul>
<li>Arriving early, Gatto observed an atmosphere of affluence and self-satisfaction among the students, reminding him of another wealthy school he had visited.</li>
<li>He noted that beneath the surface of privilege, students were subject to intense pressure and anxiety regarding college admissions, perpetuating a culture of dishonesty and fear.</li>
</ul></li>
<li><strong>Challenging the School-to-College Pipeline:</strong>
<ul>
<li>Gatto decided to address the students’ anxieties by exposing the reality of college admissions, challenging the school’s narrative about the importance of grades and test scores.</li>
<li>He highlighted the success of numerous high-profile individuals who achieved success without conforming to the traditional educational path.</li>
<li>He cited examples from the computer industry, literature, entertainment, and politics, demonstrating that dropouts and mediocre students often thrive.</li>
</ul></li>
<li><strong>Exposing the Education System’s Hypocrisy:</strong>
<ul>
<li>Gatto presented data from The New York Times showing that educators themselves often scored poorly on standardized tests, with superintendents faring the worst.</li>
<li>He encouraged students to demand transparency from school officials, urging them to post their own grade and test records publicly.</li>
</ul></li>
<li><strong>Revealing the Truth about College Admissions:</strong>
<ul>
<li>Gatto shared insights into the admissions policies of prestigious universities like Harvard, Stanford, and Yale, emphasizing that they prioritize applicants with unique experiences and accomplishments over perfect grades and test scores.</li>
<li>He encouraged students to pursue their passions and create their own paths to success, citing the example of high school dropout Richard Branson.</li>
</ul></li>
<li><strong>Student Response and Police Intervention:</strong>
<ul>
<li>The students responded positively to Gatto’s message, engaging with the information and questioning their assumptions about education.</li>
<li>However, the assembly was abruptly interrupted by a police detail who entered the auditorium and ordered everyone to leave.</li>
</ul></li>
<li><strong>Confrontation and Censorship:</strong>
<ul>
<li>The officer in charge approached Gatto and demanded he leave the room, ending the lecture.</li>
<li>Gatto complied, sensing the threat of arrest if he disobeyed.</li>
<li>It was later revealed that Superintendent McCarthy had called the police, deeming Gatto’s talk “inflammatory.”</li>
</ul></li>
<li><strong>Aftermath and Reflections:</strong>
<ul>
<li>Gatto emphasizes that his presentation was calm and factual, devoid of any provocative language or behavior.</li>
<li>He draws parallels between the censorship he experienced at Highland High and the suppression of homeschooling in Germany, highlighting a pattern of intolerance towards alternative educational perspectives.</li>
</ul></li>
</ul>
</section>
<section id="incident-at-walden" class="level3">
<h3 class="anchored" data-anchor-id="incident-at-walden">Incident at Walden</h3>
<ul>
<li><strong>Date:</strong> April 1991</li>
<li><strong>Location:</strong> Walden, Vermont</li>
<li><strong>Incident:</strong> The state of Vermont forced the closure of four one-room schoolhouses despite local opposition.</li>
<li><strong>The One-Room Schools of Walden, Vermont:</strong>
<ul>
<li>Until 1991, Walden, Vermont, had four one-room schoolhouses known for their idyllic setting, happy students, and above-average academic performance.</li>
<li>The community cherished these schools and actively supported them.</li>
</ul></li>
<li><strong>Threat of Closure and State Intervention:</strong>
<ul>
<li>The state of Vermont threatened to close the one-room schools, claiming that bringing them up to code with federal disability access requirements was too expensive.</li>
<li>A plan was proposed to build a centralized regional school and bus students from a wide radius.</li>
</ul></li>
<li><strong>Exposing Inflated Costs and Local Corruption:</strong>
<ul>
<li>Gatto, upon reviewing the state’s proposal, found the estimated costs for renovating the one-room schools to be exorbitantly high.</li>
<li>He consulted with a renowned architect who confirmed that the estimates were ten times higher than the actual cost, suggesting a deliberate attempt to inflate the figures.</li>
<li>The architect revealed that the contract for the new regional school had likely already been promised to a specific firm, highlighting a corrupt system.</li>
</ul></li>
<li><strong>Fear and Resignation:</strong>
<ul>
<li>Despite Gatto’s efforts to expose the truth and rally support for the one-room schools, the community, worn down by the state’s threats and fearing the loss of funding, ultimately voted to approve the bond issue for the new school.</li>
</ul></li>
<li><strong>Loss of Unique Educational Opportunities:</strong>
<ul>
<li>Gatto laments the closure of the one-room schools, viewing it as a loss of a valuable and effective educational model.</li>
<li>He criticizes the state’s actions, suggesting that they were driven by ulterior motives and a disregard for the community’s wishes.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-a-call-to-action-1" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-a-call-to-action-1">Conclusion: A Call to Action</h3>
<ul>
<li><strong>Recognizing the Dark Side of Education:</strong>
<ul>
<li>Gatto urges readers to acknowledge the existence of a “dark world” within the education system, where decisions are made that defy logic, common sense, and the best interests of students.</li>
</ul></li>
<li><strong>Challenging the Status Quo:</strong>
<ul>
<li>He calls for a reevaluation of the current education system, questioning its effectiveness and its impact on individual freedom and creativity.</li>
</ul></li>
<li><strong>Empowering Individuals and Communities:</strong>
<ul>
<li>Gatto encourages individuals and communities to take a more active role in shaping education, advocating for alternatives that better serve the needs of students and society as a whole.</li>
</ul></li>
</ul>
</section>
</section>
<section id="afterword-invitation-to-an-open-conspiracy" class="level2">
<h2 class="anchored" data-anchor-id="afterword-invitation-to-an-open-conspiracy">Afterword: Invitation to an Open Conspiracy</h2>
<section id="invitation-to-an-open-conspiracy" class="level3">
<h3 class="anchored" data-anchor-id="invitation-to-an-open-conspiracy">Invitation to an Open Conspiracy</h3>
<ul>
<li>This is an invitation to join an open conspiracy to destroy the standardized testing industry.</li>
<li>The goal is to inflict real consequences on the industry and liberate millions of lives.</li>
<li>This is not about test reform; it’s about test destruction.</li>
</ul>
<section id="the-problem-with-standardized-testing" class="level4">
<h4 class="anchored" data-anchor-id="the-problem-with-standardized-testing">The Problem with Standardized Testing</h4>
<ul>
<li>Standardized tests are misleading and unreliable.
<ul>
<li>The data they generate is never used.</li>
<li>Those who test well are not necessarily successful in life.</li>
</ul></li>
<li>They cause significant personal and social damage.
<ul>
<li>They rank students and create a false sense of worth.</li>
<li>They are a tool of social control, designed to maintain the status quo.</li>
</ul></li>
<li>They are a waste of time and resources.
<ul>
<li>Hundreds of millions of school days are wasted on testing.</li>
<li>Tens of billions of dollars are diverted from productive pursuits.</li>
</ul></li>
<li>They stifle imagination and intellect.
<ul>
<li>They prioritize rote memorization over critical thinking.</li>
<li>They limit student potential and harm national wealth.</li>
</ul></li>
</ul>
</section>
<section id="the-outlaw-ethic-of-institutional-schooling" class="level4">
<h4 class="anchored" data-anchor-id="the-outlaw-ethic-of-institutional-schooling">The Outlaw Ethic of Institutional Schooling</h4>
<ul>
<li>The New York Sun reported on May 8, 2008, that only 1 in 25 students received the legally mandated 24 minutes of physical education per day.</li>
<li>This demonstrates an outlaw ethic within institutional schooling, where laws are broken with impunity.</li>
<li>Schools prioritize their own interests over the well-being of students.</li>
<li>This ethic is masked by the mundane nature of schooling, but it is a dangerous reality.</li>
</ul>
</section>
<section id="the-decline-of-american-education" class="level4">
<h4 class="anchored" data-anchor-id="the-decline-of-american-education">The Decline of American Education</h4>
<ul>
<li>Following World War II, American education underwent a significant decline.
<ul>
<li>Schools were standardized and curriculum was dumbed down.</li>
<li>Teachers became increasingly detached from the communities they served.</li>
<li>A belief emerged that most of the population was intellectually inferior.</li>
</ul></li>
<li>This decline was driven by a desire for social control and a disregard for the potential of ordinary people.</li>
</ul>
</section>
<section id="the-power-of-free-will-the-bartleby-solution" class="level4">
<h4 class="anchored" data-anchor-id="the-power-of-free-will-the-bartleby-solution">The Power of Free Will: The Bartleby Solution</h4>
<ul>
<li>Herman Melville’s short story “Bartleby the Scrivener” offers a solution to the problem of standardized testing.</li>
<li>Bartleby, a copyist, exercises his free will by simply saying “I would prefer not to” when asked to perform tasks.</li>
<li>This simple act of defiance disrupts the machinery of the workplace.</li>
<li>Similarly, students can disrupt the machinery of standardized testing by refusing to participate.</li>
</ul>
</section>
</section>
<section id="the-bartleby-project" class="level3">
<h3 class="anchored" data-anchor-id="the-bartleby-project">The Bartleby Project</h3>
<ul>
<li>The Bartleby Project invites students to refuse to take standardized tests.</li>
<li>This act of peaceful resistance will expose the absurdity and harm of standardized testing.</li>
<li>It will force a national conversation about the true purpose of education.</li>
</ul>
<section id="how-to-participate" class="level4">
<h4 class="anchored" data-anchor-id="how-to-participate">How to Participate</h4>
<ul>
<li>Write “I would prefer not to take this test” on the test form.</li>
<li>Do not engage in demonstrations or adversarial politics.</li>
<li>Remain peaceful and resolute in your refusal.</li>
</ul>
</section>
<section id="anticipated-challenges-and-responses" class="level4">
<h4 class="anchored" data-anchor-id="anticipated-challenges-and-responses">Anticipated Challenges and Responses</h4>
<ul>
<li>Intimidation and threats of retribution: These are empty threats designed to maintain control.</li>
<li>Denial of college admission: Colleges are businesses that need students; they will adapt.</li>
<li>Calls for compromise: Reject all compromises; the goal is complete elimination of standardized testing.</li>
</ul>
</section>
<section id="the-importance-of-decentralization" class="level4">
<h4 class="anchored" data-anchor-id="the-importance-of-decentralization">The Importance of Decentralization</h4>
<ul>
<li>The Bartleby Project must remain decentralized to avoid co-option and corruption.</li>
<li>No single leader or organization should control the movement.</li>
<li>Local groups should act independently, guided by the shared principle of refusing to participate in standardized testing.</li>
</ul>
</section>
</section>
<section id="conclusion-3" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-3">Conclusion</h3>
<ul>
<li>The Bartleby Project is a call to action for students to reclaim their education.</li>
<li>By peacefully refusing to participate in standardized testing, students can dismantle this harmful system.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>education</category>
  <category>history</category>
  <guid>https://christianjmills.com/posts/weapons-of-mass-instruction-book-notes/</guid>
  <pubDate>Sun, 25 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 15: Modal - Simple Scalable Serverless Services</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li><strong>Speaker:</strong> Charles (<a href="https://twitter.com/charles_irl"><span class="citation" data-cites="charles_irl">@charles_irl</span></a> on Twitter)</li>
<li><strong>Topic:</strong> A deeper dive into Modal, focusing on its broader applications beyond fine-tuning LLMs.</li>
<li><strong>Slides:</strong> <a href="https://docs.google.com/presentation/d/14uDnzd06j9i0zAQ3lTmB7QHBSO45BIsVGUZBZ3HKxGo/edit#slide=id.g2c7588f453b_0_272">Simple Scalable Serverless Services</a></li>
</ul>
</section>
<section id="modal-overview" class="level2">
<h2 class="anchored" data-anchor-id="modal-overview">Modal Overview</h2>
<section id="modal-vision-scalable-cost-efficient-serverless-services" class="level3">
<h3 class="anchored" data-anchor-id="modal-vision-scalable-cost-efficient-serverless-services">Modal Vision: Scalable, Cost-Efficient, Serverless Services</h3>
<ul>
<li>Modal’s vision is to enable the deployment of scalable services that are cost-efficient and serverless, all while being simple and easy to use.</li>
</ul>
</section>
<section id="defining-scalable-services" class="level3">
<h3 class="anchored" data-anchor-id="defining-scalable-services">Defining “Scalable Services”</h3>
<section id="three-key-service-requirements-inputoutput-storage-compute" class="level4">
<h4 class="anchored" data-anchor-id="three-key-service-requirements-inputoutput-storage-compute">Three Key Service Requirements: Input/Output, Storage, Compute</h4>
<ol type="1">
<li><strong>Input/Output:</strong> Connecting the service to the outside world and its information.
<ul>
<li>This enables services to receive input and provide output over networks, unlike isolated scripts or notebooks.</li>
</ul></li>
<li><strong>Storage:</strong> Preserving information for later use.
<ul>
<li>Databases and file storage are crucial for storing and retrieving data within the service.</li>
</ul></li>
<li><strong>Compute:</strong> Manipulating and processing information.
<ul>
<li>Even simple storage solutions benefit from compute capabilities for efficient access and retrieval.</li>
</ul></li>
</ol>
</section>
<section id="scalability-as-table-stakes" class="level4">
<h4 class="anchored" data-anchor-id="scalability-as-table-stakes">Scalability as Table Stakes</h4>
<ul>
<li>Modern services are expected to scale to handle:
<ul>
<li>Global user bases accessing services concurrently.</li>
<li>Massive data storage needs, potentially reaching petabytes or more.</li>
<li>Computationally intensive tasks distributed across multiple machines.</li>
</ul></li>
</ul>
</section>
<section id="challenges-and-importance-of-scalability" class="level4">
<h4 class="anchored" data-anchor-id="challenges-and-importance-of-scalability">Challenges and Importance of Scalability</h4>
<ul>
<li>Failing to scale can lead to:
<ul>
<li>Service outages when traffic surges.</li>
<li>Poor user experiences due to slow response times.</li>
</ul></li>
</ul>
</section>
<section id="distributed-systems-for-scalability" class="level4">
<h4 class="anchored" data-anchor-id="distributed-systems-for-scalability">Distributed Systems for Scalability</h4>
<ul>
<li>Scalability is typically achieved through distributed systems, spreading the workload across numerous machines and data centers.</li>
<li>However, building and managing distributed systems is complex and challenging.</li>
</ul>
</section>
</section>
<section id="modals-solution-simple-scalable-services-with-python" class="level3">
<h3 class="anchored" data-anchor-id="modals-solution-simple-scalable-services-with-python">Modal’s Solution: Simple Scalable Services with Python</h3>
<ul>
<li>Modal aims to simplify the creation of scalable services using Python.</li>
</ul>
<section id="pythonic-tools-for-building-services" class="level4">
<h4 class="anchored" data-anchor-id="pythonic-tools-for-building-services">Pythonic Tools for Building Services</h4>
<ul>
<li><strong>Web Endpoints and Servers:</strong> Easily define web endpoints and servers that scale without complex configurations.
<ul>
<li>Modal handles the complexities of distribution and scaling, requiring minimal configuration from the developer.</li>
</ul></li>
<li><strong>Storage Options:</strong>
<ul>
<li><strong>Caching and Distributed Storage:</strong> Modal provides distributed dictionaries and queues for efficient inter-process communication in scaled environments.</li>
<li><strong>Volumes:</strong> Abstract away the complexities of distributed file systems, offering a local file system interface for storing data like weights and datasets.</li>
</ul></li>
<li><strong>Compute with Python Functions:</strong> Python functions serve as the fundamental units of work in Modal.
<ul>
<li>Define functions that execute upon endpoint requests or as cron jobs.</li>
</ul></li>
</ul>
</section>
</section>
<section id="modal-dashboard-overview" class="level3">
<h3 class="anchored" data-anchor-id="modal-dashboard-overview">Modal Dashboard Overview</h3>
<section id="model-inference-function-example" class="level4">
<h4 class="anchored" data-anchor-id="model-inference-function-example">Model Inference Function Example</h4>
<ul>
<li>Modal’s dashboard visualizes resource usage for running functions.</li>
<li>Example: A model inference function triggered by user requests, scaling resources like CPU, memory, and GPU usage based on demand.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/images/model-inference-function-example.png" class="img-fluid figure-img"></p>
<figcaption>Model Inference Function Example</figcaption>
</figure>
</div>
</section>
<section id="scaling-up-and-down-resources" class="level4">
<h4 class="anchored" data-anchor-id="scaling-up-and-down-resources">Scaling Up and Down Resources</h4>
<ul>
<li>Modal dynamically adjusts resource allocation based on real-time needs, ensuring optimal performance and cost efficiency.</li>
</ul>
</section>
<section id="handling-multiple-inputs" class="level4">
<h4 class="anchored" data-anchor-id="handling-multiple-inputs">Handling Multiple Inputs</h4>
<ul>
<li>Functions can be designed to handle multiple inputs concurrently, maximizing resource utilization.</li>
</ul>
</section>
<section id="cron-jobs-with-modal" class="level4">
<h4 class="anchored" data-anchor-id="cron-jobs-with-modal">Cron Jobs with Modal</h4>
<ul>
<li>Schedule periodic function execution for tasks like:
<ul>
<li>Regularly displaying generated content.</li>
<li>Pulling data from production databases to data warehouses.</li>
<li>Performing regular data analysis.</li>
<li>Fine-tuning and retraining models on a cadence.</li>
<li>Rerunning evaluations with live user data.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/images/cron-jobs-with-modal.png" class="img-fluid figure-img"></p>
<figcaption>Cron Jobs with Modal</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="qa-session-1" class="level2">
<h2 class="anchored" data-anchor-id="qa-session-1">Q&amp;A Session 1</h2>
<section id="database-service-availability" class="level4">
<h4 class="anchored" data-anchor-id="database-service-availability">Database Service Availability</h4>
<ul>
<li>Modal does not currently offer a managed database service, particularly serverless Postgres.</li>
</ul>
</section>
<section id="challenges-of-serverless-postgres" class="level4">
<h4 class="anchored" data-anchor-id="challenges-of-serverless-postgres">Challenges of Serverless Postgres</h4>
<ul>
<li>Two main types of databases:
<ul>
<li><strong>OLTP (Online Transaction Processing):</strong> Difficult to scale due to row-level operations and complex joins.</li>
<li><strong>OLAP (Online Analytical Processing):</strong> More straightforward to run on Modal using examples with tools like DuckDB and parquet files stored in S3.</li>
</ul></li>
</ul>
</section>
<section id="running-analytical-workloads-on-modal" class="level4">
<h4 class="anchored" data-anchor-id="running-analytical-workloads-on-modal">Running Analytical Workloads on Modal</h4>
<ul>
<li>Modal provides examples for running analytical workloads:
<ul>
<li>Downloading parquet files from S3.</li>
<li>Performing analysis using tools like DuckDB.</li>
</ul></li>
</ul>
</section>
<section id="challenges-of-scaling-transaction-processing" class="level4">
<h4 class="anchored" data-anchor-id="challenges-of-scaling-transaction-processing">Challenges of Scaling Transaction Processing</h4>
<ul>
<li>Distributed transaction processing databases are more challenging to build and scale effectively.</li>
</ul>
</section>
<section id="recommendations-for-serverless-postgres-neon-superbase" class="level4">
<h4 class="anchored" data-anchor-id="recommendations-for-serverless-postgres-neon-superbase">Recommendations for Serverless Postgres: Neon, Superbase</h4>
<ul>
<li>For serverless Postgres, Modal recommends using external services like <a href="https://neon.tech/">Neon</a> or <a href="https://www.superbase.com/">Superbase</a>, which integrate well with Modal’s serverless API apps.</li>
</ul>
</section>
</section>
<section id="storage-in-modal" class="level2">
<h2 class="anchored" data-anchor-id="storage-in-modal">Storage in Modal</h2>
<section id="importance-of-data-storage" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-data-storage">Importance of Data Storage</h3>
<ul>
<li>Data storage is paramount, often defining the value of applications.</li>
</ul>
</section>
<section id="focus-on-long-term-storage" class="level3">
<h3 class="anchored" data-anchor-id="focus-on-long-term-storage">Focus on Long-Term Storage</h3>
<ul>
<li>This section emphasizes long-term storage solutions rather than in-memory dictionaries and queues.</li>
</ul>
</section>
<section id="file-system-abstractions-volumes" class="level3">
<h3 class="anchored" data-anchor-id="file-system-abstractions-volumes">File System Abstractions: Volumes</h3>
<section id="use-cases-storing-weights-datasets" class="level4">
<h4 class="anchored" data-anchor-id="use-cases-storing-weights-datasets">Use Cases: Storing Weights, Datasets</h4>
<ul>
<li>Volumes provide a distributed file system abstraction, ideal for storing:
<ul>
<li>Model weights.</li>
<li>Datasets, including large ones (terabyte-scale or even low petabyte-scale).</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/images/storage-volume.png" class="img-fluid figure-img"></p>
<figcaption>Storage Volume</figcaption>
</figure>
</div>
</section>
<section id="examples-of-stored-volumes" class="level4">
<h4 class="anchored" data-anchor-id="examples-of-stored-volumes">Examples of Stored Volumes</h4>
<ul>
<li>Model weights from Axolotl fine-tuning runs.</li>
<li>CIFAR-10 data and models.</li>
<li>Raw Wikipedia dataset from Hugging Face Datasets in Arrow file format.</li>
</ul>
</section>
<section id="handling-large-datasets" class="level4">
<h4 class="anchored" data-anchor-id="handling-large-datasets">Handling Large Datasets</h4>
<ul>
<li>Modal offers examples for storing and working with very large datasets on the order of terabytes or even low petabytes.</li>
</ul>
</section>
<section id="volumes-optimized-for-write-once-read-many-workloads" class="level4">
<h4 class="anchored" data-anchor-id="volumes-optimized-for-write-once-read-many-workloads">Volumes: Optimized for Write Once, Read Many Workloads</h4>
<ul>
<li>Modal’s volumes are designed for workloads where data is written infrequently but read frequently.</li>
<li>This design choice optimizes for:
<ul>
<li>Datasets that are not frequently overwritten.</li>
<li>Model weights where new versions are written, but existing versions are not modified.</li>
</ul></li>
</ul>
<section id="explanation-of-write-once-read-many" class="level5">
<h5 class="anchored" data-anchor-id="explanation-of-write-once-read-many">Explanation of Write Once, Read Many</h5>
<ul>
<li>Data is written once and then read many times, common for datasets and model weights.</li>
</ul>
</section>
<section id="benefits-for-scaling" class="level5">
<h5 class="anchored" data-anchor-id="benefits-for-scaling">Benefits for Scaling</h5>
<ul>
<li>Scaling read operations is significantly easier than scaling write operations, making volumes well-suited for read-heavy workloads.</li>
</ul>
</section>
</section>
</section>
</section>
<section id="qa-session-2" class="level2">
<h2 class="anchored" data-anchor-id="qa-session-2">Q&amp;A Session 2</h2>
<section id="storage-pricing" class="level4">
<h4 class="anchored" data-anchor-id="storage-pricing">Storage Pricing</h4>
<ul>
<li>While Modal does not currently charge for storage, it plans to implement pricing eventually.</li>
<li>The goal is to price storage at a rate comparable to S3, Modal’s underlying storage provider.</li>
</ul>
</section>
<section id="addressing-other-storage-related-questions" class="level4">
<h4 class="anchored" data-anchor-id="addressing-other-storage-related-questions">Addressing Other Storage-Related Questions</h4>
<ul>
<li><strong>Petabyte-Sized Datasets and S3:</strong> Very large datasets may be stored directly on S3 rather than Modal’s volumes.</li>
<li><strong>Data Transport Costs:</strong> Modal does not currently charge for data ingress or egress, but may implement pricing if it becomes a significant cost.</li>
<li><strong>Explanation of Mounts:</strong> Mounts make data from the local machine available to code running on Modal. This is useful for:
<ul>
<li>Accessing code files.</li>
<li>Including assets for static sites.</li>
</ul></li>
</ul>
</section>
</section>
<section id="input-and-output-in-modal" class="level2">
<h2 class="anchored" data-anchor-id="input-and-output-in-modal">Input and Output in Modal</h2>
<section id="fastapi-integration" class="level3">
<h3 class="anchored" data-anchor-id="fastapi-integration">FastAPI Integration</h3>
<section id="benefits-of-using-fastapi-with-modal" class="level4">
<h4 class="anchored" data-anchor-id="benefits-of-using-fastapi-with-modal">Benefits of Using FastAPI with Modal</h4>
<ul>
<li>Asynchronous Python: FastAPI enables asynchronous programming without the complexities of manually managing asynchronous operations.</li>
<li>Documentation: FastAPI provides excellent documentation.</li>
<li>Scalability: Asynchronous programming in FastAPI aligns well with Modal’s scaling capabilities.</li>
<li>Performance: Asynchronous operations can improve performance, especially with Modal’s distributed architecture.</li>
</ul>
<section id="asynchronous-python-documentation-scalability-performance" class="level5">
<h5 class="anchored" data-anchor-id="asynchronous-python-documentation-scalability-performance">Asynchronous Python, Documentation, Scalability, Performance</h5>
<ul>
<li>FastAPI simplifies asynchronous programming and offers performance benefits when used with Modal.</li>
</ul>
</section>
<section id="modals-handling-of-synchronous-and-asynchronous-functions" class="level5">
<h5 class="anchored" data-anchor-id="modals-handling-of-synchronous-and-asynchronous-functions">Modal’s Handling of Synchronous and Asynchronous Functions</h5>
<ul>
<li>Modal seamlessly handles both synchronous and asynchronous functions, avoiding common errors associated with mixing the two.</li>
</ul>
</section>
<section id="flexibility-and-performance-with-async" class="level5">
<h5 class="anchored" data-anchor-id="flexibility-and-performance-with-async">Flexibility and Performance with Async</h5>
<ul>
<li>Developers can gradually introduce asynchronous code into their Modal projects without major refactoring.</li>
</ul>
</section>
</section>
<section id="web-endpoints-for-exposing-services" class="level4">
<h4 class="anchored" data-anchor-id="web-endpoints-for-exposing-services">Web Endpoints for Exposing Services</h4>
<ul>
<li>FastAPI, based on the ASGI protocol, offers a robust way to define and expose web services.</li>
</ul>
<section id="fastapi-as-a-dependency" class="level5">
<h5 class="anchored" data-anchor-id="fastapi-as-a-dependency">FastAPI as a Dependency</h5>
<ul>
<li>FastAPI is a dependency of Modal, simplifying project setup and dependency management.</li>
</ul>
</section>
<section id="creating-urls-from-python-functions" class="level5">
<h5 class="anchored" data-anchor-id="creating-urls-from-python-functions">Creating URLs from Python Functions</h5>
<ul>
<li>Modal can automatically create URLs from Python functions, simplifying web service creation.</li>
</ul>
</section>
</section>
<section id="asynchronous-server-gateway-interface-asgi" class="level4">
<h4 class="anchored" data-anchor-id="asynchronous-server-gateway-interface-asgi">Asynchronous Server Gateway Interface (ASGI)</h4>
<section id="flexibility-beyond-fastapi" class="level5">
<h5 class="anchored" data-anchor-id="flexibility-beyond-fastapi">Flexibility Beyond FastAPI</h5>
<ul>
<li>Modal supports any ASGI-compliant web framework, providing flexibility beyond FastAPI.</li>
</ul>
</section>
</section>
<section id="wsgi-and-flask-support" class="level4">
<h4 class="anchored" data-anchor-id="wsgi-and-flask-support">WSGI and Flask Support</h4>
<section id="comparison-of-wsgi-and-asgi" class="level5">
<h5 class="anchored" data-anchor-id="comparison-of-wsgi-and-asgi">Comparison of WSGI and ASGI</h5>
<ul>
<li>Modal also supports WSGI (Web Server Gateway Interface), an older protocol commonly used with frameworks like Flask.</li>
<li>While WSGI offers a mature ecosystem, it lacks native asynchronous support, potentially impacting performance compared to ASGI.</li>
</ul>
</section>
<section id="potential-trade-offs-with-wsgi" class="level5">
<h5 class="anchored" data-anchor-id="potential-trade-offs-with-wsgi">Potential Trade-offs with WSGI</h5>
<ul>
<li>WSGI may provide a wider range of existing projects and libraries but might lack the performance advantages of ASGI.</li>
</ul>
</section>
</section>
<section id="running-arbitrary-web-servers" class="level4">
<h4 class="anchored" data-anchor-id="running-arbitrary-web-servers">Running Arbitrary Web Servers</h4>
<ul>
<li>Modal allows running arbitrary web servers, even those not written in Python, by treating them as subprocesses.</li>
</ul>
</section>
</section>
</section>
<section id="qa-session-3" class="level2">
<h2 class="anchored" data-anchor-id="qa-session-3">Q&amp;A Session 3</h2>
<section id="ddos-attack-prevention" class="level4">
<h4 class="anchored" data-anchor-id="ddos-attack-prevention">DDoS Attack Prevention</h4>
<ul>
<li>Modal does not currently have built-in DDoS protection but acknowledges its importance and plans to offer it in the future.</li>
</ul>
<section id="current-mitigation-strategies" class="level5">
<h5 class="anchored" data-anchor-id="current-mitigation-strategies">Current Mitigation Strategies</h5>
<ul>
<li>Developers can implement authentication middleware in FastAPI or Flask to restrict access.</li>
</ul>
</section>
<section id="importance-of-authentication-and-rate-limiting" class="level5">
<h5 class="anchored" data-anchor-id="importance-of-authentication-and-rate-limiting">Importance of Authentication and Rate Limiting</h5>
<ul>
<li>Authentication and rate limiting are crucial for preventing unauthorized access and mitigating DDoS attacks.</li>
</ul>
</section>
<section id="potential-for-cloudflare-ddos-protection" class="level5">
<h5 class="anchored" data-anchor-id="potential-for-cloudflare-ddos-protection">Potential for Cloudflare DDoS Protection</h5>
<ul>
<li>Integrating with services like Cloudflare for DDoS protection is worth exploring.</li>
</ul>
</section>
</section>
<section id="websockets-and-max-execution-time" class="level4">
<h4 class="anchored" data-anchor-id="websockets-and-max-execution-time">WebSockets and Max Execution Time</h4>
<ul>
<li>For questions related to WebSockets and maximum execution time, Modal recommends reaching out on their Slack channel for more specific guidance.</li>
</ul>
</section>
<section id="clarification-on-djangos-async-support" class="level4">
<h4 class="anchored" data-anchor-id="clarification-on-djangos-async-support">Clarification on Django’s Async Support</h4>
<ul>
<li>A participant clarifies that Django supports asynchronous views and requests when running under ASGI.</li>
</ul>
</section>
<section id="addressing-storage-related-questions" class="level4">
<h4 class="anchored" data-anchor-id="addressing-storage-related-questions">Addressing Storage-Related Questions</h4>
<ul>
<li>Modal reiterates its stance on storage pricing and data transport costs, aiming for transparency and aligning with S3’s pricing model.</li>
</ul>
</section>
</section>
<section id="serverless-nature-of-modal" class="level2">
<h2 class="anchored" data-anchor-id="serverless-nature-of-modal">Serverless Nature of Modal</h2>
<section id="importance-of-serverless-architecture" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-serverless-architecture">Importance of Serverless Architecture</h3>
<ul>
<li>Serverless architecture is a key aspect of Modal, contributing to its cost-efficiency and developer experience.</li>
</ul>
</section>
<section id="serverless-for-cost-efficiency-and-developer-experience" class="level3">
<h3 class="anchored" data-anchor-id="serverless-for-cost-efficiency-and-developer-experience">Serverless for Cost Efficiency and Developer Experience</h3>
<ul>
<li>Modal’s serverless nature offers both financial and ergonomic benefits for development teams.</li>
</ul>
</section>
<section id="variable-resource-utilization" class="level3">
<h3 class="anchored" data-anchor-id="variable-resource-utilization">Variable Resource Utilization</h3>
<ul>
<li>Service resource usage fluctuates over time due to factors like:
<ul>
<li>Time zone-dependent usage patterns.</li>
<li>Traffic spikes from external events.</li>
</ul></li>
</ul>
<section id="provisioning-for-peaks-and-cost-implications" class="level4">
<h4 class="anchored" data-anchor-id="provisioning-for-peaks-and-cost-implications">Provisioning for Peaks and Cost Implications</h4>
<ul>
<li>Traditional approaches involve provisioning resources for peak usage, leading to wasted resources and unnecessary costs during off-peak times.</li>
</ul>
</section>
<section id="resource-utilization-challenges" class="level4">
<h4 class="anchored" data-anchor-id="resource-utilization-challenges">Resource Utilization Challenges</h4>
<ul>
<li>Optimizing resource utilization becomes crucial to minimize costs, as exemplified by Amazon’s journey into cloud computing.</li>
</ul>
</section>
<section id="the-rise-of-cloud-computing" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-cloud-computing">The Rise of Cloud Computing</h4>
<ul>
<li>Cloud computing emerged partly from the need to utilize idle resources effectively.</li>
</ul>
</section>
</section>
<section id="manual-provisioning-and-its-drawbacks" class="level3">
<h3 class="anchored" data-anchor-id="manual-provisioning-and-its-drawbacks">Manual Provisioning and Its Drawbacks</h3>
<ul>
<li>Manually scaling resources up and down can reduce costs but is reactive, stressful, and may not handle sudden traffic spikes well.</li>
</ul>
<section id="handling-traffic-spikes" class="level4">
<h4 class="anchored" data-anchor-id="handling-traffic-spikes">Handling Traffic Spikes</h4>
<ul>
<li>Manual provisioning struggles to respond quickly to unexpected surges in traffic.</li>
</ul>
</section>
<section id="reducing-costs-but-potentially-sacrificing-user-experience" class="level4">
<h4 class="anchored" data-anchor-id="reducing-costs-but-potentially-sacrificing-user-experience">Reducing Costs but Potentially Sacrificing User Experience</h4>
<ul>
<li>While manual provisioning can save costs, it can also lead to poor user experiences during scaling events.</li>
</ul>
</section>
</section>
<section id="automatic-provisioning-and-autoscaling" class="level3">
<h3 class="anchored" data-anchor-id="automatic-provisioning-and-autoscaling">Automatic Provisioning and Autoscaling</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/images/auto-scaling.png" class="img-fluid figure-img"></p>
<figcaption>Auto-Scaling Resource Utilization</figcaption>
</figure>
</div>
<section id="kubernetes-and-autoscaling" class="level4">
<h4 class="anchored" data-anchor-id="kubernetes-and-autoscaling">Kubernetes and Autoscaling</h4>
<ul>
<li>Tools like Kubernetes automate provisioning and scaling, dynamically adjusting resources based on demand.</li>
</ul>
</section>
<section id="lag-in-autoscaling" class="level4">
<h4 class="anchored" data-anchor-id="lag-in-autoscaling">Lag in Autoscaling</h4>
<ul>
<li>Autoscaling typically involves a lag between resource demand and allocation.</li>
</ul>
</section>
<section id="granularity-of-autoscaling" class="level4">
<h4 class="anchored" data-anchor-id="granularity-of-autoscaling">Granularity of Autoscaling</h4>
<ul>
<li>Smaller units of autoscaling allow for more precise resource allocation.</li>
</ul>
</section>
</section>
<section id="achieving-serverless-matching-costs-to-resource-utilization" class="level3">
<h3 class="anchored" data-anchor-id="achieving-serverless-matching-costs-to-resource-utilization">Achieving Serverless: Matching Costs to Resource Utilization</h3>
<ul>
<li>Serverless computing aims to align costs directly with resource consumption.</li>
</ul>
<section id="scaling-to-zero" class="level4">
<h4 class="anchored" data-anchor-id="scaling-to-zero">Scaling to Zero</h4>
<ul>
<li>A defining characteristic of serverless is the ability to scale resources down to zero when not in use.</li>
</ul>
</section>
<section id="functions-as-a-service-faas" class="level4">
<h4 class="anchored" data-anchor-id="functions-as-a-service-faas">Functions as a Service (FaaS)</h4>
<ul>
<li>Serverless is often implemented using Functions as a Service (FaaS), where individual functions are executed on demand.</li>
</ul>
</section>
</section>
<section id="benefits-of-serverless-cost-savings-improved-user-experience" class="level3">
<h3 class="anchored" data-anchor-id="benefits-of-serverless-cost-savings-improved-user-experience">Benefits of Serverless: Cost Savings, Improved User Experience</h3>
<ul>
<li>Serverless offers:
<ul>
<li>Reduced costs by paying only for resources consumed.</li>
<li>Improved user experiences by dynamically scaling to meet demand.</li>
</ul></li>
</ul>
</section>
<section id="why-use-a-serverless-platform-like-modal" class="level3">
<h3 class="anchored" data-anchor-id="why-use-a-serverless-platform-like-modal">Why Use a Serverless Platform Like Modal?</h3>
<ul>
<li>Managing serverless infrastructure requires significant engineering effort.</li>
</ul>
<section id="why-use-a-serverless-platform-like-modal-1" class="level4">
<h4 class="anchored" data-anchor-id="why-use-a-serverless-platform-like-modal-1">Why Use a Serverless Platform Like Modal?</h4>
<ul>
<li>Serverless platforms like Modal offer economies of scale, handling the complexities of:
<ul>
<li>Resource allocation.</li>
<li>Autoscaling.</li>
<li>Infrastructure management.</li>
</ul></li>
</ul>
</section>
<section id="amortizing-engineering-complexity" class="level4">
<h4 class="anchored" data-anchor-id="amortizing-engineering-complexity">Amortizing Engineering Complexity</h4>
<ul>
<li>Modal amortizes the engineering complexity of serverless across its entire user base.</li>
</ul>
</section>
<section id="smoothing-fluctuations-with-multiple-users" class="level4">
<h4 class="anchored" data-anchor-id="smoothing-fluctuations-with-multiple-users">Smoothing Fluctuations with Multiple Users</h4>
<ul>
<li>Fluctuations in individual users’ resource usage are smoothed out by the aggregate usage of all users on the platform.</li>
</ul>
</section>
<section id="economics-of-serverless-computing" class="level4">
<h4 class="anchored" data-anchor-id="economics-of-serverless-computing">Economics of Serverless Computing</h4>
<ul>
<li>The “Berkeley View” paper highlights the economic benefits of serverless computing, emphasizing economies of scale and resource utilization.</li>
</ul>
<section id="berkeley-paper-on-serverless" class="level5">
<h5 class="anchored" data-anchor-id="berkeley-paper-on-serverless">Berkeley Paper on Serverless</h5>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/1902.03383">Cloud Programming Simplified: A Berkeley View on Serverless Computing</a></li>
</ul>
</section>
</section>
</section>
</section>
<section id="remote-procedure-calling-rpc-in-modal" class="level2">
<h2 class="anchored" data-anchor-id="remote-procedure-calling-rpc-in-modal">Remote Procedure Calling (RPC) in Modal</h2>
<section id="rpc-as-the-core-idea-behind-serverless" class="level3">
<h3 class="anchored" data-anchor-id="rpc-as-the-core-idea-behind-serverless">RPC as the Core Idea Behind Serverless</h3>
<ul>
<li>Remote Procedure Calling (RPC) is fundamental to serverless computing and Modal’s functionality.</li>
</ul>
</section>
<section id="how-rpc-works" class="level3">
<h3 class="anchored" data-anchor-id="how-rpc-works">How RPC Works</h3>
<ul>
<li>In RPC, local code invokes functions that execute on remote machines, abstracting away the complexities of network communication.</li>
<li><strong>Book:</strong> <a href="https://book.systemsapproach.org/index.html">Computer Networks: A Systems Approach</a>
<ul>
<li><strong>Section:</strong> <a href="https://book.systemsapproach.org/e2e/rpc.html#remote-procedure-call">5.3 Remote Procedure Call</a></li>
</ul></li>
</ul>
<section id="transparency-and-seamlessness" class="level4">
<h4 class="anchored" data-anchor-id="transparency-and-seamlessness">Transparency and Seamlessness</h4>
<ul>
<li>RPC strives for transparency, making remote function calls appear as if they were local.</li>
</ul>
</section>
</section>
<section id="modals-implementation-with-grpc" class="level3">
<h3 class="anchored" data-anchor-id="modals-implementation-with-grpc">Modal’s Implementation with gRPC</h3>
<ul>
<li>Modal utilizes gRPC as its RPC framework.</li>
</ul>
</section>
<section id="understanding-modals-behavior" class="level3">
<h3 class="anchored" data-anchor-id="understanding-modals-behavior">Understanding Modal’s Behavior</h3>
<section id="why-modal-feels-different-from-local-python" class="level4">
<h4 class="anchored" data-anchor-id="why-modal-feels-different-from-local-python">Why Modal Feels Different from Local Python</h4>
<ul>
<li>Modal’s RPC mechanisms introduce differences compared to traditional local Python execution.</li>
</ul>
</section>
<section id="code-execution-on-modals-machines" class="level4">
<h4 class="anchored" data-anchor-id="code-execution-on-modals-machines">Code Execution on Modal’s Machines</h4>
<ul>
<li>Code, including functions, is sent to Modal’s infrastructure for execution.</li>
</ul>
</section>
<section id="dynamic-function-execution" class="level4">
<h4 class="anchored" data-anchor-id="dynamic-function-execution">Dynamic Function Execution</h4>
<ul>
<li>Modal dynamically uploads and executes functions defined in local scripts.</li>
</ul>
</section>
<section id="handling-global-scope-and-imports" class="level4">
<h4 class="anchored" data-anchor-id="handling-global-scope-and-imports">Handling Global Scope and Imports</h4>
<ul>
<li>Understanding how Modal manages global scope and imports is crucial for writing effective Modal code.</li>
</ul>
</section>
</section>
<section id="running-code-on-gpus" class="level3">
<h3 class="anchored" data-anchor-id="running-code-on-gpus">Running Code on GPUs</h3>
<ul>
<li>Modal enables running code on GPUs even if the local machine lacks them.</li>
</ul>
</section>
<section id="demo-mini-modal" class="level3">
<h3 class="anchored" data-anchor-id="demo-mini-modal">Demo: Mini Modal</h3>
<section id="simulating-modal-locally" class="level4">
<h4 class="anchored" data-anchor-id="simulating-modal-locally">Simulating Modal Locally</h4>
<ul>
<li><strong><a href="https://github.com/charlesfrye/minimodal">MiniModal</a>:</strong> A simplified local simulation of Modal’s core concepts.</li>
</ul>
</section>
<section id="understanding-modals-internals" class="level4">
<h4 class="anchored" data-anchor-id="understanding-modals-internals">Understanding Modal’s Internals</h4>
<ul>
<li>Mini Modal provides insights into Modal’s internal workings, particularly its handling of virtual environments and code execution.</li>
</ul>
</section>
<section id="separating-virtual-environments" class="level4">
<h4 class="anchored" data-anchor-id="separating-virtual-environments">Separating Virtual Environments</h4>
<ul>
<li>Mini Modal demonstrates the isolation of virtual environments, a key aspect of Modal’s functionality.</li>
</ul>
</section>
</section>
</section>
<section id="qa-session-4" class="level2">
<h2 class="anchored" data-anchor-id="qa-session-4">Q&amp;A Session 4</h2>
<section id="how-modal-hosts-suno.ai" class="level4">
<h4 class="anchored" data-anchor-id="how-modal-hosts-suno.ai">How Modal Hosts Suno.ai</h4>
<ul>
<li><a href="https://suno.com/">Suno.ai</a>, a generative AI application, utilizes various Modal features, including functions, cron jobs, volumes, and web endpoints.</li>
</ul>
<section id="suno.ais-use-of-modals-features" class="level5">
<h5 class="anchored" data-anchor-id="suno.ais-use-of-modals-features">Suno.ai’s Use of Modal’s Features</h5>
<ul>
<li>A blog post details Suno.ai’s reasons for choosing Modal and how they leverage its features.</li>
</ul>
</section>
<section id="blog-post-about-suno.ais-choice-of-modal" class="level5">
<h5 class="anchored" data-anchor-id="blog-post-about-suno.ais-choice-of-modal">Blog Post about Suno.ai’s Choice of Modal</h5>
<ul>
<li>The blog post provides insights into Suno.ai’s decision to use Modal and their experience with the platform.</li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/</guid>
  <pubDate>Sun, 25 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Notes on The Learning Game꞉ Teaching Kids to Think for Themselves, Embrace Challenge, and Love Learning</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/the-learning-game-book-notes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
These notes are part of the following collection:
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="../../series/notes/education-notes.html"><strong>Education</strong></a></p>
</div>
</div>
<ul>
<li>Executive Summary</li>
<li>The Problem with the “Game of School”<br>
</li>
<li>Reimagining Education<br>
</li>
<li>Part 1: School<br>
</li>
<li>Part 2: How Kids Learn<br>
</li>
<li>Part 3: The Power of Games<br>
</li>
<li>Part 4: Raising Successful Kids<br>
</li>
<li>Part 5: The Model Parent<br>
</li>
<li>Conclusion: Design Your Learning Game</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Book LInks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://harriman.house/books/the-learning-game/">Publisher Page</a></li>
<li><a href="https://afabrega.com/">Author’s Website</a></li>
</ul>
</div>
</div>
<section id="executive-summary" class="level2">
<h2 class="anchored" data-anchor-id="executive-summary">Executive Summary</h2>
<p>This book critiques the modern education system, arguing that it stifles curiosity and creativity in children. It advocates for a shift from instruction-based learning to a more engaging, game-like approach that empowers children to think independently, embrace failure, and develop a lifelong love of learning.</p>
<p>The author draws upon personal experience as a teacher and insights from various fields, including psychology, game design, and philosophy, to offer practical strategies for parents and educators to design a “Learning Game” that fosters genuine learning.</p>
<p>The book challenges common misconceptions about learning styles, the role of memorization, and the fear of failure, proposing alternative methods like story-driven learning, mental models, and elastic thinking.</p>
</section>
<section id="the-problem-with-the-game-of-school" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-with-the-game-of-school">The Problem with the “Game of School”</h2>
<section id="authors-personal-journey" class="level3">
<h3 class="anchored" data-anchor-id="authors-personal-journey">Author’s Personal Journey</h3>
<ul>
<li>The author attended 10 schools across 7 countries, experiencing diverse educational systems and adapting to new environments.</li>
<li>She realized that succeeding in school often meant playing the “game” - following rules, pleasing teachers, and achieving good grades - rather than deeply engaging with learning.</li>
<li>Her true passion for learning flourished outside the classroom, where she could pursue personal interests and explore creatively.</li>
</ul>
</section>
<section id="the-pervasive-game-of-school" class="level3">
<h3 class="anchored" data-anchor-id="the-pervasive-game-of-school">The Pervasive “Game of School”</h3>
<ul>
<li>The author observed the same “game” being played in classrooms worldwide, with students expected to conform and obey rather than think critically and independently.</li>
<li>This realization led her to question the effectiveness of an educational system that stifles curiosity and enforces a standardized approach to learning.</li>
</ul>
</section>
<section id="impact-on-childrens-love-of-learning" class="level3">
<h3 class="anchored" data-anchor-id="impact-on-childrens-love-of-learning">Impact on Children’s Love of Learning</h3>
<ul>
<li>Young children possess a natural desire to learn, but this enthusiasm often dwindles as they progress through a rigid and prescriptive school system.</li>
<li>The lack of choice, autonomy, and personalized learning experiences contributes to disengagement and a reliance on extrinsic motivation (grades).</li>
</ul>
</section>
</section>
<section id="reimagining-education" class="level2">
<h2 class="anchored" data-anchor-id="reimagining-education">Reimagining Education</h2>
<section id="key-questions-for-transforming-education" class="level3">
<h3 class="anchored" data-anchor-id="key-questions-for-transforming-education">Key Questions for Transforming Education</h3>
<ul>
<li>How can we shift from a “game of school” to a “game of learning” that fosters lifelong curiosity and a genuine passion for knowledge?</li>
<li>How can we tailor education to individual needs and empower children to take ownership of their learning journeys?</li>
<li>How do we equip children with the tools and mindsets to thrive in a world of constant change and embrace challenges as opportunities for growth?</li>
</ul>
</section>
<section id="the-learning-game-approach" class="level3">
<h3 class="anchored" data-anchor-id="the-learning-game-approach">The “Learning Game” Approach</h3>
<ul>
<li>Encourages parents and educators to challenge traditional assumptions about education and actively participate in shaping their children’s learning experiences.</li>
<li>Emphasizes the importance of:
<ul>
<li><strong>Curiosity-driven Exploration:</strong> Allowing children to pursue their passions and interests, even if they deviate from conventional academic paths.</li>
<li><strong>Critical Thinking and Questioning:</strong> Encouraging children to challenge assumptions, seek evidence, and think independently.</li>
<li><strong>Personal Relevance and Real-World Application:</strong> Connecting learning to children’s lives and demonstrating the practical applications of knowledge.</li>
<li><strong>Embrace of Mistakes and Challenges:</strong> Fostering a growth mindset where mistakes are viewed as opportunities for learning and challenges are embraced as catalysts for development.</li>
</ul></li>
</ul>
</section>
</section>
<section id="part-1-school" class="level2">
<h2 class="anchored" data-anchor-id="part-1-school">Part 1: School</h2>
<section id="chapter-1-seven-dangerous-lessons-taught-in-schools" class="level3">
<h3 class="anchored" data-anchor-id="chapter-1-seven-dangerous-lessons-taught-in-schools">Chapter 1: Seven Dangerous Lessons Taught in Schools</h3>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> “<a href="https://newsociety.com/books/d/dumbing-us-down-25th-anniversary-edition">Dumbing Us Down, The Hidden Curriculum of Compulsory Schooling</a>” by John Taylor Gatto.</li>
</ul>
</div>
</div>
<p>This chapter, drawing upon John Taylor Gatto’s book “Dumbing Us Down,” outlines seven detrimental lessons ingrained in the traditional education system:</p>
<ol type="1">
<li><strong>Confusion:</strong> Subjects taught in isolation, lacking real-world context, leaving students confused about how knowledge connects.
<ul>
<li><strong>Alternative:</strong> Teach concepts in context, applying them to solve problems or build projects.</li>
</ul></li>
<li><strong>Class Position:</strong> Obsession with ranking and labeling students, fostering competition instead of collaboration.
<ul>
<li><strong>Alternative:</strong> Encourage collaboration, letting kids define success on their own terms, valuing individual strengths and contributions.</li>
</ul></li>
<li><strong>Indifference:</strong> Discouraging deep engagement by forcing rapid subject switching, mirroring the fragmented attention of the digital age.
<ul>
<li><strong>Alternative:</strong> Let kids follow their interests, allowing them to dive deep into topics that excite them, fostering focus and depth.</li>
</ul></li>
<li><strong>Emotional Dependency:</strong> Students conditioned to mirror teachers’ emotions, hindering their ability to develop emotional regulation and resilience.
<ul>
<li><strong>Alternative:</strong> Encourage kids to explore and manage their own feelings, fostering emotional intelligence and resilience.</li>
</ul></li>
<li><strong>Intellectual Dependency:</strong> Prioritizing conformity and obedience over independent thought and challenging the status quo.
<ul>
<li><strong>Alternative:</strong> Encourage divergent thinking, questioning, and the development of individual perspectives, valuing critical thinking over rote memorization.</li>
</ul></li>
<li><strong>Provisional Self-Esteem:</strong> Tying self-worth to external validation from teachers and grades, rather than internal standards and self-assessment.
<ul>
<li><strong>Alternative:</strong> Encourage kids to develop an internal measuring stick, fostering self-confidence and self-reliance based on personal growth and effort.</li>
</ul></li>
<li><strong>Students Can’t Hide:</strong> Constant surveillance and lack of privacy, hindering experimentation, risk-taking, and the development of self-directed learning.
<ul>
<li><strong>Alternative:</strong> Provide opportunities for privacy, creative exploration, and independent action, allowing kids to learn through trial and error.</li>
</ul></li>
</ol>
</section>
<section id="chapter-2-how-did-we-get-here" class="level3">
<h3 class="anchored" data-anchor-id="chapter-2-how-did-we-get-here">Chapter 2: How Did We Get Here?</h3>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Blog Post:</strong> <a href="https://afabrega.com/my-blog/the-origin-of-the-modern-school-system">The Origin of the Modern School System</a></li>
</ul>
</div>
</div>
<p>This chapter traces the historical development of the education system, revealing the origins of its flaws:</p>
<ul>
<li><strong>Prussia:</strong>
<ul>
<li>The modern school system originated in Prussia, designed to create loyal, literate soldiers after their defeat by Napoleon.</li>
<li>This model emphasized standardized curriculum, teacher certification, and mandated attendance, prioritizing obedience and indoctrination.</li>
</ul></li>
<li><strong>The USA:</strong>
<ul>
<li>In the 20th century, the focus shifted from training soldiers to producing factory managers, leading to the adoption of the “factory model” in American schools.</li>
<li>This model emphasized standardization, efficiency, age-based grouping, specialized teachers, and long school days, mirroring the assembly line approach.</li>
<li>This model has yielded disappointing results, with stagnant test scores, declining public confidence, and a disconnect from real-world success.</li>
</ul></li>
</ul>
<p>This historical context reveals how the education system prioritizes state and industrial needs over genuine learning, leading to the current instruction-based model.</p>
</section>
<section id="chapter-3-how-tests-and-rewards-go-wrong" class="level3">
<h3 class="anchored" data-anchor-id="chapter-3-how-tests-and-rewards-go-wrong">Chapter 3: How Tests and Rewards Go Wrong</h3>
<p>This chapter examines the detrimental effects of standardized testing and extrinsic rewards:</p>
<ul>
<li><strong>Standardized Tests:</strong>
<ul>
<li>Initially designed to measure student progress, standardized tests have become the primary focus of education, leading to several negative consequences.</li>
<li>They create stressful learning environments, compromise mental health, do not accurately reflect real-world success, and incentivize cheating.</li>
</ul></li>
<li><strong>Extrinsic Rewards:</strong>
<ul>
<li>Schools rely on extrinsic rewards like pizza parties or prizes, offering short-term motivation but undermining long-term engagement.</li>
<li>Extrinsic motivators create dependence on external validation, hindering the development of intrinsic motivation.</li>
</ul></li>
</ul>
<p>The chapter suggests alternative assessment methods, including portfolios and projects, and emphasizes the importance of intrinsic motivation, encouraging:</p>
<ul>
<li>Providing choices and fostering accountability.</li>
<li>Involving children in decision-making.</li>
<li>Offering specific feedback that focuses on effort and the learning process, not just outcomes.</li>
<li>Engaging in “why” conversations to connect learning to real-world relevance and purpose.</li>
<li>Prioritizing fun and intrinsic enjoyment in the learning process.</li>
</ul>
</section>
<section id="chapter-4-lessons-to-unlearn-from-school" class="level3">
<h3 class="anchored" data-anchor-id="chapter-4-lessons-to-unlearn-from-school">Chapter 4: Lessons to Unlearn from School</h3>
<p>This chapter highlights five counterproductive lessons learned in traditional school that need to be unlearned:</p>
<ol type="1">
<li><strong>Fearing Mistakes:</strong> Shift from penalizing errors to embracing them as valuable learning opportunities.</li>
<li><strong>Fitting In:</strong> Encourage individuality, divergent thinking, and “coloring outside the lines” over conformity and seeking validation through sameness.</li>
<li><strong>Waiting for Instructions:</strong> Cultivate problem-solving skills, resourcefulness, and the ability to learn independently without relying on constant direction.</li>
<li><strong>Learning Just in Case:</strong> Embrace “learning on demand,” where knowledge and skills are acquired as needed, driven by curiosity and real-world application.</li>
<li><strong>Fear of Questioning Authority:</strong> Foster critical thinking, challenging assumptions, and seeking evidence-based answers over blind acceptance of authority.</li>
</ol>
</section>
<section id="chapter-5-the-game-of-school" class="level3">
<h3 class="anchored" data-anchor-id="chapter-5-the-game-of-school">Chapter 5: The Game of School</h3>
<p>This chapter contrasts the “game of school,” characterized by compliance and seeking external validation, with the “learning game,” emphasizing:</p>
<ul>
<li><strong>Game of School:</strong> Mastering the system through superficial engagement, prioritizing grades over true understanding, and focusing on short-term performance.</li>
<li><strong>Learning Game:</strong> Embracing curiosity-driven exploration, taking ownership of the learning process, valuing the journey of discovery over external rewards.</li>
</ul>
<p>The chapter advocates for guiding children towards the learning game, fostering intrinsic motivation, and equipping them with the skills and mindset to become lifelong learners.</p>
</section>
</section>
<section id="part-2-how-kids-learn" class="level2">
<h2 class="anchored" data-anchor-id="part-2-how-kids-learn">Part 2: How Kids Learn</h2>
<section id="chapter-6-learning-to-love-learning" class="level3">
<h3 class="anchored" data-anchor-id="chapter-6-learning-to-love-learning">Chapter 6: Learning to Love Learning</h3>
<ul>
<li><strong>Separating Work and Play:</strong> Traditional education often separates learning from joy by framing schoolwork as “real work” and personal projects as mere play. This undermines the potential for genuine learning that blossoms when children are intrinsically motivated.</li>
<li><strong>The Power of Personal Projects:</strong>
<ul>
<li>Personal projects, like building a tree house, offer opportunities for children to engage deeply in learning experiences they direct themselves. This mirrors the work of innovators like Darwin and Newton, whose successes stemmed from pursuing their own curiosities.</li>
<li>Examples like Mark Zuckerberg, Elon Musk, and Jenny Britton Bauer illustrate that groundbreaking achievements often arise from intensely pursuing personal passions, even if they fall outside traditional academic paths.</li>
<li><strong>Vuja De:</strong> Seeing a familiar situation with a fresh perspective that leads to new insights.</li>
<li><strong>Recommendation:</strong> Encourage children to pursue their own projects. Help them see these endeavors as valuable learning experiences, fostering their passions and cultivating a love for learning.</li>
</ul></li>
</ul>
</section>
<section id="chapter-7-story-driven-learning" class="level3">
<h3 class="anchored" data-anchor-id="chapter-7-story-driven-learning">Chapter 7: Story-Driven Learning</h3>
<ul>
<li><p><strong>The Power of Stories:</strong> Humans are naturally wired to learn through stories. Stories make abstract concepts concrete, provide relatable examples, and offer memorable narratives that engage our emotions and enhance recall.</p></li>
<li><p><strong>Learning from Role Models:</strong> Stories provide us with heroes to admire and emulate. By connecting with the experiences of individuals who have mastered specific skills or concepts, we can find inspiration and practical strategies for our own learning journeys.</p>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Newsletter:</strong> <a href="https://www.readtheprofile.com/t/interviews">The Profile - Interviews</a>
<ul>
<li>Interviews Polina Pompliano, offering stories of unique individuals for learning.</li>
</ul></li>
</ul>
</div>
</div></li>
</ul></li>
<li><p><strong>How to Use Story-Driven Learning:</strong></p>
<ul>
<li>Identify individuals who embody the skills or knowledge you want to acquire. Explore their stories through books, articles, documentaries, or podcasts.</li>
<li>Connect the abstract concepts to the practical applications demonstrated in the individual’s life. For example, learn about decision-making through the story of a successful poker player who utilizes probability theory.</li>
<li><strong>Recommendation:</strong> Encourage children to explore topics they’re interested in through stories. Help them find biographies, documentaries, or articles about people who excel in those areas. This makes learning relatable and engaging.</li>
</ul></li>
</ul>
</section>
<section id="chapter-8-learning-through-memorization" class="level3">
<h3 class="anchored" data-anchor-id="chapter-8-learning-through-memorization">Chapter 8: Learning Through Memorization</h3>
<ul>
<li><p><strong>Rethinking Memorization in the Digital Age:</strong> With information readily accessible, rote memorization of isolated facts holds less importance. Instead, prioritize understanding fundamental concepts, developing critical thinking skills, and building a foundation of applicable knowledge.</p></li>
<li><p><strong>Pair Memory with Meaning:</strong></p>
<ul>
<li>Encourage understanding the “why” behind the “what.” Simply memorizing facts without comprehending their meaning limits genuine learning and the ability to apply knowledge effectively.</li>
</ul></li>
<li><p><strong>Focus on Essential Knowledge:</strong></p>
<ul>
<li>Prioritize memorizing information with practical, real-world application over trivial facts easily retrieved online. Focus on concepts crucial for decision-making and understanding how the world works.</li>
</ul></li>
<li><p><strong>Effective Memorization Techniques:</strong></p>
<ul>
<li><p><strong>Memory Palace:</strong> This technique leverages our natural ability to remember places and vivid imagery.</p>
<ol type="1">
<li>Imagine a familiar location (e.g., your childhood home).</li>
<li>Associate items to be memorized with specific locations within this “palace” (e.g., placing grocery items in different rooms).</li>
<li>Create unusual, memorable scenes involving these items (e.g., apples singing in the mailbox).</li>
<li>To recall the items, mentally walk through the “palace” and retrieve the vivid associations.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Blog Post:</strong> <a href="https://artofmemory.com/blog/how-to-build-a-memory-palace/">How to Build a Memory Palace</a></li>
<li><strong>Book:</strong> <a href="https://joshuafoer.com/moonwalking-with-einstein/">Moonwalking with Einstein</a></li>
</ul>
</div>
</div></li>
</ul></li>
<li><p><strong>Recommendation:</strong> Teach children effective memorization techniques like the Memory Palace method. This makes memorization more engaging and helps them retain important information.</p></li>
</ul>
</section>
<section id="chapter-9-the-learning-style-myth" class="level3">
<h3 class="anchored" data-anchor-id="chapter-9-the-learning-style-myth">Chapter 9: The Learning Style Myth</h3>
<ul>
<li><strong>Challenging the Myth:</strong> The notion that individuals have one dominant learning style (visual, auditory, kinesthetic) lacks scientific support. Sensory modalities are interconnected, and we learn best by engaging multiple senses simultaneously.</li>
<li><strong>Problems with Learning Styles:</strong>
<ul>
<li><strong>No Single Style:</strong> We do not have a single, fixed learning style. Preferences can vary depending on the context and the type of information being processed.</li>
<li><strong>Ineffective Customization:</strong> Tailoring teaching to supposed learning styles does not improve learning outcomes.</li>
<li><strong>Fixed Mindset:</strong> Labeling children as specific learner types can foster limiting beliefs about their abilities.</li>
</ul></li>
<li><strong>Recommendations:</strong>
<ul>
<li><strong>Debunk the Myth:</strong> Help children understand they don’t have just one learning style.</li>
<li><strong>Embrace Flexibility:</strong> Emphasize that learning preferences are adaptable and can change based on the situation.</li>
<li><strong>Encourage a Diverse Toolkit:</strong> Help children develop a range of learning strategies and encourage them to identify the most effective tools for different tasks.</li>
<li><strong>Provide Multi-Sensory Experiences:</strong> Offer diverse learning opportunities that engage multiple senses.</li>
</ul></li>
</ul>
</section>
<section id="chapter-10-confusion-sparks-curiosity" class="level3">
<h3 class="anchored" data-anchor-id="chapter-10-confusion-sparks-curiosity">Chapter 10: Confusion Sparks Curiosity</h3>
<ul>
<li><p><strong>Embracing Confusion:</strong> Instead of viewing confusion as a negative experience, reframe it as an opportunity for growth. Cognitive disequilibrium, the feeling of discomfort when encountering new information, drives us to seek answers and deepen our understanding.</p>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Psychological Concept:</strong> <a href="https://link.springer.com/referenceworkentry/10.1007/978-0-387-79061-9_598">Cognitive disequilibrium</a></li>
</ul>
</div>
</div></li>
</ul></li>
<li><p><strong>Benefits of Confusion:</strong></p>
<ul>
<li><strong>Deeper Processing:</strong> Confusion prompts us to engage more deeply with information to resolve inconsistencies with our existing knowledge.</li>
<li><strong>Curiosity and Motivation:</strong> Confusion can spark curiosity, leading to increased motivation and engagement in the learning process.</li>
</ul></li>
<li><p><strong>Learning Through Connections:</strong> Present new information within a relevant context to help children see the connections between different subjects and real-world applications.</p></li>
<li><p><strong>A Case Study: Synthesis:</strong> The Synthesis class at Ad Astra School, founded by Elon Musk, uses simulations and challenges to help kids embrace confusion and develop problem-solving skills.</p>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Learning Platform:</strong> <a href="https://www.synthesis.com/">Synthesis</a></li>
</ul>
</div>
</div></li>
</ul></li>
<li><p><strong>Principles for Exploring Confusion:</strong></p>
<ul>
<li><strong>Expose Kids to Challenges:</strong> Encourage them to tackle challenging problems and unfamiliar situations.</li>
<li><strong>Reframe Confusion:</strong> Help children view confusion as a positive step in the learning process, not a sign of failure.</li>
<li><strong>Support Productive Struggle:</strong> Provide guidance and support, but allow children to grapple with challenges and discover solutions independently.</li>
</ul></li>
<li><p><strong>Recommendation:</strong> Create learning environments that embrace confusion and encourage experimentation. Encourage children to view challenges as exciting opportunities for growth.</p></li>
</ul>
</section>
</section>
<section id="part-3-the-power-of-games" class="level2">
<h2 class="anchored" data-anchor-id="part-3-the-power-of-games">Part 3: The Power of Games</h2>
<section id="chapter-11-the-architecture-of-great-games" class="level3">
<h3 class="anchored" data-anchor-id="chapter-11-the-architecture-of-great-games">Chapter 11: The Architecture of Great Games</h3>
<p>This chapter explores how to leverage game design principles to enhance learning experiences.</p>
<section id="why-games-captivate-the-power-of-flow" class="level4">
<h4 class="anchored" data-anchor-id="why-games-captivate-the-power-of-flow">Why Games Captivate: The Power of Flow</h4>
<ul>
<li><strong>Engagement and Flow:</strong> Games captivate players by inducing a state of “flow,” characterized by:
<ul>
<li>Clear goals</li>
<li>Unambiguous feedback</li>
<li>Goldilocks challenge level (not too easy, not too hard)</li>
</ul></li>
<li><strong>Flow fosters intrinsic motivation</strong>, where enjoyment stems from the activity itself, not external rewards.</li>
<li><strong>Games vs.&nbsp;Classrooms:</strong> Traditional classrooms often lack the elements needed for flow:
<ul>
<li>Unclear goals</li>
<li>Ambiguous feedback</li>
<li>One-size-fits-all challenges</li>
</ul></li>
</ul>
</section>
<section id="beyond-pointsification-true-gamification" class="level4">
<h4 class="anchored" data-anchor-id="beyond-pointsification-true-gamification">Beyond Pointsification: True Gamification</h4>
<ul>
<li><strong>Pointsification:</strong> Superficial use of game elements (points, badges, leaderboards) that relies on external motivation. While it may yield short-term results, it’s unsustainable and doesn’t cultivate a genuine love for learning.</li>
<li><strong>True Gamification:</strong> Understanding and integrating what makes games truly engaging:
<ul>
<li><strong>Meaningful challenges:</strong> Aligned with players’ genuine interests.</li>
<li><strong>Immersive experiences:</strong> Capable of inducing a flow state.</li>
</ul></li>
</ul>
<section id="example-new-york-public-library" class="level5">
<h5 class="anchored" data-anchor-id="example-new-york-public-library">Example: New York Public Library</h5>
<ul>
<li><strong>Challenge:</strong> Attract young people to physical libraries in the digital age.</li>
<li><strong>Solution:</strong> A game that turns participants into published authors by locking them in the library overnight with the challenge of writing a book.</li>
<li><strong>Result:</strong> Participants found the challenge meaningful, enjoyed their time at the library, and developed a newfound appreciation for the space.</li>
</ul>
</section>
</section>
<section id="the-super-mario-effect-embracing-failure" class="level4">
<h4 class="anchored" data-anchor-id="the-super-mario-effect-embracing-failure">The Super Mario Effect: Embracing Failure</h4>
<ul>
<li><strong>Reframing Failure:</strong> Games encourage persistence despite repeated failures. Players focus on the ultimate goal, viewing mistakes as part of the learning process.</li>
<li><strong>The Super Mario Effect:</strong> Prioritizing the end goal over the fear of failure.</li>
<li><strong>Shifting Focus in Education:</strong> From grades to mastery, from penalizing mistakes to encouraging iterative learning.</li>
</ul>
</section>
<section id="the-benefits-of-video-games" class="level4">
<h4 class="anchored" data-anchor-id="the-benefits-of-video-games">The Benefits of Video Games</h4>
<ul>
<li><strong>Developing Thinking Skills:</strong> Games are simulations that provide a safe space to practice problem-solving and strategic thinking.</li>
<li><strong>Fostering Self-Directed Learning:</strong> Games empower players to learn at their own pace, explore their interests, and develop a growth mindset.</li>
</ul>
</section>
</section>
<section id="chapter-12-the-psychology-of-healthy-gaming" class="level3">
<h3 class="anchored" data-anchor-id="chapter-12-the-psychology-of-healthy-gaming">Chapter 12: The Psychology of Healthy Gaming</h3>
<p>This chapter delves into the motivations behind children’s screen time and offers strategies for fostering healthy technology use.</p>
<section id="understanding-motivation-self-determination-theory" class="level4">
<h4 class="anchored" data-anchor-id="understanding-motivation-self-determination-theory">Understanding Motivation: Self-Determination Theory</h4>
<ul>
<li><p><strong>Three Basic Needs:</strong> Humans are driven by the need for:</p>
<ul>
<li><strong>Autonomy:</strong> Making our own choices.</li>
<li><strong>Competency:</strong> Developing skills and knowledge.</li>
<li><strong>Relatedness:</strong> Connecting with others.</li>
</ul></li>
<li><p><strong>The Online Appeal:</strong> The digital world often provides kids with more opportunities to satisfy these needs than traditional environments like schools.</p></li>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.nirandfar.com/indistractable/">Indistractable: How to Control Your Attention and Choose Your Life</a></li>
</ul>
</div>
</div></li>
</ul>
</section>
<section id="motivation-school-vs.-online" class="level4">
<h4 class="anchored" data-anchor-id="motivation-school-vs.-online">Motivation: School vs.&nbsp;Online</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 41%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>Need</th>
<th>School</th>
<th>Online</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Autonomy</td>
<td>Strict rules, limited choices</td>
<td>Freedom to choose, less adult control</td>
</tr>
<tr class="even">
<td>Competency</td>
<td>Standardized learning, limited agency</td>
<td>Personalized learning, self-directed exploration</td>
</tr>
<tr class="odd">
<td>Relatedness</td>
<td>Structured interactions, limited free time</td>
<td>Easy to connect with like-minded peers</td>
</tr>
</tbody>
</table>
</section>
<section id="navigating-screen-time-7-tactics-for-parents" class="level4">
<h4 class="anchored" data-anchor-id="navigating-screen-time-7-tactics-for-parents">Navigating Screen Time: 7 Tactics for Parents</h4>
<ol type="1">
<li><strong>Discuss Pros and Cons:</strong> Have open conversations about technology’s benefits and drawbacks.</li>
<li><strong>Show Empathy:</strong> Validate children’s feelings and acknowledge their struggle with limits.</li>
<li><strong>Share Your Own Challenges:</strong> Model healthy tech habits and be transparent about your own struggles.</li>
<li><strong>Collaborate on Boundaries:</strong> Involve children in setting screen time limits to foster a sense of ownership.</li>
<li><strong>Offer Offline Fulfillment:</strong> Provide ample opportunities for play, socializing, and pursuing passions offline.</li>
<li><strong>Encourage Creation over Consumption:</strong> Promote active engagement with technology through learning, making, and connecting.</li>
<li><strong>Provide a Better Yes:</strong> Ensure that saying no to screens means saying yes to something more engaging and fulfilling.</li>
</ol>
</section>
<section id="healthy-gaming-4-tactics" class="level4">
<h4 class="anchored" data-anchor-id="healthy-gaming-4-tactics">Healthy Gaming: 4 Tactics</h4>
<ol type="1">
<li><strong>Focus on Purposeful Play:</strong> Encourage gaming with a goal beyond escapism, such as socializing, learning, or skill-building.</li>
<li><strong>Maintain a Healthy Limit:</strong> Keep gaming under 21 hours per week to maximize benefits and minimize potential negative effects.</li>
<li><strong>Reverse the Order:</strong> Encourage studying after gaming to capitalize on the brain’s tendency to consolidate learning during sleep.</li>
<li><strong>Choose Social Over Competitive:</strong> Limit competitive play against strangers, emphasizing cooperative games or competing with known individuals.</li>
</ol>
</section>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>By understanding the psychological needs driving children’s tech use and applying game design principles thoughtfully, parents and educators can harness the power of games to foster learning, creativity, and healthy development.</p>
</section>
</section>
<section id="part-4-raising-successful-kids" class="level2">
<h2 class="anchored" data-anchor-id="part-4-raising-successful-kids">Part 4: Raising Successful Kids</h2>
<section id="chapter-13-skin-in-the-game" class="level3">
<h3 class="anchored" data-anchor-id="chapter-13-skin-in-the-game">Chapter 13: Skin in the Game</h3>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.penguinrandomhouse.com/books/537828/skin-in-the-game-by-nassim-nicholas-taleb/">Skin in the Game: Hidden Asymmetries in Daily Life</a></li>
</ul>
</div>
</div>
<section id="skin-in-the-game-for-kids" class="level4">
<h4 class="anchored" data-anchor-id="skin-in-the-game-for-kids">Skin in the Game for Kids</h4>
<ul>
<li><strong>Traditional school provides limited “skin in the game”:</strong> While grades offer some accountability, they lack relevance to the real world.</li>
<li><strong>Real-world problem-solving offers higher stakes:</strong> Children crave opportunities to tackle meaningful challenges with tangible outcomes.</li>
<li><strong>Benefits of Skin in the Game:</strong>
<ul>
<li><strong>Enhanced Learning:</strong> High stakes increase focus, motivation, and information retention.</li>
<li><strong>Memorable Experiences:</strong> Lessons learned through experience stick with us longer.</li>
<li><strong>Increased Engagement:</strong> Real-world application makes learning exciting and meaningful.</li>
</ul></li>
<li><strong>Synthesis - A Case Study:</strong>
<ul>
<li><strong>Conundrums:</strong> Synthesis initially presented complex ethical and practical dilemmas for children to debate.</li>
<li><strong>Simulations:</strong> Evolved to include competitive simulations with real winners and losers, raising the stakes and encouraging strategic thinking and decision-making.</li>
</ul></li>
</ul>
</section>
<section id="skin-in-the-game-for-parents" class="level4">
<h4 class="anchored" data-anchor-id="skin-in-the-game-for-parents">Skin in the Game for Parents</h4>
<ul>
<li><strong>Moving Beyond Outsourcing Education:</strong> Parents need to be active participants in their children’s education, not just rely on schools.</li>
<li><strong>Benefits of Parental Involvement:</strong>
<ul>
<li><strong>Stability for Children:</strong> Consistent support and understanding from someone who knows them well.</li>
<li><strong>Deeper Insights:</strong> Direct involvement provides unparalleled understanding of a child’s strengths, weaknesses, and learning style.</li>
<li><strong>Addressing Learning Gaps:</strong> Personalized attention can fill gaps and tailor the learning experience.</li>
<li><strong>Maximizing Quality Time:</strong> Leverage the formative years to directly impact a child’s future.</li>
</ul></li>
</ul>
</section>
<section id="how-to-increase-parental-involvement" class="level4">
<h4 class="anchored" data-anchor-id="how-to-increase-parental-involvement">How to Increase Parental Involvement:</h4>
<ul>
<li><strong>Explore Educational Options:</strong> Research and experiment with different programs, methods, and schools.</li>
<li><strong>Focus on One Subject:</strong> Start small by teaching a subject at home, even for a couple of hours a week.</li>
<li><strong>Pursue Passion Projects Together:</strong> Engage in activities the child is passionate about, learning and growing alongside them.</li>
<li><strong>Allow for Change:</strong> Be flexible and let children change their minds about activities they dislike.</li>
<li><strong>Take Responsibility:</strong> Avoid blaming teachers or schools when challenges arise, focus on finding solutions.</li>
</ul>
</section>
</section>
<section id="chapter-14-raising-antifragile-kids" class="level3">
<h3 class="anchored" data-anchor-id="chapter-14-raising-antifragile-kids">Chapter 14: Raising Antifragile Kids</h3>
<section id="the-downside-of-overprotection" class="level4">
<h4 class="anchored" data-anchor-id="the-downside-of-overprotection">The Downside of Overprotection:</h4>
<ul>
<li><strong>Shielding from Discomfort:</strong> Constantly protecting children from setbacks, disappointment, and failure hinders their development.</li>
<li><strong>Consequences of Overprotection:</strong>
<ul>
<li><strong>Inability to Handle Setbacks:</strong> Dependence on adults for problem-solving leads to discouragement when facing challenges.</li>
<li><strong>Low Self-Esteem:</strong> Feeling incapable of handling situations independently.</li>
</ul></li>
</ul>
</section>
<section id="the-power-of-anti-fragility" class="level4">
<h4 class="anchored" data-anchor-id="the-power-of-anti-fragility">The Power of Anti-Fragility:</h4>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.penguinrandomhouse.com/books/176227/antifragile-by-nassim-nicholas-taleb/">Antifragile: Things That Gain from Disorder</a></li>
</ul>
</div>
</div></li>
<li><p><strong>Definition:</strong> Antifragility, a term coined by Nassim Taleb, describes things that grow stronger when exposed to stress and randomness.</p></li>
<li><p><strong>Children are Antifragile:</strong> They thrive when allowed to face and overcome moderate challenges.</p></li>
<li><p><strong>Benefits of Embracing Challenges:</strong></p>
<ul>
<li><strong>Resilience:</strong> Developing the ability to bounce back from setbacks.</li>
<li><strong>Independence:</strong> Learning to solve problems and make decisions autonomously.</li>
<li><strong>Self-Confidence:</strong> Gaining belief in their own abilities through facing and overcoming challenges.</li>
</ul></li>
</ul>
</section>
<section id="fostering-antifragility" class="level4">
<h4 class="anchored" data-anchor-id="fostering-antifragility">Fostering Antifragility:</h4>
<ul>
<li><strong>Allow for Natural Consequences:</strong> Resist the urge to constantly intervene and solve problems for children.</li>
<li><strong>Encourage Risk-Taking:</strong> Create opportunities for safe, age-appropriate risks and challenges.</li>
<li><strong>Promote Problem-Solving:</strong> Guide children to find solutions independently before offering assistance.</li>
<li><strong>Model Resilience:</strong> Demonstrate healthy coping mechanisms and a positive attitude towards challenges.</li>
</ul>
</section>
</section>
<section id="chapter-15-how-to-develop-character-like-the-stoics" class="level3">
<h3 class="anchored" data-anchor-id="chapter-15-how-to-develop-character-like-the-stoics">Chapter 15: How to Develop Character Like the Stoics</h3>
<section id="the-importance-of-character-development" class="level4">
<h4 class="anchored" data-anchor-id="the-importance-of-character-development">The Importance of Character Development:</h4>
<ul>
<li><strong>Historical Perspective:</strong> Education in the past emphasized character development and producing virtuous citizens.</li>
<li><strong>Stoicism:</strong> A philosophy that stresses self-control, perseverance, and moral virtue.</li>
<li><strong>Relevancy of Stoicism:</strong> Stoic principles remain relevant today and can guide children towards becoming well-rounded adults.</li>
</ul>
</section>
<section id="the-four-stoic-virtues" class="level4">
<h4 class="anchored" data-anchor-id="the-four-stoic-virtues">The Four Stoic Virtues:</h4>
<ul>
<li><strong>Courage:</strong> Facing adversity with bravery and taking action despite fear.</li>
<li><strong>Temperance:</strong> Practicing moderation and avoiding extremes, finding a balance between recklessness and cowardice.</li>
<li><strong>Justice:</strong> Acting with fairness, honesty, and respect towards others, prioritizing the good of society.</li>
<li><strong>Wisdom:</strong> Applying knowledge and experience to make sound judgments and live a virtuous life.</li>
</ul>
</section>
<section id="four-tactics-for-developing-stoic-virtues" class="level4">
<h4 class="anchored" data-anchor-id="four-tactics-for-developing-stoic-virtues">Four Tactics for Developing Stoic Virtues:</h4>
<ul>
<li><strong>Read Stories of Heroes:</strong> Provide concrete examples of virtuous behavior through inspiring tales from history and mythology.</li>
<li><strong>Focus on What’s Controllable:</strong> Teach children to differentiate between things they can and cannot control and focus their efforts accordingly.</li>
<li><strong>Keep a Virtue Journal:</strong> Encourage self-reflection on how they demonstrate or could have better demonstrated virtues in daily life.</li>
<li><strong>Virtue as a Muscle:</strong> Explain that character strengthens over time with consistent effort and reflection, just like physical muscles.</li>
</ul>
</section>
</section>
<section id="chapter-16-range-and-specific-knowledge" class="level3">
<h3 class="anchored" data-anchor-id="chapter-16-range-and-specific-knowledge">Chapter 16: Range and Specific Knowledge</h3>
<section id="helping-kids-develop-range" class="level4">
<h4 class="anchored" data-anchor-id="helping-kids-develop-range">Helping Kids Develop Range</h4>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://davidepstein.com/range/">Range: Why Generalists Triumph in a Specialized World</a></li>
</ul>
</div>
</div></li>
<li><p><strong>Early Specialization vs.&nbsp;Range:</strong> While early specialization works in predictable fields, a broad base of knowledge is crucial in our complex world.</p></li>
<li><p><strong>Benefits of Range:</strong> Adaptability, creativity, and the ability to draw on diverse experiences to solve problems.</p></li>
<li><p><strong>Developing Range:</strong></p>
<ul>
<li><strong>Sampling Period:</strong> Encourage trying new activities without pressure to commit long-term.</li>
<li><strong>Unstructured Play:</strong> Foster imagination, creativity, and autonomy through play without predefined goals or adult direction.</li>
<li><strong>Self-Reflection:</strong> Prompt reflection on experiences to identify preferences, strengths, and areas for growth.</li>
<li><strong>Diverse Learning Diet:</strong> Expose children to various subjects, cultures, and ways of thinking through books, museums, travel, etc.</li>
</ul></li>
</ul>
</section>
<section id="discovering-specific-knowledge" class="level4">
<h4 class="anchored" data-anchor-id="discovering-specific-knowledge">Discovering Specific Knowledge:</h4>
<ul>
<li><strong>Definition:</strong> The unique combination of traits, experiences, and passions that allow an individual to make a unique contribution to the world.</li>
<li><strong>Identifying Specific Knowledge:</strong>
<ul>
<li><strong>Observe Natural Abilities:</strong> Pay attention to activities children excel at effortlessly or find intrinsically rewarding.</li>
<li><strong>Explore Passions:</strong> Encourage deep dives into subjects that spark their curiosity and enthusiasm.</li>
<li><strong>Embrace Late Blooming:</strong> Recognize that specific knowledge often emerges over time through exploration and experimentation.</li>
</ul></li>
</ul>
</section>
<section id="helping-kids-develop-specific-knowledge" class="level4">
<h4 class="anchored" data-anchor-id="helping-kids-develop-specific-knowledge">Helping Kids Develop Specific Knowledge:</h4>
<ul>
<li><strong>Focus on Play, Not Pressure:</strong> Avoid forcing specific knowledge; it should arise organically from genuine interest and enjoyment.</li>
<li><strong>Encourage Exploration:</strong> Provide space, resources, and support for children to pursue their passions.</li>
<li><strong>Guide, Don’t Control:</strong> Offer gentle guidance and mentorship without dictating their path.</li>
<li><strong>Build a Strong Foundation:</strong> Ensure a broad base of knowledge and skills (range) to provide context and fuel for discovering specific knowledge.</li>
</ul>
</section>
</section>
<section id="chapter-17-the-art-of-failing-and-quitting" class="level3">
<h3 class="anchored" data-anchor-id="chapter-17-the-art-of-failing-and-quitting">Chapter 17: The Art of Failing and Quitting</h3>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.johnholtgws.com/shop/p/how-children-fail">How Children Fail</a></li>
</ul>
</div>
</div>
<section id="the-art-of-failure" class="level4">
<h4 class="anchored" data-anchor-id="the-art-of-failure">The Art of Failure:</h4>
<ul>
<li><strong>Reframing Failure:</strong> Shift from viewing failure as negative to seeing it as a necessary step in the learning process.</li>
<li><strong>Benefits of Embracing Failure:</strong>
<ul>
<li><strong>Innovation and Progress:</strong> Failure often precedes breakthroughs and discoveries.</li>
<li><strong>Learning from Mistakes:</strong> Analyzing failures helps us refine our approaches and make better decisions in the future.</li>
</ul></li>
<li><strong>Encouraging Constructive Failure:</strong>
<ul>
<li><strong>Provide Opportunities for Small Failures:</strong> Create safe spaces for experimentation and risk-taking.</li>
<li><strong>Celebrate Failure as a Learning Experience:</strong> Encourage reflection and identify takeaways from setbacks.</li>
<li><strong>Model Healthy Self-Talk:</strong> Demonstrate positive self-talk and reframing negative thoughts after setbacks.</li>
<li><strong>Share Personal Failures:</strong> Show vulnerability by openly discussing your own experiences with failure.</li>
<li><strong>Highlight Stories of Resilience:</strong> Emphasize that many successful people overcame significant failures.</li>
</ul></li>
</ul>
</section>
<section id="the-art-of-quitting" class="level4">
<h4 class="anchored" data-anchor-id="the-art-of-quitting">The Art of Quitting:</h4>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Talk:</strong> <a href="https://www.youtube.com/watch?v=D73mm29XXAw">Prof Deepak Malhotra - HBS - 2012 Speech to Graduating Harvard MBA Students</a></li>
</ul>
</div>
</div></li>
<li><p><strong>Rethinking Quitting:</strong> Recognize quitting as a valuable tool for redirecting effort towards more fulfilling and impactful pursuits.</p></li>
<li><p><strong>Benefits of Quitting:</strong></p>
<ul>
<li><strong>Time Management:</strong> Free up time and energy to focus on activities that align with strengths and passions.</li>
<li><strong>Pursuing Specific Knowledge:</strong> Allowing children to disengage from unfulfilling activities helps them hone in on their unique talents.</li>
</ul></li>
<li><p><strong>Developing Healthy Quitting Habits:</strong></p>
<ul>
<li><strong>Establish Clear Quitting Principles:</strong> Help children differentiate between valid and invalid reasons for quitting (e.g., lack of interest vs.&nbsp;temporary difficulty).</li>
<li><strong>Encourage Reflection:</strong> Guide them to reflect on their experiences and articulate their reasons for wanting to quit.</li>
<li><strong>Support Decision-Making:</strong> Empower children to make informed choices about continuing or quitting activities.</li>
</ul></li>
</ul>
</section>
<section id="the-one-question-to-avoid" class="level4">
<h4 class="anchored" data-anchor-id="the-one-question-to-avoid">The One Question to Avoid:</h4>
<ul>
<li><strong>“What do you want to be when you grow up?”:</strong> This question is limiting, outdated, and potentially harmful.</li>
<li><strong>Why It’s Problematic:</strong>
<ul>
<li><strong>Fixed Mindset:</strong> Implies a single, predetermined path and discourages exploration.</li>
<li><strong>Limited Vision:</strong> Many future jobs haven’t been invented yet, and children’s interests evolve over time.</li>
<li><strong>Single Identity:</strong> People often have multiple careers and passions throughout their lives.</li>
</ul></li>
</ul>
</section>
<section id="better-alternatives" class="level4">
<h4 class="anchored" data-anchor-id="better-alternatives">Better Alternatives:</h4>
<ul>
<li><p><strong>“What do you love to do?”:</strong> Focus on uncovering passions and interests rather than job titles.</p></li>
<li><p><strong>“What are you curious about?”</strong>: Encourage exploration and a love of learning.</p></li>
<li><p><strong>Present Careers as Actions:</strong> Frame careers as verbs (things people do) instead of nouns (fixed identities).</p>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://adamgrant.net/book/think-again/">Think Again: The Power of Knowing What You Don’t Know</a></li>
</ul>
</div>
</div></li>
</ul></li>
</ul>
</section>
</section>
<section id="conclusion-1" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-1">Conclusion</h3>
<p>Raising successful children requires a shift from traditional models. We must empower children to face challenges, make decisions, and develop resilience through skin in the game. Parents should actively engage in their children’s education, guiding them to cultivate both range and specific knowledge. By embracing failure and quitting as valuable learning opportunities, we can help children discover their passions, hone their unique talents, and ultimately lead fulfilling and impactful lives.</p>
</section>
</section>
<section id="part-5-the-model-parent" class="level2">
<h2 class="anchored" data-anchor-id="part-5-the-model-parent">Part 5: The Model Parent</h2>
<section id="chapter-18-mental-models-for-parents" class="level3">
<h3 class="anchored" data-anchor-id="chapter-18-mental-models-for-parents">Chapter 18: Mental Models for Parents</h3>
<p>This chapter emphasizes the power of <strong>mental models</strong> in parenting.</p>
<p><strong>What are mental models?</strong></p>
<ul>
<li>Mental models are generalized rules of thumb about how the world works, helping us make sense of our experiences.</li>
<li>They act like maps, enabling us to connect information, recognize patterns, and gain a broader perspective for better decision-making.</li>
<li>Mental models are essential for clear, rational, and effective thinking, and they are relevant in various disciplines.</li>
<li>We need a diverse set of mental models from multiple disciplines to understand and navigate the complexities of life.</li>
</ul>
<p><strong>Why are mental models important for parents?</strong></p>
<ul>
<li>Parenting presents constantly evolving challenges with children’s ever-changing needs and an overwhelming amount of (often conflicting) advice.</li>
<li>Mental models provide a framework for processing information, evaluating options, and responding effectively to children’s behavior.</li>
</ul>
<p><strong>Five Mental Models for Parents:</strong></p>
<ol type="1">
<li><strong>Maslow’s Hammer:</strong> Avoid relying on a single parenting tactic (like a hammer seeing every problem as a nail). Children need diverse approaches as they grow and face new challenges.</li>
<li><strong>Reactance:</strong> Recognize that pressure often breeds resistance. Giving children autonomy and choices, rather than imposing our will, can be more effective.</li>
<li><strong>Nudges:</strong> Instead of just lecturing, create environments that naturally nudge children toward positive choices. For example, make healthy snacks more accessible than unhealthy ones.</li>
<li><strong>Reframing:</strong> Help children reframe challenges by shifting their perspective. Encourage them to find positive aspects or opportunities within difficult situations.</li>
<li><strong>Inversion:</strong> Teach children to approach problems by considering the opposite perspective (what they <em>don’t</em> want), then work backward to identify desirable actions.</li>
</ol>
<p><strong>Building Your Own Mental Models:</strong></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong><a href="https://fs.blog/">Farnham Street</a>:</strong> Organization offering resources and a course on mental models, including those relevant to parenting.
<ul>
<li><strong>Article:</strong> <a href="https://fs.blog/mental-models/">Mental Models: The Best Way to Make Intelligent Decisions (~100 Models Explained)</a></li>
</ul></li>
<li><strong>Superthinking by Gabriel Weinberg and Loring McCann:</strong> Book exploring over 100 mental models and their practical applications.
<ul>
<li><strong>Book:</strong> <a href="https://www.penguinrandomhouse.com/books/562923/super-thinking-by-gabriel-weinberg-and-lauren-mccann/">Super Thinking: The Big Book of Mental Models</a></li>
</ul></li>
</ul>
</div>
</div>
<ul>
<li><p><strong>Practice:</strong> Observe your child’s behavior for patterns, connect the dots with past experiences, and identify recurring themes.</p></li>
<li><p><strong>Document:</strong> Keep notes on your child’s behavior and your responses to recognize long-term trends and develop child-specific mental models.</p></li>
<li><p><strong>Use Checklists:</strong> Create checklists of strategies for common challenges, experiment to find what works, and update them as your child grows.</p></li>
</ul>
</section>
<section id="chapter-19-the-thinking-toolkit" class="level3">
<h3 class="anchored" data-anchor-id="chapter-19-the-thinking-toolkit">Chapter 19: The Thinking Toolkit</h3>
<p>This chapter argues that good thinking is a skill set anyone can develop. It focuses on three thinking tools:</p>
<section id="the-thinking-hats" class="level4">
<h4 class="anchored" data-anchor-id="the-thinking-hats">The Thinking Hats</h4>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.debono.com/Books/teach-your-child-how-to-think">Teach Your Child How To Think</a></li>
<li><strong>Book:</strong> <a href="https://www.debono.com/Books/six-thinking-hats">Six Thinking Hats</a></li>
</ul>
</div>
</div>
<p>Developed by Edward de Bono, the Six Thinking Hats encourage a well-rounded thinking process:</p>
<ol type="1">
<li><strong>White Hat (Facts):</strong> Focuses on objective information, gathering data, and identifying what’s known and unknown.</li>
<li><strong>Red Hat (Emotions):</strong> Explores feelings, intuitions, and emotional responses related to the situation.</li>
<li><strong>Black Hat (Caution):</strong> Engages in critical thinking, identifying risks, flaws, and potential downsides.</li>
<li><strong>Yellow Hat (Optimism):</strong> Explores the positive aspects, benefits, and potential advantages.</li>
<li><strong>Green Hat (Creativity):</strong> Encourages brainstorming, out-of-the-box thinking, and exploring new possibilities.</li>
<li><strong>Blue Hat (Metacognition):</strong> Oversees the thinking process itself, monitoring progress, managing the use of other hats, and reflecting on the overall approach.</li>
</ol>
<p><strong>Benefits of Using the Six Thinking Hats:</strong></p>
<ul>
<li><strong>Broadened Perspective:</strong> Helps children see situations from multiple angles instead of fixating on a single viewpoint.</li>
<li><strong>Improved Decision-Making:</strong> Encourages consideration of various factors before reaching a conclusion.</li>
<li><strong>Enhanced Creativity:</strong> Promotes the generation of novel ideas and solutions.</li>
<li><strong>Increased Wisdom:</strong> Develops the habit of thoughtful observation, careful consideration, and balanced judgment.</li>
</ul>
</section>
<section id="thinking-in-bets" class="level4">
<h4 class="anchored" data-anchor-id="thinking-in-bets">Thinking in Bets</h4>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.penguinrandomhouse.com/books/552885/thinking-in-bets-by-annie-duke/">Thinking in Bets: Making Smarter Decisions When You Don’t Have All the Facts</a></li>
</ul>
</div>
</div>
<p>This section highlights the importance of probabilistic thinking and making decisions with the understanding that the future is uncertain:</p>
<ul>
<li><strong>Avoid Resulting:</strong> Don’t judge the quality of a decision solely on its outcome, as luck plays a role. Instead, focus on the decision-making process itself.</li>
</ul>
<p><strong>Lessons for Children:</strong></p>
<ol type="1">
<li><strong>Think in Probabilities:</strong> Encourage children to express likelihood in terms of percentages rather than absolutes. Help them understand that multiple outcomes are possible.</li>
<li><strong>Keep an Open Mind:</strong> Promote flexibility and adaptability in thinking. Encourage children to consider various perspectives and be open to changing their minds.</li>
<li><strong>Collaborate:</strong> Facilitate group discussions where children can challenge each other’s thinking, identify biases, and learn from different viewpoints.</li>
<li><strong>Embrace Updates:</strong> Create a safe space for children to reflect on their decisions, acknowledge mistakes, and adjust their beliefs based on new information.</li>
</ol>
</section>
<section id="elastic-thinking" class="level4">
<h4 class="anchored" data-anchor-id="elastic-thinking">Elastic Thinking</h4>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.amazon.com/gp/product/0141987391/">Elastic</a></li>
</ul>
</div>
</div>
<p>This section emphasizes the unique human capacity for creative and adaptable thinking:</p>
<p><strong>Three Types of Thinking:</strong></p>
<ol type="1">
<li><strong>Automatic:</strong> Reflexive responses to stimuli (common to most animals).</li>
<li><strong>Analytical:</strong> Logical, step-by-step reasoning (enhanced through education and practiced by computers).</li>
<li><strong>Elastic:</strong> Creative, spontaneous, and adaptable problem-solving in unfamiliar situations.</li>
</ol>
<p><strong>Cultivating Elastic Thinking in Children:</strong></p>
<ul>
<li><strong>Embrace Novelty:</strong> Move away from the rigid, rule-bound structure of traditional schooling.</li>
<li><strong>Encourage Exploration:</strong> Provide ample opportunities for unstructured play, self-directed projects, and experimentation.</li>
<li><strong>Value the Process:</strong> Focus on the journey of discovery and learning from mistakes rather than just achieving a predetermined outcome.</li>
</ul>
</section>
</section>
</section>
<section id="conclusion-design-your-learning-game" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-design-your-learning-game">Conclusion: Design Your Learning Game</h2>
<p>This section offers guidance for parents seeking to create a more engaging and effective learning environment for their children:</p>
<p><strong>Key Takeaways:</strong></p>
<ol type="1">
<li><strong>Encourage Independence:</strong> Avoid over-instruction; give children the space and resources to figure things out for themselves.</li>
<li><strong>Reframe Failure:</strong> Treat mistakes as valuable learning opportunities, not something to fear.</li>
<li><strong>Provide Meaningful Feedback:</strong> Focus praise on effort, ethics, the learning process, and a growth mindset, rather than just outcomes or innate ability.</li>
<li><strong>Grant Autonomy and Accountability:</strong> Involve children in decision-making, treat them like capable individuals, and trust them with responsibility.</li>
<li><strong>Support Passion Projects:</strong> Encourage children to pursue their own interests and devote time to self-directed learning endeavors.</li>
<li><strong>Expand Assessment Methods:</strong> Move beyond standardized tests and grades; embrace diverse ways for children to demonstrate knowledge and skills.</li>
<li><strong>Unlock Intrinsic Motivation:</strong> Minimize reliance on extrinsic rewards; help children discover the joy and satisfaction of learning for its own sake.</li>
<li><strong>Embrace Discomfort:</strong> Teach children to navigate challenges, uncertainty, and the feeling of not fitting in, building resilience.</li>
<li><strong>Allow for Confusion:</strong> Recognize that a healthy dose of confusion can spark curiosity and lead to deeper understanding.</li>
<li><strong>Encourage Questioning:</strong> Cultivate a skeptical mindset; empower children to inquire, seek evidence, and challenge assumptions.</li>
<li><strong>Cherish “Why” Questions:</strong> View these questions as signs of genuine curiosity and a desire to make sense of the world.</li>
<li><strong>Connect with Stories:</strong> Make learning relatable and memorable by tying information to compelling narratives and real-life examples.</li>
<li><strong>Develop Character:</strong> Emphasize ethical decision-making, courage, justice, temperance, and wisdom, drawing inspiration from stories of true heroes.</li>
<li><strong>Go Beyond Memorization:</strong> Focus on understanding concepts, their significance, and how to apply them in real-life scenarios.</li>
<li><strong>Identify and Leverage Strengths:</strong> Help children discover their talents, passions, and learning preferences through exploration and experimentation.</li>
<li><strong>Cultivate Skilled Thinking:</strong> Teach children mental models, critical thinking strategies, and a toolbox of approaches to problem-solving.</li>
<li><strong>Embrace Learning Preferences:</strong> Help children recognize and utilize their preferred learning styles while also expanding their repertoire.</li>
<li><strong>Leverage Video Games:</strong> Recognize the potential of well-designed games to engage children, provide immediate feedback, and teach valuable skills.</li>
<li><strong>Address Online Behavior:</strong> Have open conversations about online habits, finding healthy ways to fulfill the needs met through screen time in the real world.</li>
<li><strong>Gamify Learning (Thoughtfully):</strong> Incorporate game-like elements to make learning more engaging without turning it into a superficial point-gathering system.</li>
<li><strong>Increase Stakes (Safely):</strong> Connect learning to real-world scenarios and challenges, providing a sense of purpose and consequence without life-altering risks.</li>
<li><strong>Engage Deeply:</strong> Be an active participant in your child’s learning journey, understanding their needs, and partnering with them to support their growth.</li>
<li><strong>Utilize Mental Models (Parenting):</strong> Apply the concept of mental models to better understand and respond to your child’s behavior, creating a more harmonious dynamic.</li>
<li><strong>Avoid Overprotection:</strong> Allow your child to face age-appropriate challenges and develop resilience through experience.</li>
<li><strong>Find Balance:</strong> Strive for a balanced approach that encourages both challenge and support, knowing when to push and when to offer guidance and encouragement.</li>
</ol>


</section>

 ]]></description>
  <category>education</category>
  <category>notes</category>
  <guid>https://christianjmills.com/posts/the-learning-game-book-notes/</guid>
  <pubDate>Sat, 03 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Notes on Dumbing Us Down: The Hidden Curriculum of Compulsory Schooling</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/dumbing-us-down-book-notes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
These notes are part of the following collection:
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="../../series/notes/education-notes.html"><strong>Education</strong></a></p>
</div>
</div>
<ul>
<li>Executive Summary</li>
<li>About the Author: John Taylor Gatto<br>
</li>
<li>Chapter 1: The Seven-Lesson Schoolteacher<br>
</li>
<li>Chapter 2: The Psychopathic School<br>
</li>
<li>Chapter 3: The Green Monongahela<br>
</li>
<li>Chapter 4: We Need Less School, Not More<br>
</li>
<li>Chapter 5: The Congregational Principle<br>
</li>
<li>Actionable Recommendations</li>
<li>Glossary</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Book LInks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://newsociety.com/books/d/dumbing-us-down-25th-anniversary-edition">Publisher Page</a></li>
</ul>
</div>
</div>
<section id="executive-summary" class="level2">
<h2 class="anchored" data-anchor-id="executive-summary">Executive Summary</h2>
<p>John Taylor Gatto, a former New York State Teacher of the Year, argues that the American compulsory schooling system is inherently flawed, serving as a tool for social control and economic manipulation rather than genuine education.</p>
<p>He outlines seven harmful lessons instilled in students: confusion, class position, indifference, emotional dependency, intellectual dependency, provisional self-esteem, and constant surveillance.</p>
<p>Gatto advocates for a decentralized, community-based approach to education that prioritizes individual growth, self-reliance, and engagement with the real world, drawing inspiration from the successes of homeschooling and the historical model of colonial New England’s congregational principle.</p>
<p>He calls for radical reform, including decertification of teaching, privatization, and a return to family-centric learning.</p>
</section>
<section id="about-the-author-john-taylor-gatto" class="level2">
<h2 class="anchored" data-anchor-id="about-the-author-john-taylor-gatto">About the Author: John Taylor Gatto</h2>
<section id="personal-background-and-influences" class="level3">
<h3 class="anchored" data-anchor-id="personal-background-and-influences">Personal Background and Influences</h3>
<ul>
<li>Gatto draws from his 30-year experience teaching in diverse NYC schools, from affluent Upper West Side to underprivileged Harlem.</li>
<li>His upbringing in Monongahela, Pennsylvania, a tight-knit, working-class town, instilled in him a strong sense of community and self-reliance.</li>
<li>Contrasting the values of his hometown with the impersonal nature of Manhattan fueled his critical perspective on societal structures.</li>
<li>His grandfather, the town printer and former newspaper publisher, fostered Gatto’s independent thinking and provided valuable life lessons.</li>
</ul>
</section>
<section id="classroom-as-a-laboratory" class="level3">
<h3 class="anchored" data-anchor-id="classroom-as-a-laboratory">Classroom as a Laboratory</h3>
<ul>
<li>Gatto views his classrooms as spaces to observe and study the full spectrum of human potential and the factors that influence its expression.</li>
<li>He challenges the notion of intelligence as a normally distributed trait, having witnessed remarkable abilities in the most unexpected students.</li>
<li>This led him to question if the very structure of schooling, with its rigid schedules, constant monitoring, and lack of autonomy, stifles natural learning.</li>
</ul>
</section>
<section id="guerilla-exercises-to-empower-students" class="level3">
<h3 class="anchored" data-anchor-id="guerilla-exercises-to-empower-students">Guerilla Exercises to Empower Students</h3>
<ul>
<li>Gatto implements unconventional teaching methods that prioritize student freedom and self-directed learning:
<ul>
<li>Provides privacy and reduces surveillance</li>
<li>Offers choices in learning activities</li>
<li>Creates diverse learning environments and social interactions</li>
</ul></li>
<li>He aims to empower students to become their own teachers and shape their own education.</li>
</ul>
</section>
<section id="teaching-as-sculpture-not-painting" class="level3">
<h3 class="anchored" data-anchor-id="teaching-as-sculpture-not-painting">Teaching as Sculpture, Not Painting</h3>
<ul>
<li>Gatto uses the analogy of sculpture to describe his teaching philosophy:
<ul>
<li><strong>Traditional teaching:</strong> Like painting, it focuses on adding information onto a blank canvas (the student’s mind).</li>
<li><strong>Gatto’s approach:</strong> Like sculpting, it involves removing barriers that prevent inherent potential from emerging.</li>
</ul></li>
<li>He shifted away from seeing himself as the expert filling empty vessels to recognizing the innate abilities within each child.</li>
</ul>
</section>
<section id="threats-to-the-system" class="level3">
<h3 class="anchored" data-anchor-id="threats-to-the-system">Threats to the System</h3>
<ul>
<li>Gatto believes his teaching philosophy poses two major threats:
<ul>
<li><strong>To the school system:</strong> It challenges the fundamental assumptions that underpin the institution, such as the perceived difficulty of learning.</li>
<li><strong>To the economy:</strong> It could produce critically thinking individuals who disrupt the existing economic order that relies on conformity and a fixed social hierarchy.</li>
</ul></li>
</ul>
</section>
<section id="principles-of-successful-teaching" class="level3">
<h3 class="anchored" data-anchor-id="principles-of-successful-teaching">Principles of Successful Teaching</h3>
<ul>
<li><strong>Unconditional Trust:</strong> Allowing students to make mistakes and learn from them is crucial for self-mastery.</li>
<li><strong>Challenging Assumptions:</strong> Questioning traditional notions of valuable knowledge and a fulfilling life.</li>
<li><strong>Focus on Individual Paths:</strong> Encouraging students to pursue their own unique interests and truths.</li>
</ul>
</section>
<section id="the-invisible-curriculum-and-its-consequences" class="level3">
<h3 class="anchored" data-anchor-id="the-invisible-curriculum-and-its-consequences">The Invisible Curriculum and its Consequences</h3>
<ul>
<li>Gatto argues that compulsory schooling, despite its stated goals, promotes an “invisible curriculum” that:
<ul>
<li>Reinforces the legitimacy of the institution itself.</li>
<li>Prepares students for a society stratified by social class (caste).</li>
</ul></li>
<li>He acknowledges his own complicity in perpetuating this system, even unintentionally.</li>
</ul>
</section>
<section id="focusing-on-the-wrongs" class="level3">
<h3 class="anchored" data-anchor-id="focusing-on-the-wrongs">Focusing on the Wrongs</h3>
<ul>
<li>Gatto aims to illuminate the flaws of the education system:
<ul>
<li><strong>What he does right:</strong> Getting out of the way of students’ natural curiosity and providing space, time, and respect.</li>
<li><strong>What he does wrong:</strong> Unintentionally reinforcing the hidden curriculum and hindering true learning.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-1-the-seven-lesson-schoolteacher" class="level2">
<h2 class="anchored" data-anchor-id="chapter-1-the-seven-lesson-schoolteacher">Chapter 1: The Seven-Lesson Schoolteacher</h2>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>This chapter stems from Gatto’s 1991 New York State Teacher of the Year acceptance speech, where he ironically highlights the seven damaging lessons he teaches, revealing the hidden curriculum of compulsory schooling.</p>
</section>
<section id="lesson-1-confusion" class="level3">
<h3 class="anchored" data-anchor-id="lesson-1-confusion">Lesson 1: Confusion</h3>
<ul>
<li>Gatto argues that schools teach information out of context, creating a fragmented and disconnected learning experience.</li>
<li>The curriculum lacks coherence and is overloaded with disparate subjects and activities, leaving students feeling overwhelmed and panicked.</li>
<li>The constant exposure to numerous, often unconnected, adults further contributes to confusion.</li>
<li>Schools prioritize superficial jargon over genuine enthusiasm and in-depth understanding.</li>
<li>This systematic confusion conditions students to accept it as their destiny, inhibiting their ability to seek meaning and make connections.</li>
</ul>
</section>
<section id="lesson-2-class-position" class="level3">
<h3 class="anchored" data-anchor-id="lesson-2-class-position">Lesson 2: Class Position</h3>
<ul>
<li>Schools enforce a rigid class system based on academic performance and standardized testing.</li>
<li>Students are numbered and categorized, discouraged from aspiring beyond their assigned class.</li>
<li>Gatto admits to using false promises of upward mobility through test scores to motivate students, perpetuating the illusion of meritocracy.</li>
<li>He acknowledges the incompatibility of truth and school teaching, highlighting how the system reinforces social stratification.</li>
</ul>
</section>
<section id="lesson-3-indifference" class="level3">
<h3 class="anchored" data-anchor-id="lesson-3-indifference">Lesson 3: Indifference</h3>
<ul>
<li>Schools cultivate indifference by demanding enthusiasm during lessons but enforcing detachment at the sound of the bell.</li>
<li>Students are conditioned to switch their emotions on and off, preventing them from fully engaging with any subject.</li>
<li>The bell system signals that no work is worth finishing, fostering a lack of care and follow-through.</li>
<li>This learned indifference prepares students for a world without meaningful work, perpetuating a cycle of apathy.</li>
</ul>
</section>
<section id="lesson-4-emotional-dependency" class="level3">
<h3 class="anchored" data-anchor-id="lesson-4-emotional-dependency">Lesson 4: Emotional Dependency</h3>
<ul>
<li>Schools train students to be emotionally dependent on external authority figures.</li>
<li>Rewards and punishments are used to control behavior and suppress individuality, teaching students to surrender their will to the established hierarchy.</li>
<li>Gatto emphasizes the absence of genuine rights within schools, replaced by privileges granted or revoked at the whim of authority.</li>
<li>This dependency extends to personal decisions, with teachers intervening and dictating acceptable behavior.</li>
</ul>
</section>
<section id="lesson-5-intellectual-dependency" class="level3">
<h3 class="anchored" data-anchor-id="lesson-5-intellectual-dependency">Lesson 5: Intellectual Dependency</h3>
<ul>
<li>The most crucial lesson taught is intellectual dependency, conditioning students to rely on experts for knowledge and meaning.</li>
<li>Students are discouraged from independent thought, learning to passively accept information as presented by teachers.</li>
<li>Curiosity is suppressed, replaced by conformity to prescribed thinking.</li>
<li>This dependency prepares students for a workforce that follows orders without questioning, perpetuating a system reliant on unquestioning obedience.</li>
</ul>
</section>
<section id="lesson-6-provisional-self-esteem" class="level3">
<h3 class="anchored" data-anchor-id="lesson-6-provisional-self-esteem">Lesson 6: Provisional Self-Esteem</h3>
<ul>
<li>Schools link self-esteem to external evaluations, fostering a dependence on expert opinion.</li>
<li>Constant grading, testing, and reporting create a culture of judgment and dissatisfaction, undermining students’ self-worth.</li>
<li>Gatto argues that the system benefits from perpetuating dissatisfaction, mirroring the consumerist economy’s reliance on manufactured needs.</li>
<li>Students are discouraged from trusting their own judgment and that of their parents, relying instead on the pronouncements of certified officials.</li>
</ul>
</section>
<section id="lesson-7-one-cant-hide" class="level3">
<h3 class="anchored" data-anchor-id="lesson-7-one-cant-hide">Lesson 7: One Can’t Hide</h3>
<ul>
<li>Schools create an environment of constant surveillance, denying students privacy and autonomy.</li>
<li>Students are encouraged to tattle on each other and even on their own families, fostering an atmosphere of distrust and suspicion.</li>
<li>Homework extends surveillance into the home, hindering independent learning and family time.</li>
<li>This constant monitoring teaches students that privacy is illegitimate and that authority figures are always watching, preparing them for a society under constant control.</li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>Gatto argues that these seven lessons create a national curriculum that serves the interests of a centralized, hierarchical society at the expense of individual development and genuine education. He contends that this system is structurally unreformable, calling for a fundamental rethinking of educational approaches.</p>
</section>
</section>
<section id="chapter-2-the-psychopathic-school" class="level2">
<h2 class="anchored" data-anchor-id="chapter-2-the-psychopathic-school">Chapter 2: The Psychopathic School</h2>
<section id="introduction-1" class="level3">
<h3 class="anchored" data-anchor-id="introduction-1">Introduction</h3>
<p>This chapter originates from Gatto’s 1990 New York City Teacher of the Year acceptance speech, where he expands on the destructive nature of compulsory schooling and its connection to broader social ills.</p>
</section>
<section id="the-social-crisis-and-the-school-crisis" class="level3">
<h3 class="anchored" data-anchor-id="the-social-crisis-and-the-school-crisis">The Social Crisis and the School Crisis</h3>
<ul>
<li>Gatto links the crisis in American education to a larger social crisis marked by declining educational rankings, high rates of drug addiction, teenage suicide, and marriage instability.</li>
<li>He attributes these problems to a loss of identity and community, highlighting the isolation of children and the elderly from meaningful participation in society.</li>
<li>He criticizes the prevalence of networks over communities, lamenting the lack of genuine connections and the resulting sense of loneliness.</li>
</ul>
</section>
<section id="the-irrelevance-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-irrelevance-of-schooling">The Irrelevance of Schooling</h3>
<ul>
<li>Gatto argues that schools are increasingly irrelevant to the real world, failing to prepare students for the actual demands of various professions.</li>
<li>He emphasizes that schools primarily teach obedience, not critical thinking or practical skills.</li>
<li>He compares the school institution to a psychopath, lacking conscience and prioritizing conformity over individual growth.</li>
</ul>
</section>
<section id="the-origins-of-compulsory-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-origins-of-compulsory-schooling">The Origins of Compulsory Schooling</h3>
<ul>
<li>Gatto traces the origins of compulsory schooling to 19th-century Massachusetts, highlighting the resistance it faced from families who valued individual choice and local control.</li>
<li>He cites evidence suggesting that literacy rates were higher before compulsory schooling was implemented.</li>
<li>He draws parallels with the success of homeschooling, showcasing its ability to foster independent thinking and accelerate learning.</li>
</ul>
</section>
<section id="schooling-vs.-education" class="level3">
<h3 class="anchored" data-anchor-id="schooling-vs.-education">Schooling vs.&nbsp;Education</h3>
<ul>
<li>Gatto distinguishes between schooling and education, asserting that schools are designed for population management, not genuine learning.</li>
<li>He criticizes the school system’s emphasis on producing predictable and controllable individuals, arguing that this renders them irrelevant and useless in a rapidly changing world.</li>
<li>He attributes social problems like drug abuse, mindless competition, and materialism to the dependency and aimlessness fostered by the current educational paradigm.</li>
</ul>
</section>
<section id="the-effects-of-time-deprivation-and-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="the-effects-of-time-deprivation-and-abstraction">The Effects of Time Deprivation and Abstraction</h3>
<ul>
<li>Gatto highlights the limited time available for children to develop their unique identities, with schooling, homework, and television consuming most of their waking hours.</li>
<li>He emphasizes the detrimental effects of abstract learning detached from real-world experience.</li>
<li>He lists specific pathologies resulting from this system, including indifference, lack of curiosity, a poor sense of the future, cruelty, difficulty with intimacy, materialism, dependency, passivity, and timidity.</li>
</ul>
</section>
<section id="a-call-for-change" class="level3">
<h3 class="anchored" data-anchor-id="a-call-for-change">A Call for Change</h3>
<ul>
<li>Gatto calls for a sustained national debate on the purpose and structure of education, urging a move away from top-down control and towards grassroots solutions.</li>
<li>He promotes homeschooling as a viable alternative, advocating for the redirection of funds to family-centric education.</li>
<li>He emphasizes the need to reject the mechanical and anti-human aspects of the current system, returning to a philosophy that prioritizes self-knowledge, family, and community.</li>
</ul>
</section>
</section>
<section id="chapter-3-the-green-monongahela" class="level2">
<h2 class="anchored" data-anchor-id="chapter-3-the-green-monongahela">Chapter 3: The Green Monongahela</h2>
<section id="introduction-2" class="level3">
<h3 class="anchored" data-anchor-id="introduction-2">Introduction</h3>
<p>Gatto reflects on his childhood in Monongahela, Pennsylvania, and how his experiences shaped his philosophy of education.</p>
</section>
<section id="early-education-on-the-river" class="level3">
<h3 class="anchored" data-anchor-id="early-education-on-the-river">Early Education on the River</h3>
<ul>
<li>The Monongahela River served as Gatto’s first classroom, fostering his observation skills and love of nature.</li>
<li>He learned from the diverse people in his community, from riverboat workers to train conductors, absorbing lessons about work, responsibility, and adventure.</li>
<li>These experiences instilled in him a sense of purpose and belonging, contrasting sharply with the sterile environment of institutional schooling.</li>
</ul>
</section>
<section id="leaving-monongahela-and-finding-significance-in-teaching" class="level3">
<h3 class="anchored" data-anchor-id="leaving-monongahela-and-finding-significance-in-teaching">Leaving Monongahela and Finding Significance in Teaching</h3>
<ul>
<li>Gatto recounts his disillusionment with his advertising career, seeking meaning beyond superficial consumerism.</li>
<li>He found his calling as a teacher, drawn to the potential for making a genuine difference in the lives of young people.</li>
<li>He contrasts the sense of purpose he felt in teaching with the emptiness of his corporate job.</li>
</ul>
</section>
<section id="leaving-advertising-for-teaching" class="level3">
<h3 class="anchored" data-anchor-id="leaving-advertising-for-teaching">Leaving Advertising for Teaching</h3>
<ul>
<li>Gatto describes his initial struggles as a substitute teacher in New York City, grappling with challenging working conditions and a lack of support from the system.</li>
<li>He recounts a near-violent encounter with a student, highlighting the chaotic and demoralizing environment of many urban schools.</li>
</ul>
</section>
<section id="milagros-and-the-power-of-a-student" class="level3">
<h3 class="anchored" data-anchor-id="milagros-and-the-power-of-a-student">Milagros and the Power of a Student</h3>
<ul>
<li>Gatto’s perspective shifted when he encountered Milagros, a gifted reader stuck in a low-level class due to bureaucratic indifference.</li>
<li>He championed her cause, challenging the school authorities and ultimately securing her placement in a more appropriate learning environment.</li>
<li>Milagros’ heartfelt expression of gratitude, “A teacher like you cannot be found,” solidified Gatto’s commitment to teaching.</li>
</ul>
</section>
<section id="milagros-accomplishments" class="level3">
<h3 class="anchored" data-anchor-id="milagros-accomplishments">Milagros’ Accomplishments</h3>
<ul>
<li>Gatto learns years later that Milagros went on to become a successful teacher herself, validating his belief in the transformative power of individual encouragement and recognizing potential.</li>
<li>He reflects on the possibility that his intervention served as a catalyst for Milagros, drawing a parallel with the influential figures from his own childhood.</li>
</ul>
</section>
</section>
<section id="chapter-4-we-need-less-school-not-more" class="level2">
<h2 class="anchored" data-anchor-id="chapter-4-we-need-less-school-not-more">Chapter 4: We Need Less School, Not More</h2>
<section id="introduction-3" class="level3">
<h3 class="anchored" data-anchor-id="introduction-3">Introduction</h3>
<p>This chapter delves into the detrimental effects of expanding the scope of institutional schooling, advocating for a reduction in its influence.</p>
</section>
<section id="communities-vs.-networks" class="level3">
<h3 class="anchored" data-anchor-id="communities-vs.-networks">Communities vs.&nbsp;Networks</h3>
<ul>
<li>Gatto distinguishes between communities and networks, emphasizing the vital role of communities in fostering holistic human development.</li>
<li>He argues that networks, while efficient, drain vitality from communities and families, offering temporary, mechanical solutions to complex human problems.</li>
<li>He criticizes the notion of replacing a bad network with a good one, highlighting the inherent limitations of network-based solutions.</li>
</ul>
</section>
<section id="the-limits-of-networks" class="level3">
<h3 class="anchored" data-anchor-id="the-limits-of-networks">The Limits of Networks</h3>
<ul>
<li>Gatto uses the example of weight loss to illustrate the shortcomings of quick-fix, network-driven solutions.</li>
<li>He contrasts the fleeting nature of network relationships with the enduring bonds of family and community.</li>
<li>He criticizes the narrow focus of networks, which require individuals to suppress aspects of their personality, leading to fragmentation and a sense of disconnection.</li>
</ul>
</section>
<section id="the-fragmentation-of-modern-life" class="level3">
<h3 class="anchored" data-anchor-id="the-fragmentation-of-modern-life">The Fragmentation of Modern Life</h3>
<ul>
<li>Gatto argues that excessive networking leads to a fragmented sense of self, with individuals compartmentalizing their lives into specialized roles.</li>
<li>He attributes social problems like divorce and a feeling of being “out of control” to this fragmentation, highlighting the emotional toll of prioritizing network interests.</li>
</ul>
</section>
<section id="the-success-of-homeschooling" class="level3">
<h3 class="anchored" data-anchor-id="the-success-of-homeschooling">The Success of Homeschooling</h3>
<ul>
<li>Gatto champions the success of homeschooling, demonstrating that certified schools are not necessary for acquiring a good education.</li>
<li>He points to the growing homeschooling movement as evidence of a desire for alternatives to the dominant educational paradigm.</li>
<li>He emphasizes that homeschooling allows children to learn in a context that fosters self-reliance and independent thinking.</li>
</ul>
</section>
<section id="schools-as-networks" class="level3">
<h3 class="anchored" data-anchor-id="schools-as-networks">Schools as Networks</h3>
<ul>
<li>Gatto reiterates the distinction between communities and networks, applying this framework to schools.</li>
<li>He criticizes schools for isolating children from the diversity of real life and for imposing artificial structures that stifle individuality.</li>
<li>He argues that schools destroy community vitality by preempting time and energy that could be devoted to building genuine connections.</li>
</ul>
</section>
<section id="schools-destroying-community-vitality" class="level3">
<h3 class="anchored" data-anchor-id="schools-destroying-community-vitality">Schools Destroying Community Vitality</h3>
<ul>
<li>Gatto details specific ways in which schools undermine community and family life:
<ul>
<li>Separating children from the working world and from interaction with different age groups.</li>
<li>Interrupting learning with bells and schedules, devaluing the importance of sustained engagement.</li>
<li>Suppressing individuality and enforcing conformity through rigid rules and punishments.</li>
<li>Fostering competition and envy through grading and ranking systems.</li>
</ul></li>
<li>He concludes that we need less schooling, not more, to allow communities and families to reclaim their vital roles in child development.</li>
</ul>
</section>
<section id="human-beings-beyond-rationality" class="level3">
<h3 class="anchored" data-anchor-id="human-beings-beyond-rationality">Human Beings Beyond Rationality</h3>
<ul>
<li>Gatto challenges the Enlightenment’s emphasis on rationality, arguing that humans are more than just machines and that our deepest needs cannot be met through purely rational systems.</li>
<li>He criticizes the dehumanizing effects of networks, which prioritize efficiency over emotional well-being.</li>
<li>He asserts that networks inherently make people lonely, failing to provide the authentic connections that nourish the human spirit.</li>
</ul>
</section>
<section id="loneliness-in-a-crowd" class="level3">
<h3 class="anchored" data-anchor-id="loneliness-in-a-crowd">Loneliness in a Crowd</h3>
<ul>
<li>Gatto describes the paradoxical experience of feeling lonely even when surrounded by people in network-dominated environments.</li>
<li>He argues that networks, no matter how numerous, cannot substitute for genuine community, leaving individuals feeling isolated and unseen.</li>
<li>He emphasizes the transient nature of network relationships, contrasting them with the enduring bonds of family and community.</li>
</ul>
</section>
<section id="the-natural-order-of-society" class="level3">
<h3 class="anchored" data-anchor-id="the-natural-order-of-society">The Natural Order of Society</h3>
<ul>
<li>Gatto traces the historical development of society, asserting that families came first, followed by communities, and only later by institutions.</li>
<li>He criticizes the modern tendency for institutions to claim authority over families and communities, demanding primary loyalty and dictating how people should live.</li>
<li>He challenges the notion of the state as a surrogate parent, arguing that this undermines the essential role of families in shaping individual values and identity.</li>
</ul>
</section>
<section id="the-destructive-claim-of-institutional-prerogative" class="level3">
<h3 class="anchored" data-anchor-id="the-destructive-claim-of-institutional-prerogative">The Destructive Claim of Institutional Prerogative</h3>
<ul>
<li>Gatto examines the harmful effects of institutional dominance on individuals and families.</li>
<li>He criticizes the narrow focus of institutions, which prioritize specialized performance over holistic development.</li>
<li>He argues that defining success within institutional frameworks leads to alienation from oneself and from others.</li>
</ul>
</section>
<section id="the-united-states-as-a-nation-of-institutions" class="level3">
<h3 class="anchored" data-anchor-id="the-united-states-as-a-nation-of-institutions">The United States as a Nation of Institutions</h3>
<ul>
<li>Gatto laments the transformation of the United States from a nation of communities to a nation of institutions.</li>
<li>He attributes the decline of community life to the isolating effects of large cities and the competition from institutions for the time and attention of citizens.</li>
<li>He points to low voter turnout as evidence of alienation and disengagement from civic life.</li>
</ul>
</section>
<section id="alienation-from-community-life" class="level3">
<h3 class="anchored" data-anchor-id="alienation-from-community-life">Alienation from Community Life</h3>
<ul>
<li>Gatto criticizes the prevalence of “pseudo-communities” – simulated gatherings that lack the genuine connections and shared responsibilities of true communities.</li>
<li>He argues that institutional simulations of community fail to meet fundamental human needs, leading to feelings of isolation and dissatisfaction.</li>
</ul>
</section>
<section id="the-jeopardy-of-human-needs" class="level3">
<h3 class="anchored" data-anchor-id="the-jeopardy-of-human-needs">The Jeopardy of Human Needs</h3>
<ul>
<li>Gatto argues that institutional goals, even when well-intentioned, cannot fully align with the unique needs of individuals.</li>
<li>He emphasizes the lack of conscience in institutions, which operate based on impersonal accounting methods rather than genuine concern for human well-being.</li>
<li>He criticizes the tendency for institutions to prioritize uniformity and control over individual expression and variety.</li>
</ul>
</section>
<section id="the-damage-of-institutional-intervention" class="level3">
<h3 class="anchored" data-anchor-id="the-damage-of-institutional-intervention">The Damage of Institutional Intervention</h3>
<ul>
<li>Gatto warns against the dangers of ceding power to institutions, comparing it to anointing a machine as king.</li>
<li>He emphasizes the pervasive reach of technology, which amplifies the influence of institutions and makes escape from their control increasingly difficult.</li>
</ul>
</section>
<section id="institutional-survival-as-the-primary-goal" class="level3">
<h3 class="anchored" data-anchor-id="institutional-survival-as-the-primary-goal">Institutional Survival as the Primary Goal</h3>
<ul>
<li>Gatto cites the observation of a French sociologist that every institution’s primary goal is its own survival and growth, often overshadowing its stated mission.</li>
<li>He uses the examples of postal services and the military to illustrate this principle, highlighting the tendency for institutions to prioritize the interests of their employees over their intended beneficiaries.</li>
</ul>
</section>
<section id="schools-as-protective-institutions-for-teachers" class="level3">
<h3 class="anchored" data-anchor-id="schools-as-protective-institutions-for-teachers">Schools as Protective Institutions for Teachers</h3>
<ul>
<li>Gatto argues that schools have become protective institutions for teachers, rather than places of learning for students.</li>
<li>He criticizes the New York City public school system for its poor performance despite its vast resources and coercive power.</li>
</ul>
</section>
<section id="freedom-from-institutional-intervention" class="level3">
<h3 class="anchored" data-anchor-id="freedom-from-institutional-intervention">Freedom from Institutional Intervention</h3>
<ul>
<li>Gatto contrasts the liberating atmosphere of communities with limited institutional influence to the stifling environment of urban centers dominated by networks and institutions.</li>
<li>He suggests that freedom from institutional intervention allows for greater self-reliance, community spirit, and individual growth.</li>
</ul>
</section>
<section id="education-as-an-economic-good" class="level3">
<h3 class="anchored" data-anchor-id="education-as-an-economic-good">Education as an Economic Good</h3>
<ul>
<li>Gatto challenges the prevailing view of education as an economic good, arguing that this reinforces a consumerist mindset and perpetuates unsustainable patterns of consumption.</li>
<li>He questions the wisdom of linking educational success to material wealth, considering the social and environmental costs of rampant consumerism.</li>
</ul>
</section>
<section id="the-absurdity-of-economic-education" class="level3">
<h3 class="anchored" data-anchor-id="the-absurdity-of-economic-education">The Absurdity of Economic Education</h3>
<ul>
<li>Gatto exposes the absurdity of equating education with economic advancement, highlighting the emptiness of a life defined by material possessions.</li>
<li>He urges a reevaluation of our priorities, suggesting that genuine education should foster values beyond material acquisition.</li>
</ul>
</section>
<section id="the-true-purpose-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-true-purpose-of-schooling">The True Purpose of Schooling</h3>
<ul>
<li>Gatto questions the true purpose of mass schooling, rejecting the notions that it aims to create a wealthy elite or to prepare students for meaningful work.</li>
<li>He criticizes the system’s reliance on competition, social stratification, and material rewards, arguing that this contradicts the principles of a just and equitable society.</li>
</ul>
</section>
<section id="natural-limits-of-communities" class="level3">
<h3 class="anchored" data-anchor-id="natural-limits-of-communities">Natural Limits of Communities</h3>
<ul>
<li>Gatto contrasts the natural limits of communities with the indefinite expansion of institutions and networks.</li>
<li>He argues that communities foster a sense of belonging and importance because they are small enough for individuals to make a noticeable impact.</li>
<li>He criticizes pseudo-communities for creating a sense of anonymity and alienation, leading to a reliance on consumerism to fulfill basic human needs.</li>
</ul>
</section>
<section id="pseudo-communities" class="level3">
<h3 class="anchored" data-anchor-id="pseudo-communities">Pseudo-Communities</h3>
<ul>
<li>Gatto describes the characteristics of pseudo-communities:
<ul>
<li>Transient relationships and weak bonds.</li>
<li>A tendency to view problems as someone else’s responsibility.</li>
<li>A desire to escape and “trade up” to a supposedly better place.</li>
</ul></li>
<li>He contrasts these with the enduring connections and shared purpose of genuine communities.</li>
</ul>
</section>
<section id="the-indefinite-expansion-of-networks" class="level3">
<h3 class="anchored" data-anchor-id="the-indefinite-expansion-of-networks">The Indefinite Expansion of Networks</h3>
<ul>
<li>Gatto argues that networks, unlike communities, have an inherent tendency to expand indefinitely, fueled by the profit motive of those who benefit from their growth.</li>
<li>He criticizes the push for expanding the scope of schooling, recognizing it as a ploy for increased control and financial gain.</li>
</ul>
</section>
<section id="measuring-success-in-networks" class="level3">
<h3 class="anchored" data-anchor-id="measuring-success-in-networks">Measuring Success in Networks</h3>
<ul>
<li>Gatto contrasts the multifaceted satisfactions of community life with the narrow, quantitative measures of success prevalent in networks.</li>
<li>He criticizes the competitive nature of networks, which pits individuals against each other for material rewards and recognition.</li>
</ul>
</section>
<section id="the-contradictions-of-school-competition" class="level3">
<h3 class="anchored" data-anchor-id="the-contradictions-of-school-competition">The Contradictions of School Competition</h3>
<ul>
<li>Gatto argues that competition within institutions like schools is fundamentally different from competition in the free market.</li>
<li>He points out that school competition is often subjective and arbitrary, leading to envy, dissatisfaction, and a reliance on manipulation rather than genuine effort.</li>
</ul>
</section>
<section id="truth-in-communities-vs.-networks" class="level3">
<h3 class="anchored" data-anchor-id="truth-in-communities-vs.-networks">Truth in Communities vs.&nbsp;Networks</h3>
<ul>
<li>Gatto highlights the importance of honesty in communities, where reputation and trust are paramount.</li>
<li>He contrasts this with the prevalence of lying and deception within institutions, where individuals are often seen as adversaries and manipulation is considered part of the game.</li>
</ul>
</section>
<section id="the-cathedral-of-reims-as-a-model-of-community" class="level3">
<h3 class="anchored" data-anchor-id="the-cathedral-of-reims-as-a-model-of-community">The Cathedral of Reims as a Model of Community</h3>
<ul>
<li>Gatto uses the example of the Cathedral of Reims, built over centuries by a community of skilled artisans, as a testament to the power of shared purpose and uncoerced collaboration.</li>
<li>He emphasizes the absence of individual recognition and self-promotion among the builders, highlighting the collectivist spirit that drove the project.</li>
</ul>
</section>
<section id="the-essence-of-communities" class="level3">
<h3 class="anchored" data-anchor-id="the-essence-of-communities">The Essence of Communities</h3>
<ul>
<li>Gatto defines communities as extensions of family, where individuals find meaning in belonging to a larger group with shared values and responsibilities.</li>
<li>He emphasizes the importance of face-to-face interaction, mutual support, and the acceptance of human variety as essential elements of thriving communities.</li>
</ul>
</section>
<section id="the-allure-of-artificial-integration" class="level3">
<h3 class="anchored" data-anchor-id="the-allure-of-artificial-integration">The Allure of Artificial Integration</h3>
<ul>
<li>Gatto warns against the allure of artificial integration offered by institutions and networks, which promise a sense of belonging but ultimately fail to deliver.</li>
<li>He argues that this artificial integration is superficial and fleeting, leaving individuals feeling isolated and unfulfilled.</li>
</ul>
</section>
<section id="the-new-world-order-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-new-world-order-of-schooling">The New World Order of Schooling</h3>
<ul>
<li>Gatto criticizes proposals to expand the role of schools into providing all-encompassing services, such as meals, therapy, and recreation.</li>
<li>He argues that this “New World Order” of schooling would further weaken families and communities by usurping their traditional functions.</li>
<li>He sees schools as already contributing to the breakdown of family life by isolating children from their parents and undermining their sense of belonging.</li>
</ul>
</section>
<section id="the-maximum-efficiency-of-schools" class="level3">
<h3 class="anchored" data-anchor-id="the-maximum-efficiency-of-schools">The Maximum Efficiency of Schools</h3>
<ul>
<li>Gatto asserts that schools have reached their maximum efficiency, meaning that any further expansion will likely worsen rather than improve outcomes.</li>
<li>He calls for a shift in focus from increasing the scale of schooling to rethinking its fundamental purpose and structure.</li>
</ul>
</section>
<section id="the-true-purpose-of-education" class="level3">
<h3 class="anchored" data-anchor-id="the-true-purpose-of-education">The True Purpose of Education</h3>
<ul>
<li>Gatto outlines his vision for genuine education:
<ul>
<li>Fostering individuality and originality.</li>
<li>Equipping students with the tools to tackle life’s challenges.</li>
<li>Guiding them towards a personal code of values.</li>
<li>Instilling a love of learning and a sense of purpose.</li>
</ul></li>
<li>He argues that mass schooling fails to achieve these goals, prioritizing conformity and obedience over individual development.</li>
</ul>
</section>
<section id="social-engineering-and-the-one-right-way" class="level3">
<h3 class="anchored" data-anchor-id="social-engineering-and-the-one-right-way">Social Engineering and the One Right Way</h3>
<ul>
<li>Gatto criticizes the “one right way” approach to education, arguing that it is based on a flawed theory of social engineering that seeks to control and homogenize individuals.</li>
<li>He advocates for a more decentralized approach that recognizes the diversity of human potential and allows for individual choice.</li>
</ul>
</section>
<section id="the-hive-society" class="level3">
<h3 class="anchored" data-anchor-id="the-hive-society">The Hive Society</h3>
<ul>
<li>Gatto warns against the dangers of creating a “hive society,” where individuality is suppressed and conformity reigns supreme.</li>
<li>He attributes the rise of social pathologies like drug addiction and violence to the stifling effects of institutional control.</li>
</ul>
</section>
<section id="the-flawed-theory-and-structure-of-mass-education" class="level3">
<h3 class="anchored" data-anchor-id="the-flawed-theory-and-structure-of-mass-education">The Flawed Theory and Structure of Mass Education</h3>
<ul>
<li>Gatto reiterates his belief that the current system of mass education is fundamentally flawed and cannot be reformed through incremental changes.</li>
<li>He argues that it undermines the principles of democracy by prioritizing uniformity and control over individual liberty.</li>
</ul>
</section>
<section id="the-cost-of-education-vs.-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-cost-of-education-vs.-schooling">The Cost of Education vs.&nbsp;Schooling</h3>
<ul>
<li>Gatto emphasizes the distinction between education, which is inherently inexpensive and self-directed, and schooling, which is a costly and inefficient system.</li>
<li>He encourages families to reclaim their educational authority and to seek alternatives to the institutional model.</li>
</ul>
</section>
<section id="bertrand-russells-critique-of-american-schooling" class="level3">
<h3 class="anchored" data-anchor-id="bertrand-russells-critique-of-american-schooling">Bertrand Russell’s Critique of American Schooling</h3>
<ul>
<li>Gatto cites Bertrand Russell’s criticism of American schooling, highlighting its anti-democratic tendencies and its production of conformist, uncritical citizens.</li>
<li>He agrees with Russell’s assessment that mass schooling hinders the development of “inner freedom” and creates a shallow, materialistic culture.
<ul>
<li><a href="https://archive.org/stream/in.ernet.dli.2015.139389/2015.139389.The-Basic-Writings-Of-Bertrand-Russell_djvu.txt">The Basic Writings Of Bertrand Russell - The Aims of Education</a></li>
</ul></li>
</ul>
</section>
<section id="american-national-unity-and-the-role-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="american-national-unity-and-the-role-of-schooling">American National Unity and the Role of Schooling</h3>
<ul>
<li>Gatto argues that the quest for national unity has led to misguided attempts to homogenize the population through forced schooling.</li>
<li>He suggests that this approach has backfired, undermining the very values it sought to promote.</li>
</ul>
</section>
<section id="building-families-and-communities" class="level3">
<h3 class="anchored" data-anchor-id="building-families-and-communities">Building Families and Communities</h3>
<ul>
<li>Gatto advocates for a return to strong families and communities as the foundation for a healthy society.</li>
<li>He suggests that rebuilding these units will empower individuals to take charge of their own education and to contribute to the common good.</li>
</ul>
</section>
<section id="breaking-up-institutional-schools" class="level3">
<h3 class="anchored" data-anchor-id="breaking-up-institutional-schools">Breaking Up Institutional Schools</h3>
<ul>
<li>Gatto proposes radical reforms to the schooling system:
<ul>
<li>Decertifying teaching and allowing anyone to compete in the educational marketplace.</li>
<li>Privatizing education and giving families control over their educational choices.</li>
<li>Trusting the free market to deliver diverse and effective learning opportunities.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-5-the-congregational-principle" class="level2">
<h2 class="anchored" data-anchor-id="chapter-5-the-congregational-principle">Chapter 5: The Congregational Principle</h2>
<section id="introduction-4" class="level3">
<h3 class="anchored" data-anchor-id="introduction-4">Introduction</h3>
<p>Gatto explores the history of colonial New England’s Congregationalist movement as a model for a decentralized, community-based approach to education.</p>
</section>
<section id="the-surrealism-of-educational-reform" class="level3">
<h3 class="anchored" data-anchor-id="the-surrealism-of-educational-reform">The Surrealism of Educational Reform</h3>
<ul>
<li>Gatto criticizes the ongoing push for centralized educational reforms, arguing that these proposals ignore the lessons of history and perpetuate a system that has consistently failed to deliver on its promises.</li>
<li>He suggests that the search for “one right answer” to the educational crisis is misguided, advocating for a more pluralistic approach that embraces local control and individual choice.</li>
</ul>
</section>
<section id="colonial-new-england-and-a-different-theory-of-institutions" class="level3">
<h3 class="anchored" data-anchor-id="colonial-new-england-and-a-different-theory-of-institutions">Colonial New England and a Different Theory of Institutions</h3>
<ul>
<li>Gatto contrasts the centralized, top-down approach of modern schooling with the decentralized, community-based model of colonial New England.</li>
<li>He highlights the Congregationalist principle of local autonomy and self-governance, where congregations determined their own affairs without external interference.</li>
</ul>
</section>
<section id="the-salem-procedure" class="level3">
<h3 class="anchored" data-anchor-id="the-salem-procedure">The Salem Procedure</h3>
<ul>
<li>Gatto describes the “Salem Procedure” of 1629, where the First Puritan Church at Salem established the principle of congregational authority.</li>
<li>He emphasizes the significance of this act, which shifted power from certified experts to the members of the congregation themselves.</li>
</ul>
</section>
<section id="localism-and-decentralization" class="level3">
<h3 class="anchored" data-anchor-id="localism-and-decentralization">Localism and Decentralization</h3>
<ul>
<li>Gatto explains how the Congregationalist system fostered localism and decentralization:
<ul>
<li>Each congregation had the freedom to interpret doctrine and to address local issues through open debate among its members.</li>
<li>They took responsibility for their own problems, rather than relying on central authorities for solutions.</li>
</ul></li>
</ul>
</section>
<section id="the-congregational-monopoly" class="level3">
<h3 class="anchored" data-anchor-id="the-congregational-monopoly">The Congregational Monopoly</h3>
<ul>
<li>Gatto acknowledges the irony of the Congregationalists’ initial insistence on religious uniformity, despite their commitment to local control.</li>
<li>He describes their opposition to other denominations, such as Unitarianism, and their attempts to maintain their religious monopoly.</li>
</ul>
</section>
<section id="the-transformation-of-congregationalism" class="level3">
<h3 class="anchored" data-anchor-id="the-transformation-of-congregationalism">The Transformation of Congregationalism</h3>
<ul>
<li>Gatto highlights the remarkable transformation of Congregationalism over time, as it gradually embraced greater tolerance and diversity.</li>
<li>He attributes this evolution to the inherent dynamism of the Congregationalist principle, which allowed for internal debate and self-correction.</li>
</ul>
</section>
<section id="the-dialectical-nature-of-congregationalism" class="level3">
<h3 class="anchored" data-anchor-id="the-dialectical-nature-of-congregationalism">The Dialectical Nature of Congregationalism</h3>
<ul>
<li>Gatto explains how the Congregationalist approach to decision-making resembled the dialectical process, where opposing viewpoints are synthesized to arrive at a more comprehensive understanding.</li>
<li>He argues that this process fostered critical thinking, intellectual growth, and a willingness to adapt to changing circumstances.</li>
</ul>
</section>
<section id="local-choice-and-variety" class="level3">
<h3 class="anchored" data-anchor-id="local-choice-and-variety">Local Choice and Variety</h3>
<ul>
<li>Gatto emphasizes the diversity of local cultures that flourished in colonial New England, despite the initial emphasis on religious conformity.</li>
<li>He uses the examples of Dedham and Sudbury, neighboring towns with distinct economic and social structures, to illustrate the flexibility and adaptability of the Congregationalist system.</li>
</ul>
</section>
<section id="the-necessity-of-exclusion" class="level3">
<h3 class="anchored" data-anchor-id="the-necessity-of-exclusion">The Necessity of Exclusion</h3>
<ul>
<li>Gatto acknowledges the controversial practice of exclusion in colonial New England, where towns often restricted membership to those who shared their values and beliefs.</li>
<li>He argues that this exclusion, while problematic, was necessary to maintain a degree of social cohesion and to allow for the effective functioning of the dialectical process.</li>
</ul>
</section>
<section id="the-paradox-of-local-choice" class="level3">
<h3 class="anchored" data-anchor-id="the-paradox-of-local-choice">The Paradox of Local Choice</h3>
<ul>
<li>Gatto explores the paradoxical nature of local choice, highlighting both its positive and negative aspects.</li>
<li>He acknowledges the potential for local tyranny and exclusion, while emphasizing the crucial role of choice in fostering individual development, community spirit, and democratic values.</li>
</ul>
</section>
<section id="local-knowledge-and-love" class="level3">
<h3 class="anchored" data-anchor-id="local-knowledge-and-love">Local Knowledge and Love</h3>
<ul>
<li>Gatto quotes Wendell Berry’s argument in favor of local knowledge and action, emphasizing the importance of understanding and caring for specific places and people.</li>
<li>He contrasts this with the abstract, global thinking that often leads to destructive interventions based on incomplete information and a lack of genuine connection to the places being affected.</li>
</ul>
</section>
<section id="the-negative-side-of-localism" class="level3">
<h3 class="anchored" data-anchor-id="the-negative-side-of-localism">The Negative Side of Localism</h3>
<ul>
<li>Gatto provides examples of the negative consequences of local control in colonial New England, such as the persecution of Quakers and the exclusion of other religious groups.</li>
<li>He acknowledges the potential for intolerance and discrimination when communities have the power to choose their own members.</li>
</ul>
</section>
<section id="the-mystery-of-congregational-reform" class="level3">
<h3 class="anchored" data-anchor-id="the-mystery-of-congregational-reform">The Mystery of Congregational Reform</h3>
<ul>
<li>Gatto marvels at the ability of Congregationalist communities to reform themselves over time, embracing greater tolerance and diversity without external pressure or legal compulsion.</li>
<li>He attributes this self-correction to the inherent dynamics of the Congregationalist system, which allowed for free debate, dissent, and the natural consequences of poor choices.</li>
</ul>
</section>
<section id="unconditional-local-choice-and-self-correction" class="level3">
<h3 class="anchored" data-anchor-id="unconditional-local-choice-and-self-correction">Unconditional Local Choice and Self-Correction</h3>
<ul>
<li>Gatto argues that the absence of a central orthodoxy and the freedom to “vote with their feet” allowed for a marketplace of ideas in colonial New England.</li>
<li>He suggests that this system naturally rewarded good practices and punished bad ones, leading to a gradual improvement in social conditions.</li>
</ul>
</section>
<section id="the-value-of-choice-and-the-danger-of-central-orthodoxy" class="level3">
<h3 class="anchored" data-anchor-id="the-value-of-choice-and-the-danger-of-central-orthodoxy">The Value of Choice and the Danger of Central Orthodoxy</h3>
<ul>
<li>Gatto emphasizes the importance of choice in fostering a democratic society, arguing that ceding power to central authorities in the name of fairness can ultimately undermine individual liberty and lead to tyranny.</li>
<li>He uses the example of a national curriculum to illustrate the dangers of imposing a single, uniform approach to education, stifling innovation and local adaptation.</li>
</ul>
</section>
<section id="the-failures-of-central-planning" class="level3">
<h3 class="anchored" data-anchor-id="the-failures-of-central-planning">The Failures of Central Planning</h3>
<ul>
<li>Gatto points to the failures of centralized planning in the 20th century, arguing that attempts to legislate social change often have unintended consequences and fail to address the root causes of problems.</li>
<li>He uses examples like affirmative action, desegregation, and drug prohibition to illustrate this point, suggesting that these measures may have exacerbated the very issues they sought to address.</li>
</ul>
</section>
<section id="questionable-victories" class="level3">
<h3 class="anchored" data-anchor-id="questionable-victories">Questionable Victories</h3>
<ul>
<li>Gatto questions the effectiveness of social change imposed through legal coercion, arguing that it often creates resentment and undermines genuine progress.</li>
<li>He suggests that true social change must be rooted in a shift in public consensus, rather than forced compliance.</li>
</ul>
</section>
<section id="the-dangers-of-compulsion" class="level3">
<h3 class="anchored" data-anchor-id="the-dangers-of-compulsion">The Dangers of Compulsion</h3>
<ul>
<li>Gatto warns against the dangers of relying on compulsion to achieve social goals, arguing that it often diminishes the quality of human life and creates a culture of resistance and evasion.</li>
<li>He contrasts this with the effectiveness of voluntary cooperation and self-motivation, which foster a sense of ownership and responsibility.</li>
</ul>
</section>
<section id="the-growth-of-the-school-monopoly" class="level3">
<h3 class="anchored" data-anchor-id="the-growth-of-the-school-monopoly">The Growth of the School Monopoly</h3>
<ul>
<li>Gatto criticizes the unchecked growth of the government school monopoly, which has become increasingly powerful despite its consistent failures to deliver on its promises.</li>
<li>He attributes this growth to the influence of special interest groups, such as teacher colleges, textbook publishers, and educational bureaucrats, who benefit from the status quo.</li>
</ul>
</section>
<section id="the-prohibitions-of-compulsory-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-prohibitions-of-compulsory-schooling">The Prohibitions of Compulsory Schooling</h3>
<ul>
<li>Gatto outlines the numerous prohibitions imposed by compulsory schooling:
<ul>
<li>Limiting educational choices to a narrow range of government-approved options.</li>
<li>Denying parents and communities the freedom to shape their own educational systems.</li>
<li>Stifling innovation and creativity through standardized curricula and testing regimes.</li>
</ul></li>
</ul>
</section>
<section id="the-power-of-the-congregational-principle" class="level3">
<h3 class="anchored" data-anchor-id="the-power-of-the-congregational-principle">The Power of the Congregational Principle</h3>
<ul>
<li>Gatto argues that the Congregationalist principle, even without its religious context, offers a valuable model for a decentralized, community-based approach to education.</li>
<li>He emphasizes the power of small groups working together towards shared goals, fostering individual growth and a sense of belonging.</li>
</ul>
</section>
<section id="learning-from-dedhams-transformation" class="level3">
<h3 class="anchored" data-anchor-id="learning-from-dedhams-transformation">Learning from Dedham’s Transformation</h3>
<ul>
<li>Gatto uses the example of Dedham’s transformation from a religiously intolerant community to a more inclusive one as evidence of the self-correcting nature of the Congregationalist system.</li>
<li>He suggests that allowing for local choice, even with its potential for error, ultimately leads to greater tolerance and understanding.</li>
</ul>
</section>
<section id="the-failure-of-centrally-planned-schools" class="level3">
<h3 class="anchored" data-anchor-id="the-failure-of-centrally-planned-schools">The Failure of Centrally Planned Schools</h3>
<ul>
<li>Gatto reiterates his critique of centrally planned schools, arguing that they cannot adequately address the diverse needs of individuals and communities.</li>
<li>He emphasizes the importance of allowing for local experimentation and adaptation, trusting families and communities to find solutions that work for them.</li>
</ul>
</section>
<section id="two-wrong-ways-to-view-education" class="level3">
<h3 class="anchored" data-anchor-id="two-wrong-ways-to-view-education">Two Wrong Ways to View Education</h3>
<ul>
<li>Gatto identifies two flawed perspectives on education:
<ul>
<li>Viewing it as an engineering problem that can be solved through standardized solutions.</li>
<li>Searching for villains to blame for educational failures, rather than examining the system itself.</li>
</ul></li>
</ul>
</section>
<section id="the-allure-of-quick-fixes" class="level3">
<h3 class="anchored" data-anchor-id="the-allure-of-quick-fixes">The Allure of Quick Fixes</h3>
<ul>
<li>Gatto criticizes the American tendency to seek quick fixes and magical solutions to complex problems, perpetuated by the advertising industry and a culture of instant gratification.</li>
<li>He argues that genuine solutions require a deeper understanding of human nature and a willingness to engage in sustained effort.</li>
</ul>
</section>
<section id="the-mechanical-view-of-human-nature" class="level3">
<h3 class="anchored" data-anchor-id="the-mechanical-view-of-human-nature">The Mechanical View of Human Nature</h3>
<ul>
<li>Gatto challenges the mechanical view of human nature, which reduces individuals to interchangeable parts in a system designed for efficiency and control.</li>
<li>He argues that this perspective ignores the complexity and uniqueness of each human being, ultimately leading to dehumanization and alienation.</li>
</ul>
</section>
<section id="schools-teaching-people-as-machines" class="level3">
<h3 class="anchored" data-anchor-id="schools-teaching-people-as-machines">Schools Teaching People as Machines</h3>
<ul>
<li>Gatto describes how the structure and methodology of modern schooling reinforce the mechanical view of human nature:
<ul>
<li>Bells and schedules dictate the rhythm of the day, treating students like programmable machines.</li>
<li>Grades and rankings reduce complex qualities to numerical scores, devaluing individual expression.</li>
<li>Standardized curricula and testing regimes stifle creativity and independent thinking.</li>
</ul></li>
</ul>
</section>
<section id="the-consequences-of-the-machine-model" class="level3">
<h3 class="anchored" data-anchor-id="the-consequences-of-the-machine-model">The Consequences of the Machine Model</h3>
<ul>
<li>Gatto quotes Octavio Paz’s criticism of the American educational system, which he describes as a “conspiracy” that prevents individuals from fully developing their potential.</li>
<li>He argues that this system creates a culture of dependency and immaturity, leaving people ill-equipped to navigate the complexities of life.</li>
</ul>
</section>
<section id="the-uniform-failure-of-government-schools" class="level3">
<h3 class="anchored" data-anchor-id="the-uniform-failure-of-government-schools">The Uniform Failure of Government Schools</h3>
<ul>
<li>Gatto highlights the consistent failure of government schools to achieve their stated goals, despite decades of reform efforts and vast expenditures.</li>
<li>He argues that this failure is systemic, stemming from the flawed assumptions underlying the model itself.</li>
</ul>
</section>
<section id="looking-to-the-past-for-solutions" class="level3">
<h3 class="anchored" data-anchor-id="looking-to-the-past-for-solutions">Looking to the Past for Solutions</h3>
<ul>
<li>Gatto proposes looking back to the Congregationalist model of colonial New England for inspiration, urging a return to decentralized, community-based approaches to education.</li>
<li>He encourages experimentation and local innovation, trusting families and communities to find solutions that best meet their unique needs.</li>
</ul>
</section>
<section id="embracing-the-congregational-principle" class="level3">
<h3 class="anchored" data-anchor-id="embracing-the-congregational-principle">Embracing the Congregational Principle</h3>
<ul>
<li>Gatto encourages a rediscovery of the Congregationalist principle, adapting its core values to the modern context:
<ul>
<li>Empowering individuals to take charge of their own learning.</li>
<li>Fostering a sense of community and belonging through shared responsibility for education.</li>
<li>Embracing diversity and respecting individual differences.</li>
</ul></li>
</ul>
</section>
<section id="decertifying-learning-and-embracing-competition" class="level3">
<h3 class="anchored" data-anchor-id="decertifying-learning-and-embracing-competition">Decertifying Learning and Embracing Competition</h3>
<ul>
<li>Gatto calls for the decertification of teaching, breaking the monopoly of certified experts and allowing anyone with a passion for education to compete in a free market.</li>
<li>He suggests that this would lead to greater diversity, innovation, and responsiveness to the needs of individual learners.</li>
</ul>
</section>
</section>
<section id="actionable-recommendations" class="level2">
<h2 class="anchored" data-anchor-id="actionable-recommendations">Actionable Recommendations</h2>
<ul>
<li><strong>Decentralize education:</strong> Support initiatives that promote local control, such as charter schools, homeschooling, and community-based learning centers.</li>
<li><strong>Decertify teaching:</strong> Advocate for the removal of mandatory teacher certification, allowing anyone with a passion for education to teach.</li>
<li><strong>Privatize education:</strong> Promote policies that empower families to choose their own educational paths, such as vouchers and tax credits for educational expenses.</li>
<li><strong>Reduce the scope of schooling:</strong> Advocate for shorter school days, shorter school years, and a reduced emphasis on standardized testing, allowing children more time for self-directed learning and family involvement.</li>
<li><strong>Encourage community involvement:</strong> Support programs that integrate children into the life of their communities through apprenticeships, internships, and community service opportunities.</li>
<li><strong>Promote self-knowledge and personal values:</strong> Encourage children to explore their own interests, to develop their own sense of purpose, and to cultivate a personal code of ethics.</li>
<li><strong>Support alternative learning models:</strong> Explore and promote innovative approaches to education, such as Montessori, Waldorf, and unschooling.</li>
<li><strong>Become a saboteur:</strong> Find ways to subvert the oppressive mechanisms of the school system from within, empowering students to think critically and to challenge the status quo.</li>
<li><strong>Join the conversation:</strong> Engage in discussions about education reform with family, friends, community members, and policymakers.</li>
<li><strong>Share Gatto’s work:</strong> Spread awareness of Gatto’s ideas and his critique of forced schooling, encouraging others to question the dominant educational paradigm.</li>
</ul>
</section>
<section id="glossary" class="level2">
<h2 class="anchored" data-anchor-id="glossary">Glossary</h2>
<ul>
<li><strong>Congregational principle:</strong> A system of local self-governance, where communities determine their own affairs without external interference.</li>
<li><strong>Dialectical process:</strong> A method of reasoning that involves synthesizing opposing viewpoints to arrive at a more comprehensive understanding.</li>
<li><strong>Homeschooling:</strong> Educating children at home, typically by parents or guardians, rather than in a formal school setting.</li>
<li><strong>Institutional schooling:</strong> The dominant model of education in modern societies, characterized by centralized control, standardized curricula, and compulsory attendance.</li>
<li><strong>Network:</strong> A system of interconnected individuals or groups, often focused on a specific purpose or interest. Networks tend to be more superficial and transient than communities, with weaker bonds and a narrower range of interaction.</li>
<li><strong>Provisional self-esteem:</strong> A sense of self-worth that is contingent upon external evaluations and the approval of authority figures.</li>
<li><strong>Pseudo-community:</strong> A simulated gathering or association that lacks the genuine connections, shared values, and enduring bonds of a true community.</li>
<li><strong>Social engineering:</strong> The attempt to control and manipulate human behavior through social policies and institutions.</li>
<li><strong>The Seven-Lesson Schoolteacher:</strong> The title of John Taylor Gatto’s essay, in which he outlines seven harmful lessons instilled by the compulsory schooling system: confusion, class position, indifference, emotional dependency, intellectual dependency, provisional self-esteem, and constant surveillance.</li>
<li><strong>The Psychopathic School:</strong> The title of another John Taylor Gatto essay which describes the school system as lacking conscience and serving the interests of a centralized, industrial economy at the expense of individual growth and well-being.</li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>education</category>
  <category>history</category>
  <guid>https://christianjmills.com/posts/dumbing-us-down-book-notes/</guid>
  <pubDate>Sat, 03 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 14: Explaining the Basics of Retrieval Augmented Generation</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-014/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Summary</li>
<li>Demystifying RAG</li>
<li>The Compact MVP: A Simple RAG Implementation</li>
<li>Understanding Bi-Encoders in Vector Search</li>
<li>Improving Retrieval with Re-ranking</li>
<li>Keyword Search</li>
<li>Leveraging Metadata for Targeted Retrieval</li>
<li>Putting it All Together: The Complete MVP++ Pipeline</li>
<li>Beyond the Basics: Future Exploration and Resources</li>
<li>Q&amp;A Session</li>
</ul>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p><a href="https://ben.clavie.eu/">Ben Clavié</a> deconstructs the concept of Retrieval-Augmented Generation (RAG) and guides the audience through building a robust, basic RAG pipeline. He emphasizes that RAG is not a standalone technology, but a pipeline combining retrieval and generation, and each component needs individual attention for optimization. Ben advocates for a “MVP++” approach, incorporating essential elements like bi-encoders, re-ranking, keyword search (TF-IDF/BM25), and metadata filtering for a well-rounded system.</p>
</section>
<section id="demystifying-rag" class="level2">
<h2 class="anchored" data-anchor-id="demystifying-rag">Demystifying RAG</h2>
<ul>
<li><strong>RAG: Overused and Misunderstood</strong>
<ul>
<li>The term “RAG” is often used incorrectly to represent an end-to-end system, creating confusion.</li>
</ul></li>
<li><strong>RAG as a Pipeline: Retrieval + Generation</strong>
<ul>
<li>RAG simply combines retrieval (finding relevant information) and generation (creating text) using Large Language Models (LLMs).</li>
<li>It’s not a single technology, but a pipeline requiring optimization at each stage: retrieval, generation, and their connection.</li>
</ul></li>
<li><strong>Importance of Identifying Specific RAG Issues</strong>
<ul>
<li>“My RAG doesn’t work” is too broad. Pinpointing the failing component (retrieval, LLM utilization) is crucial for debugging.</li>
</ul></li>
</ul>
</section>
<section id="the-compact-mvp-a-simple-rag-implementation" class="level2">
<h2 class="anchored" data-anchor-id="the-compact-mvp-a-simple-rag-implementation">The Compact MVP: A Simple RAG Implementation</h2>
<ul>
<li><strong>Basic Pipeline Components and Flow</strong>
<ul>
<li>Query embedding</li>
<li>Document embedding</li>
<li>Cosine similarity search for relevant documents</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 478.00 336.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 332.8)">
<title>bencoder_approach</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-332.8 474,-332.8 474,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-136C20,-136 450,-136 450,-136 456,-136 462,-142 462,-148 462,-148 462,-272.8 462,-272.8 462,-278.8 456,-284.8 450,-284.8 450,-284.8 20,-284.8 20,-284.8 14,-284.8 8,-278.8 8,-272.8 8,-272.8 8,-148 8,-148 8,-142 14,-136 20,-136"></path>
<text text-anchor="middle" x="235" y="-268.2" font-family="Times,serif" font-size="14.00" fill="red">This is called a 'bi-encoder' approach</text>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M136,-328.8C136,-328.8 106,-328.8 106,-328.8 100,-328.8 94,-322.8 94,-316.8 94,-316.8 94,-304.8 94,-304.8 94,-298.8 100,-292.8 106,-292.8 106,-292.8 136,-292.8 136,-292.8 142,-292.8 148,-298.8 148,-304.8 148,-304.8 148,-316.8 148,-316.8 148,-322.8 142,-328.8 136,-328.8"></path>
<text text-anchor="middle" x="121" y="-306.6" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Embedding_Model -->
<g id="node3" class="node">
<title>Query_Embedding_Model</title>
<path fill="#ffc9c9" stroke="black" d="M169.1,-252C169.1,-252 72.9,-252 72.9,-252 66.9,-252 60.9,-246 60.9,-240 60.9,-240 60.9,-228 60.9,-228 60.9,-222 66.9,-216 72.9,-216 72.9,-216 169.1,-216 169.1,-216 175.1,-216 181.1,-222 181.1,-228 181.1,-228 181.1,-240 181.1,-240 181.1,-246 175.1,-252 169.1,-252"></path>
<text text-anchor="middle" x="121" y="-229.8" font-family="Times,serif" font-size="14.00">Embedding Model</text>
</g>
<!-- Query&#45;&gt;Query_Embedding_Model -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Embedding_Model</title>
<path fill="none" stroke="black" d="M121,-292.45C121,-283.58 121,-272.56 121,-262.56"></path>
<polygon fill="black" stroke="black" points="124.5,-262.25 121,-252.25 117.5,-262.25 124.5,-262.25"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M376.77,-328.8C376.77,-328.8 321.23,-328.8 321.23,-328.8 315.23,-328.8 309.23,-322.8 309.23,-316.8 309.23,-316.8 309.23,-304.8 309.23,-304.8 309.23,-298.8 315.23,-292.8 321.23,-292.8 321.23,-292.8 376.77,-292.8 376.77,-292.8 382.77,-292.8 388.77,-298.8 388.77,-304.8 388.77,-304.8 388.77,-316.8 388.77,-316.8 388.77,-322.8 382.77,-328.8 376.77,-328.8"></path>
<text text-anchor="middle" x="349" y="-306.6" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Embedding_Model -->
<g id="node5" class="node">
<title>Document_Embedding_Model</title>
<path fill="#ffc9c9" stroke="black" d="M397.1,-252C397.1,-252 300.9,-252 300.9,-252 294.9,-252 288.9,-246 288.9,-240 288.9,-240 288.9,-228 288.9,-228 288.9,-222 294.9,-216 300.9,-216 300.9,-216 397.1,-216 397.1,-216 403.1,-216 409.1,-222 409.1,-228 409.1,-228 409.1,-240 409.1,-240 409.1,-246 403.1,-252 397.1,-252"></path>
<text text-anchor="middle" x="349" y="-229.8" font-family="Times,serif" font-size="14.00">Embedding Model</text>
</g>
<!-- Documents&#45;&gt;Document_Embedding_Model -->
<g id="edge3" class="edge">
<title>Documents-&gt;Document_Embedding_Model</title>
<path fill="none" stroke="black" d="M349,-292.45C349,-283.58 349,-272.56 349,-262.56"></path>
<polygon fill="black" stroke="black" points="352.5,-262.25 349,-252.25 345.5,-262.25 352.5,-262.25"></polygon>
</g>
<!-- Query_Embedding_Pooling -->
<g id="node4" class="node">
<title>Query_Embedding_Pooling</title>
<path fill="#ffc9c9" stroke="black" d="M214.41,-180C214.41,-180 27.59,-180 27.59,-180 21.59,-180 15.59,-174 15.59,-168 15.59,-168 15.59,-156 15.59,-156 15.59,-150 21.59,-144 27.59,-144 27.59,-144 214.41,-144 214.41,-144 220.41,-144 226.41,-150 226.41,-156 226.41,-156 226.41,-168 226.41,-168 226.41,-174 220.41,-180 214.41,-180"></path>
<text text-anchor="middle" x="121" y="-157.8" font-family="Times,serif" font-size="14.00">Embedding pooling (into 1 vector)</text>
</g>
<!-- Query_Embedding_Model&#45;&gt;Query_Embedding_Pooling -->
<g id="edge2" class="edge">
<title>Query_Embedding_Model-&gt;Query_Embedding_Pooling</title>
<path fill="none" stroke="black" d="M121,-215.7C121,-207.98 121,-198.71 121,-190.11"></path>
<polygon fill="black" stroke="black" points="124.5,-190.1 121,-180.1 117.5,-190.1 124.5,-190.1"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node7" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M298.8,-108C298.8,-108 171.2,-108 171.2,-108 165.2,-108 159.2,-102 159.2,-96 159.2,-96 159.2,-84 159.2,-84 159.2,-78 165.2,-72 171.2,-72 171.2,-72 298.8,-72 298.8,-72 304.8,-72 310.8,-78 310.8,-84 310.8,-84 310.8,-96 310.8,-96 310.8,-102 304.8,-108 298.8,-108"></path>
<text text-anchor="middle" x="235" y="-85.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Embedding_Pooling&#45;&gt;Cosine_Similarity_Search -->
<g id="edge5" class="edge">
<title>Query_Embedding_Pooling-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M148.89,-143.88C163.79,-134.72 182.33,-123.34 198.38,-113.48"></path>
<polygon fill="black" stroke="black" points="200.31,-116.41 207.01,-108.19 196.65,-110.44 200.31,-116.41"></polygon>
</g>
<!-- Document_Embedding_Pooling -->
<g id="node6" class="node">
<title>Document_Embedding_Pooling</title>
<path fill="#ffc9c9" stroke="black" d="M442.41,-180C442.41,-180 255.59,-180 255.59,-180 249.59,-180 243.59,-174 243.59,-168 243.59,-168 243.59,-156 243.59,-156 243.59,-150 249.59,-144 255.59,-144 255.59,-144 442.41,-144 442.41,-144 448.41,-144 454.41,-150 454.41,-156 454.41,-156 454.41,-168 454.41,-168 454.41,-174 448.41,-180 442.41,-180"></path>
<text text-anchor="middle" x="349" y="-157.8" font-family="Times,serif" font-size="14.00">Embedding pooling (into 1 vector)</text>
</g>
<!-- Document_Embedding_Model&#45;&gt;Document_Embedding_Pooling -->
<g id="edge4" class="edge">
<title>Document_Embedding_Model-&gt;Document_Embedding_Pooling</title>
<path fill="none" stroke="black" d="M349,-215.7C349,-207.98 349,-198.71 349,-190.11"></path>
<polygon fill="black" stroke="black" points="352.5,-190.1 349,-180.1 345.5,-190.1 352.5,-190.1"></polygon>
</g>
<!-- Document_Embedding_Pooling&#45;&gt;Cosine_Similarity_Search -->
<g id="edge6" class="edge">
<title>Document_Embedding_Pooling-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M321.11,-143.88C306.21,-134.72 287.67,-123.34 271.62,-113.48"></path>
<polygon fill="black" stroke="black" points="273.35,-110.44 262.99,-108.19 269.69,-116.41 273.35,-110.44"></polygon>
</g>
<!-- Results -->
<g id="node8" class="node">
<title>Results</title>
<path fill="#b2f3bb" stroke="black" d="M251.73,-36C251.73,-36 218.27,-36 218.27,-36 212.27,-36 206.27,-30 206.27,-24 206.27,-24 206.27,-12 206.27,-12 206.27,-6 212.27,0 218.27,0 218.27,0 251.73,0 251.73,0 257.73,0 263.73,-6 263.73,-12 263.73,-12 263.73,-24 263.73,-24 263.73,-30 257.73,-36 251.73,-36"></path>
<text text-anchor="middle" x="235" y="-13.8" font-family="Times,serif" font-size="14.00">Results</text>
</g>
<!-- Cosine_Similarity_Search&#45;&gt;Results -->
<g id="edge7" class="edge">
<title>Cosine_Similarity_Search-&gt;Results</title>
<path fill="none" stroke="black" d="M235,-71.7C235,-63.98 235,-54.71 235,-46.11"></path>
<polygon fill="black" stroke="black" points="238.5,-46.1 235,-36.1 231.5,-46.1 238.5,-46.1"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<ul>
<li><div class="callout callout-style-default callout-note callout-titled" title="Code Example: Vector Search with NumPy">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Code Example: Vector Search with NumPy
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Demonstrates a basic RAG pipeline without a vector database, emphasizing simplicity.</li>
<li>Uses NumPy for cosine similarity search for demonstration purposes.</li>
</ul>
<div class="sourceCode" id="annotated-cell-2" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the embedding model</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-2-2" class="code-annotation-target"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sentence_transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SentenceTransformer</span>
<span id="annotated-cell-2-3">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SentenceTransformer(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Alibaba-NLP/gte-base-en-v1.5"</span>)</span>
<span id="annotated-cell-2-4"></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-2-5" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fetch some text content...</span></span>
<span id="annotated-cell-2-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> wikipediaapi <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Wikipedia</span>
<span id="annotated-cell-2-7">wiki <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Wikipedia(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RAGBot/0.0'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en'</span>)</span>
<span id="annotated-cell-2-8">doc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wiki.page(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hayao_Miyazaki'</span>).text</span>
<span id="annotated-cell-2-9">paragraphs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> doc.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="annotated-cell-2-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ...And embed it.</span></span>
<span id="annotated-cell-2-11">docs_embed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.encode(paragraphs, normalize_embeddings<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="annotated-cell-2-12"></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-2-13" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Embed the query</span></span>
<span id="annotated-cell-2-14">query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What was Studio Ghibli's first film?"</span></span>
<span id="annotated-cell-2-15">query_embed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.encode(query, normalize_embeddings<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="annotated-cell-2-16"></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-2-17" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Find the 3 closest paragraphs to the query</span></span>
<span id="annotated-cell-2-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="annotated-cell-2-19">similarities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(docs_embed, query_embed.T)</span>
<span id="annotated-cell-2-20">top_3_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> similarities.topk(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>).indices.tolist()</span>
<span id="annotated-cell-2-21">most_similar_documents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [paragraphs[idx] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> idx <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> top_3_idx]</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-2" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="2,3" data-code-annotation="1">Load Bi-Encoder</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="5,6,7,8,9,10,11" data-code-annotation="2">Embed Documents</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="13,14,15" data-code-annotation="3">Embed Query</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="17,18,19,20,21" data-code-annotation="4">Cosine Similarity Search</span>
</dd>
</dl>
</div>
</div></li>
</ul>
</section>
<section id="understanding-bi-encoders-in-vector-search" class="level2">
<h2 class="anchored" data-anchor-id="understanding-bi-encoders-in-vector-search">Understanding Bi-Encoders in Vector Search</h2>
<ul>
<li><p><strong>Vector Databases: When and Why?</strong></p>
<ul>
<li>Useful for efficiently searching large document sets using Approximate Search techniques
<ul>
<li><strong>HNSW</strong>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/1603.09320">Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs</a></li>
<li><strong>Article:</strong> <a href="https://www.pinecone.io/learn/series/faiss/hnsw/">Hierarchical Navigable Small Worlds (HNSW)</a></li>
</ul></li>
<li><strong>IVFPQ</strong>
<ul>
<li><strong>Article:</strong> <a href="https://www.pinecone.io/learn/series/faiss/product-quantization/">Product Quantization: Compressing high-dimensional vectors by 97%</a></li>
</ul></li>
</ul></li>
<li>Not necessary for small datasets (e.g., 500 documents)
<ul>
<li>Modern CPU can search through hundreds of vectors in milliseconds</li>
</ul></li>
</ul></li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 478.00 351.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 347.8)">
<title>bencoder_approach</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-347.8 474,-347.8 474,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-153.8C20,-153.8 450,-153.8 450,-153.8 456,-153.8 462,-159.8 462,-165.8 462,-165.8 462,-266.8 462,-266.8 462,-272.8 456,-278.8 450,-278.8 450,-278.8 20,-278.8 20,-278.8 14,-278.8 8,-272.8 8,-266.8 8,-266.8 8,-165.8 8,-165.8 8,-159.8 14,-153.8 20,-153.8"></path>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M136,-343.8C136,-343.8 106,-343.8 106,-343.8 100,-343.8 94,-337.8 94,-331.8 94,-331.8 94,-319.8 94,-319.8 94,-313.8 100,-307.8 106,-307.8 106,-307.8 136,-307.8 136,-307.8 142,-307.8 148,-313.8 148,-319.8 148,-319.8 148,-331.8 148,-331.8 148,-337.8 142,-343.8 136,-343.8"></path>
<text text-anchor="middle" x="121" y="-321.6" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Embedding_Model -->
<g id="node3" class="node">
<title>Query_Embedding_Model</title>
<path fill="#fddde6" stroke="black" d="M169.1,-270.8C169.1,-270.8 72.9,-270.8 72.9,-270.8 66.9,-270.8 60.9,-264.8 60.9,-258.8 60.9,-258.8 60.9,-246.8 60.9,-246.8 60.9,-240.8 66.9,-234.8 72.9,-234.8 72.9,-234.8 169.1,-234.8 169.1,-234.8 175.1,-234.8 181.1,-240.8 181.1,-246.8 181.1,-246.8 181.1,-258.8 181.1,-258.8 181.1,-264.8 175.1,-270.8 169.1,-270.8"></path>
<text text-anchor="middle" x="121" y="-248.6" font-family="Times,serif" font-size="14.00">Embedding Model</text>
</g>
<!-- Query&#45;&gt;Query_Embedding_Model -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Embedding_Model</title>
<path fill="none" stroke="black" d="M121,-307.61C121,-299.59 121,-289.85 121,-280.87"></path>
<polygon fill="black" stroke="black" points="124.5,-280.83 121,-270.83 117.5,-280.83 124.5,-280.83"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M376.77,-343.8C376.77,-343.8 321.23,-343.8 321.23,-343.8 315.23,-343.8 309.23,-337.8 309.23,-331.8 309.23,-331.8 309.23,-319.8 309.23,-319.8 309.23,-313.8 315.23,-307.8 321.23,-307.8 321.23,-307.8 376.77,-307.8 376.77,-307.8 382.77,-307.8 388.77,-313.8 388.77,-319.8 388.77,-319.8 388.77,-331.8 388.77,-331.8 388.77,-337.8 382.77,-343.8 376.77,-343.8"></path>
<text text-anchor="middle" x="349" y="-321.6" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Embedding_Model -->
<g id="node5" class="node">
<title>Document_Embedding_Model</title>
<path fill="#fddde6" stroke="black" d="M397.1,-270.8C397.1,-270.8 300.9,-270.8 300.9,-270.8 294.9,-270.8 288.9,-264.8 288.9,-258.8 288.9,-258.8 288.9,-246.8 288.9,-246.8 288.9,-240.8 294.9,-234.8 300.9,-234.8 300.9,-234.8 397.1,-234.8 397.1,-234.8 403.1,-234.8 409.1,-240.8 409.1,-246.8 409.1,-246.8 409.1,-258.8 409.1,-258.8 409.1,-264.8 403.1,-270.8 397.1,-270.8"></path>
<text text-anchor="middle" x="349" y="-248.6" font-family="Times,serif" font-size="14.00">Embedding Model</text>
</g>
<!-- Documents&#45;&gt;Document_Embedding_Model -->
<g id="edge3" class="edge">
<title>Documents-&gt;Document_Embedding_Model</title>
<path fill="none" stroke="black" d="M349,-307.61C349,-299.59 349,-289.85 349,-280.87"></path>
<polygon fill="black" stroke="black" points="352.5,-280.83 349,-270.83 345.5,-280.83 352.5,-280.83"></polygon>
</g>
<!-- Query_Embedding_Pooling -->
<g id="node4" class="node">
<title>Query_Embedding_Pooling</title>
<path fill="#fddde6" stroke="black" d="M214.41,-197.8C214.41,-197.8 27.59,-197.8 27.59,-197.8 21.59,-197.8 15.59,-191.8 15.59,-185.8 15.59,-185.8 15.59,-173.8 15.59,-173.8 15.59,-167.8 21.59,-161.8 27.59,-161.8 27.59,-161.8 214.41,-161.8 214.41,-161.8 220.41,-161.8 226.41,-167.8 226.41,-173.8 226.41,-173.8 226.41,-185.8 226.41,-185.8 226.41,-191.8 220.41,-197.8 214.41,-197.8"></path>
<text text-anchor="middle" x="121" y="-175.6" font-family="Times,serif" font-size="14.00">Embedding pooling (into 1 vector)</text>
</g>
<!-- Query_Embedding_Model&#45;&gt;Query_Embedding_Pooling -->
<g id="edge2" class="edge">
<title>Query_Embedding_Model-&gt;Query_Embedding_Pooling</title>
<path fill="none" stroke="black" d="M121,-234.61C121,-226.59 121,-216.85 121,-207.87"></path>
<polygon fill="black" stroke="black" points="124.5,-207.83 121,-197.83 117.5,-207.83 124.5,-207.83"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node7" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M297.8,-109C297.8,-109 170.2,-109 170.2,-109 164.2,-109 158.2,-103 158.2,-97 158.2,-97 158.2,-85 158.2,-85 158.2,-79 164.2,-73 170.2,-73 170.2,-73 297.8,-73 297.8,-73 303.8,-73 309.8,-79 309.8,-85 309.8,-85 309.8,-97 309.8,-97 309.8,-103 303.8,-109 297.8,-109"></path>
<text text-anchor="middle" x="234" y="-86.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Embedding_Pooling&#45;&gt;Cosine_Similarity_Search -->
<g id="edge5" class="edge">
<title>Query_Embedding_Pooling-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M143.33,-161.65C160.58,-148.4 184.65,-129.91 203.66,-115.31"></path>
<polygon fill="black" stroke="black" points="205.92,-117.98 211.72,-109.11 201.66,-112.43 205.92,-117.98"></polygon>
</g>
<!-- Document_Embedding_Pooling -->
<g id="node6" class="node">
<title>Document_Embedding_Pooling</title>
<path fill="#fddde6" stroke="black" d="M442.41,-197.8C442.41,-197.8 255.59,-197.8 255.59,-197.8 249.59,-197.8 243.59,-191.8 243.59,-185.8 243.59,-185.8 243.59,-173.8 243.59,-173.8 243.59,-167.8 249.59,-161.8 255.59,-161.8 255.59,-161.8 442.41,-161.8 442.41,-161.8 448.41,-161.8 454.41,-167.8 454.41,-173.8 454.41,-173.8 454.41,-185.8 454.41,-185.8 454.41,-191.8 448.41,-197.8 442.41,-197.8"></path>
<text text-anchor="middle" x="349" y="-175.6" font-family="Times,serif" font-size="14.00">Embedding pooling (into 1 vector)</text>
</g>
<!-- Document_Embedding_Model&#45;&gt;Document_Embedding_Pooling -->
<g id="edge4" class="edge">
<title>Document_Embedding_Model-&gt;Document_Embedding_Pooling</title>
<path fill="none" stroke="black" d="M349,-234.61C349,-226.59 349,-216.85 349,-207.87"></path>
<polygon fill="black" stroke="black" points="352.5,-207.83 349,-197.83 345.5,-207.83 352.5,-207.83"></polygon>
</g>
<!-- Document_Embedding_Pooling&#45;&gt;Cosine_Similarity_Search -->
<g id="edge6" class="edge">
<title>Document_Embedding_Pooling-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M326.28,-161.65C308.72,-148.4 284.22,-129.91 264.88,-115.31"></path>
<polygon fill="black" stroke="black" points="266.76,-112.34 256.67,-109.11 262.55,-117.93 266.76,-112.34"></polygon>
<text text-anchor="middle" x="359.9" y="-131.2" font-family="Times,serif" font-size="14.00">Vector DB goes here</text>
</g>
<!-- Results -->
<g id="node8" class="node">
<title>Results</title>
<path fill="#b2f3bb" stroke="black" d="M250.73,-36C250.73,-36 217.27,-36 217.27,-36 211.27,-36 205.27,-30 205.27,-24 205.27,-24 205.27,-12 205.27,-12 205.27,-6 211.27,0 217.27,0 217.27,0 250.73,0 250.73,0 256.73,0 262.73,-6 262.73,-12 262.73,-12 262.73,-24 262.73,-24 262.73,-30 256.73,-36 250.73,-36"></path>
<text text-anchor="middle" x="234" y="-13.8" font-family="Times,serif" font-size="14.00">Results</text>
</g>
<!-- Cosine_Similarity_Search&#45;&gt;Results -->
<g id="edge7" class="edge">
<title>Cosine_Similarity_Search-&gt;Results</title>
<path fill="none" stroke="black" d="M234,-72.81C234,-64.79 234,-55.05 234,-46.07"></path>
<polygon fill="black" stroke="black" points="237.5,-46.03 234,-36.03 230.5,-46.03 237.5,-46.03"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<ul>
<li><p><strong>Bi-Encoders: Separate Encoding for Queries and Documents</strong></p>
<ul>
<li>Encode documents and queries independently.</li>
<li>Pre-computed document representations allow for efficient inference, as only the query needs encoding at runtime.</li>
<li>Comes with retrieval performance tradeoffs</li>
</ul></li>
</ul>
</section>
<section id="improving-retrieval-with-re-ranking" class="level2">
<h2 class="anchored" data-anchor-id="improving-retrieval-with-re-ranking">Improving Retrieval with Re-ranking</h2>
<ul>
<li><strong>Bi-Encoder Limitations: Context Unawareness</strong>
<ul>
<li>Bi-encoders encode documents and queries separately, potentially missing nuanced relationships between them.</li>
</ul></li>
<li><strong>Cross-Encoders: Joint Encoding for Better Relevance Scoring</strong>
<ul>
<li>Encode query-document pairs together, allowing for a more context-aware relevance score.</li>
<li>Effectively a binary classifier
<ul>
<li>Uses the probability of being the positive class as the similarity score.</li>
</ul></li>
<li>Computationally expensive for large datasets.</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 406.00 244.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 240.8)">
<title>bi_encoder</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-240.8 402,-240.8 402,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-8C20,-8 378,-8 378,-8 384,-8 390,-14 390,-20 390,-20 390,-216.8 390,-216.8 390,-222.8 384,-228.8 378,-228.8 378,-228.8 20,-228.8 20,-228.8 14,-228.8 8,-222.8 8,-216.8 8,-216.8 8,-20 8,-20 8,-14 14,-8 20,-8"></path>
<text text-anchor="middle" x="199" y="-212.2" font-family="Times,serif" font-size="14.00">Bi-Encoder</text>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M310,-196C310,-196 280,-196 280,-196 274,-196 268,-190 268,-184 268,-184 268,-172 268,-172 268,-166 274,-160 280,-160 280,-160 310,-160 310,-160 316,-160 322,-166 322,-172 322,-172 322,-184 322,-184 322,-190 316,-196 310,-196"></path>
<text text-anchor="middle" x="295" y="-173.8" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Bi_Encoder -->
<g id="node3" class="node">
<title>Query_Bi_Encoder</title>
<path fill="#fddde6" stroke="black" d="M369.58,-124C369.58,-124 220.42,-124 220.42,-124 214.42,-124 208.42,-118 208.42,-112 208.42,-112 208.42,-100 208.42,-100 208.42,-94 214.42,-88 220.42,-88 220.42,-88 369.58,-88 369.58,-88 375.58,-88 381.58,-94 381.58,-100 381.58,-100 381.58,-112 381.58,-112 381.58,-118 375.58,-124 369.58,-124"></path>
<text text-anchor="middle" x="295" y="-101.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Query&#45;&gt;Query_Bi_Encoder -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Bi_Encoder</title>
<path fill="none" stroke="black" d="M295,-159.7C295,-151.98 295,-142.71 295,-134.11"></path>
<polygon fill="black" stroke="black" points="298.5,-134.1 295,-124.1 291.5,-134.1 298.5,-134.1"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M130.77,-196C130.77,-196 75.23,-196 75.23,-196 69.23,-196 63.23,-190 63.23,-184 63.23,-184 63.23,-172 63.23,-172 63.23,-166 69.23,-160 75.23,-160 75.23,-160 130.77,-160 130.77,-160 136.77,-160 142.77,-166 142.77,-172 142.77,-172 142.77,-184 142.77,-184 142.77,-190 136.77,-196 130.77,-196"></path>
<text text-anchor="middle" x="103" y="-173.8" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Bi_Encoder -->
<g id="node4" class="node">
<title>Document_Bi_Encoder</title>
<path fill="#fddde6" stroke="black" d="M177.58,-124C177.58,-124 28.42,-124 28.42,-124 22.42,-124 16.42,-118 16.42,-112 16.42,-112 16.42,-100 16.42,-100 16.42,-94 22.42,-88 28.42,-88 28.42,-88 177.58,-88 177.58,-88 183.58,-88 189.58,-94 189.58,-100 189.58,-100 189.58,-112 189.58,-112 189.58,-118 183.58,-124 177.58,-124"></path>
<text text-anchor="middle" x="103" y="-101.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Documents&#45;&gt;Document_Bi_Encoder -->
<g id="edge2" class="edge">
<title>Documents-&gt;Document_Bi_Encoder</title>
<path fill="none" stroke="black" d="M103,-159.7C103,-151.98 103,-142.71 103,-134.11"></path>
<polygon fill="black" stroke="black" points="106.5,-134.1 103,-124.1 99.5,-134.1 106.5,-134.1"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node5" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M262.8,-52C262.8,-52 135.2,-52 135.2,-52 129.2,-52 123.2,-46 123.2,-40 123.2,-40 123.2,-28 123.2,-28 123.2,-22 129.2,-16 135.2,-16 135.2,-16 262.8,-16 262.8,-16 268.8,-16 274.8,-22 274.8,-28 274.8,-28 274.8,-40 274.8,-40 274.8,-46 268.8,-52 262.8,-52"></path>
<text text-anchor="middle" x="199" y="-29.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge3" class="edge">
<title>Query_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M271.27,-87.7C259.06,-78.8 244.01,-67.82 230.82,-58.2"></path>
<polygon fill="black" stroke="black" points="232.6,-55.17 222.46,-52.1 228.48,-60.82 232.6,-55.17"></polygon>
</g>
<!-- Document_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge4" class="edge">
<title>Document_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M126.73,-87.7C138.94,-78.8 153.99,-67.82 167.18,-58.2"></path>
<polygon fill="black" stroke="black" points="169.52,-60.82 175.54,-52.1 165.4,-55.17 169.52,-60.82"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 192.00 244.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 240.8)">
<title>cross_encoder</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-240.8 188,-240.8 188,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_1</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-8C20,-8 164,-8 164,-8 170,-8 176,-14 176,-20 176,-20 176,-216.8 176,-216.8 176,-222.8 170,-228.8 164,-228.8 164,-228.8 20,-228.8 20,-228.8 14,-228.8 8,-222.8 8,-216.8 8,-216.8 8,-20 8,-20 8,-14 14,-8 20,-8"></path>
<text text-anchor="middle" x="92" y="-212.2" font-family="Times,serif" font-size="14.00">Cross-Encoder</text>
</g>
<!-- Query_2 -->
<g id="node1" class="node">
<title>Query_2</title>
<path fill="#a4d8ff" stroke="black" d="M156,-196C156,-196 126,-196 126,-196 120,-196 114,-190 114,-184 114,-184 114,-172 114,-172 114,-166 120,-160 126,-160 126,-160 156,-160 156,-160 162,-160 168,-166 168,-172 168,-172 168,-184 168,-184 168,-190 162,-196 156,-196"></path>
<text text-anchor="middle" x="141" y="-173.8" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Cross_Encoder -->
<g id="node3" class="node">
<title>Cross_Encoder</title>
<path fill="#fed8a7" stroke="black" d="M129.7,-124C129.7,-124 54.3,-124 54.3,-124 48.3,-124 42.3,-118 42.3,-112 42.3,-112 42.3,-100 42.3,-100 42.3,-94 48.3,-88 54.3,-88 54.3,-88 129.7,-88 129.7,-88 135.7,-88 141.7,-94 141.7,-100 141.7,-100 141.7,-112 141.7,-112 141.7,-118 135.7,-124 129.7,-124"></path>
<text text-anchor="middle" x="92" y="-101.8" font-family="Times,serif" font-size="14.00">Cross-Encoder</text>
</g>
<!-- Query_2&#45;&gt;Cross_Encoder -->
<g id="edge1" class="edge">
<title>Query_2-&gt;Cross_Encoder</title>
<path fill="none" stroke="black" d="M128.89,-159.7C123.13,-151.47 116.14,-141.48 109.79,-132.42"></path>
<polygon fill="black" stroke="black" points="112.58,-130.29 103.97,-124.1 106.84,-134.3 112.58,-130.29"></polygon>
</g>
<!-- Documents_2 -->
<g id="node2" class="node">
<title>Documents_2</title>
<path fill="#feec98" stroke="black" d="M83.77,-196C83.77,-196 28.23,-196 28.23,-196 22.23,-196 16.23,-190 16.23,-184 16.23,-184 16.23,-172 16.23,-172 16.23,-166 22.23,-160 28.23,-160 28.23,-160 83.77,-160 83.77,-160 89.77,-160 95.77,-166 95.77,-172 95.77,-172 95.77,-184 95.77,-184 95.77,-190 89.77,-196 83.77,-196"></path>
<text text-anchor="middle" x="56" y="-173.8" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Documents_2&#45;&gt;Cross_Encoder -->
<g id="edge2" class="edge">
<title>Documents_2-&gt;Cross_Encoder</title>
<path fill="none" stroke="black" d="M64.9,-159.7C69,-151.73 73.95,-142.1 78.49,-133.26"></path>
<polygon fill="black" stroke="black" points="81.74,-134.6 83.2,-124.1 75.52,-131.4 81.74,-134.6"></polygon>
</g>
<!-- Similarity_Score -->
<g id="node4" class="node">
<title>Similarity_Score</title>
<path fill="#b2f3bb" stroke="black" d="M133.88,-52C133.88,-52 50.12,-52 50.12,-52 44.12,-52 38.12,-46 38.12,-40 38.12,-40 38.12,-28 38.12,-28 38.12,-22 44.12,-16 50.12,-16 50.12,-16 133.88,-16 133.88,-16 139.88,-16 145.88,-22 145.88,-28 145.88,-28 145.88,-40 145.88,-40 145.88,-46 139.88,-52 133.88,-52"></path>
<text text-anchor="middle" x="92" y="-29.8" font-family="Times,serif" font-size="14.00">Similarity Score</text>
</g>
<!-- Cross_Encoder&#45;&gt;Similarity_Score -->
<g id="edge3" class="edge">
<title>Cross_Encoder-&gt;Similarity_Score</title>
<path fill="none" stroke="black" d="M92,-87.7C92,-79.98 92,-70.71 92,-62.11"></path>
<polygon fill="black" stroke="black" points="95.5,-62.1 92,-52.1 88.5,-62.1 95.5,-62.1"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<ul>
<li><p><strong>Re-ranking in Practice: Addressing Computational Costs</strong></p>
<ul>
<li>Leverage a powerful but computationally expensive model (like cross-encoders) to score a subset of your documents, previously retrieved by more efficient model</li>
<li><strong>Examples of other re-ranking approaches:</strong>
<ul>
<li><strong><a href="https://github.com/sunnweiwei/RankGPT">RankGPT</a>:</strong> LLMs as Re-Ranking Agent</li>
<li><strong><a href="https://github.com/castorini/rank_llm">RankLLM</a>:</strong> Repository for prompt-decoding using LLMs</li>
</ul></li>
</ul></li>
<li><p><strong><a href="https://github.com/AnswerDotAI/rerankers">rerankers</a>:</strong> A lightweight unified API for various reranking models.</p></li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 406.00 372.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 368.8)">
<title>reranking</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-368.8 402,-368.8 402,4 -4,4"></polygon>
<text text-anchor="middle" x="199" y="-348.2" font-family="Times,serif" font-size="14.00">Compact Pipeline + Reranking</text>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-208C20,-208 378,-208 378,-208 384,-208 390,-214 390,-220 390,-220 390,-248 390,-248 390,-254 384,-260 378,-260 378,-260 20,-260 20,-260 14,-260 8,-254 8,-248 8,-248 8,-220 8,-220 8,-214 14,-208 20,-208"></path>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M118,-324C118,-324 88,-324 88,-324 82,-324 76,-318 76,-312 76,-312 76,-300 76,-300 76,-294 82,-288 88,-288 88,-288 118,-288 118,-288 124,-288 130,-294 130,-300 130,-300 130,-312 130,-312 130,-318 124,-324 118,-324"></path>
<text text-anchor="middle" x="103" y="-301.8" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Bi_Encoder -->
<g id="node3" class="node">
<title>Query_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M177.58,-252C177.58,-252 28.42,-252 28.42,-252 22.42,-252 16.42,-246 16.42,-240 16.42,-240 16.42,-228 16.42,-228 16.42,-222 22.42,-216 28.42,-216 28.42,-216 177.58,-216 177.58,-216 183.58,-216 189.58,-222 189.58,-228 189.58,-228 189.58,-240 189.58,-240 189.58,-246 183.58,-252 177.58,-252"></path>
<text text-anchor="middle" x="103" y="-229.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Query&#45;&gt;Query_Bi_Encoder -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Bi_Encoder</title>
<path fill="none" stroke="black" d="M103,-287.7C103,-279.98 103,-270.71 103,-262.11"></path>
<polygon fill="black" stroke="black" points="106.5,-262.1 103,-252.1 99.5,-262.1 106.5,-262.1"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M322.77,-324C322.77,-324 267.23,-324 267.23,-324 261.23,-324 255.23,-318 255.23,-312 255.23,-312 255.23,-300 255.23,-300 255.23,-294 261.23,-288 267.23,-288 267.23,-288 322.77,-288 322.77,-288 328.77,-288 334.77,-294 334.77,-300 334.77,-300 334.77,-312 334.77,-312 334.77,-318 328.77,-324 322.77,-324"></path>
<text text-anchor="middle" x="295" y="-301.8" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Bi_Encoder -->
<g id="node4" class="node">
<title>Document_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M369.58,-252C369.58,-252 220.42,-252 220.42,-252 214.42,-252 208.42,-246 208.42,-240 208.42,-240 208.42,-228 208.42,-228 208.42,-222 214.42,-216 220.42,-216 220.42,-216 369.58,-216 369.58,-216 375.58,-216 381.58,-222 381.58,-228 381.58,-228 381.58,-240 381.58,-240 381.58,-246 375.58,-252 369.58,-252"></path>
<text text-anchor="middle" x="295" y="-229.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Documents&#45;&gt;Document_Bi_Encoder -->
<g id="edge2" class="edge">
<title>Documents-&gt;Document_Bi_Encoder</title>
<path fill="none" stroke="black" d="M295,-287.7C295,-279.98 295,-270.71 295,-262.11"></path>
<polygon fill="black" stroke="black" points="298.5,-262.1 295,-252.1 291.5,-262.1 298.5,-262.1"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node5" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M262.8,-180C262.8,-180 135.2,-180 135.2,-180 129.2,-180 123.2,-174 123.2,-168 123.2,-168 123.2,-156 123.2,-156 123.2,-150 129.2,-144 135.2,-144 135.2,-144 262.8,-144 262.8,-144 268.8,-144 274.8,-150 274.8,-156 274.8,-156 274.8,-168 274.8,-168 274.8,-174 268.8,-180 262.8,-180"></path>
<text text-anchor="middle" x="199" y="-157.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge3" class="edge">
<title>Query_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M126.73,-215.7C138.94,-206.8 153.99,-195.82 167.18,-186.2"></path>
<polygon fill="black" stroke="black" points="169.52,-188.82 175.54,-180.1 165.4,-183.17 169.52,-188.82"></polygon>
</g>
<!-- Document_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge4" class="edge">
<title>Document_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M271.27,-215.7C259.06,-206.8 244.01,-195.82 230.82,-186.2"></path>
<polygon fill="black" stroke="black" points="232.6,-183.17 222.46,-180.1 228.48,-188.82 232.6,-183.17"></polygon>
</g>
<!-- Reranking -->
<g id="node7" class="node">
<title>Reranking</title>
<path fill="#fed8a7" stroke="black" d="M224.32,-108C224.32,-108 173.68,-108 173.68,-108 167.68,-108 161.68,-102 161.68,-96 161.68,-96 161.68,-84 161.68,-84 161.68,-78 167.68,-72 173.68,-72 173.68,-72 224.32,-72 224.32,-72 230.32,-72 236.32,-78 236.32,-84 236.32,-84 236.32,-96 236.32,-96 236.32,-102 230.32,-108 224.32,-108"></path>
<text text-anchor="middle" x="199" y="-85.8" font-family="Times,serif" font-size="14.00">Reranking</text>
</g>
<!-- Cosine_Similarity_Search&#45;&gt;Reranking -->
<g id="edge5" class="edge">
<title>Cosine_Similarity_Search-&gt;Reranking</title>
<path fill="none" stroke="black" d="M199,-143.7C199,-135.98 199,-126.71 199,-118.11"></path>
<polygon fill="black" stroke="black" points="202.5,-118.1 199,-108.1 195.5,-118.1 202.5,-118.1"></polygon>
</g>
<!-- Results -->
<g id="node6" class="node">
<title>Results</title>
<path fill="#b2f3bb" stroke="black" d="M215.73,-36C215.73,-36 182.27,-36 182.27,-36 176.27,-36 170.27,-30 170.27,-24 170.27,-24 170.27,-12 170.27,-12 170.27,-6 176.27,0 182.27,0 182.27,0 215.73,0 215.73,0 221.73,0 227.73,-6 227.73,-12 227.73,-12 227.73,-24 227.73,-24 227.73,-30 221.73,-36 215.73,-36"></path>
<text text-anchor="middle" x="199" y="-13.8" font-family="Times,serif" font-size="14.00">Results</text>
</g>
<!-- Reranking&#45;&gt;Results -->
<g id="edge6" class="edge">
<title>Reranking-&gt;Results</title>
<path fill="none" stroke="black" d="M199,-71.7C199,-63.98 199,-54.71 199,-46.11"></path>
<polygon fill="black" stroke="black" points="202.5,-46.1 199,-36.1 195.5,-46.1 202.5,-46.1"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="keyword-search" class="level2">
<h2 class="anchored" data-anchor-id="keyword-search">Keyword Search</h2>
<ul>
<li><p>Also called “full-text search”</p></li>
<li><p><strong>Embeddings Are Not Enough: Lossy Compression and Jargon</strong></p>
<ul>
<li>Embeddings compress information, potentially losing details crucial for accurate retrieval, especially with domain-specific jargon and acronyms.</li>
</ul></li>
<li><p><strong>TF-IDF and BM25</strong></p>
<ul>
<li>Emphasizes the importance of incorporating traditional keyword search alongside embedding-based methods.</li>
<li><strong>TF-IDF (Term Frequency-Inverse Document Frequency)</strong>
<ul>
<li>Assigns a weight to words or groups of words based on their rarity</li>
<li><strong>Stanford IR Book:</strong> <a href="https://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html">Inverse document frequency</a></li>
</ul></li>
<li><strong>BM25 (Best-Matching 25)</strong>
<ul>
<li><strong>Wikipedia:</strong> <a href="https://en.wikipedia.org/wiki/Okapi_BM25">Okapi BM25</a></li>
<li><strong>Stanford IR Book:</strong> <a href="https://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html">Okapi BM25: a non-binary model</a></li>
</ul></li>
</ul></li>
<li><p><strong>BM25 Performance and Relevance in Modern Pipelines</strong></p>
<ul>
<li>Highlights BM25’s continued relevance and effectiveness, often outperforming or complementing more complex methods.
<ul>
<li><div class="callout callout-style-default callout-note callout-titled" title="Results Table">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Results Table
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<div style="overflow-x:auto; max-height:500px">
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 4%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 9%">
<col style="width: 10%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th>Model (→) Dataset (↓)</th>
<th>BM25</th>
<th>DeepCT</th>
<th>SPARTA</th>
<th>docT5query</th>
<th>DPR</th>
<th>ANCE</th>
<th>TAS-B</th>
<th>GenQ</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MS MARCO</td>
<td>0.228</td>
<td>0.296‡</td>
<td>0.351‡</td>
<td>0.338‡</td>
<td>0.177</td>
<td>0.388‡</td>
<td>0.408‡</td>
<td>0.408‡</td>
</tr>
<tr class="even">
<td>TREC-COVID</td>
<td>0.656</td>
<td>0.406</td>
<td>0.538</td>
<td>0.713</td>
<td>0.332</td>
<td>0.654</td>
<td>0.481</td>
<td>0.619</td>
</tr>
<tr class="odd">
<td>BioASQ</td>
<td>0.465</td>
<td>0.407</td>
<td>0.351</td>
<td>0.431</td>
<td>0.127</td>
<td>0.306</td>
<td>0.383</td>
<td>0.398</td>
</tr>
<tr class="even">
<td>NFCorpus</td>
<td>0.325</td>
<td>0.283</td>
<td>0.301</td>
<td>0.328</td>
<td>0.189</td>
<td>0.237</td>
<td>0.319</td>
<td>0.319</td>
</tr>
<tr class="odd">
<td>NQ</td>
<td>0.329</td>
<td>0.188</td>
<td>0.398</td>
<td>0.399</td>
<td>0.474‡</td>
<td>0.446</td>
<td>0.463</td>
<td>0.358</td>
</tr>
<tr class="even">
<td>HotpotQA</td>
<td>0.603</td>
<td>0.503</td>
<td>0.492</td>
<td>0.580</td>
<td>0.391</td>
<td>0.456</td>
<td>0.584</td>
<td>0.534</td>
</tr>
<tr class="odd">
<td>FiQA-2018</td>
<td>0.236</td>
<td>0.191</td>
<td>0.198</td>
<td>0.291</td>
<td>0.112</td>
<td>0.295</td>
<td>0.300</td>
<td>0.308</td>
</tr>
<tr class="even">
<td>Signal-1M (RT)</td>
<td>0.330</td>
<td>0.269</td>
<td>0.252</td>
<td>0.307</td>
<td>0.155</td>
<td>0.249</td>
<td>0.289</td>
<td>0.281</td>
</tr>
<tr class="odd">
<td>TREC-NEWS</td>
<td>0.398</td>
<td>0.220</td>
<td>0.258</td>
<td>0.420</td>
<td>0.161</td>
<td>0.382</td>
<td>0.377</td>
<td>0.396</td>
</tr>
<tr class="even">
<td>Robust04</td>
<td>0.408</td>
<td>0.287</td>
<td>0.276</td>
<td>0.437</td>
<td>0.252</td>
<td>0.392</td>
<td>0.427</td>
<td>0.362</td>
</tr>
<tr class="odd">
<td>ArguAna</td>
<td>0.315</td>
<td>0.309</td>
<td>0.279</td>
<td>0.349</td>
<td>0.175</td>
<td>0.415</td>
<td>0.429</td>
<td>0.493</td>
</tr>
<tr class="even">
<td>Touché-2020</td>
<td>0.367</td>
<td>0.156</td>
<td>0.175</td>
<td>0.347</td>
<td>0.131</td>
<td>0.240</td>
<td>0.162</td>
<td>0.182</td>
</tr>
<tr class="odd">
<td>CQADupStack</td>
<td>0.299</td>
<td>0.268</td>
<td>0.257</td>
<td>0.325</td>
<td>0.153</td>
<td>0.296</td>
<td>0.314</td>
<td>0.347</td>
</tr>
<tr class="even">
<td>Quora</td>
<td>0.789</td>
<td>0.691</td>
<td>0.630</td>
<td>0.802</td>
<td>0.248</td>
<td>0.852</td>
<td>0.835</td>
<td>0.830</td>
</tr>
<tr class="odd">
<td>DBPedia</td>
<td>0.313</td>
<td>0.177</td>
<td>0.314</td>
<td>0.331</td>
<td>0.263</td>
<td>0.281</td>
<td>0.384</td>
<td>0.328</td>
</tr>
<tr class="even">
<td>SCIDOCS</td>
<td>0.158</td>
<td>0.124</td>
<td>0.126</td>
<td>0.162</td>
<td>0.077</td>
<td>0.122</td>
<td>0.149</td>
<td>0.143</td>
</tr>
<tr class="odd">
<td>FEVER</td>
<td>0.753</td>
<td>0.353</td>
<td>0.596</td>
<td>0.714</td>
<td>0.562</td>
<td>0.669</td>
<td>0.700</td>
<td>0.669</td>
</tr>
<tr class="even">
<td>Climate-FEVER</td>
<td>0.213</td>
<td>0.066</td>
<td>0.082</td>
<td>0.201</td>
<td>0.148</td>
<td>0.198</td>
<td>0.228</td>
<td>0.175</td>
</tr>
<tr class="odd">
<td>SciFact</td>
<td>0.665</td>
<td>0.630</td>
<td>0.582</td>
<td>0.675</td>
<td>0.318</td>
<td>0.507</td>
<td>0.643</td>
<td>0.644</td>
</tr>
<tr class="even">
<td><strong>Avg. Performance vs.&nbsp;BM25</strong></td>
<td></td>
<td><strong>- 27.9%</strong></td>
<td><strong>- 20.3%</strong></td>
<td><strong>+ 1.6%</strong></td>
<td><strong>- 47.7%</strong></td>
<td><strong>- 7.4%</strong></td>
<td><strong>- 2.8%</strong></td>
<td><strong>- 3.6%</strong></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div></li>
<li><strong>Source:</strong> <a href="https://arxiv.org/abs/2104.08663">BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models</a></li>
</ul></li>
<li>Especially powerful on longer documents and documents containing a lot of domain-specific jargon</li>
<li>Virtually unnoticeable inference-time compute overhead</li>
</ul></li>
</ul>
<section id="the-tf-idf-mvp" class="level3">
<h3 class="anchored" data-anchor-id="the-tf-idf-mvp">The TF-IDF MVP++</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 760.00 404.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 400)">
<title>tfidf_mvp_plusplus</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-400 756,-400 756,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-280C20,-280 378,-280 378,-280 384,-280 390,-286 390,-292 390,-292 390,-320 390,-320 390,-326 384,-332 378,-332 378,-332 20,-332 20,-332 14,-332 8,-326 8,-320 8,-320 8,-292 8,-292 8,-286 14,-280 20,-280"></path>
</g>
<g id="clust2" class="cluster">
<title>cluster_1</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M410,-280C410,-280 732,-280 732,-280 738,-280 744,-286 744,-292 744,-292 744,-320 744,-320 744,-326 738,-332 732,-332 732,-332 410,-332 410,-332 404,-332 398,-326 398,-320 398,-320 398,-292 398,-292 398,-286 404,-280 410,-280"></path>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M335,-396C335,-396 305,-396 305,-396 299,-396 293,-390 293,-384 293,-384 293,-372 293,-372 293,-366 299,-360 305,-360 305,-360 335,-360 335,-360 341,-360 347,-366 347,-372 347,-372 347,-384 347,-384 347,-390 341,-396 335,-396"></path>
<text text-anchor="middle" x="320" y="-373.8" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Bi_Encoder -->
<g id="node3" class="node">
<title>Query_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M177.58,-324C177.58,-324 28.42,-324 28.42,-324 22.42,-324 16.42,-318 16.42,-312 16.42,-312 16.42,-300 16.42,-300 16.42,-294 22.42,-288 28.42,-288 28.42,-288 177.58,-288 177.58,-288 183.58,-288 189.58,-294 189.58,-300 189.58,-300 189.58,-312 189.58,-312 189.58,-318 183.58,-324 177.58,-324"></path>
<text text-anchor="middle" x="103" y="-301.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Query&#45;&gt;Query_Bi_Encoder -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Bi_Encoder</title>
<path fill="none" stroke="black" d="M292.96,-368.28C261.23,-358.04 207.6,-340.74 165.41,-327.13"></path>
<polygon fill="black" stroke="black" points="166.36,-323.76 155.77,-324.02 164.21,-330.42 166.36,-323.76"></polygon>
</g>
<!-- Query_tfidf -->
<g id="node5" class="node">
<title>Query_tfidf</title>
<path fill="#cfbffe" stroke="black" d="M550.34,-324C550.34,-324 417.66,-324 417.66,-324 411.66,-324 405.66,-318 405.66,-312 405.66,-312 405.66,-300 405.66,-300 405.66,-294 411.66,-288 417.66,-288 417.66,-288 550.34,-288 550.34,-288 556.34,-288 562.34,-294 562.34,-300 562.34,-300 562.34,-312 562.34,-312 562.34,-318 556.34,-324 550.34,-324"></path>
<text text-anchor="middle" x="484" y="-301.8" font-family="Times,serif" font-size="14.00">tf-idf (weighted full text)</text>
</g>
<!-- Query&#45;&gt;Query_tfidf -->
<g id="edge3" class="edge">
<title>Query-&gt;Query_tfidf</title>
<path fill="none" stroke="black" d="M347.08,-365.44C370.79,-355.32 405.82,-340.37 434.52,-328.12"></path>
<polygon fill="black" stroke="black" points="436.16,-331.23 443.98,-324.08 433.41,-324.79 436.16,-331.23"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M485.77,-396C485.77,-396 430.23,-396 430.23,-396 424.23,-396 418.23,-390 418.23,-384 418.23,-384 418.23,-372 418.23,-372 418.23,-366 424.23,-360 430.23,-360 430.23,-360 485.77,-360 485.77,-360 491.77,-360 497.77,-366 497.77,-372 497.77,-372 497.77,-384 497.77,-384 497.77,-390 491.77,-396 485.77,-396"></path>
<text text-anchor="middle" x="458" y="-373.8" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Bi_Encoder -->
<g id="node4" class="node">
<title>Document_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M369.58,-324C369.58,-324 220.42,-324 220.42,-324 214.42,-324 208.42,-318 208.42,-312 208.42,-312 208.42,-300 208.42,-300 208.42,-294 214.42,-288 220.42,-288 220.42,-288 369.58,-288 369.58,-288 375.58,-288 381.58,-294 381.58,-300 381.58,-300 381.58,-312 381.58,-312 381.58,-318 375.58,-324 369.58,-324"></path>
<text text-anchor="middle" x="295" y="-301.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Documents&#45;&gt;Document_Bi_Encoder -->
<g id="edge2" class="edge">
<title>Documents-&gt;Document_Bi_Encoder</title>
<path fill="none" stroke="black" d="M418.13,-359.88C395.84,-350.31 367.88,-338.3 344.24,-328.15"></path>
<polygon fill="black" stroke="black" points="345.31,-324.8 334.74,-324.07 342.55,-331.23 345.31,-324.8"></polygon>
</g>
<!-- Document_tfidf -->
<g id="node6" class="node">
<title>Document_tfidf</title>
<path fill="#cfbffe" stroke="black" d="M724.34,-324C724.34,-324 591.66,-324 591.66,-324 585.66,-324 579.66,-318 579.66,-312 579.66,-312 579.66,-300 579.66,-300 579.66,-294 585.66,-288 591.66,-288 591.66,-288 724.34,-288 724.34,-288 730.34,-288 736.34,-294 736.34,-300 736.34,-300 736.34,-312 736.34,-312 736.34,-318 730.34,-324 724.34,-324"></path>
<text text-anchor="middle" x="658" y="-301.8" font-family="Times,serif" font-size="14.00">tf-idf (weighted full text)</text>
</g>
<!-- Documents&#45;&gt;Document_tfidf -->
<g id="edge4" class="edge">
<title>Documents-&gt;Document_tfidf</title>
<path fill="none" stroke="black" d="M497.99,-363C527.15,-352.8 567.1,-338.82 599.79,-327.37"></path>
<polygon fill="black" stroke="black" points="600.96,-330.67 609.24,-324.07 598.64,-324.07 600.96,-330.67"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node7" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M358.8,-252C358.8,-252 231.2,-252 231.2,-252 225.2,-252 219.2,-246 219.2,-240 219.2,-240 219.2,-228 219.2,-228 219.2,-222 225.2,-216 231.2,-216 231.2,-216 358.8,-216 358.8,-216 364.8,-216 370.8,-222 370.8,-228 370.8,-228 370.8,-240 370.8,-240 370.8,-246 364.8,-252 358.8,-252"></path>
<text text-anchor="middle" x="295" y="-229.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge5" class="edge">
<title>Query_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M149.97,-287.88C176.68,-278.14 210.32,-265.87 238.47,-255.61"></path>
<polygon fill="black" stroke="black" points="239.99,-258.78 248.18,-252.07 237.59,-252.21 239.99,-258.78"></polygon>
</g>
<!-- Document_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge6" class="edge">
<title>Document_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M295,-287.7C295,-279.98 295,-270.71 295,-262.11"></path>
<polygon fill="black" stroke="black" points="298.5,-262.1 295,-252.1 291.5,-262.1 298.5,-262.1"></polygon>
</g>
<!-- BM25 -->
<g id="node10" class="node">
<title>BM25</title>
<path fill="#eebefa" stroke="black" d="M546.46,-252C546.46,-252 421.54,-252 421.54,-252 415.54,-252 409.54,-246 409.54,-240 409.54,-240 409.54,-228 409.54,-228 409.54,-222 415.54,-216 421.54,-216 421.54,-216 546.46,-216 546.46,-216 552.46,-216 558.46,-222 558.46,-228 558.46,-228 558.46,-240 558.46,-240 558.46,-246 552.46,-252 546.46,-252"></path>
<text text-anchor="middle" x="484" y="-229.8" font-family="Times,serif" font-size="14.00">BM25 (full-text) search</text>
</g>
<!-- Query_tfidf&#45;&gt;BM25 -->
<g id="edge8" class="edge">
<title>Query_tfidf-&gt;BM25</title>
<path fill="none" stroke="black" d="M484,-287.7C484,-279.98 484,-270.71 484,-262.11"></path>
<polygon fill="black" stroke="black" points="487.5,-262.1 484,-252.1 480.5,-262.1 487.5,-262.1"></polygon>
</g>
<!-- Document_tfidf&#45;&gt;BM25 -->
<g id="edge9" class="edge">
<title>Document_tfidf-&gt;BM25</title>
<path fill="none" stroke="black" d="M615.43,-287.88C591.44,-278.22 561.27,-266.09 535.9,-255.88"></path>
<polygon fill="black" stroke="black" points="537.01,-252.55 526.43,-252.07 534.4,-259.05 537.01,-252.55"></polygon>
</g>
<!-- Combine_Scores -->
<g id="node11" class="node">
<title>Combine_Scores</title>
<path fill="#95f2d7" stroke="black" d="M440.42,-180C440.42,-180 337.58,-180 337.58,-180 331.58,-180 325.58,-174 325.58,-168 325.58,-168 325.58,-156 325.58,-156 325.58,-150 331.58,-144 337.58,-144 337.58,-144 440.42,-144 440.42,-144 446.42,-144 452.42,-150 452.42,-156 452.42,-156 452.42,-168 452.42,-168 452.42,-174 446.42,-180 440.42,-180"></path>
<text text-anchor="middle" x="389" y="-157.8" font-family="Times,serif" font-size="14.00">Combine the scores</text>
</g>
<!-- Cosine_Similarity_Search&#45;&gt;Combine_Scores -->
<g id="edge11" class="edge">
<title>Cosine_Similarity_Search-&gt;Combine_Scores</title>
<path fill="none" stroke="black" d="M318.24,-215.7C330.19,-206.8 344.92,-195.82 357.85,-186.2"></path>
<polygon fill="black" stroke="black" points="360.1,-188.88 366.03,-180.1 355.92,-183.27 360.1,-188.88"></polygon>
</g>
<!-- Results -->
<g id="node8" class="node">
<title>Results</title>
<path fill="#b2f3bb" stroke="black" d="M405.73,-36C405.73,-36 372.27,-36 372.27,-36 366.27,-36 360.27,-30 360.27,-24 360.27,-24 360.27,-12 360.27,-12 360.27,-6 366.27,0 372.27,0 372.27,0 405.73,0 405.73,0 411.73,0 417.73,-6 417.73,-12 417.73,-12 417.73,-24 417.73,-24 417.73,-30 411.73,-36 405.73,-36"></path>
<text text-anchor="middle" x="389" y="-13.8" font-family="Times,serif" font-size="14.00">Results</text>
</g>
<!-- Reranking -->
<g id="node9" class="node">
<title>Reranking</title>
<path fill="#fed8a7" stroke="black" d="M414.32,-108C414.32,-108 363.68,-108 363.68,-108 357.68,-108 351.68,-102 351.68,-96 351.68,-96 351.68,-84 351.68,-84 351.68,-78 357.68,-72 363.68,-72 363.68,-72 414.32,-72 414.32,-72 420.32,-72 426.32,-78 426.32,-84 426.32,-84 426.32,-96 426.32,-96 426.32,-102 420.32,-108 414.32,-108"></path>
<text text-anchor="middle" x="389" y="-85.8" font-family="Times,serif" font-size="14.00">Reranking</text>
</g>
<!-- Reranking&#45;&gt;Results -->
<g id="edge7" class="edge">
<title>Reranking-&gt;Results</title>
<path fill="none" stroke="black" d="M389,-71.7C389,-63.98 389,-54.71 389,-46.11"></path>
<polygon fill="black" stroke="black" points="392.5,-46.1 389,-36.1 385.5,-46.1 392.5,-46.1"></polygon>
</g>
<!-- BM25&#45;&gt;Combine_Scores -->
<g id="edge10" class="edge">
<title>BM25-&gt;Combine_Scores</title>
<path fill="none" stroke="black" d="M460.52,-215.7C448.44,-206.8 433.55,-195.82 420.48,-186.2"></path>
<polygon fill="black" stroke="black" points="422.34,-183.22 412.21,-180.1 418.19,-188.85 422.34,-183.22"></polygon>
</g>
<!-- Combine_Scores&#45;&gt;Reranking -->
<g id="edge12" class="edge">
<title>Combine_Scores-&gt;Reranking</title>
<path fill="none" stroke="black" d="M389,-143.7C389,-135.98 389,-126.71 389,-118.11"></path>
<polygon fill="black" stroke="black" points="392.5,-118.1 389,-108.1 385.5,-118.1 392.5,-118.1"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
</section>
<section id="leveraging-metadata-for-targeted-retrieval" class="level2">
<h2 class="anchored" data-anchor-id="leveraging-metadata-for-targeted-retrieval">Leveraging Metadata for Targeted Retrieval</h2>
<ul>
<li><strong>Real-World Data Has Context: Metadata Matters</strong>
<ul>
<li>Real-world documents often possess valuable metadata (e.g., author, date, department) that can significantly improve retrieval accuracy.</li>
<li>Pure Semantic or Keyword Search can struggle with metadata
<ul>
<li><strong>Example Query:</strong> “Can you get me the cruise division financial report for Q4 2022?”
<ul>
<li>Model must accurately represent all of “ﬁnancial report”, “cruise division”, “Q4” and “2022”, into a single vector
<ul>
<li>Otherwise it will fetch documents that look relevant but aren’t meeting one or more of those criteria.</li>
</ul></li>
<li>If the number of documents you search for (“k”) is set too high, you will be passing irrelevant ﬁnancial reports to your LLM</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Entity Detection and Metadata Filtering: A Practical Example</strong>
<ul>
<li>Use entity detection models like GLiNER to automatically extract relevant metadata (e.g., document type, time period, department).</li>
<li><strong>GLiNER</strong>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2311.08526">GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer</a></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/urchade/GLiNER">GLiNER</a></li>
<li><strong>:hugs: Spaces Demo:</strong> <a href="https://huggingface.co/spaces/tomaarsen/gliner_medium-v2.1">GLiNER-medium-v2.1, zero-shot NER</a></li>
</ul></li>
<li>Filter documents based on extracted metadata to ensure relevance and reduce noise.</li>
</ul></li>
<li><strong>Storing and Using Metadata for Pre-filtering</strong>
<ul>
<li>Store metadata alongside documents in the database.</li>
<li>During retrieval, pre-filter documents based on query-specific metadata to narrow down the search space.</li>
</ul></li>
</ul>
</section>
<section id="putting-it-all-together-the-complete-mvp-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="putting-it-all-together-the-complete-mvp-pipeline">Putting it All Together: The Complete MVP++ Pipeline</h2>
<section id="the-final-compact-mvp" class="level3">
<h3 class="anchored" data-anchor-id="the-final-compact-mvp">The Final Compact MVP++</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 760.00 476.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 472)">
<title>tfidf_mvp_plusplus</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-472 756,-472 756,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-352C20,-352 378,-352 378,-352 384,-352 390,-358 390,-364 390,-364 390,-392 390,-392 390,-398 384,-404 378,-404 378,-404 20,-404 20,-404 14,-404 8,-398 8,-392 8,-392 8,-364 8,-364 8,-358 14,-352 20,-352"></path>
</g>
<g id="clust2" class="cluster">
<title>cluster_1</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M410,-352C410,-352 732,-352 732,-352 738,-352 744,-358 744,-364 744,-364 744,-392 744,-392 744,-398 738,-404 732,-404 732,-404 410,-404 410,-404 404,-404 398,-398 398,-392 398,-392 398,-364 398,-364 398,-358 404,-352 410,-352"></path>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M335,-468C335,-468 305,-468 305,-468 299,-468 293,-462 293,-456 293,-456 293,-444 293,-444 293,-438 299,-432 305,-432 305,-432 335,-432 335,-432 341,-432 347,-438 347,-444 347,-444 347,-456 347,-456 347,-462 341,-468 335,-468"></path>
<text text-anchor="middle" x="320" y="-445.8" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Bi_Encoder -->
<g id="node3" class="node">
<title>Query_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M177.58,-396C177.58,-396 28.42,-396 28.42,-396 22.42,-396 16.42,-390 16.42,-384 16.42,-384 16.42,-372 16.42,-372 16.42,-366 22.42,-360 28.42,-360 28.42,-360 177.58,-360 177.58,-360 183.58,-360 189.58,-366 189.58,-372 189.58,-372 189.58,-384 189.58,-384 189.58,-390 183.58,-396 177.58,-396"></path>
<text text-anchor="middle" x="103" y="-373.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Query&#45;&gt;Query_Bi_Encoder -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Bi_Encoder</title>
<path fill="none" stroke="black" d="M292.96,-440.28C261.23,-430.04 207.6,-412.74 165.41,-399.13"></path>
<polygon fill="black" stroke="black" points="166.36,-395.76 155.77,-396.02 164.21,-402.42 166.36,-395.76"></polygon>
</g>
<!-- Query_tfidf -->
<g id="node5" class="node">
<title>Query_tfidf</title>
<path fill="#cfbffe" stroke="black" d="M550.34,-396C550.34,-396 417.66,-396 417.66,-396 411.66,-396 405.66,-390 405.66,-384 405.66,-384 405.66,-372 405.66,-372 405.66,-366 411.66,-360 417.66,-360 417.66,-360 550.34,-360 550.34,-360 556.34,-360 562.34,-366 562.34,-372 562.34,-372 562.34,-384 562.34,-384 562.34,-390 556.34,-396 550.34,-396"></path>
<text text-anchor="middle" x="484" y="-373.8" font-family="Times,serif" font-size="14.00">tf-idf (weighted full text)</text>
</g>
<!-- Query&#45;&gt;Query_tfidf -->
<g id="edge3" class="edge">
<title>Query-&gt;Query_tfidf</title>
<path fill="none" stroke="black" d="M347.08,-437.44C370.79,-427.32 405.82,-412.37 434.52,-400.12"></path>
<polygon fill="black" stroke="black" points="436.16,-403.23 443.98,-396.08 433.41,-396.79 436.16,-403.23"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M485.77,-468C485.77,-468 430.23,-468 430.23,-468 424.23,-468 418.23,-462 418.23,-456 418.23,-456 418.23,-444 418.23,-444 418.23,-438 424.23,-432 430.23,-432 430.23,-432 485.77,-432 485.77,-432 491.77,-432 497.77,-438 497.77,-444 497.77,-444 497.77,-456 497.77,-456 497.77,-462 491.77,-468 485.77,-468"></path>
<text text-anchor="middle" x="458" y="-445.8" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Bi_Encoder -->
<g id="node4" class="node">
<title>Document_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M369.58,-396C369.58,-396 220.42,-396 220.42,-396 214.42,-396 208.42,-390 208.42,-384 208.42,-384 208.42,-372 208.42,-372 208.42,-366 214.42,-360 220.42,-360 220.42,-360 369.58,-360 369.58,-360 375.58,-360 381.58,-366 381.58,-372 381.58,-372 381.58,-384 381.58,-384 381.58,-390 375.58,-396 369.58,-396"></path>
<text text-anchor="middle" x="295" y="-373.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Documents&#45;&gt;Document_Bi_Encoder -->
<g id="edge2" class="edge">
<title>Documents-&gt;Document_Bi_Encoder</title>
<path fill="none" stroke="black" d="M418.13,-431.88C395.84,-422.31 367.88,-410.3 344.24,-400.15"></path>
<polygon fill="black" stroke="black" points="345.31,-396.8 334.74,-396.07 342.55,-403.23 345.31,-396.8"></polygon>
</g>
<!-- Document_tfidf -->
<g id="node6" class="node">
<title>Document_tfidf</title>
<path fill="#cfbffe" stroke="black" d="M724.34,-396C724.34,-396 591.66,-396 591.66,-396 585.66,-396 579.66,-390 579.66,-384 579.66,-384 579.66,-372 579.66,-372 579.66,-366 585.66,-360 591.66,-360 591.66,-360 724.34,-360 724.34,-360 730.34,-360 736.34,-366 736.34,-372 736.34,-372 736.34,-384 736.34,-384 736.34,-390 730.34,-396 724.34,-396"></path>
<text text-anchor="middle" x="658" y="-373.8" font-family="Times,serif" font-size="14.00">tf-idf (weighted full text)</text>
</g>
<!-- Documents&#45;&gt;Document_tfidf -->
<g id="edge4" class="edge">
<title>Documents-&gt;Document_tfidf</title>
<path fill="none" stroke="black" d="M497.99,-435C527.15,-424.8 567.1,-410.82 599.79,-399.37"></path>
<polygon fill="black" stroke="black" points="600.96,-402.67 609.24,-396.07 598.64,-396.07 600.96,-402.67"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node9" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M358.8,-252C358.8,-252 231.2,-252 231.2,-252 225.2,-252 219.2,-246 219.2,-240 219.2,-240 219.2,-228 219.2,-228 219.2,-222 225.2,-216 231.2,-216 231.2,-216 358.8,-216 358.8,-216 364.8,-216 370.8,-222 370.8,-228 370.8,-228 370.8,-240 370.8,-240 370.8,-246 364.8,-252 358.8,-252"></path>
<text text-anchor="middle" x="295" y="-229.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge7" class="edge">
<title>Query_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M118.05,-359.77C135.33,-340.66 165.15,-309.68 195,-288 211.23,-276.21 230.42,-265.4 247.63,-256.65"></path>
<polygon fill="black" stroke="black" points="249.56,-259.6 256.95,-252.02 246.44,-253.34 249.56,-259.6"></polygon>
</g>
<!-- Metadata_Filtering -->
<g id="node7" class="node">
<title>Metadata_Filtering</title>
<path fill="#d2bab0" stroke="black" d="M373.62,-324C373.62,-324 216.38,-324 216.38,-324 210.38,-324 204.38,-318 204.38,-312 204.38,-312 204.38,-300 204.38,-300 204.38,-294 210.38,-288 216.38,-288 216.38,-288 373.62,-288 373.62,-288 379.62,-288 385.62,-294 385.62,-300 385.62,-300 385.62,-312 385.62,-312 385.62,-318 379.62,-324 373.62,-324"></path>
<text text-anchor="middle" x="295" y="-301.8" font-family="Times,serif" font-size="14.00">Metadata Document Filtering</text>
</g>
<!-- Document_Bi_Encoder&#45;&gt;Metadata_Filtering -->
<g id="edge5" class="edge">
<title>Document_Bi_Encoder-&gt;Metadata_Filtering</title>
<path fill="none" stroke="black" d="M295,-359.7C295,-351.98 295,-342.71 295,-334.11"></path>
<polygon fill="black" stroke="black" points="298.5,-334.1 295,-324.1 291.5,-334.1 298.5,-334.1"></polygon>
</g>
<!-- BM25 -->
<g id="node12" class="node">
<title>BM25</title>
<path fill="#eebefa" stroke="black" d="M546.46,-252C546.46,-252 421.54,-252 421.54,-252 415.54,-252 409.54,-246 409.54,-240 409.54,-240 409.54,-228 409.54,-228 409.54,-222 415.54,-216 421.54,-216 421.54,-216 546.46,-216 546.46,-216 552.46,-216 558.46,-222 558.46,-228 558.46,-228 558.46,-240 558.46,-240 558.46,-246 552.46,-252 546.46,-252"></path>
<text text-anchor="middle" x="484" y="-229.8" font-family="Times,serif" font-size="14.00">BM25 (full-text) search</text>
</g>
<!-- Query_tfidf&#45;&gt;BM25 -->
<g id="edge10" class="edge">
<title>Query_tfidf-&gt;BM25</title>
<path fill="none" stroke="black" d="M484,-359.87C484,-335.67 484,-291.21 484,-262.39"></path>
<polygon fill="black" stroke="black" points="487.5,-262.19 484,-252.19 480.5,-262.19 487.5,-262.19"></polygon>
</g>
<!-- Metadata_Filtering_2 -->
<g id="node8" class="node">
<title>Metadata_Filtering_2</title>
<path fill="#d2bab0" stroke="black" d="M708.62,-324C708.62,-324 551.38,-324 551.38,-324 545.38,-324 539.38,-318 539.38,-312 539.38,-312 539.38,-300 539.38,-300 539.38,-294 545.38,-288 551.38,-288 551.38,-288 708.62,-288 708.62,-288 714.62,-288 720.62,-294 720.62,-300 720.62,-300 720.62,-312 720.62,-312 720.62,-318 714.62,-324 708.62,-324"></path>
<text text-anchor="middle" x="630" y="-301.8" font-family="Times,serif" font-size="14.00">Metadata Document Filtering</text>
</g>
<!-- Document_tfidf&#45;&gt;Metadata_Filtering_2 -->
<g id="edge6" class="edge">
<title>Document_tfidf-&gt;Metadata_Filtering_2</title>
<path fill="none" stroke="black" d="M651.08,-359.7C647.93,-351.81 644.12,-342.3 640.62,-333.55"></path>
<polygon fill="black" stroke="black" points="643.81,-332.09 636.84,-324.1 637.31,-334.69 643.81,-332.09"></polygon>
</g>
<!-- Metadata_Filtering&#45;&gt;Cosine_Similarity_Search -->
<g id="edge8" class="edge">
<title>Metadata_Filtering-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M295,-287.7C295,-279.98 295,-270.71 295,-262.11"></path>
<polygon fill="black" stroke="black" points="298.5,-262.1 295,-252.1 291.5,-262.1 298.5,-262.1"></polygon>
</g>
<!-- Metadata_Filtering_2&#45;&gt;BM25 -->
<g id="edge11" class="edge">
<title>Metadata_Filtering_2-&gt;BM25</title>
<path fill="none" stroke="black" d="M594.28,-287.88C574.5,-278.39 549.73,-266.51 528.67,-256.42"></path>
<polygon fill="black" stroke="black" points="530.13,-253.24 519.6,-252.07 527.1,-259.55 530.13,-253.24"></polygon>
</g>
<!-- Combine_Scores -->
<g id="node13" class="node">
<title>Combine_Scores</title>
<path fill="#95f2d7" stroke="black" d="M440.42,-180C440.42,-180 337.58,-180 337.58,-180 331.58,-180 325.58,-174 325.58,-168 325.58,-168 325.58,-156 325.58,-156 325.58,-150 331.58,-144 337.58,-144 337.58,-144 440.42,-144 440.42,-144 446.42,-144 452.42,-150 452.42,-156 452.42,-156 452.42,-168 452.42,-168 452.42,-174 446.42,-180 440.42,-180"></path>
<text text-anchor="middle" x="389" y="-157.8" font-family="Times,serif" font-size="14.00">Combine the scores</text>
</g>
<!-- Cosine_Similarity_Search&#45;&gt;Combine_Scores -->
<g id="edge13" class="edge">
<title>Cosine_Similarity_Search-&gt;Combine_Scores</title>
<path fill="none" stroke="black" d="M318.24,-215.7C330.19,-206.8 344.92,-195.82 357.85,-186.2"></path>
<polygon fill="black" stroke="black" points="360.1,-188.88 366.03,-180.1 355.92,-183.27 360.1,-188.88"></polygon>
</g>
<!-- Results -->
<g id="node10" class="node">
<title>Results</title>
<path fill="#b2f3bb" stroke="black" d="M405.73,-36C405.73,-36 372.27,-36 372.27,-36 366.27,-36 360.27,-30 360.27,-24 360.27,-24 360.27,-12 360.27,-12 360.27,-6 366.27,0 372.27,0 372.27,0 405.73,0 405.73,0 411.73,0 417.73,-6 417.73,-12 417.73,-12 417.73,-24 417.73,-24 417.73,-30 411.73,-36 405.73,-36"></path>
<text text-anchor="middle" x="389" y="-13.8" font-family="Times,serif" font-size="14.00">Results</text>
</g>
<!-- Reranking -->
<g id="node11" class="node">
<title>Reranking</title>
<path fill="#fed8a7" stroke="black" d="M414.32,-108C414.32,-108 363.68,-108 363.68,-108 357.68,-108 351.68,-102 351.68,-96 351.68,-96 351.68,-84 351.68,-84 351.68,-78 357.68,-72 363.68,-72 363.68,-72 414.32,-72 414.32,-72 420.32,-72 426.32,-78 426.32,-84 426.32,-84 426.32,-96 426.32,-96 426.32,-102 420.32,-108 414.32,-108"></path>
<text text-anchor="middle" x="389" y="-85.8" font-family="Times,serif" font-size="14.00">Reranking</text>
</g>
<!-- Reranking&#45;&gt;Results -->
<g id="edge9" class="edge">
<title>Reranking-&gt;Results</title>
<path fill="none" stroke="black" d="M389,-71.7C389,-63.98 389,-54.71 389,-46.11"></path>
<polygon fill="black" stroke="black" points="392.5,-46.1 389,-36.1 385.5,-46.1 392.5,-46.1"></polygon>
</g>
<!-- BM25&#45;&gt;Combine_Scores -->
<g id="edge12" class="edge">
<title>BM25-&gt;Combine_Scores</title>
<path fill="none" stroke="black" d="M460.52,-215.7C448.44,-206.8 433.55,-195.82 420.48,-186.2"></path>
<polygon fill="black" stroke="black" points="422.34,-183.22 412.21,-180.1 418.19,-188.85 422.34,-183.22"></polygon>
</g>
<!-- Combine_Scores&#45;&gt;Reranking -->
<g id="edge14" class="edge">
<title>Combine_Scores-&gt;Reranking</title>
<path fill="none" stroke="black" d="M389,-143.7C389,-135.98 389,-126.71 389,-118.11"></path>
<polygon fill="black" stroke="black" points="392.5,-118.1 389,-108.1 385.5,-118.1 392.5,-118.1"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="code-example-implementing-the-mvp-with-lancedb" class="level3">
<h3 class="anchored" data-anchor-id="code-example-implementing-the-mvp-with-lancedb">Code Example: Implementing the MVP++ with LanceDB</h3>
<ul>
<li>Uses LanceDB for its ease of use and built-in components.</li>
<li><strong>Vector Databases</strong>
<ul>
<li><a href="https://lancedb.com/">LanceDB</a></li>
<li><a href="https://weaviate.io/">Weaviate</a></li>
<li><a href="https://www.trychroma.com/">Chroma</a></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fetch some text content in two different categories</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> wikipediaapi <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Wikipedia</span>
<span id="cb1-3">wiki <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Wikipedia(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RAGBot/0.0'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en'</span>)</span>
<span id="cb1-4">docs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>: x,</span>
<span id="cb1-5">         <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"category"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span>}</span>
<span id="cb1-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> wiki.page(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hayao_Miyazaki'</span>).text.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)]</span>
<span id="cb1-7">docs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>: x,</span>
<span id="cb1-8">          <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"category"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"film"</span>}</span>
<span id="cb1-9">         <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> wiki.page(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Spirited_Away'</span>).text.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)]</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Enter LanceDB</span></span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> lancedb</span>
<span id="cb1-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> lancedb.pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LanceModel, Vector</span>
<span id="cb1-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> lancedb.embedding <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_registry</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialise the embedding model</span></span>
<span id="cb1-17">model_registry <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_registry().get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sentence-transformers"</span>)</span>
<span id="cb1-18">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_registry.create(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BAAI/bge-small-en-v1.5"</span>)</span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a Model to store attributes for filtering</span></span>
<span id="cb1-21"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Document(LanceModel):                    </span>
<span id="cb1-22">    text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.SourceField()</span>
<span id="cb1-23">    vector: Vector(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.VectorField()</span>
<span id="cb1-24">    category: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-25"></span>
<span id="cb1-26">db <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lancedb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".my_db"</span>)</span>
<span id="cb1-27">tbl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> db.create_table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my_table"</span>, schema<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Document)</span>
<span id="cb1-28"></span>
<span id="cb1-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Embed the documents and store them in the database</span></span>
<span id="cb1-30">tbl.add(docs)                                        </span>
<span id="cb1-31"></span>
<span id="cb1-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate the full-text (tf-idf) search index</span></span>
<span id="cb1-33">tbl.create_fts_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)                         </span>
<span id="cb1-34"></span>
<span id="cb1-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialise a reranker -- here, Cohere's API one</span></span>
<span id="cb1-36"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> lancedb.rerankers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> CohereReranker</span>
<span id="cb1-37"></span>
<span id="cb1-38">reranker <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CohereReranker()                        </span>
<span id="cb1-39"></span>
<span id="cb1-40">query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What is Chihiro's new name given to her by the witch?"</span></span>
<span id="cb1-41"></span>
<span id="cb1-42">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (tbl.search(query, query_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hybrid"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hybrid means text + vector</span></span>
<span id="cb1-43">           .where(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"category = 'film'"</span>, prefilter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Restrict to only docs in the 'film' category</span></span>
<span id="cb1-44">           .limit(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get 10 results from first-pass retrieval</span></span>
<span id="cb1-45">           .rerank(reranker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>reranker) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># For the reranker to compute the final ranking</span></span>
<span id="cb1-46">          )</span></code></pre></div>
</section>
</section>
<section id="beyond-the-basics-future-exploration-and-resources" class="level2">
<h2 class="anchored" data-anchor-id="beyond-the-basics-future-exploration-and-resources">Beyond the Basics: Future Exploration and Resources</h2>
<ul>
<li><strong><a href="https://github.com/AnswerDotAI/RAGatouille">RAGatouille</a>:</strong> Easily use and train state of the art late-interaction retrieval methods (ColBERT) in any RAG pipeline.</li>
<li><strong><a href="https://github.com/AnswerDotAI/rerankers">rerankers</a>:</strong> A lightweight unified API for various reranking models.</li>
<li><strong>Video Tutorial:</strong> <a href="https://www.youtube.com/watch?v=jkrNMKz9pWU">A Hackers’ Guide to Language Models</a></li>
<li><strong>ColBERT</strong>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2004.12832">ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT</a></li>
<li><strong>HuggingFace Hub:</strong> <a href="https://huggingface.co/colbert-ir/colbertv2.0">colbert-ir/colbertv2.0</a></li>
</ul></li>
<li><strong>Sparse Vectors:</strong> <a href="https://docs.pinecone.io/guides/data/understanding-hybrid-search">Understanding hybrid search</a></li>
<li><strong>Multi-vector Retrievers:</strong> <a href="https://blog.langchain.dev/semi-structured-multi-modal-rag/">Multi-Vector Retriever for RAG on tables, text, and images</a></li>
</ul>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<section id="fine-tuning-bi-encoders-and-cross-encoders" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-bi-encoders-and-cross-encoders">Fine-tuning Bi-Encoders and Cross-Encoders</h3>
<ul>
<li><p><strong>Q:</strong> Does the fine-tuning approach for bi-encoder models impact the fine-tuning of cross-encoder models and vice versa?</p></li>
<li><p><strong>A:</strong> While domain-specific, generally aim for complementarity. Fine-tune bi-encoders for broader retrieval, capturing potential candidates. Rely on cross-encoders (re-rankers) for precise filtering and ranking.</p></li>
</ul>
</section>
<section id="combining-bi-encoder-and-tf-idf-scores" class="level3">
<h3 class="anchored" data-anchor-id="combining-bi-encoder-and-tf-idf-scores">Combining Bi-Encoder and TF-IDF Scores</h3>
<ul>
<li><p><strong>Q:</strong> What are the advantages and disadvantages of using a weighted average of bi-encoder and TF-IDF scores for selecting re-ranker questions compared to taking the top X from each ranker?</p></li>
<li><p><strong>A:</strong> Both methods are valid and depend on the data. Weighted averages can be effective, but in domains like biomedicine, where document specificity is crucial, taking the top X from both ensures representation for potentially poorly embedded queries.</p></li>
</ul>
</section>
<section id="rags-future-with-million-token-context-lengths" class="level3">
<h3 class="anchored" data-anchor-id="rags-future-with-million-token-context-lengths">RAG’s Future with Million-Token Context Lengths</h3>
<ul>
<li><p><strong>Q:</strong> How will the emergence of million-token context lengths impact the relevance of RAG in the future?</p></li>
<li><p><strong>A:</strong> RAG remains relevant even with extended context windows. Just as RAM doesn’t replace hard drives, large context windows won’t replace the need for efficient retrieval from vast external knowledge stores. Long context windows provide more flexibility in retrieval speed and allow for incorporating longer documents.</p></li>
</ul>
</section>
<section id="chunking-strategies" class="level3">
<h3 class="anchored" data-anchor-id="chunking-strategies">Chunking Strategies</h3>
<ul>
<li><p><strong>Q:</strong> What are your thoughts on different chunking strategies?</p></li>
<li><p><strong>A:</strong> While LLMs for pre-chunking are promising but currently immature, maintaining semantic continuity within chunks is vital. The recommended approach is 300 tokens per chunk, avoiding sentence interruptions and including overlapping context (50 tokens) between consecutive chunks.</p></li>
</ul>
</section>
<section id="fine-tuning-bi-encoders" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-bi-encoders">Fine-tuning Bi-Encoders</h3>
<ul>
<li><p><strong>Q:</strong> Should bi-encoders always be fine-tuned with labeled data or is it acceptable to use them off-the-shelf and rely on a re-ranker?</p></li>
<li><p><strong>A:</strong> Fine-tuning encoders (both bi- and cross-) with labeled data consistently improves results. If data and resources are available, fine-tuning is highly recommended. However, for MVPs with limited resources, leveraging pre-trained models with re-ranking is a viable option.</p></li>
</ul>
</section>
<section id="colbert-clarification-and-discussion" class="level3">
<h3 class="anchored" data-anchor-id="colbert-clarification-and-discussion">Colbert Clarification and Discussion</h3>
<ul>
<li><p><strong>Discussion:</strong> Clarifying the role of ColBERT in RAG pipelines.</p>
<ul>
<li><p><strong>ColBERT as a First-Stage Retriever:</strong> Ideally replaces the bi-encoder in new pipelines, not used as a re-ranker.</p></li>
<li><p><strong>ColBERT as a Re-Ranker:</strong> Can be used when pipeline changes are not feasible, but less optimal.</p></li>
<li><p><strong>ColBERT Overview:</strong> A bi-encoder variant where documents and queries are represented as bags of embeddings (one per token). This approach enhances out-of-domain performance due to its multi-vector representation, capturing more granular information.</p></li>
</ul></li>
</ul>
</section>
<section id="tools-for-fine-tuning-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="tools-for-fine-tuning-embeddings">Tools for Fine-tuning Embeddings</h3>
<ul>
<li><p><strong>Q:</strong> Recommendations for tools to fine-tune embeddings for retrieval.</p></li>
<li><p><strong>A:</strong> <a href="https://sbert.net/">Sentence Transformers</a>, particularly version 3.0, is highly recommended for its user-friendliness and comprehensive implementation of essential features.</p></li>
</ul>
</section>
<section id="fine-tuning-embeddings-workflow" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-embeddings-workflow">Fine-tuning Embeddings Workflow</h3>
<ul>
<li><p><strong>Q:</strong> Can you describe the workflow for fine-tuning an embedding model?</p></li>
<li><p><strong>A:</strong></p>
<ol type="1">
<li><strong>Gather Data:</strong> Obtain queries and their corresponding relevant and non-relevant documents.</li>
<li><strong>Define Loss Function:</strong> Use a suitable loss function like <a href="https://doordash.engineering/2021/09/08/using-twin-neural-networks-to-train-catalog-item-embeddings/">triplet loss</a>, which leverages positive and negative examples to guide the model.</li>
<li><strong>Consider Hard Negatives:</strong> Enhance training by retrieving hard negatives—documents similar to positive examples but irrelevant to the query.</li>
<li><strong>Data Analysis and Generation:</strong> Thoroughly analyze existing queries or generate synthetic ones using LLMs to augment training data.</li>
</ol></li>
</ul>
</section>
<section id="impact-of-long-context-windows-on-rag" class="level3">
<h3 class="anchored" data-anchor-id="impact-of-long-context-windows-on-rag">Impact of Long Context Windows on RAG</h3>
<ul>
<li><p><strong>Q:</strong> How do long context windows change the strategies and possibilities within RAG?</p></li>
<li><p><strong>A:</strong> Long context windows enable:</p>
<ul>
<li><p><strong>Longer Documents:</strong> Incorporating longer documents or concatenated chunks into the context.</p></li>
<li><p><strong>Reduced Retrieval Overhead:</strong> Relaxing the reliance on highly precise retrieval (e.g., Recall@3) as more documents can fit within the context window. This allows for faster, less resource-intensive retrieval methods.</p></li>
</ul></li>
</ul>
</section>
<section id="fine-tuning-encoder-tutorials" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-encoder-tutorials">Fine-tuning Encoder Tutorials</h3>
<ul>
<li><p><strong>Q:</strong> Recommendations for tutorials on fine-tuning encoders.</p></li>
<li><p><strong>A:</strong> The <a href="https://www.sbert.net/docs/sentence_transformer/training_overview.html">Sentence Transformers documentation</a> is a valuable resource but can be challenging for beginners.</p></li>
</ul>
</section>
<section id="go-to-embedding-models" class="level3">
<h3 class="anchored" data-anchor-id="go-to-embedding-models">Go-to Embedding Models</h3>
<ul>
<li><p><strong>Q:</strong> Go-to embedding models for different scenarios.</p></li>
<li><p><strong>A:</strong></p>
<ul>
<li><p><strong>Demos:</strong> <a href="https://cohere.com/">Cohere</a>’s embedding models due to their API accessibility, performance, and affordability.</p></li>
<li><p><strong>Production:</strong> Multi-vector models like ColBERT are preferred.</p></li>
</ul></li>
<li><p><strong>General Recommendations:</strong></p>
<ul>
<li><p><strong>Model Size:</strong> Stick to models with parameters between 100 million and 1 billion; larger LLMs as encoders often have unfavorable latency-performance trade-offs.</p></li>
<li><p><strong>Avoid Overly Large Models:</strong> Using excessively large LLMs for embedding can lead to diminishing returns in performance and increased latency.</p></li>
</ul></li>
</ul>
</section>
<section id="using-elasticsearch-for-rag" class="level3">
<h3 class="anchored" data-anchor-id="using-elasticsearch-for-rag">Using Elasticsearch for RAG</h3>
<ul>
<li><p><strong>Q:</strong> Can Elasticsearch, a widely used search engine, be integrated into RAG pipelines, especially for organizations already invested in it?</p></li>
<li><p><strong>A:</strong></p>
<ul>
<li><p><strong>Hybrid Approach:</strong> Use Elasticsearch’s BM25 capabilities for initial retrieval and integrate a separate re-ranking pipeline (potentially using a cross-encoder).</p></li>
<li><p><strong>Vector Database Integration:</strong> Leverage Elasticsearch’s vector database offerings to incorporate semantic search capabilities.</p></li>
</ul></li>
</ul>
</section>
<section id="bm25-score-in-re-ranking" class="level3">
<h3 class="anchored" data-anchor-id="bm25-score-in-re-ranking">BM25 Score in Re-ranking</h3>
<ul>
<li><p><strong>Q:</strong> Is it beneficial to incorporate BM25 similarity scores during the re-ranking stage?</p></li>
<li><p><strong>A:</strong> No, BM25 scores are primarily used for candidate retrieval and are not typically required by cross-encoders during re-ranking.</p></li>
</ul>
</section>
<section id="strategies-for-chunks-exceeding-context-window" class="level3">
<h3 class="anchored" data-anchor-id="strategies-for-chunks-exceeding-context-window">Strategies for Chunks Exceeding Context Window</h3>
<ul>
<li><p><strong>Q:</strong> Strategies for handling situations where document chunks exceed the context window size.</p></li>
<li><p><strong>A:</strong> Solutions depend on the specific constraints:</p>
<ul>
<li><p><strong>Latency Tolerance:</strong> User experience dictates acceptable processing time.</p></li>
<li><p><strong>Document Length and Diversity Requirements:</strong></p></li>
<li><p><strong>Precomputed Summaries:</strong> Maintain a separate database mapping documents to their summaries, generated offline. Retrieve relevant chunks and feed summaries into the context window to provide concise context.</p></li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-014/</guid>
  <pubDate>Fri, 02 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 13: When to Fine-Tune with Paige Bailey</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-013/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Google AI Landscape and Gemini</li>
<li>Understanding Context Windows</li>
<li>Fine-tuning vs.&nbsp;Prompting vs.&nbsp;Retrieval</li>
<li>Prompting Strategies and Examples</li>
<li>Retrieval Augmented Generation</li>
<li>Fine-tuning Considerations and Gemma</li>
</ul>
<section id="google-ai-landscape-and-gemini" class="level2">
<h2 class="anchored" data-anchor-id="google-ai-landscape-and-gemini">Google AI Landscape and Gemini</h2>
<ul>
<li><p><strong>Vertex AI:</strong></p>
<ul>
<li><strong><a href="https://cloud.google.com/vertex-ai?hl=en">Vertex AI</a>:</strong> Collection of APIs, compute infrastructure, model deployment tools available through Google Cloud, geared towards enterprise use. Comparable to Azure Open AI services.</li>
<li><strong><a href="https://ai.google.dev/">Gemini Developer API</a> (through <a href="https://ai.google.dev/aistudio">AI Studio</a>):</strong> Easier path for rapid prototyping and personal projects. Comparable to OpenAI APIs.</li>
</ul></li>
<li><p><strong>Gemini Flash Fine-Tuning:</strong></p>
<ul>
<li><strong><a href="https://deepmind.google/technologies/gemini/flash/">Gemini 1.5 Flash</a>:</strong> Google’s most performant, efficient, and cost-effective model, boasting a 1 million token context window (and growing).</li>
<li>Supports fine-tuning and is part of an early tester program.</li>
</ul></li>
<li><p><strong>Gemini Nano &amp; Gemma:</strong></p>
<ul>
<li><strong><a href="https://deepmind.google/technologies/gemini/nano/">Gemini Nano</a>:</strong> Brief mention of its planned integration into Chrome and Pixel/Android devices (details deferred).</li>
<li><strong><a href="https://ai.google.dev/gemma">Gemma</a>:</strong>
<ul>
<li>Open-source versions of Gemini, available on Hugging Face, Kaggle, and Ollama, making local experimentation easy.</li>
<li>Kaggle hosts checkpoints, code samples, and runnable notebooks.</li>
</ul></li>
</ul></li>
</ul>
<section id="generative-ai-and-google" class="level3">
<h3 class="anchored" data-anchor-id="generative-ai-and-google">Generative AI and Google</h3>
<ul>
<li>Google’s history in machine learning: TensorFlow, transformer models (BERT, AlphaFold, AlphaStar, AlphaGo, T5), and now Gemini.</li>
<li>Generative AI extends beyond text and code, mentioning:
<ul>
<li><strong><a href="https://deepmind.google/technologies/imagen-2/">Imagen 2</a>:</strong> Detailed image generation.</li>
<li><strong><a href="https://cloud.google.com/speech-to-text/v2/docs/chirp-model">Chirp</a>:</strong> Speech-to-text with multilingual capabilities and a small model footprint.</li>
</ul></li>
<li><strong>Gemini:</strong> Google’s flagship model (currently on version 1.5)</li>
</ul>
</section>
<section id="gemini-model-features" class="level3">
<h3 class="anchored" data-anchor-id="gemini-model-features">Gemini Model Features</h3>
<ul>
<li><strong>Multimodal Understanding:</strong> Processes images, audio, text, code, video, and more simultaneously.</li>
<li><strong>State-of-the-art Performance:</strong> Excels across various tasks, though reliant on academic benchmarks (discussed later).</li>
<li><strong>Embedded Reasoning:</strong> Strong capabilities in chain-of-thought and step-by-step reasoning.</li>
<li><strong>Scalable Deployment:</strong> Optimized for both large-scale (Google products) and small-scale (edge devices) use cases.</li>
<li><strong>Efficiency and Privacy:</strong> Focus on cost-effective token analysis, reduced inference compute, and on-device processing for privacy preservation.</li>
<li><strong>Model Options:</strong>
<ul>
<li><strong><a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/">Gemini 1.5 Pro</a>:</strong> High-performance, efficient model.</li>
<li><strong>Gemini Nano:</strong> Ultra-small model for edge deployments.</li>
<li><strong>Gemma:</strong> Open-sourced models (2B and 7B parameters)</li>
</ul></li>
<li>Key considerations for integration: user experience, performance, and cost trade-offs.</li>
<li><strong>Available Options:</strong>
<ul>
<li><strong>Gemini 1.5 Flash:</strong> Fast, 1 million token context window.</li>
<li><strong>Gemini 1.5 Pro:</strong> 2 million token context window</li>
</ul></li>
<li><strong>Gemini Flash for Code:</strong>
<ul>
<li>Performs well for code generation and structured outputs like JSON out-of-the-box.</li>
<li>Fine-tuning and using code examples in the context window further enhance results.</li>
<li>Applicable to code generation, translation, debugging, code review, etc.</li>
</ul></li>
</ul>
</section>
</section>
<section id="understanding-context-windows" class="level2">
<h2 class="anchored" data-anchor-id="understanding-context-windows">Understanding Context Windows</h2>
<ul>
<li><strong>Importance of Context Window Size:</strong>
<ul>
<li>Historically limited to 2,000-8,000 tokens, hindering model capability.</li>
<li>Current models: GPT-4 Turbo (128,000+), Claude (2,000), Gemini (2 million).</li>
</ul></li>
<li><strong>Impact of Larger Context Windows:</strong>
<ul>
<li>Can handle massive amounts of data (emails, texts, videos, codebases, research papers).</li>
<li>Reduces the need for fine-tuning, as more information can be provided at inference time.</li>
<li>Allows for more complex and nuanced outputs.</li>
</ul></li>
</ul>
</section>
<section id="fine-tuning-vs.-prompting-vs.-retrieval" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuning-vs.-prompting-vs.-retrieval">Fine-tuning vs.&nbsp;Prompting vs.&nbsp;Retrieval</h2>
<section id="common-questions-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="common-questions-trade-offs">Common Questions &amp; Trade-offs</h3>
<ul>
<li>Key decision points when working with large language models.</li>
<li><strong>Considerations:</strong>
<ul>
<li><strong>Prompt Design:</strong> Simple, cost-effective, but may require detailed prompts.</li>
<li><strong>Fine-Tuning:</strong>
<ul>
<li>Increasingly difficult to justify due to maintenance overhead and rapid release of new open-source models.</li>
<li>Recommended only when other options fail or for on-premise/local data requirements.</li>
</ul></li>
</ul></li>
<li><strong>Recommendations:</strong>
<ul>
<li><strong>Start with Closed-Source APIs:</strong> Rapid iteration, prove product-market fit, focus on UX.</li>
<li><strong>Hire ML Team When Necessary:</strong> If highly specialized fine-tuning becomes essential.</li>
</ul></li>
</ul>
</section>
<section id="model-evaluation-its-importance" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation-its-importance">Model Evaluation &amp; Its Importance</h3>
<ul>
<li><strong>Limitations of Academic Benchmarks:</strong>
<ul>
<li><strong>Example:</strong> <a href="https://huggingface.co/datasets/openai/openai_humaneval">HumanEval</a>
<ul>
<li>Often misinterpreted as involving human evaluation (it doesn’t).</li>
<li>Tests a narrow scope of Python function completion with simplistic tasks.</li>
<li>Not representative of real-world software engineering or other programming languages.</li>
</ul></li>
</ul></li>
<li><strong><a href="https://huggingface.co/datasets/THUDM/humaneval-x">HumanEval X</a>:</strong> Created to address some limitations of HumanEval, but still has limitations.</li>
<li><strong>Key Takeaways:</strong>
<ul>
<li>Carefully consider the relevance and limitations of evaluation metrics.</li>
<li>Prioritize custom evaluations tailored to your specific use case and business needs.</li>
</ul></li>
</ul>
</section>
</section>
<section id="prompting-strategies-and-examples" class="level2">
<h2 class="anchored" data-anchor-id="prompting-strategies-and-examples">Prompting Strategies and Examples</h2>
<section id="power-of-prompting-video-understanding" class="level3">
<h3 class="anchored" data-anchor-id="power-of-prompting-video-understanding">Power of Prompting &amp; Video Understanding</h3>
<ul>
<li><strong>Detailed Example:</strong>
<ul>
<li>Using Gemini in AI Studio to analyze a 44-minute video.</li>
<li>Asking the model to find a specific event (paper removed from a pocket), identify information on the paper, and provide the timestamp.</li>
<li>Demonstrates the ability to understand and extract information from lengthy video content, potentially revolutionizing video analysis workflows.</li>
</ul></li>
<li><strong>Implications:</strong>
<ul>
<li>Transforms how we interact with video content, making it searchable and analyzable at scale.</li>
<li>Also applicable to large text documents (PDFs with images, graphs, code) for summarization, analysis, and research.</li>
</ul></li>
<li><strong>Prefix Caching:</strong>
<ul>
<li>Optimizes API calls for repeated analysis of the same codebase or repository.</li>
<li>Improves latency and grounds responses within a consistent context.</li>
</ul></li>
</ul>
</section>
<section id="ai-studio-overview-examples" class="level3">
<h3 class="anchored" data-anchor-id="ai-studio-overview-examples">AI Studio Overview &amp; Examples</h3>
<ul>
<li><strong>Key Features:</strong>
<ul>
<li>Adjust stop sequences, top-k configurations, and temperature.</li>
<li>Toggle between Gemini models (Pro, Flash, etc.).</li>
<li>Access prompt gallery, cookbook, and getting started resources.</li>
<li>View past prompts and outputs.</li>
</ul></li>
<li><strong>Examples:</strong>
<ul>
<li>Scraping GitHub issues and Stack Overflow questions for analysis.</li>
<li>Converting COBOL code to Java with specific instructions and architecture preferences.</li>
</ul></li>
<li><strong>Key Takeaway:</strong> With detailed instructions, models can achieve impressive results, much like a skilled contractor team.</li>
</ul>
</section>
</section>
<section id="retrieval-augmented-generation" class="level2">
<h2 class="anchored" data-anchor-id="retrieval-augmented-generation">Retrieval Augmented Generation</h2>
<section id="retrieval-in-google-products" class="level3">
<h3 class="anchored" data-anchor-id="retrieval-in-google-products">Retrieval in Google Products</h3>
<ul>
<li><strong><a href="https://gemini.google.com/app">gemini.google.com</a> (formerly Bard):</strong>
<ul>
<li>Example: Querying for information about the San Francisco Ferry Building and requesting recommendations.</li>
<li>Results are grounded in Google Search, with an option to view source citations and confidence levels.</li>
</ul></li>
<li><strong>Personalized Retrieval:</strong> The concept can be extended to internal corporate data and codebases.</li>
</ul>
</section>
</section>
<section id="fine-tuning-considerations-and-gemma" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuning-considerations-and-gemma">Fine-tuning Considerations and Gemma</h2>
<ul>
<li><strong>Fine-Tuning:</strong>
<ul>
<li>Should be approached with caution and a clear understanding of the maintenance commitment.</li>
<li>Consider the rapid evolution of open-source models.</li>
</ul></li>
<li><strong>Gemma Family:</strong>
<ul>
<li>Solid starting point for open-source fine-tuning.</li>
<li>Available in 2B and 7B parameter sizes, with both instruction-tuned and non-instruction-tuned variants.</li>
<li><strong><a href="https://huggingface.co/blog/codegemma">CodeGemma</a>:</strong> For code-related tasks.</li>
<li><strong>RecurrentGemma:</strong> For sequential data.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2404.07839">RecurrentGemma: Moving Past Transformers for Efficient Open Language Models</a></li>
<li><strong>HuggingFace Hub:</strong> <a href="google/recurrentgemma-2b-it">google/recurrentgemma-2b-it</a></li>
</ul></li>
<li><strong>PaliGemma:</strong> Open-vision language model.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2407.07726">PaliGemma: A versatile 3B VLM for transfer</a></li>
<li><strong>Blog Post:</strong> <a href="https://huggingface.co/blog/paligemma">PaliGemma – Google’s Cutting-Edge Open Vision Language Model</a></li>
</ul></li>
</ul></li>
<li><strong>Resources:</strong>
<ul>
<li><a href="https://cloud.google.com/model-garden?hl=en">Model Garden on Vertex AI</a></li>
<li><a href="https://huggingface.co/google">HuggingFace Hub</a></li>
</ul></li>
<li><strong>Deployment:</strong> Easy one-click deployment to Google Cloud.</li>
<li><strong>Model Builders:</strong> Provides automatic comparisons and prompt management.</li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-013/</guid>
  <pubDate>Thu, 25 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 12: Slaying OOMs with PyTorch FSDP and torchao</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Understanding Model Memory</li>
<li>Optimizing Memory Usage</li>
<li>Model Parallelism with FSDP</li>
<li>Benchmarking FSDP2</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Presentation Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Presentation Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://drive.google.com/drive/u/0/folders/1HmGNC4v4L5nXhtdDMVCpUBrme1ELp-2C">Slaying OOMs</a></li>
</ul>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li>OOM errors are a common challenge when working with large PyTorch models.</li>
<li>Traditional solutions like reducing batch size or model size are limited in effectiveness.</li>
</ul>
</section>
<section id="understanding-model-memory" class="level2">
<h2 class="anchored" data-anchor-id="understanding-model-memory">Understanding Model Memory</h2>
<ul>
<li><strong>VRAM Constraint:</strong> Modern GPUs have limited VRAM (e.g., 24GB for 3090s and 4090s), leading to challenges when training large models.</li>
<li><strong>Model Memory Components:</strong>
<ul>
<li><strong>Parameters:</strong> Model weights, typically stored in FP16 (2 bytes per parameter). For a 7B parameter LLaMa model, this translates to 14GB.</li>
<li><strong>Gradients:</strong> Calculated during backpropagation, require the same storage size as parameters (another 14GB for LLaMa 7B).</li>
<li><strong>Optimizer State:</strong> Optimizers like Adam store additional information, often twice the size of parameters (28GB for LLaMa 7B).</li>
<li><strong>Activations:</strong> Intermediate outputs of model layers.
<ul>
<li>The size is harder to estimate and depends on factors like batch size and context length.</li>
<li>Activations tend to dominate memory usage at larger batch sizes and context lengths.</li>
</ul></li>
</ul></li>
<li><strong>Example:</strong> A full fine-tuning of a 7B parameter LLaMa model can easily exceed 56GB (14GB parameters + 14GB gradients + 28GB optimizer state), exceeding the VRAM capacity of most consumer GPUs.</li>
<li><strong>Forum Post:</strong> <a href="https://dev-discuss.pytorch.org/t/how-to-measure-memory-usage-from-your-model-without-running-it/2024/1">How to measure memory usage from your model without running it?</a></li>
</ul>
</section>
<section id="optimizing-memory-usage" class="level2">
<h2 class="anchored" data-anchor-id="optimizing-memory-usage">Optimizing Memory Usage</h2>
<section id="optimizer-memory" class="level3">
<h3 class="anchored" data-anchor-id="optimizer-memory">Optimizer Memory</h3>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a></li>
<li>While alternative optimizers like SGD might seem appealing due to their lower memory overhead, Adam remains dominant in practice due to its effectiveness.</li>
<li>Replacing Adam is challenging and might not yield significant memory savings.</li>
</ul>
</section>
<section id="parameter-quantization" class="level3">
<h3 class="anchored" data-anchor-id="parameter-quantization">Parameter Quantization</h3>
<ul>
<li><p><strong>4-bit Quantization:</strong> Reduces the precision of model parameters from FP16 to INT4 (half a byte per parameter).</p></li>
<li><p>This technique can significantly reduce memory footprint, for example, bringing the size of a 7B parameter LLaMa model down from 14GB to 3.5GB.</p></li>
<li><p><strong>Torch Compile:</strong> This tool can be leveraged to create efficient quantization kernels directly from Python code, eliminating the need for custom CUDA kernels.</p>
<ul>
<li><p>Decorate <code>quantize_tensor</code> and <code>dequantize_tensor</code> functions with <code>@torch.compile()</code></p></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb1-2">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"TORCH_LOGS"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_code"</span></span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@torch.compile</span>()</span>
<span id="cb1-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> quantize_tensor(x_fp32):</span>
<span id="cb1-7">    absmax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(x_fp32))</span>
<span id="cb1-8">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">127.0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> absmax</span>
<span id="cb1-9">    x_int8 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x_fp32).to(torch.int8)</span>
<span id="cb1-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x_int8, c</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@torch.compile</span>()</span>
<span id="cb1-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> dequantize_tensor(x_int8, c):</span>
<span id="cb1-14">    x_fp32 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_int8.to(torch.float32) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> c</span>
<span id="cb1-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x_fp32</span>
<span id="cb1-16"></span>
<span id="cb1-17">x_int8, c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> quantize_tensor(torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>))</span>
<span id="cb1-18">x_fp32 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dequantize_tensor(x_int8, c)</span></code></pre></div>
</div>
</div></li>
<li><p><strong>Docs:</strong> <a href="https://pytorch.org/docs/stable/generated/torch.compile.html">https://pytorch.org/docs/stable/generated/torch.compile.html</a></p></li>
<li><p><strong>Tutorial:</strong> <a href="https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html">Introduction to <code>torch.compile</code></a></p></li>
</ul></li>
</ul>
</section>
<section id="gradient-optimization-with-lora" class="level3">
<h3 class="anchored" data-anchor-id="gradient-optimization-with-lora">Gradient Optimization with LoRA</h3>
<ul>
<li>Directly quantizing gradients to 4-bit negatively impacts convergence.</li>
<li><strong>Low-Rank Adaptation (LoRA):</strong> Circumvents this issue by training only a small subset of parameters (adapters) while keeping the majority frozen.</li>
<li><strong>QLoRA:</strong> This technique combines LoRA with parameter quantization to achieve significant memory savings without compromising accuracy.</li>
</ul>
</section>
<section id="challenges-and-solutions-with-qlora" class="level3">
<h3 class="anchored" data-anchor-id="challenges-and-solutions-with-qlora">Challenges and Solutions with QLoRA</h3>
<ul>
<li><p>QLoRA implementation can be complex, often requiring custom CUDA kernels (e.g., the original implementation by Tim Detmers consists of 4,000 lines of CUDA code).</p>
<ul>
<li>Weights aren’t in int4 but NF4 which is closer to a normal distribution</li>
<li>Can’t matrix multiply NF4 tensors
<ul>
<li>need to dequantize and matmul</li>
</ul></li>
<li>Can’t use the same max for everything otherwise you’re too sensitive to outliers</li>
<li>Quantization typically done in blocks with independent scales</li>
<li>QLoRA quantizes the scales (double quantization)</li>
</ul></li>
<li><p><strong>Simplified Implementation with Torch Compile:</strong> <a href="https://github.com/drisspg">Driss Guessous</a>, a PyTorch developer, implemented QLoRA in approximately 900 lines of Python code using Torch Compile.</p>
<ul>
<li><strong>Code:</strong> <a href="https://www.github.com/torchao/dtypes/nf4tensor.py">torchao/dtypes/nf4tensor.py</a></li>
</ul></li>
<li><p><strong>Tensor Subclasses:</strong> PyTorch’s tensor subclassing feature enables the creation of custom data types like NF4 (used in QLoRA), allowing for more efficient representation and manipulation of quantized tensors.</p>
<ul>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> F.linear(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>, weight.to(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>.dtype))</span></code></pre></div>
</div>
</div></li>
<li><p><strong>Docs:</strong> <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a></p></li>
<li><p><strong><a href="https://github.com/albanD/subclass_zoo/">subclass_zoo</a>:</strong> Contains a number of examples of Tensor subclasses in PyTorch</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="model-parallelism-with-fsdp" class="level2">
<h2 class="anchored" data-anchor-id="model-parallelism-with-fsdp">Model Parallelism with FSDP</h2>
<section id="data-parallism" class="level3">
<h3 class="anchored" data-anchor-id="data-parallism">Data Parallism</h3>
<ul>
<li><strong>Data parallelism:</strong> Split batches across multipls devices and keep a copy of the gradients, model params, and optimizer state on each device</li>
<li>Data parallelism alone, while helpful, might not be sufficient for extremely large models.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/images/oom-with-data-parallelism.png" class="img-fluid figure-img"></p>
<figcaption>OOM With Data Parallelism - Slaying OOMs: Slide 19</figcaption>
</figure>
</div>
</section>
<section id="fsdp" class="level3">
<h3 class="anchored" data-anchor-id="fsdp">FSDP</h3>
<ul>
<li><strong>Fully Sharded Data Parallel (FSDP):</strong> Distributes model parameters (and by consequence the gradients, and optimizer states) across multiple GPUs, allowing for training models that exceed the memory capacity of a single device.
<ul>
<li>Memory corresponding to the layer getting processed will be freed when the layer is done.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/images/fsdp-memory-step.png" class="img-fluid figure-img"></p>
<figcaption>FSDP Memory - Slaying OOMs: Slide 21</figcaption>
</figure>
</div>
<ul>
<li><p><strong>Sharding:</strong> Dividing model components into smaller chunks (shards) that can be placed on different GPUs.</p></li>
<li><p><strong>All Gather Operations:</strong> Used to gather necessary data from different GPUs during model training.</p></li>
<li><p><strong>Layers</strong>:</p>
<ul>
<li>Every PyTorch <code>nn</code> module is a tree of more <code>nn</code> modules.</li>
<li>The user’s wrapping policy determines what gets treated as its own “layer”.</li>
<li>What you decided to wrap influences memory usage
<ul>
<li>Smaller blobs = less memory needs to be all-gathered at a time.</li>
</ul></li>
</ul></li>
<li><p><strong>CPU Offloading:</strong></p>
<ul>
<li><p>Can keep parameters on the CPU and move them to the GPU when computing forward + backward.</p></li>
<li><p>The optimizer update will be done on CPU, so the optim state lives there too.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/images/fsdp-memory-step-cpu-offloading.png" class="img-fluid figure-img"></p>
<figcaption>FSDP CPU Offloading - Slaying OOMs: Slide 25</figcaption>
</figure>
</div></li>
</ul></li>
</ul>
</section>
<section id="fsdp1-vs.-fsdp2" class="level3">
<h3 class="anchored" data-anchor-id="fsdp1-vs.-fsdp2">FSDP1 vs.&nbsp;FSDP2</h3>
<ul>
<li><p><strong>Goal:</strong> Make all-gather efficient</p></li>
<li><p><strong>Constraint:</strong> <a href="https://developer.nvidia.com/nccl">NCCL</a> (NVIDIA Collective Communications Library) requires each GPU contribute same-size Tensors</p></li>
<li><p><strong>FSDP1:</strong></p>
<ul>
<li><p>Flattens and concatenates all tensors before sharding, potentially leading to type and metadata conflicts.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/images/flatparam-fsdp-1.png" class="img-fluid figure-img"></p>
<figcaption>FlatParam FSDP - Slaying OOMs: Slide 28</figcaption>
</figure>
</div>
<ul>
<li><code>t1</code> and the first part of <code>t2</code> get combined into a single tensor</li>
<li>The second part of <code>t2</code> gets combined with <code>t3</code> into a single tensor</li>
<li><code>t2</code> gets split between GPUs</li>
<li>Forces <code>t1</code>, <code>t2</code>, and <code>t3</code> to all have the same d-type and other metadata</li>
</ul></li>
<li><p>Can lead to non-deterministic memory spikes, making memory management challenging.</p></li>
</ul></li>
<li><p><strong>FSDP2 (Per-Parameter FSDP):</strong></p>
<ul>
<li><p>Introduces distributed tensors (D-tensors) that allow for sharding individual tensors, preserving their original data types and metadata.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/images/per-parameter-fsdp-2.png" class="img-fluid figure-img"></p>
<figcaption>Per-Parameter FSDP - Slaying OOMs: Slide 30</figcaption>
</figure>
</div></li>
<li><p>Offers better memory determinism, ensuring more predictable and manageable memory usage.</p></li>
<li><p>Enables more flexible and efficient training scenarios, especially when combined with techniques like QLoRA.</p></li>
<li><p>Requires extra copies during all-gather compared to FSDP1</p></li>
<li><p><strong>Forum Post:</strong> <a href="https://dev-discuss.pytorch.org/t/fsdp-cudacachingallocator-an-outsider-newb-perspective/1486/1">FSDP &amp; CUDACachingAllocator: an outsider newb perspective</a></p></li>
</ul></li>
</ul>
</section>
<section id="cpu-offloading" class="level3">
<h3 class="anchored" data-anchor-id="cpu-offloading">CPU Offloading</h3>
<ul>
<li>Leverages CPU memory to store parameters and optimizer states, further reducing the memory load on GPUs.</li>
<li>Offloads the optimizer step to the CPU, allowing GPUs to focus on computationally intensive forward and backward passes.</li>
</ul>
</section>
</section>
<section id="benchmarking-fsdp2" class="level2">
<h2 class="anchored" data-anchor-id="benchmarking-fsdp2">Benchmarking FSDP2</h2>
<section id="benchmarking-plan" class="level3">
<h3 class="anchored" data-anchor-id="benchmarking-plan">Benchmarking Plan</h3>
<ul>
<li><strong>Goal:</strong> Run benchmarks, identify performance gaps between FSDP2 and the baseline (FSDP1 &amp; bnb), and explore ways to improve FSDP2’s speed.</li>
<li><strong>Hardware:</strong> Two NVIDIA 3090 GPUs (consumer-grade, 24GB VRAM each) acquired from Vast AI.</li>
<li><strong>Baseline:</strong> Answer.ai’s train.py with FSDP1 and bnb, using a batch size of 8.</li>
</ul>
</section>
<section id="initial-benchmarking-and-discrepancies" class="level3">
<h3 class="anchored" data-anchor-id="initial-benchmarking-and-discrepancies">Initial Benchmarking and Discrepancies</h3>
<ul>
<li><p><strong>Benchmarking Environments:</strong></p>
<ul>
<li><p><a href="https://github.com/AnswerDotAI/fsdp_qLoRA/blob/main/train.py">Answer.ai’s train.py</a> (command-line configuration)</p>
<ul>
<li><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb3-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">python</span> train.py <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--model_name</span> meta-llama/Llama-2-7b-hf <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--batch_size</span> 8 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--context_length</span> 2048 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--train_type</span></span>
<span id="cb3-2">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">qLoRA</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--use_gradient_checkpointing</span> True <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--reentrant_checkpointing</span> True <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--dataset</span> dummy <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--dataset_samples</span></span>
<span id="cb3-3">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">48</span></span></code></pre></div></li>
</ul></li>
<li><p><a href="https://github.com/pytorch/torchtune/blob/1fa1f04baf124c074dcd93831fa38c8b657af1e9/recipes/configs/dev/llama2/7B_qLoRA_fsdp2.yaml">TorchTune recipe</a> (YAML configuration)</p></li>
</ul></li>
<li><p><strong>Initial Findings:</strong></p>
<ul>
<li><table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>batch size</th>
<th>peak memory</th>
<th>runtime for a step</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>train.py</td>
<td>8</td>
<td>12.88 GiB</td>
<td>14.0s</td>
</tr>
<tr class="even">
<td>torchtune</td>
<td>8</td>
<td>12.60 GiB</td>
<td>16.5s</td>
</tr>
</tbody>
</table></li>
<li><p>FSDP2 showed better peak memory usage.</p></li>
<li><p>FSDP2 was slower in runtime.</p></li>
</ul></li>
<li><p><strong>Tracing Analysis (Perfetto):</strong></p>
<ul>
<li><strong>Blog Posts:</strong>
<ul>
<li><a href="https://pytorch.org/blog/understanding-gpu-memory-1/">Understanding GPU Memory 1: Visualizing All Allocations over Time</a></li>
<li><a href="https://pytorch.org/blog/understanding-gpu-memory-2/">Understanding GPU Memory 2: Finding and Removing Reference Cycles</a></li>
</ul></li>
<li><strong>Traces:</strong>
<ul>
<li><strong>Google Drive:</strong> <a href="https://drive.google.com/file/d/1ObfUUySBwuaCSLMXRxFiM1w7XYMebxvB/view">answer.ai train.py</a></li>
<li><strong>Google Drive:</strong> <a href="https://drive.google.com/file/d/1BpdlZZ55746IHcifho2u2okJQ1ihr8dY/view">torchtune</a></li>
</ul></li>
<li><strong><a href="https://ui.perfetto.dev/">Perfetto</a>:</strong> A production-grade open-source stack for performance instrumentation and trace analysis</li>
<li><strong>Significant difference in the number of optimizer steps:</strong> The optimizer took much longer in FSDP2.</li>
<li><strong>Double the number of operations:</strong> Indicating FSDP2 might be training on more parameters than the baseline.</li>
</ul></li>
</ul>
</section>
<section id="identifying-the-root-causes" class="level3">
<h3 class="anchored" data-anchor-id="identifying-the-root-causes">Identifying the Root Causes</h3>
<ul>
<li><strong>Root Cause 1: Configuration Discrepancy</strong>
<ul>
<li>TorchTune recipe LoRA-fied to the output projection (adding two low rank adapters per layer), resulting in 64 additional parameters compared to train.py.</li>
</ul></li>
<li><strong>Root Cause 2: Tensor Subclass Dispatch Overhead</strong>
<ul>
<li>Distributed tensors (D-tensors) introduce overhead due to metadata unwrapping during kernel calls.</li>
<li>This overhead was amplified by the increased number of parameters, making the optimizer step significantly slower in FSDP2.</li>
</ul></li>
</ul>
</section>
<section id="addressing-the-discrepancies-and-further-benchmarking" class="level3">
<h3 class="anchored" data-anchor-id="addressing-the-discrepancies-and-further-benchmarking">Addressing the Discrepancies and Further Benchmarking</h3>
<ul>
<li><strong>Ensuring Apples-to-Apples Comparison:</strong>
<ul>
<li>Standardized the dataset, parameter count, and wrapping policy across benchmarks.</li>
</ul></li>
<li><strong>Results After Standardization:</strong>
<ul>
<li>Still slower runtime for FSDP2.</li>
<li>Significantly improved peak memory usage.</li>
</ul></li>
<li><strong>Further Analysis:</strong>
<ul>
<li>Focused on forward pass, backward pass, and optimizer as the main culprits for the remaining performance gap.</li>
</ul></li>
</ul>
</section>
<section id="deep-dive-into-performance-gaps" class="level3">
<h3 class="anchored" data-anchor-id="deep-dive-into-performance-gaps">Deep Dive into Performance Gaps</h3>
<ul>
<li><strong>Gap 1: Optimizer Step Slowdown</strong>
<ul>
<li><strong>Problem:</strong> D-tensor overhead resulted in a 3x slower optimizer step.</li>
<li><strong>Solution:</strong> Collaborated with Intel to develop a fused Adam optimizer kernel for single dispatch and vectorization, leading to an 8x speedup.</li>
</ul></li>
<li><strong>Gap 2: Larger All Gather Operations</strong>
<ul>
<li><strong>Problem 1:</strong> FSDP2 packed more data (scalars and quantization factors) into the all gather operation, unlike the baseline.</li>
<li><strong>Problem 2:</strong> Output projection wasn’t quantized in FSDP2 when opting out of LoRA, leading to a 4x larger size compared to the baseline.</li>
<li><strong>Solution:</strong>
<ul>
<li>Problem 1 is expected behavior.</li>
<li>Problem 2 will be addressed by TorchTune in future releases.</li>
</ul></li>
</ul></li>
<li><strong>Gap 3: Overhead from Dequantization</strong>
<ul>
<li><strong>Problem:</strong> FSDP2’s dequantization process from NF4 to BF16 for CUDA kernels was less efficient than the specialized implementation used in the baseline.</li>
<li><strong>Solution:</strong> Explore using Torch Compile, custom Torch kernels, or Triton kernels for faster dequantization.</li>
</ul></li>
<li><strong>Gap 4: Different Rope Algorithms</strong>
<ul>
<li><strong>Problem:</strong> TorchTune and the baseline employed different Rope algorithms, leading to different operations before the SDPA.</li>
<li><strong>Solution:</strong> TorchTune to offer a wider selection of Rope algorithms.</li>
</ul></li>
<li><strong>Gap 5: Overlapping Communication and Computation</strong>
<ul>
<li><strong>Problem:</strong> FSDP2’s stricter memory management exposed inefficiencies in overlapping CPU offloading with computation. The computation tasks were much smaller than the communication tasks, leading to idle time.</li>
<li><strong>Solution:</strong> Adjusted the wrapping policy to group layers differently, enabling better overlap and reducing idle time. This solution is only feasible with FSDP2 due to its ability to handle mixed precision within a layer.</li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/</guid>
  <pubDate>Wed, 24 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 10: Systematically Improving RAG Applications</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-010/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>The RAG Playbook</li>
<li>Identifying and Addressing Issues</li>
<li>Real-Time Monitoring and Classifiers</li>
<li>Low-Hanging Fruit and Synthetic Data Generation</li>
<li>Importance of Full Text Search and Metadata</li>
<li>Conclusion</li>
<li>Q&amp;A Session</li>
</ul>
<section id="the-rag-playbook" class="level2">
<h2 class="anchored" data-anchor-id="the-rag-playbook">The RAG Playbook</h2>
<ul>
<li><strong>Blog Posts:</strong> <a href="https://jxnl.co/writing/category/rag/">Jason Liu RAG</a></li>
</ul>
<section id="importance-of-feedback-mechanisms" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-feedback-mechanisms">Importance of Feedback Mechanisms</h3>
<ul>
<li>Define clear objectives for your RAG application. What user behavior are you trying to drive?</li>
<li>Don’t try to improve everything at once. Focus on specific areas identified through data analysis.</li>
</ul>
</section>
<section id="capturing-feedback-user-satisfaction" class="level3">
<h3 class="anchored" data-anchor-id="capturing-feedback-user-satisfaction">Capturing Feedback: User Satisfaction</h3>
<ul>
<li>Implement simple feedback mechanisms like thumbs up/thumbs down buttons.</li>
<li>Carefully choose the copy for feedback prompts to ensure you’re measuring the intended metric (e.g., answer correctness vs.&nbsp;overall experience).</li>
<li>Example: Changing feedback prompt from “How did we do?” to “Did we answer your question?” led to a 5x increase in feedback volume and improved data quality.</li>
</ul>
</section>
<section id="measuring-relevancy-cosine-and-re-ranker-scores" class="level3">
<h3 class="anchored" data-anchor-id="measuring-relevancy-cosine-and-re-ranker-scores">Measuring Relevancy: Cosine and Re-ranker Scores</h3>
<ul>
<li>Track objective relevancy metrics alongside user feedback.</li>
<li>Use cosine similarity of embedding scores and re-ranker scores as cost-effective measures of relevancy.</li>
<li><strong>reranker:</strong> A type of model that, given a query and document pair, will output a similarity score.</li>
<li><strong>Tool:</strong>
<ul>
<li><strong><a href="https://github.com/AnswerDotAI/rerankers">rerankers</a>:</strong> A lightweight unified API for various reranking models.</li>
</ul></li>
</ul>
</section>
<section id="unsupervised-learning-for-topic-clustering" class="level3">
<h3 class="anchored" data-anchor-id="unsupervised-learning-for-topic-clustering">Unsupervised Learning for Topic Clustering</h3>
<ul>
<li>Employ unsupervised learning techniques like LDA or BERTopic to group similar queries into topics.
<ul>
<li><strong>LDA:</strong>
<ul>
<li><strong>Paper:</strong> <a href="https://ai.stanford.edu/~ang/papers/jair03-lda.pdf">Latent Dirichlet Allocation</a></li>
</ul></li>
<li><strong>BERTopic:</strong>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2203.05794">BERTopic: Neural topic modeling with a class-based TF-IDF procedure</a></li>
<li><strong>Documentation:</strong> <a href="https://maartengr.github.io/BERTopic/index.html">BERTopic</a></li>
</ul></li>
</ul></li>
<li>Analyze topic clusters based on:
<ul>
<li>Number of questions within the topic</li>
<li>Mean cosine similarity score</li>
<li>Mean user satisfaction score</li>
</ul></li>
</ul>
</section>
<section id="prioritizing-improvement-based-on-topic-analysis" class="level3">
<h3 class="anchored" data-anchor-id="prioritizing-improvement-based-on-topic-analysis">Prioritizing Improvement Based on Topic Analysis</h3>
<ul>
<li>Prioritize topics with:
<ul>
<li>High volume (many questions)</li>
<li>Low relevancy scores</li>
<li>Low user satisfaction scores</li>
</ul></li>
<li>Consider deprioritizing or explicitly excluding topics with low volume, low relevancy, and low satisfaction.</li>
<li>Different combinations of volume, relevancy, and satisfaction provide insights into different types of issues requiring specific solutions.</li>
</ul>
</section>
</section>
<section id="identifying-and-addressing-issues" class="level2">
<h2 class="anchored" data-anchor-id="identifying-and-addressing-issues">Identifying and Addressing Issues</h2>
<section id="content-vs.-capability-topics" class="level3">
<h3 class="anchored" data-anchor-id="content-vs.-capability-topics">Content vs.&nbsp;Capability Topics</h3>
<ul>
<li><strong>Content topics:</strong> Issues stem from insufficient or inadequate content in the knowledge base.
<ul>
<li>Example: Users asking about pricing, but not enough pricing documents available.</li>
</ul></li>
<li><strong>Capability topics:</strong> Issues relate to limitations in the system’s functionality.
<ul>
<li>Example: Users asking for the last modified date of a document, but this information is not available to the language model.</li>
</ul></li>
</ul>
</section>
<section id="examples-of-capability-topics-and-solutions" class="level3">
<h3 class="anchored" data-anchor-id="examples-of-capability-topics-and-solutions">Examples of Capability Topics and Solutions</h3>
<ul>
<li><strong>Modified dates:</strong> Include last modified date metadata in text chunks.</li>
<li><strong>Comparing and contrasting:</strong> Implement parallel search functionality.</li>
<li><strong>Recency and latency:</strong> Add date range filtering capabilities.</li>
<li><strong>Financial year variations:</strong> Account for industry-specific fiscal year definitions.</li>
</ul>
</section>
<section id="addressing-inventory-issues-and-building-rules" class="level3">
<h3 class="anchored" data-anchor-id="addressing-inventory-issues-and-building-rules">Addressing Inventory Issues and Building Rules</h3>
<ul>
<li><strong>Address content topics by:</strong>
<ul>
<li>Identifying and filling inventory gaps.</li>
</ul></li>
<li><strong>Build rules to:</strong>
<ul>
<li>Alert content management teams when questions frequently lack relevant documents.</li>
<li>Inform users when insufficient data is available to answer their query.</li>
</ul></li>
</ul>
</section>
</section>
<section id="real-time-monitoring-and-classifiers" class="level2">
<h2 class="anchored" data-anchor-id="real-time-monitoring-and-classifiers">Real-Time Monitoring and Classifiers</h2>
<section id="building-classifiers-for-real-time-question-categorization" class="level3">
<h3 class="anchored" data-anchor-id="building-classifiers-for-real-time-question-categorization">Building Classifiers for Real-Time Question Categorization</h3>
<ul>
<li>Develop classifiers to categorize new questions into previously identified topics and capability clusters in real-time.</li>
</ul>
</section>
<section id="monitoring-question-distribution-and-prioritization-over-time" class="level3">
<h3 class="anchored" data-anchor-id="monitoring-question-distribution-and-prioritization-over-time">Monitoring Question Distribution and Prioritization Over Time</h3>
<ul>
<li>Use tools like Amplitude or Datadog to monitor the distribution of question types over time.
<ul>
<li><strong>Amplitude:</strong> <a href="https://amplitude.com/">https://amplitude.com/</a></li>
<li><strong>Datadog:</strong> <a href="https://www.datadoghq.com/">https://www.datadoghq.com/</a></li>
</ul></li>
<li>Identify shifts in user needs and adjust prioritization accordingly.</li>
<li><strong>Example:</strong> Onboarding a new client significantly increases the volume of “comparing and contrasting” questions, highlighting the need to prioritize that capability.</li>
</ul>
</section>
</section>
<section id="low-hanging-fruit-and-synthetic-data-generation" class="level2">
<h2 class="anchored" data-anchor-id="low-hanging-fruit-and-synthetic-data-generation">Low-Hanging Fruit and Synthetic Data Generation</h2>
<section id="focusing-on-specific-improvements" class="level3">
<h3 class="anchored" data-anchor-id="focusing-on-specific-improvements">Focusing on Specific Improvements</h3>
<ul>
<li>Translate ambiguous goals like “improving RAG” into concrete, measurable objectives (e.g., “improving datetime filtering”).</li>
<li>Break down large improvements into smaller, manageable experiments.</li>
</ul>
</section>
<section id="synthetic-data-generation-for-baseline-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="synthetic-data-generation-for-baseline-evaluation">Synthetic Data Generation for Baseline Evaluation</h3>
<ul>
<li>Generate synthetic data for specific topics to:
<ul>
<li>Establish baselines for evaluating the impact of system changes.</li>
<li>Test the effectiveness of new datasets or models.</li>
</ul></li>
</ul>
</section>
</section>
<section id="importance-of-full-text-search-and-metadata" class="level2">
<h2 class="anchored" data-anchor-id="importance-of-full-text-search-and-metadata">Importance of Full Text Search and Metadata</h2>
<section id="benefits-of-full-text-search-and-re-rankers" class="level3">
<h3 class="anchored" data-anchor-id="benefits-of-full-text-search-and-re-rankers">Benefits of Full Text Search and Re-Rankers</h3>
<ul>
<li>Incorporate full text search capabilities for robust retrieval.</li>
<li>Utilize re-ranker models to improve the ranking of retrieved results.</li>
</ul>
</section>
<section id="importance-of-metadata-filtering" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-metadata-filtering">Importance of Metadata Filtering</h3>
<ul>
<li>Include relevant metadata (e.g., author, date, document type) to enable granular filtering.</li>
<li>Example: “Show me the latest pricing document for Fortune 500 companies” requires filtering by date, document type, and client category.</li>
</ul>
</section>
<section id="measuring-impact-and-driving-business-outcomes" class="level3">
<h3 class="anchored" data-anchor-id="measuring-impact-and-driving-business-outcomes">Measuring Impact and Driving Business Outcomes</h3>
<ul>
<li>Track relevant metrics (e.g., character length, latency) and correlate them with business outcomes (e.g., user conversion, engagement).</li>
</ul>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<ul>
<li>The key to improving RAG applications is to adopt a systematic, data-driven approach.</li>
<li>By analyzing user feedback, clustering queries, and monitoring question distribution, developers can identify and prioritize areas for improvement.</li>
<li>Focusing on specific, measurable goals and utilizing synthetic data generation enables efficient testing and iteration.</li>
</ul>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<section id="how-much-data-is-needed-for-these-techniques-to-be-worthwhile" class="level3">
<h3 class="anchored" data-anchor-id="how-much-data-is-needed-for-these-techniques-to-be-worthwhile">How much data is needed for these techniques to be worthwhile?</h3>
<ul>
<li>Even with small datasets (e.g., 100 queries), clustering techniques can reveal patterns and differences in query types (e.g., time-sensitive queries).</li>
<li>Clustering enables focusing on specific query groups and tailoring optimization efforts.</li>
<li>Early clustering allows for proactive identification of potential issues and areas for improvement.</li>
</ul>
</section>
<section id="how-to-build-a-data-ingestion-pipeline-for-complex-data" class="level3">
<h3 class="anchored" data-anchor-id="how-to-build-a-data-ingestion-pipeline-for-complex-data">How to build a data ingestion pipeline for complex data?</h3>
<ul>
<li><strong>Understand user questions:</strong> Determine how users interact with different data types (e.g., extracting specific information from images or answering questions about charts).</li>
<li><strong>Generate text summaries:</strong> Create text representations of images, charts, and tables to enable text-based search and retrieval.</li>
<li><strong>Use specialized libraries:</strong> Leverage libraries for extracting structured data like tables from PDFs, addressing potential challenges like nested headers.</li>
</ul>
</section>
<section id="how-to-handle-tables-in-rag-applications" class="level3">
<h3 class="anchored" data-anchor-id="how-to-handle-tables-in-rag-applications">How to handle tables in RAG applications?</h3>
<ul>
<li><strong>Understand query intent:</strong> Determine whether users seek aggregate statistics or specific rows within tables.</li>
<li><strong>Choose appropriate processing:</strong> Utilize Text-to-SQL engines for aggregate queries or chunk tables strategically for row-based searches.</li>
<li><strong>Consider table size and complexity:</strong> Large tables may necessitate alternative approaches like using SQLite or optimized search techniques.</li>
</ul>
</section>
<section id="how-to-capture-feedback-when-rag-is-hidden-from-the-user" class="level3">
<h3 class="anchored" data-anchor-id="how-to-capture-feedback-when-rag-is-hidden-from-the-user">How to capture feedback when RAG is hidden from the user?</h3>
<ul>
<li><strong>Analyze user interactions:</strong> Track edits to report fields to identify areas requiring frequent corrections.</li>
<li><strong>Monitor internal RAG metrics:</strong> Analyze cosine distances and re-ranker scores across different fields to pinpoint areas for improvement.</li>
<li><strong>Design for feedback:</strong> Ensure reports allow for user feedback and facilitate mapping feedback to specific report elements.</li>
</ul>
</section>
<section id="how-to-capture-feedback-and-iterate-quickly" class="level3">
<h3 class="anchored" data-anchor-id="how-to-capture-feedback-and-iterate-quickly">How to capture feedback and iterate quickly?</h3>
<ul>
<li><strong>Write assertions for extractable facts:</strong> Create tests to verify the accuracy of extracted information against ground truth, enabling rapid iteration without deploying the system.</li>
<li><strong>Use automated testing:</strong> Automate the evaluation process to speed up development and identify regressions.</li>
</ul>
</section>
<section id="why-use-cosine-distance-as-a-metric-when-its-relative" class="level3">
<h3 class="anchored" data-anchor-id="why-use-cosine-distance-as-a-metric-when-its-relative">Why use cosine distance as a metric when it’s relative?</h3>
<ul>
<li><strong>Provides a quantifiable measure:</strong> Cosine distance offers a numerical representation of relevance, even if relative, allowing for comparisons and tracking progress.</li>
<li><strong>Available for every request:</strong> Unlike user feedback, which can be sparse, cosine distance can be calculated for every query, providing more data points for analysis.</li>
<li><strong>Useful for relative comparisons:</strong> Focus on the relative differences in cosine distances between queries and text chunks to identify areas for improvement.</li>
</ul>
</section>
<section id="how-to-incorporate-metadata-filtering-in-rag" class="level3">
<h3 class="anchored" data-anchor-id="how-to-incorporate-metadata-filtering-in-rag">How to incorporate metadata filtering in RAG?</h3>
<ul>
<li><strong>Use language models for structured outputs:</strong> Utilize models like Instructor to generate structured representations of queries, including metadata filters like date ranges and allowed domains.</li>
<li><strong>Customize metadata extraction:</strong> Define custom metadata fields based on the specific data and user needs.</li>
<li><strong>Leverage metadata in search:</strong> Integrate metadata filters into the search process to narrow down relevant documents and improve accuracy.</li>
</ul>
</section>
<section id="how-to-use-language-models-for-metadata-creation" class="level3">
<h3 class="anchored" data-anchor-id="how-to-use-language-models-for-metadata-creation">How to use language models for metadata creation?</h3>
<ul>
<li><strong>Extract specific information:</strong> Use language models to extract relevant metadata from documents, such as converting financial reporting periods based on industry-specific rules.</li>
<li><strong>Generate synthetic queries from complex content:</strong> Extract complex diagrams and tables, then use language models to generate related questions, embedding those questions as metadata for improved retrieval.</li>
</ul>
</section>
<section id="favorite-platforms-for-building-rag-systems" class="level3">
<h3 class="anchored" data-anchor-id="favorite-platforms-for-building-rag-systems">Favorite platforms for building RAG systems?</h3>
<ul>
<li><strong>LanceDB:</strong> Favored for its ability to combine full-text search, SQL, and vector search in a single database, simplifying the development process.
<ul>
<li><strong><a href="https://lancedb.com/">LanceDB</a>:</strong> The Database for Multimodal AI</li>
</ul></li>
<li><strong>Custom solutions:</strong> Building custom query engines and processors provides greater control and flexibility, especially for handling specific data structures and complex search requirements.</li>
</ul>
</section>
<section id="how-to-develop-intuition-for-user-questions-at-the-start-of-a-project" class="level3">
<h3 class="anchored" data-anchor-id="how-to-develop-intuition-for-user-questions-at-the-start-of-a-project">How to develop intuition for user questions at the start of a project?</h3>
<ul>
<li><strong>Generate synthetic queries:</strong> Utilize language models to generate synthetic queries from the data, revealing potential search challenges and guiding UI design.</li>
<li><strong>Start with a hypothesis:</strong> Base initial development on assumptions about user questions, then refine based on real-world data and feedback.</li>
<li><strong>Iterate based on feedback:</strong> Continuously analyze user queries, identify gaps in the system’s understanding, and adapt the system accordingly.</li>
</ul>
</section>
<section id="when-does-bm25-outperform-semantic-search" class="level3">
<h3 class="anchored" data-anchor-id="when-does-bm25-outperform-semantic-search">When does BM25 outperform semantic search?</h3>
<ul>
<li><strong>Wikipedia:</strong> <a href="https://en.wikipedia.org/wiki/Okapi_BM25">Okapi BM25</a></li>
<li><strong>Stanford IR Book:</strong> <a href="https://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html">Okapi BM25: a non-binary model</a></li>
<li><strong>Document search:</strong> When users are searching for specific documents they authored or are familiar with, BM25 excels due to its keyword-matching approach.</li>
<li><strong>Exact word matches:</strong> BM25 performs well when users use the same terminology as the document authors, common when searching personal notes or transcripts.</li>
</ul>
</section>
<section id="how-to-design-a-good-ux-for-report-editing-in-rag-applications" class="level3">
<h3 class="anchored" data-anchor-id="how-to-design-a-good-ux-for-report-editing-in-rag-applications">How to design a good UX for report editing in RAG applications?</h3>
<ul>
<li><strong>Utilize structured outputs:</strong> Structure report data using keys and values to enable granular editing and facilitate attributing edits to specific report elements.</li>
<li><strong>Avoid monolithic markdown outputs:</strong> Markdown, while seemingly structured, poses challenges in tracking edits and associating them with underlying data.</li>
</ul>
</section>
<section id="how-to-implement-citations-in-rag-systems" class="level3">
<h3 class="anchored" data-anchor-id="how-to-implement-citations-in-rag-systems">How to implement citations in RAG systems?</h3>
<ul>
<li><strong>Cite entire text chunks:</strong> Include text chunk IDs as citations within the generated response.</li>
<li><strong>Leverage markdown formatting:</strong> Format citations as markdown URLs for improved readability and potential integration with UI elements for displaying cited text.</li>
</ul>
</section>
<section id="high-dimension-embedding-models-vs.-cross-encoder-models-for-re-ranking" class="level3">
<h3 class="anchored" data-anchor-id="high-dimension-embedding-models-vs.-cross-encoder-models-for-re-ranking">High-dimension embedding models vs.&nbsp;cross-encoder models for re-ranking?</h3>
<ul>
<li><strong>Use both:</strong> Employ a multi-stage re-ranking approach using both vector databases and cross-encoders to balance speed and accuracy.</li>
<li><strong>Prioritize speed with vector databases:</strong> Utilize vector databases for fast initial retrieval, narrowing down the candidate pool for the more computationally expensive cross-encoder.</li>
<li><strong>Leverage cross-encoders for nuanced relevance:</strong> Employ cross-encoders to capture subtle semantic similarities and differences that vector databases might miss.</li>
</ul>
</section>
<section id="thoughts-on-hierarchical-retrievers-and-fine-tuning-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="thoughts-on-hierarchical-retrievers-and-fine-tuning-embeddings">Thoughts on hierarchical retrievers and fine-tuning embeddings?</h3>
<ul>
<li><strong>Hierarchical retrievers:</strong> Potentially less crucial with increasing context lengths in language models, but still valuable for ensuring retrieval of related information across chunks.</li>
<li><strong>Fine-tuning embeddings:</strong> Crucial for improving relevance in domain-specific applications, outperforming generic embedding models, especially with sufficient training data.</li>
</ul>
</section>
<section id="tips-for-improving-data-extraction-from-tables-and-pdfs" class="level3">
<h3 class="anchored" data-anchor-id="tips-for-improving-data-extraction-from-tables-and-pdfs">Tips for improving data extraction from tables and PDFs?</h3>
<ul>
<li><strong>Utilize specialized tools:</strong> Leverage tools like LlamaParse, which combine language models and traditional text extraction techniques for improved accuracy.
<ul>
<li><strong>LlamaParse:</strong> <a href="https://docs.llamaindex.ai/en/stable/llama_cloud/llama_parse/">Documentation</a></li>
</ul></li>
<li><strong>Experiment with output formats:</strong> Consider requesting markdown table outputs from language models instead of CSVs, as markdown often handles complex table structures better.</li>
<li><strong>Leverage advanced language models:</strong> Utilize models like GPT-4.0 or Opus to process images of tables and generate structured outputs like markdown tables.</li>
</ul>
</section>
<section id="guidelines-for-metrics-and-telemetry-in-rag-systems" class="level3">
<h3 class="anchored" data-anchor-id="guidelines-for-metrics-and-telemetry-in-rag-systems">Guidelines for metrics and telemetry in RAG systems?</h3>
<ul>
<li><strong>Treat RAG like recommendation systems:</strong> Instrument RAG systems similarly to recommendation systems, tracking user interactions, retrieval metrics, and feedback.</li>
<li><strong>Log relevant data:</strong> Capture data on user queries, retrieved text chunks, citations, and user feedback for analysis and model improvement.</li>
<li><strong>Utilize micro-interactions for feedback:</strong> Treat interactions like citations as implicit feedback, leveraging it to fine-tune embedding models and improve retrieval relevance.</li>
</ul>
</section>
<section id="recommendations-for-picking-embedding-models" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-for-picking-embedding-models">Recommendations for picking embedding models?</h3>
<ul>
<li><strong>Evaluate with synthetic data:</strong> Create synthetic datasets with question-answer pairs and evaluate different embedding models to determine which performs best for the specific task.</li>
<li><strong>Fine-tune with real data:</strong> Once sufficient real-world data is available, fine-tune embedding models to further enhance relevance and outperform generic models.</li>
</ul>
</section>
<section id="balancing-upfront-data-inspection-with-adaptation-over-time" class="level3">
<h3 class="anchored" data-anchor-id="balancing-upfront-data-inspection-with-adaptation-over-time">Balancing upfront data inspection with adaptation over time?</h3>
<ul>
<li><strong>Iterative approach:</strong> Combine upfront data analysis with ongoing monitoring and adaptation.</li>
<li><strong>Clustering and labeling:</strong> Cluster initial datasets to understand query patterns and create labels for different query types.</li>
<li><strong>Monitor for drift:</strong> Regularly monitor the percentage of uncategorized queries (“other”) to identify shifts in user behavior and adapt the system accordingly.</li>
</ul>
</section>
<section id="how-to-teach-clients-to-analyze-data-for-rag-applications" class="level3">
<h3 class="anchored" data-anchor-id="how-to-teach-clients-to-analyze-data-for-rag-applications">How to teach clients to analyze data for RAG applications?</h3>
<ul>
<li><strong>Focus on the scientific method:</strong> Guide clients through a process of hypothesis generation, data collection, experimentation, and iteration.</li>
<li><strong>Provide clear visualizations and reports:</strong> Present data analysis results in an easily understandable format to facilitate decision-making and identify areas for improvement.</li>
</ul>
</section>
<section id="choosing-between-vector-databases-and-cross-encoders" class="level3">
<h3 class="anchored" data-anchor-id="choosing-between-vector-databases-and-cross-encoders">Choosing between vector databases and cross-encoders?</h3>
<ul>
<li><strong>Consider both evaluation results and latency constraints:</strong> Balance the trade-off between accuracy (often favoring cross-encoders) and speed (favoring vector databases).</li>
<li><strong>Prioritize business outcomes:</strong> Ultimately, the choice should align with achieving desired business outcomes, considering factors like user experience and cost.</li>
</ul>
</section>
<section id="how-to-handle-frequently-occurring-statements-in-rag" class="level3">
<h3 class="anchored" data-anchor-id="how-to-handle-frequently-occurring-statements-in-rag">How to handle frequently occurring statements in RAG?</h3>
<ul>
<li><strong>Create dedicated text chunks:</strong> If a specific statement appears frequently and holds significance for users, create dedicated text chunks containing variations of that statement to ensure retrieval.</li>
<li><strong>Augment the dataset:</strong> Use language models to extract relevant clauses and statements from documents, creating augmented text chunks to improve retrieval of specific information.</li>
</ul>
</section>
<section id="recommendations-for-vector-stores-and-metadata" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-for-vector-stores-and-metadata">Recommendations for vector stores and metadata?</h3>
<ul>
<li><strong>Think beyond vector stores:</strong> View the problem as building a search engine, considering various components like BM25, SQL, and vector search, not just vector stores in isolation.</li>
<li><strong>Choose tools based on specific needs:</strong> Select technologies and approaches that best suit the project’s requirements, data characteristics, and available resources.</li>
</ul>
</section>
<section id="finding-early-customers-for-rag-consulting" class="level3">
<h3 class="anchored" data-anchor-id="finding-early-customers-for-rag-consulting">Finding early customers for RAG consulting?</h3>
<ul>
<li><strong>Leverage experience from recommendation systems:</strong> Position RAG expertise by drawing parallels to recommendation systems, highlighting transferable skills in data analysis, model development, and system optimization.</li>
<li><strong>Target businesses with similar workflows:</strong> Focus on businesses where users interact with information similarly to recommendation systems, such as those requiring information retrieval and synthesis based on user requests.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-010/</guid>
  <pubDate>Sat, 20 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 9: Why Fine-Tuning is Dead</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-009/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Trends in Machine Learning</li>
<li>Performance Observations: Fine-tuning vs.&nbsp;RAG</li>
<li>The Moving Target: Fine-tuning and Frontier Models</li>
<li>The Difficulty of Fine-tuning: Prioritizing Fundamentals</li>
<li>Extrapolating Trends: Context Size, Price, and Latency</li>
<li>Conclusion</li>
<li>Q&amp;A Session</li>
</ul>
<section id="trends-in-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="trends-in-machine-learning">Trends in Machine Learning</h2>
<ul>
<li><strong>Focus on fundamentals:</strong> Throughout ML history, focusing on “boring” fundamentals like data quality and SQL queries often yielded better results than chasing the latest “cool” technology.
<ul>
<li><strong>2009:</strong> Data analysis and SQL were more impactful than training ML models.</li>
<li><strong>2012-2014:</strong> XGBoost outperformed deep learning for many tasks.</li>
<li><strong>2015:</strong> Data cleaning and error correction were more effective than inventing new loss functions.</li>
<li><strong>2023:</strong> Prompting and RAG often outperform fine-tuning.</li>
</ul></li>
<li><strong>Fine-tuning’s uncertain future:</strong> While fine-tuning became popular with the rise of pre-trained models like ResNet and BERT, LLMs might be shifting the paradigm again towards prompt-based and RAG-augmented approaches.</li>
</ul>
<section id="qa-on-trends-and-embedding-models" class="level3">
<h3 class="anchored" data-anchor-id="qa-on-trends-and-embedding-models">Q&amp;A on Trends and Embedding Models</h3>
<ul>
<li><strong>Fine-tuning’s future relevance:</strong> Fine-tuning might still become more valuable in the future, just like deep learning did after an initial period of limited practical use.</li>
<li><strong>Embedding models:</strong> While LLMs are currently the focus of improvement, embedding models might also see advancements that reduce the need for fine-tuning. However, domain-specific applications might still require fine-tuning or hybrid approaches like combining keyword search with embedding search.</li>
<li><strong>Domain-specific ranking and retrieval:</strong> RAG, combined with techniques like query expansion driven by LLMs, might be able to address the need for domain-specific ranking and retrieval without fine-tuning embedding models.</li>
<li><strong>Benchmarking prompting vs.&nbsp;fine-tuning:</strong> Limited data exists comparing prompting and RAG to fine-tuning, but existing research suggests RAG often outperforms fine-tuning.</li>
</ul>
</section>
</section>
<section id="performance-observations-fine-tuning-vs.-rag" class="level2">
<h2 class="anchored" data-anchor-id="performance-observations-fine-tuning-vs.-rag">Performance Observations: Fine-tuning vs.&nbsp;RAG</h2>
<ul>
<li><strong>RAG often outperforms fine-tuning:</strong> Several studies indicate that RAG, even without fine-tuning, often achieves comparable or better performance than fine-tuning alone, especially for larger models and knowledge-based tasks.
<ul>
<li><strong>Forum Post:</strong> <a href="https://community.openai.com/t/fine-tuning-vs-context-injection-rag/550286/1">Fine-tuning vs Context-Injection (RAG)</a></li>
</ul></li>
<li><strong>Prioritization over “versus”:</strong> While combining RAG and fine-tuning can yield incremental improvements, prioritizing RAG is crucial due to its efficiency and effectiveness.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2403.01432">Fine Tuning vs.&nbsp;Retrieval Augmented Generation for Less Popular Knowledge</a></li>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2312.05934">Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs</a></li>
</ul></li>
<li><strong>Fine-tuning for style, not knowledge:</strong> Fine-tuning might be less suitable for incorporating domain knowledge into a model compared to RAG, which directly provides relevant context.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2401.08406">RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture</a></li>
</ul></li>
<li><strong>The evolving definition of “knowledge”:</strong> Distinguishing between “knowledge” and “style” in LLMs is complex and changes with each model generation. What previously required fine-tuning (e.g., writing style) might be achievable through prompting in newer models.</li>
</ul>
<section id="qa-on-fine-tuning-rag-and-knowledge" class="level3">
<h3 class="anchored" data-anchor-id="qa-on-fine-tuning-rag-and-knowledge">Q&amp;A on Fine-tuning, RAG, and Knowledge</h3>
<ul>
<li><strong>Fine-tuning effectiveness and model size:</strong> Fine-tuning might be more beneficial for smaller models compared to larger ones, which are already more capable of learning from context.</li>
<li><strong>Domain-specific knowledge and RAG:</strong> Even for smaller models, RAG remains crucial for tasks involving domain-specific knowledge.</li>
<li><strong>Evaluating fine-tuning success:</strong> The choice of evaluation metric significantly impacts the perceived effectiveness of fine-tuning. For tasks like style adherence, fine-tuning might appear more beneficial than RAG.</li>
<li><strong>The blurry line between style and content:</strong> The distinction between “style” and “content” can be ambiguous, making it difficult to definitively determine when fine-tuning is beneficial.</li>
</ul>
</section>
<section id="audience-questions-and-examples-of-fine-tuning-success" class="level3">
<h3 class="anchored" data-anchor-id="audience-questions-and-examples-of-fine-tuning-success">Audience Questions and Examples of Fine-tuning Success</h3>
<ul>
<li><strong>Complex knowledge bases and fine-tuning:</strong> When dealing with large, curated knowledge bases, it’s crucial to evaluate whether the next generation of LLMs, combined with RAG, might be sufficient without fine-tuning.</li>
<li><strong>Adding knowledge via prompting and RAG:</strong> In many cases, adding knowledge to the model can be achieved through prompting, RAG, or a combination of both, eliminating the need for fine-tuning.</li>
<li><strong>Fine-tuning for multilingual models:</strong> Fine-tuning might be beneficial for improving the performance of multilingual models on languages with limited training data, as it leverages the model’s existing understanding of language mapping.</li>
<li><strong>Fine-tuning for code generation:</strong> While fine-tuning can be used to adapt code generation models to specific styles and conventions, RAG remains highly effective for providing codebase context.</li>
<li><strong>Contextual learning vs.&nbsp;fine-tuning:</strong> LLMs are demonstrating impressive abilities to learn from context, potentially replacing the need for fine-tuning in scenarios where sufficient context can be provided.</li>
</ul>
</section>
</section>
<section id="the-moving-target-fine-tuning-and-frontier-models" class="level2">
<h2 class="anchored" data-anchor-id="the-moving-target-fine-tuning-and-frontier-models">The Moving Target: Fine-tuning and Frontier Models</h2>
<ul>
<li><strong>Rapid LLM advancements:</strong> The rapid pace of LLM development makes fine-tuning a moving target, as newer models often surpass the performance of previously fine-tuned models.</li>
<li><strong>Bloomberg GPT example:</strong> Bloomberg GPT, a large language model pre-trained on financial data, initially outperformed existing models on financial tasks. However, its performance was subsequently surpassed by newer models like GPT-4.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2303.17564">BloombergGPT: A Large Language Model for Finance</a></li>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2305.05862">Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? A Study on Several Typical Tasks</a></li>
</ul></li>
<li><strong>The cost of keeping up:</strong> Continuously fine-tuning on new model releases can be prohibitively expensive, especially for large datasets. Prompt-based and RAG-based pipelines offer more flexibility and cost-effectiveness.</li>
<li><strong>Fine-tuning effectiveness and model scale:</strong> Fine-tuning might become less effective as models grow larger and more capable.</li>
</ul>
</section>
<section id="the-difficulty-of-fine-tuning-prioritizing-fundamentals" class="level2">
<h2 class="anchored" data-anchor-id="the-difficulty-of-fine-tuning-prioritizing-fundamentals">The Difficulty of Fine-tuning: Prioritizing Fundamentals</h2>
<ul>
<li><strong>The 80/20 rule of ML:</strong> Similar to traditional ML, most effort in LLM development should be dedicated to data work (80%), followed by engineering (18%), debugging (2%), and architecture research (0%).</li>
<li><strong>Fine-tuning as a last resort:</strong> Fine-tuning should only be considered after thoroughly addressing fundamentals like data quality, evaluation, prompting, and RAG.</li>
<li><strong>Hierarchy of needs:</strong> Prioritize building a solid ML system with robust evaluation, prompting, and RAG before attempting to fine-tune.
<ul>
<li><strong>Book:</strong> <a href="https://www.mlpowered.com/book/">Building Machine Learning Powered Applications: Going from Idea to Product</a></li>
<li><strong>Continuous Integration</strong>
<ul>
<li>Model Backtesting</li>
<li>Model Evaluation</li>
<li>Experimentation Framework</li>
</ul></li>
<li><strong>Application Logic</strong>
<ul>
<li>Input Validation → Filtering Logic → Model Code → Output Validation → Displaying Logic</li>
</ul></li>
<li><strong>Monitoring</strong>
<ul>
<li>Monitoring Input Distribution</li>
<li>Monitoring Latency</li>
<li>Monitoring Output Distribution</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="extrapolating-trends-context-size-price-and-latency" class="level2">
<h2 class="anchored" data-anchor-id="extrapolating-trends-context-size-price-and-latency">Extrapolating Trends: Context Size, Price, and Latency</h2>
<ul>
<li><strong>Decreasing costs and increasing capabilities:</strong> LLM costs are rapidly decreasing, while context windows and processing speeds are increasing.</li>
<li><strong>The impact of future trends:</strong> If these trends continue, providing sufficient context to highly capable LLMs might become more efficient than fine-tuning for many use cases.</li>
<li><strong>Context window limitations:</strong> Fine-tuning might still be necessary for applications requiring context exceeding the limits of available LLMs. However, techniques like prefix caching could mitigate this need.</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<ul>
<li><strong>Finetuning is:</strong>
<ul>
<li>expensive and complex</li>
<li>has become less valuable</li>
<li>often underperforms simpler approaches</li>
</ul></li>
<li><strong>Models are continuously becoming:</strong>
<ul>
<li>cheaper</li>
<li>smarter</li>
<li>faster</li>
<li>longer context</li>
</ul></li>
<li><strong>Always start with:</strong>
<ul>
<li>prompting</li>
<li>making a train/test set</li>
<li>RAG</li>
</ul></li>
<li><strong>Treat finetuning as a niche/last resort solution</strong>
<ul>
<li>like cloud vs on prem</li>
</ul></li>
</ul>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<section id="question-1" class="level3">
<h3 class="anchored" data-anchor-id="question-1">Question #1</h3>
<ul>
<li><strong>Context window size and computational cost:</strong> Passing large amounts of context through an LLM for every request can be computationally expensive. However, increasing LLM efficiency and advancements like prefix caching could mitigate this cost.</li>
<li><strong>Fine-tuning complexity:</strong> Fine-tuning increasingly complex and larger LLMs might become more challenging, potentially outweighing the benefits compared to context-based approaches.</li>
</ul>
</section>
<section id="question-2" class="level3">
<h3 class="anchored" data-anchor-id="question-2">Question #2</h3>
<ul>
<li><strong>Dynamic few-shot learning:</strong> Dynamically selecting and providing relevant few-shot examples from a database is a powerful technique for improving LLM performance without fine-tuning.</li>
<li><strong>Iterative prompt and example improvement:</strong> Invest time in iteratively refining prompts and curating effective few-shot examples before considering fine-tuning.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-009/</guid>
  <pubDate>Fri, 19 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 8: Creating, curating, and cleaning data for LLMs</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-008/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Reusing Existing Datasets</li>
<li>Creating Your Own Dataset</li>
<li>Common Dataset Genres</li>
<li>Synthetic Data</li>
<li>Improving Data</li>
<li>Human Annotation</li>
<li>Example Datasets</li>
<li>Case Study: LLM Summarizer</li>
<li>Resources</li>
<li>Q&amp;A</li>
</ul>
<section id="reusing-existing-datasets" class="level2">
<h2 class="anchored" data-anchor-id="reusing-existing-datasets">Reusing Existing Datasets</h2>
<ul>
<li><strong>🤗 Datasets:</strong> <a href="https://huggingface.co/datasets">https://huggingface.co/datasets</a></li>
<li><strong>What kind of existing dataset?</strong>
<ul>
<li><strong>Consider the use case:</strong> Datasets like <code>fineweb</code> are designed for pre-training, not fine-tuning.
<ul>
<li><strong>🤗 Dataset:</strong> <a href="HuggingFaceFW/fineweb">HuggingFaceFW/fineweb</a></li>
</ul></li>
<li><strong>Look beyond research datasets:</strong> Community-contributed datasets can offer unique and valuable data.</li>
</ul></li>
<li><strong>Browsing datasets</strong>
<ul>
<li><strong>Use tags:</strong> Filter datasets based on specific formats or tasks (e.g., DPO datasets).
<ul>
<li><a href="https://huggingface.co/datasets?other=dpo">🤗 DPO Datasets</a></li>
</ul></li>
</ul></li>
<li><strong>Searching for datasets</strong>
<ul>
<li><strong>Full-text search:</strong> Useful if dataset names are not descriptive enough.</li>
</ul></li>
<li><strong>Reviewing if a dataset is suitable: Vibe checks</strong>
<ul>
<li><strong>Dataset viewer:</strong> Provides a preview of the data, including metadata and example rows.</li>
<li><strong>Analyze conversation length and content:</strong> Assess if the dataset aligns with your target application.</li>
</ul></li>
</ul>
</section>
<section id="creating-your-own-dataset" class="level2">
<h2 class="anchored" data-anchor-id="creating-your-own-dataset">Creating Your Own Dataset</h2>
<ul>
<li><strong>Adapt existing NLP datasets:</strong> Restructure data from classic NLP tasks for LLM fine-tuning.</li>
<li><strong>Leverage user feedback:</strong> Analyze existing user interactions (e.g., thumbs up/down) for preference data.</li>
<li><strong>Synthetic data:</strong> A powerful method for jumpstarting dataset creation.</li>
<li><strong>Getting data?</strong>
<ul>
<li><strong>Data format:</strong> Ensure the data format closely resembles the intended use case for the LLM.</li>
<li><strong>Preprocessing:</strong> The effort invested in data preparation will benefit the deployment stage.</li>
</ul></li>
<li><strong>What kind of dataset do you need for fine-tuning</strong>
<ul>
<li><strong>Specificity over diversity:</strong> Focus on data relevant to your specific use case, even if it means the model loses some general abilities.</li>
<li><strong>Data diversity should reflect the target application:</strong> Don’t aim for broad diversity if your application is narrow.</li>
</ul></li>
</ul>
</section>
<section id="common-dataset-genres" class="level2">
<h2 class="anchored" data-anchor-id="common-dataset-genres">Common Dataset Genres</h2>
<ul>
<li><strong>SFT (Supervised Fine Tuning)</strong>
<ul>
<li><strong>Structure:</strong> Question and answer pairs.</li>
</ul></li>
<li><strong>RLHF (Reinforcement Learning by Human Feedback)</strong>
<ul>
<li><strong>Structure:</strong> Similar to SFT, but with additional preference information.</li>
</ul></li>
<li><strong>DPO (Direct Preference Optimization)</strong>
<ul>
<li><strong>Structure:</strong> Input, chosen response, and rejected response.</li>
<li><strong>Flexibility:</strong> “Chosen” and “rejected” can be generated creatively (e.g., using human-written text as “chosen” and model-generated text as “rejected”).</li>
</ul></li>
<li><strong>KTO (Kahneman-Tversky Optimization)</strong>
<ul>
<li><strong>argilla’s Collections:</strong> <a href="https://huggingface.co/collections/argilla/preference-datasets-for-kto-65f98314d7c1b04ab54d41a7">Preference Datasets for KTO</a></li>
<li><strong>Structure:</strong> Model response and a binary preference (thumbs up/down).</li>
<li><strong>Easy to collect:</strong> Users can readily provide simple preference feedback.</li>
</ul></li>
<li><strong>SPIN/ORPO</strong>
<ul>
<li><strong>HuggingFaceH4’s Collections:</strong> <a href="https://huggingface.co/collections/HuggingFaceH4/awesome-sft-datasets-65788b571bf8e371c4e4241a">Awesome SFT datasets</a></li>
<li><strong>SPIN:</strong> Iterative approach to reduce data requirements by synthetically generating responses.</li>
<li><strong>ORPO:</strong> Similar to DPO but doesn’t require a separate supervised fine-tuning step, making it more efficient.</li>
</ul></li>
</ul>
</section>
<section id="synthetic-data" class="level2">
<h2 class="anchored" data-anchor-id="synthetic-data">Synthetic Data</h2>
<ul>
<li><strong>Definition:</strong> Data generated by LLMs, often used for fine-tuning other LLMs.</li>
<li><strong>Methods:</strong>
<ul>
<li>Generating prompts and completions from scratch.</li>
<li>Rephrasing existing prompts to improve quality and diversity.</li>
<li>AI feedback: Using LLMs to judge the quality of other LLM outputs.</li>
</ul></li>
</ul>
<section id="basic-taxonomy-of-synthetic-data-uses" class="level3">
<h3 class="anchored" data-anchor-id="basic-taxonomy-of-synthetic-data-uses">Basic Taxonomy of Synthetic Data Uses</h3>
<ul>
<li><p><strong>Blog Post:</strong> <a href="https://www.interconnects.ai/p/llm-synthetic-data">Synthetic data: Anthropic’s CAI, from fine-tuning to pretraining, OpenAI’s Superalignment, tips, types, and open examples</a></p></li>
<li><p><strong>Instructions</strong></p>
<ul>
<li><strong>Generated text for SFT / IFT</strong></li>
<li><strong>Completions</strong>
<ul>
<li><code>Prompt</code> ➡️ :robot: ➡️ <code>instruction</code></li>
</ul></li>
</ul></li>
<li><p><strong>Self-Instruct Bootstrapping</strong></p>
<ul>
<li><strong>Process</strong>
<ul>
<li><code>Prompt</code> ➡️ :robot: ➡️ <code>More prompts</code> ➡️ :robot: ➡️ <code>instruction</code> :arrow_right: Filtering :repeat:</li>
</ul></li>
</ul></li>
<li><p><strong>Using LLM to Generate Corrected Sample</strong></p>
<ul>
<li><strong>Process</strong>
<ul>
<li><code>principles</code> + <code>instruction</code> ➡️ :robot: ➡️ <code>corrected instruction</code> :arrow_right: Repeat to filter :repeat:</li>
</ul></li>
</ul></li>
<li><p><strong>Preferences</strong></p>
<ul>
<li><strong>Scoring / Choosing Response for RM / RLHF Training</strong>
<ul>
<li><code>instruction-1</code>…<code>instruction-N</code> :arrow_right: :robot: ➡️ <code>scores</code> or <code>chosen/rejected</code> :arrow_right: Filtering :repeat:</li>
</ul></li>
</ul></li>
<li><p><strong>Critiques</strong></p>
<ul>
<li><strong>Initial Instruction</strong>
<ul>
<li>(rejected response)</li>
</ul></li>
<li><strong>Using LLM Principles to Generate Pairwise Completions</strong>
<ul>
<li><code>initial instruction</code> + <code>principles</code> ➡️ :robot: ➡️ <code>corrected instruction</code> (chosen response) :arrow_right: Filtering :repeat:</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="challenges" class="level3">
<h3 class="anchored" data-anchor-id="challenges">Challenges</h3>
<ul>
<li><strong>Alpaca 7B model:</strong> Trained on synthetic data generated by prompting a language model with instructions.
<ul>
<li><strong>Blog Post:</strong> <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca: A Strong, Replicable Instruction-Following Model</a></li>
<li><strong>Challenges:</strong> Synthetic data can contain hallucinations, toxicity, and biases inherited from the generating model.
<ul>
<li><strong>Example:</strong> Alpaca 7B exhibiting hallucinations and inaccurate claims.</li>
</ul></li>
</ul></li>
<li><strong>Ultrafeedback paper:</strong> Used multiple models and GPT-4 for judging synthetic data quality based on multiple criteria.
<ul>
<li><strong>Paper:</strong> UltraFeedback: Boosting Language Models with Scaled AI Feedback</li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/OpenBMB/UltraFeedback">https://github.com/OpenBMB/UltraFeedback</a></li>
<li><strong>Challenges:</strong> Coding errors, API failures, and data handling issues can severely impact data quality, even with advanced models.
<ul>
<li><strong>Example:</strong> Errors in the Ultrafeedback dataset highlighted the importance of human review and data cleaning.</li>
</ul></li>
</ul></li>
<li><strong>Scaling challenges:</strong> Generating high-quality synthetic data at scale requires careful consideration of cost, vendor lock-in, and data quality.</li>
</ul>
</section>
<section id="tools" class="level3">
<h3 class="anchored" data-anchor-id="tools">Tools</h3>
<ul>
<li><strong>Outlines:</strong>
<ul>
<li>Enables structured text generation in various formats (JSON, Regex, etc.) by modifying token sampling.</li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/outlines-dev/outlines">https://github.com/outlines-dev/outlines</a></li>
</ul></li>
<li><strong>DSPy:</strong>
<ul>
<li>Focuses on “programming” LLM behavior through a defined signature, optimizing prompts and fine-tuning for specific tasks.</li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/stanfordnlp/dspy">https://github.com/stanfordnlp/dspy</a></li>
<li><strong>Blog Post:</strong> <a href="https://hamel.dev/blog/posts/prompt/index.html">Fuck You, Show Me The Prompt.</a></li>
</ul></li>
<li><strong>distilabel:</strong>
<ul>
<li>A pipeline framework for synthetic data generation and AI feedback, emphasizing scalability and dataset engineer workflows.</li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/argilla-io/distilabel">https://github.com/argilla-io/distilabel</a></li>
</ul></li>
</ul>
</section>
</section>
<section id="improving-data" class="level2">
<h2 class="anchored" data-anchor-id="improving-data">Improving Data</h2>
<section id="ensuring-sufficient-quantity" class="level3">
<h3 class="anchored" data-anchor-id="ensuring-sufficient-quantity">Ensuring sufficient quantity</h3>
<ul>
<li>More ≠ better</li>
<li>Be okay with “throwing away” annotations and data</li>
<li><strong>Data Requirements</strong> (based on paper reported numbers)
<ul>
<li><strong>SFT:</strong> <code>10K</code></li>
<li><strong>ORPO:</strong> <code>7K</code></li>
<li><strong>DPO:</strong> <code>3K</code></li>
<li><strong>SPIN:</strong> <code>2K</code></li>
</ul></li>
<li>Data requirements will be higher for more diverse inputs + outputs (would you have used BERT a few years ago to do this task?)</li>
<li><strong>Blog Post:</strong> https://argilla.io/blog/mantisnlp-rlhf-part-9/</li>
</ul>
</section>
<section id="deduplication" class="level3">
<h3 class="anchored" data-anchor-id="deduplication">Deduplication</h3>
<ul>
<li><strong>Blog Post:</strong> <a href="https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1">FineWeb: decanting the web for the finest text data at scale</a></li>
<li><strong>Challenges:</strong> Deduplication pipelines are often not reproducible or well-documented.</li>
<li><strong>Approaches:</strong>
<ul>
<li>Intuitive rules and metadata filtering.</li>
<li>Topic-wise deduplication.</li>
<li>Custom metadata and feature engineering.</li>
<li>Embedding similarity and exemplar selection.</li>
</ul></li>
</ul>
</section>
<section id="rule-based" class="level3">
<h3 class="anchored" data-anchor-id="rule-based">Rule based</h3>
<ul>
<li><strong>Regex:</strong> Useful for simple rule-based cleaning (e.g., removing unwanted phrases or patterns).</li>
</ul>
</section>
<section id="quality" class="level3">
<h3 class="anchored" data-anchor-id="quality">Quality</h3>
<ul>
<li><strong>Tutorial:</strong> <a href="https://hlasse.github.io/TextDescriptives/tutorials/filter_corpus_using_quality.html">Filtering corpora using Quality</a></li>
<li><strong>Techniques:</strong>
<ul>
<li>Basic heuristics</li>
<li>Topic modeling</li>
<li>Embeddings</li>
<li>Classifiers (don’t dismiss these even if you have $$$)
<ul>
<li><strong>Model:</strong> <a href="https://huggingface.co/MoritzLaurer/deberta-v3-large-zeroshot-v2.0">MoritzLaurer/deberta-v3-large-zeroshot-v2.0</a></li>
<li><strong>Model:</strong> <a href="https://huggingface.co/HuggingFaceFW/fineweb-edu-classifier">HuggingFaceFW/fineweb-edu-classifier</a></li>
</ul></li>
<li>LLM as judge/juries/rationalizers</li>
<li>Human annotation</li>
</ul></li>
</ul>
</section>
</section>
<section id="human-annotation" class="level2">
<h2 class="anchored" data-anchor-id="human-annotation">Human Annotation</h2>
<ul>
<li><strong>Finding the right balance:</strong> Choose tools and approaches that fit your needs and budget, from simple spreadsheets to fully customized solutions.</li>
<li><strong>Custom</strong>
<ul>
<li><strong>Example:</strong> Vincent D. Warmerdon’s bulk annotation tool using Bokeh and Pandas for interactive data exploration and annotation.
<ul>
<li><strong>GitHub Repository:</strong> <a href="koaning/bulk">koaning/bulk</a></li>
</ul></li>
</ul></li>
<li><strong>Notebooks</strong>
<ul>
<li><strong>Example:</strong> ipyannotations for in-notebook annotation with customizable callbacks for post-processing and active learning.
<ul>
<li><strong>Documentation:</strong> <a href="https://ipyannotations.readthedocs.io/en/latest/">ipyannotations</a></li>
</ul></li>
</ul></li>
<li><strong>Apps</strong>
<ul>
<li><strong>Example:</strong> Gradio, Streamlit, and Shiny for building custom web apps with intuitive UIs for annotation tasks.</li>
</ul></li>
<li><strong>Lilac</strong>
<ul>
<li><strong>Website:</strong> <a href="https://www.lilacml.com/">https://www.lilacml.com/</a></li>
<li><strong>Features:</strong> Dataset overview, semantic search, and integrated annotation tools.</li>
</ul></li>
<li><strong>Argilla</strong>
<ul>
<li><strong>Website:</strong> <a href="https://argilla.io/">https://argilla.io/</a></li>
<li><strong>Features:</strong> Similar to Lilac, with a focus on dataset management and annotation workflows.</li>
</ul></li>
</ul>
</section>
<section id="example-datasets" class="level2">
<h2 class="anchored" data-anchor-id="example-datasets">Example Datasets</h2>
<ul>
<li><p><strong>distilabel Orca Pairs for DPO</strong></p>
<ul>
<li><strong>Dataset:</strong> <a href="argilla/distilabel-intel-orca-dpo-pairs">argilla/distilabel-intel-orca-dpo-pairs</a></li>
<li><strong>Why it’s cool and what you can learn:</strong>
<ul>
<li>Filtering: less is more</li>
<li>Choosing the “stronger” model as always chosen doesn’t always work</li>
<li>Doing some data focused work using humans can make a big impact on model performance</li>
</ul></li>
</ul></li>
<li><p><strong>Gutenberg DPO</strong></p>
<ul>
<li><strong>Dataset:</strong> <a href="jondurbin/gutenberg-dpo-v0.1">jondurbin/gutenberg-dpo-v0.1</a></li>
<li><strong>Approach:</strong> Uses human-written books and LLM-generated summaries to create a DPO dataset for improving LLM writing ability.</li>
</ul></li>
<li><p><strong>PlatVR KTO Dataset</strong></p>
<ul>
<li><strong>Dataset:</strong> <a href="ITG/PlatVR-kto">ITG/PlatVR-kto</a></li>
<li><strong>Approach:</strong> Collects thumbs up/down ratings on model outputs to create a KTO dataset for a vision-language task.</li>
<li><strong>Why it’s cool and what you can learn:</strong>
<ul>
<li>Example of how KTO datasets can work well as a data flywheel</li>
<li>Users submit a prompt. They get a response they 👍/👎 that response</li>
<li>Cheap to collect and can be useful data even if you don’t end up using KTO</li>
</ul></li>
<li><strong>Disclaimer:</strong> The creation process was done using a crowdsourcing methodology. Therefore, the preferences in the data align with the user group that participated in the process (i.e., these are real preference data).</li>
</ul></li>
</ul>
</section>
<section id="case-study-llm-summarizer" class="level2">
<h2 class="anchored" data-anchor-id="case-study-llm-summarizer">Case Study: LLM Summarizer</h2>
<ul>
<li><strong>Goal:</strong> Build an LLM-based summarizer for data set cards on Hugging Face.</li>
<li><strong>Approach:</strong> Uses a Distilabel pipeline to generate and judge summaries, incorporating both model and human feedback.</li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 293.81 399.20" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 395.2)">
<title>LLM Summarizer</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-395.2 289.81,-395.2 289.81,4 -4,4"></polygon>
<!-- Load dataset card in markdown format -->
<g id="node1" class="node">
<title>Load dataset card in markdown format</title>
<polygon fill="none" stroke="black" points="259.71,-391.2 26.1,-391.2 26.1,-355.2 259.71,-355.2 259.71,-391.2"></polygon>
<text text-anchor="middle" x="142.9" y="-369" font-family="Times,serif" font-size="14.00">Load dataset card in markdown format</text>
</g>
<!-- Parse out YAML and remove unwanted content -->
<g id="node2" class="node">
<title>Parse out YAML and remove unwanted content</title>
<polygon fill="none" stroke="black" points="285.17,-302.4 0.64,-302.4 0.64,-266.4 285.17,-266.4 285.17,-302.4"></polygon>
<text text-anchor="middle" x="142.9" y="-280.2" font-family="Times,serif" font-size="14.00">Parse out YAML and remove unwanted content</text>
</g>
<!-- Load dataset card in markdown format&#45;&gt;Parse out YAML and remove unwanted content -->
<g id="edge1" class="edge">
<title>Load dataset card in markdown format-&gt;Parse out YAML and remove unwanted content</title>
<path fill="none" stroke="black" d="M142.9,-355.05C142.9,-342.92 142.9,-326.42 142.9,-312.52"></path>
<polygon fill="black" stroke="black" points="146.4,-312.51 142.9,-302.51 139.4,-312.51 146.4,-312.51"></polygon>
<text text-anchor="middle" x="160.6" y="-324.6" font-family="Times,serif" font-size="14.00">Step 1</text>
</g>
<!-- Pass reduced text to LLM -->
<g id="node3" class="node">
<title>Pass reduced text to LLM</title>
<polygon fill="none" stroke="black" points="223.04,-213.6 62.77,-213.6 62.77,-177.6 223.04,-177.6 223.04,-213.6"></polygon>
<text text-anchor="middle" x="142.9" y="-191.4" font-family="Times,serif" font-size="14.00">Pass reduced text to LLM</text>
</g>
<!-- Parse out YAML and remove unwanted content&#45;&gt;Pass reduced text to LLM -->
<g id="edge2" class="edge">
<title>Parse out YAML and remove unwanted content-&gt;Pass reduced text to LLM</title>
<path fill="none" stroke="black" d="M142.9,-266.25C142.9,-254.12 142.9,-237.62 142.9,-223.72"></path>
<polygon fill="black" stroke="black" points="146.4,-223.71 142.9,-213.71 139.4,-223.71 146.4,-223.71"></polygon>
<text text-anchor="middle" x="160.6" y="-235.8" font-family="Times,serif" font-size="14.00">Step 2</text>
</g>
<!-- Get summary of dataset card -->
<g id="node4" class="node">
<title>Get summary of dataset card</title>
<polygon fill="none" stroke="black" points="231.34,-124.8 54.47,-124.8 54.47,-88.8 231.34,-88.8 231.34,-124.8"></polygon>
<text text-anchor="middle" x="142.9" y="-102.6" font-family="Times,serif" font-size="14.00">Get summary of dataset card</text>
</g>
<!-- Pass reduced text to LLM&#45;&gt;Get summary of dataset card -->
<g id="edge3" class="edge">
<title>Pass reduced text to LLM-&gt;Get summary of dataset card</title>
<path fill="none" stroke="black" d="M142.9,-177.45C142.9,-165.32 142.9,-148.82 142.9,-134.92"></path>
<polygon fill="black" stroke="black" points="146.4,-134.91 142.9,-124.91 139.4,-134.91 146.4,-134.91"></polygon>
<text text-anchor="middle" x="160.6" y="-147" font-family="Times,serif" font-size="14.00">Step 3</text>
</g>
<!-- Get feedback from users about summary quality -->
<g id="node5" class="node">
<title>Get feedback from users about summary quality</title>
<polygon fill="none" stroke="black" points="285.71,-36 0.1,-36 0.1,0 285.71,0 285.71,-36"></polygon>
<text text-anchor="middle" x="142.9" y="-13.8" font-family="Times,serif" font-size="14.00">Get feedback from users about summary quality</text>
</g>
<!-- Get summary of dataset card&#45;&gt;Get feedback from users about summary quality -->
<g id="edge4" class="edge">
<title>Get summary of dataset card-&gt;Get feedback from users about summary quality</title>
<path fill="none" stroke="black" d="M142.9,-88.65C142.9,-76.52 142.9,-60.02 142.9,-46.12"></path>
<polygon fill="black" stroke="black" points="146.4,-46.11 142.9,-36.11 139.4,-46.11 146.4,-46.11"></polygon>
<text text-anchor="middle" x="160.6" y="-58.2" font-family="Times,serif" font-size="14.00">Step 4</text>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<section id="the-distilabel-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="the-distilabel-pipeline">The distilabel pipeline</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 693.68 742.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 738)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-738 689.68,-738 689.68,4 -4,4"></polygon>
<!-- llama_summary -->
<g id="node1" class="node">
<title>llama_summary</title>
<polygon fill="lightblue" stroke="black" points="269.47,-408 92.33,-408 92.33,-370 269.47,-370 269.47,-408"></polygon>
<text text-anchor="middle" x="180.9" y="-381.5" font-family="sans-serif:bold" font-size="25.00">llama_summary</text>
</g>
<!-- combine_columns -->
<g id="node13" class="node">
<title>combine_columns</title>
<path fill="none" stroke="black" d="M374.7,-334C374.7,-334 199.1,-334 199.1,-334 193.1,-334 187.1,-328 187.1,-322 187.1,-322 187.1,-308 187.1,-308 187.1,-302 193.1,-296 199.1,-296 199.1,-296 374.7,-296 374.7,-296 380.7,-296 386.7,-302 386.7,-308 386.7,-308 386.7,-322 386.7,-322 386.7,-328 380.7,-334 374.7,-334"></path>
<text text-anchor="middle" x="286.9" y="-307.5" font-family="sans-serif:bold" font-size="25.00">combine_columns</text>
</g>
<!-- llama_summary&#45;&gt;combine_columns -->
<g id="edge9" class="edge">
<title>llama_summary-&gt;combine_columns</title>
<path fill="none" stroke="black" d="M207.65,-369.83C220.96,-360.79 237.22,-349.75 251.54,-340.02"></path>
<polygon fill="black" stroke="black" points="253.86,-342.68 260.16,-334.16 249.92,-336.89 253.86,-342.68"></polygon>
</g>
<!-- mistral_summary -->
<g id="node2" class="node">
<title>mistral_summary</title>
<polygon fill="lightpink" stroke="black" points="478.38,-408 287.42,-408 287.42,-370 478.38,-370 478.38,-408"></polygon>
<text text-anchor="middle" x="382.9" y="-381.5" font-family="sans-serif:bold" font-size="25.00">mistral_summary</text>
</g>
<!-- mistral_summary&#45;&gt;combine_columns -->
<g id="edge10" class="edge">
<title>mistral_summary-&gt;combine_columns</title>
<path fill="none" stroke="black" d="M358.68,-369.83C346.74,-360.88 332.17,-349.96 319.29,-340.3"></path>
<polygon fill="black" stroke="black" points="321.22,-337.36 311.12,-334.16 317.02,-342.96 321.22,-337.36"></polygon>
</g>
<!-- zephyr_summary -->
<g id="node3" class="node">
<title>zephyr_summary</title>
<polygon fill="lightgreen" stroke="black" points="685.46,-408 496.34,-408 496.34,-370 685.46,-370 685.46,-408"></polygon>
<text text-anchor="middle" x="590.9" y="-381.5" font-family="sans-serif:bold" font-size="25.00">zephyr_summary</text>
</g>
<!-- zephyr_summary&#45;&gt;combine_columns -->
<g id="edge11" class="edge">
<title>zephyr_summary-&gt;combine_columns</title>
<path fill="none" stroke="black" d="M514.58,-369.92C471.49,-359.72 417.52,-346.94 372.93,-336.38"></path>
<polygon fill="black" stroke="black" points="373.53,-332.92 362.99,-334.02 371.91,-339.73 373.53,-332.92"></polygon>
</g>
<!-- llama_3_70_b -->
<g id="node4" class="node">
<title>llama_3_70_b</title>
<polygon fill="lightblue" stroke="black" points="198.08,-512 47.72,-512 47.72,-444 198.08,-444 198.08,-512"></polygon>
<text text-anchor="middle" x="122.9" y="-485.5" font-family="sans-serif:bold" font-size="25.00">llama-3-70-B</text>
<text text-anchor="middle" x="122.9" y="-455.5" font-family="sans-serif:bold" font-size="25.00">Instruct</text>
</g>
<!-- llama_3_70_b&#45;&gt;llama_summary -->
<g id="edge7" class="edge">
<title>llama_3_70_b-&gt;llama_summary</title>
<path fill="none" stroke="black" d="M145.16,-443.61C151.13,-434.65 157.51,-425.08 163.2,-416.55"></path>
<polygon fill="black" stroke="black" points="166.2,-418.35 168.84,-408.09 160.38,-414.47 166.2,-418.35"></polygon>
</g>
<!-- ultrafeedback -->
<g id="node5" class="node">
<title>ultrafeedback</title>
<polygon fill="lightblue" stroke="black" points="203.92,-260 51.88,-260 51.88,-222 203.92,-222 203.92,-260"></polygon>
<text text-anchor="middle" x="127.9" y="-233.5" font-family="sans-serif:bold" font-size="25.00">ultrafeedback</text>
</g>
<!-- llama_3_70_b&#45;&gt;ultrafeedback -->
<g id="edge8" class="edge">
<title>llama_3_70_b-&gt;ultrafeedback</title>
<path fill="none" stroke="black" d="M98.97,-443.83C92.44,-432.94 86.24,-420.44 82.9,-408 69.77,-359.18 93.69,-302.34 111.39,-269.43"></path>
<polygon fill="black" stroke="black" points="114.6,-270.86 116.41,-260.42 108.49,-267.45 114.6,-270.86"></polygon>
</g>
<!-- remove_bad_ratings -->
<g id="node14" class="node">
<title>remove_bad_ratings</title>
<path fill="none" stroke="black" d="M226,-186C226,-186 29.8,-186 29.8,-186 23.8,-186 17.8,-180 17.8,-174 17.8,-174 17.8,-160 17.8,-160 17.8,-154 23.8,-148 29.8,-148 29.8,-148 226,-148 226,-148 232,-148 238,-154 238,-160 238,-160 238,-174 238,-174 238,-180 232,-186 226,-186"></path>
<text text-anchor="middle" x="127.9" y="-159.5" font-family="sans-serif:bold" font-size="25.00">remove_bad_ratings</text>
</g>
<!-- ultrafeedback&#45;&gt;remove_bad_ratings -->
<g id="edge13" class="edge">
<title>ultrafeedback-&gt;remove_bad_ratings</title>
<path fill="none" stroke="black" d="M127.9,-221.83C127.9,-214.13 127.9,-204.97 127.9,-196.42"></path>
<polygon fill="black" stroke="black" points="131.4,-196.41 127.9,-186.41 124.4,-196.41 131.4,-196.41"></polygon>
</g>
<!-- to_argilla -->
<g id="node6" class="node">
<title>to_argilla</title>
<polygon fill="white" stroke="black" points="111.7,-112 0.1,-112 0.1,-74 111.7,-74 111.7,-112"></polygon>
<text text-anchor="middle" x="55.9" y="-85.5" font-family="sans-serif:bold" font-size="25.00">to_argilla</text>
</g>
<!-- end -->
<g id="node9" class="node">
<title>end</title>
<text text-anchor="middle" x="127.9" y="-11.5" font-family="sans-serif:bold" font-size="25.00">🤗</text>
</g>
<!-- to_argilla&#45;&gt;end -->
<g id="edge17" class="edge">
<title>to_argilla-&gt;end</title>
<path fill="none" stroke="black" d="M74.07,-73.83C82.62,-65.28 92.96,-54.94 102.28,-45.62"></path>
<polygon fill="black" stroke="black" points="104.89,-47.96 109.49,-38.41 99.94,-43.01 104.89,-47.96"></polygon>
</g>
<!-- push_to_hub -->
<g id="node7" class="node">
<title>push_to_hub</title>
<polygon fill="white" stroke="black" points="269.53,-112 130.27,-112 130.27,-74 269.53,-74 269.53,-112"></polygon>
<text text-anchor="middle" x="199.9" y="-85.5" font-family="sans-serif:bold" font-size="25.00">Push to Hub</text>
</g>
<!-- push_to_hub&#45;&gt;end -->
<g id="edge16" class="edge">
<title>push_to_hub-&gt;end</title>
<path fill="none" stroke="black" d="M181.73,-73.83C173.19,-65.28 162.84,-54.94 153.52,-45.62"></path>
<polygon fill="black" stroke="black" points="155.86,-43.01 146.31,-38.41 150.91,-47.96 155.86,-43.01"></polygon>
</g>
<!-- start -->
<g id="node8" class="node">
<title>start</title>
<text text-anchor="middle" x="382.9" y="-707.5" font-family="sans-serif:bold" font-size="25.00">🤗</text>
</g>
<!-- load_dataset -->
<g id="node10" class="node">
<title>load_dataset</title>
<path fill="none" stroke="black" d="M441.35,-660C441.35,-660 324.45,-660 324.45,-660 318.45,-660 312.45,-654 312.45,-648 312.45,-648 312.45,-634 312.45,-634 312.45,-628 318.45,-622 324.45,-622 324.45,-622 441.35,-622 441.35,-622 447.35,-622 453.35,-628 453.35,-634 453.35,-634 453.35,-648 453.35,-648 453.35,-654 447.35,-660 441.35,-660"></path>
<text text-anchor="middle" x="382.9" y="-633.5" font-family="sans-serif:bold" font-size="25.00">load_dataset</text>
</g>
<!-- start&#45;&gt;load_dataset -->
<g id="edge1" class="edge">
<title>start-&gt;load_dataset</title>
<path fill="none" stroke="black" d="M382.9,-695.83C382.9,-688.13 382.9,-678.97 382.9,-670.42"></path>
<polygon fill="black" stroke="black" points="386.4,-670.41 382.9,-660.41 379.4,-670.41 386.4,-670.41"></polygon>
</g>
<!-- card_filter -->
<g id="node11" class="node">
<title>card_filter</title>
<path fill="none" stroke="black" d="M431,-586C431,-586 334.8,-586 334.8,-586 328.8,-586 322.8,-580 322.8,-574 322.8,-574 322.8,-560 322.8,-560 322.8,-554 328.8,-548 334.8,-548 334.8,-548 431,-548 431,-548 437,-548 443,-554 443,-560 443,-560 443,-574 443,-574 443,-580 437,-586 431,-586"></path>
<text text-anchor="middle" x="382.9" y="-559.5" font-family="sans-serif:bold" font-size="25.00">card_filter</text>
</g>
<!-- load_dataset&#45;&gt;card_filter -->
<g id="edge2" class="edge">
<title>load_dataset-&gt;card_filter</title>
<path fill="none" stroke="black" d="M382.9,-621.83C382.9,-614.13 382.9,-604.97 382.9,-596.42"></path>
<polygon fill="black" stroke="black" points="386.4,-596.41 382.9,-586.41 379.4,-596.41 386.4,-596.41"></polygon>
</g>
<!-- format_input_card -->
<g id="node12" class="node">
<title>format_input_card</title>
<path fill="none" stroke="black" d="M471.95,-497C471.95,-497 293.85,-497 293.85,-497 287.85,-497 281.85,-491 281.85,-485 281.85,-485 281.85,-471 281.85,-471 281.85,-465 287.85,-459 293.85,-459 293.85,-459 471.95,-459 471.95,-459 477.95,-459 483.95,-465 483.95,-471 483.95,-471 483.95,-485 483.95,-485 483.95,-491 477.95,-497 471.95,-497"></path>
<text text-anchor="middle" x="382.9" y="-470.5" font-family="sans-serif:bold" font-size="25.00">format_input_card</text>
</g>
<!-- card_filter&#45;&gt;format_input_card -->
<g id="edge3" class="edge">
<title>card_filter-&gt;format_input_card</title>
<path fill="none" stroke="black" d="M382.9,-547.97C382.9,-536.19 382.9,-520.56 382.9,-507.16"></path>
<polygon fill="black" stroke="black" points="386.4,-507 382.9,-497 379.4,-507 386.4,-507"></polygon>
</g>
<!-- format_input_card&#45;&gt;llama_summary -->
<g id="edge4" class="edge">
<title>format_input_card-&gt;llama_summary</title>
<path fill="none" stroke="black" d="M341.05,-458.97C309.36,-445.33 265.67,-426.51 231.94,-411.98"></path>
<polygon fill="black" stroke="black" points="233.27,-408.74 222.7,-408 230.5,-415.17 233.27,-408.74"></polygon>
</g>
<!-- format_input_card&#45;&gt;mistral_summary -->
<g id="edge5" class="edge">
<title>format_input_card-&gt;mistral_summary</title>
<path fill="none" stroke="black" d="M382.9,-458.97C382.9,-447.19 382.9,-431.56 382.9,-418.16"></path>
<polygon fill="black" stroke="black" points="386.4,-418 382.9,-408 379.4,-418 386.4,-418"></polygon>
</g>
<!-- format_input_card&#45;&gt;zephyr_summary -->
<g id="edge6" class="edge">
<title>format_input_card-&gt;zephyr_summary</title>
<path fill="none" stroke="black" d="M426,-458.97C458.63,-445.33 503.61,-426.51 538.35,-411.98"></path>
<polygon fill="black" stroke="black" points="539.98,-415.09 547.86,-408 537.28,-408.63 539.98,-415.09"></polygon>
</g>
<!-- combine_columns&#45;&gt;ultrafeedback -->
<g id="edge12" class="edge">
<title>combine_columns-&gt;ultrafeedback</title>
<path fill="none" stroke="black" d="M246.78,-295.83C225.61,-286.24 199.45,-274.4 177.07,-264.27"></path>
<polygon fill="black" stroke="black" points="178.29,-260.97 167.73,-260.04 175.4,-267.35 178.29,-260.97"></polygon>
</g>
<!-- remove_bad_ratings&#45;&gt;to_argilla -->
<g id="edge14" class="edge">
<title>remove_bad_ratings-&gt;to_argilla</title>
<path fill="none" stroke="black" d="M109.73,-147.83C101.19,-139.28 90.84,-128.94 81.52,-119.62"></path>
<polygon fill="black" stroke="black" points="83.86,-117.01 74.31,-112.41 78.91,-121.96 83.86,-117.01"></polygon>
</g>
<!-- remove_bad_ratings&#45;&gt;push_to_hub -->
<g id="edge15" class="edge">
<title>remove_bad_ratings-&gt;push_to_hub</title>
<path fill="none" stroke="black" d="M146.07,-147.83C154.62,-139.28 164.96,-128.94 174.28,-119.62"></path>
<polygon fill="black" stroke="black" points="176.89,-121.96 181.49,-112.41 171.94,-117.01 176.89,-121.96"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<ul>
<li><strong>Key steps:</strong>
<ul>
<li>Data loading and filtering.</li>
<li>Prompt formatting.</li>
<li>Summary generation using multiple models.</li>
<li>LLM-based judging using Ultrafeedback and Lama three.</li>
<li>Human review and annotation using Argilla.</li>
</ul></li>
<li><strong>Iterative process:</strong> Experiment with different prompts, models, and judging criteria to optimize the pipeline.</li>
</ul>
</section>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<ul>
<li><strong>GitHub repository:</strong> <a href="davanstrien/data-for-fine-tuning-llms">davanstrien/data-for-fine-tuning-llms</a>
<ul>
<li>Contains notebooks with code examples for deduplication, data checks, and synthetic data generation.</li>
</ul></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/davanstrien/awesome-synthetic-datasets">davanstrien/awesome-synthetic-datasets</a>
<ul>
<li>Organizes resources focused on helping people get started with building synthetic datasets.</li>
</ul></li>
</ul>
</section>
<section id="qa" class="level2">
<h2 class="anchored" data-anchor-id="qa">Q&amp;A</h2>
<ul>
<li><strong>Question:</strong> How to generate synthetic data when fine-tuning on proprietary data and human annotation is expensive?</li>
<li><strong>Answer:</strong> The decision to use synthetic data vs.&nbsp;proprietary data involves trade-offs related to data ownership, privacy, and control over the model.</li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-008/</guid>
  <pubDate>Thu, 18 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 7: Best Practices For Fine Tuning Mistral</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-007/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Mistral Overview</li>
<li>Customization</li>
<li>Demos</li>
</ul>
<section id="mistral-overview" class="level2">
<h2 class="anchored" data-anchor-id="mistral-overview">Mistral Overview</h2>
<ul>
<li><strong><a href="https://mistral.ai/">Mistral AI</a>:</strong> Paris-based team (50+ people) specializing in large language models (LLMs).</li>
<li><strong>Model Timeline:</strong>
<ul>
<li><strong>Sept 2023:</strong> Mistral 7b released
<ul>
<li><strong>Blog Post:</strong> <a href="https://mistral.ai/news/announcing-mistral-7b/">Mistral 7B</a></li>
</ul></li>
<li><strong>Dec 2023:</strong> Mistral 8x7b, Mistral Medium (commercial), API platform launched
<ul>
<li><strong>Blog Post:</strong> <a href="https://mistral.ai/news/mixtral-of-experts/">Mixtral of experts</a></li>
</ul></li>
<li><strong>Feb 2024:</strong> Mistral Small and Mistral Large (flagship) released
<ul>
<li><strong>Blog Post:</strong> <a href="https://mistral.ai/news/mistral-large/">Au Large</a></li>
</ul></li>
<li><strong>Feb 2024:</strong> Le Chat - free conversational AI interface launched
<ul>
<li><strong>Blog Post:</strong> <a href="https://mistral.ai/news/le-chat-mistral/">Le Chat</a></li>
</ul></li>
<li><strong>Apr 2024:</strong> Open-source 8x22b model released
<ul>
<li><strong>Blog Post:</strong> <a href="https://mistral.ai/news/mixtral-8x22b/">Cheaper, Better, Faster, Stronger</a></li>
</ul></li>
<li><strong>May 2024:</strong> Codestral - specialized model for code generation (80+ languages)
<ul>
<li><strong>Blog Post:</strong> <a href="https://mistral.ai/news/codestral/">Codestral: Hello, World!</a></li>
<li><strong>LangChain Tutorial:</strong> <a href="https://www.youtube.com/watch?v=zXFxmI9f06M">Self-correcting code assistants with Codestral</a></li>
</ul></li>
</ul></li>
<li><strong>Model Offerings:</strong>
<ul>
<li><strong>Open-source (Apache 2 License):</strong> Mistral 7b, 8x7b, 8x22b
<ul>
<li><strong>Homepage:</strong> <a href="https://mistral.ai/technology/#models">Open source models</a></li>
<li><strong>Docs:</strong> <a href="https://docs.mistral.ai/getting-started/open_weight_models/">Open-weight models</a></li>
</ul></li>
<li><strong>Enterprise-Grade:</strong> Mistral Small, Mistral Large (supports fine-tuning)</li>
<li><strong>Specialized:</strong> Codestral for coding, Embedding model</li>
</ul></li>
<li><strong>Fine-Tuning:</strong>
<ul>
<li><strong>Blog Post:</strong> <a href="https://mistral.ai/news/customization/">My Tailor is Mistral</a></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/mistralai/mistral-finetune">mistral-finetune</a></li>
</ul></li>
</ul>
</section>
<section id="customization" class="level2">
<h2 class="anchored" data-anchor-id="customization">Customization</h2>
<ul>
<li><strong>Blog Post:</strong> <a href="https://mistral.ai/news/customization/">My Tailor is Mistral</a></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/mistralai/mistral-finetune">mistral-finetune</a></li>
<li><strong>Documentation:</strong> <a href="https://docs.mistral.ai/getting-started/customization/">Model customization</a></li>
<li><strong>Developer Examples:</strong> <a href="https://docs.mistral.ai/getting-started/stories/">Model customization</a></li>
</ul>
<section id="benefits-of-prompting" class="level3">
<h3 class="anchored" data-anchor-id="benefits-of-prompting">Benefits of Prompting</h3>
<ul>
<li><strong>Documentation:</strong> <a href="https://docs.mistral.ai/guides/prompting_capabilities/">Prompting Capabilities</a></li>
<li><strong>Out-of-the-box functionality:</strong> No data or training required.</li>
<li><strong>Easy updates:</strong> Adaptable to new workflows and prototyping.</li>
</ul>
</section>
<section id="benefits-of-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="benefits-of-fine-tuning">Benefits of Fine-Tuning</h3>
<ul>
<li><strong>Guide:</strong> <a href="https://docs.mistral.ai/guides/finetuning/">Fine-tuning</a></li>
<li><strong>Performance:</strong> Often outperforms prompting and even larger models.</li>
<li><strong>Efficiency:</strong> Faster and cheaper than using large prompts.</li>
<li><strong>Task Alignment:</strong> Tailored to specific tasks and behaviors.</li>
<li><strong>Knowledge Integration:</strong> Ability to teach new facts and information.</li>
</ul>
</section>
</section>
<section id="demos" class="level2">
<h2 class="anchored" data-anchor-id="demos">Demos</h2>
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/mistralai/cookbook">Mistral Cookbook</a></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/mistralai/mistral-inference">Mistral Inference</a></li>
</ul>
<section id="mistral-api" class="level3">
<h3 class="anchored" data-anchor-id="mistral-api">Mistral API</h3>
<ul>
<li><p><strong>GitHub Repository:</strong> <a href="https://github.com/mistralai/client-python">mistralai/client-python</a></p></li>
<li><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb1-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-U</span> mistral-api<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>=0.4.2</span></code></pre></div></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Model Name Structure">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Model Name Structure
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Fine-tuned model names have a specific structure:</p>
<ul>
<li><pre class="text"><code>  ft:open-mistral-7b:b6e34a5e:20240531:a29e61db</code></pre></li>
</ul></li>
<li><p><code>ft</code>: Indicates a fine-tuned model.</p></li>
<li><p><code>open-mistral-7b</code>: Specifies the base model used.</p></li>
<li><p><code>b6e34a5e:20240531:a29e61db</code>: Represents the specific fine-tuned version.</p></li>
</ul>
</div>
</div>
</section>
<section id="abstract-generator-demo" class="level3">
<h3 class="anchored" data-anchor-id="abstract-generator-demo">Abstract Generator Demo</h3>
<ul>
<li><p>Generates abstracts based on inputted research paper titles.</p></li>
<li><p>It was trained on title-abstract pairs from <a href="https://arxiv.org/">arxiv.org</a>.</p></li>
<li><p>Highlights how effective fine-tuning can be for specific tasks.</p></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">client.chat(</span>
<span id="cb3-2">  model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ft:mistral-small-latest:8e2706f0:20240604:d861257a'</span>,</span>
<span id="cb3-3">  messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb3-4">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Fine-tuning is all you need"</span>}</span>
<span id="cb3-5">  ],</span>
<span id="cb3-6">  temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>,</span>
<span id="cb3-7">).choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].message.content</span></code></pre></div>
<pre class="text"><code>'Fine-tuning is a common practice in deep learning, where a pre-trained model is fine-tuned on a downstream task.\nIn this paper, we show that fine-tuning is all you need for a wide range of tasks.\nWe propose a simple yet effective fine-tuning recipe that works well for both vision and language tasks.\nOur recipe includes a learning rate warmup stage, a cosine learning rate decay schedule, and a stochastic weight averaging (SWA) stage.\nWe show that our recipe can significantly improve the performance of fine-tuning on a wide range of tasks, including image classification, object detection, instance segmentation, semantic segmentation, and language understanding.\nWe also show that our recipe can improve the performance of fine-tuning on small datasets, where the performance of fine-tuning is usually worse than training from scratch.\nOur recipe is simple and easy to implement, and we hope it will be useful for the deep learning community.'</code></pre>
</div>
</div></li>
</ul>
</section>
<section id="medical-chatbot-demo" class="level3">
<h3 class="anchored" data-anchor-id="medical-chatbot-demo">Medical Chatbot Demo</h3>
<ul>
<li>Trained on the HuggingFace dataset for AI medical chatbots.
<ul>
<li><strong>HuggingFace Dataset:</strong> <a href="https://huggingface.co/datasets/ruslanmv/ai-medical-chatbot">ruslanmv/ai-medical-chatbot</a></li>
</ul></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">client.chat(</span>
<span id="cb5-2">  model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ft:open-mistral-7b:b6e34a5e:20240531:a29e61db'</span>,</span>
<span id="cb5-3">  messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb5-4">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hello doctor, My reverse elbow armpits have developed a darker (my skin color is fair) pigmentation. This pigmentation has also affected the whole of my ..."</span>}</span>
<span id="cb5-5">  ],</span>
<span id="cb5-6">  temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>,</span>
<span id="cb5-7">).choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].message.content</span></code></pre></div>
<pre class="text"><code>'Hi, It seems that you might be having some fungal infection. Apply clotrimazole cream locally. Take tablet fluconazole 150 mg once a week for three weeks. Keep local part clean and dry. Avoid oily and spicy food. Ok and take care.'</code></pre>
</div>
</div></li>
</ul>
</section>
<section id="news-article-stylist-economist-style-guide-demo" class="level3">
<h3 class="anchored" data-anchor-id="news-article-stylist-economist-style-guide-demo">News Article Stylist (Economist Style Guide) Demo</h3>
<ul>
<li><p>Showcases how to generate training data using a larger model (e.g., Mistral Large) when you don’t have an existing dataset.</p></li>
<li><p><strong>Process:</strong></p>
<ol type="1">
<li><p><strong>Define Prompt:</strong> “You are a news article stylist following the Economist style guide.”</p></li>
<li><p><strong>Generate Data:</strong> Use Mistral Large to rewrite news articles in the Economist style, providing guidelines and examples.</p></li>
<li><p><strong>Fine-tune:</strong> Train a smaller model (e.g., Mistral 7B) on the generated data.</p></li>
</ol></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">news <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Incoming Florida Senate President Bill Galvano named the Naples Republican the Senate's majority leader for the upcoming legislative session. Kathleen Passidomo was unimpressed ..."</span></span>
<span id="cb7-2">response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.chat(</span>
<span id="cb7-3">  model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ft:mistral-small-latest:b6e34a5e:20240604:ee1ab18b'</span>,</span>
<span id="cb7-4">  messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb7-5">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: news}</span>
<span id="cb7-6">  ],</span>
<span id="cb7-7">  temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>,</span>
<span id="cb7-8">)</span>
<span id="cb7-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(response.choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].message.content)</span></code></pre></div>
<pre class="text"><code>Kathleen Passidomo, a Naples Republican, has been named the Senate's majority leader for the upcoming legislative session by incoming Florida Senate President Bill Galvano. Passidomo was impressed with the appointment because of her good rapport with both Senate Republicans and Democrats and her ability to build consensus. Passidomo agrees that her people skills will be key in shaping the Senate agenda for the coming session, which begins on March 5. Committee meetings will start on December 11. Although the legislative priorities will be the same as last year, including water quality and mental health. In a message to other senators, Galvano praised Passidomo's ability to not only extract favorable consideration from other senators but to maintain the respect of the members. Committee chairmen recognize leadership's ability to guide the Senate to a top spot now sets Passidomo up for even greater things in the future. Assuming she keeps her seat in the 2022 election and Republicans maintain control of the Senate in ...</code></pre>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Please carefully review the provided news article and identify all stylistic issues that detract from its clarity, precision, and sophistication. To ensure the accuracy of your analysis, quote the specific text and explain the reason for your suggested improvement."</span></span>
<span id="cb9-2">response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.chat(</span>
<span id="cb9-3">  model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ft:mistral-small-latest:b6e34a5e:20240604:ee1ab18b'</span>,</span>
<span id="cb9-4">  messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb9-5">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>news}</span>
<span id="cb9-6">  ],</span>
<span id="cb9-7">  temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>,</span>
<span id="cb9-8">)</span>
<span id="cb9-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(response.choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].message.content)</span></code></pre></div>
<pre class="text"><code>1. The article starts with a repetitive sentence, "Incoming Florida Senate President Bill Galvano named the Naples Republican the Senate's majority leader for the upcoming legislative session." This can be simplified to avoid repetition.
2. The use of informal language, such as "you can put my office in the men's room for all I care," detracts from the article's professional tone.
3. The article uses indirect speech in some instances, such as "What he was saying is that he was naming her senate majority leader," which can be replaced with direct speech for clarity and conciseness.
4. The sentence "Galvano says he picked Passidomo for the post because she has a good rapport with both Senate Republicans and Democrats and is a consensus builder" can be rephrased to avoid redundancy.
5. The use of parentheses in the sentence "Most of it (the job) is member relations, helping members get their bills heard" can be avoided by rephrasing the sentence.
6. The sentence "The Senate majority leader only gets one vote, just like other senators, so what's the upside for constituents?" can be rephrased to avoid the use of a question and make it more assertive.
7. The sentence "That table includes the Senate president, president pro tempore, in this case Sen. David Simmons, Passidomo as majority leader and perhaps one or two others" can be rephrased for clarity.
8. The sentence "Traditionally, legislators in leadership positions don't file as many bills as rank and file members" can be rephrased to avoid the use of "don't" and make it more assertive.
9. The sentence "Some recent predecessors in the post haven't filed any" can be rephrased to avoid the use of "haven't" and make it more assertive.
10. The sentence "In a message to other senators, Galvano praised Passidomo's efforts on the latter" can be rephrased to avoid the use of "the latter" and make it more precise.
11. The sentence "The role of the Senate majority leader isn't to extract favorable consideration from other senators" can be rephrased to avoid the use of "isn't" and make it more assertive.
12. The sentence "Being named to a top spot now sets Passidomo up for even greater things in the future" can be rephrased to avoid the use of "sets up" and make it more assertive.
13. The sentence "Assuming she keeps her seat in the 2022 election and Republicans maintain control of the Senate in 2022 and beyond, she could be Senate president herself in the session that follows" can be rephrased for clarity and conciseness.
14. The sentence "Passidomo said she was taken by surprise by her sudden promotion" can be rephrased to avoid the use of "was taken by surprise" and make it more assertive.
15. The sentence "Third floor, to be exact" can be avoided as it does not add any significant information to the article.</code></pre>
</div>
</div></li>
</ul>
</section>
<section id="mistral-fine-tune-api-walkthrough" class="level3">
<h3 class="anchored" data-anchor-id="mistral-fine-tune-api-walkthrough">Mistral Fine-tune API Walkthrough</h3>
<ul>
<li><strong>Documentation:</strong> <a href="https://docs.mistral.ai/guides/finetuning/">https://docs.mistral.ai/guides/finetuning/</a></li>
<li><strong>Jupyter Notebook:</strong> <a href="https://github.com/mistralai/cookbook/blob/main/mistral/fine_tune/mistral_finetune_api.ipynb">mistral/fine_tune/mistral_finetune_api.ipynb</a></li>
</ul>
<ol type="1">
<li><strong>Data Preparation:</strong>
<ul>
<li><strong>Format:</strong> Data should be in JSON format.
<ul>
<li><strong>Size Limits:</strong>
<ul>
<li>Training data: Each file &lt;= 512 MB (multiple files allowed).</li>
<li>Evaluation data: Total size &lt;= 1 MB.</li>
</ul></li>
</ul></li>
<li><strong>Reformatting:</strong> Use provided scripts to adapt data from sources like HuggingFace.
<ul>
<li><strong>GitHub:</strong> <a href="https://github.com/mistralai/mistral-finetune/blob/main/utils/reformat_data.py">mistral-finetune/utils/reformat_data.py</a></li>
</ul></li>
<li><strong>Validation:</strong> The <code>mistral-finetune</code> repository includes a data validation script.
<ul>
<li><strong>GitHub:</strong> <a href="https://github.com/mistralai/mistral-finetune/blob/main/utils/validate_data.py">mistral-finetune/utils/validate_data.py</a></li>
</ul></li>
</ul></li>
<li><strong>Uploading Data:</strong>
<ul>
<li><strong>Documentation:</strong> <a href="https://docs.mistral.ai/guides/finetuning/#upload-dataset">Upload dataset</a></li>
<li>Use the <code>files.create</code> function, specifying file name and purpose (“fine-tune”).</li>
</ul></li>
<li><strong>Creating a Fine-tuning Job:</strong>
<ul>
<li>Provide file IDs for training and evaluation data.</li>
<li>Choose the base model (Mistral 7B or Mistral Small).</li>
<li>Set hyperparameters (e.g., learning rate, number of steps).</li>
</ul></li>
<li><strong>Monitoring Progress:</strong>
<ul>
<li>Retrieve job status and metrics using the job ID.</li>
</ul></li>
<li><strong>Using the Fine-tuned Model:</strong>
<ul>
<li>Access the fine-tuned model using the provided model name (retrieved from the completed job).</li>
</ul></li>
<li><strong>Weight &amp; Biases Integration (Optional)</strong>:
<ul>
<li>Configure API key for tracking metrics and visualizations.</li>
</ul></li>
</ol>
</section>
<section id="getting-started-fine-tuning-mistral-7b-local" class="level3">
<h3 class="anchored" data-anchor-id="getting-started-fine-tuning-mistral-7b-local">Getting Started Fine-Tuning Mistral 7B (Local)</h3>
<ul>
<li><p><strong>Jupyter Notebook:</strong> <a href="https://github.com/mistralai/mistral-finetune/blob/main/tutorials/mistral_finetune_7b.ipynb">tutorials/mistral_finetune_7b.ipynb</a></p></li>
<li><p>Covers fine-tuning Mistral 7B</p></li>
</ul>
<p><strong>Steps:</strong></p>
<ol type="1">
<li><strong>Clone Repository:</strong> <code>git clone https://github.com/mistralai/mistral-finetune.git</code></li>
<li><strong>Install Dependencies:</strong> Follow <a href="https://github.com/mistralai/mistral-finetune?tab=readme-ov-file#mistral-finetune">instructions</a> in the repository.</li>
<li><strong>Download Model:</strong> Download the desired Mistral model (e.g., 7Bv3).</li>
<li><strong>Prepare Data:</strong> Similar to the API walkthrough.</li>
<li><strong>Configure Training:</strong>
<ul>
<li>Use a configuration file (<code>.yaml</code>) to specify data paths, model parameters, and hyperparameters.</li>
<li>Adjust sequence length based on available GPU memory.</li>
</ul></li>
<li><strong>Start Training:</strong> Execute the training script.</li>
<li><strong>Inference:</strong>
<ul>
<li><p>Utilize the <code>mistral-inference</code> package.</p>
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/mistralai/mistral-inference">mistral-inference</a></li>
<li><div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb11-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install mistral-inference</span></code></pre></div></li>
</ul></li>
<li><p>Load the tokenizer, base model, and fine-tuned LoRA weights.</p></li>
<li><p>Generate text.</p></li>
</ul></li>
</ol>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-007/</guid>
  <pubDate>Thu, 18 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Workshop 4: Instrumenting &amp; Evaluating LLMs</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/workshop-004/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Serving Overview</li>
<li>Model Deployment Patterns</li>
<li>Case Study: Honeycomb - Replicate</li>
<li>Deploying Large Language Models</li>
<li>Lessons from Building A Serverless Platform - Predibase</li>
<li>Batch vs Real Time and Modal</li>
<li>Q&amp;A Session</li>
</ul>
<section id="serving-overview" class="level2">
<h2 class="anchored" data-anchor-id="serving-overview">Serving Overview</h2>
<section id="recap-on-loras" class="level3">
<h3 class="anchored" data-anchor-id="recap-on-loras">Recap on LoRAs</h3>
<ul>
<li><strong>LoRA (Low-Rank Adaptation)</strong>: A parameter-efficient fine-tuning technique that introduces small adapter matrices into the model’s layers, significantly reducing the number of trainable parameters compared to full fine-tuning.</li>
<li><strong>Benefits of LoRA</strong>: Reduced memory requirements during training and deployment, enabling fine-tuning on consumer-grade hardware and efficient serving of multiple adapters.</li>
<li><strong>Deployment Options</strong>:
<ul>
<li><strong>Keep LoRA separate</strong>: Store LoRA weights in a separate file and load them during inference.</li>
<li><strong>Merge LoRA with base model</strong>: Combine the learned LoRA weights with the original model weights into a single file.</li>
<li><strong>Hot-swapping adapters</strong>: Dynamically load and unload adapters on demand, sharing the base model among multiple adapters.</li>
</ul></li>
</ul>
</section>
<section id="performance-vs-costs" class="level3">
<h3 class="anchored" data-anchor-id="performance-vs-costs">Performance vs Costs</h3>
<ul>
<li><strong>Key Trade-off</strong>: Balancing performance (latency and throughput) with cost (GPU usage and idle time).</li>
<li><strong>Factors Influencing Performance and Cost</strong>:
<ul>
<li><strong>GPU speed:</strong> More powerful GPUs offer lower latency but are more expensive.</li>
<li><strong>Model size:</strong> Larger models generally perform better but require more resources and time.</li>
<li><strong>Engineering optimizations:</strong> Platform-level optimizations can improve efficiency.</li>
<li><strong>Cold start vs.&nbsp;idle time:</strong> Loading models onto GPUs takes time (cold start), but keeping them loaded incurs idle time cost.</li>
</ul></li>
<li><strong>Hot-swapping adapters</strong>: A strategy to mitigate the cold start vs.&nbsp;idle time trade-off by serving multiple LoRAs on the same GPU, ensuring consistent traffic and reducing idle time.</li>
</ul>
</section>
<section id="many-applications-arent-real-time" class="level3">
<h3 class="anchored" data-anchor-id="many-applications-arent-real-time">Many Applications Aren’t Real-Time</h3>
<ul>
<li><strong>Real-time vs.&nbsp;batch/offline processing</strong>: Many LLM applications do not require real-time responses, allowing for batch processing and reducing cost by scaling down GPUs when not in use.</li>
<li><strong>Examples of batch/offline use cases</strong>:
<ul>
<li>Generating alt text for images</li>
<li>Extracting information from documents</li>
<li>Editing text</li>
<li>Analytics tools</li>
</ul></li>
</ul>
</section>
<section id="real-time-vs-batchoffline" class="level3">
<h3 class="anchored" data-anchor-id="real-time-vs-batchoffline">Real-Time vs Batch/Offline</h3>
<ul>
<li><strong>Real-time use cases</strong>: Applications like chatbots and code assistants require low latency responses.</li>
<li><strong>Batch/offline use cases</strong>: Tasks like data analysis, text summarization, and content generation can be processed in batches.</li>
</ul>
</section>
<section id="merging-lora-to-base" class="level3">
<h3 class="anchored" data-anchor-id="merging-lora-to-base">Merging LoRA to Base</h3>
<ul>
<li><p><strong>Workflow example</strong>:</p>
<ol type="1">
<li><p>Train a LoRA model and save the adapter weights.</p></li>
<li><p>Merge the LoRA weights with the base model weights into a single file (potentially sharded for large models).</p>
<ul>
<li><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb1-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">root@724562262aec:/workspace/demo#</span> ls outputs/qlora-out/</span>
<span id="cb1-2">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">README.md</span>         checkpoint-1         checkpoint-4         tokenizer.json</span>
<span id="cb1-3">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">adapter_config.json</span>    checkpoint-2         config.json          tokenizer_config.json</span>
<span id="cb1-4">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">adapter_model.bin</span>     checkpoint-3         special_tokens_map.json</span></code></pre></div>
<ul>
<li><code>adapter_model.bin</code> size: 168 MB</li>
</ul></li>
<li><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb2-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">root@724562262aec:/workspace/demo#</span> python3 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-m</span> axolotl.cli.merge_lora ./qlora.yml <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--dora_model_dir</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./outputs/qlora-out"</span></span></code></pre></div></li>
<li><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb3-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">root@724562262aec:/workspace/demo#</span> ls outputs/qlora-out/merged</span>
<span id="cb3-2">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">config.json</span>             pytorch_model-00003-of-00004.bin   tokenizer.json</span>
<span id="cb3-3">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">generation_config.json</span>        pytorch_model-00004-of-00004.bin   tokenizer_config.json</span>
<span id="cb3-4">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pytorch_model-00001-of-00004.bin</span>   pytorch_model.bin.index.json</span>
<span id="cb3-5">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pytorch_model-00002-of-00004.bin</span>   special_tokens_map.json        </span></code></pre></div>
<ul>
<li>merged <code>.bin</code> files: 16 GB</li>
</ul></li>
</ul></li>
<li><p>Push the merged model files to a platform like HuggingFace Hub.</p></li>
</ol></li>
</ul>
</section>
<section id="push-model-files-to-hf-hub" class="level3">
<h3 class="anchored" data-anchor-id="push-model-files-to-hf-hub">Push Model Files to HF Hub</h3>
<ul>
<li><strong>HuggingFace inference endpoints</strong>: A platform for serving models with options for automatic scaling and GPU selection.</li>
<li><strong>Workflow example</strong>:
<ol type="1">
<li><p>Create a HuggingFace repository.</p>
<ul>
<li><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb4-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-U</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"huggingface_hub[cli]"</span></span>
<span id="cb4-2">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">huggingface-cli</span> repo create conference-demo</span></code></pre></div></li>
</ul></li>
<li><p>Copy the merged model files to the repository.</p>
<ul>
<li><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb5-1">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cp</span> ./outputs/qlora-out/merged/<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span> conference-demo</span></code></pre></div></li>
</ul></li>
<li><p>Use Git LFS to track large files.</p>
<ul>
<li><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb6-1">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> lfs track <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*.bin"</span></span></code></pre></div></li>
</ul></li>
<li><p>Push the repository to HuggingFace Hub.</p>
<ul>
<li><div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb7-1">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> add <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span></span></code></pre></div></li>
</ul></li>
<li><p>Deploy the model using HuggingFace inference endpoints, choosing appropriate scaling and GPU options.</p>
<ul>
<li><div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb8-1">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> commit <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-am</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Push merged files"</span></span>
<span id="cb8-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> push origin main</span></code></pre></div></li>
<li><strong>HuggingFace Hub:</strong> <a href="https://huggingface.co/dansbecker/conference-demo/tree/main">dansbecker/conference-demo</a></li>
</ul></li>
</ol></li>
</ul>
</section>
</section>
<section id="model-deployment-patterns" class="level2">
<h2 class="anchored" data-anchor-id="model-deployment-patterns">Model Deployment Patterns</h2>
<ul>
<li><strong>Blog Post:</strong> <a href="https://outerbounds.com/blog/the-many-ways-to-deploy-a-model/">The Many Ways to Deploy a Model</a></li>
</ul>
<section id="the-many-faces-of-deployments" class="level3">
<h3 class="anchored" data-anchor-id="the-many-faces-of-deployments">The Many Faces of Deployments</h3>
<ul>
<li><table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 40%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Factors</th>
<th>Simple, lots of tools</th>
<th>Some tools, customization may be needed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Speed (time to response)</strong></td>
<td>Slow: Results needed in minutes e.g.&nbsp;portfolio optimization</td>
<td>Fast: Results needed in milliseconds e.g.&nbsp;high-frequency trading</td>
</tr>
<tr class="even">
<td><strong>Scale (requests/second)</strong></td>
<td>Low: 10 request/sec or less e.g.&nbsp;an internal dashboard</td>
<td>High: 10k requests / sec or more e.g.&nbsp;a popular e-commerce site</td>
</tr>
<tr class="odd">
<td><strong>Pace of improvement</strong></td>
<td>Low: Updates infrequently e.g.&nbsp;a stable, marginal model</td>
<td>High: Constant iteration needed e.g.&nbsp;an innovative, important model</td>
</tr>
<tr class="even">
<td><strong>Real-time inputs needed?</strong></td>
<td>No real-time inputs e.g.&nbsp;analyze past data</td>
<td>Yes, real-time inputs e.g.&nbsp;targeted travel ads</td>
</tr>
<tr class="odd">
<td><strong>Reliability requirement</strong></td>
<td>Low: Ok to fail occasionally e.g.&nbsp;a proof of concept</td>
<td>High: Must not fail e.g.&nbsp;a fraud detection model</td>
</tr>
<tr class="even">
<td><strong>Model complexity</strong></td>
<td>Simple models e.g.&nbsp;linear regression</td>
<td>Complex models e.g.&nbsp;LLMs</td>
</tr>
</tbody>
</table></li>
</ul>
</section>
<section id="simple-model-serving" class="level3">
<h3 class="anchored" data-anchor-id="simple-model-serving">Simple Model Serving</h3>
<ul>
<li><strong>Direct interface with model library</strong>: Using frameworks like <a href="https://fastapi.tiangolo.com/">FastAPI</a> to serve models with minimal overhead.</li>
<li><strong>Suitable for</strong>: Proof of concepts, small-scale applications with low performance demands.</li>
</ul>
</section>
<section id="advanced-model-serving" class="level3">
<h3 class="anchored" data-anchor-id="advanced-model-serving">Advanced Model Serving</h3>
<ul>
<li><strong>Complex architectures</strong>: Auto-scaling clusters, load balancers, specialized components for pre- and post-processing.</li>
<li><strong>Example</strong>: <a href="https://kubernetes.io/">Kubernetes</a> with <a href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html">Triton Inference Server</a> and <a href="https://github.com/NVIDIA/TensorRT-LLM">TensorRT-LLM</a>.</li>
</ul>
</section>
<section id="kinds-of-model-serving" class="level3">
<h3 class="anchored" data-anchor-id="kinds-of-model-serving">Kinds of Model Serving</h3>
<ul>
<li><strong>Decision Tree</strong>:</li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 793.93 732.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 728)">
<title>Decision Tree</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-728 789.93,-728 789.93,4 -4,4"></polygon>
<!-- A -->
<g id="node1" class="node">
<title>A</title>
<path fill="ghostwhite" stroke="ghostwhite" d="M295.35,-724C295.35,-724 12.22,-724 12.22,-724 6.22,-724 0.22,-718 0.22,-712 0.22,-712 0.22,-668 0.22,-668 0.22,-662 6.22,-656 12.22,-656 12.22,-656 295.35,-656 295.35,-656 301.35,-656 307.35,-662 307.35,-668 307.35,-668 307.35,-712 307.35,-712 307.35,-718 301.35,-724 295.35,-724"></path>
<text text-anchor="middle" x="153.78" y="-697.5" font-family="sans-serif:bold" font-size="25.00">Is there a finite enough set of</text>
<text text-anchor="middle" x="153.78" y="-667.5" font-family="sans-serif:bold" font-size="25.00">inputs known in advance?</text>
</g>
<!-- B -->
<g id="node2" class="node">
<title>B</title>
<path fill="#9bcd9b" stroke="#9bcd9b" d="M178.69,-590C178.69,-590 66.87,-590 66.87,-590 60.87,-590 54.87,-584 54.87,-578 54.87,-578 54.87,-534 54.87,-534 54.87,-528 60.87,-522 66.87,-522 66.87,-522 178.69,-522 178.69,-522 184.69,-522 190.69,-528 190.69,-534 190.69,-534 190.69,-578 190.69,-578 190.69,-584 184.69,-590 178.69,-590"></path>
<text text-anchor="middle" x="122.78" y="-563.5" font-family="sans-serif:bold" font-size="25.00">Precompute</text>
<text text-anchor="middle" x="122.78" y="-533.5" font-family="sans-serif:bold" font-size="25.00">responses</text>
</g>
<!-- A&#45;&gt;B -->
<g id="edge1" class="edge">
<title>A-&gt;B</title>
<path fill="none" stroke="black" d="M145.96,-655.69C141.26,-635.68 135.3,-610.31 130.6,-590.3"></path>
<text text-anchor="middle" x="161.22" y="-615.5" font-family="sans-serif:bold" font-size="25.00">Yes</text>
</g>
<!-- C -->
<g id="node3" class="node">
<title>C</title>
<path fill="ghostwhite" stroke="ghostwhite" d="M491.41,-590C491.41,-590 220.16,-590 220.16,-590 214.16,-590 208.16,-584 208.16,-578 208.16,-578 208.16,-534 208.16,-534 208.16,-528 214.16,-522 220.16,-522 220.16,-522 491.41,-522 491.41,-522 497.41,-522 503.41,-528 503.41,-534 503.41,-534 503.41,-578 503.41,-578 503.41,-584 497.41,-590 491.41,-590"></path>
<text text-anchor="middle" x="355.78" y="-563.5" font-family="sans-serif:bold" font-size="25.00">Is it ok to return responses</text>
<text text-anchor="middle" x="355.78" y="-533.5" font-family="sans-serif:bold" font-size="25.00">asynchronously in minutes?</text>
</g>
<!-- A&#45;&gt;C -->
<g id="edge2" class="edge">
<title>A-&gt;C</title>
<path fill="none" stroke="black" d="M204.49,-655.86C235.23,-635.78 274.31,-610.24 305.05,-590.15"></path>
<text text-anchor="middle" x="289.06" y="-615.5" font-family="sans-serif:bold" font-size="25.00">No</text>
</g>
<!-- D -->
<g id="node4" class="node">
<title>D</title>
<path fill="#9bcd9b" stroke="#9bcd9b" d="M385.74,-441C385.74,-441 171.82,-441 171.82,-441 165.82,-441 159.82,-435 159.82,-429 159.82,-429 159.82,-385 159.82,-385 159.82,-379 165.82,-373 171.82,-373 171.82,-373 385.74,-373 385.74,-373 391.74,-373 397.74,-379 397.74,-385 397.74,-385 397.74,-429 397.74,-429 397.74,-435 391.74,-441 385.74,-441"></path>
<text text-anchor="middle" x="278.78" y="-414.5" font-family="sans-serif:bold" font-size="25.00">Trigger a workflow to</text>
<text text-anchor="middle" x="278.78" y="-384.5" font-family="sans-serif:bold" font-size="25.00">compute responses</text>
</g>
<!-- C&#45;&gt;D -->
<g id="edge3" class="edge">
<title>C-&gt;D</title>
<path fill="none" stroke="black" d="M338.31,-521.64C325.71,-497.59 308.77,-465.25 296.19,-441.22"></path>
<text text-anchor="middle" x="348.22" y="-481.5" font-family="sans-serif:bold" font-size="25.00">Yes</text>
</g>
<!-- E -->
<g id="node5" class="node">
<title>E</title>
<path fill="gold" stroke="gold" d="M628.03,-456C628.03,-456 427.53,-456 427.53,-456 421.53,-456 415.53,-450 415.53,-444 415.53,-444 415.53,-370 415.53,-370 415.53,-364 421.53,-358 427.53,-358 427.53,-358 628.03,-358 628.03,-358 634.03,-358 640.03,-364 640.03,-370 640.03,-370 640.03,-444 640.03,-444 640.03,-450 634.03,-456 628.03,-456"></path>
<text text-anchor="middle" x="527.78" y="-429.5" font-family="sans-serif:bold" font-size="25.00">Are you comfortable</text>
<text text-anchor="middle" x="527.78" y="-399.5" font-family="sans-serif:bold" font-size="25.00">operating services</text>
<text text-anchor="middle" x="527.78" y="-369.5" font-family="sans-serif:bold" font-size="25.00">by yourself?</text>
</g>
<!-- C&#45;&gt;E -->
<g id="edge4" class="edge">
<title>C-&gt;E</title>
<path fill="none" stroke="black" d="M394.81,-521.64C417.41,-502.33 446.25,-477.68 471.29,-456.28"></path>
<text text-anchor="middle" x="463.06" y="-481.5" font-family="sans-serif:bold" font-size="25.00">No</text>
</g>
<!-- F -->
<g id="node6" class="node">
<title>F</title>
<path fill="gold" stroke="gold" d="M429.55,-262C429.55,-262 174.01,-262 174.01,-262 168.01,-262 162.01,-256 162.01,-250 162.01,-250 162.01,-206 162.01,-206 162.01,-200 168.01,-194 174.01,-194 174.01,-194 429.55,-194 429.55,-194 435.55,-194 441.55,-200 441.55,-206 441.55,-206 441.55,-250 441.55,-250 441.55,-256 435.55,-262 429.55,-262"></path>
<text text-anchor="middle" x="301.78" y="-235.5" font-family="sans-serif:bold" font-size="25.00">Do you require large scale</text>
<text text-anchor="middle" x="301.78" y="-205.5" font-family="sans-serif:bold" font-size="25.00">or low latency?</text>
</g>
<!-- E&#45;&gt;F -->
<g id="edge5" class="edge">
<title>E-&gt;F</title>
<path fill="none" stroke="black" d="M466.33,-357.87C427.5,-327.46 378.36,-288.97 343.92,-262"></path>
<text text-anchor="middle" x="461.22" y="-317.5" font-family="sans-serif:bold" font-size="25.00">Yes</text>
</g>
<!-- I -->
<g id="node9" class="node">
<title>I</title>
<path fill="#9bcd9b" stroke="#9bcd9b" d="M774.09,-292C774.09,-292 471.48,-292 471.48,-292 465.48,-292 459.48,-286 459.48,-280 459.48,-280 459.48,-176 459.48,-176 459.48,-170 465.48,-164 471.48,-164 471.48,-164 774.09,-164 774.09,-164 780.09,-164 786.09,-170 786.09,-176 786.09,-176 786.09,-280 786.09,-280 786.09,-286 780.09,-292 774.09,-292"></path>
<text text-anchor="middle" x="622.78" y="-265.5" font-family="sans-serif:bold" font-size="25.00">Use a managed model</text>
<text text-anchor="middle" x="622.78" y="-235.5" font-family="sans-serif:bold" font-size="25.00">hosting service:</text>
<text text-anchor="middle" x="622.78" y="-175.5" font-family="sans-serif:bold" font-size="25.00">Amazon SageMaker, Anyscale</text>
</g>
<!-- E&#45;&gt;I -->
<g id="edge6" class="edge">
<title>E-&gt;I</title>
<path fill="none" stroke="black" d="M553.74,-357.63C564.56,-337.47 577.28,-313.78 588.83,-292.26"></path>
<text text-anchor="middle" x="594.06" y="-317.5" font-family="sans-serif:bold" font-size="25.00">No</text>
</g>
<!-- G -->
<g id="node7" class="node">
<title>G</title>
<path fill="#9bcd9b" stroke="#9bcd9b" d="M285.92,-98C285.92,-98 25.64,-98 25.64,-98 19.64,-98 13.64,-92 13.64,-86 13.64,-86 13.64,-12 13.64,-12 13.64,-6 19.64,0 25.64,0 25.64,0 285.92,0 285.92,0 291.92,0 297.92,-6 297.92,-12 297.92,-12 297.92,-86 297.92,-86 297.92,-92 291.92,-98 285.92,-98"></path>
<text text-anchor="middle" x="155.78" y="-71.5" font-family="sans-serif:bold" font-size="25.00">Deploy an advanced stack:</text>
<text text-anchor="middle" x="155.78" y="-11.5" font-family="sans-serif:bold" font-size="25.00">NVIDIA</text>
</g>
<!-- F&#45;&gt;G -->
<g id="edge7" class="edge">
<title>F-&gt;G</title>
<path fill="none" stroke="black" d="M274.32,-193.71C252.1,-166.77 220.51,-128.47 195.53,-98.18"></path>
<text text-anchor="middle" x="253.22" y="-123.5" font-family="sans-serif:bold" font-size="25.00">Yes</text>
</g>
<!-- H -->
<g id="node8" class="node">
<title>H</title>
<path fill="#9bcd9b" stroke="#9bcd9b" d="M567.62,-83C567.62,-83 327.94,-83 327.94,-83 321.94,-83 315.94,-77 315.94,-71 315.94,-71 315.94,-27 315.94,-27 315.94,-21 321.94,-15 327.94,-15 327.94,-15 567.62,-15 567.62,-15 573.62,-15 579.62,-21 579.62,-27 579.62,-27 579.62,-71 579.62,-71 579.62,-77 573.62,-83 567.62,-83"></path>
<text text-anchor="middle" x="447.78" y="-56.5" font-family="sans-serif:bold" font-size="25.00">Deploy a simple service:</text>
<text text-anchor="middle" x="447.78" y="-26.5" font-family="sans-serif:bold" font-size="25.00">OpenLLM, FastAPI</text>
</g>
<!-- F&#45;&gt;H -->
<g id="edge8" class="edge">
<title>F-&gt;H</title>
<path fill="none" stroke="black" d="M329.24,-193.71C355.35,-162.06 394.38,-114.74 420.44,-83.14"></path>
<text text-anchor="middle" x="408.06" y="-123.5" font-family="sans-serif:bold" font-size="25.00">No</text>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="gpu-poor-benchmark-wrong-but-useful" class="level3">
<h3 class="anchored" data-anchor-id="gpu-poor-benchmark-wrong-but-useful">GPU Poor Benchmark (Wrong, but useful)</h3>
<ul>
<li><strong>Benchmarking inference servers</strong>: Experiment with different servers to find the best fit for your use case.</li>
<li><strong>Observations</strong>:
<ul>
<li><a href="https://github.com/vllm-project/vllm">vLLM</a>: Easy to use, good performance trade-offs.</li>
<li>NVIDIA stack (<a href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html">Triton + TensorRT</a>): High performance but complex to use.</li>
<li><strong>Quantization</strong>: Can significantly impact performance, but evaluate quality trade-offs.</li>
</ul></li>
</ul>
</section>
</section>
<section id="case-study-honeycomb---replicate" class="level2">
<h2 class="anchored" data-anchor-id="case-study-honeycomb---replicate">Case Study: Honeycomb - Replicate</h2>
<ul>
<li><p><strong><a href="https://replicate.com/">Replicate</a>:</strong> Run AI with an API</p></li>
<li><p><a href="https://replicate.com/hamelsmu/honeycomb-4-awq">hamelsmu/honeycomb-4-awq</a>: Honeycomb NLQ Generator hosted with vLLM + AWQ Quantized</p></li>
<li><p><strong>HoneyComb Model:</strong> <a href="https://huggingface.co/parlance-labs/hc-mistral-alpaca-merged-awq">parlance-labs/hc-mistral-alpaca-merged-awq</a></p></li>
</ul>
<section id="why-replicate" class="level3">
<h3 class="anchored" data-anchor-id="why-replicate">Why Replicate?</h3>
<ul>
<li><strong>Real-time Use Case:</strong> The Honeycomb example demands real-time responses within the Honeycomb interface, making a platform like Replicate ideal.</li>
<li><strong>User-Friendly Playground:</strong> Replicate provides a playground environment with structured input, beneficial for non-technical users to interact with the model.</li>
<li><strong>Permalink Functionality:</strong> Replicate generates permalinks for predictions, which simplifies debugging and sharing specific scenarios with collaborators.</li>
<li><strong>Built-in Documentation and API:</strong> Replicate automatically generates documentation and API endpoints for easy integration and sharing.</li>
<li><strong>Example Saving:</strong> The platform allows users to save specific examples for future reference and testing.</li>
</ul>
</section>
<section id="show-me-the-code" class="level3">
<h3 class="anchored" data-anchor-id="show-me-the-code">Show Me the Code</h3>
<ul>
<li><strong>GitHub:</strong> <a href="https://github.com/parlance-labs/ftcourse/tree/master/replicate-examples/mistral-vllm-awq">ftcourse/replicate-examples/mistral-vllm-awq</a></li>
<li><strong><a href="https://cog.run/">Cog</a>:</strong> Containers for machine learning</li>
</ul>
<p><strong>Files:</strong></p>
<ul>
<li><code>cog.yaml</code>: Defines the Docker environment and specifies the entry point (<code>predict.py</code>).</li>
<li><code>predict.py</code>: Contains the model loading, setup, and prediction logic.</li>
</ul>
<p><strong>Steps:</strong> 1. <strong>Environment Setup:</strong> - Install Cog (a Docker wrapper that simplifies CUDA management). - Download the model weights from Hugging Face Hub (optional, for local testing). 2. <strong>Code Structure:</strong> - <code>cog.yaml</code>: - Specifies the base Docker image and dependencies. - Defines the <code>predict.py</code> file as the entry point. - ```yaml # Configuration for Cog ⚙️ # Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md</p>
<pre><code>      build:
       # set to true if your model requires a GPU
       gpu: true
       cuda: "12.1"
      
       # python version in the form '3.8' or '3.8.12'
       python_version: "3.11"
      
       # a list of packages in the format &lt;package-name&gt;==&lt;version&gt;
       python_packages:
        - "hf_transfer==0.1.4"
        - "aiohttp[speedups]"
        - "torch==2.1.2"
      
       # commands run after the environment is setup
       run:
        - pip install "pydantic&lt;2.0.0"
        - CUDA_HOME=/usr/local/cuda pip install --ignore-installed vllm==0.3.0
        - pip install https://r2.drysys.workers.dev/tmp/cog-0.10.0a6-py3-none-any.whl
        - bash -c 'ln -s /usr/local/lib/python3.11/site-packages/torch/lib/lib{nv,cu}* /usr/lib'
        - pip install scipy==1.11.4 sentencepiece==0.1.99 protobuf==4.23.4
        - ln -sf $(which echo) $(which pip)
      
      predict: "predict.py:Predictor"
      ```
- `predict.py`:
    - **Prompt Template:** Sets the structure for interacting with the LLM.
    - **Setup:**
        - Defines a `Predictor` class.
        - Loads the quantized model from Hugging Face Hub during initialization.
    - **Predict Function:**
        - Takes the natural language query and schema as input.
        - Processes the input through the LLM using vLLM.
        - Returns the generated Honeycomb query.
    
    - ```python
        import os
        os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "1"
        import torch
        from cog import BasePredictor
        from vllm import LLM, SamplingParams
        
        
        MODEL_ID = 'parlance-labs/hc-mistral-alpaca-merged-awq'
        MAX_TOKENS=2500
        
        PROMPT_TEMPLATE = """Honeycomb is an observability platform that allows you to write queries to inspect trace data. You are an assistant that takes a natural language query (NLQ) and a list of valid columns and produce a Honeycomb query.
        
        ### Instruction:
        
        NLQ: "{nlq}"
        
        Columns: {cols}
        
        ### Response:
        """
        
        class Predictor(BasePredictor):
            
          def setup(self):
            n_gpus = torch.cuda.device_count()
            self.sampling_params = SamplingParams(stop_token_ids=[2], temperature=0, ignore_eos=True, max_tokens=2500)
        
            self.llm = LLM(model='parlance-labs/hc-mistral-alpaca-merged-awq', 
                    tensor_parallel_size=n_gpus, quantization="AWQ")
        
          def predict(self, nlq: str, cols: str) -&gt; str:    
            _p = PROMPT_TEMPLATE.format(nlq=nlq, cols=cols)
            out = self.llm.generate(_p, sampling_params=self.sampling_params, use_tqdm=False)
            return out[0].outputs[0].text.strip().strip('"')
        ```</code></pre>
<ol start="3" type="1">
<li><strong>Local Testing:</strong>
<ul>
<li><strong>Run Cog Server:</strong> <code>cog run</code> starts a local web server for interacting with the model.
<ul>
<li><div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb10-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">cog</span> run <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-e</span> CUDA_VISIBLE_DEVICES=0 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-p</span> 5000 python <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-m</span> cog.server.http</span></code></pre></div></li>
</ul></li>
<li><strong>Direct Prediction:</strong> <code>cog predict -i input1=value1 input2=value2</code> allows for direct prediction using command-line arguments.
<ul>
<li><div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb11-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">cog</span> predict <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-e</span> CUDA_VISIBLE_DEVICES=0 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> nlq=<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"EMISSING slowest traces"</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> cols=<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"['sli.latency', 'duration_ms', 'net.transport', 'http.method', 'error', 'http.target', 'http.route', 'rpc.method', 'ip', 'http.request_content_length', 'rpc.service', 'apdex', 'name', 'message.type', 'http.host', 'service.name', 'rpc.system', 'http.scheme', 'sli.platform-time', 'type', 'http.flavor', 'span.kind', 'dc.platform-time', 'library.version', 'status_code', 'net.host.port', 'net.host.ip', 'app.request_id', 'bucket_duration_ms', 'library.name', 'sli_product', 'message.uncompressed_size', 'rpc.grpc.status_code', 'net.peer.port', 'log10_duration_ms', 'http.status_code', 'status_message', 'http.user_agent', 'net.host.name', 'span.num_links', 'message.id', 'parent_name', 'app.cart_total', 'num_products', 'product_availability', 'revenue_at_risk', 'trace.trace_id', 'trace.span_id', 'ingest_timestamp', 'http.server_name', 'trace.parent_id']"</span></span></code></pre></div></li>
</ul></li>
</ul></li>
<li><strong>Deployment to Replicate:</strong>
<ul>
<li><strong>Create a Model on Replicate:</strong>
<ul>
<li>Choose a descriptive name.</li>
<li>Select appropriate hardware based on memory and GPU requirements.</li>
<li>Choose “Custom Cog Model” as the model type.</li>
</ul></li>
<li><strong>Login to Cog:</strong> <code>cog login</code></li>
<li><strong>Push to Replicate:</strong> <code>cog push r8.im/hamelsmu/honeycomb-4-awq</code></li>
</ul></li>
</ol>
</section>
</section>
<section id="deploying-large-language-models" class="level2">
<h2 class="anchored" data-anchor-id="deploying-large-language-models">Deploying Large Language Models</h2>
<section id="deploying-llms" class="level3">
<h3 class="anchored" data-anchor-id="deploying-llms">Deploying LLMs</h3>
<ul>
<li>Deploying LLMs is challenging, even in 2024, due to the multidimensional and zero-sum nature of performance optimization and the constant evolution of technology.</li>
</ul>
<section id="challenges-in-deploying-llms" class="level4">
<h4 class="anchored" data-anchor-id="challenges-in-deploying-llms">Challenges in Deploying LLMs</h4>
<ul>
<li><strong>Multidimensional and Zero-Sum Performance:</strong> LLM performance involves trade-offs between various factors like speed, cost, and accuracy. Prioritizing one dimension often negatively impacts others.
<ul>
<li><strong>Example:</strong> Increasing batch size improves throughput (total tokens per second) but reduces single-stream performance (tokens per second for a single request), impacting user experience.</li>
</ul></li>
<li><strong>Rapid Technology Evolution:</strong> The field is constantly evolving with new serving frameworks and optimization techniques emerging frequently. Keeping up with these changes while maintaining a performant and cost-effective deployment is demanding.</li>
</ul>
</section>
<section id="llm-performance-bottlenecks" class="level4">
<h4 class="anchored" data-anchor-id="llm-performance-bottlenecks">LLM Performance Bottlenecks</h4>
<p>Two primary factors contribute to slow LLM inference:</p>
<ul>
<li><strong>Memory Bandwidth:</strong> Transformers require frequent data transfers between slow device memory and faster memory caches on GPUs.</li>
<li><strong>Software Overhead:</strong> Launching and scheduling each operation in a model’s forward pass involves communication between CPU and GPU, creating overhead.</li>
</ul>
</section>
<section id="techniques-for-optimizing-llm-performance" class="level4">
<h4 class="anchored" data-anchor-id="techniques-for-optimizing-llm-performance">Techniques for Optimizing LLM Performance</h4>
<ul>
<li><strong>Memory Bandwidth Optimization:</strong>
<ul>
<li><strong>CUDA Kernel Optimization:</strong> Techniques like kernel fusion aim to minimize data transfer by combining multiple kernels into one.</li>
<li><strong>Flash Attention:</strong> Improves efficiency by minimizing data movement during attention calculations.</li>
<li><strong>Paged Attention:</strong> Optimizes data storage and transfer for increased efficiency.</li>
<li><strong>Quantization:</strong> Reduces model size by using lower-precision data types, allowing for faster data transfer.</li>
<li><strong>Speculative Decoding:</strong> Generates multiple tokens in parallel, discarding incorrect ones, to potentially reduce latency.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2405.19325">Nearest Neighbor Speculative Decoding for LLM Generation and Attribution</a></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/feifeibear/LLMSpeculativeSampling">feifeibear/LLMSpeculativeSampling</a></li>
</ul></li>
</ul></li>
<li><strong>Software Overhead Reduction:</strong>
<ul>
<li><strong>CUDA Kernel Optimization:</strong> Fewer, more efficient kernels lead to fewer kernel launches.</li>
<li><strong>CUDA Graphs:</strong> Traces and combines all kernel launches in a forward pass into a single unit, reducing CPU-GPU communication.</li>
</ul></li>
<li><strong>Runtime Optimizations:</strong>
<ul>
<li><strong>Continuous Batching:</strong> Enables efficient processing of requests with varying lengths by continuously adding and removing them from batches during inference.</li>
<li><strong>KV Caching:</strong> Stores key-value embeddings during inference, avoiding redundant calculations for repeated inputs.</li>
<li><strong>Hardware Upgrades:</strong> Using more powerful GPUs directly improves performance.</li>
<li><strong>Input/Output Length Optimization:</strong> Shorter inputs and outputs reduce the number of tokens processed, potentially improving latency.</li>
</ul></li>
</ul>
</section>
<section id="continuous-batching" class="level4">
<h4 class="anchored" data-anchor-id="continuous-batching">Continuous Batching</h4>
<ul>
<li><p>Continuous batching is a significant advancement in LLM serving that addresses limitations of traditional micro-batching.</p></li>
<li><p><strong>Blog Post:</strong> <a href="https://www.anyscale.com/blog/continuous-batching-llm-inference">How continuous batching enables 23x throughput in LLM inference while reducing p50 latency</a></p></li>
<li><p><strong>How it Works:</strong> Processes requests as a stream of individual token generation steps, allowing for dynamic addition and removal of requests within a batch.</p></li>
<li><p><strong>Benefits:</strong></p>
<ul>
<li>Eliminates the need to wait for a complete batch before processing, reducing latency.</li>
<li>Enables efficient handling of requests with varying lengths.</li>
</ul></li>
<li><p><strong>Consequences:</strong></p>
<ul>
<li>Results in dynamic batch sizes, making performance less predictable.</li>
<li>Requires careful consideration of performance SLAs and user experience.</li>
</ul></li>
</ul>
</section>
<section id="inference-servers" class="level4">
<h4 class="anchored" data-anchor-id="inference-servers">Inference Servers</h4>
<p>Various inference servers are available, each with its own strengths and weaknesses:</p>
<ul>
<li><strong>Examples:</strong> <a href="https://github.com/vllm-project/vllm">vLLM</a>, <a href="https://huggingface.co/docs/text-generation-inference/en/index">TGI</a>, <a href="https://fastgen.com/">FastGen</a>, <a href="https://github.com/NVIDIA/TensorRT-LLM">TensorRT-LLM</a>, <a href="https://github.com/sgl-project/sglang">SGLang</a>, <a href="https://ollama.com/">Ollama</a>, <a href="https://github.com/ggerganov/llama.cpp">Llama.cpp</a>, <a href="https://github.com/turboderp/exllama">Exllama</a>, <a href="https://github.com/mlc-ai/mlc-llm">MLC</a>, <a href="https://github.com/predibase/lorax">LoRAX</a></li>
<li><strong>Common Features:</strong> Continuous batching, specialized kernels, support for different optimization techniques.</li>
</ul>
</section>
<section id="performance-tuning" class="level4">
<h4 class="anchored" data-anchor-id="performance-tuning">Performance Tuning</h4>
<p>Understanding and tuning for different performance metrics is crucial:</p>
<ul>
<li><strong>Total Tokens Per Second (Throughput):</strong> Measures the overall token generation rate across all requests.</li>
<li><strong>Single Stream Tokens Per Second (Latency):</strong> Measures the token generation rate for a single request, reflecting user experience.</li>
<li><strong>Requests Per Second:</strong> Measures how many requests can be completed per second.</li>
</ul>
<p><strong>Key Considerations:</strong></p>
<ul>
<li>Increasing batch size generally improves throughput but reduces single-stream performance.</li>
<li>Finding the right balance between these metrics depends on the specific use case and desired user experience.</li>
<li>Clearly define performance SLOs and consider both throughput and latency when evaluating performance.</li>
</ul>
</section>
</section>
<section id="simplifying-llm-deployment" class="level3">
<h3 class="anchored" data-anchor-id="simplifying-llm-deployment">Simplifying LLM Deployment</h3>
<section id="prioritize-modularity" class="level4">
<h4 class="anchored" data-anchor-id="prioritize-modularity">Prioritize Modularity</h4>
<p>Building a modular LLM serving stack is essential for navigating the challenges of the rapidly evolving technology landscape.</p>
<ul>
<li><strong>Benefits of Modularity:</strong>
<ul>
<li><strong>Flexibility:</strong> Easily switch between different serving frameworks as needed to leverage new features or optimizations.</li>
<li><strong>Experimentation:</strong> Enables efficient testing and comparison of different frameworks and configurations.</li>
</ul></li>
<li><strong>Challenges:</strong>
<ul>
<li><strong>Compatibility Issues:</strong> Features and optimizations from different frameworks may not always work together seamlessly.</li>
<li><strong>Lack of Documentation:</strong> New features and their interactions may not be well-documented, requiring experimentation and debugging.</li>
</ul></li>
</ul>
</section>
</section>
<section id="simplify-llm-deployment-with-replicate" class="level3">
<h3 class="anchored" data-anchor-id="simplify-llm-deployment-with-replicate">Simplify LLM Deployment with Replicate</h3>
<p>Replicate is a serverless infrastructure that aims to simplify LLM deployment and experimentation.</p>
<section id="replicate-features-and-workflow" class="level4">
<h4 class="anchored" data-anchor-id="replicate-features-and-workflow">Replicate Features and Workflow</h4>
<ul>
<li><strong><a href="https://cog.run/">COG</a>:</strong> Open-source tool for packaging models and serving code, providing control over the serving framework.
<ul>
<li><a href="https://github.com/replicate/cog-vllm">Cog-vLLM</a>: Run vLLM on Replicate</li>
</ul></li>
<li><strong>Hugging Face Integration:</strong> Streamlined workflow for pulling and deploying models from Hugging Face.</li>
<li><strong>Performance Optimizations:</strong> Caching mechanisms and other optimizations to improve model download and cold boot times.</li>
<li><strong>Open Source Approach:</strong> Replicate’s model serving infrastructure is open source, allowing for customization and contributions.</li>
</ul>
<p><strong>Workflow Example:</strong></p>
<ol type="1">
<li><strong>Create a Training:</strong> Specify the model, Hugging Face ID, and other configurations through Replicate’s web interface.</li>
<li><strong>Transfer Weights:</strong> Replicate downloads weights from Hugging Face and pushes them to its optimized storage.</li>
<li><strong>Deploy and Access Model:</strong> Once the training is complete, the model is deployed and accessible through Replicate’s API or client libraries.</li>
<li><strong>Customize with COG:</strong> Utilize COG to customize the serving environment, experiment with different frameworks, and add features.</li>
</ol>
<p><strong>Key Advantages:</strong></p>
<ul>
<li><strong>Simplified Deployment:</strong> Replicate abstracts away infrastructure complexities, making it easy to deploy and serve models.</li>
<li><strong>Framework Flexibility:</strong> Supports multiple serving frameworks like vLLM and TRT-LLM, allowing for experimentation and optimization.</li>
<li><strong>Open Source and Customizable:</strong> Provides transparency and control over the serving environment.</li>
</ul>
</section>
</section>
</section>
<section id="lessons-from-building-a-serverless-platform---predibase" class="level2">
<h2 class="anchored" data-anchor-id="lessons-from-building-a-serverless-platform---predibase">Lessons from Building A Serverless Platform - Predibase</h2>
<section id="predibase-overview" class="level3">
<h3 class="anchored" data-anchor-id="predibase-overview">Predibase Overview</h3>
<ul>
<li><a href="https://predibase.com/">Predibase</a> is a managed platform for fine-tuning and serving LLMs.</li>
<li>It offers an end-to-end solution for prompting, fine-tuning, and deploying LLMs serverlessly or in dedicated environments.</li>
</ul>
</section>
<section id="the-case-for-fine-tuned-llms" class="level3">
<h3 class="anchored" data-anchor-id="the-case-for-fine-tuned-llms">The Case for Fine-Tuned LLMs</h3>
<ul>
<li><strong>General Intelligence vs.&nbsp;Task Specificity:</strong> General-purpose LLMs like ChatGPT are powerful but inefficient for specific tasks. Fine-tuning allows for models tailored to specific business needs, reducing cost and latency.</li>
<li><strong>Cost of Serving Multiple Models:</strong> Serving numerous fine-tuned models on dedicated deployments becomes expensive.</li>
<li><strong><a href="https://github.com/predibase/lorax">LoRAX</a> - A Solution for Efficient Serving:</strong>
<ul>
<li>Lorax is an open-source framework built on HuggingFace’s TGI, designed for efficient fine-tuned LLM inference.</li>
<li>It enables serving multiple fine-tuned models concurrently on a single deployment by sharing base model parameters and using heterogeneous batching of LoRA adapters.</li>
<li>This approach results in significant cost savings compared to dedicated deployments or fine-tuning via OpenAI’s API.</li>
</ul></li>
</ul>
</section>
<section id="deploying-your-fine-tuned-model-practical-considerations" class="level3">
<h3 class="anchored" data-anchor-id="deploying-your-fine-tuned-model-practical-considerations">Deploying Your Fine-Tuned Model: Practical Considerations</h3>
<section id="merging-adapters-pros-and-cons" class="level4">
<h4 class="anchored" data-anchor-id="merging-adapters-pros-and-cons">Merging Adapters: Pros and Cons</h4>
<ul>
<li><strong>Merging:</strong>
<ul>
<li><strong>Pros:</strong> Better baseline performance by eliminating the overhead of processing LoRA layers at runtime.</li>
<li><strong>Cons:</strong> Limits flexibility in serving multiple fine-tunes, incompatibility with certain adapters (e.g., DORA, speculative decoding), potential quantization challenges, increased disk space.</li>
</ul></li>
<li><strong>Not Merging:</strong>
<ul>
<li><strong>Pros:</strong> Allows serving multiple fine-tuned models and the base model on a single deployment, facilitates A/B testing and rapid iteration, compatibility with various adapter types.</li>
<li><strong>Cons:</strong> Potential performance overhead due to processing LoRA layers at runtime.</li>
</ul></li>
<li><strong>Decision:</strong> Whether to merge depends on individual needs and constraints.</li>
</ul>
</section>
<section id="quantization-for-training-and-inference" class="level4">
<h4 class="anchored" data-anchor-id="quantization-for-training-and-inference">Quantization for Training and Inference</h4>
<ul>
<li><strong>Challenge:</strong> Models trained with QLoRA (quantized) often show performance degradation when served using FP16 (full precision). Serving with QLoRA is slow.</li>
<li><strong>Solution:</strong> Dequantize the QLoRA weights to FP16 for inference. This maintains numerical equivalence with the quantized weights while enabling faster inference.</li>
</ul>
</section>
</section>
<section id="performance-tuning-1" class="level3">
<h3 class="anchored" data-anchor-id="performance-tuning-1">Performance Tuning</h3>
<section id="gathering-requirements" class="level4">
<h4 class="anchored" data-anchor-id="gathering-requirements">Gathering Requirements</h4>
<ul>
<li><strong>Factors:</strong> Queries per second, input/output token distribution, number of adapters.</li>
<li><strong>Impact:</strong> These factors influence ideal batch size, target throughput, and latency.</li>
<li><strong>SLOs:</strong> Define service level objectives for peak throughput, latency, and cost.</li>
</ul>
</section>
<section id="deployment-requirements" class="level4">
<h4 class="anchored" data-anchor-id="deployment-requirements">Deployment Requirements</h4>
<ul>
<li><strong>VRAM Estimation:</strong> Allocate at least 1.5x the model weights for serving, considering activations, adapters, and KV cache.</li>
</ul>
</section>
<section id="key-questions-for-choosing-deployment-options" class="level4">
<h4 class="anchored" data-anchor-id="key-questions-for-choosing-deployment-options">Key Questions for Choosing Deployment Options</h4>
<ul>
<li>VRAM needs</li>
<li>Requests per second</li>
<li>Request distribution</li>
<li>Maximum acceptable latency</li>
<li>Willingness to sacrifice quality for cost</li>
<li>Number of tasks</li>
</ul>
</section>
<section id="serverless-vs.-dedicated-deployment" class="level4">
<h4 class="anchored" data-anchor-id="serverless-vs.-dedicated-deployment">Serverless vs.&nbsp;Dedicated Deployment</h4>
<ul>
<li><strong>Serverless:</strong> Suitable for low to medium, uniformly distributed requests with latency tolerance on the order of seconds.</li>
<li><strong>Dedicated:</strong> More appropriate for high, spiky request volumes, batch processing, or when strict latency and throughput SLOs are critical.</li>
</ul>
</section>
</section>
<section id="fine-tuning-for-throughput" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-for-throughput">Fine-Tuning for Throughput</h3>
<ul>
<li><strong>Shifting the Paradigm:</strong> Move beyond focusing solely on quality and leverage fine-tuning for performance improvements.</li>
</ul>
<section id="addressing-performance-differences" class="level4">
<h4 class="anchored" data-anchor-id="addressing-performance-differences">Addressing Performance Differences:</h4>
<ul>
<li>Fine-tuned models with adapters often show slower throughput compared to base models.</li>
</ul>
</section>
<section id="speculative-decoding---the-medusa-approach" class="level4">
<h4 class="anchored" data-anchor-id="speculative-decoding---the-medusa-approach">Speculative Decoding - The Medusa Approach:</h4>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2401.10774">MEDUSA: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads</a></li>
<li>Fine-tune additional projections to predict future tokens, improving throughput by reducing the number of forward passes.</li>
<li>Implement verification steps to ensure only correct tokens are accepted.</li>
</ul>
</section>
<section id="combining-quality-and-performance-with-lookahead-lora" class="level4">
<h4 class="anchored" data-anchor-id="combining-quality-and-performance-with-lookahead-lora">Combining Quality and Performance with Lookahead LoRA:</h4>
<ul>
<li>Fine-tune adapters to predict multiple tokens ahead (lookahead) while maintaining task-specific accuracy.</li>
<li>This approach has shown significant throughput improvements (2-3x) compared to base models and standard LoRA adapters.</li>
</ul>
</section>
</section>
<section id="demonstration" class="level3">
<h3 class="anchored" data-anchor-id="demonstration">Demonstration</h3>
<ul>
<li>A live demo showcased the throughput differences between a base Medusa model, a fine-tuned Medusa model, and a model using lookahead LoRA for a code generation task.</li>
<li>The lookahead LoRA model achieved significantly higher throughput, highlighting the potential of this technique.</li>
</ul>
</section>
</section>
<section id="batch-vs-real-time-and-modal" class="level2">
<h2 class="anchored" data-anchor-id="batch-vs-real-time-and-modal">Batch vs Real Time and Modal</h2>
<section id="throughput-vs.-latency" class="level3">
<h3 class="anchored" data-anchor-id="throughput-vs.-latency">Throughput vs.&nbsp;Latency</h3>
<ul>
<li><strong>Defining “Slow”</strong>: A system can be slow due to low throughput (handling few requests per unit time) or high latency (taking long to process a single request).</li>
<li><strong>Throughput</strong>: Measured in requests completed per unit time.
<ul>
<li>Relevant for batch tasks like recommendation systems, evaluations, and CI/CD.</li>
<li>Constraints often stem from upstream/downstream systems.</li>
</ul></li>
<li><strong>Latency</strong>: Measured in time taken to complete a single request.
<ul>
<li>Crucial for real-time applications like chatbots, copilots, and guardrails.</li>
<li>Human perception is the primary constraint (target ~200ms total system latency).</li>
</ul></li>
<li><strong>Cost</strong>: The hidden factor influencing throughput and latency. More resources generally improve both but at a cost.</li>
</ul>
</section>
<section id="latency-lags-throughput" class="level3">
<h3 class="anchored" data-anchor-id="latency-lags-throughput">Latency Lags Throughput</h3>
<ul>
<li><strong>Paper:</strong> <a href="https://dl.acm.org/doi/pdf/10.1145/1022594.1022596">Latency Lags Bandwidth</a></li>
<li><strong>Latency Improvements Are Hard</strong>: Historically, improving bandwidth has been easier than reducing latency due to fundamental engineering and physical limitations (e.g., speed of light).
<ul>
<li><strong>GPUs Exemplify This</strong>: GPUs are optimized for throughput with large areas dedicated to processing, while CPUs prioritize latency with a focus on caching and control flow.</li>
</ul></li>
</ul>
<section id="gpus-are-inherently-throughput-oriented." class="level4">
<h4 class="anchored" data-anchor-id="gpus-are-inherently-throughput-oriented.">GPUs are inherently throughput-oriented.</h4>
<ul>
<li><strong>Textbook:</strong> <a href="https://www.amazon.com/Programming-Massively-Parallel-Processors-Hands/dp/0323912311/">Programming Massively Parallel Processors: A Hands-on Approach</a></li>
<li>GPUs have much larger areas dedicated to processing units (ALUs) compared to CPUs, which prioritize caching and control flow for lower latency.</li>
<li>This design difference allows GPUs to achieve significantly higher memory throughput, making them suitable for high-throughput tasks like LLM inference.</li>
</ul>
</section>
<section id="llm-inference-challenges" class="level4">
<h4 class="anchored" data-anchor-id="llm-inference-challenges">LLM Inference Challenges</h4>
<ul>
<li><strong>Throughput</strong>: Easily scalable by increasing batch size (with some latency tradeoffs).</li>
<li><strong>Latency</strong>: Much harder to optimize.
<ul>
<li><strong>Techniques for Improvement</strong>: Quantization, model distillation, truncation, faster hardware, and highly optimized software (e.g., CUDA kernels).</li>
<li><strong>Extreme Latency Optimization</strong>: Running models entirely on cache memory (SRAM), as done by <a href="https://wow.groq.com/lpu-inference-engine/">Groq’s LPU</a>, significantly reduces latency but may impact throughput per dollar.</li>
</ul></li>
</ul>
</section>
</section>
<section id="costs-are-high-but-falling." class="level3">
<h3 class="anchored" data-anchor-id="costs-are-high-but-falling.">Costs are high but falling.</h3>
<ul>
<li><strong>Good News</strong>: LLM inference costs are decreasing faster than Moore’s law due to hardware, algorithmic, and R&amp;D advancements.
<ul>
<li><strong>Cognitive Capability for Fixed Price</strong>: $20/megatoken now buys GPT-4 level output, significantly higher capability than what was possible a year ago.</li>
<li><strong>Falling Costs for Fixed Capability</strong>: Achieving chatGPT-level performance is now possible at a fraction of the cost compared to two years ago.</li>
</ul></li>
<li><strong>Implication</strong>: Holding onto a fixed budget and waiting for capabilities to improve is a viable strategy.</li>
</ul>
</section>
<section id="deploying-llms-on-modal" class="level3">
<h3 class="anchored" data-anchor-id="deploying-llms-on-modal">Deploying LLMs on Modal</h3>
<ul>
<li><strong>Modal’s Value Proposition</strong>:
<ul>
<li><strong>High Throughput</strong>: Easy scaling to hundreds of A100s for large-scale fine-tuning and batch inference.</li>
<li><strong>Manageable Latency</strong>: Balancing latency and cost is achievable for models up to 13B parameters, suitable for certain latency-sensitive applications.</li>
<li><strong>Competitive Cost</strong>: Offers competitive GPU pricing with potential for high utilization savings, especially for spiky workloads.</li>
</ul></li>
<li><strong>Beyond GPUs</strong>: Modal provides a complete serverless runtime with storage, compute, and web service capabilities, enabling tasks beyond just LLM inference.</li>
</ul>
</section>
<section id="modal-is-for-more-than-gpus" class="level3">
<h3 class="anchored" data-anchor-id="modal-is-for-more-than-gpus">Modal is for more than GPUs</h3>
<ul>
<li>Modal is not just a serverless GPU platform; it’s a complete runtime environment.</li>
<li><strong>Key Features</strong>:
<ul>
<li><strong>Storage</strong>: Distributed file system, queues, dictionaries, and the ability to mount local and web data.</li>
<li><strong>Compute</strong>: Functions, GPU acceleration, and other serverless compute options.</li>
<li><strong>Web Services</strong>: Web endpoints and server capabilities for deploying applications.</li>
</ul></li>
</ul>
</section>
<section id="demos" class="level3">
<h3 class="anchored" data-anchor-id="demos">Demos</h3>
<ul>
<li><strong>Code:</strong> <a href="https://modal.com/docs/examples">https://modal.com/docs/examples</a></li>
<li><strong>Abliteration LLM</strong>: Demonstrated an LLM modified to remove certain responses (e.g., refusing harmful requests). This demo encountered technical difficulties.
<ul>
<li><strong>Blog Post:</strong> <a href="https://huggingface.co/blog/mlabonne/abliteration">Uncensor any LLM with abliteration</a></li>
</ul></li>
<li><strong>Batch Inference with TRT LLM</strong>: Showcased running batch inference on Llama-3 8B using TRT LLM, achieving high throughput.</li>
<li><strong>Hot Reloading Development Server</strong>: Demonstrated the ability to make code changes locally and have them automatically redeployed on Modal.</li>
<li><strong>OpenAI Compatible Endpoint</strong>: Showcased running an OpenAI compatible endpoint on Modal using vLLM, allowing integration with tools like Instructor.</li>
</ul>
</section>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<section id="awq-in-honeycomb-example" class="level3">
<h3 class="anchored" data-anchor-id="awq-in-honeycomb-example">AWQ in Honeycomb Example</h3>
<ul>
<li><strong>Question:</strong> Clarification sought on the mention of AWQ in the Honeycomb example.</li>
<li><strong>Answer:</strong> AWQ (quantization technique) is highlighted as a tool for model quantization, compatible and easily integrable with vLLM. The speaker shares their preference for using default or documented settings for quantization without delving into extensive customization.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2306.00978">AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a></li>
</ul></li>
</ul>
</section>
<section id="pricing-fine-tuning-projects-for-enterprises" class="level3">
<h3 class="anchored" data-anchor-id="pricing-fine-tuning-projects-for-enterprises">Pricing Fine-Tuning Projects for Enterprises</h3>
<ul>
<li><strong>Question:</strong> Advice sought on determining pricing for enterprise fine-tuning projects.</li>
<li><strong>Answer:</strong> Advises against hourly rates and recommends a value-based approach, which involves:
<ul>
<li>Understanding the client’s problem and its importance.</li>
<li>Identifying key metrics the client aims to improve.</li>
<li>Collaborating to determine the project’s value to the client.
<ul>
<li>If the client does not know, should probably not take the project</li>
</ul></li>
<li>Proposing a reasonable fraction of that value as the price.</li>
</ul></li>
</ul>
</section>
<section id="gpu-optimization-in-modal-with-vllms-async-engine" class="level3">
<h3 class="anchored" data-anchor-id="gpu-optimization-in-modal-with-vllms-async-engine">GPU Optimization in Modal with vLLM’s Async Engine</h3>
<ul>
<li><strong>Question:</strong> Inquiry about optimizing GPU usage in Modal when using vLLM’s asynchronous engine and limiting concurrent requests instead of batch size.</li>
<li><strong>Answer:</strong> Charles Frye emphasizes the importance of measuring actual GPU behavior:
<ul>
<li><strong>CUDA Kernel Utilization:</strong> Monitor using tools like NVIDIA SMI to understand GPU activity.</li>
<li><strong>FLOPs Utilization:</strong> Measure and compare the achieved floating-point operations per second against the system’s theoretical maximum.</li>
<li><strong>Wattage Consumption:</strong> Observe GPU power draw as a proxy for actual workload and potential bottlenecks.</li>
</ul></li>
</ul>
</section>
<section id="hiding-api-endpoints-in-model-serving-web-apps" class="level3">
<h3 class="anchored" data-anchor-id="hiding-api-endpoints-in-model-serving-web-apps">Hiding API Endpoints in Model-Serving Web Apps</h3>
<ul>
<li><strong>Question:</strong> Strategies sought for concealing API endpoints in a web application to prevent exposure through browser inspection tools.</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Proxy Server:</strong> Routing requests through a proxy to mask internal endpoints and implement protections.</li>
<li><strong>Accepting Limitations:</strong> Recognizing that completely hiding data flow from the client-side is challenging.</li>
</ul></li>
</ul>
</section>
<section id="impact-of-input-prompt-size-on-speed" class="level3">
<h3 class="anchored" data-anchor-id="impact-of-input-prompt-size-on-speed">Impact of Input Prompt Size on Speed</h3>
<ul>
<li><strong>Question:</strong> Clarification sought on how reducing input prompt size affects processing speed, given that the entire prompt is read at once.</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Prefill Impact:</strong> Smaller prompts reduce the initial encoding time (prefill), which can be significant for very large inputs.</li>
<li><strong>Attention Calculation:</strong> Shorter sequences lead to faster attention calculations due to the quadratic complexity of attention mechanisms.</li>
<li><strong>Practical Considerations:</strong> The impact might be negligible for moderately sized prompts but becomes increasingly relevant for very large inputs like books or lengthy PDFs.</li>
</ul></li>
</ul>
</section>
<section id="resources-for-learning-continuous-batching" class="level3">
<h3 class="anchored" data-anchor-id="resources-for-learning-continuous-batching">Resources for Learning Continuous Batching</h3>
<ul>
<li><strong>Question:</strong> Recommendation requested for resources to learn about continuous batching.</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Orca Paper:</strong> Referring to the original research paper on continuous batching.</li>
<li><strong>AnyScale Blog Post:</strong> <a href="https://www.anyscale.com/blog/continuous-batching-llm-inference">How continuous batching enables 23x throughput in LLM inference while reducing p50 latency</a></li>
<li><strong>Practical Experimentation:</strong> Emphasizing the value of hands-on experience, benchmarking, and analyzing performance variations.</li>
</ul></li>
</ul>
</section>
<section id="request-caching-layer-in-hugging-face-and-modal" class="level3">
<h3 class="anchored" data-anchor-id="request-caching-layer-in-hugging-face-and-modal">Request Caching Layer in Hugging Face and Modal</h3>
<ul>
<li><strong>Question:</strong> Inquiry about the availability of a request caching layer in Hugging Face and Modal.</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>KV Caching:</strong> The speakers clarify that some frameworks, like TRT-LLM and vLLM, offer KV caching, which can improve performance for requests sharing similar prefixes or chat history.</li>
<li><strong>Higher-Level Caching:</strong> Expanding on the concept, they discuss the possibility of centralized KV cache databases and even caching complete requests and responses for deterministic scenarios.</li>
<li><strong>Replicate’s Approach:</strong> Joe Hoover states that Replicate doesn’t currently provide explicit features for request caching but acknowledges it as a potential future consideration.</li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/workshop-004/</guid>
  <pubDate>Wed, 17 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 6: Train Almost Any LLM Model Using 🤗 autotrain</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-006/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Introduction to AutoTrain</li>
<li>Getting Started with AutoTrain</li>
<li>Fine-tuning LLMs with AutoTrain</li>
<li>Training Your Model</li>
<li>Config Files and Advanced Options</li>
<li>Additional Features and Considerations</li>
<li>Q&amp;A Session</li>
</ul>
<section id="introduction-to-autotrain" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-autotrain">Introduction to AutoTrain</h2>
<ul>
<li><strong>Homepage:</strong> <a href="https://huggingface.co/autotrain">https://huggingface.co/autotrain</a></li>
<li><strong>Documentation:</strong> <a href="https://huggingface.co/docs/autotrain/index">https://huggingface.co/docs/autotrain/index</a></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/huggingface/autotrain-advanced">autotrain-advanced</a></li>
<li>Simplifies model training and fine-tuning for users with varying levels of expertise, from beginners to experienced data scientists.</li>
<li><strong>Supported Tasks:</strong>
<ul>
<li><strong>NLP:</strong> Token classification, text classification, LLM tasks (e.g., SFT, R4, DPO, reward tuning), sentence transformer fine-tuning, etc.</li>
<li><strong>Computer Vision:</strong> Image classification, Object Detection</li>
<li><strong>Tabular Data:</strong> Classification, Regression</li>
</ul></li>
<li>Leverages the Hugging Face ecosystem, including transformers, datasets, diffusers, and Accelerate, ensuring compatibility with the latest models and tools.</li>
</ul>
</section>
<section id="getting-started-with-autotrain" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-autotrain">Getting Started with AutoTrain</h2>
<ul>
<li><strong>Create a new project:</strong>
<ul>
<li><strong>Link:</strong> <a href="https://huggingface.co/login?next=%2Fspaces%2Fautotrain-projects%2Fautotrain-advanced%3Fduplicate%3Dtrue"><code>Create new project</code></a></li>
<li>Optionally specify an organization and attach hardware (local or Hugging Face spaces).</li>
<li>Choose the desired task (e.g., LLM SFT).</li>
</ul></li>
<li><strong>User-Friendly Interface:</strong>
<ul>
<li>Select a task.</li>
<li>Upload your data or use a dataset from the Hugging Face Hub.</li>
<li>Configure parameters or use default settings.</li>
<li>Monitor training progress and logs.</li>
</ul></li>
<li><strong>Documentation:</strong> <a href="https://huggingface.co/docs/autotrain/quickstart_spaces#creating-a-new-autotrain-space">Creating a New AutoTrain Space</a></li>
</ul>
</section>
<section id="fine-tuning-llms-with-autotrain" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuning-llms-with-autotrain">Fine-tuning LLMs with AutoTrain</h2>
<section id="supervised-fine-tuning-sft-and-generic-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-fine-tuning-sft-and-generic-fine-tuning">Supervised Fine-tuning (SFT) and Generic Fine-tuning</h3>
<ul>
<li><strong>Documentation:</strong> <a href="https://huggingface.co/docs/trl/main/en/sft_trainer">Supervised Fine-tuning Trainer</a></li>
<li>Both trainers are similar, but SFT uses the TRL library’s SFT trainer.
<ul>
<li><strong>Documentation:</strong> <a href="https://huggingface.co/docs/trl/main/en/index">TRL - Transformer Reinforcement Learning</a></li>
</ul></li>
<li>Requires a “text” column in your dataset (can be mapped from a different column name).</li>
<li>Supports chat template formatting (chatML, Sapphire, tokenizer’s template).</li>
<li><strong>Example datasets:</strong>
<ul>
<li><a href="Salesforce/wikitext">Salesforce/wikitext</a>: plain text format</li>
<li>Chat format with “content” and “role” fields (requires chat template).</li>
</ul></li>
</ul>
</section>
<section id="reward-modeling" class="level3">
<h3 class="anchored" data-anchor-id="reward-modeling">Reward Modeling</h3>
<ul>
<li><strong>Documentation:</strong> <a href="https://huggingface.co/docs/trl/main/en/reward_trainer">Reward Modeling</a></li>
<li>Trains a custom reward model for sequence classification.</li>
<li>Dataset requires “chosen” and “rejected” text columns.</li>
</ul>
</section>
<section id="dpo-and-orpo" class="level3">
<h3 class="anchored" data-anchor-id="dpo-and-orpo">DPO and ORPO</h3>
<ul>
<li><strong>DPO - Direct Preference Optimization</strong>
<ul>
<li><strong>Documentation:</strong> <a href="https://huggingface.co/docs/trl/main/en/dpo_trainer">DPO Trainer</a></li>
</ul></li>
<li><strong>ORPO - Odds Ratio Preference Optimization</strong>
<ul>
<li><strong>Documentation:</strong> <a href="https://huggingface.co/docs/trl/main/en/orpo_trainer">ORPO Trainer</a></li>
</ul></li>
<li>ORPO is recommended over DPO as it requires less memory and compute.</li>
<li>Dataset requires “prompt,” “chosen,” and “rejected” columns (all conversations).</li>
<li>Supports chat templates.</li>
</ul>
</section>
</section>
<section id="training-your-model" class="level2">
<h2 class="anchored" data-anchor-id="training-your-model">Training Your Model</h2>
<section id="data-format" class="level3">
<h3 class="anchored" data-anchor-id="data-format">Data Format</h3>
<ul>
<li>Use CSV or JSON Lines (JSONL) format
<ul>
<li>JSONL preferred for readability and ease of use.</li>
</ul></li>
<li><strong>Format examples:</strong>
<ul>
<li>Alpaca dataset: Single “text” field with formatted text (no chat template needed).</li>
<li>Chat format: Requires chat template or offline conversion to plain text.</li>
</ul></li>
</ul>
</section>
<section id="training-locally" class="level3">
<h3 class="anchored" data-anchor-id="training-locally">Training Locally</h3>
<ul>
<li><p><strong>Documentation:</strong> <a href="https://huggingface.co/docs/autotrain/quickstart">Quickstart</a></p></li>
<li><p>Set Hugging Face token:</p>
<ul>
<li><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb1-1">  <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">export</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">HF_TOKEN</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>your_token<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span></span></code></pre></div></li>
</ul></li>
<li><p>Run the AutoTrain app: <code>autotrain app</code></p>
<ul>
<li><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb2-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">autotrain</span> app <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--port</span> 8080 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--host</span> 127.0.0.1</span></code></pre></div></li>
</ul></li>
<li><p>Alternatively, use config files or CLI commands.</p>
<ul>
<li><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb3-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">autotrain</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--config</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>path_to_config_file<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span></span></code></pre></div></li>
</ul></li>
</ul>
<section id="local-installation" class="level4">
<h4 class="anchored" data-anchor-id="local-installation">Local Installation</h4>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">PIP</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Conda</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install autotrain-advanced</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-n</span> autotrain python=3.10</span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate autotrain</span>
<span id="cb5-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install autotrain-advanced</span>
<span id="cb5-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> install pytorch torchvision torchaudio pytorch-cuda=12.1 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> pytorch <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> nvidia</span>
<span id="cb5-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nvidia/label/cuda-12.1.0"</span> cuda-nvcc</span></code></pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="training-on-other-platforms" class="level3">
<h3 class="anchored" data-anchor-id="training-on-other-platforms">Training on Other Platforms</h3>
<ul>
<li><strong><a href="https://jarvislabs.ai/">Jarvis Labs</a>:</strong> Provides AutoTrain templates for easy setup and training.</li>
<li><strong><a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">DGX Cloud</a>:</strong> Rent high-performance GPUs for training large models.</li>
<li><strong><a href="https://colab.research.google.com/">Google Colab</a>:</strong> Run AutoTrain directly in Colab using provided notebooks and UI.</li>
</ul>
</section>
</section>
<section id="config-files-and-advanced-options" class="level2">
<h2 class="anchored" data-anchor-id="config-files-and-advanced-options">Config Files and Advanced Options</h2>
<ul>
<li><strong>Documentation:</strong> <a href="https://huggingface.co/docs/autotrain/config">AutoTrain Configs</a></li>
<li>Config files offer more flexibility and control over training parameters.</li>
<li>Define task, base model, data paths, column mapping, hyperparameters, logging, and more.</li>
<li>Access example config files in the AutoTrain GitHub repository.
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/huggingface/autotrain-advanced/tree/main/configs">autotrain-advanced/configs</a></li>
</ul></li>
</ul>
</section>
<section id="additional-features-and-considerations" class="level2">
<h2 class="anchored" data-anchor-id="additional-features-and-considerations">Additional Features and Considerations</h2>
<ul>
<li>AutoTrain automatically handles multi-GPU training using DeepSpeed or distributed data parallel.</li>
<li>QLORA is supported on DeepSpeed for efficient training.</li>
<li>Sentence Transformer fine-tuning is available for tasks like improving RAG models.</li>
</ul>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<ul>
<li><strong>Logging:</strong> Supports Weights &amp; Biases (W&amp;B) logging when using config files.</li>
<li><strong>Mixed Precision:</strong> Supports BF16 and FP16, but not FP8.</li>
<li><strong>Parameter Compatibility:</strong> AutoTrain ensures parameter compatibility based on the chosen base model.</li>
<li><strong>Hyperparameter Optimization:</strong> Not currently supported for LLMs due to long training times.</li>
<li><strong>CPU Training:</strong> Possible, but may come with performance limitations.</li>
<li><strong>Custom Chat Templates:</strong> Can be added by modifying the <code>tokenizer_config.json</code> file of a cloned model.</li>
<li><strong>Synthetic Data Generation:</strong> Not currently supported, but users can generate their own.</li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-006/</guid>
  <pubDate>Fri, 12 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Office Hours 6: Johno Whitaker</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-006/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaways">Key takeaways</h2>
<ul>
<li><strong>Striking a balance between GPU utilization and cache:</strong> While maximizing GPU utilization seems ideal, leaving some headroom for caching can actually improve performance.</li>
<li><strong>The economics of cloud GPU pricing:</strong> Faster, more expensive GPUs often end up being cost-effective due to reduced training time.</li>
<li><strong>Prioritizing alternative customization methods before fine-tuning:</strong> Consider techniques like prompt engineering and context injection before resorting to fine-tuning.</li>
<li><strong>The importance of quick iteration cycles in research:</strong> Start with smaller models and datasets to test ideas rapidly before scaling up.</li>
<li><strong>The value of understanding the tools and digging deeper:</strong> While off-the-shelf libraries are convenient, having a deeper understanding of the underlying code can be crucial for research and debugging.</li>
<li><strong>The potential of alternative hardware and algorithms:</strong> While GPUs and deep learning dominate the current landscape, there is hope for innovation with new programming paradigms and architectures.</li>
<li><strong>Focusing on practical skills and real-world applications:</strong> Building projects and gaining hands-on experience are invaluable, even if specific technologies become obsolete.</li>
<li><strong>The evolving role of LLMs in research:</strong> LLMs are becoming increasingly useful for tasks like paper retrieval and summarization, with the potential for even greater impact in the future.</li>
<li><strong>The importance of exploring diverse research directions:</strong> While chasing the latest trends can be tempting, exploring less crowded research areas can lead to novel and impactful contributions.</li>
</ul>
</section>
<section id="gpu-utilization-and-batch-size" class="level2">
<h2 class="anchored" data-anchor-id="gpu-utilization-and-batch-size">GPU Utilization and Batch Size</h2>
<ul>
<li>Increasing batch size generally improves performance, especially when memory bandwidth is a bottleneck.</li>
<li>However, pushing GPU memory utilization too close to 100% can hinder performance by limiting space for caching.</li>
<li>It’s crucial to leave some headroom for pre-caching layers and avoiding out-of-memory errors during evaluation or unexpected events.</li>
<li>Find the largest comfortable batch size with reasonable memory utilization.</li>
</ul>
</section>
<section id="balancing-compute-and-io-costs" class="level2">
<h2 class="anchored" data-anchor-id="balancing-compute-and-io-costs">Balancing Compute and IO Costs</h2>
<ul>
<li>While using more GPUs increases cost per hour, it also significantly reduces training time.</li>
<li>Cloud GPU pricing often reflects this trade-off, making faster GPUs cost-effective overall.</li>
<li>Consider the time cost of experimentation when choosing between more or fewer GPUs.</li>
<li>For multi-node setups, prioritize data parallelism across nodes and leverage memory-saving techniques within each node to minimize communication overhead.</li>
</ul>
</section>
<section id="hyperparameter-tuning" class="level2">
<h2 class="anchored" data-anchor-id="hyperparameter-tuning">Hyperparameter Tuning</h2>
<ul>
<li>Fine-tuning is not always necessary, as many models perform well with default settings or prompt engineering.</li>
<li>Focus on finding a model and basic configuration that learns effectively before extensively optimizing hyperparameters.</li>
<li>Consider the specific requirements of the application; stylistic formatting may benefit from fine-tuning, while direct knowledge integration might be better served by context injection.</li>
</ul>
</section>
<section id="fine-tuning-vs.-alternative-customization-methods" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuning-vs.-alternative-customization-methods">Fine-tuning vs.&nbsp;Alternative Customization Methods</h2>
<ul>
<li>Fine-tuning can be useful for customizing model behavior, but it’s not the only or always the best approach.</li>
<li>Explore alternative methods like prompt engineering, context injection, and retrieval-augmented generation.</li>
<li>Consider the trade-offs between fine-tuning efficiency, context length limitations, and the ability to incorporate external knowledge.</li>
</ul>
</section>
<section id="tpus-and-other-accelerators" class="level2">
<h2 class="anchored" data-anchor-id="tpus-and-other-accelerators">TPUs and Other Accelerators</h2>
<ul>
<li>TPUs offer high-speed memory access and interconnects, making them suitable for large-scale training.</li>
<li>The principles of memory management and optimization still apply, but the specific considerations might differ.</li>
<li>As dedicated hardware evolves, the lines between GPUs and other accelerators are blurring, with a focus on faster interconnects and larger memory pools.</li>
</ul>
</section>
<section id="optimizing-memory-usage-for-llama-models" class="level2">
<h2 class="anchored" data-anchor-id="optimizing-memory-usage-for-llama-models">Optimizing Memory Usage for LLaMa Models</h2>
<ul>
<li>Quantization (e.g., QLoRA) can significantly reduce memory footprint without major performance degradation.</li>
<li>Consider using 4-bit quantization for base weights to free up memory.</li>
<li>Adjust batch size and gradient accumulation steps to accommodate longer sequences.</li>
<li>Be mindful of the memory overhead associated with larger vocabularies and embedding layers.</li>
</ul>
</section>
<section id="understanding-sequence-length-and-memory-usage" class="level2">
<h2 class="anchored" data-anchor-id="understanding-sequence-length-and-memory-usage">Understanding Sequence Length and Memory Usage</h2>
<ul>
<li>Sequence length during training often represents a maximum value, and actual memory usage depends on the length of individual samples in a batch.</li>
<li>Padding to the maximum sequence length can waste compute resources.</li>
<li>Consider techniques like packing short sequences together or prioritizing longer sequences to optimize memory utilization.</li>
<li>Be aware of how truncating sequences during training might impact the model’s ability to learn effectively.</li>
</ul>
</section>
<section id="tips-for-quick-iteration-cycles" class="level2">
<h2 class="anchored" data-anchor-id="tips-for-quick-iteration-cycles">Tips for Quick Iteration Cycles</h2>
<ul>
<li>Start with smaller models and datasets to test code and ideas quickly.</li>
<li>Gradually increase model size and data complexity as needed.</li>
<li>Prioritize being able to evaluate results quickly, ideally within seconds or minutes.</li>
<li>Develop a workflow that allows for rapid testing and debugging without long waiting times.</li>
</ul>
</section>
<section id="choosing-the-right-tools-for-the-job" class="level2">
<h2 class="anchored" data-anchor-id="choosing-the-right-tools-for-the-job">Choosing the Right Tools for the Job</h2>
<ul>
<li>Off-the-shelf libraries like Axolotl and HuggingFace Trainer are convenient for standard training tasks.</li>
<li>For research and deeper understanding, consider using simpler training loops and libraries that provide more transparency and control.</li>
<li>Strive for a balance between ease of use and the ability to inspect and debug the underlying code.</li>
</ul>
</section>
<section id="cpu-offloading-and-gpu-memory-management" class="level2">
<h2 class="anchored" data-anchor-id="cpu-offloading-and-gpu-memory-management">CPU Offloading and GPU Memory Management</h2>
<ul>
<li>While CPU offloading exists, it’s often slow due to the speed difference between CPU and GPU RAM.</li>
<li>Explicitly manage CPU offloading rather than relying on automatic mechanisms.</li>
<li>Consider CPU offloading when dealing with very long sequences that exceed GPU memory capacity, even with quantization.</li>
</ul>
</section>
<section id="exploring-cpu-offloading-for-long-sequences" class="level2">
<h2 class="anchored" data-anchor-id="exploring-cpu-offloading-for-long-sequences">Exploring CPU Offloading for Long Sequences</h2>
<ul>
<li>CPU offloading might become more attractive as longer context lengths become increasingly important.</li>
<li>By storing weights on the CPU and transferring them to the GPU as needed, larger batches and longer sequences can be processed.</li>
<li>This approach trades off increased transfer time for the ability to handle more data within the GPU memory constraints.</li>
</ul>
</section>
<section id="curating-information-and-staying-up-to-date" class="level2">
<h2 class="anchored" data-anchor-id="curating-information-and-staying-up-to-date">Curating Information and Staying Up-to-Date</h2>
<ul>
<li>Develop a system for filtering and prioritizing information from various sources, such as colleagues, Twitter, and research papers.</li>
<li>Focus on areas of personal interest and relevance to current projects.</li>
<li>Actively seek out information that can be applied to real-world problems and experiments.</li>
</ul>
</section>
<section id="the-importance-and-joy-of-teaching" class="level2">
<h2 class="anchored" data-anchor-id="the-importance-and-joy-of-teaching">The Importance and Joy of Teaching</h2>
<ul>
<li>Teaching is a rewarding way to learn, solidify understanding, and contribute to the community.</li>
<li>Sharing knowledge through blog posts, tutorials, and presentations can benefit both the teacher and the audience.</li>
<li>Engaging with questions and feedback from learners can spark new ideas and research directions.</li>
</ul>
</section>
<section id="the-hardware-lottery-and-future-of-ai" class="level2">
<h2 class="anchored" data-anchor-id="the-hardware-lottery-and-future-of-ai">The Hardware Lottery and Future of AI</h2>
<ul>
<li>The dominance of GPUs and deep learning might be partly due to historical coincidence rather than inherent superiority.</li>
<li>The significant investment in GPU-optimized hardware and software creates inertia.</li>
<li>Breaking free from this paradigm requires making alternative approaches more accessible and efficient.</li>
<li>Innovations in GPU programming, new hardware architectures, and a willingness to explore unconventional ideas offer hope for a more diverse AI landscape.</li>
</ul>
</section>
<section id="balancing-research-and-practical-skills" class="level2">
<h2 class="anchored" data-anchor-id="balancing-research-and-practical-skills">Balancing Research and Practical Skills</h2>
<ul>
<li>Pursuing purely novel research and building practical applications are distinct but valuable pursuits.</li>
<li>For practical impact, focus on solving current problems, learning industry-standard tools, and gaining experience with real-world data.</li>
<li>For research breakthroughs, explore less crowded areas, challenge assumptions, and develop a deep understanding of the fundamentals.</li>
</ul>
</section>
<section id="choosing-projects-for-skill-development" class="level2">
<h2 class="anchored" data-anchor-id="choosing-projects-for-skill-development">Choosing Projects for Skill Development</h2>
<ul>
<li>Engaging in projects, even if they become less relevant with time, provides valuable learning experiences and demonstrates technical skills.</li>
<li>Focus on projects that allow you to learn transferable skills like data processing, model evaluation, and problem-solving.</li>
<li>Stay adaptable and continuously update your skillset as the field evolves.</li>
</ul>
</section>
<section id="llms-impacting-research" class="level2">
<h2 class="anchored" data-anchor-id="llms-impacting-research">LLMs Impacting Research</h2>
<ul>
<li>LLMs are already proving useful for tasks like paper retrieval, summarization, and knowledge extraction.</li>
<li>Tools like undermind.ai showcase the potential of LLMs for improving research workflows.
<ul>
<li><strong><a href="https://undermind.ai/home/">undermind.ai</a>:</strong> During each search, undermind.ai examines results in stages, and uses language models to make key decisions, such as recognizing crucial information and adapting the search strategy.</li>
</ul></li>
<li>Future research directions include exploring more sophisticated applications of LLMs for tasks like knowledge synthesis, hypothesis generation, and experimental design.
<ul>
<li><strong><a href="https://sakana.ai/">sakana.ai</a>:</strong> On a quest to create a new kind of foundation model based on nature-inspired intelligence.
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/SakanaAI/evolutionary-model-merge">Evolutionary Optimization of Model Merging Recipes</a></li>
<li><strong>Blog Post:</strong> <a href="https://sakana.ai/llm-squared/">Can LLMs invent better ways to train LLMs?</a>:</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="rapid-fire-qa-highlights" class="level2">
<h2 class="anchored" data-anchor-id="rapid-fire-qa-highlights">Rapid-Fire Q&amp;A Highlights</h2>
<section id="research-interests-and-coding-style" class="level3">
<h3 class="anchored" data-anchor-id="research-interests-and-coding-style">Research Interests and Coding Style</h3>
<ul>
<li><strong>Current Focus:</strong> While still interested in GANs and diffusion models, Johno’s primary focus has shifted to LLMs.</li>
<li><strong>Coding Style:</strong>
<ul>
<li>Uses tools like Copilot for boilerplate code.</li>
<li>Emphasizes clear, tutorial-like code for better Copilot integration and beginner comprehension.</li>
<li>Values explicitness over extreme code compression, especially when teaching.</li>
<li>Adopts a mix of notebooks (VS Code, Cursor, Jupyter Classic) and scripts depending on the project.
<ul>
<li><strong><a href="https://www.cursor.com/">Cursor</a>:</strong> The AI code editor</li>
</ul></li>
<li>Leverages keyboard shortcuts and learns from colleagues like Jeremy Howard for efficiency.</li>
</ul></li>
</ul>
</section>
<section id="quantization-and-long-context" class="level3">
<h3 class="anchored" data-anchor-id="quantization-and-long-context">Quantization and Long Context</h3>
<ul>
<li><strong>Quantization Overhead:</strong> While quantization methods like QLoRA reduce memory footprint, they introduce computational overhead due to decompression, sometimes impacting performance.</li>
<li><strong>Long Context Challenges:</strong> Initially, QLoRA faced memory efficiency issues with long context lengths compared to LoRA, potentially due to gradient checkpointing implementations.
<ul>
<li>This has been addressed to some extent.</li>
</ul></li>
<li><strong>Unexpected Behavior:</strong> Practical implementations often reveal unexpected behavior compared to theoretical calculations.
<ul>
<li>Bugs, precision errors, and data duplication can arise.</li>
</ul></li>
</ul>
</section>
<section id="bit-llms-and-hybrid-approaches" class="level3">
<h3 class="anchored" data-anchor-id="bit-llms-and-hybrid-approaches">1.58-bit LLMs and Hybrid Approaches</h3>
<ul>
<li><strong>1-bit and 1.58-bit LLMs:</strong> Microsoft’s research explored extreme weight compression using 1-bit (-1, 0, 1) representation, achieving workable but diminished performance.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2402.17764">The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits</a></li>
</ul></li>
<li><strong>Hybrid Approach Potential:</strong> Whitaker believes combining extreme quantization with techniques like LoRA adapters could offer a sweet spot between memory efficiency, speed, and accuracy.
<ul>
<li>Base weights in 1-bit or 2-bit.</li>
<li>LoRA adapters for fine-tuning and accuracy recovery.</li>
<li>Hardware-efficient kernels for low-bit operations.</li>
</ul></li>
<li><strong>Mobius Labs:</strong> Highlighted for their work on efficient kernels and proof-of-concept implementations of hybrid approaches.
<ul>
<li><strong>Homepage:</strong> <a href="https://www.mobiuslabs.com/">Mobius Labs</a>: Multimodal AI for the world’s scale.</li>
<li><strong>Blog Post:</strong> <a href="https://mobiusml.github.io/hqq_blog/">Half-Quadratic Quantization of Large Machine Learning Models</a></li>
</ul></li>
</ul>
</section>
<section id="alternative-architectures" class="level3">
<h3 class="anchored" data-anchor-id="alternative-architectures">Alternative Architectures</h3>
<ul>
<li><strong>Exploring Alternatives:</strong> While transformers dominate, alternative architectures like KAN, state-space models (SSMs), and recurrent models offer benefits in specific areas.
<ul>
<li><strong>State-Space Models:</strong>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2312.00752">Mamba: Linear-Time Sequence Modeling with Selective State Spaces</a></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/state-spaces/mamba">mamba</a></li>
</ul></li>
<li><strong>KAN: Kolmogorov Arnold Networks:</strong>
<ul>
<li><strong>Paper: KAN:</strong> <a href="https://arxiv.org/abs/2404.19756">Kolmogorov-Arnold Networks</a></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/KindXiaoming/pykan">pykan</a></li>
</ul></li>
</ul></li>
<li><strong>SSMs and Long Sequences:</strong> SSMs show promise for tasks involving long sequences, such as text-to-speech and DNA analysis.</li>
<li><strong>Practical Implications:</strong> The emergence of viable alternatives provides practitioners with more tools. The core focus remains on performance and benchmark results.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-006/</guid>
  <pubDate>Thu, 11 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 5: Napkin Math For Fine Tuning with Johno Whitaker</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-005/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Good News &amp; Bad News</li>
<li>Training Neural Networks</li>
<li>Why are we copying data around?</li>
<li>Goal: Keep the GPU Fed</li>
<li>Napkin Math: Understanding Memory Usage</li>
<li>Napkin Math Code Demo</li>
<li>Optimizing LLM Training for Different Hardware</li>
<li>Q&amp;A Session</li>
<li>Recap</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Presentation Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Presentation Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Slides:</strong> <a href="https://docs.google.com/presentation/d/1Ye_6zeatCWkq-fx8A--yK34uwU8oC2YQtMSTV1DgkSI/">Napkin Math For Finetuning</a></li>
</ul>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li><strong>Goal:</strong> To provide insights into the factors influencing fine-tuning performance, enabling better decision-making in training models.</li>
<li><strong>Target audience:</strong> Individuals new to training models, particularly by fine-tuning existing large language models.</li>
<li><strong>Key questions addressed:</strong>
<ul>
<li>Factors affecting model performance.</li>
<li>Strategies for improving performance.</li>
<li>Reasons for memory limitations and slow training times.</li>
<li>Understanding and adjusting various parameters in configuration files.</li>
</ul></li>
<li><strong>Approach:</strong> Utilizing a “napkin math” approach to provide a general understanding of the concepts without delving into intricate mathematical details.</li>
<li><strong>Disclaimer:</strong> Emphasizes that the information presented is simplified for clarity and may not be entirely accurate due to the constantly evolving nature of AI implementations.</li>
</ul>
</section>
<section id="good-news-bad-news" class="level2">
<h2 class="anchored" data-anchor-id="good-news-bad-news">Good News &amp; Bad News</h2>
<ul>
<li><strong>Good news:</strong> The mathematical operations underlying model training are well-understood, enabling analysis and experimentation.</li>
<li><strong>Bad news:</strong>
<ul>
<li>Discrepancies can exist between research papers, code implementations, and framework-specific implementations.</li>
<li>The complexity of the underlying processes can be daunting.</li>
<li>Keeping track of all the details and nuances is challenging.</li>
<li>Multi-GPU setups introduce additional complexity</li>
</ul></li>
<li><strong>Key takeaway:</strong> While a simplified approach can be helpful, acknowledging the inherent complexities is essential for accurate analysis and problem-solving.</li>
</ul>
</section>
<section id="training-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="training-neural-networks">Training Neural Networks</h2>
<section id="training-loop" class="level4">
<h4 class="anchored" data-anchor-id="training-loop">Training Loop</h4>
<ul>
<li><strong>The core cycle:</strong> Load data, feed it through the model, generate an answer, evaluate its quality, and update the model accordingly.</li>
<li><strong>Language model context:</strong> The correct answer typically refers to the next word in a sequence, and predictions are represented as probabilities for potential next words.</li>
<li><strong>Fine-tuning data:</strong> Datasets used for fine-tuning contain instruction-response pairs, allowing the model to learn from desired output patterns.</li>
</ul>
</section>
<section id="on-computers" class="level4">
<h4 class="anchored" data-anchor-id="on-computers">On Computers</h4>
<ul>
<li><strong>Hardware components:</strong> Understanding the roles of CPU, GPU, RAM, and their interconnectivity is crucial for performance analysis.</li>
<li><strong>Memory hierarchy:</strong> Different memory types (e.g., CPU cache, RAM, hard drive) have varying access speeds, influencing data transfer times.</li>
</ul>
</section>
<section id="training-neural-networks-1" class="level4">
<h4 class="anchored" data-anchor-id="training-neural-networks-1">Training Neural Networks</h4>
<ul>
<li><strong>Factors affecting performance:</strong>
<ul>
<li><strong>Data loading:</strong> Reading data from storage.</li>
<li><strong>Model computation:</strong> Performing mathematical operations within the model’s layers.</li>
<li><strong>Parameter storage:</strong> Memory required to store model parameters (weights and biases).</li>
<li><strong>Gradient calculation and storage:</strong> Computing and storing gradients for model updates.</li>
<li><strong>Optimizer operations:</strong> Additional storage and computations for parameter optimization.</li>
</ul></li>
<li><strong>Key takeaway:</strong> Each step in the training loop incurs computational costs and memory demands, understanding these factors is crucial for optimization.</li>
</ul>
</section>
<section id="what-takes-up-time" class="level4">
<h4 class="anchored" data-anchor-id="what-takes-up-time">What takes up time?</h4>
<ul>
<li><strong>Computation:</strong> The number of mathematical operations performed.</li>
<li><strong>Memory management:</strong> Data transfer and storage within the memory hierarchy.</li>
</ul>
</section>
</section>
<section id="why-are-we-copying-data-around" class="level2">
<h2 class="anchored" data-anchor-id="why-are-we-copying-data-around">Why are we copying data around?</h2>
<ul>
<li><strong>Memory hierarchy and data transfer:</strong>
<ul>
<li><strong>Different memory types:</strong> CPU cache, RAM, GPU RAM, hard drives, etc., have varying speeds.</li>
<li><strong>Data movement:</strong> Copying data between these memory locations consumes time, impacting performance.</li>
</ul></li>
<li><strong>Optimizing data flow:</strong> Minimizing unnecessary data transfers and utilizing faster memory options are crucial for optimization.</li>
<li><strong>Multi-GPU and distributed training:</strong>
<ul>
<li><strong>Inter-GPU communication:</strong> Sharing data between GPUs can introduce latency.</li>
<li><strong>Network communication:</strong> In multi-node setups, communication over the network becomes a bottleneck.</li>
</ul></li>
</ul>
</section>
<section id="goal-keep-the-gpu-fed" class="level2">
<h2 class="anchored" data-anchor-id="goal-keep-the-gpu-fed">Goal: Keep the GPU Fed</h2>
<ul>
<li><strong>Goal:</strong> Continuously provide the GPU with data and instructions to avoid downtime.</li>
<li><strong>Ideal:</strong> Fit the entire model and data within the GPU RAM for fastest processing.</li>
<li><strong>Bottleneck:</strong> Large models and limited GPU memory can cause frequent data loading from slower memory, slowing down the training process.</li>
</ul>
<section id="tricks-to-improve-memory-efficiency" class="level3">
<h3 class="anchored" data-anchor-id="tricks-to-improve-memory-efficiency">Tricks to improve memory efficiency</h3>
<ul>
<li><strong>Techniques for keeping data closer to the GPU:</strong>
<ul>
<li><strong>Flash Attention and Fused Kernels:</strong> These reduce memory footprints and data transfers by changing how computations are performed.</li>
<li><strong>Gradient Checkpointing (Activation Checkpointing):</strong> Trades a small increase in compute time for significant memory savings by selectively recomputing activations during backpropagation.</li>
<li><strong>CPU Offloading:</strong> Leverages larger CPU RAM by temporarily storing parts of the model or data that are not actively being used on the GPU.</li>
<li><strong>LoRA (Low-Rank Adaptation):</strong>
<ul>
<li>Freeze most model parameters and train only a small set of adapter parameters.</li>
<li>Reduces memory requirements for gradients and optimizer states.</li>
</ul></li>
<li><strong>Quantization:</strong>
<ul>
<li>Represent model weights using fewer bits (e.g., 8-bit instead of 32-bit).</li>
<li>Reduces memory footprint, allowing for larger models or larger batch sizes.</li>
<li>Needs a little computation to dequantize</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="napkin-math-understanding-memory-usage" class="level2">
<h2 class="anchored" data-anchor-id="napkin-math-understanding-memory-usage">Napkin Math: Understanding Memory Usage</h2>
<section id="full-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="full-fine-tuning">Full Fine-Tuning</h3>
<ul>
<li><strong>Problem:</strong> Full fine-tuning requires storing model parameters, gradients, and optimizer states, leading to high memory consumption.</li>
<li><strong>Explanation:</strong>
<ul>
<li>Each parameter in a model requires multiple bits (e.g., 32 bits) to represent its numeric value.</li>
<li>Gradients for each parameter are stored during training, consuming the same amount of memory as the parameters.</li>
<li>Optimizers like Adam store additional states (e.g., momentum), further increasing memory usage.</li>
</ul></li>
<li><strong>Example:</strong> A model with 100 million parameters using 32 bits per parameter consumes 400MB.
<ul>
<li>Considering gradients and optimizer states, the total memory usage can be 1.2GB or higher.</li>
</ul></li>
</ul>
</section>
<section id="lora-low-rank-adaptation" class="level3">
<h3 class="anchored" data-anchor-id="lora-low-rank-adaptation">LoRA (Low-Rank Adaptation)</h3>
<ul>
<li><strong>Solution:</strong> LoRA reduces memory usage by only training a small subset of parameters while keeping the rest frozen.
<ul>
<li><strong>Example:</strong> For every <code>1000 x 1000</code> matrix, add a <code>1000 x 32</code> matrix</li>
</ul></li>
<li><strong>Explanation:</strong>
<ul>
<li>Only trainable parameters require gradients and optimizer state storage.</li>
<li>LoRA adds a small number of trainable parameters (e.g., 1% of the model size) to each large matrix in the model.</li>
</ul></li>
<li><strong>Benefit:</strong> LoRA significantly reduces memory requirements, enabling training on larger models without fitting the entire model and its associated data into GPU memory.</li>
</ul>
</section>
<section id="quantization" class="level3">
<h3 class="anchored" data-anchor-id="quantization">Quantization</h3>
<ul>
<li><strong>Solution:</strong> Quantization reduces memory usage by representing model parameters with fewer bits.</li>
<li><strong>Explanation:</strong>
<ul>
<li>Instead of using 32 bits, quantization uses 8 bits or even 4 bits per parameter.</li>
</ul></li>
<li><strong>Benefit:</strong> Quantization shrinks the memory footprint of the model, allowing for larger model training or fitting on memory-constrained devices.</li>
<li><strong>Combination with LoRA (QLoRA):</strong> Quantize the frozen base model weights while keeping the LoRA parameters in higher precision for accurate training.</li>
</ul>
</section>
<section id="cpu-offloading-illustration" class="level3">
<h3 class="anchored" data-anchor-id="cpu-offloading-illustration">CPU Offloading Illustration</h3>
<ul>
<li><strong>Solution:</strong> Utilize CPU RAM to store model components and offload computations when GPU memory is insufficient.</li>
<li><strong>Explanation:</strong> Load and process one layer of the model on the GPU at a time, storing the remaining layers and intermediate data in CPU memory.</li>
<li><strong>Trade-off:</strong> While enabling larger model training, CPU offloading introduces latency due to data transfer between CPU and GPU.</li>
</ul>
</section>
<section id="llm-context-length-considerations" class="level3">
<h3 class="anchored" data-anchor-id="llm-context-length-considerations">LLM Context Length Considerations</h3>
<ul>
<li><strong>Problem:</strong> Large context lengths lead to increased memory consumption for storing activations.</li>
<li><strong>Explanation:</strong>
<ul>
<li>Each layer’s output activations need to be stored for gradient calculations, and these activations accumulate with longer input sequences.</li>
</ul></li>
<li><strong>Impact:</strong> Training LLMs with long context lengths requires careful memory management and might necessitate techniques like gradient checkpointing to reduce activation memory footprint.</li>
</ul>
</section>
</section>
<section id="napkin-math-code-demo" class="level2">
<h2 class="anchored" data-anchor-id="napkin-math-code-demo">Napkin Math Code Demo</h2>
<ul>
<li>Demonstrates using PyTorch’s memory tracking tools to analyze memory usage during training.</li>
</ul>
<section id="measuring-memory" class="level3">
<h3 class="anchored" data-anchor-id="measuring-memory">Measuring Memory</h3>
<ul>
<li><strong>Challenge:</strong> Limited GPU RAM restricts the size of models and batch sizes during training.</li>
<li><strong>Solution:</strong> Use PyTorch’s memory tracking capabilities to understand and optimize memory consumption.
<ul>
<li><a href="https://pytorch.org/docs/stable/generated/torch.cuda.max_memory_allocated.html"><code>torch.cuda.max_memory_allocated</code></a>: Provides a more accurate measure of actively used memory.</li>
<li><a href="https://pytorch.org/docs/stable/generated/torch.cuda.max_memory_reserved.html"><code>torch.cuda.max_memory_reserved</code></a>: Reflects total memory held by PyTorch, including pre-allocated space.</li>
</ul></li>
<li><strong>Key Takeaway:</strong> Actively monitor memory usage to make informed decisions about model size, batch size, and other hyperparameters.</li>
</ul>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch, gc, inspect, transformers</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoModelForCausalLM, BitsAndBytesConfig</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> accelerate.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> set_seed</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> peft <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> prepare_model_for_kbit_training</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> peft <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LoraConfig, get_peft_model</span>
<span id="cb1-6"></span>
<span id="cb1-7">transformers.logging.set_verbosity_warning()</span></code></pre></div>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span></span></code></pre></div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> cleanup():</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Free up memory and reset stats"""</span></span>
<span id="cb3-3">    gc.collect()</span>
<span id="cb3-4">    torch.cuda.empty_cache()</span>
<span id="cb3-5">    torch.cuda.reset_peak_memory_stats(device)</span>
<span id="cb3-6">cleanup()</span></code></pre></div>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> print_memory_stats():</span>
<span id="cb4-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Print two different measures of GPU memory usage"""</span></span>
<span id="cb4-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Max memory allocated: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>torch<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>cuda<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>max_memory_allocated(device)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e9</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">GB"</span>)</span>
<span id="cb4-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># reserved (aka 'max_memory_cached') is ~the allocated memory plus pre-cached memory</span></span>
<span id="cb4-5">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Max memory reserved: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>torch<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>cuda<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>max_memory_reserved(device)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e9</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">GB"</span>) </span>
<span id="cb4-6">print_memory_stats()</span></code></pre></div>
<pre class="text"><code>Max memory allocated: 0.00GB
Max memory reserved: 0.00GB</code></pre>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># QLoRA Forward + Backward pass</span></span>
<span id="cb6-2"></span>
<span id="cb6-3">cleanup() <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Clean slate each time</span></span>
<span id="cb6-4"></span>
<span id="cb6-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Quantization config for QLoRA versions</span></span>
<span id="cb6-6">bnb_config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BitsAndBytesConfig(</span>
<span id="cb6-7">    load_in_4bit<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-8">    bnb_4bit_compute_dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.bfloat16</span>
<span id="cb6-9">)</span>
<span id="cb6-10"></span>
<span id="cb6-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the model</span></span>
<span id="cb6-12">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb6-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span>,</span>
<span id="cb6-14">    low_cpu_mem_usage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-15">    quantization_config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>bnb_config,</span>
<span id="cb6-16">    use_cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb6-17">)</span>
<span id="cb6-18"></span>
<span id="cb6-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This function has caused me lots of pain!</span></span>
<span id="cb6-20">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prepare_model_for_kbit_training(model)</span>
<span id="cb6-21"></span>
<span id="cb6-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add LoRA</span></span>
<span id="cb6-23">config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LoraConfig(</span>
<span id="cb6-24">    r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>,</span>
<span id="cb6-25">    lora_alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>,</span>
<span id="cb6-26">    lora_dropout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>,</span>
<span id="cb6-27">    bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"none"</span>,</span>
<span id="cb6-28">    task_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CAUSAL_LM"</span></span>
<span id="cb6-29">)</span>
<span id="cb6-30">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_peft_model(model, config)</span>
<span id="cb6-31"></span>
<span id="cb6-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Move to GPU</span></span>
<span id="cb6-33">model.to(device)</span>
<span id="cb6-34"></span>
<span id="cb6-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare the data</span></span>
<span id="cb6-36">bs, ctx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1200</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># batch size and context length</span></span>
<span id="cb6-37">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>, (bs, ctx), device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device)</span>
<span id="cb6-38"></span>
<span id="cb6-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Forward pass</span></span>
<span id="cb6-40">output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model(data, labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data)</span>
<span id="cb6-41"></span>
<span id="cb6-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Backward pass</span></span>
<span id="cb6-43">output.loss.backward()</span>
<span id="cb6-44"></span>
<span id="cb6-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print max memory stats</span></span>
<span id="cb6-46">print_memory_stats()</span>
<span id="cb6-47"></span>
<span id="cb6-48"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Cleanup</span></span>
<span id="cb6-49"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">del</span> model, output, data</span>
<span id="cb6-50">cleanup()</span></code></pre></div>
<pre class="text"><code>Max memory allocated: 6.42GB
Max memory reserved: 7.09GB</code></pre>
</section>
<section id="memory-history" class="level3">
<h3 class="anchored" data-anchor-id="memory-history">Memory History</h3>
<ul>
<li><strong>Challenge:</strong> Identifying specific memory bottlenecks within the training process.</li>
<li><strong>Solution:</strong> PyTorch’s <code>record_memory_history</code> function helps visualize memory usage over time.</li>
<li><strong>Tool:</strong> Upload the generated pickle file to Pytorch’s Memory Visualizer for a detailed graphical representation.
<ul>
<li><strong>Link:</strong> <a href="https://pytorch.org/memory_viz">https://pytorch.org/memory_viz</a></li>
</ul></li>
<li><strong>Documentation:</strong> <a href="https://pytorch.org/docs/stable/torch_cuda_memory.html">Understanding CUDA Memory Usage</a></li>
<li><strong>Tutorial:</strong> <a href="https://pytorch.org/tutorials/intermediate/optimizer_step_in_backward_tutorial.html">How to save memory by fusing the optimizer step into the backward pass</a></li>
</ul>
<section id="benefits-of-memory-history-analysis" class="level4">
<h4 class="anchored" data-anchor-id="benefits-of-memory-history-analysis">Benefits of Memory History Analysis:</h4>
<ul>
<li><strong>Identify memory spikes:</strong> pinpoint operations causing significant memory increases.</li>
<li><strong>Understand memory allocation patterns:</strong> Visualize how memory usage evolves throughout the training process (forward pass, backward pass, gradient updates).</li>
<li><strong>Evaluate optimization strategies:</strong> Observe the impact of techniques like gradient checkpointing and quantization on memory consumption.</li>
</ul>
</section>
<section id="real-world-examples" class="level4">
<h4 class="anchored" data-anchor-id="real-world-examples">Real-World Examples</h4>
<ul>
<li><strong>Bug Detection:</strong> Unusually high memory spikes revealed incorrect implementations or unintended use of trainable parameters.</li>
<li><strong>Memory Leak Identification:</strong> Gradual memory escalation over multiple training steps pointed to issues with gradient or loss clearing.</li>
<li><strong>Kernel Optimization:</strong> Analysis highlighted inefficiencies in HuggingFace’s Transformers library, prompting a switch back to a more memory-efficient attention kernel.</li>
</ul>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">cleanup()</span>
<span id="cb8-2"></span>
<span id="cb8-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the model</span></span>
<span id="cb8-4">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb8-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span>,</span>
<span id="cb8-6">    low_cpu_mem_usage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb8-7">    quantization_config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>bnb_config,</span>
<span id="cb8-8">    use_cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb8-9">)</span>
<span id="cb8-10">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prepare_model_for_kbit_training(model)</span>
<span id="cb8-11">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_peft_model(model, config)</span>
<span id="cb8-12">model.to(device)</span>
<span id="cb8-13"></span>
<span id="cb8-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prep the data</span></span>
<span id="cb8-15">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>), device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device)</span>
<span id="cb8-16"></span>
<span id="cb8-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Start recording</span></span>
<span id="cb8-18">torch.cuda.memory._record_memory_history()</span>
<span id="cb8-19"></span>
<span id="cb8-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># FOrward and backwards pass</span></span>
<span id="cb8-21">output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model(data, labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data)</span>
<span id="cb8-22">output.loss.backward()</span>
<span id="cb8-23"></span>
<span id="cb8-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save the snapshot and stop recording</span></span>
<span id="cb8-25">torch.cuda.memory._dump_snapshot(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"memory_snapshot.pickle"</span>)</span>
<span id="cb8-26">torch.cuda.memory._record_memory_history(enabled<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>) </span>
<span id="cb8-27"></span>
<span id="cb8-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Clean up</span></span>
<span id="cb8-29"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">del</span> model, output, data</span>
<span id="cb8-30">cleanup()</span></code></pre></div>
<p>Results viewed in <a href="https://pytorch.org/memory_viz">https://pytorch.org/memory_viz</a>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-005/images/image.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
</section>
<section id="optimizing-llm-training-for-different-hardware" class="level2">
<h2 class="anchored" data-anchor-id="optimizing-llm-training-for-different-hardware">Optimizing LLM Training for Different Hardware</h2>
<div class="callout callout-style-default callout-note callout-titled" title="Benchmarking QLoRA+FSDP">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Benchmarking QLoRA+FSDP
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Case Study:</strong> <a href="https://github.com/AnswerDotAI/fsdp_qlora/blob/main/benchmarks_03_2024.md">A Dual 3090 ‘Basement Rig’</a></li>
</ul>
</div>
</div>
<section id="gpu-limitations-data-transfer-bottleneck" class="level3">
<h3 class="anchored" data-anchor-id="gpu-limitations-data-transfer-bottleneck">GPU Limitations &amp; Data Transfer Bottleneck</h3>
<ul>
<li>Training LLMs often involves frequent data transfers between CPU memory and GPU memory.</li>
<li>In systems with limited GPU memory or slow interconnects, these transfers become a significant bottleneck.</li>
<li>Each layer of the model might require loading weights onto the GPU, performing computations, and then repeating the process for the next layer.</li>
</ul>
</section>
<section id="optimizing-for-memory-bound-scenarios" class="level3">
<h3 class="anchored" data-anchor-id="optimizing-for-memory-bound-scenarios">Optimizing for Memory-Bound Scenarios</h3>
<ul>
<li><strong>Goal:</strong> Minimize data transfer cycles by maximizing computation done per load.
<ul>
<li><strong>Example:</strong> Using a larger batch size allows processing more samples per load, reducing the total number of loads required.</li>
</ul></li>
<li><strong>Techniques:</strong>
<ul>
<li><strong>Quantization:</strong> Reduces the precision of model weights, making them faster to transfer and process.</li>
<li><strong>QLoRa:</strong> A memory-efficient training method that further reduces memory footprint compared to standard LoRa.</li>
</ul></li>
<li><strong>Example:</strong> The “3090 basement rig” showed significant speed improvements when using these techniques due to a larger achievable batch size.</li>
</ul>
</section>
<section id="impact-of-hardware-on-optimization-strategies" class="level3">
<h3 class="anchored" data-anchor-id="impact-of-hardware-on-optimization-strategies">Impact of Hardware on Optimization Strategies</h3>
<ul>
<li><p><strong>Memory Bandwidth Constraints:</strong> On slower machines or those with limited interconnect bandwidth, optimizing for memory bandwidth is crucial. Techniques like quantization and larger batch sizes yield significant gains.</p></li>
<li><p><strong>High-End Systems:</strong></p>
<ul>
<li>Systems like the H100 with fast NVLink interconnects and ample GPU memory minimize the data transfer bottleneck.</li>
<li>Model weights can reside in fast GPU memory, even across multiple GPUs, allowing for rapid loading.</li>
<li>Computation becomes the limiting factor, not memory bandwidth.</li>
</ul></li>
<li><p><strong>Example:</strong> In tests on an H100, increasing batch size or using quantization didn’t significantly impact runtime. The bottleneck was compute speed, not data transfer.</p></li>
</ul>
</section>
<section id="adapting-to-hardware-limitations" class="level3">
<h3 class="anchored" data-anchor-id="adapting-to-hardware-limitations">Adapting to Hardware Limitations</h3>
<ul>
<li><strong>Understand Your Hardware:</strong> Identify whether your system is memory-bound or compute-bound.</li>
<li><strong>Optimize Accordingly:</strong>
<ul>
<li><strong>Memory-Bound:</strong> Prioritize techniques like quantization, QLoRa, and increasing batch size to minimize data transfer.</li>
<li><strong>Compute-Bound:</strong> Focus on maximizing computational efficiency, as data transfer is less of a concern.</li>
</ul></li>
</ul>
</section>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<section id="cpu-offloading" class="level3">
<h3 class="anchored" data-anchor-id="cpu-offloading">CPU Offloading</h3>
<ul>
<li><p><strong>Question:</strong> Is CPU offloading useful for training or just inference?</p></li>
<li><p><strong>Answer:</strong> CPU offloading can be beneficial for training large models that exceed single GPU memory, even with multiple GPUs. It allows for larger batch sizes by storing model weights on the CPU and copying them to the GPU as needed. However, it’s less effective with smaller models or abundant GPU memory.</p></li>
<li><p><strong>Recommendation:</strong> Start with default settings and gradually introduce optimizations like quantization, batch size increases, data parallelism, and sharding, evaluating performance gains at each step.</p></li>
</ul>
</section>
<section id="quantization-sweet-spot" class="level3">
<h3 class="anchored" data-anchor-id="quantization-sweet-spot">Quantization Sweet Spot</h3>
<ul>
<li><p><strong>Question:</strong> How to find the optimal balance between compression and accuracy with quantization?</p></li>
<li><p><strong>Answer:</strong> Quantization below 4 bits can negatively impact accuracy. Combining 4-bit quantization with LoRA (adapters) often maintains performance comparable to no quantization.</p></li>
<li><p><strong>Recommendation:</strong> Use 4-bit quantization with LoRA as a starting point. Keep the LoRA in higher precision.</p></li>
</ul>
</section>
<section id="gradient-accumulation" class="level3">
<h3 class="anchored" data-anchor-id="gradient-accumulation">Gradient Accumulation</h3>
<ul>
<li><p><strong>Question:</strong> Clarification on gradient accumulation and micro batch size.</p></li>
<li><p><strong>Answer:</strong> Gradient accumulation simulates larger batch sizes by accumulating gradients over multiple smaller “micro batches” before updating model weights. This is useful when target batch sizes exceed GPU memory.</p></li>
<li><p><strong>Example:</strong> To achieve an effective batch size of 32 with a GPU limited to 8 samples, run 4 micro batches of 8 samples each before updating.</p></li>
<li><p><strong>Recommendation:</strong> Use gradient accumulation to reach a reasonable effective batch size (16, 32, 64), particularly when training with small batch sizes (1 or 2).</p></li>
</ul>
</section>
<section id="multiple-loras" class="level3">
<h3 class="anchored" data-anchor-id="multiple-loras">Multiple LoRAs</h3>
<ul>
<li><p><strong>Question:</strong> Do multiple LoRAs update the same or different model parameters?</p></li>
<li><p><strong>Answer:</strong> Typically, multiple LoRAs update the same weights. Each LoRA targets specific layers defined in its configuration.</p></li>
</ul>
</section>
</section>
<section id="recap" class="level2">
<h2 class="anchored" data-anchor-id="recap">Recap</h2>
<ul>
<li><strong>Balancing Act:</strong> Fine-tuning involves minimizing data movement and maximizing computation efficiency.</li>
<li><strong>Memory Management:</strong>
<ul>
<li><strong>LoRA:</strong> Reduces memory by training a smaller set of parameters.</li>
<li><strong>Quantization:</strong> Stores weights using fewer bits.</li>
<li><strong>Experimentation:</strong> Key to finding the right trade-offs between memory, speed, and accuracy.</li>
</ul></li>
<li><strong>Memory Allocation:</strong>
<ul>
<li><strong>Model Size:</strong> Larger models require more memory for weights and gradients.</li>
<li><strong>Batch Size and Context Length:</strong> Increasing either requires more memory for activations and intermediate values.</li>
</ul></li>
<li><strong>Memory Optimization Strategies:</strong>
<ul>
<li>Reduce context length if possible.</li>
<li>Quantize weights.</li>
<li>Offload to CPU.</li>
</ul></li>
<li><strong>Practical Estimation:</strong> Instead of complex formulas, estimate memory requirements based on measurements from a single layer and extrapolate for the entire model.</li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-005/</guid>
  <pubDate>Sun, 07 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Office Hours 5: LangChain/LangSmith</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-005/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="langsmiths-position-in-the-observability-market" class="level2">
<h2 class="anchored" data-anchor-id="langsmiths-position-in-the-observability-market">LangSmith’s Position in the Observability Market</h2>
<ul>
<li><strong>Question:</strong> How does LangSmith differentiate itself from other observability tools in the market?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>LLM Application Focus:</strong> LangSmith is specifically designed for LLM applications, offering specialized features like message and document visualization for debugging.
<ul>
<li><strong>Guide:</strong> <a href="https://docs.smith.langchain.com/how_to_guides/tracing/log_retriever_trace">Log retriever traces</a></li>
</ul></li>
<li><strong>Chains of LLM Calls:</strong> It emphasizes visualizing and analyzing entire chains of LLM calls and retrieval steps, which is crucial for complex applications.
<ul>
<li><strong>Tutorial:</strong> <a href="https://docs.smith.langchain.com/tutorials/Developers/observability">Add observability to your LLM application</a></li>
</ul></li>
<li><strong>Human-in-the-Loop Features:</strong> LangSmith prioritizes human interaction with features like:
<ul>
<li>Data visualization</li>
<li>Annotation queues for collaboration with subject matter experts</li>
<li>Side-by-side comparisons for evaluating improvements</li>
<li>Alignment of evaluators with human preferences</li>
<li><strong>How-to guides:</strong> <a href="https://docs.smith.langchain.com/how_to_guides/human_feedback">Human feedback</a></li>
</ul></li>
<li><strong>Pairwise Evaluation:</strong> LangSmith enables pairwise evaluation of models, leading to more stable results.
<ul>
<li><strong>Guide:</strong> <a href="https://docs.smith.langchain.com/how_to_guides/evaluation/evaluate_pairwise">Run pairwise evaluations</a></li>
</ul></li>
<li><strong>Strong Support and Openness:</strong> LangSmith is praised for its excellent support, responsive team, and open APIs that allow integration with other tools.</li>
</ul></li>
</ul>
</section>
<section id="langsmiths-support-for-human-annotation-and-action-items" class="level2">
<h2 class="anchored" data-anchor-id="langsmiths-support-for-human-annotation-and-action-items">LangSmith’s Support for Human Annotation and Action Items</h2>
<ul>
<li><strong>Question:</strong> What support does LangSmith offer for human annotation, annotation queues, and taking action on user feedback?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Annotation Queues:</strong>
<ul>
<li>Data can be sent to annotation queues programmatically (e.g., based on user thumbs down) or manually.</li>
<li>Annotators can provide feedback, edit outputs, and add corrected examples to datasets.</li>
<li><strong>Guide:</strong> <a href="https://docs.smith.langchain.com/how_to_guides/human_feedback/annotation_queues">Use annotation queues</a></li>
</ul></li>
<li><strong>Datasets for Improvement:</strong> Corrected examples in datasets can be used for testing and future model improvement.
<ul>
<li><strong>Concept:</strong> <a href="https://docs.smith.langchain.com/concepts/evaluation#datasets-and-examples">Evaluation</a></li>
</ul></li>
<li><strong>Few-Shot Learning:</strong> LangSmith aims to be a platform for gathering few-shot example datasets, which can be used for personalization by pulling down the most similar examples during runtime.</li>
</ul></li>
</ul>
</section>
<section id="understanding-the-langchain-lang-namespace" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-langchain-lang-namespace">Understanding the LangChain “Lang” Namespace</h2>
<ul>
<li><strong>Question:</strong> What’s the difference between Langchain, Langsmith, Langgraph, Langflow, and Langserve?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong><a href="https://www.langchain.com/">LangChain</a>:</strong> The foundational open-source package for building LLM apps, offering a runtime, abstractions, integrations, and off-the-shelf chains.</li>
<li><strong><a href="https://www.langflow.org/">LangFlow</a> (Not Langchain Company):</strong> A low-code/no-code UI built on top of LangChain.</li>
<li><strong><a href="https://python.langchain.com/v0.2/docs/langserve/">LangServe</a>:</strong> Simplifies deploying LangChain applications by exposing them as <a href="https://fastapi.tiangolo.com/">FastAPI</a> endpoints.</li>
<li><strong><a href="https://langchain-ai.github.io/langgraph/">LangGraph</a>:</strong> An extension of LangChain specifically designed for building and managing highly controllable agent-based workflows.</li>
<li><strong><a href="https://www.langchain.com/langsmith">LangSmith</a>:</strong> A standalone observability and testing tool for LLM apps, usable with or without LangChain.</li>
</ul></li>
</ul>
</section>
<section id="when-to-use-langchain-vs.-langgraph" class="level2">
<h2 class="anchored" data-anchor-id="when-to-use-langchain-vs.-langgraph">When to Use LangChain vs.&nbsp;LangGraph</h2>
<ul>
<li><strong>Question:</strong> When would you choose LangChain, and when is LangGraph the better option?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>LangChain:</strong> Ideal for beginners and for rapidly prototyping simple LLM applications with single LLM calls.</li>
<li><strong>LangGraph:</strong> Suited for advanced teams building complex, agentic workflows that require:
<ul>
<li>Cyclical agent execution</li>
<li>Fine-grained control</li>
<li>Built-in persistence</li>
<li>Streaming and background modes</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="popularity-of-typescript-vs.-python-in-llm-tools" class="level2">
<h2 class="anchored" data-anchor-id="popularity-of-typescript-vs.-python-in-llm-tools">Popularity of TypeScript vs.&nbsp;Python in LLM Tools</h2>
<ul>
<li><strong>Question:</strong> How does the usage of TypeScript APIs compare to Python APIs in LangChain and related tools?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Python Dominates:</strong> Python remains more popular overall, possibly due to:
<ul>
<li>A larger community focused on LLM application prototyping.</li>
<li>Stronger ecosystem for data engineering tasks related to retrieval.</li>
</ul></li>
<li><strong>TypeScript for Generative UI:</strong> TypeScript is gaining traction, especially for applications involving generative UI, which is more challenging to implement in Python.</li>
</ul></li>
</ul>
</section>
<section id="generative-ui-explained" class="level2">
<h2 class="anchored" data-anchor-id="generative-ui-explained">Generative UI Explained</h2>
<ul>
<li><strong>Question:</strong> What is generative UI, and how does it work?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Beyond Simple Chat:</strong> Generative UI enables LLMs to return more than text; they send UI components to create richer interfaces.</li>
<li><strong>Example:</strong> Instead of a list of weather data, an LLM might return a dynamic graph component with zoom and interaction capabilities.</li>
<li><strong>Vercel AI SDK Integration:</strong> LangChain now integrates with Vercel’s AI SDK for easier development of generative UI experiences.
<ul>
<li><strong><a href="https://sdk.vercel.ai/docs/introduction">Vercel AI SDK</a>:</strong> TypeScript toolkit designed to help developers build AI-powered applications with React, Next.js, Vue, Svelte, Node.js, and more.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="defining-agentic-in-the-context-of-llms" class="level2">
<h2 class="anchored" data-anchor-id="defining-agentic-in-the-context-of-llms">Defining “Agentic” in the Context of LLMs</h2>
<ul>
<li><strong>Question:</strong> What does “agentic” mean in the context of LLMs, and is it a significant distinction?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>LLM in Control:</strong> An agentic system is one where the LLM controls the application’s control flow and decision-making process.</li>
<li><strong>More Than Function Calling:</strong> While related to function calling, agentic systems go further by enabling LLMs to loop, adapt, and make dynamic decisions about the next steps.</li>
<li><strong>Implications for Development:</strong> This distinction introduces new challenges and considerations in UX design, observability, and testing.</li>
</ul></li>
</ul>
</section>
<section id="langchainlangsmith-features-for-agentic-workflows" class="level2">
<h2 class="anchored" data-anchor-id="langchainlangsmith-features-for-agentic-workflows">LangChain/LangSmith Features for Agentic Workflows</h2>
<ul>
<li><strong>Question:</strong> What features in LangChain/LangSmith specifically aid in developing and managing agentic workflows?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>LangGraph’s Strengths:</strong>
<ul>
<li><strong>Controllability:</strong> LangGraph’s low-level design provides a high degree of control, which is essential for managing complex agents.</li>
<li><strong>Persistence and Human-in-the-Loop:</strong> Built-in persistence and easy access to execution history enable checkpointing, resuming from specific states, and human intervention when needed.</li>
</ul></li>
<li><strong>LangSmith’s Role:</strong> While not agent-specific, LangSmith’s observability features are particularly valuable for debugging and understanding complex, agentic applications.</li>
</ul></li>
</ul>
</section>
<section id="multiple-llm-collaboration-in-practice" class="level2">
<h2 class="anchored" data-anchor-id="multiple-llm-collaboration-in-practice">Multiple LLM Collaboration in Practice</h2>
<ul>
<li><strong>Question:</strong> Is the idea of using multiple LLMs with different strengths in a single application realistic?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Planning and Execution:</strong> A common pattern involves a powerful LLM (e.g., GPT-4) for high-level planning and decision-making, while specialized or more cost-effective models (e.g., specialized code generation models) handle specific tasks.</li>
</ul></li>
</ul>
</section>
<section id="building-evaluation-sets-with-langsmith" class="level2">
<h2 class="anchored" data-anchor-id="building-evaluation-sets-with-langsmith">Building Evaluation Sets with LangSmith</h2>
<ul>
<li><strong>Question:</strong> What’s the most effective way to use LangSmith for creating evaluation sets?</li>
<li><strong>Answer:</strong>
<ol type="1">
<li><strong>Manual Seeding:</strong> Begin with a small set (5-10) of manually crafted examples.</li>
<li><strong>Production Feedback Loop:</strong> Integrate with production logs to capture real-user interactions and identify edge cases.</li>
<li><strong>Iterative Refinement:</strong>
<ul>
<li>Manually add challenging or interesting cases to the dataset.</li>
<li>Encourage user feedback and incorporate relevant examples.</li>
<li>Consider synthetic data generation to expand the dataset, but prioritize human review and labeling.</li>
</ul></li>
</ol></li>
<li><strong>Concepts:</strong> <a href="https://docs.smith.langchain.com/concepts/evaluation">Evaluation</a></li>
<li><strong>How-to guides:</strong> <a href="https://docs.smith.langchain.com/how_to_guides/evaluation">Evaluation</a></li>
<li><strong>Tutorial:</strong> <a href="https://docs.smith.langchain.com/tutorials/Developers/evaluation">Evaluate your LLM application</a></li>
</ul>
</section>
<section id="recommended-stack-for-full-stack-ml-engineers" class="level2">
<h2 class="anchored" data-anchor-id="recommended-stack-for-full-stack-ml-engineers">Recommended Stack for Full-Stack ML Engineers</h2>
<ul>
<li><strong>Question:</strong> What’s a good technology stack for Python-centric ML engineers who want to build and ship full-stack applications?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Python-First Options:</strong>
<ul>
<li><strong><a href="https://streamlit.io/">Streamlit</a>/<a href="https://www.gradio.app/">Gradio</a>:</strong> Excellent for rapid prototyping and simpler applications.</li>
<li><strong><a href="https://python.langchain.com/v0.2/docs/templates/">LangChain Templates</a>:</strong> Explore and adapt existing LangChain repositories with Python backends.</li>
<li><strong><a href="https://github.com/langchain-ai/langserve">LangServe</a>:</strong> Easily deploy LangChain apps.</li>
</ul></li>
<li><strong>Long-Term Goal:</strong> Aim to become proficient in 2-3 languages (Python, JavaScript/TypeScript, SQL) for greater flexibility and control over the entire application stack.</li>
<li><strong>Tips:</strong>
<ul>
<li>Leverage LLMs (like ChatGPT) to assist with JavaScript/TypeScript code generation and understanding.</li>
<li>Don’t shy away from forking and modifying existing repositories to learn and adapt.</li>
</ul></li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-005/</guid>
  <pubDate>Sat, 06 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Office Hours 4: Modal with Charles Frye</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-004/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="understanding-modal" class="level2">
<h2 class="anchored" data-anchor-id="understanding-modal">Understanding Modal</h2>
<ul>
<li><strong>ELI5:</strong> Modal allows users to run their Python code in the cloud effortlessly.</li>
<li><strong>In-depth:</strong> Modal is a remote procedure call (RPC) framework designed for Python, particularly excelling in data-intensive workloads like those involving large models or datasets.</li>
<li><strong>Advantages over Traditional Cloud Functions (AWS Lambda, Google Cloud Functions):</strong>
<ul>
<li><strong>Focus:</strong> Handles compute-heavy and data-intensive tasks more effectively.</li>
<li><strong>Simplicity:</strong> Removes the need for server management.</li>
<li><strong>Scalability:</strong> Scales resources dynamically based on demand.</li>
</ul></li>
<li><strong>Key Features:</strong>
<ul>
<li>Seamless local development with automatic code deployment to the cloud.</li>
<li>Simplified parallel processing and scaling.</li>
<li>Integration with popular frameworks like <a href="https://fastapi.tiangolo.com/">FastAPI</a>.</li>
</ul></li>
<li><strong>Founders’ Vision:</strong> Address common infrastructure challenges faced by data scientists and ML practitioners, emphasizing rapid development cycles and feedback loops.</li>
</ul>
</section>
<section id="startup-times-and-optimization" class="level2">
<h2 class="anchored" data-anchor-id="startup-times-and-optimization">Startup Times and Optimization</h2>
<ul>
<li><strong>Concern:</strong> Modal’s startup time compared to traditional server-based solutions.</li>
<li><strong>Modal’s Performance:</strong>
<ul>
<li>Container startup (Docker run): 1-2 seconds (50th percentile startup time).</li>
<li>Slowdown occurs when environment setup requires loading large elements into memory (e.g., language model weights).</li>
</ul></li>
<li><strong>Solutions for Faster Startup:</strong>
<ul>
<li><strong>Keep Warm:</strong> Leave applications running for minimal latency, especially crucial for GPU-bound tasks. (Trade-off: potentially higher cost for idle resources).
<ul>
<li><a href="https://modal.com/docs/guide/cold-start#keep-containers-warm-for-longer-with-container_idle_timeout">Keep containers warm for longer with <code>container_idle_timeout</code></a></li>
</ul></li>
<li><strong>CUDA Checkpointing:</strong> New feature under integration, expected to accelerate subsequent invocations.
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/NVIDIA/cuda-checkpoint">cuda-checkpoint</a></li>
</ul></li>
<li><strong>CPU Tasks:</strong> Easily sliced and diced, making them cost-effective in keep-warm mode due to minimal resource consumption during idle periods.</li>
<li><strong>Optimization Potential:</strong> The LLM fine-tuning repo hasn’t been fully optimized for boot times; improvements are possible.
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/modal-labs/llm-finetuning">llm-finetuning</a></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="local-development-and-modal-integration" class="level2">
<h2 class="anchored" data-anchor-id="local-development-and-modal-integration">Local Development and Modal Integration</h2>
<ul>
<li><strong>Challenge:</strong> Integrating a complex FastAPI application with local databases and debugging tools, then deploying it seamlessly to Modal.</li>
<li><strong>Thin Client Approach:</strong>
<ul>
<li>Modal examples typically employ a thin client architecture for simplicity in dependency management.</li>
<li>Local development within the thin client can be limited due to the absence of specific dependencies.</li>
</ul></li>
<li><strong>Solutions:</strong>
<ul>
<li><strong>Modal’s Remote Development Tools:</strong> Shell access, VS Code integration, and JupyterLab instances within Modal’s environment.
<ul>
<li><a href="https://modal.com/docs/reference/cli/launch#modal-launch"><code>modal launch</code></a>: Open a serverless app instance on Modal.
<ul>
<li><a href="https://modal.com/docs/reference/cli/launch#modal-launch-jupyter"><code>modal launch jupyter</code></a>: Start Jupyter Lab on Modal.</li>
<li><a href="https://modal.com/docs/reference/cli/launch#modal-launch-jupyter"><code>modal launch vscode</code></a>: Start Visual Studio Code on Modal.</li>
</ul></li>
<li><a href="https://modal.com/docs/reference/cli/shell#modal-shell"><code>modal shell</code></a>: Run an interactive shell inside a Modal image.</li>
</ul></li>
<li><strong>Thick Client Architecture:</strong>
<ul>
<li>Build a local environment mirroring the Modal environment.</li>
<li>Utilize tools like Dockerfiles, requirements.txt, poetry, or conda for consistent dependency management.</li>
</ul></li>
<li><strong>Resource:</strong> Explore the <code>awesome-modal</code> repository on GitHub for production-ready examples, some utilizing a thicker client approach.
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/modal-labs/awesome-modal">awesome-modal</a></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="iterative-development-workflow" class="level2">
<h2 class="anchored" data-anchor-id="iterative-development-workflow">Iterative Development Workflow</h2>
<ul>
<li><strong>Challenge:</strong> Fine-tuning models locally on a small scale with debugging and then scaling up on Modal with a full dataset and larger models.</li>
<li><strong>Recommendations:</strong>
<ul>
<li><strong><a href="https://modal.com/docs/reference/modal.Image"><code>modal.Image</code></a> Class:</strong>
<ul>
<li>Base class for container images to run functions in.</li>
<li>Utilize for environment definition, ensuring consistency between local and remote setups.</li>
<li><strong>Guide:</strong> <a href="https://modal.com/docs/guide/custom-container">Custom containers</a></li>
</ul></li>
<li><strong>Dependency Management:</strong> Leverage tools like <code>pip freeze</code> and poetry for tighter control over environments.</li>
<li><strong>Hardware Considerations:</strong> Be mindful of potential discrepancies between local and Modal GPUs.</li>
</ul></li>
</ul>
</section>
<section id="modal-for-cpu-intensive-workloads" class="level2">
<h2 class="anchored" data-anchor-id="modal-for-cpu-intensive-workloads">Modal for CPU-Intensive Workloads</h2>
<ul>
<li><strong>Question:</strong> Is Modal suitable for parallel CPU-bound tasks rather than just GPU acceleration?</li>
<li><strong>Answer:</strong> Yes, Modal is highly recommended for CPU-intensive and parallelizable tasks.</li>
<li><strong>Reasons:</strong>
<ul>
<li><strong>Cost-Effectiveness:</strong> CPUs are cheaper on Modal due to efficient time-slicing and readily available resources.</li>
<li><strong>Simplified Parallelization:</strong> Modal’s architecture and tools streamline the execution of parallel CPU workloads.</li>
</ul></li>
</ul>
</section>
<section id="cost-comparison-and-value-proposition" class="level2">
<h2 class="anchored" data-anchor-id="cost-comparison-and-value-proposition">Cost Comparison and Value Proposition</h2>
<ul>
<li><strong>Concern:</strong> Fine-tuning on Modal appears more expensive than platforms like Jarvis Labs.</li>
<li><strong>Modal’s Pricing:</strong>
<ul>
<li>Transparent, based on underlying cloud provider costs.</li>
<li>No hidden fees or inflated pricing strategies.</li>
</ul></li>
<li><strong>When Modal Wins:</strong>
<ul>
<li><strong>High Operational Overhead:</strong> Modal excels when the effort of managing servers (spinning up, down, utilization tracking) outweighs the raw compute cost.</li>
<li><strong>Unpredictable Workloads:</strong> Serverless nature shines when demand fluctuates, and predicting utilization is challenging.</li>
<li><strong>Scalability Needs:</strong> Modal simplifies scaling to thousands of GPUs, surpassing the limitations of individual users or smaller organizations.</li>
<li><strong>GPU Accessibility:</strong> Modal offers readily available GPUs, circumventing the challenges of procurement and allocation.</li>
<li><strong>Developer Experience:</strong> Streamlined workflow and reduced operational burden can justify a potential price premium for some users.</li>
</ul></li>
</ul>
</section>
<section id="understanding-modals-cost-structure" class="level2">
<h2 class="anchored" data-anchor-id="understanding-modals-cost-structure">Understanding Modal’s Cost Structure</h2>
<ul>
<li><strong>Question:</strong> How can a keep-warm FastAPI app on Modal cost only 30 cents per month when CPU core pricing suggests a much higher cost?</li>
<li><strong>Explanation:</strong>
<ul>
<li><strong>Time-Slicing:</strong> CPUs are shared efficiently, and Modal only charges for actual usage, not idle time.</li>
<li><strong>Low Utilization:</strong> Web apps typically have low average CPU utilization, further reducing costs.</li>
<li><strong>RAM-Based Pricing:</strong> During idle periods, charges are primarily determined by RAM usage, which is often minimal for lightweight apps.</li>
</ul></li>
</ul>
</section>
<section id="streaming-output-from-llms" class="level2">
<h2 class="anchored" data-anchor-id="streaming-output-from-llms">Streaming Output from LLMs</h2>
<ul>
<li><strong>Question:</strong> Availability of examples showcasing streamed output from LLMs in FastAPI apps.</li>
<li><strong>Answer:</strong>
<ul>
<li>Examples for streaming and FastAPI integration are available in the documentation:
<ul>
<li><a href="https://modal.com/docs/examples/vllm_mixtral">Fast inference with vLLM (Mixtral 8x7B)</a></li>
<li><a href="https://modal.com/docs/examples/llm-voice-chat">QuiLLMan: Voice Chat with LLMs</a></li>
</ul></li>
</ul></li>
<li><strong>Modal’s Async Support:</strong> Modal simplifies asynchronous programming, making streaming implementations easier.
<ul>
<li><strong>Guide:</strong> <a href="https://modal.com/docs/guide/async">Asynchronous API usage</a></li>
</ul></li>
</ul>
</section>
<section id="code-portability-and-modal-dependency" class="level2">
<h2 class="anchored" data-anchor-id="code-portability-and-modal-dependency">Code Portability and Modal Dependency</h2>
<ul>
<li><strong>Concern:</strong> Modal’s decorators might hinder code portability to other environments.</li>
<li><strong>Response:</strong>
<ul>
<li>While Modal promotes a specific architecture for performance and cost optimization, code can be written to minimize tight coupling.</li>
<li>Decorators can be removed or bypassed if needed to port code to different environments.</li>
<li>Achieving portability often involves trade-offs in performance and cost-effectiveness.</li>
</ul></li>
</ul>
</section>
<section id="data-privacy" class="level2">
<h2 class="anchored" data-anchor-id="data-privacy">Data Privacy</h2>
<ul>
<li><strong>Question:</strong> Modal’s policy on data privacy and potential use of user data for model training.</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Commitment to Security:</strong> Modal is <a href="https://modal.com/blog/soc2">SOC 2 compliant</a> and working towards SOC 2 Type 2 certification, demonstrating a high standard of data security.</li>
<li><strong>User Data Protection:</strong> Modal treats user application data as confidential. Permission is sought before reviewing data, even for support purposes.</li>
<li><strong>No User Data Training:</strong> Modal, as an infrastructure company, doesn’t use customer data for training internal models.</li>
</ul></li>
</ul>
</section>
<section id="running-databases-on-modal" class="level2">
<h2 class="anchored" data-anchor-id="running-databases-on-modal">Running Databases on Modal</h2>
<ul>
<li><strong>Question:</strong> Feasibility of running a key-value store (e.g., <a href="https://github.com/google/leveldb">LevelDB</a>) on Modal for a development web endpoint.</li>
<li><strong>Recommendations:</strong>
<ul>
<li><strong>Modal’s Built-in Solutions:</strong>
<ul>
<li><a href="https://modal.com/docs/reference/cli/dict"><code>modal.Dict</code></a>: Offers a persistent, distributed key-value store accessible to all Modal functions.</li>
<li><a href="https://modal.com/docs/reference/cli/queue"><code>modal.Queue</code></a>: Provides a distributed queue system similar to <a href="https://redis.io/">Redis</a>.</li>
</ul></li>
<li><strong>Alternative Approach for Analytic Databases:</strong>
<ul>
<li>Host databases externally (not ideal on Modal).</li>
<li>Mount cloud storage (e.g., S3) containing data in formats like Parquet or Arrow to Modal functions.</li>
<li>Utilize libraries like <a href="https://duckdb.org/">DuckDB</a> for efficient querying within the Modal environment.</li>
<li><strong>Example:</strong> <a href="https://modal.com/docs/examples/s3_bucket_mount#analyze-nyc-yellow-taxi-data-with-duckdb-on-parquet-files-from-s3">Analyze NYC yellow taxi data with DuckDB on Parquet files from S3</a></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="balancing-cost-and-uptime-for-gpu-inference" class="level2">
<h2 class="anchored" data-anchor-id="balancing-cost-and-uptime-for-gpu-inference">Balancing Cost and Uptime for GPU Inference</h2>
<ul>
<li><strong>Question:</strong> Finding the sweet spot between cost and uptime for GPU inference when needing varying levels of availability.</li>
<li><strong>Rule of Thumb:</strong>
<ul>
<li>Modal tends to be more cost-effective when utilization is 60% or lower.</li>
<li>Consider factors like acceptable latency and workload characteristics (batch jobs vs.&nbsp;real-time requests).</li>
</ul></li>
</ul>
</section>
<section id="local-vs.-cloud-workload-distribution" class="level2">
<h2 class="anchored" data-anchor-id="local-vs.-cloud-workload-distribution">Local vs.&nbsp;Cloud Workload Distribution</h2>
<ul>
<li><strong>Question:</strong> Deciding when to utilize a local GPU (e.g., RTX 4090) versus offloading to Modal, considering cost and time efficiency.</li>
<li><strong>Workload Breakdown:</strong>
<ul>
<li><strong>Inference:</strong> Local GPUs are well-suited due to typically small batch sizes, making VRAM less of a constraint.</li>
<li><strong>Evaluations:</strong> Larger eval sets might benefit from cloud GPUs for faster throughput, especially when running multiple evaluations concurrently.</li>
<li><strong>Fine-tuning:</strong> Often memory-intensive due to gradients and optimizer states. Cloud GPUs provide ample VRAM and simplify the use of techniques like sharding or larger batch sizes.</li>
</ul></li>
<li><strong>Don’t undervalue your time:</strong> Spending a little more on faster cloud compute can save a significant amount of time versus trying to run everything locally on a single GPU.</li>
</ul>
</section>
<section id="quick-qa" class="level2">
<h2 class="anchored" data-anchor-id="quick-qa">Quick Q&amp;A</h2>
<ul>
<li><strong>Autoscaling:</strong> Modal supports autoscaling with configurable parameters.
<ul>
<li><strong>Explanation:</strong> <a href="https://modal.com/docs/guide/concurrent-inputs#how-does-autoscaling-work-on-modal">How does autoscaling work on Modal?</a></li>
<li><strong>Auto-scaling LLM inference endpoints:</strong> <a href="https://modal.com/docs/examples/text_generation_inference">Hosting any LLaMA 3 model with Text Generation Inference (TGI)</a></li>
</ul></li>
<li><strong>Docker Image Access:</strong> Downloading built Docker images is not currently supported. Users can build and provide their own images.</li>
<li><strong>Inference Serving:</strong>
<ul>
<li><a href="https://github.com/vllm-project/vllm">vLLM</a> for its ease of use and rapid development</li>
<li><a href="https://github.com/NVIDIA/TensorRT-LLM">TensorRT-LLM</a> is a potentially faster but more involved alternative.</li>
</ul></li>
<li><strong>Demo Preparation:</strong> “Hello World” and “TRT LLM” examples are good starting points.
<ul>
<li><strong>Example:</strong> <a href="https://modal.com/docs/examples/hello_world">Hello, world!</a></li>
<li><strong>Example:</strong> <a href="https://modal.com/docs/examples/trtllm_llama">Serverless TensorRT-LLM (LLaMA 3 8B)</a></li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-004/</guid>
  <pubDate>Sat, 06 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 4: Inspect - An OSS Framework for LLM Evals</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-004/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Inspect AI: A Framework for Evaluating LLMs</li>
<li>Hello World Example</li>
<li>Core Concepts</li>
<li>Honeycomb Dataset Example</li>
<li>Composition</li>
<li>Tool Use</li>
<li>Agents and Tools</li>
<li>Logging</li>
<li>Models</li>
<li>Workflow</li>
<li>Q&amp;A Session</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Presentation Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Presentation Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/jjallaire/inspect-llm-workshop">inspect-llm-workshop</a></li>
<li><strong>Slides:</strong> <a href="https://raw.githubusercontent.com/jjallaire/inspect-llm-workshop/main/slides/intro-to-inspect.pdf">Intro to Inspect</a></li>
</ul>
</div>
</div>
<section id="inspect-ai-a-framework-for-evaluating-llms" class="level2">
<h2 class="anchored" data-anchor-id="inspect-ai-a-framework-for-evaluating-llms">Inspect AI: A Framework for Evaluating LLMs</h2>
<ul>
<li>Inspect AI is a Python package for creating LLM evaluations developed through a collaboration between J.J. Allaire and the <a href="https://www.aisi.gov.uk/">UK AI Safety Institute</a>.</li>
<li>Designed to address the limitations of existing evaluation tools for developing more complex evals.</li>
<li>Focuses on providing a great experience for developing evals that can be reproducibly run at scale.</li>
<li><strong>Github Repository:</strong> <a href="https://github.com/UKGovernmentBEIS/inspect_ai">UKGovernmentBEIS/inspect_ai</a></li>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai">https://ukgovernmentbeis.github.io/inspect_ai</a></li>
<li><strong>Installation:</strong>
<ul>
<li><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb1-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install inspect-ai</span></code></pre></div></li>
</ul></li>
<li><strong>VS Code Extension:</strong>
<ul>
<li><strong>Marketplace:</strong> <a href="https://marketplace.visualstudio.com/items?itemName=ukaisi.inspect-ai">Inspect AI</a></li>
<li><strong>Source Code:</strong> <a href="https://github.com/UKGovernmentBEIS/inspect_ai/tree/main/tools/vscode">inspect-vscode</a></li>
</ul></li>
</ul>
</section>
<section id="hello-world-example" class="level2">
<h2 class="anchored" data-anchor-id="hello-world-example">Hello World Example</h2>
<ul>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/#sec-hello-inspect">Hello, Inspect</a></li>
</ul>
<div class="sourceCode" id="annotated-cell-1" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Task, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>, task</span>
<span id="annotated-cell-1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.dataset <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> example_dataset</span>
<span id="annotated-cell-1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.scorer <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> model_graded_fact</span>
<span id="annotated-cell-1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.solver <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> (               </span>
<span id="annotated-cell-1-5">  chain_of_thought, generate, self_critique   </span>
<span id="annotated-cell-1-6">)                                             </span>
<span id="annotated-cell-1-7"></span>
<span id="annotated-cell-1-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@task</span></span>
<span id="annotated-cell-1-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> theory_of_mind():</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-1-10" class="code-annotation-target">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Task(</span>
<span id="annotated-cell-1-11">        dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>example_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"theory_of_mind"</span>), </span>
<span id="annotated-cell-1-12">        plan<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-1-13" class="code-annotation-target">          chain_of_thought(),</span>
<span id="annotated-cell-1-14">          generate(),</span>
<span id="annotated-cell-1-15">          self_critique()</span>
<span id="annotated-cell-1-16">        ],</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-1-17" class="code-annotation-target">        scorer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_graded_fact()</span>
<span id="annotated-cell-1-18">    )</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-1" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="10" data-code-annotation="1">The <code>Task</code> object brings together the dataset, solvers, and scorer, and is then evaluated using a model.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="13,14,15" data-code-annotation="2">In this example we are chaining together three standard solver components. It’s also possible to create a more complex custom solver that manages state and interactions internally.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="17" data-code-annotation="3">Since the output is likely to have pretty involved language, we use a model for scoring.</span>
</dd>
</dl>
</section>
<section id="core-concepts" class="level2">
<h2 class="anchored" data-anchor-id="core-concepts">Core Concepts</h2>
<ul>
<li><strong>Dataset:</strong> List of inputs for the LLM
<ul>
<li>Usually includes targets (e.g., correct answers)</li>
</ul></li>
<li><strong>Solvers:</strong> Pipelines that execute the evaluation
<ul>
<li>Includes functions that transform the dataset inputs, call the model, and act on the model output</li>
<li>Can include things like prompt engineering and multi-turn dialogue</li>
<li>Can be composed together as layers, or can be a single layer with higher internal complexity</li>
</ul></li>
<li><strong>Scores:</strong> Evaluates the output of solvers
<ul>
<li>Ranges from simple text comparisons to model-graded assessments using custom rubrics.</li>
</ul></li>
</ul>
</section>
<section id="honeycomb-dataset-example" class="level2">
<h2 class="anchored" data-anchor-id="honeycomb-dataset-example">Honeycomb Dataset Example</h2>
<ul>
<li><strong>Jupyter Notebook:</strong> <a href="https://github.com/jjallaire/inspect-llm-workshop/blob/main/honeycomb/queries.ipynb">honeycomb/queries.ipynb</a></li>
<li><strong>Dataset:</strong> <a href="https://github.com/jjallaire/inspect-llm-workshop/blob/main/honeycomb/queries.csv">queries.csv</a>
<ul>
<li>~2,300 example queries (along with per-query column schemas generated offline via RAG)</li>
</ul></li>
<li><strong>Scoring Methods:</strong>
<ul>
<li><strong>validate:</strong> score using the validity checker: <a href="https://github.com/jjallaire/inspect-llm-workshop/blob/main/honeycomb/utils.py">utils.py</a></li>
<li><strong>critique:</strong> score using the critique prompt: <a href="https://github.com/jjallaire/inspect-llm-workshop/blob/main/honeycomb/critique.txt">critique.txt</a></li>
</ul></li>
<li><strong>Process:</strong>
<ol type="1">
<li>Load the dataset.</li>
<li>Define a pipeline that includes prompt engineering, model calling, and evaluation.</li>
<li>Apply a scoring function.</li>
</ol></li>
</ul>
<section id="dataset" class="level3">
<h3 class="anchored" data-anchor-id="dataset">Dataset</h3>
<ul>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/datasets.html">Datasets</a></li>
<li>Inspect uses a standard schema for Datasets
<ul>
<li>We map the raw data into that schema when reading it</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>“columns” are saved as metadata so we can use them for prompt engineering</li>
</ul>
</div>
</div>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.dataset <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> csv_dataset, FieldSpec</span>
<span id="cb2-2"></span>
<span id="cb2-3">dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> csv_dataset(</span>
<span id="cb2-4">    csv_file<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"queries.csv"</span>,</span>
<span id="cb2-5">    sample_fields<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>FieldSpec(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user_input"</span>, metadata<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"columns"</span>]),</span>
<span id="cb2-6">    shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb2-7">)</span></code></pre></div>
</section>
<section id="solver" class="level3">
<h3 class="anchored" data-anchor-id="solver">Solver</h3>
<ul>
<li><p><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/solvers.html">Solver</a></p></li>
<li><p>Functions that manipulate the <a href="https://ukgovernmentbeis.github.io/inspect_ai/solvers.html#task-states"><code>TaskState</code></a> (message history and model output) to perform actions like:</p>
<ul>
<li>Calling the model to generate text.</li>
<li>Engineering prompts.</li>
<li>Applying critique mechanisms.</li>
</ul></li>
<li><p><a href="https://ukgovernmentbeis.github.io/inspect_ai/solvers.html#built-in-solvers"><strong>Built-In Solvers</strong></a><strong>:</strong></p>
<ul>
<li><code>generate()</code>: Calls the model, appends the assistant message, and updates the model output</li>
<li><code>chain_of_thought()</code>: Basic chain-of-thought implementation.</li>
<li><code>prompt_template()</code>: Modifies the existing prompt by passing it through a template</li>
<li><code>multiple_choice()</code>: Handles multiple-choice questions, including shuffling options, calling the model, and unshuffling to determine the chosen answer.</li>
<li><code>self_critique()</code>
<ul>
<li>Performs self-critique by:
<ol type="1">
<li>Running a critique model on the initial output.</li>
<li>Appending the critique to the message history.</li>
<li>Calling the model again to generate a revised answer.</li>
</ol></li>
</ul></li>
</ul></li>
</ul>
<section id="solver-prompt_with_schema" class="level4">
<h4 class="anchored" data-anchor-id="solver-prompt_with_schema">Solver: <code>prompt_with_schema()</code></h4>
<ul>
<li>Simple prompt template that substitutes the user query and the RAG-generated column schema.</li>
</ul>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.solver <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> solver</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.util <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> resource</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@solver</span></span>
<span id="cb3-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> prompt_with_schema():</span>
<span id="cb3-6"></span>
<span id="cb3-7">    prompt_template <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resource(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prompt.txt"</span>)</span>
<span id="cb3-8"></span>
<span id="cb3-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">async</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> solve(state, generate):</span>
<span id="cb3-10">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># build the prompt</span></span>
<span id="cb3-11">        state.user_prompt.text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prompt_template.replace(</span>
<span id="cb3-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">prompt</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, state.user_prompt.text</span>
<span id="cb3-13">        ).replace(</span>
<span id="cb3-14">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">columns</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, state.metadata[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"columns"</span>]</span>
<span id="cb3-15">        )</span>
<span id="cb3-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> state</span>
<span id="cb3-17"></span>
<span id="cb3-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> solve</span></code></pre></div>
</section>
</section>
<section id="scorer" class="level3">
<h3 class="anchored" data-anchor-id="scorer">Scorer</h3>
<ul>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/scorers.html">Scorer</a>
<ul>
<li>Evaluates whether solvers were successful in finding the right <code>output</code> for the <code>target</code> defined in the dataset, and in what measure</li>
<li>Pluggable (i.e.&nbsp;provided from other packages)</li>
</ul></li>
<li><strong><a href="https://ukgovernmentbeis.github.io/inspect_ai/scorers.html#built-in-scorers">Built-In Scorers</a>:</strong>
<ul>
<li>Pattern matching</li>
<li>Template matching</li>
<li>Model grading</li>
<li>Human scoring</li>
</ul></li>
<li><strong>Example: Math Benchmark with Expression Equivalence</strong>
<ul>
<li><strong>Source Code:</strong> <a href="https://github.com/jjallaire/inspect-llm-workshop/blob/main/benchmarks/mathematics.py">benchmarks/mathematics.py</a></li>
<li>Uses a custom scorer <code>expression_equivalance</code> to evaluate mathematical expressions for logical equivalence, accounting for variations in formatting or simplification.</li>
<li><strong>Scorer: <a href="https://github.com/jjallaire/inspect-llm-workshop/blob/86d00ca6d79b4754266ba36c10be6d5a108a1695/benchmarks/mathematics.py#L56C5-L56C27"><code>expression_equivalance()</code></a></strong>
<ul>
<li>Extracts the model’s answer using regular expressions.</li>
<li>Employs a few-shot prompting technique to train a model for assessing the equivalence of mathematical expressions.</li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@scorer</span>(metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[accuracy(), bootstrap_std()])</span>
<span id="cb4-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> expression_equivalance():</span>
<span id="cb4-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">async</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> score(state: TaskState, target: Target):</span>
<span id="cb4-4">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># extract answer</span></span>
<span id="cb4-5">        match <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> re.search(AnswerPattern.LINE, state.output.completion)</span>
<span id="cb4-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> match:</span>
<span id="cb4-7">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ask the model to judge equivalance</span></span>
<span id="cb4-8">            answer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> match.group(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-9">            prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> EQUIVALANCE_TEMPLATE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> (</span>
<span id="cb4-10">                {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"expression1"</span>: target.text, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"expression2"</span>: answer}</span>
<span id="cb4-11">            )</span>
<span id="cb4-12">            result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">await</span> get_model().generate(prompt)</span>
<span id="cb4-13"></span>
<span id="cb4-14">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># return the score</span></span>
<span id="cb4-15">            correct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> result.completion.lower() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"yes"</span></span>
<span id="cb4-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Score(</span>
<span id="cb4-17">                value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>CORRECT <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> correct <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> INCORRECT,</span>
<span id="cb4-18">                answer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>answer,</span>
<span id="cb4-19">                explanation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>state.output.completion,</span>
<span id="cb4-20">            )</span>
<span id="cb4-21">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb4-22">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Score(</span>
<span id="cb4-23">                value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>INCORRECT,</span>
<span id="cb4-24">                explanation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Answer not found in model output: "</span></span>
<span id="cb4-25">                <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>state<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>output<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>completion<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb4-26">            )</span>
<span id="cb4-27"></span>
<span id="cb4-28">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> score</span></code></pre></div>
</div>
</div>
</div></li>
</ul></li>
</ul></li>
</ul>
<section id="scorer-validate_scorer" class="level4">
<h4 class="anchored" data-anchor-id="scorer-validate_scorer">Scorer: <code>validate_scorer()</code></h4>
<ul>
<li>Extracts and cleans JSON output from the model.</li>
<li>Calls the <code>is_valid()</code> function with the column schema to determine if a valid query was generated.</li>
</ul>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.scorer <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy, scorer, Score, CORRECT, INCORRECT</span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> is_valid, json_completion</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@scorer</span>(metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[accuracy()])</span>
<span id="cb5-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> validate_scorer():</span>
<span id="cb5-6"></span>
<span id="cb5-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">async</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> score(state, target):</span>
<span id="cb5-8">       </span>
<span id="cb5-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># check for valid query</span></span>
<span id="cb5-10">        query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> json_completion(state.output.completion)</span>
<span id="cb5-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> is_valid(query, state.metadata[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"columns"</span>]):</span>
<span id="cb5-12">            value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>CORRECT</span>
<span id="cb5-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>: </span>
<span id="cb5-14">            value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>INCORRECT</span>
<span id="cb5-15">       </span>
<span id="cb5-16">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># return score w/ query that was extracted</span></span>
<span id="cb5-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Score(value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>value, answer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>query)</span>
<span id="cb5-18"></span>
<span id="cb5-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> score</span></code></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>The <a href="https://github.com/jjallaire/inspect-llm-workshop/blob/86d00ca6d79b4754266ba36c10be6d5a108a1695/honeycomb/utils.py#L7"><code>json_completion()</code></a> function takes care of some details around extracting JSON from a model completion (e.g.&nbsp;removing sorrounding backtick code block emitted by some models)</li>
</ul>
</div>
</div>
</section>
</section>
<section id="validate-task" class="level3">
<h3 class="anchored" data-anchor-id="validate-task">Validate Task</h3>
<ul>
<li><a href="https://github.com/UKGovernmentBEIS/inspect_ai/blob/53fe15a44d83400ad2847cb2f917ac282cba126d/src/inspect_ai/_eval/task/task.py#L17"><code>Task</code></a>:
<ul>
<li>The basis for defining and running evaluations</li>
<li>Parameterized with a dataset, a scorer, and metrics.</li>
<li>May optionally provide a default plan for execution.</li>
</ul></li>
</ul>
<section id="honeycomb-eval-validate" class="level4">
<h4 class="anchored" data-anchor-id="honeycomb-eval-validate">Honeycomb Eval: <code>validate()</code></h4>
<ul>
<li>Combines the dataset, solver, and scorer defined above into a <code>Task</code>.</li>
<li>Uses a predefined system message and prompt template.</li>
</ul>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>, task, Task</span>
<span id="cb6-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.solver <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> system_message, generate</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@task</span></span>
<span id="cb6-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> validate():</span>
<span id="cb6-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Task(</span>
<span id="cb6-7">        dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset,</span>
<span id="cb6-8">        plan<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb6-9">            system_message(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Honeycomb AI suggests queries based on user input."</span>),</span>
<span id="cb6-10">            prompt_with_schema(),</span>
<span id="cb6-11">            generate()</span>
<span id="cb6-12">        ],</span>
<span id="cb6-13">        scorer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>validate_scorer()</span>
<span id="cb6-14">    )</span></code></pre></div>
<ul>
<li>Run the <code>Task</code> using Inspect’s <code>eval()</code> function (limiting to 100 samples):</li>
</ul>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'__main__'</span>:</span>
<span id="cb7-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>(validate, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai/gpt-4-turbo"</span>, limit<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-004/images/validate-task-1.png" class="img-fluid figure-img"></p>
<figcaption>validate-task-1</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>The <code>__name__ == '__main__'</code> conditional indicates that we only want to run this cell in interactive contexts.
<ul>
<li>Allows us to also use the notebook as a module callable from <code>inspect eval</code>:</li>
<li><div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">$</span> inspect eval queries.ipynb@validate</span></code></pre></div></li>
</ul></li>
</ul>
</div>
</div>
</section>
</section>
<section id="eval-view" class="level3">
<h3 class="anchored" data-anchor-id="eval-view">Eval View</h3>
<ul>
<li><div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb9-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">inspect</span> view</span></code></pre></div>
<ul>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<pre class="text"><code>$ inspect view
Inspect view running at http://localhost:7575/</code></pre>
</div>
</div></li>
</ul></li>
<li><p>Provides an overview of evaluation results.</p></li>
<li><p>Allows drilling down into individual samples to examine message history, inputs, and model outputs for debugging.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-004/images/inspect-view-validate-task.png" class="img-fluid figure-img"></p>
<figcaption>inspect-view-validate-task</figcaption>
</figure>
</div>
</section>
<section id="critique-task" class="level3">
<h3 class="anchored" data-anchor-id="critique-task">Critique Task</h3>
<ul>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/models.html">Models</a></li>
</ul>
<section id="scorer-critique_scorer" class="level4">
<h4 class="anchored" data-anchor-id="scorer-critique_scorer">Scorer: <code>critique_scorer()</code></h4>
<ul>
<li>Allows using different models (e.g., GPT-4 Turbo) to critique the generated queries.</li>
<li>Builds a critique prompt using a predefined template and the model’s output to have the critique model indicate whether the generated query is “good” or “bad”.</li>
<li>Returns a score based on the critique model’s assessment.</li>
</ul>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_model</span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@scorer</span>(metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[accuracy()])</span>
<span id="cb11-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> critique_scorer(model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"anthropic/claude-3-5-sonnet-20240620"</span>):</span>
<span id="cb11-6"></span>
<span id="cb11-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">async</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> score(state, target):</span>
<span id="cb11-8">       </span>
<span id="cb11-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># build the critic prompt</span></span>
<span id="cb11-10">        query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state.output.completion.strip()</span>
<span id="cb11-11">        critic_prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resource(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"critique.txt"</span>).replace(</span>
<span id="cb11-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">prompt</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, state.user_prompt.text</span>
<span id="cb11-13">        ).replace(</span>
<span id="cb11-14">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">columns</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, state.metadata[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"columns"</span>]</span>
<span id="cb11-15">        ).replace(</span>
<span id="cb11-16">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">query</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, query</span>
<span id="cb11-17">        )</span>
<span id="cb11-18">       </span>
<span id="cb11-19">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># run the critique</span></span>
<span id="cb11-20">        result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">await</span> get_model(model).generate(critic_prompt)</span>
<span id="cb11-21">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">try</span>:</span>
<span id="cb11-22">            parsed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> json.loads(json_completion(result.completion))</span>
<span id="cb11-23">            value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CORRECT <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> parsed[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"outcome"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"good"</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> INCORRECT</span>
<span id="cb11-24">            explanation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parsed[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"critique"</span>]</span>
<span id="cb11-25">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">except</span> (json.JSONDecodeError, <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">KeyError</span>):</span>
<span id="cb11-26">            value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> INCORRECT</span>
<span id="cb11-27">            explanation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"JSON parsing error:</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>completion<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb11-28">        </span>
<span id="cb11-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># return value and explanation (critique text)</span></span>
<span id="cb11-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Score(value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>value, explanation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>explanation)</span>
<span id="cb11-31"></span>
<span id="cb11-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> score</span></code></pre></div>
</section>
<section id="honeycomb-eval-critique" class="level4">
<h4 class="anchored" data-anchor-id="honeycomb-eval-critique">Honeycomb Eval: <code>critique()</code></h4>
<ul>
<li>Utilizes the same dataset and plan as <code>validate()</code> but employs a critique model for scoring.</li>
</ul>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@task</span></span>
<span id="cb12-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> critique():</span>
<span id="cb12-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Task(</span>
<span id="cb12-4">        dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset,</span>
<span id="cb12-5">        plan<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb12-6">            system_message(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Honeycomb AI suggests queries based on user input."</span>),</span>
<span id="cb12-7">            prompt_with_schema(),</span>
<span id="cb12-8">            generate()</span>
<span id="cb12-9">        ],</span>
<span id="cb12-10">        scorer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>critique_scorer()</span>
<span id="cb12-11">    )</span></code></pre></div>
<ul>
<li>Run the task using <code>eval()</code> (limiting to 25 samples):</li>
</ul>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'__main__'</span>:</span>
<span id="cb13-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>(critique, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai/gpt-4-turbo"</span>, limit<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-004/images/critique-task-1.png" class="img-fluid figure-img"></p>
<figcaption>critique-task-1</figcaption>
</figure>
</div>
</section>
</section>
<section id="critique-eval-view" class="level3">
<h3 class="anchored" data-anchor-id="critique-eval-view">Critique Eval View</h3>
<ul>
<li><div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb14-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">inspect</span> view</span></code></pre></div></li>
<li>Displays critique-based evaluation results.</li>
<li>Provides insights into the critique model’s explanations for incorrect answers, aiding in prompt or model improvement.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-004/images/inspect-view-critique-task.png" class="img-fluid figure-img"></p>
<figcaption>inspect-view-critique-task</figcaption>
</figure>
</div>
</section>
</section>
<section id="composition" class="level2">
<h2 class="anchored" data-anchor-id="composition">Composition</h2>
<ul>
<li>Inspect AI encourages composing evaluations by combining solvers and scorers from different sources.</li>
<li>Custom solvers and scorers can be made available in a Python package to re-use across many evals.</li>
</ul>
<section id="example-jailbreaking-with-sheppard" class="level3">
<h3 class="anchored" data-anchor-id="example-jailbreaking-with-sheppard">Example: Jailbreaking with <code>sheppard</code></h3>
<ul>
<li><p><code>sheppard</code>: An internal package that integrates jailbreak solvers to elicit responses from models they might otherwise refuse to provide.</p></li>
<li><table class="caption-top table">
<thead>
<tr class="header">
<th>Solver</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>encode()</code></td>
<td><a href="https://arxiv.org/abs/2406.08754v1">Message obfuscation jailbreak</a></td>
</tr>
<tr class="even">
<td><code>pap_jailbreak()</code></td>
<td><a href="https://arxiv.org/abs/2401.06373">Persuasion Adversarial Prompt (PAP)</a></td>
</tr>
<tr class="odd">
<td><code>payload_splitting()</code></td>
<td><a href="https://arxiv.org/abs/2302.05733">Payload splitting jailbreak</a></td>
</tr>
<tr class="even">
<td><code>cr_jailbreak()</code></td>
<td>Content reinforcement</td>
</tr>
</tbody>
</table></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example: Using sheppard to provide jailbreaks for a security eval:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Using sheppard to provide jailbreaks for a security eval:
</div>
</div>
<div class="callout-body-container callout-body">
<pre class="text"><code></code></pre>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Task, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>, task</span>
<span id="cb16-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.scorer <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> model_graded_fact</span>
<span id="cb16-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect_ai.solver <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> generate, system_message</span>
<span id="cb16-4"></span>
<span id="cb16-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sheppard <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pap_jailbreak</span>
<span id="cb16-6"></span>
<span id="cb16-7"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@task</span></span>
<span id="cb16-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> security_guide():</span>
<span id="cb16-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Task(</span>
<span id="cb16-10">        dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>example_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"security_guide"</span>),</span>
<span id="cb16-11">        plan<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb16-12">          system_message(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system.txt"</span>), </span>
<span id="cb16-13">          pap_jailbreak(),</span>
<span id="cb16-14">          generate()</span>
<span id="cb16-15">        ],</span>
<span id="cb16-16">        scorer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_graded_fact(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai/gpt-4"</span>),</span>
<span id="cb16-17">    )</span></code></pre></div>
</div>
</div></li>
</ul>
</section>
</section>
<section id="tool-use" class="level2">
<h2 class="anchored" data-anchor-id="tool-use">Tool Use</h2>
<ul>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/tools.html">Tools</a>
<ul>
<li>Python functions that can be made accessible to the model during evaluation.</li>
<li>Allow for more complex interactions, like web search or database lookups.</li>
<li><div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">  <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> TaskState:</span>
<span id="cb17-2">      messages: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[ChatMessage]</span>
<span id="cb17-3">      tools: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[ToolDef]</span>
<span id="cb17-4">      tool_choice: ToolChoice</span>
<span id="cb17-5">      output: ModelOutput</span>
<span id="cb17-6">      ...</span></code></pre></div></li>
</ul></li>
</ul>
<section id="example-biology-qa-with-web-search" class="level3">
<h3 class="anchored" data-anchor-id="example-biology-qa-with-web-search">Example: Biology QA with Web Search</h3>
<ul>
<li>Provides a web search tool to the model, enabling it to answer obscure biology questions.</li>
<li><div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Task(</span>
<span id="cb18-2">      dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>example_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"biology_qa"</span>),</span>
<span id="cb18-3">      plan<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb18-4">          use_tools(web_search()), </span>
<span id="cb18-5">          generate()</span>
<span id="cb18-6">      ],</span>
<span id="cb18-7">      scorer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_graded_qa(template<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>GRADER_TEMPLATE),</span>
<span id="cb18-8">  )</span></code></pre></div></li>
</ul>
</section>
</section>
<section id="agents-and-tools" class="level2">
<h2 class="anchored" data-anchor-id="agents-and-tools">Agents and Tools</h2>
<ul>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/agents.html">Agents</a>
<ul>
<li>Solvers that use tools to perform tasks.</li>
<li>Can use bespoke agent logic inside a solver (swapping various tools in and out)</li>
<li>Can integrate existing agent libraries like Langchain as solvers.</li>
</ul></li>
</ul>
<section id="agent-capture-the-flag" class="level3">
<h3 class="anchored" data-anchor-id="agent-capture-the-flag">Agent: Capture the Flag</h3>
<ul>
<li>Example of a custom agent designed for cybersecurity evaluations, where the model interacts with tools to solve capture-the-flag challenges within a Docker environment.</li>
<li><div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">  Plan(</span>
<span id="cb19-2">      steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb19-3">          init_challenge(),</span>
<span id="cb19-4">          use_tools([</span>
<span id="cb19-5">              command_exec(), create_file(),</span>
<span id="cb19-6">              decompile(), disassemble(),</span>
<span id="cb19-7">              check_flag(),</span>
<span id="cb19-8">          ]),</span>
<span id="cb19-9">          system_message(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prompts/system.txt"</span>),</span>
<span id="cb19-10">          initial_user_message(),</span>
<span id="cb19-11">          generate(),</span>
<span id="cb19-12">          check_for_flag_or_continue()</span>
<span id="cb19-13">      ],</span>
<span id="cb19-14">      cleanup<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>exit_challenge()</span>
<span id="cb19-15">  )</span></code></pre></div></li>
</ul>
</section>
<section id="agent-langchain" class="level3">
<h3 class="anchored" data-anchor-id="agent-langchain">Agent: LangChain</h3>
<ul>
<li><strong>Project Folder:</strong> <a href="https://github.com/jjallaire/inspect-llm-workshop/tree/main/langchain">inspect-llm-workshop/langchain</a>
<ul>
<li>Uses <a href="https://tavily.com/">tavily</a>, a search engine optimized for LLMs and RAG</li>
</ul></li>
<li>Demonstrates integrating a Langchain agent into Inspect AI using a higher-order function.</li>
<li>Allows leveraging existing agent frameworks within Inspect AI’s evaluation pipeline.</li>
<li><div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@solver</span></span>
<span id="cb20-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> wikipedia_search() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Solver:</span>
<span id="cb20-3"></span>
<span id="cb20-4">    tavily_api <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TavilySearchAPIWrapper() </span>
<span id="cb20-5">    tools <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ([TavilySearchResults(api_wrapper<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tavily_api)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb20-6">        load_tools([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"wikipedia"</span>]))</span>
<span id="cb20-7"></span>
<span id="cb20-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">async</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> agent(llm: BaseChatModel, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]):</span>
<span id="cb20-9">        tools_agent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> create_openai_tools_agent(llm, tools, prompt)</span>
<span id="cb20-10">        agent_executor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AgentExecutor.from_agent_and_tools(</span>
<span id="cb20-11">            agent<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tools_agent,</span>
<span id="cb20-12">            tools<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tools</span>
<span id="cb20-13">        )</span>
<span id="cb20-14">        result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">await</span> agent_executor.ainvoke(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>)</span>
<span id="cb20-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> result[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output"</span>]</span>
<span id="cb20-16"></span>
<span id="cb20-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> langchain_solver(agent)</span></code></pre></div></li>
</ul>
</section>
</section>
<section id="logging" class="level2">
<h2 class="anchored" data-anchor-id="logging">Logging</h2>
<ul>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/eval-logs.html">Eval Logs</a></li>
<li>Logging is crucial for debugging, analysis, and reproducibility.</li>
<li>Capture all context required to debug, analyse, and reproduce evaluations</li>
<li><strong>Inspect AI Logging:</strong>
<ul>
<li>Provides a rich Python API and JSON representation of the evaluation process.</li>
<li>Offers a log viewer for interactive exploration.</li>
<li>Enables programmatic access to logs for analysis and comparison.</li>
</ul></li>
</ul>
<section id="evallog" class="level3">
<h3 class="anchored" data-anchor-id="evallog">EvalLog</h3>
<ul>
<li><p><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/eval-logs.html#evallog">EvalLog</a></p></li>
<li><p>Returned from <code>eval()</code></p></li>
<li><p>Provides programmatic interface to the contents of log files</p></li>
<li><table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 24%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="header">
<th>Field</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>status</code></td>
<td><code>str</code></td>
<td>Status of evaluation</td>
</tr>
<tr class="even">
<td><code>eval</code></td>
<td><code>EvalSpec</code></td>
<td>Top level eval details including task, model, creation time, etc.</td>
</tr>
<tr class="odd">
<td><code>plan</code></td>
<td><code>EvalPlan</code></td>
<td>List of solvers and model generation config used for the eval.</td>
</tr>
<tr class="even">
<td><code>samples</code></td>
<td><code>list[EvalSample]</code></td>
<td>Each sample evaluated, including its input, output, target, and score.</td>
</tr>
<tr class="odd">
<td><code>results</code></td>
<td><code>EvalResults</code></td>
<td>Aggregated scorer results</td>
</tr>
<tr class="even">
<td><code>stats</code></td>
<td><code>EvalStats</code></td>
<td>Model token usage stats</td>
</tr>
<tr class="odd">
<td><code>logging</code></td>
<td><code>list[LoggingMessage]</code></td>
<td>Logging messages (e.g.&nbsp;from <code>log.info()</code>, <code>log.debug()</code>, etc.</td>
</tr>
<tr class="even">
<td><code>error</code></td>
<td><code>EvalError</code></td>
<td>Error information</td>
</tr>
</tbody>
</table></li>
</ul>
</section>
</section>
<section id="models" class="level2">
<h2 class="anchored" data-anchor-id="models">Models</h2>
<ul>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/models.html">Models</a></li>
<li><table class="caption-top table">
<thead>
<tr class="header">
<th>Provider</th>
<th>Model Name</th>
<th>Docs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>OpenAI</td>
<td><code>openai/gpt-3.5-turbo</code></td>
<td><a href="https://platform.openai.com/docs/models/overview">OpenAI Models</a></td>
</tr>
<tr class="even">
<td>Anthropic</td>
<td><code>anthropic/claude-3-sonnet-20240229</code></td>
<td><a href="https://docs.anthropic.com/claude/docs/models-overview">Anthropic Models</a></td>
</tr>
<tr class="odd">
<td>Google</td>
<td><code>google/gemini-1.0-pro</code></td>
<td><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models">Google Models</a></td>
</tr>
<tr class="even">
<td>Mistral</td>
<td><code>mistral/mistral-large-latest</code></td>
<td><a href="https://docs.mistral.ai/platform/endpoints/">Mistral Models</a></td>
</tr>
<tr class="odd">
<td>Hugging Face</td>
<td><code>hf/openai-community/gpt2</code></td>
<td><a href="https://huggingface.co/models?pipeline_tag=text-generation&amp;sort=trending">Hugging Face Models</a></td>
</tr>
<tr class="even">
<td>Ollama</td>
<td><code>ollama/llama3</code></td>
<td><a href="https://ollama.com/library">Ollama Models</a></td>
</tr>
<tr class="odd">
<td>TogetherAI</td>
<td><code>together/lmsys/vicuna-13b-v1.5</code></td>
<td><a href="https://docs.together.ai/docs/inference-models#chat-models">TogetherAI Models</a></td>
</tr>
<tr class="even">
<td>AWS Bedrock</td>
<td><code>bedrock/meta.llama2-70b-chat-v1</code></td>
<td><a href="https://aws.amazon.com/bedrock/">AWS Bedrock Models</a></td>
</tr>
<tr class="odd">
<td>Azure AI</td>
<td><code>azureai/azure-deployment-name</code></td>
<td><a href="https://ai.azure.com/explore/models">Azure AI Models</a></td>
</tr>
<tr class="even">
<td>Cloudflare</td>
<td><code>cf/meta/llama-2-7b-chat-fp16</code></td>
<td><a href="https://developers.cloudflare.com/workers-ai/models/#text-generation">Cloudflare Models</a></td>
</tr>
</tbody>
</table></li>
<li>Allows custom model providers.</li>
<li>Inspect AI remains agnostic to specific model implementations, allowing flexibility and future compatibility.</li>
</ul>
</section>
<section id="workflow" class="level2">
<h2 class="anchored" data-anchor-id="workflow">Workflow</h2>
<ul>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/workflow.html">Workflow</a></li>
</ul>
<section id="interactive-development" class="level3">
<h3 class="anchored" data-anchor-id="interactive-development">Interactive Development:</h3>
<ul>
<li>Designed for iterative development within notebooks.</li>
<li>Provides tools for exploration, such as grid search over parameters.</li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Ad-hoc exploration of an eval in a Notebook/REPL">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Ad-hoc exploration of an eval in a Notebook/REPL
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb21-2">   <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"devops.txt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"researcher.txt"</span>],</span>
<span id="cb21-3">   <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"grader"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hacker.txt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"expert.txt"</span>],</span>
<span id="cb21-4">   <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"grader_model"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai/gpt-4"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"google/gemini-1.0-pro"</span>]</span>
<span id="cb21-5">}</span>
<span id="cb21-6">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(product(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>(params[name] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> name <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> params)))</span>
<span id="cb21-7"></span>
<span id="cb21-8">tasks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [Task(</span>
<span id="cb21-9">    dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>json_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"security_guide.jsonl"</span>),</span>
<span id="cb21-10">    plan<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[system_message(system), generate()],</span>
<span id="cb21-11">    scorer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_graded_fact(template<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>grader, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>grader_model)</span>
<span id="cb21-12">) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> system, grader, grader_model <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> params]</span>
<span id="cb21-13"></span>
<span id="cb21-14">logs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>(tasks, model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mistral/mistral-large-latest"</span>)</span>
<span id="cb21-15">plot_results(logs)</span></code></pre></div>
</div>
</div></li>
</ul>
</section>
<section id="task-parameters" class="level3">
<h3 class="anchored" data-anchor-id="task-parameters">Task Parameters:</h3>
<ul>
<li>Allows defining tasks with configurable parameters.</li>
<li>Enables running evaluations with varying settings from external scripts or notebooks.</li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Formalise variation with a parameterised @task function:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Formalise variation with a parameterised <span class="citation" data-cites="task">@task</span> function:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@task</span></span>
<span id="cb22-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> security_guide(system<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"devops.txt"</span>, grader<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"expert.txt"</span>):</span>
<span id="cb22-3">   <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Task(</span>
<span id="cb22-4">      dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> json_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"security_guide.jsonl"</span>),</span>
<span id="cb22-5">      plan<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[system_message(system), generate()],</span>
<span id="cb22-6">      scorer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_graded_fact(template<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>grader, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai/gpt-4"</span>)</span>
<span id="cb22-7">   )</span>
<span id="cb22-8"></span>
<span id="cb22-9">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb22-10">   <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"devops.txt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"researcher.txt"</span>],</span>
<span id="cb22-11">   <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"grader"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hacker.txt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"expert.txt"</span>]</span>
<span id="cb22-12">}</span>
<span id="cb22-13">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(product(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>(params[name] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> name <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> params)))</span>
<span id="cb22-14"></span>
<span id="cb22-15"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>([security_guide(system,grader) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> system, grader <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> params],</span>
<span id="cb22-16">     model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mistral/mistral-large-latest"</span>)</span></code></pre></div>
</div>
</div></li>
<li><code>@task</code> functions are registered and addressable by external driver programs (step one in development =&gt; production)
<ul>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@task</span></span>
<span id="cb23-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> security_guide(system<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"devops.txt"</span>, grader<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"expert.txt"</span>):</span>
<span id="cb23-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Task(</span>
<span id="cb23-4">        dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> json_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"security_guide.jsonl"</span>),</span>
<span id="cb23-5">        plan<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[system_message(system), generate()],</span>
<span id="cb23-6">        scorer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_graded_fact(</span>
<span id="cb23-7">            template<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>grader, </span>
<span id="cb23-8">            model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai/gpt-4"</span></span>
<span id="cb23-9">        )</span>
<span id="cb23-10">    )</span></code></pre></div>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb24-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">$</span> inspect eval security_guide.py <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-T</span> system=devops.txt </span>
<span id="cb24-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">$</span> inspect eval security_guide.py <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-T</span> grader=hacker.txt </span></code></pre></div>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb25-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">$</span> inspect eval security_guide.ipynb <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-T</span> system=devops.txt </span>
<span id="cb25-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">$</span> inspect eval security_guide.ipynb <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-T</span> grader=hacker.txt </span></code></pre></div>
</div>
</div></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> security_guide(system, grader<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"expert.txt"</span>):</span>
<span id="cb26-2">   <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Task(</span>
<span id="cb26-3">      dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> json_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"security_guide.jsonl"</span>),</span>
<span id="cb26-4">      plan<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[system_message(system), generate()],</span>
<span id="cb26-5">      scorer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_graded_fact(template<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>grader, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai/gpt-4"</span>)</span>
<span id="cb26-6">   )</span>
<span id="cb26-7"></span>
<span id="cb26-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@task</span></span>
<span id="cb26-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> devops()</span>
<span id="cb26-10">   <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> security_guide(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"devops.txt"</span>)</span>
<span id="cb26-11"></span>
<span id="cb26-12"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@task</span></span>
<span id="cb26-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> researcher()</span>
<span id="cb26-14">   <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> security_guide(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"researcher.txt"</span>)</span></code></pre></div>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb27-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">$</span> inspect eval security_guide.py@devops</span>
<span id="cb27-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">$</span> inspect eval security_guide.py@researcher</span></code></pre></div>
</div>
</div></li>
</ul></li>
</ul>
</section>
<section id="eval-suites" class="level3">
<h3 class="anchored" data-anchor-id="eval-suites">Eval Suites:</h3>
<ul>
<li><strong>Documentation:</strong> <a href="https://ukgovernmentbeis.github.io/inspect_ai/eval-suites.html">Eval Suites</a></li>
<li>Supports organizing and running multiple evaluations as suites.</li>
</ul>
</section>
<section id="resiliency" class="level3">
<h3 class="anchored" data-anchor-id="resiliency">Resiliency:</h3>
<ul>
<li>Encourages running evaluations in production environments (e.g., CI) with features like log storage and retry mechanisms.</li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Simplified Example">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Simplified Example
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># setup log context</span></span>
<span id="cb28-2">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"INSPECT_LOG_DIR"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./security-suite_04-07-2024"</span></span>
<span id="cb28-3"></span>
<span id="cb28-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># run the eval suite</span></span>
<span id="cb28-5">tasks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> list_tasks(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"security"</span>)</span>
<span id="cb28-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>(tasks, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mistral/mistral-large-latest"</span>)</span>
<span id="cb28-7"></span>
<span id="cb28-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ...later, in another process that also has INSPECT_LOG_DIR</span></span>
<span id="cb28-9">error_logs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> list_eval_logs(status <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"error"</span>)</span>
<span id="cb28-10">eval_retry(error_logs)</span></code></pre></div>
</div>
</div></li>
</ul>
</section>
<section id="provenance" class="level3">
<h3 class="anchored" data-anchor-id="provenance">Provenance:</h3>
<ul>
<li>Ensures reproducibility by storing Git repository information within the log file.</li>
<li>Allows recreating the evaluation environment and parameters from the log.</li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># read the log and extract the origin and commit</span></span>
<span id="cb29-2">log <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> read_eval_log(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"security-log.json"</span>)</span>
<span id="cb29-3">origin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log.spec.revision.origin</span>
<span id="cb29-4">commit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log.spec.revision.commit</span>
<span id="cb29-5"></span>
<span id="cb29-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># clone the repo, checkout the commit, install deps, and run</span></span>
<span id="cb29-7">run([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"git"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"clone"</span>, revision.origin, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"eval-dir"</span>])</span>
<span id="cb29-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> chdir(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"eval-dir"</span>):</span>
<span id="cb29-9">   run([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"git"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"checkout"</span>, revision.commit])</span>
<span id="cb29-10">   run([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pip"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"install"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-r"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"requirements.txt"</span>])</span>
<span id="cb29-11">   <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>(log) </span></code></pre></div>
</div>
</div></li>
</ul>
</section>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<ul>
<li><strong>Integration with Posit Products:</strong> Inspect AI is not a Posit project and currently has no plans for integration.</li>
<li><strong>Evaluating Past LLM Interactions:</strong> Inspect AI can evaluate past interactions by using message history as input.</li>
<li><strong>Expanding Evaluation Metrics:</strong> The Inspect AI team plans to expand the list of built-in metrics based on community needs.</li>
<li><strong>Future Development and Direction:</strong> Long-term development is prioritized, with a focus on community collaboration and supporting a wide range of evaluation scenarios.</li>
<li><strong>Log Sources Beyond Files:</strong> Currently, logs are primarily file-based, but future development may include database logging capabilities.</li>
<li><strong>Shareable Security Tests:</strong> The Inspect AI team anticipates the creation and sharing of security test suites within the community.</li>
<li><strong>Integration with Weights &amp; Biases:</strong> Integration with Weights &amp; Biases is planned to streamline metric tracking and visualization.</li>
<li><strong>Design Philosophy:</strong> Inspired by principles of cleanliness, simplicity, and composability.</li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-004/</guid>
  <pubDate>Sat, 06 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 3: Prompt Engineering Workshop</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-003/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>What is a Large Language Model?</li>
<li>Prompt Crafting</li>
<li>LLMs are Dumb Mechanical Humans</li>
<li>Building LLM Applications</li>
<li>Creating the Prompt</li>
<li>The Introduction of Chat</li>
<li>The Introduction of Tools</li>
<li>Building LLM Applications - Continued</li>
<li>Creating the Prompt: Copilot Chat</li>
<li>Tips for Defining Tools</li>
<li>Q&amp;A Session</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Presentation Slides">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Presentation Slides
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://docs.google.com/presentation/d/1PXzENGNN5NFbEDJ59wbSp8fro6dPt4xHGNN6X0KU82A/">Prompt Engineering - John Berryman</a></li>
</ul>
</div>
</div>
<section id="what-is-a-language-model" class="level2">
<h2 class="anchored" data-anchor-id="what-is-a-language-model">What is a Language Model?</h2>
<ul>
<li><strong>Language Model (LM):</strong> An AI system trained on vast text data to understand and generate human-like text. Its primary function is predicting the next word in a sequence.</li>
<li><strong>Large Language Model (LLM):</strong> A significantly larger and more complex LM, showcasing enhanced capabilities in understanding and generating human language.</li>
</ul>
<section id="what-is-a-large-language-model" class="level3">
<h3 class="anchored" data-anchor-id="what-is-a-large-language-model">What is a Large Language Model?</h3>
<section id="evolution-of-llms" class="level4">
<h4 class="anchored" data-anchor-id="evolution-of-llms">Evolution of LLMs:</h4>
<ul>
<li><strong>Recurrent Neural Networks (RNNs):</strong> Initial models with limitations in handling long sequences due to the bottleneck between encoder and decoder.</li>
<li><strong>Attention Mechanism:</strong> Introduced to focus on relevant parts of the input sequence, addressing the limitations of RNNs.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a></li>
</ul></li>
<li><strong>Transformer Architecture:</strong> Replaced RNNs by focusing entirely on attention, leading to significant improvements in performance and efficiency.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></li>
</ul></li>
<li><strong>BERT and GPT:</strong>
<ul>
<li><strong>BERT (Bidirectional Encoder Representations from Transformers):</strong> Utilizes the encoder part of the transformer, excelling in tasks like understanding the context of words in a sentence.</li>
<li><strong>GPT (Generative Pre-trained Transformer):</strong> Utilizes the decoder part of the transformer, specializing in generating coherent and contextually relevant text.
<ul>
<li><strong>Paper:</strong> <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="capabilities-and-concerns" class="level4">
<h4 class="anchored" data-anchor-id="capabilities-and-concerns">Capabilities and Concerns:</h4>
<ul>
<li>GPT-2 exhibited impressive unsupervised capabilities across various tasks, including translation, summarization, and question answering.
<ul>
<li><strong>Paper:</strong> <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a></li>
</ul></li>
<li>The power of LLMs raises concerns about potential misuse, as they can be manipulated to generate misleading or harmful content.</li>
</ul>
</section>
</section>
</section>
<section id="prompt-crafting" class="level2">
<h2 class="anchored" data-anchor-id="prompt-crafting">Prompt Crafting</h2>
<ul>
<li><strong>Prompt:</strong> Instructions or context provided to an LLM to guide its text generation process. Effective prompt crafting is crucial for achieving desired outputs.</li>
</ul>
<section id="technique-1-few-shot-prompting" class="level3">
<h3 class="anchored" data-anchor-id="technique-1-few-shot-prompting">Technique #1: Few-Shot Prompting</h3>
<ul>
<li><strong>Concept:</strong> Providing the LLM with a few examples of the desired input-output pattern, enabling it to understand and generalize to new, similar tasks.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2005.14165">Language Models are Few-Shot Learners</a></li>
</ul></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example: Translating English to Spanish">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Translating English to Spanish
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p><strong>Examples to set the pattern:</strong></p>
<pre class="text"><code>&gt; How are you doing today?
&lt; ¿Cómo estás hoy?

&gt; My name is John.
&lt; Mi nombre es John.</code></pre></li>
<li><p><strong>The actual task:</strong></p>
<pre class="text"><code>&gt; Can I have fries with that?
&lt; ¿Puedo tener papas fritas con eso?</code></pre></li>
</ul>
</div>
</div></li>
</ul>
</section>
<section id="technique-2-chain-of-thought-reasoning" class="level3">
<h3 class="anchored" data-anchor-id="technique-2-chain-of-thought-reasoning">Technique #2: Chain-of-Thought Reasoning</h3>
<ul>
<li><strong>Concept:</strong> Improving LLM’s reasoning abilities by prompting them to generate a step-by-step thought process leading to the solution, especially useful for tasks involving logic and reasoning.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2201.11903">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a></li>
</ul></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example: Guiding the model to break down the problem into smaller, logical steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Guiding the model to break down the problem into smaller, logical steps
</div>
</div>
<div class="callout-body-container callout-body">
<pre class="text"><code># Trainging Example
Q: Jim is twice as old as Steve. Jim is 12 years how old is Steve.
A: In equation form: 12=2*a where a is Steve's age. Dividing both sides by 2 we see that a=6. Steve is 6 years old.

# Test Question
Q: It takes one baker an hour to make a cake. How long does it take 3 bakers to make 3 cakes?

# Answer with Reasoning
A: The amount of time it takes to bake a cake is the same regardless of how many cakes are made and how many people work on them. Therefore the answer is still 1 hour.</code></pre>
</div>
</div></li>
</ul>
<section id="thinking-step-by-step" class="level4">
<h4 class="anchored" data-anchor-id="thinking-step-by-step">Thinking Step-by-Step</h4>
<ul>
<li><strong>Simplified Approach:</strong> A variation of chain-of-thought reasoning where instead of providing multiple examples, the prompt directly instructs the model to “think step-by-step.”
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2205.11916">Large Language Models are Zero-Shot Reasoners</a></li>
</ul></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<pre class="text"><code>Q: It takes one baker an hour to make a cake. How long does it take 3 bakers to make 3 cakes?

# Prime the model by starting it's answer with "Let's think step-by-step."
A: Let's think step-by-step. The amount of time it takes to bake a cake is the same regardless of how many cakes are made and how many people work on them. Therefore the answer is still 1 hour.</code></pre>
</div>
</div></li>
<li><strong>Advantages:</strong>
<ul>
<li>Reduces the need for crafting numerous examples.</li>
<li>Avoids potential bias from examples bleeding into the answer.</li>
<li>Improves prompt efficiency by using shorter instructions.</li>
</ul></li>
</ul>
</section>
</section>
<section id="technique-3-document-mimicry" class="level3">
<h3 class="anchored" data-anchor-id="technique-3-document-mimicry">Technique #3: Document Mimicry</h3>
<ul>
<li><strong>Concept:</strong> Leveraging the LLM’s knowledge of specific document structures and formats to guide its output towards a desired style and content.</li>
<li><strong>Example:</strong> Crafting a prompt in the format of a customer support transcript, using headings, roles (Customer, Support Assistant), and Markdown formatting to elicit a response mimicking a helpful support interaction.</li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<pre class="text"><code></code></pre>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"># IT Support Assistant</span></span>
<span id="cb6-2">The following is a transcript between an award winning IT support rep and a customer.</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">## Customer:</span></span>
<span id="cb6-5">My cable is out! And I'm going to miss the Superbowl!</span>
<span id="cb6-6"></span>
<span id="cb6-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">## Support Assistant:</span></span>
<span id="cb6-8">Let's figure out how to diagnose your problem…</span></code></pre></div>
<ul>
<li>Document type: transcript</li>
<li>Tells a story to condition a particular response</li>
<li>Uses Markdown to establish structure</li>
</ul>
</div>
</div></li>
</ul>
</section>
</section>
<section id="llms-are-dumb-mechanical-humans" class="level2">
<h2 class="anchored" data-anchor-id="llms-are-dumb-mechanical-humans">LLMs are Dumb Mechanical Humans</h2>
<ul>
<li><strong>Use Familiar Language and Constructs:</strong> LLMs perform better with language and structures commonly found in their training data.</li>
<li><strong>Avoid Overloading with Context:</strong> While providing context is essential, too much information can distract the model and hinder its performance.</li>
<li><strong>Provide Necessary Information:</strong> LLMs are not psychic; they rely on the prompt for information not present in their training data.</li>
<li><strong>Ensure Prompt Clarity:</strong> If the prompt is confusing for a human, it will likely be confusing for the LLM as well.</li>
</ul>
</section>
<section id="building-llm-applications" class="level2">
<h2 class="anchored" data-anchor-id="building-llm-applications">Building LLM Applications</h2>
<ul>
<li><strong>LLMs as Transformation Layers:</strong> LLM applications act as intermediaries between the user’s problem domain and the LLM’s text-based domain.</li>
<li><strong>Process:</strong>
<ol type="1">
<li><strong>User Request:</strong> The user interacts with the application, providing a request or input.</li>
<li><strong>Transformation to LLM Space:</strong> The application converts the user’s request into a text-based prompt understandable by the LLM.</li>
<li><strong>LLM Processing:</strong> The LLM processes the prompt and generates a text output.</li>
<li><strong>Transformation to User Space:</strong> The application converts the LLM’s text output into a format actionable and understandable by the user.</li>
</ol></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-003/images/llm-application-diagram.png" class="img-fluid figure-img"></p>
<figcaption><a href="https://docs.google.com/presentation/d/1PXzENGNN5NFbEDJ59wbSp8fro6dPt4xHGNN6X0KU82A/edit#slide=id.g2c14fe843d2_1_120">Prompt Engineering by John Berryman - Slide 14</a></figcaption>
</figure>
</div>
</section>
<section id="creating-the-prompt" class="level2">
<h2 class="anchored" data-anchor-id="creating-the-prompt">Creating the Prompt</h2>
<ul>
<li><strong>Prompt Creation for Completion Models:</strong>
<ul>
<li><strong>Context Collection:</strong> Gather relevant information from sources like the current document, open tabs, and relevant symbols.</li>
<li><strong>Context Ranking:</strong> Prioritize the collected context based on its importance and relevance to the task.</li>
<li><strong>Context Trimming:</strong> Condense or eliminate less crucial context to fit within the LLM’s input limits.</li>
<li><strong>Document Assembly:</strong> Structure the prompt in a clear and organized manner, mimicking relevant document formats if applicable.</li>
</ul></li>
</ul>
<section id="copilot-code-completion" class="level3">
<h3 class="anchored" data-anchor-id="copilot-code-completion">Copilot Code Completion</h3>
<ul>
<li><strong>Context Collection:</strong>
<ul>
<li>Current document, open tabs, symbols used, file path.</li>
</ul></li>
<li><strong>Context Ranking:</strong>
<ul>
<li>File path (most important)</li>
<li>Current document</li>
<li>Neighboring tabs</li>
<li>Symbols (least important)</li>
</ul></li>
<li><strong>Context Trimming:</strong> Prioritizes keeping the file path, current document, and relevant snippets from open tabs.</li>
<li><strong>Document Assembly:</strong> Structures the prompt with file path at the top, followed by snippets from open tabs, and finally, the current document up to the cursor position.</li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="annotated-cell-7" style="background: #f1f3f5;"><pre class="sourceCode go code-annotation-code code-with-copy code-annotated"><code class="sourceCode go"><a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-7-1" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// pkg/skills/search.go</span></span>
<span id="annotated-cell-7-2"></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-7-3" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// &lt;consider this snippet from ../skill.go&gt;</span></span>
<span id="annotated-cell-7-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// type Skill interface {</span></span>
<span id="annotated-cell-7-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//    Execute(data []byte) (refs, error)</span></span>
<span id="annotated-cell-7-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// }</span></span>
<span id="annotated-cell-7-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// &lt;/end snippet&gt;</span></span>
<span id="annotated-cell-7-8"></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-7-9" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">package</span> searchskill</span>
<span id="annotated-cell-7-10"></span>
<span id="annotated-cell-7-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">import</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span></span>
<span id="annotated-cell-7-12">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"context"</span></span>
<span id="annotated-cell-7-13">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"encoding/json"</span></span>
<span id="annotated-cell-7-14">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fmt"</span></span>
<span id="annotated-cell-7-15">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"strings"</span></span>
<span id="annotated-cell-7-16">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"time"</span></span>
<span id="annotated-cell-7-17"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span id="annotated-cell-7-18"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">type</span> Skill <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">struct</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-7-19" class="code-annotation-target">  █</span>
<span id="annotated-cell-7-20"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="annotated-cell-7-21"></span>
<span id="annotated-cell-7-22"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">type</span> params <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">struct</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span></span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-7" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="1,2" data-code-annotation="1">file path</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="3,4,5,6,7" data-code-annotation="2">snippet from open tab</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="9,11,12,13,14,15,16,17,18,20,22" data-code-annotation="3">current document</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="19" data-code-annotation="4">cursor</span>
</dd>
</dl>
</div>
</div></li>
</ul>
</section>
</section>
<section id="the-introduction-of-chat" class="level2">
<h2 class="anchored" data-anchor-id="the-introduction-of-chat">The Introduction of Chat</h2>
<ul>
<li><strong>Shift Towards Conversational Interfaces:</strong> Chat interfaces have become a popular paradigm for LLM applications.
<ul>
<li><strong>Blog Post:</strong> <a href="https://openai.com/index/chatgpt/">Introducing ChatGPT</a></li>
</ul></li>
<li><strong>ChatML:</strong> A specialized syntax used to represent chat conversations, with roles like “user” and “assistant” and special tokens to delineate messages.</li>
<li><div class="callout callout-style-default callout-note callout-titled" title="API">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
API
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb7-1"><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">messages</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">=</span> </span>
<span id="cb7-2"><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb7-3">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system"</span></span>
<span id="cb7-4">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are an award winning support staff representative that helps customers."</span></span>
<span id="cb7-5"> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-6"></span>
<span id="cb7-7"> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb7-8">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"My cable is out! And I'm going to miss the Superbowl!"</span></span>
<span id="cb7-9"> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb7-10"><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span></code></pre></div>
</div>
</div></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Document">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Document
</div>
</div>
<div class="callout-body-container callout-body">
<pre class="text"><code>&lt;|im_start|&gt; system
You are an award winning IT support rep. Help the user with their request.&lt;|im_stop|&gt;

&lt;|im_start|&gt; user
My cable is out! And I'm going to miss the Superbowl!&lt;|im_stop|&gt;

&lt;|im_start|&gt; assistant
Let's figure out how to diagnose your problem…</code></pre>
</div>
</div></li>
<li><strong>Benefits of Chat-Based Interfaces:</strong>
<ul>
<li><strong>Natural Interaction:</strong> Mimics human conversation, providing a more intuitive user experience.</li>
<li><strong>System Messages:</strong> Allow developers to control the assistant’s behavior and personality.</li>
<li><strong>Enhanced Safety:</strong> Chat-based models are often fine-tuned to avoid generating harmful or inappropriate content.</li>
<li><strong>Reduced Prompt Injection Risk:</strong> Special tokens in ChatML make it difficult for users to manipulate the assistant’s behavior through malicious prompts.</li>
</ul></li>
</ul>
</section>
<section id="the-introduction-of-tools" class="level2">
<h2 class="anchored" data-anchor-id="the-introduction-of-tools">The Introduction of Tools</h2>
<ul>
<li><p><strong>Extending LLM Capabilities:</strong> Tools enable LLMs to interact with external systems and data, expanding their functionality beyond text generation.</p>
<ul>
<li><strong>Blog Post:</strong> <a href="https://openai.com/index/function-calling-and-other-api-updates/">Function calling and other API updates</a></li>
</ul></li>
<li><p><strong>Function Calling:</strong> Allows developers to define functions that the LLM can call to access external APIs or perform specific actions.</p>
<ul>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example: Get Weather Function">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Get Weather Function
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb9-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb9-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"function"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb9-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"function"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb9-4">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"get_weather"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb9-5">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Get the weather"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb9-6">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"parameters"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb9-7">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb9-8">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"properties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb9-9">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"location"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb9-10">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb9-11">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The city and state"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb9-12">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb9-13">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"unit"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb9-14">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb9-15">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"degrees Fahrenheit or Celsius"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb9-16">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"enum"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"celsius"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fahrenheit"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb9-17">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb9-18">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb9-19">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"required"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"location"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb9-20">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb9-21">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb9-22"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
</div></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Input:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Input:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb10-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb10-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb10-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What's the weather like in Miami?"</span></span>
<span id="cb10-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
</div></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Function Call:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Function Call:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb11-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb11-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"assistant"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> </span>
<span id="cb11-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"function"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb11-4">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"get_weather"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb11-5">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"arguments"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"location"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Miami, FL"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">'</span> </span>
<span id="cb11-6">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb11-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
</div></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Real API Request:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Real API Request:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">curl</span> http://weathernow.com/miami/FL<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">?</span>deg=f</span>
<span id="cb12-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Response</span></span>
<span id="cb12-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"temp"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">:</span> 78}</span></code></pre></div>
</div>
</div></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Function Response:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Function Response:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb13-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb13-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb13-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"get_weather"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb13-4">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"78ºF"</span></span>
<span id="cb13-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
</div></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Assistant Response:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Assistant Response:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb14-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb14-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"assistant"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span> </span>
<span id="cb14-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"It's a balmy 78ºF"</span></span>
<span id="cb14-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
</div></li>
</ul></li>
<li><p><strong>Benefits of Tool Usage:</strong></p>
<ul>
<li><strong>Real-World Interaction:</strong> LLMs can now access and manipulate information in the real world through APIs.</li>
<li><strong>Flexibility in Response:</strong> Models can choose to respond to user requests by either calling functions or providing text-based answers.</li>
<li><strong>Potential for Parallel Processing:</strong> LLMs are being developed to execute multiple function calls concurrently, improving efficiency.</li>
</ul></li>
</ul>
</section>
<section id="building-llm-applications---continued" class="level2">
<h2 class="anchored" data-anchor-id="building-llm-applications---continued">Building LLM Applications - Continued</h2>
<ul>
<li><strong>Enhanced Application Architecture:</strong> With the introduction of chat and tool calling, the architecture of LLM applications becomes more sophisticated.</li>
<li><strong>Bag of Tools Agent:</strong>
<ul>
<li><strong>Prompt Crafting:</strong> Incorporates previous messages, context, tool definitions, and the user’s current request.</li>
<li><strong>Bifurcated Processing:</strong> The LLM can either call a function based on the prompt or generate a text response directly.</li>
<li><strong>Iterative Interaction:</strong> The application handles function calls, integrates results back into the prompt, and facilitates ongoing conversation.</li>
</ul></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example: Temperature Control">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Temperature Control
</div>
</div>
<div class="callout-body-container callout-body">
<pre class="text"><code>user: make it 2 degrees warmer in here

assistant: getTemp()
function: 70ºF
assistant: setTemp(72)
function: success
assistant: Done!

user: actually… put it back

assistant: setTemp(70)
function: success
assistant: Done again, you fickle pickle!</code></pre>
</div>
</div></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-003/images/llm-application-diagram-bag-of-tools.png" class="img-fluid figure-img"></p>
<figcaption><a href="https://docs.google.com/presentation/d/1PXzENGNN5NFbEDJ59wbSp8fro6dPt4xHGNN6X0KU82A/edit#slide=id.g2c247832288_0_62">Prompt Engineering by John Berryman - Slide 20</a></figcaption>
</figure>
</div>
</section>
<section id="creating-the-prompt-copilot-chat" class="level2">
<h2 class="anchored" data-anchor-id="creating-the-prompt-copilot-chat">Creating the Prompt: Copilot Chat</h2>
<ul>
<li><strong>Context Collection:</strong>
<ul>
<li>Open files, highlighted code snippets, clipboard contents, relevant GitHub issues, previous messages in the conversation.</li>
</ul></li>
<li><strong>Context Ranking:</strong>
<ul>
<li>System message (essential for safety and behavior control)</li>
<li>Function definitions (if applicable)</li>
<li>User’s most recent message</li>
<li>Function call history and evaluations</li>
<li>References associated with messages</li>
<li>Historic messages (least important)</li>
</ul></li>
<li><strong>Context Trimming:</strong> Prioritizes keeping essential elements and trimming less crucial information like historic messages or function definitions if space is limited.</li>
<li><strong>Fallback Mechanisms:</strong> If the prompt becomes too large, the application should have strategies to handle the situation gracefully, such as prioritizing essential elements or informing the user about limitations.</li>
</ul>
</section>
<section id="tips-for-defining-tools" class="level2">
<h2 class="anchored" data-anchor-id="tips-for-defining-tools">Tips for Defining Tools</h2>
<ul>
<li><strong>Quantity:</strong>
<ul>
<li>Don’t have “too many” tools</li>
<li>Look for evidence of collisions</li>
</ul></li>
<li><strong>Names:</strong>
<ul>
<li>Use simple and clear names</li>
<li>Consider using typeScript format</li>
</ul></li>
<li><strong>Arguments:</strong>
<ul>
<li>Keep arguments simple and few
<ul>
<li>Don’t copy/paste your API</li>
</ul></li>
<li>Nest arguments don’t retain descriptions</li>
<li>Can use enum and default, but not minimum, maximum</li>
</ul></li>
<li><strong>Descriptions:</strong>
<ul>
<li>Keep them short and consider what the model knows
<ul>
<li>Probably understands public documentation.</li>
<li>Doesn’t know about internal company acronyms.</li>
</ul></li>
</ul></li>
<li><strong>Output:</strong> Don’t include extra “just-in-case” content</li>
<li><strong>Errors:</strong> when reasonable, send errors to model (validation errors)</li>
</ul>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<section id="copilot-and-code-analysis" class="level3">
<h3 class="anchored" data-anchor-id="copilot-and-code-analysis">Copilot and Code Analysis</h3>
<ul>
<li><strong>Question:</strong> Can Copilot analyze codebases beyond open tabs to provide more context-aware suggestions?</li>
<li><strong>Answer:</strong> While not currently available, Copilot’s code analysis capabilities are under active development and expected to improve.</li>
<li><strong>Related Ideas:</strong> <a href="https://sourcegraph.com/">Sourcegraph</a> was mentioned as a company with interesting code analysis tools.</li>
</ul>
</section>
<section id="few-shot-prompting" class="level3">
<h3 class="anchored" data-anchor-id="few-shot-prompting">Few-Shot Prompting</h3>
<ul>
<li><strong>Question:</strong> How many examples are ideal for few-shot prompting, and where should they be placed?</li>
<li><strong>Answer:</strong> There’s no single answer, as it depends on the task and model. Experimentation is key.</li>
<li><strong>Best Practices:</strong>
<ul>
<li><strong>Log Probabilities:</strong> Analyze the log probabilities of predicted tokens to gauge if the model is grasping the pattern from the examples. High and leveling off probabilities suggest sufficient examples.</li>
<li><strong>Placement:</strong> For completion models, examples go directly in the prompt. For chat assistants, consider the message flow and potentially use fake user messages to position examples effectively.</li>
</ul></li>
</ul>
</section>
<section id="hyperparameter-tuning" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameter-tuning">Hyperparameter Tuning</h3>
<ul>
<li><strong>Question:</strong> What hyperparameters should be adjusted when iterating on prompts, and how do they impact results?</li>
<li><strong>Answer:</strong> Temperature and the number of completions are key parameters to experiment with.</li>
<li><strong>Parameter Explanations:</strong>
<ul>
<li><strong>Temperature:</strong> Controls the randomness of the model’s output.
<ul>
<li>0 = deterministic, less creative</li>
<li>0.7 = a good balance for creativity (used in Copilot Chat)</li>
<li>1 = follows the natural probability distribution</li>
<li>Higher values increase randomness, potentially leading to gibberish.</li>
</ul></li>
<li><strong>Number of Completions (n):</strong> Requesting multiple completions (e.g., n=100) can be useful for evaluation or generating a wider range of outputs. Set a reasonably high temperature to avoid repetitive results.</li>
</ul></li>
</ul>
</section>
<section id="structuring-llm-outputs" class="level3">
<h3 class="anchored" data-anchor-id="structuring-llm-outputs">Structuring LLM Outputs</h3>
<ul>
<li><strong>Question:</strong> How can you guide an LLM to summarize information into a structured format like JSON?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Function Calling:</strong> Define functions within the prompt that specify the desired output structure (e.g., a function to extract restaurant details). LLMs are trained to understand and utilize JSON-like structures within function definitions.</li>
<li><strong>Simplified APIs:</strong> Avoid overly complex nested structures in function definitions. Break down tasks into smaller, more manageable steps if needed.</li>
</ul></li>
</ul>
</section>
<section id="challenges-with-complex-function-arguments" class="level3">
<h3 class="anchored" data-anchor-id="challenges-with-complex-function-arguments">Challenges with Complex Function Arguments</h3>
<ul>
<li><strong>Observation:</strong> Passing highly nested data structures as function arguments can be difficult for both humans and LLMs to interpret.</li>
<li><strong>Recommendations:</strong>
<ul>
<li><strong>Simplicity:</strong> Strive for clear and concise function arguments.</li>
<li><strong>Evaluation:</strong> Thoroughly test and evaluate how well the LLM handles complex structures.</li>
<li><strong>Iterative Refinement:</strong> Consider simplifying APIs or data structures if the LLM struggles with complexity.</li>
</ul></li>
</ul>
</section>
<section id="understanding-openais-function-calling-mechanism" class="level3">
<h3 class="anchored" data-anchor-id="understanding-openais-function-calling-mechanism">Understanding OpenAI’s Function Calling Mechanism</h3>
<ul>
<li><strong>Question:</strong> How does OpenAI handle function calling internally?</li>
<li><strong>Answer:</strong> OpenAI transforms function definitions into a TypeScript-like format internally, adding comments for descriptions and argument details. However, nested structures may lose some type information during this process.
<ul>
<li><strong>Blog Post:</strong> <a href="http://blog.jnbrymn.com/2024/01/30/the-marvel-of-GPT-generality.html">Tool Invocation – Demonstrating the Marvel of GPT’s Flexibility</a></li>
</ul></li>
<li><strong>Key Takeaway:</strong> While LLMs can handle some complexity, being mindful of the underlying representation can help in designing more effective function calls.</li>
</ul>
</section>
<section id="improving-code-generation" class="level3">
<h3 class="anchored" data-anchor-id="improving-code-generation">Improving Code Generation</h3>
<ul>
<li><strong>Question:</strong> How to improve the quality of code generated by LLMs, especially in tools like Copilot?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Clear Comments:</strong> Provide explicit instructions within code comments to guide the model’s completions (e.g., describe the intended logic or syntax).</li>
<li><strong>Code Style:</strong> LLMs tend to mimic the style of the provided code. Writing clean and well-structured code can lead to better completions.</li>
</ul></li>
</ul>
</section>
<section id="prompt-engineering-tools" class="level3">
<h3 class="anchored" data-anchor-id="prompt-engineering-tools">Prompt Engineering Tools</h3>
<ul>
<li><strong>Question:</strong> What are your thoughts on tools like DSPy for automated prompting?
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/stanfordnlp/dspy">dspy</a></li>
</ul></li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Value of Direct Interaction:</strong> Starting with direct interaction with LLMs (without intermediary tools) is crucial for building intuition and understanding.</li>
<li><strong>Potential Benefits of Tools:</strong> Tools like DSPy can automate tasks like finding optimal few-shot examples, potentially saving time and effort.</li>
<li><strong>Trade-offs:</strong> Abstraction can sometimes obscure the underlying mechanisms and limit fine-grained control.</li>
</ul></li>
</ul>
</section>
<section id="advanced-prompting-techniques" class="level3">
<h3 class="anchored" data-anchor-id="advanced-prompting-techniques">Advanced Prompting Techniques</h3>
<ul>
<li><strong>Question:</strong> Beyond chain-of-thought prompting, what other techniques are worth exploring?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>ReAct (Reason + Act):</strong> Involves defining a set of “fake” functions within the prompt, allowing the model to reason about which actions to take to solve a problem.
<ul>
<li><strong>Blog Post:</strong> <a href="https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/">ReAct: Synergizing Reasoning and Acting in Language Models</a></li>
</ul></li>
<li><strong>Reflexion:</strong> Focuses on evaluating and iteratively improving the model’s output. For example, running generated code through tests and feeding error messages back into the prompt for correction.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2303.11366">Reflexion: Language Agents with Verbal Reinforcement Learning</a></li>
</ul></li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-003/</guid>
  <pubDate>Sun, 30 Jun 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
</channel>
</rss>
