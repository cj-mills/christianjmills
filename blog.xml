<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Christian Mills</title>
<link>christianjmills.com/blog.html</link>
<atom:link href="christianjmills.com/blog.xml" rel="self" type="application/rss+xml"/>
<description>This is Christian Mills&#39; personal Blog.</description>
<image>
<url>christianjmills.com/images/logo.png</url>
<title>Christian Mills</title>
<link>christianjmills.com/blog.html</link>
<height>142</height>
<width>144</width>
</image>
<generator>quarto-1.4.550</generator>
<lastBuildDate>Fri, 23 Feb 2024 08:00:00 GMT</lastBuildDate>
<item>
  <title>Notes on Why Greatness Cannot Be Planned</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/why-greatness-cannot-be-planned-book-notes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Book LInks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://link.springer.com/book/10.1007/978-3-319-15524-1">Publisher Page</a></li>
<li><a href="https://www.kenstanley.net/home">Author’s Website: Kenneth O. Stanley</a></li>
<li><a href="http://joellehman.com/">Author’s Website: Joel Lehman</a></li>
</ul>
</div>
</div>
<ul>
<li>Ch. 1: Questioning Objectives</li>
<li>Ch. 2: Victory For The Aimless</li>
<li>Ch. 3: The Art Of Breeding Art</li>
<li>Ch. 4: The False Compass</li>
<li>Ch. 5: The Interesting And The Novel</li>
<li>Ch. 6: Long Live The Treasure Hunter</li>
<li>Ch. 7: Unshackling Education</li>
<li>Ch. 8: Unchaining Innovation</li>
<li>Ch. 9: Farewell To The Mirage</li>
<li>Ch. 10: Reinterpreting Natural Evolution</li>
<li>Ch. 11: Objectives And The Quest For AI</li>
</ul>
<section id="questioning-objectives" class="level2">
<h2 class="anchored" data-anchor-id="questioning-objectives">Questioning Objectives</h2>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>The book challenges the traditional focus on objectives in society, proposing that true greatness and discovery often come from less structured and objective-driven approaches. Through various examples, including historical innovations and cultural developments like rock and roll, the authors argue that a preoccupation with objectives may limit potential achievements. They suggest that exploration without specific goals can lead to significant discoveries and advancements, advocating a shift from objective-driven action to open-ended exploration.</p>
</section>
<section id="key-concepts" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts">Key Concepts</h3>
<ul>
<li><strong>Dominance of Objectives:</strong> Objectives are deeply ingrained in our culture, guiding personal and societal actions, from early education to professional and personal life.</li>
<li><strong>Limitations of Objectives:</strong> While objectives can provide direction and a sense of security, they often constrain creativity, exploration, and the potential for major breakthroughs or serendipitous discoveries.</li>
<li><strong>The Paradox of Achievement:</strong> Ambitious achievements become less likely when they are made objectives. The path to significant discoveries or innovations often involves navigating through unexpected “stepping stones” that may not be directly related to the ultimate goal.</li>
<li><strong>Stepping Stones:</strong> Achievements are seen as a process of discovery, involving navigating through a vast space of possibilities to find valuable outcomes. The journey to finding these outcomes often requires exploring unexpected paths that are not directly aligned with initial objectives.</li>
<li><strong>Open-Ended Exploration:</strong> The authors advocate for pursuing exploration and creativity without predefined objectives, highlighting that some of the greatest achievements and discoveries come from such an approach.</li>
<li><strong>Critique of Objective Culture:</strong> The book critiques the prevalent culture of setting and pursuing objectives, arguing that it limits human potential and creativity. The authors call for a reassessment of how society and individuals approach achievement and success.</li>
</ul>
</section>
<section id="theoretical-insights" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-insights">Theoretical Insights</h3>
<ul>
<li><strong>Search Space Concept:</strong> The notion that creativity and achievement are akin to searching through a vast room of possibilities, where understanding and exploring this space can lead to novel discoveries.</li>
<li><strong>Creativity as a Search:</strong> Creativity is framed as searching for valuable outcomes within a vast set of possibilities, with the process being more about exploration than following a linear path toward a specific objective.</li>
<li><strong>Unpredictability of Stepping Stones:</strong> The paths to significant achievements often involve stepping stones that are unpredictable and may seem unrelated to the ultimate goal, challenging the effectiveness of setting specific objectives.</li>
<li><strong>Objective Paradox:</strong> Ambitious objectives can actually become obstacles to the achievements they seek to attain, suggesting that an open-ended exploration without specific goals may be more effective in reaching genuine innovation.</li>
</ul>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<ul>
<li><strong>Embrace Exploration:</strong> Encourage a shift from objective-driven pursuits to open-ended exploration, allowing for greater creativity and the potential for serendipitous discoveries.</li>
<li><strong>Redefine Achievement:</strong> Challenge the traditional notion that achievements must be goal-oriented, and recognize the value of the journey and exploration in itself.</li>
<li><strong>Cultivate Serendipity:</strong> Recognize and embrace the role of serendipity in discovery and innovation, rather than relying solely on predefined objectives.</li>
<li><strong>Foster Interdisciplinary Connections:</strong> Encourage cross-disciplinary pursuits and the exploration of seemingly unrelated fields, as they can lead to unexpected and valuable discoveries.</li>
<li><strong>Reassess Personal Goals:</strong> Individuals are encouraged to reassess their personal and professional objectives, considering the potential benefits of a more open-ended approach to pursuing their interests and passions.</li>
</ul>
</section>
<section id="additional-insights" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights">Additional Insights</h3>
<ul>
<li><strong>Historical Perspectives:</strong> The book provides historical examples where significant achievements or discoveries were the result of exploration without clear objectives, such as the development of computers and the genre of rock and roll.</li>
<li><strong>AI and Objectives:</strong> The authors discuss the role of objectives in the field of artificial intelligence, suggesting that even in highly technical fields, an open-ended exploration could be more beneficial than rigid objective-driven approaches.</li>
<li><strong>Personal Liberation:</strong> Beyond societal and professional implications, the book advocates for a personal liberation from the constraints of objectives, suggesting that this can lead to a more fulfilling and creative life.</li>
</ul>
</section>
</section>
<section id="victory-for-the-aimless" class="level2">
<h2 class="anchored" data-anchor-id="victory-for-the-aimless">Victory For The Aimless</h2>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary</h3>
<p>Chapter 2 argues that many of life’s greatest successes do not follow a pre-planned path but are the result of serendipity and openness to unexpected opportunities. It presents numerous examples of individuals who found success in fields unrelated to their original plans or objectives, including Johnny Depp, John Grisham, J.K. Rowling, and Colonel Sanders among others. The text emphasizes the importance of flexibility and being receptive to unforeseen possibilities, highlighting that a willingness to deviate from one’s initial objectives can lead to remarkable outcomes.</p>
</section>
<section id="key-concepts-1" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-1">Key Concepts</h3>
<ul>
<li><strong>Serendipity in Success:</strong> Many successful careers and achievements arise from unplanned, unexpected opportunities rather than strict adherence to an initial plan.</li>
<li><strong>Openness to Opportunity:</strong> Being open and flexible to change can be more crucial to finding happiness and success than rigorous planning.</li>
<li><strong>Stepping Stones to Success:</strong> Initial goals or careers often end up serving as stepping stones to different, sometimes unrelated, successes.</li>
<li><strong>The Limitations of Objective Thinking:</strong> The narrative challenges the conventional wisdom of setting realistic, objective goals, suggesting instead that aimlessness can lead to greatness.</li>
</ul>
</section>
<section id="noteworthy-facts" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts">Noteworthy Facts</h3>
<ul>
<li><strong>Impact of Serendipity:</strong> Nearly two thirds of adults attribute part of their career choice to serendipity.</li>
<li><strong>Academic Backing:</strong> The chapter references studies and surveys that support the notion that unplanned experiences significantly influence career paths and personal growth.</li>
<li><strong>Historical Examples:</strong> It provides historical accounts of figures like Raymond Chandler and Colonel Sanders, who only found their iconic careers at a later stage in life through incidental circumstances.</li>
</ul>
</section>
<section id="practical-implications" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications">Practical Implications</h3>
<ul>
<li><strong>Career Guidance:</strong> Suggests that career counseling and guidance might benefit from incorporating an understanding of serendipity and the value of openness to various experiences.</li>
<li><strong>Education Systems:</strong> Educational systems and methods could be reevaluated to foster a greater sense of exploration and discovery, rather than overly focusing on specific objectives.</li>
<li><strong>Personal Development:</strong> Individuals seeking fulfillment and success may consider valuing flexibility and openness over stringent adherence to predefined goals.</li>
</ul>
</section>
<section id="additional-insights-1" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-1">Additional Insights</h3>
<ul>
<li><strong>Paradox of Objectives:</strong> The chapter delves into the paradox that sometimes, not directly pursuing an ambitious objective (like love or happiness) can paradoxically lead to attaining it.</li>
<li><strong>Cultural Instances of Serendipity:</strong> It also touches on the broader cultural recognition of the power of serendipity, even if it’s not always termed as such, in stories of love and in various hobbies that evolve into careers.</li>
</ul>
</section>
<section id="recommendations-1" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-1">Recommendations</h3>
<ul>
<li><strong>Embrace Openness:</strong> Encourage individuals to remain open to new experiences and be willing to diverge from their original paths in pursuit of happiness and success.</li>
<li><strong>Valuing Serendipity:</strong> Suggest societal and cultural shifts towards valuing serendipity and the unexpected in personal development and career planning.</li>
<li><strong>Non-Objective Exploration:</strong> Advocate for exploration without a fixed objective in various areas of life, from education to career, to foster greater potential for discovery and fulfillment.</li>
</ul>
</section>
</section>
<section id="the-art-of-breeding-art" class="level2">
<h2 class="anchored" data-anchor-id="the-art-of-breeding-art">The Art Of Breeding Art</h2>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<p>Chapter 3 discusses the concept that setting specific objectives might hinder rather than help achieve groundbreaking outcomes, as evidenced by the development and results of <a href="https://nbenko1.github.io/#/">Picbreeder</a>, a platform that allows users to “breed” pictures, leading to unexpected artistic creations. The principle learned from Picbreeder’s success is that open-minded exploration, rather than a strict focus on objectives, often leads to the most significant discoveries. This insight is suggested to be applicable beyond Picbreeder, impacting various aspects of life and efforts to achieve goals.</p>
</section>
<section id="key-concepts-2" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-2">Key Concepts</h3>
<ul>
<li><strong>Questioning Objectives</strong>: The authors challenge the common practice of setting objectives, suggesting that it may be counterproductive.</li>
<li><a href="https://nbenko1.github.io/#/"><strong>Picbreeder Platform</strong></a>: An experiment in artificial intelligence allowing users to breed artistic images through a process similar to animal breeding, but with pictures.</li>
<li><strong>Genetic Art</strong>: A concept based on artificial “DNA” for pictures, inspired by Richard Dawkins’ work, that enables the breeding of images to produce unique artworks.</li>
<li><strong>Serendipity in Discovery</strong>: The most successful outcomes on Picbreeder come from unexpected, serendipitous discoveries rather than from pursuing specific objectives.</li>
</ul>
</section>
<section id="noteworthy-facts-1" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-1">Noteworthy Facts</h3>
<ul>
<li><strong>Origin of Genetic Art</strong>: Inspired by Richard Dawkins’ <em>The Blind Watchmaker</em>, genetic art involves creating images based on artificial DNA.</li>
<li><strong>Impact of Objectives</strong>: Evidence from Picbreeder suggests that setting objectives can be an obstacle to creativity and discovery.</li>
<li><strong>Role of Serendipity</strong>: Key discoveries on Picbreeder, such as the creation of a car image from an alien face, resulted from unplanned, serendipitous mutations rather than targeted objectives.</li>
</ul>
</section>
<section id="practical-implications-1" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-1">Practical Implications</h3>
<ul>
<li><strong>Designing AI Systems</strong>: The insights from Picbreeder can influence how artificial intelligence systems are designed, emphasizing exploration over objective-driven approaches.</li>
<li><strong>Creativity Process</strong>: The principle that objectives might hinder discovery can apply to artistic creation, research, and development, suggesting a more exploratory and open-minded approach instead.</li>
</ul>
</section>
<section id="supporting-evidence" class="level3">
<h3 class="anchored" data-anchor-id="supporting-evidence">Supporting Evidence</h3>
<ul>
<li><strong>Picbreeder Success Stories</strong>: Several instances on Picbreeder, such as the unplanned evolution of a car image from an alien face, illustrate the power of serendipity over objectives.</li>
<li><strong>Research Validation</strong>: Studies cited by the authors, including their own work published in academic conferences, validate the deleterious effects of a priori objectives on evolution and representation.</li>
</ul>
</section>
<section id="recommendations-2" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-2">Recommendations</h3>
<ul>
<li><strong>Encouraging Exploration</strong>: In fields ranging from AI development to creative arts, fostering an environment that prioritizes exploration and open-mindedness over strict objectives could lead to more significant breakthroughs.</li>
<li><strong>Reevaluating Objectives</strong>: Individuals and organizations could benefit from reevaluating how objectives are set and pursued, considering the potential limitations they impose on discovery and innovation.</li>
</ul>
</section>
</section>
<section id="the-false-compass" class="level2">
<h2 class="anchored" data-anchor-id="the-false-compass">The False Compass</h2>
<section id="summary-3" class="level3">
<h3 class="anchored" data-anchor-id="summary-3">Summary</h3>
<ul>
<li>Chapter 4 discusses the limitations of objective-driven approaches in achieving greatness or innovation, illustrating this through metaphors like the stepping stones across a misty lake and the Chinese finger trap. It argues that focusing too closely on a specific objective can lead to deception, diverting us from potential paths to unexpected discoveries.</li>
<li>The concept of non-objective searching, or collecting stepping stones without a specific end objective, is presented as an alternative approach to discovery and innovation, exemplified by natural evolution, human innovation, and systems like Picbreeder.</li>
<li>The text challenges the conventional wisdom that clear, ambitious objectives are essential for success, suggesting instead that significant achievements often result from indirect, unanticipated paths.</li>
</ul>
</section>
<section id="key-concepts-3" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-3">Key Concepts</h3>
<ul>
<li><strong>Stepping Stones:</strong> Represent the waypoints in any large, uncharted search space, critical in the path to discovery or achievement.</li>
<li><strong>Objective Function:</strong> A measure of progress towards a goal, which can be misleading if improvement in the measure doesn’t actually bring one closer to the objective.</li>
<li><strong>Deception:</strong> The problem arising when the path to an objective includes steps that do not appear to bring one closer to, or even seem to diverge from, the ultimate goal.</li>
<li><strong>Non-Objective Systems of Discovery:</strong> Systems like Picbreeder, natural evolution, and human innovation, which operate without a final objective and instead focus on collecting useful or innovative “stepping stones” without a specific end goal in mind.</li>
</ul>
</section>
<section id="noteworthy-facts-2" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-2">Noteworthy Facts</h3>
<ul>
<li>The human brain, created by natural evolution, consists of approx. 100 trillion neural connections.</li>
<li>Evolutionary stepping stones to human-level intelligence included developments such as multicellularity and bilateral symmetry, which do not resemble the end result.</li>
<li>Many of humanity’s greatest achievements, like flight or the discovery of electricity, were not the explicit objectives of their inventors’ initial endeavors.</li>
</ul>
</section>
<section id="practical-implications-2" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-2">Practical Implications</h3>
<ul>
<li>In pursuing ambitious goals, whether in personal, academic, or professional realms, a non-objective approach (focusing on collecting and exploring stepping stones) might lead to greater innovation and unexpected success.</li>
<li>Instead of setting a direct path towards an ambitious objective, it could be more productive to embrace uncertainty and remain open to paths that initially do not seem to lead directly to the goal.</li>
</ul>
</section>
<section id="recommendations-3" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-3">Recommendations</h3>
<ul>
<li>Embrace a stepping-stone approach to discovery and innovation, focusing on exploring and collecting a wide range of experiences, skills, and knowledge without always having a clear, final objective in mind.</li>
<li>Regularly reassess and question the relevance of conventional objective functions and the direction they are guiding you towards, to avoid the traps of deception.</li>
<li>Foster environments, whether in education, business, or technology development, that encourage non-linear paths and value the exploration of diverse and unexpected stepping stones.</li>
</ul>
</section>
</section>
<section id="the-interesting-and-the-novel" class="level2">
<h2 class="anchored" data-anchor-id="the-interesting-and-the-novel">The Interesting And The Novel</h2>
<section id="summary-4" class="level3">
<h3 class="anchored" data-anchor-id="summary-4">Summary</h3>
<p>Chapter 5 discusses the limitations of setting specific objectives for innovation and progress, arguing that such focus can inhibit discovery by overlooking unexpected or non-linear paths to success. Instead, it promotes the concept of seeking novelty without a predefined goal, highlighting how this approach can lead to serendipitous discoveries and advance knowledge in ways that strictly goal-oriented strategies cannot. Through examples like Picbreeder and algorithmic explorations, the text underscores the power of novelty search in driving innovation and reflecting on the natural world’s complexity through non-objective search processes.</p>
</section>
<section id="key-concepts-4" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-4">Key Concepts</h3>
<ul>
<li><strong>Novelty Over Objectives</strong>: Emphasizes the importance of seeking newness rather than strictly adhering to predefined goals.</li>
<li><strong>Stepping Stones</strong>: The chapter introduces the concept of identifying and valuing stepping stones - interim discoveries or achievements that may lead to unforeseen outcomes, not necessarily tied to an initial objective.</li>
<li><strong>Interestingness as a Guide</strong>: Proposes that what is interesting or novel can be more valuable in the long run than what is strictly useful or goal-oriented at the start.</li>
<li><strong>Non-objective Search Processes</strong>: Contrasts objective-driven search with non-objective or novelty-driven search, showing how the latter can lead to unexpected and often more fruitful outcomes.</li>
</ul>
</section>
<section id="facts" class="level3">
<h3 class="anchored" data-anchor-id="facts">Facts</h3>
<ul>
<li>New Year’s resolutions often fail, with only 12% of people achieving their stated goals.</li>
<li>Traditional objectives can be limiting, as they may not account for unforeseen stepping stones that are critical for reaching new frontiers of discovery.</li>
<li>Algorithms can be designed to seek novelty without specific objectives, leading to potentially groundbreaking discoveries.</li>
</ul>
</section>
<section id="practical-implications-3" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-3">Practical Implications</h3>
<ul>
<li><strong>Rethinking Goal Setting</strong>: Encourages individuals and organizations to evaluate the potential limitations of rigid goal setting and consider the benefits of open-ended exploration.</li>
<li><strong>Innovation Strategies</strong>: Suggests that industries focused on innovation might benefit from incorporating novelty search in their research and development processes.</li>
<li><strong>Educational Approaches</strong>: Proposes a shift in educational strategies to foster creativity and discovery, emphasizing exploration over rote achievement of predefined objectives.</li>
</ul>
</section>
<section id="recommendations-4" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-4">Recommendations</h3>
<ul>
<li>Consider adopting novelty search principles in problem-solving and creative endeavors to unlock potential avenues of innovation that may not be apparent from the outset.</li>
<li>In goal setting, allow for flexibility and the pursuit of interesting or novel paths that may divert from original objectives but offer valuable discoveries.</li>
<li>Incorporate the assessment of past achievements as stepping stones in the pursuit of novelty, rather than focusing solely on the future goals.</li>
</ul>
</section>
<section id="additional-insights-2" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-2">Additional Insights</h3>
<ul>
<li><strong>Historical Examples of Serendipitous Discoveries</strong>: The chapter highlights how many significant scientific discoveries were not the result of direct pursuit of a specific goal but rather emerged from curiosity-driven exploration.</li>
<li><strong>Limitations of Novelty Search</strong>: While advocating for the benefits of novelty search, the text acknowledges its limitations and the fact that it’s not a panacea for all challenges in discovery and innovation.</li>
<li><strong>The Role of Constraints</strong>: Discusses how the constraints of the physical world naturally limit the scope of novelty search, making it a practical approach despite initial appearances of aimlessness.</li>
</ul>
</section>
</section>
<section id="long-live-the-treasure-hunter" class="level2">
<h2 class="anchored" data-anchor-id="long-live-the-treasure-hunter">Long Live The Treasure Hunter</h2>
<section id="summary-5" class="level3">
<h3 class="anchored" data-anchor-id="summary-5">Summary</h3>
<p>Chapter 6 delves into the limitations and potential of novelty search, a method that often yields better results when not directly pursuing specific objectives. Despite its potential, novelty search is not a universal solution, and combining it with objective-driven methods does not reliably overcome the issue of deception inherent in ambitious goals. The discussion transitions into exploring the broader implications of moving away from objective-based approaches to embrace a treasure-hunting mindset that values diversity and serendipitous discovery over direct goal pursuit.</p>
</section>
<section id="key-concepts-5" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-5">Key Concepts</h3>
<ul>
<li><strong>Novelty Search:</strong> A method that can sometimes outperform objective-driven searches by valuing diversity and exploration over direct goal pursuit.</li>
<li><strong>Objective-Driven Search:</strong> The traditional method focused on achieving specific, pre-defined goals, which can sometimes be deceiving or limit discovery.</li>
</ul>
</section>
<section id="ideas" class="level3">
<h3 class="anchored" data-anchor-id="ideas">Ideas</h3>
<ul>
<li>Novelty search illustrates the power of serendipitous discovery, showing that not directly seeking an objective can lead to unexpected and valuable outcomes.</li>
<li>The limitations of objective-driven search become evident in complex or deceptive environments where direct approaches towards goals can mislead or fail.</li>
<li>Embracing a treasure-hunting approach means discarding the notion of a unified objective in favor of exploring a diversity of possibilities and being open to serendipitous discoveries.</li>
</ul>
</section>
<section id="noteworthy-facts-3" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-3">Noteworthy Facts</h3>
<ul>
<li>Novelty search has proven more successful in some experiments, such as with maze-navigating robots and biped walking, than traditional objective-driven methods.</li>
<li>Critical analysis and scientific experiments underline the limitations and potential deception inherent in exclusively objective-driven pursuits, demonstrating the value of novelty search.</li>
</ul>
</section>
<section id="critical-analysis" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis">Critical Analysis</h3>
<ul>
<li>Objective-driven searches are not always optimal, especially in complex situations where the pathway to success is not straightforward or is unknown at the outset.</li>
<li>The concept of objectives as a guiding compass is challenged, showing that a rigid focus can sometimes hinder discovery and innovation.</li>
</ul>
</section>
<section id="practical-implications-4" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-4">Practical Implications</h3>
<ul>
<li>For researchers and practitioners, understanding the limitations and potential of novelty search vs.&nbsp;objective-driven search can inspire new approaches to problem-solving and innovation.</li>
<li>This insight encourages a shift towards fostering environments where exploration, serendipity, and diversity of ideas are valued over single-minded pursuit of pre-defined goals.</li>
</ul>
</section>
<section id="recommendations-5" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-5">Recommendations</h3>
<ul>
<li><strong>In Research:</strong> Incorporate novelty search principles to explore a broader space of possibilities in scientific and technological research.</li>
<li><strong>In Innovation:</strong> Adopt a treasure hunter’s mindset to encourage diversity and serendipity in the development of new ideas, products, and solutions.</li>
<li><strong>In Organizational Strategy:</strong> Create environments that value exploration and diversity of thought, moving away from rigid objective-only focused approaches.</li>
</ul>
</section>
<section id="additional-insights-3" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-3">Additional Insights</h3>
<ul>
<li>The treasure hunter approach to discovery and innovation aligns closely with natural evolution, human innovation, and processes like Picbreeder, showcasing the potential for untapped discoveries when not solely driven by predefined objectives.</li>
<li>This approach could revolutionize various fields by fostering a culture that prioritizes exploration and the accumulation of a diverse set of ‘stepping stones’ over direct pursuit of specific targets.</li>
</ul>
</section>
</section>
<section id="unshackling-education" class="level2">
<h2 class="anchored" data-anchor-id="unshackling-education">Unshackling Education</h2>
<section id="summary-6" class="level3">
<h3 class="anchored" data-anchor-id="summary-6">Summary</h3>
<p>Chapter 7 discusses the detrimental effects of society’s obsession with objectives, particularly within the education system. It argues that focusing on measurable objectives, such as standardized test scores, not only fails to improve outcomes but can also lead to unintended negative consequences.</p>
<p>The text delves into various aspects of how objectives can mislead and hinder societal progress, emphasizing education as a case study. It challenges the reliance on standardized testing and the push towards uniform standards, advocating for a non-objective approach that embraces exploration, creativity, and diversity.</p>
</section>
<section id="key-concepts-6" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-6">Key Concepts</h3>
<ul>
<li><strong>Objective Obsession</strong>: The societal fixation on measurable goals and benchmarks, which often leads to deceptive practices and stifles creativity.</li>
<li><strong>Campbell’s Law</strong>: A principle stating that the more an indicator is used for social decision-making, the more it will corrupt the processes it is intended to monitor.</li>
<li><strong>Perverse Incentives</strong>: When measures designed to improve a situation end up causing negative, unintended consequences.</li>
</ul>
</section>
<section id="noteworthy-facts-4" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-4">Noteworthy Facts</h3>
<ul>
<li>Standardized testing and the focus on measurable outcomes can distort true learning and development.</li>
<li>Objective-driven approaches in societal progress can be deceptive, preventing the discovery of superior results.</li>
<li>Examples of perverse incentives include breeding cobras for bounties in India, which increased the venomous snake population instead of decreasing it.</li>
</ul>
</section>
<section id="critical-analysis-1" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-1">Critical Analysis</h3>
<ul>
<li>The reliance on objectives for societal progress, especially in education, is critiqued. The text presents evidence and arguments suggesting that objectives often lead to superficial or counterproductive outcomes.</li>
<li>The discussion on non-objective approaches to discovery and creativity presents an alternative to the traditional objective-driven mindset, particularly in education and innovation.</li>
</ul>
</section>
<section id="recommendations-for-education" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-for-education">Recommendations for Education</h3>
<ul>
<li><strong>Shift Away from Standardized Testing</strong>: Emphasize diverse and explorative learning over objective measures like test scores.</li>
<li><strong>Encourage Teacher Autonomy</strong>: Grant teachers the freedom to innovate and tailor their teaching methods based on student needs, moving away from a one-size-fits-all curriculum.</li>
<li><strong>Foster Diversity of Ideas</strong>: Avoid uniform standards that stifle creativity and exploration, allowing for a variety of educational practices and assessments.</li>
<li><strong>Peer-Driven Assessment</strong>: Implement a system where teachers review each other’s methodologies and outcomes instead of relying on standardized tests, promoting a culture of sharing and improvement.</li>
</ul>
</section>
<section id="additional-insights-4" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-4">Additional Insights</h3>
<ul>
<li>The critique of objective-driven efforts extends beyond education to broader societal goals, including economic indicators like GDP.</li>
<li>The narrative suggests that focusing on stepping stones, explorative processes, and divergent thinking can lead to significant discoveries and advancements, contrary to traditional objective-focused approaches.</li>
</ul>
</section>
<section id="future-perspectives" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives">Future Perspectives</h3>
<ul>
<li>The discussion hints at the potential for innovative breakthroughs in education, society, and beyond if non-objective thinking and exploration are embraced more broadly.</li>
<li>There’s a call to reassess and possibly reframe societal goals and measures of success, moving away from purely objective benchmarks towards more nuanced and holistic approaches.</li>
</ul>
</section>
</section>
<section id="unchaining-innovation" class="level2">
<h2 class="anchored" data-anchor-id="unchaining-innovation">Unchaining Innovation</h2>
<section id="summary-7" class="level3">
<h3 class="anchored" data-anchor-id="summary-7">Summary</h3>
<p>Chapter 8 delves into the impact of objective-driven pursuits on innovation across multiple domains, including science, business, and art. It highlights the historical drive for exploration and innovation, contrasting traditional exploration of the physical world with contemporary exploration in the realm of ideas. The narrative underscores the pitfalls of focusing solely on predefined objectives in the pursuit of scientific progress, arguing for a more open-ended approach that embraces uncertainty and the serendipitous discovery of stepping stones to advance knowledge and technology.</p>
</section>
<section id="key-concepts-7" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-7">Key Concepts</h3>
<ul>
<li><strong>The Myth of the Objective</strong>: The belief that defining clear, specific objectives is the best way to achieve progress and innovation.</li>
<li><strong>Stepping Stones</strong>: Unpredictable discoveries or ideas that lead to significant progress, but whose value may not be immediately evident.</li>
<li><strong>Non-objective Exploration</strong>: An approach that values curiosity-driven exploration without a predetermined goal, allowing for serendipity and unexpected discoveries.</li>
</ul>
</section>
<section id="ideas-1" class="level3">
<h3 class="anchored" data-anchor-id="ideas-1">Ideas</h3>
<ul>
<li>Innovation and exploration have historically been driven by a blend of curiosity, the promise of rewards, and the acceptance of risks.</li>
<li>The pursuit of predefined objectives can hinder scientific innovation by limiting funding to projects with clear, consensus-driven goals, ignoring the potential of risky or unconventional ideas.</li>
<li>The most transformational discoveries often arise from unpredictable stepping stones rather than direct, objective-driven research.</li>
</ul>
</section>
<section id="noteworthy-facts-5" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-5">Noteworthy Facts</h3>
<ul>
<li>Magellan’s and Giovanni da Verrazzano’s expeditions, despite their significant risks and minimal immediate rewards, paved the way for future geographical and cultural explorations.</li>
<li>Scientific progress, such as internet-based communication, significantly transformed human life within a relatively short timeframe.</li>
</ul>
</section>
<section id="recommendations-6" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-6">Recommendations</h3>
<ul>
<li><strong>Funding Diverse Paths</strong>: Embrace a funding model that values divergent thinking and the exploration of unpredictable stepping stones, even at the risk of short-term failures.</li>
<li><strong>Valuing Disagreement</strong>: Consider funding scientific projects that polarize expert opinions, as they may represent uncharted territories with the potential for breakthrough discoveries.</li>
<li><strong>Beyond Objective Metrics</strong>: Move away from objective-driven metrics in evaluating the potential impact of scientific research, recognizing the role of serendipity and the unpredictability of stepping stones.</li>
</ul>
</section>
<section id="additional-insights-5" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-5">Additional Insights</h3>
<ul>
<li>The narratives of historical explorers and modern scientific endeavors underscore a universal truth: genuine progress often stems from venturing into the unknown, guided by curiosity rather than a rigid set of objectives.</li>
<li>The critique of objective-based thinking in scientific funding sheds light on broader societal and cultural dynamics that favor conformity and risk aversion, potentially at the expense of groundbreaking innovations.</li>
</ul>
</section>
</section>
<section id="farewell-to-the-mirage" class="level2">
<h2 class="anchored" data-anchor-id="farewell-to-the-mirage">Farewell To The Mirage</h2>
<section id="summary-8" class="level3">
<h3 class="anchored" data-anchor-id="summary-8">Summary</h3>
<ul>
<li>Chapter 9 argues against the traditional emphasis on objectives, suggesting that they can often hinder creativity, discovery, and true innovation.</li>
<li>Through examples across different domains, it’s shown that an objective-driven approach might limit potential by narrowing focus, whereas exploring without fixed objectives can lead to significant, unforeseen accomplishments.</li>
<li>It stresses the importance of interestingness and novelty as guiding principles in the pursuit of innovation rather than rigid objectives.</li>
<li>Real-life success stories, like the development of Minecraft and the release of the iPad, illustrate how moving beyond traditional goals can lead to groundbreaking results.</li>
</ul>
</section>
<section id="key-concepts-8" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-8">Key Concepts</h3>
<ul>
<li><strong>Objective Myth</strong>: The belief that setting and pursuing fixed objectives is the best way to achieve success.</li>
<li><strong>Stepping Stone Principle</strong>: The idea that one innovation or discovery leads to another, forming a chain of progression that cannot be planned in advance.</li>
<li><strong>Treasure Hunter Approach</strong>: A metaphor for exploring and pursuing what feels interesting or novel without a predefined objective or goal.</li>
</ul>
</section>
<section id="noteworthy-facts-6" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-6">Noteworthy Facts</h3>
<ul>
<li>Novelty searching, as demonstrated through algorithms in robotics, showed that not having a specific end-goal can lead to more sophisticated and unexpected outcomes.</li>
<li>Examples like Minecraft and the iPad demonstrate how groundbreaking ideas often stem from combining existing concepts in new ways, without following a strict objective.</li>
<li>Great achievements historically have often resulted from curiosity-driven exploration rather than objective-driven efforts.</li>
</ul>
</section>
<section id="practical-implications-5" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-5">Practical Implications</h3>
<ul>
<li>Encourages individuals and organizations to shift from an objective-centered approach to one that values exploration, interestingness, and novelty.</li>
<li>Suggests that success and innovation can be achieved by focusing on the current context and building upon it, rather than striving towards a distant, predefined goal.</li>
<li>Proposes that the best way to encourage creativity and discovery is to allow for divergent paths and to explore based on what feels interesting or promising.</li>
</ul>
</section>
<section id="recommendations-7" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-7">Recommendations</h3>
<ul>
<li>Embrace exploration and curiosity in personal endeavors and organizational innovation strategies.</li>
<li>Cultivate an ability to perceive and pursue what is interesting or novel without being constrained by specific objectives.</li>
<li>Encourage diverse thinking and approaches in problem-solving to allow for a broader range of discoveries and innovations.</li>
<li>Invest in projects and ideas that, although may not have a clear objective, show promise of leading to new opportunities or developments.</li>
</ul>
</section>
<section id="additional-insights-6" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-6">Additional Insights</h3>
<ul>
<li>The concept of interestingness as a guiding principle suggests a more personalized and instinct-driven approach to innovation, which may align better with human creativity than rigid objectives.</li>
<li>The success of ventures like Minecraft and the iPad underlines the potential of innovation that arises from exploring combinations of existing ideas in new contexts, challenging the necessity of revolutionary technology for success.</li>
<li>The treasure hunter metaphor emphasizes the value of serendipity and the unforeseen connections between ideas, suggesting a more flexible and dynamic approach to progress.</li>
</ul>
</section>
</section>
<section id="reinterpreting-natural-evolution" class="level2">
<h2 class="anchored" data-anchor-id="reinterpreting-natural-evolution">Reinterpreting Natural Evolution</h2>
<section id="summary-9" class="level3">
<h3 class="anchored" data-anchor-id="summary-9">Summary</h3>
<p>Chapter 10 explores the idea that the creative and diverse outcomes of processes like natural evolution are not the result of objective-driven pursuits but rather emerge from non-objective, exploratory mechanisms. The book challenges traditional views of goal-oriented progression in evolution, suggesting that the diversity and complexity of life arise from a process that accumulates novelties and explores different ways to achieve basic survival and reproduction, akin to non-objective searches observed in other domains.</p>
</section>
<section id="key-concepts-9" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-9">Key Concepts</h3>
<ul>
<li><strong>Non-Objective Search</strong>: A mechanism that promotes exploration and discovery without predefined objectives, diverging from traditional goal-driven models.</li>
<li><strong>Natural Evolution</strong>: Presented as an ultimate example of non-objective search, creating vast biodiversity through processes like genetic drift, mutation, natural selection, and exaptation without an overarching objective.</li>
<li><strong>Darwin’s Discovery</strong>: Illuminates that slight imperfections in self-copying mechanisms (mutations) combined with natural selection drive the evolutionary process, countering the perception of intelligent design.</li>
<li><strong>Fitness and Natural Selection</strong>: Clarified as not the sole drivers of evolution; competition exists but is only one of many forces, and not necessarily the one fostering the most creativity and diversity.</li>
<li><strong>Perspectives on Evolution</strong>: Different interpretations of evolution’s mechanisms highlight debates within the field, such as the importance of natural selection versus other forces like genetic drift or the role of historical contingencies.</li>
<li><strong>Minimal Criteria Search</strong>: A proposed model for understanding evolution, focusing on the accumulation of diverse forms of life that meet the basic criteria of surviving and reproducing rather than optimizing for specific objectives.</li>
</ul>
</section>
<section id="noteworthy-facts-7" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-7">Noteworthy Facts</h3>
<ul>
<li>Life on Earth began with simple single-celled organisms, which still dominate in terms of numbers and biomass, despite the emergence of complex multicellular life.</li>
<li>The Cambrian explosion was a pivotal event in natural evolution, leading to the diversification of complex organisms over a relatively short geological period.</li>
</ul>
</section>
<section id="recommendations-8" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-8">Recommendations</h3>
<ul>
<li><strong>Re-evaluation of Objectives in Research and Exploration</strong>: Suggests shifting focus from objective-driven to non-objective searches in various fields, potentially leading to more diverse and creative outcomes.</li>
<li><strong>Application of Non-Objective Models</strong>: Encourages the application of concepts like minimal criteria searches and novelty search with local competition in computational and robotic systems to mimic the diversification seen in natural evolution.</li>
</ul>
</section>
<section id="additional-insights-7" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-7">Additional Insights</h3>
<ul>
<li>The book posits an interesting parallel between natural evolution and human innovation processes, highlighting the commonality of serendipity and the accumulation of novelties over the pursuit of specific objectives.</li>
<li>It proposes reinterpreting natural evolution through the lens of non-objective search, offering an alternative perspective that centers on evolution’s creativity and accumulation of diversity rather than on competitiveness and objective fitness.</li>
</ul>
</section>
</section>
<section id="objectives-and-the-quest-for-ai" class="level2">
<h2 class="anchored" data-anchor-id="objectives-and-the-quest-for-ai">Objectives And The Quest For AI</h2>
<section id="summary-10" class="level3">
<h3 class="anchored" data-anchor-id="summary-10">Summary</h3>
<p>Chapter 11 explores the impact of goal-oriented thinking in scientific discovery, particularly in the field of Artificial Intelligence (AI). It presents a critical examination of how the reliance on objectives and benchmarks can stifle innovation and overlook important insights or alternative research paths.</p>
<p>Through analysis and case studies, the text argues for a more open-ended approach to scientific inquiry and AI research, suggesting that unexpected discoveries and progress often result from exploratory processes rather than targeted searches for predetermined goals.</p>
</section>
<section id="key-concepts-10" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-10">Key Concepts</h3>
<ul>
<li><strong>Objective-Driven Thinking</strong>: A common approach in both society and science where progress is measured against specific, predefined goals.</li>
<li><strong>Science and Innovation</strong>: Recognized for advancing human knowledge and capabilities, science’s progress is attributed to both structured and exploratory research.</li>
<li><strong>AI Research Landscape</strong>: Highlighted as a field striving for the ambitious goal of creating highly intelligent machines, AI research is shaped by its community’s focus on objectives, benchmarks, and peer reviews.</li>
</ul>
</section>
<section id="ideas-2" class="level3">
<h3 class="anchored" data-anchor-id="ideas-2">Ideas</h3>
<ul>
<li>Emphasizing “anything goes” in scientific inquiry can prevent the limiting effects of strictly adhering to traditional methods and objectives.</li>
<li>The structure of scientific communities, including specialization and cultural differences, significantly influences the progress and direction of research.</li>
<li>The practice of setting objectives can inadvertently narrow the scope of inquiry and innovation within the scientific community and specifically within AI research.</li>
</ul>
</section>
<section id="recommendations-9" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-9">Recommendations</h3>
<ul>
<li><strong>Promote Open-Ended Exploration</strong>: Encourage research approaches that allow for divergence from established goals to ensure a broader exploration of possibilities.</li>
<li><strong>Rethink Peer Review and Publication Norms</strong>: Adjust the criteria for evaluating and sharing scientific work to value innovation and potential impact over adherence to benchmarks and performance metrics.</li>
<li><strong>Cultivate Interdisciplinary Collaboration</strong>: Encourage collaboration across different scientific disciplines to foster new perspectives and breakthroughs that might not emerge within the confines of specialized communities.</li>
</ul>
</section>
<section id="critical-analysis-2" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-2">Critical Analysis</h3>
<ul>
<li>The reliance on objectives and benchmarks in AI research may unknowingly limit the exploration of novel and potentially groundbreaking ideas.</li>
<li>The structural and cultural dynamics of scientific communities play critical roles in shaping research agendas and determining which paths of inquiry are pursued or neglected.</li>
<li>The evaluation processes, including peer review in scientific publication, may need reform to better reward innovative thinking and exploratory research efforts.</li>
</ul>
</section>
<section id="additional-insights-8" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-8">Additional Insights</h3>
<ul>
<li>As illustrated by the case study of AI, the challenge lies not in abandoning goals entirely but in recognizing and leveraging the unanticipated directions and opportunities that arise during the exploratory process.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>personal-growth</category>
  <category>professional-growth</category>
  <category>ai</category>
  <guid>christianjmills.com/posts/why-greatness-cannot-be-planned-book-notes/</guid>
  <pubDate>Fri, 23 Feb 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Notes on Where is My Flying Car Pt. 03</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/where-is-my-flying-car-book-notes/part-3/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/where-is-my-flying-car-book-notes.html"><strong>Where is My Flying Car?</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Ch. 14: The Dawn of Robots</li>
<li>Ch. 15: The Second Atomic Age</li>
<li>Ch. 16: Tom Swift and His Flying Car</li>
<li>Ch. 17: Escape Velocity</li>
<li>Ch. 18: Metropolis</li>
<li>Ch. 19: Engineer’s Dreams</li>
<li>Ch. 20: Rocket to the Resistance</li>
</ul>
<section id="the-dawn-of-robots" class="level2">
<h2 class="anchored" data-anchor-id="the-dawn-of-robots">The Dawn of Robots</h2>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>Chapter 14 explores the evolution, current state, and future of robots and artificial intelligence (AI), drawing on historical advancements in technology to predict the capabilities of future AI and robotics. It discusses the societal and ethical implications of advanced AI and the potential for robots to assume roles across various sectors, including healthcare, law, and everyday domestic tasks.</p>
</section>
<section id="key-concepts" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts">Key Concepts</h3>
<ul>
<li><strong>Evolution of AI and Robotics</strong>: Describes the historical development from simple machine learning to complex AI systems capable of deep learning and neural networking, leading to significant advancements in robotics and AI capabilities.</li>
<li><strong>Future of Robotics</strong>: Predicts the integration of AI into everyday life, foreseeing robots with human-like capabilities in reading, writing, talking, and listening, as well as specialized professional tasks.</li>
<li><strong>Ethical Considerations</strong>: Addresses the moral and ethical challenges of creating highly intelligent and autonomous robots, emphasizing the importance of designing AI systems that prioritize human commands and ethical guidelines.</li>
</ul>
</section>
<section id="ideas" class="level3">
<h3 class="anchored" data-anchor-id="ideas">Ideas</h3>
<ul>
<li>AI and robotics have evolved from rudimentary technologies to systems capable of deep learning and complex problem-solving.</li>
<li>Future robots are expected to perform tasks with human-like efficiency, potentially transforming various professional fields and daily life.</li>
<li>Ethical programming and control mechanisms are crucial in ensuring that AI systems act in the best interests of humanity.</li>
</ul>
</section>
<section id="noteworthy-facts" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts">Noteworthy Facts</h3>
<ul>
<li>AI systems like GPT-3 can produce human-like text but lack the comprehension of the content they generate.</li>
<li>The productivity of manufacturing workers has increased significantly, highlighting the potential for automation to reshape the workforce.</li>
<li>Ethical considerations in AI development focus on creating systems that follow human commands and make morally sound decisions.</li>
</ul>
</section>
<section id="practical-implications" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications">Practical Implications</h3>
<ul>
<li>The advancement of AI and robotics could lead to the automation of various jobs, necessitating societal adjustments to employment and education systems.</li>
<li>Ethical AI development requires careful consideration of the potential consequences of autonomous decision-making by robots.</li>
<li>The integration of AI into professional services could significantly improve the efficiency and accessibility of healthcare, legal advice, and other services.</li>
</ul>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<ul>
<li>Focus on developing AI and robotics technologies that enhance human capabilities without replacing human roles in critical decision-making processes.</li>
<li>Invest in ethical AI research to ensure future robots adhere to moral and ethical standards beneficial to society.</li>
<li>Prepare for the societal impacts of advanced robotics, including potential job displacement and the need for new education and training programs.</li>
</ul>
</section>
<section id="critical-analysis" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis">Critical Analysis</h3>
<ul>
<li>The optimistic view of AI and robotics’ future must be balanced with caution regarding ethical and societal impacts.</li>
<li>While AI advancements promise significant benefits, there is a need for robust frameworks to address the potential risks and ethical dilemmas they present.</li>
<li>The emphasis on AI’s potential to improve professional services highlights the importance of human oversight in ensuring these technologies are used responsibly.</li>
</ul>
</section>
<section id="additional-insights" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights">Additional Insights</h3>
<ul>
<li>The progression of AI technology has often paralleled historical technological advancements, suggesting that society may adapt to and integrate advanced AI and robotics as it has with past innovations.</li>
<li>The concept of AI surpassing human intelligence raises questions about identity, autonomy, and the essence of human expertise.</li>
<li>The development of ethical AI systems reflects broader societal values and priorities, underlining the importance of inclusive and multidisciplinary approaches to AI research and development.</li>
</ul>
</section>
</section>
<section id="the-second-atomic-age" class="level2">
<h2 class="anchored" data-anchor-id="the-second-atomic-age">The Second Atomic Age</h2>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary</h3>
<p>Chapter 15 delves into the evolution of technology and energy sources, comparing the industrial revolution’s leap from steam to internal combustion engines with the potential of the second atomic age powered by nanotechnology and nuclear advancements. It discusses how nanotech can revolutionize nuclear technology through isotopic separation, extreme structure building, and enhancing productive power.</p>
<p>The chapter also explores the vast potential of renewable energy sources, like uranium from seawater, and the development of safe, efficient, and small-scale nuclear reactors. Additionally, it covers the challenges and possibilities of both cold and hot fusion technologies, the current state of fusion research, and the implications for future energy production.</p>
</section>
<section id="key-concepts-1" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-1">Key Concepts</h3>
<ul>
<li><strong>Second Atomic Age</strong>: A future era characterized by the synergy of nanotechnology and nuclear technology, enabling significant advances in energy production and efficiency.</li>
<li><strong>Nanotechnology’s Role</strong>: Nanotech will revolutionize nuclear technology by enabling isotopic separation, constructing precise structures, and significantly enhancing productive power.</li>
<li><strong>Renewable Energy Potential</strong>: The chapter highlights the immense potential of uranium from seawater as a nearly inexhaustible energy source, facilitated by nanotechnology.</li>
<li><strong>Nuclear Reactor Innovations</strong>: Discusses the development of safe, efficient, and scalable nuclear reactors, including the potential for small, clean, and powerful nuclear energy sources.</li>
</ul>
</section>
<section id="practical-implications-1" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-1">Practical Implications</h3>
<ul>
<li><strong>Energy Production</strong>: Nanotechnology could enable the use of nuclear energy in more efficient, safe, and environmentally friendly ways, drastically changing global energy production.</li>
<li><strong>Environmental Impact</strong>: The extraction of uranium from seawater and the development of clean nuclear reactors could significantly reduce the environmental impact of energy generation.</li>
<li><strong>Technological Innovation</strong>: Advances in nuclear technology and nanotech could lead to breakthroughs in other fields, such as medicine, space exploration, and material science.</li>
</ul>
</section>
<section id="supporting-evidence" class="level3">
<h3 class="anchored" data-anchor-id="supporting-evidence">Supporting Evidence</h3>
<ul>
<li><strong>Isotopic Separation</strong>: Nanotech allows for precise separation of isotopes, making nuclear technology more feasible and efficient.</li>
<li><strong>Uranium from Seawater</strong>: The feasibility of extracting uranium from seawater for energy production, highlighting the potential for a sustainable energy source.</li>
<li><strong>Safe Nuclear Reactors</strong>: The development of small, safe nuclear reactors, such as those based on the Triga design, demonstrates the potential for widespread use of nuclear energy.</li>
</ul>
</section>
<section id="recommendations-1" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-1">Recommendations</h3>
<ul>
<li><strong>Invest in Nanotech and Nuclear Research</strong>: To unlock the full potential of the second atomic age, significant investment in nanotechnology and nuclear research is recommended.</li>
<li><strong>Develop Safe Nuclear Reactor Designs</strong>: Encourage the development of new nuclear reactor designs that are safe, efficient, and scalable.</li>
<li><strong>Explore Renewable Energy Sources</strong>: Continue to explore and invest in renewable energy sources, such as uranium extraction from seawater, to diversify and secure the future energy supply.</li>
</ul>
</section>
<section id="additional-insights-1" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-1">Additional Insights</h3>
<ul>
<li><strong>Cold Fusion</strong>: Despite historical controversy, recent research into Low Energy Nuclear Reactions (LENR) suggests potential for future energy production methods.</li>
<li><strong>Fusion Technology</strong>: Current efforts in hot fusion research, including various startups and experiments, indicate ongoing progress toward achieving practical fusion energy.</li>
</ul>
</section>
<section id="critical-analysis-1" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-1">Critical Analysis</h3>
<ul>
<li><strong>Challenges in Fusion Energy</strong>: The text underscores the significant technical challenges that have historically impeded the development of practical fusion energy, while also highlighting recent advancements that may overcome these obstacles.</li>
<li><strong>Economic and Environmental Considerations</strong>: The potential economic benefits and environmental impacts of advanced nuclear technologies and renewable energy sources are significant, suggesting a need for careful consideration and planning in their development and implementation.</li>
</ul>
<p>The chapter outlines a vision for a future where technological advancements in nanotechnology and nuclear energy could revolutionize how we produce and consume energy, offering solutions to current environmental and energy challenges. However, realizing this vision will require overcoming significant technical, economic, and social hurdles.</p>
</section>
</section>
<section id="tom-swift-and-his-flying-car" class="level2">
<h2 class="anchored" data-anchor-id="tom-swift-and-his-flying-car">Tom Swift and His Flying Car</h2>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<p>Chapter 16 explores the concept, feasibility, technological requirements, and societal implications of flying cars, tracing the progression from early skepticism towards automobiles to the potential reality of personal air transportation. It discusses the evolution of aviation technology, energy challenges, the potential of electric and ionic propulsion, regulatory and logistical considerations for air traffic management, and the transformative impact of nanotechnology on vehicle design and performance.</p>
</section>
<section id="key-concepts-2" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-2">Key Concepts</h3>
<ul>
<li><strong>Feasibility of Flying Cars</strong>: Acknowledges the technological advancements that make flying cars a realistic possibility.</li>
<li><strong>Energy and Propulsion</strong>: Highlights the challenges related to power sources, including electric motors, fuel cells, and the innovative concept of ionic propulsion.</li>
<li><strong>Regulatory and Logistical Considerations</strong>: Discusses air traffic control (ATC) limitations and the need for a decentralized system to manage the expected increase in air traffic with personal air vehicles.</li>
<li><strong>Impact of Nanotechnology</strong>: Envisions significant improvements in flying car capabilities through advancements in nanotechnology, making them lighter, more efficient, and potentially transforming them into private spaceships.</li>
</ul>
</section>
<section id="ideas-1" class="level3">
<h3 class="anchored" data-anchor-id="ideas-1">Ideas</h3>
<ul>
<li>The progression from skepticism about automobiles to considering flying cars underscores society’s capacity for technological acceptance and adaptation.</li>
<li>The transition to flying cars requires overcoming substantial energy, safety, and regulatory challenges.</li>
<li>Decentralized air traffic management could revolutionize personal and commercial aviation, making flying cars more viable.</li>
<li>Nanotechnology is poised to be a game-changer, offering solutions to current limitations in flying car design and functionality.</li>
</ul>
</section>
<section id="practical-implications-2" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-2">Practical Implications</h3>
<ul>
<li><strong>Urban Planning and Infrastructure</strong>: Cities may need to adapt by developing vertical takeoff and landing (VTOL) infrastructure and revising zoning laws.</li>
<li><strong>Environmental Considerations</strong>: Flying cars could have significant environmental impacts, necessitating clean energy solutions.</li>
<li><strong>Safety and Training</strong>: As flying becomes more accessible, comprehensive safety regulations and pilot training programs will be essential.</li>
</ul>
</section>
<section id="recommendations-2" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-2">Recommendations</h3>
<ul>
<li><strong>Investment in Renewable Energy Sources</strong>: To support the energy demands of flying cars, especially those utilizing electric and ionic propulsion.</li>
<li><strong>Development of Advanced Materials</strong>: Focus on nanotechnology research to create lighter, more durable materials for air vehicle construction.</li>
<li><strong>Enhanced Air Traffic Control Systems</strong>: Implement decentralized, digital air traffic management systems to safely accommodate increased air traffic.</li>
<li><strong>Public and Private Sector Collaboration</strong>: Encourage partnerships to innovate and regulate flying car technology, ensuring safety, efficiency, and accessibility.</li>
</ul>
</section>
<section id="future-perspectives" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives">Future Perspectives</h3>
<ul>
<li>With advancements in technology and infrastructure, flying cars could become an integral part of daily transportation, offering faster travel times and redefining mobility.</li>
<li>The societal impact of widespread flying car adoption could be profound, affecting everything from daily commutes to global travel, and requiring new approaches to urban planning, environmental protection, and international regulations.</li>
</ul>
</section>
</section>
<section id="escape-velocity" class="level2">
<h2 class="anchored" data-anchor-id="escape-velocity">Escape Velocity</h2>
<section id="summary-3" class="level3">
<h3 class="anchored" data-anchor-id="summary-3">Summary</h3>
<p>Chapter 17 reflects on the stagnation and regression in space travel since the Apollo missions, attributing it to bureaucratic inertia and a lack of continued political and economic motivation. It also discusses the potential for future space travel, including commercial and nuclear-powered spaceflight, and the necessity for humanity to become a space-faring civilization to avoid extinction.</p>
</section>
<section id="key-concepts-3" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-3">Key Concepts</h3>
<ul>
<li><strong>Stagnation in Space Travel</strong>: Post-Apollo missions, space exploration saw a lack of progress, attributed to political motivations and bureaucratic challenges.</li>
<li><strong>Future of Space Travel</strong>: Discusses the potential for nuclear-powered rockets and commercial spaceflight to revolutionize space exploration and human colonization of space.</li>
<li><strong>Technological and Societal Implications</strong>: Explores how advancements in technology could enable humanity to overcome current limitations and expand into the solar system and beyond.</li>
</ul>
</section>
<section id="noteworthy-facts-1" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-1">Noteworthy Facts</h3>
<ul>
<li><strong>Challenger Disaster</strong>: Highlighted the risks and consequences of bureaucratic mismanagement in space exploration.</li>
<li><strong>Cost of Space Travel</strong>: The shuttle program failed to achieve its goal of reducing costs, highlighting economic challenges in space exploration.</li>
<li><strong>Nuclear Propulsion</strong>: Described as a viable method for efficient solar system navigation, offering significantly reduced travel times to other planets.</li>
</ul>
</section>
<section id="practical-implications-3" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-3">Practical Implications</h3>
<ul>
<li><strong>Commercial Space Travel</strong>: The rise of private space companies could lead to more efficient and cost-effective space travel.</li>
<li><strong>Nuclear-Powered Rockets</strong>: Could enable human exploration and colonization of the solar system, changing the future of human civilization.</li>
<li><strong>Space Colonization</strong>: Offers a solution to Earth’s resource limitations and the existential threat of having all humanity on a single planet.</li>
</ul>
</section>
<section id="recommendations-3" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-3">Recommendations</h3>
<ul>
<li><strong>Invest in Nuclear Propulsion Research</strong>: To make interplanetary travel feasible and efficient.</li>
<li><strong>Support Commercial Space Ventures</strong>: Encourage private investment and innovation in space technology.</li>
<li><strong>Prepare for Space Colonization</strong>: Develop technologies and strategies for long-term living in space, including habitat construction and resource utilization.</li>
</ul>
</section>
<section id="critical-analysis-2" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-2">Critical Analysis</h3>
<ul>
<li>The stagnation in space exploration highlights a broader issue of technological and bureaucratic inertia that can hinder progress. The shift towards private space ventures and potential nuclear propulsion offers new paths forward but requires careful consideration of ethical, environmental, and safety concerns.</li>
</ul>
</section>
<section id="additional-insights-2" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-2">Additional Insights</h3>
<ul>
<li><strong>Space as a Frontier</strong>: Space offers a new frontier for humanity, providing opportunities for exploration, economic expansion, and the potential for new societal models.</li>
<li><strong>Human Adaptation</strong>: Future space colonization may require not just technological advancement but also biological adaptation, including genetic or cybernetic enhancements to thrive in extraterrestrial environments.</li>
</ul>
</section>
<section id="future-perspectives-1" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-1">Future Perspectives</h3>
<ul>
<li>The development of space travel and colonization technologies could fundamentally alter human civilization, offering new opportunities for growth, exploration, and the potential to safeguard the future of humanity against existential threats.</li>
</ul>
</section>
</section>
<section id="metropolis" class="level2">
<h2 class="anchored" data-anchor-id="metropolis">Metropolis</h2>
<section id="summary-4" class="level3">
<h3 class="anchored" data-anchor-id="summary-4">Summary</h3>
<p>Chapter 18 discusses the evolution of urban development, focusing on the shift towards living in artificial environments, especially in cities and the potential future of constructing mile-high or even 10-mile-high buildings. It explores the idea of vertical living as a solution to land scarcity, examines the technological advancements necessary for such constructions, and critiques current city planning ideologies while envisioning a future where cities are designed for efficiency, connectivity, and sustainability.</p>
</section>
<section id="key-concepts-4" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-4">Key Concepts</h3>
<ul>
<li><strong>Vertical Living:</strong> Emphasizes the concept of constructing tall buildings to accommodate more people in less space, with the Burj Khalifa cited as a current pinnacle of such development.</li>
<li><strong>Technological Advancements:</strong> Discusses the role of materials science, including the development of steel-aluminum alloys and the potential of nanotechnology, in enabling the construction of much taller buildings.</li>
<li><strong>Urban Planning Critiques:</strong> Criticizes current city planning approaches, particularly the focus on densification and the neglect of efficient transportation infrastructure.</li>
<li><strong>Future Urban Environments:</strong> Imagines future cities with advanced transportation systems, including flying cars and multi-level traffic interconnects, to improve living conditions and reduce travel times.</li>
</ul>
</section>
<section id="practical-implications-4" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-4">Practical Implications</h3>
<ul>
<li><strong>Housing and Urban Development:</strong> Insights into how future buildings could revolutionize housing, suggesting a shift towards more sustainable and efficient urban living spaces.</li>
<li><strong>Transportation:</strong> Proposes the development of advanced transportation systems to solve current inefficiencies and improve connectivity within cities.</li>
<li><strong>Environmental Sustainability:</strong> Highlights the potential for vertical cities and advanced transportation to significantly reduce human impact on the environment.</li>
</ul>
</section>
<section id="critical-analysis-3" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-3">Critical Analysis</h3>
<ul>
<li><strong>Feasibility of Construction:</strong> While the text discusses the potential for mile-high buildings and cities with advanced infrastructure, it acknowledges the current technological and economic limitations.</li>
<li><strong>Social and Economic Considerations:</strong> Raises questions about the accessibility of these futuristic urban developments and their implications for social equity.</li>
<li><strong>Environmental Impact:</strong> While aiming for sustainability, the construction and maintenance of such massive structures and transportation systems could have unforeseen environmental consequences.</li>
</ul>
</section>
<section id="future-perspectives-2" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-2">Future Perspectives</h3>
<ul>
<li><strong>Nanotechnology and Urban Development:</strong> Speculates on the role of nanotechnology in overcoming current limitations to building construction and materials science.</li>
<li><strong>Dynamic and Sustainable Cities:</strong> Envisions a future where cities are not only more efficient and less impactful on the environment but also offer enhanced quality of life through improved design and technology.</li>
<li><strong>Integration of Nature and Urban Environments:</strong> Proposes innovative ways to incorporate green spaces and environmental considerations into urban development, moving towards a harmonious balance between human habitation and the natural world.</li>
</ul>
</section>
<section id="additional-insights-3" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-3">Additional Insights</h3>
<ul>
<li><strong>Historical Context:</strong> Provides a brief history of skyscrapers and urban development, linking past innovations to future possibilities.</li>
<li><strong>Technological Innovation:</strong> Highlights the importance of continuous innovation in materials science and engineering for the future of urban construction.</li>
<li><strong>Urban Planning Philosophy:</strong> Challenges conventional urban planning philosophies by advocating for a holistic approach that prioritizes efficient transportation and sustainable living spaces.</li>
</ul>
</section>
</section>
<section id="engineers-dreams" class="level2">
<h2 class="anchored" data-anchor-id="engineers-dreams">Engineer’s Dreams</h2>
<section id="summary-5" class="level3">
<h3 class="anchored" data-anchor-id="summary-5">Summary</h3>
<p>Chapter 19 explores the potential for revolutionary advancements in physics and technology, focusing on anti-gravity, quantum mechanics interpretations, and space exploration enhancements. It includes a critical analysis of current theoretical physics, proposals for space infrastructure like space piers, and advanced concepts like weather machines and Dyson spheres.</p>
</section>
<section id="key-concepts-5" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-5">Key Concepts</h3>
<ul>
<li><strong>Anti-gravity and Reactionless Thrusters</strong>: The text discusses the long-standing fascination with and theoretical challenges of creating anti-gravity or reactionless drive systems for vehicles, suggesting that our understanding of gravity may evolve to enable such technologies.</li>
<li><strong>Quantum Mechanics and Theoretical Physics</strong>: It critiques the current state of theoretical physics, particularly in quantum mechanics and the interpretations of quantum phenomena, advocating for a new perspective that could revolutionize our understanding and technology.</li>
<li><strong>Space Exploration Infrastructure</strong>: Proposes innovative infrastructure, such as space piers, to bypass the rocket equation and make space travel more feasible and economical.</li>
</ul>
</section>
<section id="ideas-2" class="level3">
<h3 class="anchored" data-anchor-id="ideas-2">Ideas</h3>
<ul>
<li><strong>Revolution in Physics</strong>: The potential for a major breakthrough in basic physics that could lead to new technologies, including anti-gravity, based on a deeper understanding of quantum mechanics and gravity.</li>
<li><strong>Space Pier Concept</strong>: A detailed proposal for a structure extending into space to launch payloads into orbit more efficiently, using less energy and without the need for traditional rocket propulsion.</li>
</ul>
</section>
<section id="practical-implications-5" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-5">Practical Implications</h3>
<ul>
<li><strong>Space Travel and Exploration</strong>: Significantly reduced costs and increased accessibility to space travel could result from the space pier concept, potentially transforming space exploration and the space economy.</li>
<li><strong>Energy and Climate Control</strong>: Advanced technologies such as weather machines and Dyson spheres could offer unprecedented control over Earth’s climate and energy resources, addressing challenges like climate change and energy scarcity.</li>
</ul>
</section>
<section id="critical-analysis-4" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-4">Critical Analysis</h3>
<ul>
<li>The skepticism towards current theoretical physics, particularly the Copenhagen interpretation of quantum mechanics, suggests a need for a paradigm shift that embraces more coherent and physically intuitive theories.</li>
<li>The proposed technologies, while theoretically plausible, would require significant advancements in material science, energy production, and global cooperation to become reality.</li>
</ul>
</section>
<section id="recommendations-4" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-4">Recommendations</h3>
<ul>
<li><strong>Further Research</strong>: Encourage interdisciplinary research efforts to explore the theoretical foundations of anti-gravity and reactionless thrust, aiming to bridge the gap between current physics understanding and the proposed technologies.</li>
<li><strong>Investment in Nanotechnology and Material Science</strong>: To realize the proposed space infrastructure and energy systems, substantial investment in nanotechnology and material science is necessary.</li>
</ul>
</section>
<section id="additional-insights-4" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-4">Additional Insights</h3>
<ul>
<li>The discussion on quantum mechanics and the critique of its current interpretations highlight the deep philosophical and scientific questions still unanswered in physics, emphasizing the potential for groundbreaking discoveries that could change our interaction with the universe.</li>
<li>The concept of a Kardashev Type 1 civilization and the steps toward achieving such a status through energy and space technology development provide a visionary roadmap for humanity’s future progress.</li>
</ul>
</section>
</section>
<section id="rocket-to-the-resistance" class="level2">
<h2 class="anchored" data-anchor-id="rocket-to-the-resistance">Rocket to the Resistance</h2>
<section id="summary-6" class="level3">
<h3 class="anchored" data-anchor-id="summary-6">Summary</h3>
<p>Chapter 20 explores the transformative impact of technology and science on humanity’s future, contrasting historical skepticism with contemporary possibilities.</p>
<ul>
<li>Discusses the end of traditional agriculture through technological advancements in food production and the potential for lab-grown meat.</li>
<li>Presents the choice facing society: embrace a static existence or pursue dynamic growth enabled by technology, potentially leading to space colonization and beyond.</li>
</ul>
</section>
<section id="key-concepts-6" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-6">Key Concepts</h3>
<ul>
<li><strong>Technological Revolutions:</strong> The shift from traditional agriculture to controlled environment agriculture (CEA) and lab-grown meat signifies a major technological revolution, echoing past shifts like the Industrial Revolution.</li>
<li><strong>Future of Humanity:</strong> Envisions two paths for humanity influenced by technology: a static, comfortable existence versus a dynamic, growth-oriented future with space exploration and limitless energy.</li>
<li><strong>Societal Choice:</strong> The critical decision between maintaining the status quo or embracing technological advancements to unlock human potential and inherit the stars.</li>
</ul>
</section>
<section id="noteworthy-facts-2" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-2">Noteworthy Facts</h3>
<ul>
<li>Lab-grown meat costs have plummeted from $325,000 per pound in 2013 to $363 just five years later, with Singapore approving cultured chicken meat for sale.</li>
<li>Controlled environment agriculture allows for up to 300 times more produce per square foot than traditional methods, independent of external climate conditions.</li>
<li>Technological advancements could potentially end traditional agriculture within a century, transforming human society and its relationship with the planet.</li>
</ul>
</section>
<section id="practical-implications-6" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-6">Practical Implications</h3>
<ul>
<li><strong>Agricultural Innovation:</strong> The rise of CEA and lab-grown meat could drastically reduce water usage, land requirements, and the carbon footprint associated with traditional farming.</li>
<li><strong>Space Exploration:</strong> Technological advancements may make living on other planets or in space feasible, addressing concerns about Earth’s carrying capacity and resource depletion.</li>
<li><strong>Energy Consumption:</strong> The potential for near-limitless energy sources could transform transportation, manufacturing, and daily life, making previously unimaginable technologies feasible.</li>
</ul>
</section>
<section id="recommendations-5" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-5">Recommendations</h3>
<ul>
<li><strong>Invest in R&amp;D:</strong> Governments and private entities should invest heavily in research and development in fields like nanotechnology, biotechnology, and energy.</li>
<li><strong>Regulatory Adaptation:</strong> Legal and regulatory frameworks must evolve to encourage innovation while ensuring safety and ethical considerations.</li>
<li><strong>Education and Training:</strong> Prepare the workforce for future industries through education in STEM fields, emphasizing creativity, critical thinking, and adaptability.</li>
<li><strong>Public Engagement:</strong> Increase public awareness and engagement with science and technology to foster a society that values and supports innovation.</li>
</ul>
</section>
<section id="critical-analysis-5" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-5">Critical Analysis</h3>
<ul>
<li>The text highlights a crucial tension between technological potential and societal readiness. While technology offers solutions to many current problems, societal attitudes, regulations, and fear of the unknown can stifle innovation.</li>
<li>There is an underlying assumption that technological advancement will lead to positive outcomes. However, the ethical, environmental, and economic impacts of such rapid changes need careful consideration to avoid exacerbating inequalities or creating new problems.</li>
<li>The choice between a static or dynamic future is framed as binary, but the reality is likely to be more nuanced. A balanced approach, incorporating elements of both paths, might be necessary to navigate the challenges of technological transformation.</li>
</ul>
</section>
<section id="additional-insights-5" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-5">Additional Insights</h3>
<ul>
<li>The historical perspective on technological skepticism versus achievements offers a valuable lesson in the dangers of underestimating human ingenuity and the potential of science.</li>
<li>The concept of a “Second Atomic Age” suggests a pivotal moment in human history, where mastering energy at a fundamental level could redefine civilization’s capabilities and aspirations.</li>
<li>The role of science fiction in shaping public perceptions and aspirations for the future is significant, highlighting the need for narratives that inspire optimism and ambition towards technological progress.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>history</category>
  <guid>christianjmills.com/posts/where-is-my-flying-car-book-notes/part-3/</guid>
  <pubDate>Sun, 18 Feb 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Notes on Where is My Flying Car Pt. 02</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/where-is-my-flying-car-book-notes/part-2/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/where-is-my-flying-car-book-notes.html"><strong>Where is My Flying Car?</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Ch. 9: Sealing and Visibility Unlimited</li>
<li>Ch. 10: Dialogue Concerning the Two Great Systems of the World</li>
<li>Ch. 11: The Atomic Age</li>
<li>Ch. 12: When Worlds Collide</li>
<li>Ch. 13: When the Sleeper Wakes</li>
</ul>
<section id="sealing-and-visibility-unlimited" class="level2">
<h2 class="anchored" data-anchor-id="sealing-and-visibility-unlimited">Sealing and Visibility Unlimited</h2>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>Chapter 9 explores the feasibility, challenges, and potential of personal aviation, including flying cars and general aviation (GA) aircraft, in transforming transportation. It discusses the technological, regulatory, and practical barriers to widespread adoption of personal aircraft, while also delving into the author’s own experience of becoming a pilot to understand the complexities of flying.</p>
</section>
<section id="key-concepts" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts">Key Concepts</h3>
<ul>
<li><strong>Feasibility of Flying Cars</strong>: Since the 1930s, the technical capability to manufacture flying cars for personal use has existed, but societal, regulatory, and practical barriers have prevented widespread adoption.</li>
<li><strong>Challenges in Adoption</strong>: The low percentage of licensed pilots among the population and misconceptions about the difficulty and dangers of flying are major obstacles.</li>
<li><strong>General Aviation Insights</strong>: The author’s journey to becoming a pilot and acquiring a GA aircraft provides firsthand insights into the joys and challenges of personal aviation.</li>
<li><strong>Regulatory and Technical Barriers</strong>: The text highlights how regulations, the aging fleet of GA aircraft, and the specific technical challenges of flying (like navigation and dealing with weather conditions) limit the accessibility of personal aviation.</li>
<li><strong>Safety and Insurance</strong>: Despite perceptions, GA is presented as relatively safe and affordable in terms of insurance, comparable to car insurance.</li>
</ul>
</section>
<section id="ideas" class="level3">
<h3 class="anchored" data-anchor-id="ideas">Ideas</h3>
<ul>
<li><strong>Learning to Fly</strong>: Flying is a learnable skill within the capability of a significant portion of the population, despite common perceptions of its complexity and danger.</li>
<li><strong>Automation and Assistance</strong>: Advances in automation, such as GPS and autopilot systems, have made flying more accessible and could potentially enable more people to pilot their own aircraft safely.</li>
<li><strong>Economic and Time Productivity</strong>: While flying provides unmatched views and experiences, it is not just about the economics of time or productivity but also about the unique value of flight itself.</li>
<li><strong>Weather as a Major Barrier</strong>: Weather conditions significantly impact the practicality of personal aviation, often more so than the technological or regulatory challenges.</li>
</ul>
</section>
<section id="noteworthy-facts" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts">Noteworthy Facts</h3>
<ul>
<li>Only 0.2% of Americans are pilots, and the number owning aircraft is even smaller, indicating a large gap in personal aviation participation.</li>
<li><strong>Historical Context</strong>: The development and regulation of GA have been shaped by safety concerns, leading to an aging fleet and a prevalence of home-built aircraft.</li>
<li><strong>Economic Implications</strong>: The cost of flying, in terms of both direct expenses and the “hundred-dollar hamburger,” highlights the economic considerations of personal aviation.</li>
</ul>
</section>
<section id="practical-implications" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications">Practical Implications</h3>
<ul>
<li><strong>Training and Education</strong>: Increasing the accessibility of pilot training and demystifying the skills required for flying could encourage more individuals to consider personal aviation.</li>
<li><strong>Regulatory Reforms</strong>: Addressing regulatory barriers and incentivizing technological advancements could rejuvenate the GA industry and make personal aviation more viable.</li>
<li><strong>Infrastructure Development</strong>: Enhancing infrastructure at GA airports, including the addition of amenities like restaurants, can make personal flying more appealing for recreational and practical purposes.</li>
</ul>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<ul>
<li><strong>Promote Flying Education</strong>: Educate the public on the feasibility and safety of personal aviation to dispel myths and encourage more people to learn to fly.</li>
<li><strong>Invest in Technology</strong>: Support the development of more user-friendly and safer flying vehicles, including automated systems that can assist pilots and potentially allow more people to fly.</li>
<li><strong>Improve GA Infrastructure</strong>: Invest in the modernization of GA airports and aircraft to make personal aviation a more attractive and practical mode of transportation.</li>
<li><strong>Regulatory Adjustments</strong>: Advocate for regulatory changes that balance safety with the promotion of innovation and accessibility in personal aviation.</li>
</ul>
</section>
<section id="additional-insights" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights">Additional Insights</h3>
<ul>
<li><strong>Cultural Perception</strong>: The perception of flying and personal aviation is shaped by a mix of awe, fear, and practical considerations, affecting its adoption as a mode of transportation.</li>
<li><strong>The Experience of Flight</strong>: Beyond its practical aspects, flying offers a unique perspective on the world, unmatched by other forms of travel, emphasizing the importance of experiencing flight firsthand to truly appreciate its value.</li>
</ul>
</section>
</section>
<section id="dialogue-concerning-the-two-great-systems-of-the-world" class="level2">
<h2 class="anchored" data-anchor-id="dialogue-concerning-the-two-great-systems-of-the-world">Dialogue Concerning the Two Great Systems of the World</h2>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary</h3>
<p>Chapter 10 explores the development, possibilities, and implications of flying cars, focusing on their technological and historical evolution, economic factors, and practicality for personal and commercial use.</p>
<ul>
<li>Analyzes various flying car concepts, including convertibles (vehicles that can transition between flying and driving), VTOLs (Vertical Take-Off and Landing vehicles), helicopters, autogyros, and modern innovations in VTOL technology.</li>
<li>Discusses the technical challenges, costs, and potential societal impacts of widespread adoption of flying cars, including environmental considerations and changes in travel patterns.</li>
</ul>
</section>
<section id="key-concepts-1" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-1">Key Concepts</h3>
<ul>
<li><strong>Flying Cars</strong>: Vehicles capable of both air travel and road use, including VTOLs and convertibles.</li>
<li><strong>VTOLs</strong>: Vehicles designed for vertical take-off and landing, offering flexibility in urban environments.</li>
<li><strong>Convertibles</strong>: Flying cars that transition between flying and driving modes, requiring runways or roads.</li>
</ul>
</section>
<section id="ideas-1" class="level3">
<h3 class="anchored" data-anchor-id="ideas-1">Ideas</h3>
<ul>
<li>The feasibility of flying cars has been technically demonstrated, but practical adoption hinges on cost, safety, and infrastructure.</li>
<li>Helicopters and autogyros present different sets of advantages and challenges for personal aviation, balancing cost, complexity, and versatility.</li>
<li>Modern VTOL innovations potentially reduce the barrier to entry for flying cars, emphasizing electric propulsion and advanced aerodynamics.</li>
</ul>
</section>
<section id="noteworthy-facts-1" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-1">Noteworthy Facts</h3>
<ul>
<li>New Zealand has a higher helicopter-to-population ratio than the US, illustrating different uses and acceptances of personal aviation.</li>
<li>The history of flying cars dates back to early 20th-century concepts and prototypes, with notable advancements and public interest fluctuating over time.</li>
<li>Economic factors, including the Jevons Paradox, suggest increased efficiency in travel could lead to more, not less, overall travel.</li>
</ul>
</section>
<section id="practical-implications-1" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-1">Practical Implications</h3>
<ul>
<li>Flying cars could significantly alter commuting patterns, reduce travel times for short to medium distances, and impact urban and rural development.</li>
<li>Infrastructure for flying cars, including helipads and air traffic management systems, would require substantial investment and innovation.</li>
<li>Safety and training for pilots of personal flying vehicles present major challenges for widespread adoption.</li>
</ul>
</section>
<section id="recommendations-1" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-1">Recommendations</h3>
<ul>
<li>Continued investment in technology that reduces the cost and complexity of flying vehicles, making them accessible to a broader audience.</li>
<li>Development of comprehensive regulatory frameworks to ensure the safe integration of flying cars into national airspace and urban environments.</li>
<li>Encouragement of pilot training programs and public awareness campaigns to prepare society for the potential integration of flying cars.</li>
</ul>
</section>
<section id="critical-analysis" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis">Critical Analysis</h3>
<ul>
<li>While the dream of flying cars remains compelling, the transition from concept to mainstream reality faces significant hurdles, including technical challenges, safety concerns, and societal readiness.</li>
<li>The potential environmental impact of widespread flying car usage, particularly in terms of energy consumption and emissions, requires careful consideration and mitigation strategies.</li>
<li>The economic implications of flying cars, including their effect on existing transportation industries and infrastructure, present both opportunities and challenges for policymakers.</li>
</ul>
</section>
<section id="additional-insights-1" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-1">Additional Insights</h3>
<ul>
<li>The evolution of flying car technology mirrors broader trends in innovation, where advancements often outpace regulatory and societal adaptation.</li>
<li>Flying cars could redefine the notion of personal mobility, offering unprecedented freedom but also raising questions about equity, accessibility, and environmental stewardship.</li>
<li>The future of flying cars likely lies in a hybrid approach, combining the best aspects of helicopters, VTOLs, and convertibles, tailored to specific use cases and environments.</li>
</ul>
</section>
</section>
<section id="the-atomic-age" class="level2">
<h2 class="anchored" data-anchor-id="the-atomic-age">The Atomic Age</h2>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<p>Chapter 11 delves into the history, potential, and societal perceptions surrounding nuclear energy and its comparison with other energy sources. It highlights the optimism of the atomic age, the technological advancements in nuclear physics, and the societal and regulatory challenges that have hindered nuclear energy’s widespread adoption. It contrasts nuclear energy’s safety and efficiency with the negative public perception and regulatory burdens it faces, suggesting that nuclear energy could have significantly advanced global energy solutions if not for these challenges.</p>
</section>
<section id="key-concepts-2" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-2">Key Concepts</h3>
<ul>
<li><strong>Atomic Age Optimism:</strong> Envisioned a future where nuclear energy provides a clean, abundant, and cheap power source.</li>
<li><strong>Technological Headroom:</strong> The potential for significant advancements in nuclear energy technology compared to the slower progress in heavy-duty energy sectors.</li>
<li><strong>Nuclear vs.&nbsp;Fossil Fuels:</strong> Nuclear energy is cleaner and more efficient but faces more public and regulatory resistance.</li>
<li><strong>Economic and Environmental Impact:</strong> Nuclear energy’s potential to reduce energy costs and environmental impacts significantly.</li>
</ul>
</section>
<section id="ideas-2" class="level3">
<h3 class="anchored" data-anchor-id="ideas-2">Ideas</h3>
<ul>
<li>The concept of <strong>“Too Cheap to Meter”</strong> was associated with nuclear energy, indicating its potential to drastically reduce energy costs.</li>
<li><strong>Molten Salt Reactors and Thorium:</strong> Innovations like molten salt reactors using thorium could revolutionize nuclear power by enhancing safety, efficiency, and fuel use.</li>
<li><strong>Regulatory Impact:</strong> Excessive regulation has stifled nuclear energy innovation and increased costs, contrary to the trends in other technological fields.</li>
<li><strong>Public Perception and Media Influence:</strong> Negative public perception, fueled by media coverage and activist campaigns, has significantly impacted nuclear energy’s development and acceptance.</li>
</ul>
</section>
<section id="noteworthy-facts-2" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-2">Noteworthy Facts</h3>
<ul>
<li><strong>Energy Density:</strong> Nuclear fuels produce 1 million to 10 million times the energy per weight compared to chemical fuels.</li>
<li><strong>Cost Comparison:</strong> The cost of nuclear energy, primarily due to uranium’s low price, could be significantly lower than current energy sources if not for regulatory and societal barriers.</li>
<li><strong>Safety Record:</strong> Despite public fears, nuclear power has a better safety record compared to other energy sources, including coal and oil.</li>
<li><strong>Waste Management:</strong> Nuclear energy produces significantly less waste than fossil fuels, and technological solutions for waste management exist but are politically contentious.</li>
</ul>
</section>
<section id="practical-implications-2" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-2">Practical Implications</h3>
<ul>
<li><strong>Energy Policy:</strong> A reevaluation of nuclear energy policy and regulatory frameworks could unlock nuclear power’s full potential.</li>
<li><strong>Technological Innovation:</strong> Investment in nuclear technology research and development could lead to safer, more efficient reactors.</li>
<li><strong>Public Education:</strong> Addressing misconceptions and educating the public on nuclear energy’s benefits and safety is crucial for gaining broader acceptance.</li>
<li><strong>Global Energy Strategy:</strong> Incorporating advanced nuclear technologies into global energy strategies could significantly impact climate change efforts and energy independence.</li>
</ul>
</section>
<section id="recommendations-2" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-2">Recommendations</h3>
<ul>
<li><strong>Reform Regulatory Processes:</strong> Simplify and streamline regulatory processes to encourage innovation and reduce the cost of nuclear power development.</li>
<li><strong>Invest in Research:</strong> Increase funding for nuclear energy research, focusing on advanced reactor designs and fuel cycles.</li>
<li><strong>Public Engagement:</strong> Develop comprehensive public education campaigns to improve understanding and acceptance of nuclear energy.</li>
<li><strong>International Collaboration:</strong> Promote international cooperation on nuclear safety, waste management, and technology exchange to advance global nuclear energy deployment.</li>
</ul>
</section>
<section id="critical-analysis-1" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-1">Critical Analysis</h3>
<ul>
<li>The stagnation in nuclear energy advancement contrasts sharply with the rapid development in information technology, highlighting societal and regulatory challenges over technological limitations.</li>
<li>The potential of nuclear energy to transform the global energy landscape remains largely untapped due to historical, political, and perceptual barriers, suggesting a need for a paradigm shift in energy policy and public discourse.</li>
</ul>
</section>
<section id="additional-insights-2" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-2">Additional Insights</h3>
<ul>
<li><strong>Energy Transition:</strong> The transition from fossil fuels to nuclear power represents a critical juncture in addressing climate change and energy security challenges.</li>
<li><strong>Economic Impact:</strong> Lowering the cost of energy through nuclear power could have profound economic benefits, particularly for developing countries.</li>
<li><strong>Innovation Stagnation:</strong> The narrative also sheds light on how innovation in nuclear technology has been stifled, contrasting with potential advancements that could have been achieved.</li>
</ul>
</section>
</section>
<section id="when-worlds-collide" class="level2">
<h2 class="anchored" data-anchor-id="when-worlds-collide">When Worlds Collide</h2>
<section id="summary-3" class="level3">
<h3 class="anchored" data-anchor-id="summary-3">Summary</h3>
<p>Chapter 12 discusses the evolution and potential of nanotechnology, tracing the concept from Richard Feynman’s initial vision of molecular manufacturing to the present day. It highlights the challenges and advancements in creating self-replicating machines (SRMs) and the implications of such technology on society, emphasizing the unexplored path Feynman proposed for building machines from the top down, capable of replicating themselves and operating at increasingly smaller scales.</p>
</section>
<section id="key-concepts-3" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-3">Key Concepts</h3>
<ul>
<li><strong>Feynman’s Path</strong>: A method for achieving nanotechnology through the construction of machines that can replicate themselves at smaller scales.</li>
<li><strong>Self-Replicating Machines (SRMs)</strong>: Machines capable of producing copies of themselves, potentially down to the molecular level.</li>
<li><strong>MEMS (Micro-Electro-Mechanical Systems)</strong>: Small mechanical devices driven by electricity, highlighting the limitations of current technology in achieving nanoscale precision.</li>
<li><strong>Nanotechnology</strong>: The manipulation of matter on an atomic or molecular scale, envisioned to revolutionize manufacturing, medicine, and more.</li>
</ul>
</section>
<section id="ideas-3" class="level3">
<h3 class="anchored" data-anchor-id="ideas-3">Ideas</h3>
<ul>
<li>The potential for nanotechnology to dramatically reduce the cost and increase the availability of various products, akin to the transformative effects of the Industrial Revolution.</li>
<li>The unexplored feasibility of building compact macro-scale self-replicating machines using conventional fabrication and assembly techniques.</li>
<li>The concept of “mechanical motherhood,” where machines can create smaller, precise copies of themselves, facilitating the miniaturization and multiplication of manufacturing capabilities.</li>
<li>The importance of precision and the challenge of achieving atomic scale tolerance in manufacturing processes.</li>
</ul>
</section>
<section id="noteworthy-facts-3" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-3">Noteworthy Facts</h3>
<ul>
<li><strong>Feynman’s Vision</strong>: In the 1950s, physicist Richard Feynman conceptualized the possibility of machines that could manipulate atoms and molecules to build products with unprecedented precision.</li>
<li><strong>Manhattan and Apollo Projects</strong>: Historical examples of intense, time-sensitive projects that prioritized efficiency and innovation under the principle of “waste anything but time.”</li>
<li><strong><a href="https://reprap.org/wiki/RepRap">RepRap Project</a></strong>: An open-source initiative aimed at creating a 3D printer capable of printing most of its own components, demonstrating progress toward self-replication in manufacturing.</li>
</ul>
</section>
<section id="practical-implications-3" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-3">Practical Implications</h3>
<ul>
<li><strong>Medical Applications</strong>: Nanotechnology could revolutionize healthcare by enabling the creation of advanced medical devices and treatments.</li>
<li><strong>Manufacturing Efficiency</strong>: The ability to produce machines that can replicate themselves and operate at nanoscale would significantly reduce manufacturing costs and resource consumption.</li>
<li><strong>Economic and Social Transformation</strong>: Like the Industrial Revolution, nanotechnology could lead to a significant shift in economic structures and personal autonomy, making previously expensive or scarce products widely accessible.</li>
</ul>
</section>
<section id="recommendations-3" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-3">Recommendations</h3>
<ul>
<li><strong>Exploring Feynman’s Path</strong>: Dedicated research and development efforts should be directed toward realizing Feynman’s vision of molecular manufacturing through self-replicating machines.</li>
<li><strong>Incremental Advancements</strong>: Focus on achieving small-scale successes in SRM technology, which could lead to breakthroughs in nanotechnology.</li>
<li><strong>Interdisciplinary Collaboration</strong>: Encourage collaboration between fields such as biology, engineering, and materials science to overcome the challenges of nanoscale manufacturing.</li>
</ul>
</section>
<section id="additional-insights-3" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-3">Additional Insights</h3>
<ul>
<li>The text illustrates a gap between the potential of nanotechnology as envisioned by pioneers like Feynman and the current state of the field, which has been limited by technical challenges and perhaps a lack of bold, coordinated effort.</li>
<li>It also points to the RepRap project as a tangible step toward self-replicating technology, suggesting that more ambitious projects could accelerate progress toward Feynman’s vision.</li>
</ul>
</section>
</section>
<section id="when-the-sleeper-wakes" class="level2">
<h2 class="anchored" data-anchor-id="when-the-sleeper-wakes">When the Sleeper Wakes</h2>
<section id="summary-4" class="level3">
<h3 class="anchored" data-anchor-id="summary-4">Summary</h3>
<p>Chapter 13 explores the historical context and potential future of flying cars, the stagnation in technological progress despite advancements in other areas, and the socio-economic factors contributing to the current state of technological development. It delves into how past predictions about technology have not fully materialized, the impact of regulations and cultural shifts on innovation, and the possibilities that lie ahead if certain technological and societal barriers can be overcome.</p>
</section>
<section id="key-concepts-4" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-4">Key Concepts</h3>
<ul>
<li><strong>Technological Stagnation:</strong> The slowing of technological progress in certain areas, particularly in transportation and energy, despite advancements in computing and information technology.</li>
<li><strong>Henry Adams Curve:</strong> Refers to the historical trend of exponential growth in energy use and technological development, which flattened in the latter half of the 20th century.</li>
<li><strong>Flying Cars:</strong> Technologically feasible but hindered by historical, regulatory, and economic barriers rather than technological limitations.</li>
</ul>
</section>
<section id="noteworthy-facts-4" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-4">Noteworthy Facts</h3>
<ul>
<li>Flying cars have been technologically possible and have been built and flown since the 1930s.</li>
<li>The Great Depression, World War II, and subsequent regulatory and liability challenges have significantly hindered the development of personal aviation.</li>
<li>The stagnation in energy development, particularly the flatlining of the Henry Adams curve, is a major factor in why some technological predictions have not been realized.</li>
<li>Advances in computing and information technology have largely followed the optimistic predictions of the past, contrasting with the stagnation in other areas.</li>
</ul>
</section>
<section id="practical-implications-4" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-4">Practical Implications</h3>
<ul>
<li><strong>Infrastructure and Regulation:</strong> The development of flying cars and other advanced technologies has been significantly impacted by government regulation, infrastructure decisions, and the legal environment.</li>
<li><strong>Cultural Shifts:</strong> Changes in societal attitudes towards technology, from optimism to pessimism, have influenced the direction and pace of technological innovation.</li>
<li><strong>Economic Factors:</strong> Economic shifts, including the cost disease affecting healthcare and education, have diverted resources away from technological innovation.</li>
</ul>
</section>
<section id="recommendations-4" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-4">Recommendations</h3>
<ul>
<li>Reevaluate and potentially reduce regulatory barriers to facilitate innovation in transportation and energy.</li>
<li>Foster a cultural and societal shift towards optimism and support for technological progress.</li>
<li>Invest in research and development for alternative energy sources, including nuclear power and advanced battery technologies, to overcome the stagnation in energy development.</li>
</ul>
</section>
<section id="additional-insights-4" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-4">Additional Insights</h3>
<ul>
<li><strong>Contrast with Information Technology:</strong> The rapid progress in computing and digital technologies contrasts starkly with the stagnation in transportation and energy, highlighting the impact of regulatory environments and societal attitudes on different sectors.</li>
<li><strong>Potential for a Technological Renaissance:</strong> Emerging technologies, such as electric and VTOL (Vertical Take-Off and Landing) flying cars, small modular reactors, and advancements in biotechnology, hint at the possibility of overcoming current stagnations.</li>
<li><strong>Socio-Economic Barriers:</strong> The intertwining of technological stagnation with economic, regulatory, and cultural factors suggests that addressing the stagnation requires a holistic approach beyond mere technological innovation.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>history</category>
  <guid>christianjmills.com/posts/where-is-my-flying-car-book-notes/part-2/</guid>
  <pubDate>Sun, 18 Feb 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Notes on Where is My Flying Car Pt. 01</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/where-is-my-flying-car-book-notes/part-1/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/where-is-my-flying-car-book-notes.html"><strong>Where is My Flying Car?</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Ch. 1: The World of Tomorrow</li>
<li>Ch. 2: The Graveyard of Dreams</li>
<li>Ch. 3: The Conquest of the Air</li>
<li>Ch. 4: Waldo and Magic, Inc.</li>
<li>Ch. 5: Cold Fusion</li>
<li>Ch. 6: The Machiavelli Effect</li>
<li>Ch. 7: The Age of Aquarius</li>
<li>Ch. 8: Forbidden Fruit</li>
</ul>
<section id="the-world-of-tomorrow" class="level2">
<h2 class="anchored" data-anchor-id="the-world-of-tomorrow">The World of Tomorrow</h2>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>“Where Is My Flying Car” explores the evolution of technological optimism from the early 20th century to the 1960s, highlighting influences from science fiction, key inventors like Thomas Edison, and visionary engineers such as Kelly Johnson of Lockheed Skunk Works. It delves into the societal expectations for technological advancements, including flying cars, and the reasons why such visions have not fully materialized, drawing from historical, cultural, and scientific perspectives.</p>
</section>
<section id="key-themes" class="level3">
<h3 class="anchored" data-anchor-id="key-themes">Key Themes</h3>
<ul>
<li><strong>Technological Optimism and its Evolution</strong>: The text traces how optimism about technology’s potential to transform the future has evolved, influenced by inventors, science fiction, and significant technological achievements.</li>
<li><strong>Influence of Science Fiction on Technological Development</strong>: It highlights the impact of science fiction literature and films on real-world technological innovation and public expectations.</li>
<li><strong>The Role of Key Figures and Events</strong>: The narrative underscores the contributions of figures like Edison and Johnson, and events such as World War II and the Space Race, in shaping technological aspirations.</li>
</ul>
</section>
<section id="ideas" class="level3">
<h3 class="anchored" data-anchor-id="ideas">Ideas</h3>
<ul>
<li>The belief in a technologically advanced future was inspired by science fiction and real-life innovators.</li>
<li>The concept of flying cars, popularized by science fiction, was once considered an imminent reality.</li>
<li>The influence of key individuals like Thomas Edison and Kelly Johnson significantly propelled technological optimism.</li>
<li>Cultural and societal factors, including the World Wars and the Space Age, played crucial roles in shaping expectations for the future.</li>
</ul>
</section>
<section id="facts" class="level3">
<h3 class="anchored" data-anchor-id="facts">Facts</h3>
<ul>
<li>Thomas Edison was a major influence on the character Tom Swift, who inspired generations of engineers and inventors.</li>
<li>Kelly Johnson, inspired by Tom Swift, led Lockheed Skunk Works and contributed to major aeronautical advancements.</li>
<li>The early 20th century saw significant technological advancements, including the introduction of cars, radios, and airplanes.</li>
<li>Science fiction, particularly works like H.G. Wells’s “Things to Come,” played a role in popularizing the vision of a technological utopia.</li>
<li>The 1939 World’s Fair and its Futurama exhibit were influential in shaping public expectations of the future.</li>
</ul>
</section>
<section id="critical-analysis" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis">Critical Analysis</h3>
<ul>
<li>The persistent gap between technological optimism and reality highlights the challenges in actualizing science fiction-inspired visions.</li>
<li>The role of societal, economic, and political factors in facilitating or hindering technological advancements is critical.</li>
<li>The influence of science fiction on technological development illustrates the complex interplay between culture and innovation.</li>
</ul>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<ul>
<li>Embrace a balanced view of technological optimism, acknowledging both its inspirational value and the practical challenges of innovation.</li>
<li>Foster interdisciplinary collaboration between scientists, engineers, and creators to envision and realize sustainable technological advancements.</li>
<li>Encourage public engagement and education in science and technology to build realistic expectations and support for innovation.</li>
</ul>
</section>
<section id="future-perspectives" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives">Future Perspectives</h3>
<ul>
<li>The ongoing influence of science fiction on technology suggests that visionary narratives will continue to inspire future innovations.</li>
<li>The realization of technologies like flying cars depends not only on technical feasibility but also on addressing societal, regulatory, and environmental concerns.</li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>The exploration of technological optimism through the lens of history, science fiction, and key figures reveals both the achievements and unfulfilled promises of the past century. Understanding these dynamics is essential for navigating the path toward realizing the technological dreams of the future.</p>
</section>
</section>
<section id="the-graveyard-of-dreams" class="level2">
<h2 class="anchored" data-anchor-id="the-graveyard-of-dreams">The Graveyard of Dreams</h2>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary</h3>
<p>Chapter 2 reflects on the optimistic predictions of technological advancement from the golden age of science fiction and contrasts them with the reality of technological progress and societal developments. It discusses the decline of cities like Detroit, shifts in societal expectations towards the future, the stagnation of technological innovation in areas like transportation, and the discrepancy between past predictions and current technological achievements.</p>
</section>
<section id="ideas-1" class="level3">
<h3 class="anchored" data-anchor-id="ideas-1">Ideas</h3>
<ul>
<li>The golden age of science fiction envisioned a future filled with technological wonders, but real-world technological progress has been uneven, with some areas advancing significantly while others have stagnated.</li>
<li>Societal expectations for the future have become more pessimistic compared to the optimism of the 1960s.</li>
<li>The decline of Detroit is used as a metaphor for broader societal and technological stagnation.</li>
<li>Despite past predictions, innovations like flying cars have not materialized, and technological progress in transportation has plateaued.</li>
<li>Economic theories suggest a stagnation in technological innovation and economic growth, with the latter half of the 20th century failing to bring about the same level of transformative technological advances as the first half.</li>
</ul>
</section>
<section id="facts-1" class="level3">
<h3 class="anchored" data-anchor-id="facts-1">Facts</h3>
<ul>
<li>Detroit’s bankruptcy in 2013 highlighted a significant decline from its peak as a symbol of American industrial might.</li>
<li>Technological predictions from the golden age of science fiction often failed to materialize, such as widespread use of flying cars.</li>
<li>Economic data suggests that the growth of per capita GDP has slowed since the 1970s.</li>
<li>The private airplane industry saw a decline in the number of units sold annually since the 1970s.</li>
<li>Energy consumption and efficiency improvements have not kept pace with historical trends, contributing to a stagnation in technological innovation in energy-intensive sectors.</li>
</ul>
</section>
<section id="recommendations-1" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-1">Recommendations</h3>
<ul>
<li>Explore alternative energy sources and technologies to overcome the stagnation in energy efficiency and availability.</li>
<li>Re-evaluate economic and innovation policies to foster a more dynamic environment for technological breakthroughs.</li>
<li>Encourage a balanced view of the future, recognizing both the challenges and opportunities technological advancements can bring.</li>
<li>Invest in research and development in sectors where technological progress has stagnated, particularly in transportation and energy.</li>
<li>Foster a societal mindset that embraces change and innovation, counteracting the pessimism that has set in regarding the future.</li>
</ul>
</section>
<section id="critical-analysis-1" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-1">Critical Analysis</h3>
<ul>
<li><p>The contrast between the optimistic predictions of the past and the current technological reality underscores a need to reassess how society views and invests in technological innovation.</p></li>
<li><p>The stagnation in certain technological fields, especially transportation and energy, suggests a complex interplay between economic policies, societal expectations, and the technical challenges of surpassing certain physical and economic barriers.</p></li>
<li><p>The narrative of decline in cities like Detroit and the stagnation in technological innovation calls for a nuanced understanding of how socio-economic factors influence technological progress.</p></li>
<li><p>The disillusionment with the pace of technological progress reflects a broader societal challenge in managing expectations versus reality.</p></li>
<li><p>The focus on what has not been achieved (e.g., flying cars) may overshadow significant advancements in other areas, such as digital technology and communication.</p></li>
</ul>
</section>
<section id="future-perspectives-1" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-1">Future Perspectives</h3>
<ul>
<li>Considering the current challenges, there is potential for a new wave of technological innovation that addresses the shortcomings of past predictions, particularly by leveraging advancements in renewable energy and digital technologies.</li>
<li>Future technological progress may require a rethinking of societal priorities, with a greater emphasis on sustainable and equitable development.</li>
</ul>
</section>
</section>
<section id="the-conquest-of-the-air" class="level2">
<h2 class="anchored" data-anchor-id="the-conquest-of-the-air">The Conquest of the Air</h2>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<p>Chapter 3 explores the history and development of flying machines, specifically focusing on the transition from autogyros to helicopters and the concept of flying cars. It highlights the works of pioneers like Juan de la Sierra, Harold Pitcairn, and Moulton Taylor, among others, in the evolution of aviation technology from the early 20th century through post-World War II. The narrative critically examines the reasons why flying cars have not become mainstream, despite technological feasibility, pointing to economic, regulatory, and practical challenges.</p>
</section>
<section id="key-historical-figures-and-contributions" class="level3">
<h3 class="anchored" data-anchor-id="key-historical-figures-and-contributions">Key Historical Figures and Contributions</h3>
<ul>
<li><strong><a href="https://en.wikipedia.org/wiki/Juan_de_la_Cierva">Juan de la Sierra</a>:</strong> Invented the Auto Gyro, contributing significantly to rotary-wing aviation and laying groundwork for helicopter development.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/Harold_Frederick_Pitcairn">Harold Pitcairn</a>:</strong> Advanced autogyro technology in the U.S., contributed to helicopter development, and faced legal battles over aviation patents.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/Molt_Taylor">Moulton Taylor</a>:</strong> Designed the Aerocar, a notable attempt at creating a practical flying car.</li>
</ul>
</section>
<section id="technological-evolution" class="level3">
<h3 class="anchored" data-anchor-id="technological-evolution">Technological Evolution</h3>
<ul>
<li><strong><a href="https://en.wikipedia.org/wiki/Autogyro">Autogyros</a>:</strong> An early form of rotary-wing aircraft that led to the development of helicopters, offering short takeoff and landing capabilities.</li>
<li><strong>Helicopters:</strong> Evolved from autogyros, solving many of their limitations but remained costly and complex.</li>
<li><strong>Flying Cars:</strong> Various attempts, such as the Aerocar and Convair car, demonstrated feasibility but faced practical and regulatory hurdles.</li>
</ul>
</section>
<section id="challenges-to-widespread-adoption" class="level3">
<h3 class="anchored" data-anchor-id="challenges-to-widespread-adoption">Challenges to Widespread Adoption</h3>
<ul>
<li><strong>Economic Factors:</strong> High costs of production, maintenance, and operation limited accessibility to the broader public.</li>
<li><strong>Practical Challenges:</strong> Issues such as the need for runways, complex controls, and safety concerns hindered practical daily use.</li>
<li><strong>Regulatory and Legal Battles:</strong> Intellectual property disputes and government regulations impacted the development and commercialization of flying cars.</li>
</ul>
</section>
<section id="ideas-for-the-future" class="level3">
<h3 class="anchored" data-anchor-id="ideas-for-the-future">Ideas for the Future</h3>
<ul>
<li><strong>Technological Improvements:</strong> Continuous innovation could potentially overcome current limitations, making flying cars more practical and affordable.</li>
<li><strong>Regulatory Adaptation:</strong> Changes in aviation and urban planning regulations could facilitate the integration of flying cars into daily transportation.</li>
</ul>
</section>
<section id="reflections" class="level3">
<h3 class="anchored" data-anchor-id="reflections">Reflections</h3>
<p>The text prompts readers to consider missed opportunities and alternative paths in technological development. It raises questions about other potential innovations that have not been pursued or have failed to reach mainstream adoption due to various barriers.</p>
</section>
<section id="conclusion-1" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-1">Conclusion</h3>
<p>The history of flying cars and related aviation technologies illustrates a complex interplay of innovation, practicality, and regulation. While technical feasibility has been demonstrated, broader adoption of flying cars remains elusive due to unresolved economic, practical, and regulatory challenges.</p>
</section>
</section>
<section id="waldo-and-magic-inc." class="level2">
<h2 class="anchored" data-anchor-id="waldo-and-magic-inc.">Waldo and Magic, Inc.</h2>
<section id="summary-3" class="level3">
<h3 class="anchored" data-anchor-id="summary-3">Summary</h3>
<p>Chapter 4 delves into the evolution of nanotechnology, starting with <a href="https://en.wikipedia.org/wiki/Robert_A._Heinlein">Robert A. Heinlein</a>’s fictional concept of self-replicating, scale-shifting machines (“<a href="https://en.wikipedia.org/wiki/Waldo_(short_story)">Waldos</a>”) in his 1942 story. It moves on to discuss Richard Feynman’s 1959 proposal for nanoscale manipulation and construction, and finally, <a href="https://en.wikipedia.org/wiki/K._Eric_Drexler">K. Eric Drexler</a>’s expansion of these ideas into what is now recognized as molecular nanotechnology.</p>
<ul>
<li><strong>Feynman’s Vision:</strong> Feynman, in his 1959 talk, imagined the possibility of manipulating matter at the atomic level, suggesting a method of creating smaller and smaller tools to achieve this. Despite offering prizes to stimulate interest, the broader implications of his vision were not fully embraced at the time.</li>
<li><strong>Drexler’s Contribution:</strong> Drexler built upon Feynman’s ideas, proposing the concept of molecular assemblers that could control the structure of matter at the molecular level, thereby introducing the broader public and scientific community to the potential of nanotechnology.</li>
<li><strong>Real-world Implications:</strong> The narrative also touches on the real-world implications and potential of nanotechnology, such as dramatic increases in manufacturing efficiency, medical advancements, and even the reconstitution of materials from waste products.</li>
</ul>
</section>
<section id="ideas-2" class="level3">
<h3 class="anchored" data-anchor-id="ideas-2">Ideas</h3>
<ul>
<li><strong>Self-Replicating Technology:</strong> The concept of machines that can replicate themselves, initially fictionalized by Heinlein and later conceptualized in a more practical manner by Feynman and Drexler, could revolutionize manufacturing, medicine, and more.</li>
<li><strong>Scale-Shifting Mechanisms:</strong> The idea that machines could operate and manipulate matter at increasingly smaller scales, down to the atomic level, suggests a future where material limitations are vastly reduced.</li>
<li><strong>Nanotechnology’s Potential:</strong> Beyond the mere manipulation of atoms, the envisioned future includes the ability to construct complex machinery, electronics, and even biological materials at the nanoscale, with precision and efficiency far beyond current capabilities.</li>
</ul>
</section>
<section id="facts-2" class="level3">
<h3 class="anchored" data-anchor-id="facts-2">Facts</h3>
<ul>
<li><strong>Historical Milestones:</strong>
<ul>
<li>Heinlein’s story in 1942 introduced the concept of remotely controlled, self-replicating machines.</li>
<li>Feynman’s 1959 speech proposed the practicality of manipulating matter at the atomic level.</li>
<li>Drexler’s work in the 1980s and his publication of “Engines of Creation” brought nanotechnology into the public and academic discourse.</li>
</ul></li>
<li><strong>Technological Projections:</strong>
<ul>
<li>The potential for nanotechnology to transform industries, including manufacturing and medicine, by allowing for the precise and efficient creation of products at the atomic or molecular scale.</li>
<li>The concept of self-replicating nanomachines could lead to exponential growth in manufacturing capabilities, similar to the growth observed in digital information technology.</li>
</ul></li>
</ul>
</section>
<section id="recommendations-2" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-2">Recommendations</h3>
<ul>
<li><strong>Investment in Nanotechnology Research:</strong> Encourage and increase funding for research into nanoscale manipulation and construction techniques, focusing on practical applications and the development of infrastructure to support such technologies.</li>
<li><strong>Educational Focus:</strong> Strengthen educational programs and resources in nanotechnology and related fields to prepare future generations for advancements in this area.</li>
<li><strong>Regulatory Framework:</strong> Develop a regulatory framework to ensure the safe and ethical development and use of nanotechnologies, particularly in regards to self-replicating machines and their potential impacts on society and the environment.</li>
</ul>
</section>
<section id="critical-analysis-2" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-2">Critical Analysis</h3>
<ul>
<li><strong>Feynman’s Underappreciated Insight:</strong> Despite Feynman’s significant contributions to physics and his foresight regarding nanotechnology, his ideas were not immediately pursued with the vigor they deserved, reflecting a possible gap between visionary scientific ideas and their practical exploration and application.</li>
<li><strong>Drexler’s Role in Popularizing Nanotechnology:</strong> Drexler’s work played a crucial role in transforming nanotechnology from a theoretical concept into a field of scientific inquiry with tangible goals and research agendas.</li>
</ul>
</section>
<section id="future-perspectives-2" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-2">Future Perspectives</h3>
<ul>
<li><strong>The Path to Implementation:</strong> Consideration of how to bridge the gap between the current state of nanotechnology and the future potential outlined by pioneers like Feynman and Drexler. This includes addressing technical challenges, societal implications, and ethical considerations.</li>
<li><strong>Societal Impacts:</strong> Reflect on the potential societal changes and challenges that could arise from widespread implementation of nanotechnology, including economic, environmental, and health impacts.</li>
</ul>
</section>
</section>
<section id="cold-fusion" class="level2">
<h2 class="anchored" data-anchor-id="cold-fusion">Cold Fusion</h2>
<section id="summary-4" class="level3">
<h3 class="anchored" data-anchor-id="summary-4">Summary</h3>
<p>Chapter 5 recounts the intriguing saga of cold fusion, beginning with its unexpected discovery by electrochemists <a href="https://en.wikipedia.org/wiki/Stanley_Pons">Stanley Pons</a> and <a href="https://en.wikipedia.org/wiki/Martin_Fleischmann">Martin Fleischmann</a> in 1989, who believed they had achieved nuclear fusion at room temperature. Despite initial excitement, their claims faced skepticism and were largely discredited by the scientific community. The narrative explores the challenges and controversies surrounding cold fusion, highlighting the clash between groundbreaking scientific discovery and established scientific paradigms.</p>
</section>
<section id="key-events" class="level3">
<h3 class="anchored" data-anchor-id="key-events">Key Events</h3>
<ul>
<li><strong>Discovery:</strong> In 1989, Pons and Fleischmann announced they had achieved cold fusion, a process they thought could revolutionize energy production.</li>
<li><strong>Skepticism and Controversy:</strong> Their claims were met with skepticism and controversy, leading to a divide within the scientific community.</li>
<li><strong>Scientific Investigation:</strong> Various attempts to replicate the results were made, with mixed outcomes, contributing to ongoing debate about the validity of cold fusion.</li>
</ul>
</section>
<section id="ideas-3" class="level3">
<h3 class="anchored" data-anchor-id="ideas-3">Ideas</h3>
<ul>
<li><strong>Cold Fusion Concept:</strong> The process of achieving nuclear fusion at room temperature, as opposed to the high temperatures required in traditional fusion reactions.</li>
<li><strong>Machiavelli Effect:</strong> The phenomenon where innovators face opposition from those benefiting from the status quo, and lukewarm support from potential beneficiaries of the new order.</li>
<li><strong>Replication Challenges:</strong> Cold fusion experiments are noted for their finicky and intermittent results, making replication difficult and casting doubt on the phenomenon’s reliability.</li>
</ul>
</section>
<section id="facts-3" class="level3">
<h3 class="anchored" data-anchor-id="facts-3">Facts</h3>
<ul>
<li><strong>Initial Experiment:</strong> Pons and Fleischmann used electrolysis on a palladium electrode loaded with deuterium, claiming to observe excess heat indicative of nuclear fusion.</li>
<li><strong>Public and Scientific Reaction:</strong> The announcement was initially met with excitement but quickly turned into skepticism and outright dismissal by many in the scientific community.</li>
<li><strong>Funding and Research:</strong> Despite being discredited, cold fusion research continued with private and limited government funding, leading to further experiments and studies.</li>
</ul>
</section>
<section id="recommendations-3" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-3">Recommendations</h3>
<ul>
<li><strong>Open-minded Investigation:</strong> Encourage a balanced and open-minded approach to investigating cold fusion, acknowledging both the potential significance of the discovery and the need for rigorous scientific validation.</li>
<li><strong>Replication Efforts:</strong> Support efforts to replicate cold fusion experiments with a high degree of precision and transparency, to clarify the phenomenon’s validity.</li>
<li><strong>Interdisciplinary Collaboration:</strong> Foster collaboration between electrochemists, physicists, and other scientists to explore the underlying mechanisms of cold fusion and address the challenges in replicating results.</li>
</ul>
</section>
<section id="critical-analysis-3" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-3">Critical Analysis</h3>
<ul>
<li><strong>Scientific Process and Innovation:</strong> The cold fusion saga highlights the tension between innovation and established scientific practices, underscoring the importance of maintaining an open mind towards unconventional discoveries.</li>
<li><strong>Impact of Skepticism:</strong> The intense skepticism and dismissal faced by Pons and Fleischmann demonstrate the potential barriers to scientific progress posed by entrenched interests and the difficulty of introducing paradigm-shifting technologies.</li>
<li><strong>Need for Rigorous Validation:</strong> While the possibility of cold fusion remains intriguing, the lack of consistent, replicable results underscores the necessity of rigorous scientific validation before such claims can be accepted as fact.</li>
</ul>
</section>
<section id="future-perspectives-3" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-3">Future Perspectives</h3>
<ul>
<li><strong>Understanding the Unknown:</strong> Cold fusion represents an area of science where our current understanding is incomplete, suggesting that further research could uncover new principles of physics.</li>
<li><strong>Potential for Energy Revolution:</strong> If validated, cold fusion could dramatically transform the energy landscape, offering a clean, virtually limitless source of power.</li>
<li><strong>Role of Scientific Community:</strong> The scientific community’s response to cold fusion serves as a case study in handling extraordinary claims, emphasizing the need for a balanced approach that supports innovation while upholding scientific rigor.</li>
</ul>
</section>
</section>
<section id="the-machiavelli-effect" class="level2">
<h2 class="anchored" data-anchor-id="the-machiavelli-effect">The Machiavelli Effect</h2>
<section id="summary-5" class="level3">
<h3 class="anchored" data-anchor-id="summary-5">Summary</h3>
<p>Chapter 6 discusses the phenomena of resistance to new ideas and technologies in scientific communities, dubbed the “Machiavelli Effect.” It draws parallels between historical and contemporary examples, notably in the fields of cold fusion, nanotechnology, and broader scientific research funding dynamics.</p>
<ul>
<li>Highlights the societal and systemic responses to innovation, including the resistance from established entities (“nobles”) and the hesitancy of potential innovators (“tradesmen”) due to the fear of backlash.</li>
<li>Points to the influence of government funding in shaping scientific research and its potential to stifle innovation due to the preferential treatment of established fields or ideas over emerging ones.</li>
<li>Mentions significant examples of technological advancement and stagnation, touching on the role of education, bureaucracy, and funding in affecting the pace and direction of scientific progress.</li>
</ul>
</section>
<section id="ideas-4" class="level3">
<h3 class="anchored" data-anchor-id="ideas-4">Ideas</h3>
<ul>
<li>The Machiavelli Effect illustrates how systemic and human nature resistances to innovation can hinder scientific progress.</li>
<li>The distinction between “nobles” and “tradesmen” in the context of innovation resistance highlights the dynamic of power and fear in the face of new technologies.</li>
<li>Government funding, while critical for research, can inadvertently prioritize established fields and suppress novel ideas due to the allocation of resources and the influence of existing scientific elites.</li>
<li>Historical and contemporary examples underscore the recurring pattern of resistance to innovation, suggesting that this phenomenon is deeply rooted in societal and systemic structures.</li>
</ul>
</section>
<section id="facts-4" class="level3">
<h3 class="anchored" data-anchor-id="facts-4">Facts</h3>
<ul>
<li><strong>Cold Fusion</strong>: Initially dismissed as a mistake based on misinterpretations and bad laboratory techniques.</li>
<li><strong>Nanotechnology</strong>: Faced systemic resistance despite its potential, with funding dynamics illustrating the Machiavelli Effect.</li>
<li><strong>Government Funding</strong>: Often reshuffles resources from established programs to new initiatives, potentially stifling innovation in emerging fields.</li>
<li><strong>Historical Examples of Technological Stagnation</strong>: The industrial revolution took off in Britain, not France, despite France’s scientific prowess at the time, illustrating the complex interplay between innovation, societal structures, and economic policies.</li>
</ul>
</section>
<section id="recommendations-4" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-4">Recommendations</h3>
<ul>
<li><strong>Encourage Diverse Funding Sources</strong>: To mitigate the risk of innovation suppression inherent in centralized funding models.</li>
<li><strong>Promote Interdisciplinary Research</strong>: To foster innovation by combining existing knowledge in novel ways, breaking through the barriers of traditional fields.</li>
<li><strong>Support Risk-Taking in Scientific Research</strong>: By creating safe environments for exploring and developing new technologies, even when they contradict established paradigms.</li>
<li><strong>Educate on the History of Technological Innovation</strong>: To build awareness of the systemic and societal factors that influence scientific progress and the acceptance of new ideas.</li>
</ul>
</section>
<section id="critical-analysis-4" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-4">Critical Analysis</h3>
<ul>
<li><p>The Machiavelli Effect, as described, points to a broader issue within the sociology of science, where the power dynamics and risk aversion inherent in human nature and institutional structures can significantly impede technological and scientific advancement.</p></li>
<li><p>The narrative suggests that while funding and resources are crucial for research, the manner in which they are allocated and controlled can either bolster or hinder the development of groundbreaking technologies.</p></li>
<li><p>The comparison between historical and contemporary examples serves to underscore the persistent nature of resistance to innovation, suggesting that understanding and addressing these systemic biases is crucial for fostering future technological breakthroughs.</p></li>
<li><p>The discussion around the Machiavelli Effect and its implications for scientific innovation resonates with broader debates on how societies value and support progress. It raises important questions about the role of funding, education, and societal structures in either nurturing or stifling innovation.</p></li>
</ul>
</section>
<section id="future-perspectives-4" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-4">Future Perspectives</h3>
<ul>
<li>Exploring new models of research funding and support that emphasize innovation and risk-taking could be key to overcoming the Machiavelli Effect.</li>
<li>The evolving landscape of technology and science necessitates a reassessment of how we approach innovation, with a particular focus on fostering environments that encourage rather than inhibit new ideas.</li>
</ul>
</section>
</section>
<section id="the-age-of-aquarius" class="level2">
<h2 class="anchored" data-anchor-id="the-age-of-aquarius">The Age of Aquarius</h2>
<section id="summary-6" class="level3">
<h3 class="anchored" data-anchor-id="summary-6">Summary</h3>
<p>Chapter 7 examines the transition from a society driven by scientific progress and exploration, exemplified by the moon landing, to one captivated by the cultural and emotional shifts of the 1960s and 1970s, marked by the Age of Aquarius, a focus on love and environmentalism, and a movement away from the hard sciences. It discusses the impact of historical, cultural, and technological shifts on society’s values and priorities, highlighting the tension between scientific advancement and cultural change.</p>
</section>
<section id="ideas-5" class="level3">
<h3 class="anchored" data-anchor-id="ideas-5">Ideas</h3>
<ul>
<li>The progression from a universe understood through mythology to one explained by science and mathematics represents a monumental leap in human thought.</li>
<li>The Age of Aquarius symbolizes a shift from logical and mathematical steering of society to emotional and cultural guidance.</li>
<li>The sexual revolution and environmental movements of the 1960s and 1970s marked significant departures from previous societal norms.</li>
<li>Maslow’s hierarchy of needs provides a framework for understanding the shifts in societal focus from survival and security to self-actualization and societal change.</li>
</ul>
</section>
<section id="facts-5" class="level3">
<h3 class="anchored" data-anchor-id="facts-5">Facts</h3>
<ul>
<li>Isaac Newton’s discoveries in the 17th century laid the groundwork for modern physics and astronomy.</li>
<li>The 1960s cultural revolution included movements for civil rights, environmentalism, and feminism, drastically altering Western, particularly American, societal norms.</li>
<li>H.G. Wells’s “The Time Machine” foresaw societal shifts towards leisure and away from struggle, predicting a focus on art and eroticism over survival and advancement.</li>
<li>The environmental and technological advancements of the 20th century, such as nuclear power and the sexual revolution, were influenced by earlier scientific and cultural movements.</li>
</ul>
</section>
<section id="recommendations-5" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-5">Recommendations</h3>
<ul>
<li>Embrace the value of scientific advancement and maintain a balance between technological progress and cultural shifts.</li>
<li>Foster an understanding of history to better appreciate the evolution of societal norms and values.</li>
<li>Encourage critical thinking and skepticism to navigate the complexities of modern societal challenges, including environmental concerns and technological ethics.</li>
<li>Promote education and dialogue on the importance of balancing human needs across Maslow’s hierarchy to ensure a society that values both scientific progress and cultural richness.</li>
</ul>
</section>
<section id="critical-analysis-5" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-5">Critical Analysis</h3>
<ul>
<li><p>The juxtaposition of scientific achievements with cultural shifts underscores a recurring cycle in human history where periods of technological advancement are often followed by significant societal and cultural transformations.</p></li>
<li><p>The narrative suggests a potential underestimation of the importance of cultural movements in driving societal progress, implying a need to reevaluate how we define progress.</p></li>
<li><p>The discussion on Maslow’s hierarchy as applied to societal shifts provides insight into the evolving priorities of civilizations, hinting at a universal pattern of human development that transcends individual cultures.</p></li>
<li><p>The emphasis on scientific discovery and technological advancement as the pinnacle of human achievement might overlook the critical role of cultural and emotional development in shaping a balanced and fulfilled society.</p></li>
<li><p>The critique of the 1960s and 1970s cultural shifts as a departure from scientific rationalism to emotionalism might not fully appreciate the necessary role of cultural evolution in addressing the limitations and ethical considerations of scientific progress.</p></li>
</ul>
</section>
<section id="future-perspectives-5" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-5">Future Perspectives</h3>
<ul>
<li>The chapter suggests a future where balancing scientific advancements with cultural and emotional intelligence becomes crucial in addressing global challenges, such as environmental sustainability and social equity.</li>
<li>It hints at the potential for a new synthesis of technological and cultural evolution, where advancements in science and technology are guided by ethical considerations and a deep understanding of human needs and values.</li>
</ul>
</section>
</section>
<section id="forbidden-fruit" class="level2">
<h2 class="anchored" data-anchor-id="forbidden-fruit">Forbidden Fruit</h2>
<section id="summary-7" class="level3">
<h3 class="anchored" data-anchor-id="summary-7">Summary</h3>
<p>Chapter 8 discusses the cultural and technological shifts from the 1960s to the 1970s, the stagnation of technological advancements, particularly in the realm of flying cars, and the impact of bureaucracy, regulation, and societal attitudes towards technology on innovation. It contrasts the optimism and progress of the early 20th century with the regulatory and cultural hurdles that have since hindered technological development, using the example of flying cars to illustrate a broader stagnation in technological innovation due to increased regulation, bureaucratic inefficiency, and a societal shift away from technological optimism.</p>
</section>
<section id="key-ideas" class="level3">
<h3 class="anchored" data-anchor-id="key-ideas">Key Ideas</h3>
<ul>
<li>The 1960s and 70s marked a significant cultural shift away from trust and collaboration towards individualism and skepticism of technology.</li>
<li>Ergophobia, or the fear of work and technology, transitioned from a rare condition to a widespread societal attitude, negatively impacting technological advancement.</li>
<li>Three main barriers to technological progress identified: bureaucratic inefficiency, societal fear of technology, and excessive regulation.</li>
<li>Historical examples, such as the failure of the Aerocar and other flying car projects, illustrate how regulatory hurdles and societal attitudes prevented the commercialization and widespread adoption of revolutionary technologies.</li>
<li>The stagnation of technological progress, referred to as the “Great Stagnation,” is largely attributed to the exponential growth in regulations and a shift in societal values towards skepticism of technological advancement.</li>
<li>The concept of productivity and its impact on technological adoption and societal advancement is discussed, highlighting how increases in productivity made technologies like the family car accessible to the masses, a contrast to the stagnation seen in more recent decades.</li>
</ul>
</section>
<section id="facts-6" class="level3">
<h3 class="anchored" data-anchor-id="facts-6">Facts</h3>
<ul>
<li>By the 1970s, 20% of adult Americans could have owned a flying car, had technological and societal conditions allowed.</li>
<li>The Interstate Highway System significantly contributed to economic growth in the 1950s, showcasing the potential impact of technological advancements on the economy.</li>
<li>The Federal Regulatory Code is over 175,000 pages long, illustrating the complexity and breadth of current regulations.</li>
<li>The cost of compliance with federal regulations significantly impacts economic growth, with studies suggesting that maintaining the 1949 level of regulation could have resulted in much higher median household incomes.</li>
<li>The German economic miracle post-World War II demonstrated how reducing regulation can rapidly stimulate economic growth.</li>
</ul>
</section>
<section id="recommendations-6" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-6">Recommendations</h3>
<ul>
<li>To overcome the current stagnation in technological innovation, a reduction in bureaucratic inefficiency and excessive regulation is necessary.</li>
<li>Embracing a cultural shift towards valuing and trusting technological advancements could foster an environment more conducive to innovation.</li>
<li>Reevaluating societal attitudes towards technology, from fear and skepticism to optimism and support, could help revive the progress seen in earlier eras.</li>
<li>Policymakers and regulators should consider the long-term impacts of regulations on innovation and strive for a balance that protects public interests without stifling technological advancement.</li>
<li>Encouraging public and private investment in technological research and development can pave the way for breakthroughs similar to those seen in the early 20th century.</li>
</ul>
</section>
<section id="critical-analysis-6" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-6">Critical Analysis</h3>
<ul>
<li>The text highlights a paradox: while technological advancements have the potential to significantly improve quality of life and economic prosperity, societal and regulatory barriers often hinder their development and adoption.</li>
<li>It raises questions about the role of government and regulatory bodies in innovation, suggesting that while some oversight is necessary for safety and ethical considerations, excessive regulation can be detrimental.</li>
<li>The comparison between the rapid advancements of the early 20th century and the stagnation of recent decades prompts a reflection on the societal values and priorities that drive or inhibit progress.</li>
<li>The discussion on productivity and its impact on technological adoption offers insights into how economic factors influence the accessibility and widespread use of new technologies.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>history</category>
  <guid>christianjmills.com/posts/where-is-my-flying-car-book-notes/part-1/</guid>
  <pubDate>Sun, 18 Feb 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Notes on The Path of Least Resistance</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/the-path-of-least-resistance-book-notes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Book LInks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://www.penguinrandomhouse.com/books/56713/the-path-of-least-resistance-by-robert-fritz/">Publisher Page</a></li>
<li><a href="https://www.robertfritz.com/wp/">Author’s Website</a></li>
</ul>
</div>
</div>
<ul>
<li>Ch. 1: The Path of Least Resistance</li>
<li>Ch. 2: The Reactive-Responsive Orientation</li>
<li>Ch. 3: Creating Is No Problem</li>
<li>Ch. 4: Creating</li>
<li>Ch. 5: The Orientation of the Creative</li>
<li>Ch. 6: Tension Seeks Resolution</li>
<li>Ch. 7: Compensating Strategies</li>
<li>Ch. 8: Structural Tension</li>
<li>Ch. 9: Vision</li>
<li>Ch. 10: Current Reality</li>
<li>Ch. 11: The Creative Cycle</li>
<li>Ch. 12: Germination and Choice</li>
<li>Ch. 13: Primary, Secondary, and Fundamental Choice</li>
<li>Ch. 14: Assimilation</li>
<li>Ch. 15: Momentum</li>
<li>Ch. 16: Strategic Moments</li>
<li>Ch. 17: Completion</li>
<li>Ch. 18: The Power of Transcendence</li>
</ul>
<section id="the-path-of-least-resistance" class="level2">
<h2 class="anchored" data-anchor-id="the-path-of-least-resistance">The Path of Least Resistance</h2>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>The book “The Path of Least Resistance” by Robert Fritz explores how individuals can become the creative force in their own lives by understanding and altering the structures that guide their actions. Through the metaphor of Boston’s cow paths, Fritz illustrates how paths of least resistance are formed and how they can determine behavior. The book is structured around three main insights: our lives follow the path of least resistance, our life’s structure determines its path, and by changing this structure, we can direct our lives toward what we truly want.</p>
</section>
<section id="key-concepts" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts">Key Concepts</h3>
<ul>
<li><strong>Path of Least Resistance:</strong> The natural tendency of energy, whether in nature or human behavior, to follow the easiest route, shaped by existing structures.</li>
<li><strong>Underlying Structures:</strong> The fundamental parts and their relationships within a system that determine the path of least resistance.</li>
<li><strong>Creating Change:</strong> The possibility of altering the basic structures of one’s life to change its direction towards desired outcomes.</li>
</ul>
</section>
<section id="ideas" class="level3">
<h3 class="anchored" data-anchor-id="ideas">Ideas</h3>
<ul>
<li>People and nature inherently follow the path of least resistance, guided by the structure of their environment or life.</li>
<li>The underlying structure of life determines personal paths of least resistance, shaping behaviors and outcomes.</li>
<li>Changing the fundamental structures of life can lead to desired changes and outcomes, making new paths the path of least resistance.</li>
<li>Understanding and applying structural thinking, rather than a psychological or problem-solving approach, can lead to meaningful change.</li>
</ul>
</section>
<section id="practical-implications" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications">Practical Implications</h3>
<ul>
<li>Recognizing that attempts to change behavior without addressing underlying structures are likely to result in a return to old patterns.</li>
<li>The importance of identifying and modifying the structures that lead to undesired outcomes in life.</li>
<li>The potential for applying the principles of the creative process, traditionally used in arts, to personal and professional life for better outcomes.</li>
</ul>
</section>
<section id="supporting-evidence" class="level3">
<h3 class="anchored" data-anchor-id="supporting-evidence">Supporting Evidence</h3>
<ul>
<li>The analogy of Boston’s cow paths and the behavior of energy in nature (water, wind, electricity) illustrate how paths of least resistance are formed by existing structures.</li>
<li>Historical examples of successful change, whether in city planning or personal habits, highlight the importance of structural change over mere behavioral adjustments.</li>
</ul>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<ul>
<li>Assess and identify the underlying structures in one’s life that dictate current paths and outcomes.</li>
<li>Adopt a structural perspective to recognize and address the real causes of issues, rather than focusing solely on symptoms or behaviors.</li>
<li>Engage in the creative process to design and implement new structures that align with desired goals and outcomes.</li>
<li>Apply the principles learned from the creative process in arts and sciences to broader aspects of life, including career and personal development.</li>
</ul>
</section>
<section id="additional-insights" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights">Additional Insights</h3>
<ul>
<li>Many accomplished individuals in creative fields fail to apply the principles of the creative process to their own lives, highlighting a common disconnect between professional skills and personal development.</li>
<li>The creative process offers a model for moving from problem orientation to creation orientation, focusing on bringing into being desired results rather than merely solving problems.</li>
</ul>
</section>
<section id="critical-analysis" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis">Critical Analysis</h3>
<ul>
<li>The book challenges conventional approaches to personal change by focusing on structural rather than psychological factors. This perspective shifts the focus from internal states and behaviors to the external and internal structures that govern them.</li>
<li>While the book provides a compelling argument for the importance of structural thinking, it might underplay the role of psychological factors and the complexity of human behavior in some instances.</li>
</ul>
</section>
</section>
<section id="the-reactive-responsive-orientation" class="level2">
<h2 class="anchored" data-anchor-id="the-reactive-responsive-orientation">The Reactive-Responsive Orientation</h2>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary</h3>
<p>Chapter 2 discusses the reactive-responsive orientation formed during childhood, influenced by the need to adapt to or rebel against given circumstances and societal norms. It explores how individuals either react to or respond to their environment, based on learned behaviors from childhood, and how this orientation leads to a feeling of powerlessness, as actions are dictated by external or internal circumstances.</p>
</section>
<section id="key-concepts-1" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-1">Key Concepts</h3>
<ul>
<li><strong>Reactive-Responsive Orientation:</strong> A life approach based on reacting to or responding to circumstances, leading to a cycle of behavior that reinforces a sense of powerlessness.</li>
<li><strong>Powerlessness:</strong> The underlying presumption of the reactive-responsive orientation, where individuals feel actions and choices are determined by external circumstances.</li>
<li><strong>Avoidance Strategies:</strong> Tactics developed to evade unwanted situations or outcomes, reinforcing the cycle of reactivity or responsiveness without truly addressing underlying desires or needs.</li>
<li><strong>Preemptive Strikes:</strong> Actions taken to prevent perceived negative outcomes, often based on past experiences, which can limit personal growth and satisfaction.</li>
<li><strong>Closed and Circular System:</strong> The cycle of moving between reactive and responsive behaviors, which keeps individuals within the confines of a reactive-responsive orientation without real change.</li>
</ul>
</section>
<section id="practical-implications-1" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-1">Practical Implications</h3>
<ul>
<li><strong>Understanding Behavior:</strong> Recognizing the origins of reactive or responsive behavior can be a first step towards changing unhelpful patterns.</li>
<li><strong>Breaking the Cycle:</strong> Identifying and challenging the presumption of powerlessness can lead to more autonomous and creative approaches to life.</li>
<li><strong>Redefining Success:</strong> Success achieved through avoidance or preemptive strategies often does not lead to fulfillment, suggesting the need for a reevaluation of personal goals and methods of achieving them.</li>
<li><strong>Personal Growth:</strong> Moving beyond the reactive-responsive orientation requires a deep understanding of one’s motivations and behaviors, setting the stage for genuine change.</li>
</ul>
</section>
<section id="recommendations-1" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-1">Recommendations</h3>
<ul>
<li>Reflect on personal behaviors to identify reactive or responsive patterns and their origins.</li>
<li>Challenge the assumption of powerlessness by identifying areas of life where one can exercise creative control.</li>
<li>Develop new strategies for dealing with circumstances that focus on personal values and goals, rather than avoidance or compliance.</li>
<li>Seek experiences that encourage autonomy and self-expression, breaking the cycle of reactivity or responsiveness.</li>
</ul>
</section>
<section id="additional-insights-1" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-1">Additional Insights</h3>
<ul>
<li>The chapter highlights how societal and familial norms shape individual behavior patterns from a young age, emphasizing the importance of conscious effort in developing new orientations towards life.</li>
<li>It suggests that true satisfaction and fulfillment come from becoming the creative force in one’s own life, rather than adhering to externally imposed expectations or avoiding perceived negative outcomes.</li>
</ul>
</section>
</section>
<section id="creating-is-no-problem" class="level2">
<h2 class="anchored" data-anchor-id="creating-is-no-problem">Creating Is No Problem</h2>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<p>Chapter 3 emphasizes the distinction between problem-solving and creating. Fritz argues that while problem-solving aims to eliminate issues, creating focuses on bringing into existence something desired. He critiques the prevalent problem-solving mentality in society and advocates for a creative approach to life and societal issues.</p>
</section>
<section id="key-concepts-2" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-2">Key Concepts</h3>
<ul>
<li><strong>Problem Solving vs.&nbsp;Creating:</strong> Problem-solving is about eliminating issues, while creating is about bringing desired outcomes into reality.</li>
<li><strong>Problem Mentality:</strong> Society often focuses on identifying and solving problems rather than envisioning and creating desired outcomes.</li>
<li><strong>Creative Process:</strong> The true creative process involves envisioning what one wants to create and methodically bringing it to reality, differing from merely generating solutions to problems.</li>
</ul>
</section>
<section id="practical-implications-2" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-2">Practical Implications</h3>
<ul>
<li><strong>Individual and Societal Growth:</strong> Shifting focus from problem-solving to creating can lead to more meaningful individual and societal growth.</li>
<li><strong>Leadership:</strong> Effective leaders and statesmen are highlighted as those who build and create, not just solve problems.</li>
<li><strong>Global Development:</strong> The approach to global development, such as the case in Uganda (prioritizing self-empowerment over outside intervention), shows that empowering individuals to create can have more sustainable and impactful results than traditional problem-solving methods.</li>
</ul>
</section>
<section id="critical-analysis-1" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-1">Critical Analysis</h3>
<ul>
<li>Fritz challenges the conventional emphasis on problem-solving, suggesting that it often leads to temporary fixes rather than sustainable solutions.</li>
<li>He argues that a creative approach, focusing on the creation of desired outcomes, is more effective for individual fulfillment and societal progress.</li>
<li>The distinction between problem-solving and creating is crucial for understanding how we approach challenges and opportunities in life and society.</li>
<li>The transition from a problem-solving to a creating mindset may require significant societal and educational reform, as well as a shift in individual attitudes and behaviors.</li>
<li>Fritz’s examples, including the contrast between responses to crises like the famine in Ethiopia and development projects in Uganda, illustrate the effectiveness of a creative approach.</li>
</ul>
</section>
<section id="recommendations-2" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-2">Recommendations</h3>
<ul>
<li><strong>Shift Focus:</strong> Individuals and organizations should shift their focus from merely solving problems to envisioning and creating desired outcomes.</li>
<li><strong>Educate on Creativity:</strong> There should be more emphasis on educating people about the creative process and its importance in all aspects of life.</li>
<li><strong>Promote Creative Leadership:</strong> Encourage leadership that focuses on building and creating, rather than just problem identification and resolution.</li>
</ul>
</section>
<section id="future-perspectives" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives">Future Perspectives</h3>
<ul>
<li><strong>Shifting Societal Paradigms:</strong> A future where societies prioritize creative solutions over problem-centric approaches could lead to more innovative and sustainable developments.</li>
<li><strong>Education Reform:</strong> Educational systems might increasingly focus on nurturing creativity and the ability to create, preparing individuals to be creators in their own lives and in society.</li>
<li><strong>Increased Collaboration:</strong> A creative approach to life encourages collaboration over competition, as individuals and groups work towards shared visions of the future.</li>
</ul>
</section>
</section>
<section id="creating" class="level2">
<h2 class="anchored" data-anchor-id="creating">Creating</h2>
<section id="summary-3" class="level3">
<h3 class="anchored" data-anchor-id="summary-3">Summary</h3>
<p>Chapter 4 delves into the essence of creativity, illustrating how adverse conditions like those in East Harlem’s ghettos can foster unique artistic expressions, such as graffiti art. It challenges the notion that creativity is a product of one’s environment and instead presents it as an innate human capability that thrives regardless of circumstances. Through anecdotes and analysis, it posits that everyone has the potential to be creative in their endeavors, not just in traditional arts but across all aspects of life.</p>
</section>
<section id="ideas-1" class="level3">
<h3 class="anchored" data-anchor-id="ideas-1">Ideas</h3>
<ul>
<li>Creativity can emerge from challenging and adverse conditions, not just conducive environments.</li>
<li>The transformation of graffiti from vandalism to a recognized art form exemplifies the evolution of creativity in response to societal changes.</li>
<li>Creativity is an inherent human trait that transcends socio-economic and educational barriers.</li>
<li>The creative process is universal and can be applied in various fields beyond the arts, like manual labor and innovation in everyday life.</li>
</ul>
</section>
<section id="facts" class="level3">
<h3 class="anchored" data-anchor-id="facts">Facts</h3>
<ul>
<li>Graffiti art originated as a form of vandalism but evolved into a competitive and recognized art form, with some artists eventually gaining gallery representation.</li>
<li>Tokyo invited one of the prominent graffiti artists to paint murals on their subway cars, showcasing international recognition of this art form.</li>
<li>Historical figures like Pablo Casals and Carl Rogers emphasized the universality and value of creativity across different domains of human activity.</li>
</ul>
</section>
<section id="recommendations-3" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-3">Recommendations</h3>
<ul>
<li>Embrace creativity as an accessible process, not limited by current circumstances or traditional environments designed to foster creativity.</li>
<li>Engage actively in the creative process by conceiving clear results, understanding the current state of affairs, taking action, and adjusting based on feedback.</li>
<li>Recognize and develop the skills necessary for creativity, including the ability to view reality objectively and to innovate beyond conventional methods.</li>
<li>Understand and navigate the rhythms of the creative process: germination, assimilation, and completion, to effectively bring ideas to fruition.</li>
<li>Build momentum in creative endeavors through continuous practice and learning, recognizing that expertise and the ability to innovate improve over time.</li>
</ul>
</section>
<section id="critical-analysis-2" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-2">Critical Analysis</h3>
<ul>
<li>The narrative challenges the conventional wisdom that creativity is solely a product of favorable conditions, arguing that adversity can also be a powerful catalyst for creative expression.</li>
<li>The story of graffiti’s evolution in East Harlem serves as a metaphor for the potential of creativity to transcend boundaries and alter perceptions in society.</li>
<li>The text critiques the educational system’s failure to nurture the skill of creativity, suggesting that a reevaluation of teaching methods could better prepare individuals for creative thinking and problem-solving.</li>
</ul>
</section>
<section id="future-perspectives-1" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-1">Future Perspectives</h3>
<ul>
<li>The narrative suggests that recognizing and fostering creativity in unconventional settings could lead to innovative solutions to societal challenges.</li>
<li>There is an implication that the future of education and professional development could benefit from integrating the principles of the creative process, promoting a more holistic approach to problem-solving and innovation.</li>
</ul>
</section>
</section>
<section id="the-orientation-of-the-creative" class="level2">
<h2 class="anchored" data-anchor-id="the-orientation-of-the-creative">The Orientation of the Creative</h2>
<section id="summary-4" class="level3">
<h3 class="anchored" data-anchor-id="summary-4">Summary</h3>
<p>Chapter 5 discusses the difference between reactive/responsive orientation and the creative orientation. It emphasizes that shifting to a creative orientation enables individuals to become the predominant force in their lives, using circumstances as tools rather than being controlled by them. The text explores the essence of creativity, the importance of creating for the sake of love, and the process of making up what one wants to create, as opposed to discovering or revealing it.</p>
</section>
<section id="key-concepts-3" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-3">Key Concepts</h3>
<section id="creative-vs.-reactiveresponsive-orientation" class="level4">
<h4 class="anchored" data-anchor-id="creative-vs.-reactiveresponsive-orientation">Creative vs.&nbsp;Reactive/Responsive Orientation</h4>
<ul>
<li>The creative process is distinct from merely reacting or responding to circumstances.</li>
<li>Being creative involves organizing life around what one wants to create, rather than circumstances.</li>
<li>The transition to a creative orientation is a fundamental shift, not a gradual change.</li>
</ul>
</section>
<section id="the-nature-of-creativity" class="level4">
<h4 class="anchored" data-anchor-id="the-nature-of-creativity">The Nature of Creativity</h4>
<ul>
<li>Creativity is about making up what one wants to create, not discovering or uncovering hidden desires.</li>
<li>Emotions are not the primary driver of creation; creators work with or without positive emotions.</li>
<li>The act of creating is motivated by the desire for the creation itself to exist.</li>
</ul>
</section>
<section id="the-role-of-love-in-creativity" class="level4">
<h4 class="anchored" data-anchor-id="the-role-of-love-in-creativity">The Role of Love in Creativity</h4>
<ul>
<li>True creation is driven by love for the work itself, not for external rewards or recognition.</li>
<li>This concept parallels the unconditional love a parent has for a child, emphasizing creation for its own sake.</li>
</ul>
</section>
<section id="misconceptions-and-societys-influence" class="level4">
<h4 class="anchored" data-anchor-id="misconceptions-and-societys-influence">Misconceptions and Society’s Influence</h4>
<ul>
<li>Society often misunderstands the creative process, focusing on the result rather than the process of creation.</li>
<li>The educational system typically emphasizes learning processes rather than encouraging students to focus on what they want to create.</li>
</ul>
</section>
<section id="the-process-of-creating" class="level4">
<h4 class="anchored" data-anchor-id="the-process-of-creating">The Process of Creating</h4>
<ul>
<li>Creating involves deciding what one wants without being confined by existing conditions or precedents.</li>
<li>The creative process is flexible and can change based on the desired outcome, emphasizing the function over form.</li>
</ul>
</section>
</section>
<section id="recommendations-4" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-4">Recommendations</h3>
<ul>
<li><strong>Embrace a Creative Orientation:</strong> Shift focus from reacting to circumstances to actively creating desired outcomes.</li>
<li><strong>Create for Love, Not Reward:</strong> Engage in creative activities for the inherent satisfaction and love of the process, rather than external validation.</li>
<li><strong>Question and Explore:</strong> Continuously ask “What do I want to create?” to keep the creative process aligned with personal desires and goals.</li>
<li><strong>Allow Flexibility in Process:</strong> Be open to changing processes based on what works best for achieving the desired result, rather than sticking rigidly to preconceived methods.</li>
<li><strong>Cultivate Emotional Independence:</strong> Work towards goals regardless of current emotional states, recognizing that emotions are transient and not the core of creative action.</li>
</ul>
</section>
<section id="ideas-2" class="level3">
<h3 class="anchored" data-anchor-id="ideas-2">Ideas</h3>
<ul>
<li>The notion that creativity comes from a place of love and intrinsic motivation, rather than external circumstances or rewards.</li>
<li>The creative orientation as a paradigm shift that allows individuals to use circumstances to their advantage rather than being hindered by them.</li>
<li>The importance of making up what one wants to create as a cornerstone of the creative process, challenging the conventional wisdom that creativity involves discovery or revelation.</li>
</ul>
</section>
<section id="facts-1" class="level3">
<h3 class="anchored" data-anchor-id="facts-1">Facts</h3>
<ul>
<li><strong>Historical Perspectives:</strong> The chapter references historical figures like Robert Frost, Albert Einstein, Marie Curie, and Thomas Edison to illustrate different aspects of the creative process.</li>
<li><strong>Educational Critique:</strong> Fritz critiques the educational system for focusing more on teaching processes than on encouraging students to identify and pursue their own creative desires.</li>
<li><strong>Creative Process Insights:</strong> The text provides insights into the creative process, emphasizing the importance of asking “What do I want to create?” over “How do I create it?”</li>
</ul>
</section>
</section>
<section id="tension-seeks-resolution" class="level2">
<h2 class="anchored" data-anchor-id="tension-seeks-resolution">Tension Seeks Resolution</h2>
<section id="summary-5" class="level3">
<h3 class="anchored" data-anchor-id="summary-5">Summary</h3>
<p>Chapter 6 by Robert Fritz discusses the concept of tension seeking resolution and how structures either oscillate or resolve towards a final outcome. The chapter emphasizes the importance of creating structures that resolve in favor of the creation and introduces the concept of tension resolution systems found in nature and human behavior. It highlights the challenges of structural conflict, where competing tension resolution systems cause oscillation and prevent effective resolution.</p>
</section>
<section id="key-concepts-4" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-4">Key Concepts</h3>
<ul>
<li><strong>Tension Seeks Resolution:</strong> A fundamental principle in nature and human behavior where structures naturally move towards resolving tension.</li>
<li><strong>Oscillating vs.&nbsp;Resolving Structures:</strong> Oscillating structures are characterized by recurring patterns without final resolution, while resolving structures move towards a definitive outcome.</li>
<li><strong>Structural Conflict:</strong> Occurs when two tension resolution systems compete, leading to oscillation and preventing a clear path to resolution.</li>
</ul>
</section>
<section id="noteworthy-facts" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts">Noteworthy Facts</h3>
<ul>
<li>Tension resolution systems are ubiquitous in nature, from the formation of galaxies to the behavior of human beings.</li>
<li>Simple tension resolution systems involve a single tension that the structure seeks to resolve, such as the natural tendency to answer a question that has been posed.</li>
<li>Complex tension resolution systems can lead to oscillation, especially when there is a conflict between two competing systems, such as the desire to eat when hungry versus the desire to lose weight.</li>
</ul>
</section>
<section id="practical-implications-3" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-3">Practical Implications</h3>
<ul>
<li>Understanding the nature of structural conflict can help individuals recognize why certain goals or changes are difficult to achieve.</li>
<li>Recognizing the presence of oscillating structures in one’s life can be the first step towards creating resolving structures that support achieving desired outcomes.</li>
</ul>
</section>
<section id="supporting-evidence-1" class="level3">
<h3 class="anchored" data-anchor-id="supporting-evidence-1">Supporting Evidence</h3>
<ul>
<li>Examples provided include the struggle between the desire to eat and the goal to lose weight, and the oscillation faced by corporations balancing short-term profitability and long-term growth investments.</li>
</ul>
</section>
<section id="recommendations-5" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-5">Recommendations</h3>
<ul>
<li>To overcome structural conflict, it’s crucial to identify and adjust the underlying structures rather than focusing solely on changing behaviors or beliefs.</li>
<li>Exploring the creative process can offer ways to form resolving structures that align with one’s goals and desires, moving away from the limitations of oscillating structures.</li>
</ul>
</section>
<section id="additional-insights-2" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-2">Additional Insights</h3>
<ul>
<li>The discussion on the nature of desire versus the belief in the impossibility of fulfilling certain desires highlights a deep-rooted structural conflict many people face, impacting their ability to achieve what they truly want.</li>
</ul>
</section>
<section id="future-perspectives-2" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-2">Future Perspectives</h3>
<ul>
<li>As we further understand and apply the principles of tension resolution and structural conflict resolution, there’s potential for significant shifts in personal development, organizational behavior, and even societal change. The key lies in our ability to form and sustain resolving structures that align with our deepest desires and creative aspirations.</li>
</ul>
</section>
</section>
<section id="compensating-strategies" class="level2">
<h2 class="anchored" data-anchor-id="compensating-strategies">Compensating Strategies</h2>
<section id="summary-6" class="level3">
<h3 class="anchored" data-anchor-id="summary-6">Summary</h3>
<p>Chapter 7 discusses the concept of compensating strategies developed by individuals to manage structural conflicts in their lives. These strategies are gradually formed as a response to underlying structural issues, leading to oscillation and preventing true resolution and achievement of desired outcomes. Fritz explores three major compensating strategies: staying within an area of tolerable conflict, conflict manipulation, and willpower manipulation, explaining how each strategy ultimately reinforces existing structural conflicts and contributes to a cycle of oscillation.</p>
</section>
<section id="key-concepts-5" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-5">Key Concepts</h3>
<ul>
<li><strong>Structural Conflicts</strong>: Situations where underlying structures in one’s life lead to ongoing problems without resolution.</li>
<li><strong>Compensating Strategies</strong>: Methods individuals develop over time to cope with or temporarily alleviate the symptoms of structural conflicts.</li>
<li><strong>Oscillation</strong>: The back-and-forth movement between wanting something and the structural impediments to achieving it, caused by unresolved structural conflicts.</li>
</ul>
</section>
<section id="compensating-strategies-1" class="level3">
<h3 class="anchored" data-anchor-id="compensating-strategies-1">Compensating Strategies</h3>
<section id="area-of-tolerable-conflict" class="level4">
<h4 class="anchored" data-anchor-id="area-of-tolerable-conflict">Area of Tolerable Conflict</h4>
<ul>
<li>Involves minimizing the impact of structural conflict to keep discomfort within bearable limits, leading to a cycle of limited aspirations and mediocrity.</li>
</ul>
</section>
<section id="conflict-manipulation" class="level4">
<h4 class="anchored" data-anchor-id="conflict-manipulation">Conflict Manipulation</h4>
<ul>
<li>A strategy where individuals motivate themselves or others through the anticipation of negative consequences, leading to temporary action but ultimately reinforcing feelings of powerlessness.</li>
</ul>
</section>
<section id="willpower-manipulation" class="level4">
<h4 class="anchored" data-anchor-id="willpower-manipulation">Willpower Manipulation</h4>
<ul>
<li>Relies on forcing oneself through determination, positive thinking, or other means of self-coercion, often resulting in short-term gains but long-term reinforcement of the structural conflict.</li>
</ul>
</section>
</section>
<section id="implications" class="level3">
<h3 class="anchored" data-anchor-id="implications">Implications</h3>
<ul>
<li><strong>Emotional and Behavioral Oscillation</strong>: The emotional highs and lows and inconsistent behaviors resulting from these strategies, which prevent sustained progress towards goals.</li>
<li><strong>Reinforcement of Structural Conflict</strong>: How each strategy, rather than resolving the underlying issues, actually perpetuates them.</li>
<li><strong>Societal and Personal Impacts</strong>: The widespread adoption of these strategies across various domains of life, including personal development, organizational behavior, and societal norms, leading to a culture of mediocrity and unfulfilled potential.</li>
</ul>
</section>
<section id="recommendations-for-change" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-for-change">Recommendations for Change</h3>
<ul>
<li>Recognizing the Limitations of Compensating Strategies: An acknowledgment of the inherent flaws in these approaches as a first step towards real change.</li>
<li>Structural Change as a Precondition for Behavioral Change: Emphasizing the need to address and modify underlying structures before lasting behavioral change can occur.</li>
<li>Exploring Alternative Structures: The importance of shifting to new structures that genuinely support the achievement of desired outcomes, moving away from the reactive patterns dictated by structural conflicts.</li>
</ul>
</section>
<section id="reflections-on-positive-thinking-and-willpower" class="level3">
<h3 class="anchored" data-anchor-id="reflections-on-positive-thinking-and-willpower">Reflections on Positive Thinking and Willpower</h3>
<ul>
<li>Critique of Positive Thinking: The counterproductive nature of trying to force a positive outlook without addressing underlying structural issues.</li>
<li>The Role of Truth and Reality in Creative Processes: Highlighting the necessity for a clear and honest assessment of one’s situation as a foundation for effective creation and change.</li>
</ul>
</section>
</section>
<section id="structural-tension" class="level2">
<h2 class="anchored" data-anchor-id="structural-tension">Structural Tension</h2>
<section id="summary-7" class="level3">
<h3 class="anchored" data-anchor-id="summary-7">Summary</h3>
<p>Chapter 8 discusses the concept of structural tension in the creative process. It highlights the importance of recognizing and utilizing the discrepancy between current reality and the desired outcome to fuel creativity. The chapter argues that attempts to change within a structure of conflict lead to oscillation and compensation, suggesting instead the formation of a new structure that transcends structural conflict. This new structure should simplify complex structures and prioritize the creator’s vision, using the energy of discrepancy to drive creation.</p>
</section>
<section id="key-concepts-6" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-6">Key Concepts</h3>
<ul>
<li><strong>Structural Tension:</strong> The discrepancy between what you want (vision) and what you currently have (reality), which forms the basis of the creative process.</li>
<li><strong>Structural Conflict:</strong> A condition where efforts to change are trapped within conflicting structures, leading to oscillation and ineffective outcomes.</li>
<li><strong>Discrepancy as Creative Force:</strong> Emphasizes the role of discrepancy as a positive force in creation, contrary to common perceptions that view it negatively.</li>
</ul>
</section>
<section id="ideas-3" class="level3">
<h3 class="anchored" data-anchor-id="ideas-3">Ideas</h3>
<ul>
<li>Structural tension is essential for creativity, acting both as the framework and the driving force of the creative process.</li>
<li>Creators must learn to appreciate and utilize discrepancy, seeing it as a source of energy rather than a problem to avoid.</li>
<li>The ability to accurately perceive and articulate both one’s vision and current reality is crucial for generating and maintaining structural tension.</li>
<li>Mastery of structural tension is a developed skill and an acquired taste, improving over time with practice and experience.</li>
</ul>
</section>
<section id="facts-2" class="level3">
<h3 class="anchored" data-anchor-id="facts-2">Facts</h3>
<ul>
<li>Most attempts at change within existing structures of conflict result in compensation and oscillation, not genuine transformation.</li>
<li>A structure superior to structural conflict incorporates the conflict into itself and simplifies complex structures.</li>
<li>Creators have a higher tolerance for discrepancy compared to others, using it as a tool in the creative process.</li>
<li>The process of creation involves navigating forces like contrasts, opposites, similarities, and differences, with discrepancy being a key element.</li>
</ul>
</section>
<section id="recommendations-6" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-6">Recommendations</h3>
<ul>
<li>Cultivate an understanding and appreciation for the role of discrepancy in the creative process.</li>
<li>Practice forming and maintaining structural tension by clearly defining your vision and accurately assessing your current reality.</li>
<li>Avoid weakening structural tension by misrepresenting your desires or the current state of affairs.</li>
<li>Engage actively with the creative process, using the energy generated by discrepancy to propel your efforts towards realizing your vision.</li>
<li>Be wary of common pitfalls that reduce structural tension, such as compromising your vision or inaccurately assessing reality.</li>
<li>Experiment and test the boundaries of what is possible, rather than imposing limitations on yourself prematurely.</li>
</ul>
</section>
<section id="critical-analysis-3" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-3">Critical Analysis</h3>
<ul>
<li>The concept of structural tension challenges conventional attitudes towards discrepancy and conflict in the creative process, proposing a paradigm where these elements are not only inevitable but beneficial.</li>
<li>The emphasis on the dynamic interplay between vision and reality offers a practical framework for navigating the complexities of creation, though it requires significant self-awareness and honesty.</li>
<li>Fritz’s ideas invite a reevaluation of societal norms around goal-setting and achievement, advocating for a more nuanced understanding of the creative process that accommodates uncertainty and embraces potential failure as part of the journey towards innovation.</li>
</ul>
</section>
<section id="future-perspectives-3" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-3">Future Perspectives</h3>
<ul>
<li>Exploring the implications of structural tension in collaborative and organizational settings could offer valuable insights into how groups can harness collective creativity and navigate structural conflicts effectively.</li>
<li>Further research into the psychological and social factors that influence an individual’s capacity to tolerate and utilize discrepancy could enhance the applicability of Fritz’s theories across diverse contexts.</li>
</ul>
</section>
</section>
<section id="vision" class="level2">
<h2 class="anchored" data-anchor-id="vision">Vision</h2>
<section id="summary-8" class="level3">
<h3 class="anchored" data-anchor-id="summary-8">Summary</h3>
<p>Chapter 9 emphasizes beginning the creative process with a clear vision of the desired outcome, a practice contrary to conventional education that focuses on procedural learning before understanding the ultimate goal. This approach fosters purpose and direction in learning and creation.</p>
</section>
<section id="ideas-4" class="level3">
<h3 class="anchored" data-anchor-id="ideas-4">Ideas</h3>
<ul>
<li><strong>Begin with the End in Mind</strong>: Starting the creative process with a vision of the final result enhances focus and effectiveness.</li>
<li><strong>Blank Canvas Approach</strong>: Conceiving new ideas effectively starts from a position of openness, without preconceived notions.</li>
<li><strong>Visual Thinking</strong>: Visualizing the desired outcome can aid in comprehensively understanding and planning the creation.</li>
<li><strong>Flexibility in Creativity</strong>: While some creators work with clear visions, others discover their path through experimentation, highlighting the diverse methods in the creative process.</li>
<li><strong>Concept vs.&nbsp;Vision</strong>: Transitioning from a broad concept to a specific, focused vision is a critical step in creation, emphasizing the importance of clarity and specificity.</li>
<li><strong>Knowing What You Want</strong>: Asking oneself what one truly desires is foundational in creating a vision and setting the stage for effective creation.</li>
</ul>
</section>
<section id="facts-3" class="level3">
<h3 class="anchored" data-anchor-id="facts-3">Facts</h3>
<ul>
<li><strong>Educational System Focus</strong>: Traditional education prioritizes procedural learning over conceptual understanding or vision-setting.</li>
<li><strong>Visual Literacy</strong>: People can learn to become visually literate, enhancing their ability to visualize and create desired outcomes.</li>
<li><strong>Creative Confidence</strong>: Confidence in one’s vision can exist irrespective of personal insecurities, underlining the power of a clear creative vision.</li>
<li><strong>Process vs.&nbsp;Outcome</strong>: Distinguishing between the creative process and the clarity of the desired outcome is essential; clarity in vision does not necessitate a detailed understanding of the process to achieve it.</li>
<li><strong>Creativity and Possibility</strong>: Envisioning what one wants without being constrained by perceived limitations or possibilities is crucial for breakthroughs in creativity.</li>
</ul>
</section>
<section id="recommendations-7" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-7">Recommendations</h3>
<ul>
<li><strong>Cultivate a Clear Vision</strong>: Practice forming a clear and detailed vision of what you want to achieve to guide your creative endeavors.</li>
<li><strong>Embrace Visual Thinking</strong>: Regardless of natural inclination, work on visualizing your goals to enhance planning and realization of your projects.</li>
<li><strong>Separate Concept from Vision</strong>: Distinguish between the broad strokes of your concept and the focused clarity of your vision to refine your creative process.</li>
<li><strong>Challenge Educational Norms</strong>: Question and expand beyond traditional educational models that prioritize procedural knowledge over creative vision.</li>
<li><strong>Practice Decisiveness</strong>: Regularly ask yourself what you truly want, in various contexts, to build decisiveness and clarity in your desires and objectives.</li>
<li><strong>Think Beyond Possibilities</strong>: Allow yourself to envision desires and outcomes without being limited by current capabilities or perceived realities.</li>
</ul>
</section>
<section id="additional-insights-3" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-3">Additional Insights</h3>
<ul>
<li><strong>Visual vs.&nbsp;Aural vs.&nbsp;Kinesthetic Learners</strong>: While individuals may have a natural inclination towards one learning style, flexibility and development in other styles can enhance creative abilities.</li>
<li><strong>Creative Rituals</strong>: Some artists, like Jackson Pollock, utilize unique rituals to balance structure and spontaneity in their creative process, demonstrating the diverse methods of achieving artistic vision.</li>
<li><strong>Vision as an Organizing Principle</strong>: A clear vision not only guides the creation process but also organizes actions, values, and perceptions of reality, showcasing the transformative power of a well-defined goal.</li>
</ul>
<p>By focusing on the end goal and cultivating a clear vision, individuals can navigate the creative process more effectively, transcending traditional educational limitations and exploring new possibilities in their creative endeavors.</p>
</section>
</section>
<section id="current-reality" class="level2">
<h2 class="anchored" data-anchor-id="current-reality">Current Reality</h2>
<section id="summary-9" class="level3">
<h3 class="anchored" data-anchor-id="summary-9">Summary</h3>
<p>Chapter 10 explores the concept of reality and the importance of accurately perceiving it. Through anecdotes and philosophical discussions, it argues that misrepresenting reality or holding onto past realities can hinder personal growth and creativity. The text emphasizes the need for individuals to confront and accept reality as it is, without biases or preconceived notions, to live fully and creatively.</p>
</section>
<section id="key-concepts-7" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-7">Key Concepts</h3>
<ul>
<li><strong>Reality vs.&nbsp;Perception</strong>: Differentiates between actual reality and how individuals perceive or conceptualize it.</li>
<li><strong>The Importance of Accepting Reality</strong>: Stresses that acknowledging and accepting reality is crucial for personal development and creativity.</li>
<li><strong>Misrepresentation of Reality</strong>: Discusses how people often misrepresent reality to avoid negative consequences or due to biases.</li>
</ul>
</section>
<section id="ideas-5" class="level3">
<h3 class="anchored" data-anchor-id="ideas-5">Ideas</h3>
<ul>
<li>Reality is subjective and often clouded by personal biases and preconceived notions.</li>
<li>Accurately perceiving and accepting reality is essential for creative and personal growth.</li>
<li>Misrepresenting reality, whether to oneself or others, can have detrimental effects on one’s life and society.</li>
</ul>
</section>
<section id="noteworthy-facts-1" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-1">Noteworthy Facts</h3>
<ul>
<li>The story of the man who thought he was a zombie highlights the difficulty of changing one’s perception of reality.</li>
<li>Children learn to lie as a defense against authority, showing early encounters with the concept of altering reality.</li>
<li>Societal norms often encourage the misrepresentation of reality through excuses and reasons for failure.</li>
</ul>
</section>
<section id="practical-implications-4" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-4">Practical Implications</h3>
<ul>
<li>Understanding and accepting reality is crucial for effective decision-making and problem-solving.</li>
<li>Creativity and innovation thrive in environments where reality is accurately perceived and accepted.</li>
<li>Personal relationships can benefit from a mutual acceptance of reality, avoiding misunderstandings and conflicts.</li>
</ul>
</section>
<section id="recommendations-8" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-8">Recommendations</h3>
<ul>
<li>Practice observing reality without letting preconceived notions or biases cloud judgment.</li>
<li>Encourage open discussions about reality and perceptions to foster understanding and creativity.</li>
<li>In personal and professional settings, prioritize honesty and transparency to ensure a shared perception of reality.</li>
</ul>
</section>
<section id="critical-analysis-4" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-4">Critical Analysis</h3>
<ul>
<li>The chapter challenges the notion that altering one’s perception of reality is always negative, suggesting that creative processes often require a reimagining of reality.</li>
<li>It also prompts a reflection on the societal and cultural factors that influence our perception of reality and how these can be navigated or changed.</li>
</ul>
</section>
<section id="additional-insights-4" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-4">Additional Insights</h3>
<ul>
<li>The analogy of art students learning to see colors as they truly are serves as a powerful metaphor for the broader challenge of seeing reality without the filter of our expectations or desires.</li>
<li>The distinction between using reasons for failure as learning experiences versus excuses highlights a fundamental approach to life and success.</li>
</ul>
</section>
</section>
<section id="the-creative-cycle" class="level2">
<h2 class="anchored" data-anchor-id="the-creative-cycle">The Creative Cycle</h2>
<section id="summary-10" class="level3">
<h3 class="anchored" data-anchor-id="summary-10">Summary</h3>
<p>Chapter 11 discusses the three stages of the creative cycle: germination, assimilation, and completion. Each stage plays a crucial role in the growth and life-building process, mirroring natural and organic cycles such as the human birth cycle.</p>
</section>
<section id="germination" class="level3">
<h3 class="anchored" data-anchor-id="germination">Germination</h3>
<ul>
<li>Germination is the initial burst of energy at the beginning of a creative process, characterized by excitement and enthusiasm.</li>
<li>Notable individuals like Roger Sessions and Alfred Hitchcock thrived on this energy during the conceptual phase of their work.</li>
<li>The chapter emphasizes that while germination is important, focusing solely on this stage without progressing to the others results in fleeting experiences and unfulfilled potential.</li>
<li>It suggests that the addiction to the excitement of new beginnings can prevent sustained growth and achievement.</li>
</ul>
</section>
<section id="assimilation" class="level3">
<h3 class="anchored" data-anchor-id="assimilation">Assimilation</h3>
<ul>
<li>Assimilation represents the internalization and development phase, akin to gestation, where the creative work or idea grows organically.</li>
<li>This stage is marked by subconscious work and the emergence of the creation’s tangible aspects, often accompanied by a deepening connection with the vision or idea.</li>
<li>Insights, ideas, and momentum build during assimilation, making the creation more concrete and integrated with the creator’s identity.</li>
<li>The chapter highlights the hidden, yet essential nature of this stage, using examples from Mozart, Gertrude Stein, and Jules-Henri Poincaré to illustrate the importance of internal, often subconscious, development.</li>
</ul>
</section>
<section id="completion" class="level3">
<h3 class="anchored" data-anchor-id="completion">Completion</h3>
<ul>
<li>Completion involves finalizing the creative work, manifesting it fully, and learning to live with the result.</li>
<li>This stage is characterized by the ability to bring creative activities to fruition and the capacity to receive and appreciate the outcomes.</li>
<li>The chapter notes that many struggle with this stage, failing to finalize their creative endeavors, and underscores the importance of mastering the ability to complete projects.</li>
<li>Completion is also about releasing the creation to the world and accepting it as a separate entity, akin to a parent letting go of a grown child.</li>
</ul>
</section>
<section id="moving-forward" class="level3">
<h3 class="anchored" data-anchor-id="moving-forward">Moving Forward</h3>
<ul>
<li>Each stage of the creative cycle generates specific energy that propels the creator into the next stage, forming a continuous loop of creation.</li>
<li>The energy from completion fuels the genesis of new ideas, illustrating the self-renewing nature of creative energy.</li>
<li>Understanding and harnessing the energy inherent in each stage is crucial for sustained creative success.</li>
</ul>
</section>
<section id="critical-analysis-5" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-5">Critical Analysis</h3>
<ul>
<li>The chapter provides a comprehensive framework for understanding the creative process, emphasizing the importance of progressing through all three stages for meaningful and lasting creation.</li>
<li>It challenges common misconceptions about creativity being solely about the initial spark, highlighting the significance of development, refinement, and completion.</li>
<li>The use of examples from various fields illustrates the universal applicability of the creative cycle, offering valuable insights for creators across disciplines.</li>
</ul>
</section>
<section id="recommendations-9" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-9">Recommendations</h3>
<ul>
<li>Embrace the excitement of germination but recognize the need to progress beyond this initial stage.</li>
<li>Dedicate time and effort to the assimilation stage, allowing ideas to develop fully and integrate with your identity.</li>
<li>Cultivate the skills and mindset necessary to bring creative projects to completion, overcoming barriers to finalization.</li>
<li>Reflect on completed projects as sources of inspiration and energy for future creative endeavors, thus engaging in the continuous loop of creation.</li>
</ul>
</section>
</section>
<section id="germination-and-choice" class="level2">
<h2 class="anchored" data-anchor-id="germination-and-choice">Germination and Choice</h2>
<section id="summary-11" class="level3">
<h3 class="anchored" data-anchor-id="summary-11">Summary</h3>
<p>Chapter 12 explores the concept of making effective choices as a crucial component of the creative process. It emphasizes the importance of focusing choices on desired results to mobilize energies and resources, highlights common pitfalls in decision-making, and provides insights into developing a more strategic and creative orientation towards making choices.</p>
</section>
<section id="key-concepts-8" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-8">Key Concepts</h3>
<ul>
<li><strong>Making Choices</strong>: Choosing focuses on desired results, mobilizing untapped energies.</li>
<li><strong>Learning to Choose</strong>: Effective decision-making can be practiced and refined.</li>
<li><strong>The Creative Process</strong>: Making choices is vital in creativity, involving strategic decisions and improvisation.</li>
<li><strong>Avoiding Ineffective Choices</strong>: Identifies eight ways people undermine their decision-making power.
<ol type="1">
<li>Choice by Limitation: Choosing only what seems possible or reasonable.</li>
<li>Choice by Indirectness: Choosing the process instead of the result.</li>
<li>Choice by Elimination: Eliminating all other possibilities so that only one choice remains.</li>
<li>Choice by Default: The choice not to make a choice, so that whatever results happen seem to occur without choice.</li>
<li>Conditional Choice: Imposing preconditions on choices</li>
<li>Choice by Reaction: Choice is designed to overcome a conflict</li>
<li>Choice by Consensus: Choosing by finding out what everyone else is willing to recommend and following the results of that poll</li>
<li>Choice by Adverse Possession: Choice based on a hazy metaphysical notion about the nature of the universe</li>
</ol></li>
</ul>
</section>
<section id="ideas-6" class="level3">
<h3 class="anchored" data-anchor-id="ideas-6">Ideas</h3>
<ul>
<li>Making effective choices involves clearly identifying what you want to create and mobilizing resources towards that goal.</li>
<li>Practicing decision-making in low-risk situations can improve one’s ability to make better choices.</li>
<li>Creativity and choice-making are closely linked; being decisive can enhance one’s creative abilities.</li>
<li>Education and upbringing often neglect the development of choice-making skills, impacting personal and societal well-being.</li>
</ul>
</section>
<section id="noteworthy-facts-2" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-2">Noteworthy Facts</h3>
<ul>
<li>The author shares personal anecdotes to illustrate the importance and impact of learning to make effective choices.</li>
<li>The chapter references Karlheinz Stockhausen’s view on composing as an exercise in decision-making.</li>
<li>The text criticizes traditional education for not adequately preparing individuals to make empowering choices.</li>
</ul>
</section>
<section id="practical-implications-5" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-5">Practical Implications</h3>
<ul>
<li>Practicing quick, low-risk decision-making can build confidence and improve one’s ability to make more significant choices.</li>
<li>Recognizing and avoiding the eight common pitfalls in decision-making can lead to more effective choices.</li>
<li>Focusing on creating positive outcomes rather than avoiding negative ones establishes a more constructive and creative orientation towards life.</li>
</ul>
</section>
<section id="recommendations-10" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-10">Recommendations</h3>
<ul>
<li>Practice making decisions quickly in everyday situations to develop a sharper instinct for what you truly want.</li>
<li>Reflect on past decisions to understand your decision-making patterns and areas for improvement.</li>
<li>Educate and encourage children and young adults to make choices, fostering a sense of autonomy and responsibility.</li>
<li>Regularly reassess your goals and the choices you’re making to ensure they align with what you truly want to create in your life.</li>
</ul>
</section>
<section id="critical-analysis-6" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-6">Critical Analysis</h3>
<ul>
<li>The chapter challenges conventional attitudes towards decision-making and creativity, advocating for a more proactive and strategic approach.</li>
<li>By dissecting common ineffective choice-making strategies, it provides a clear framework for understanding and improving one’s decision-making skills.</li>
<li>The emphasis on practice and experimentation as methods to enhance decision-making abilities highlights the process-oriented nature of personal growth.</li>
</ul>
</section>
<section id="additional-insights-5" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-5">Additional Insights</h3>
<ul>
<li>The discussion on choice and power reveals a deeper philosophical perspective on autonomy and self-determination.</li>
<li>The text suggests that societal and educational systems could benefit from integrating choice-making skills into their curriculums to prepare individuals for a more successful and fulfilling life.</li>
<li>The contrast between choosing from a place of fear versus a place of desire offers a valuable lens through which to view personal motivations and behaviors.</li>
</ul>
</section>
</section>
<section id="primary-secondary-and-fundamental-choice" class="level2">
<h2 class="anchored" data-anchor-id="primary-secondary-and-fundamental-choice">Primary, Secondary, and Fundamental Choice</h2>
<section id="summary-12" class="level3">
<h3 class="anchored" data-anchor-id="summary-12">Summary</h3>
<p>Chapter 13 discusses three types of choices: primary, secondary, and fundamental choices, which are strategic elements in the creative process. Primary choices are about major results one directly desires. Secondary choices support achieving the primary choices. Fundamental choices relate to one’s state of being or basic life orientation, acting as a foundation upon which primary and secondary choices rest.</p>
</section>
<section id="primary-choice" class="level3">
<h3 class="anchored" data-anchor-id="primary-choice">Primary Choice</h3>
<ul>
<li>Primary choices are about achieving specific results for their own sake, not as means to other ends.</li>
<li>They can be professional or personal, like choosing to be an effective manager, creating a work of art, or having a meaningful job.</li>
<li>The importance of primary choices is highlighted through examples, including inventors and artists who pursue their work for the joy and fulfillment it brings, not for financial or external rewards.</li>
</ul>
</section>
<section id="secondary-choice" class="level3">
<h3 class="anchored" data-anchor-id="secondary-choice">Secondary Choice</h3>
<ul>
<li>Secondary choices are steps taken to support and achieve the primary choice.</li>
<li>They are strategic and clear once the primary choice is made, often requiring daily decisions that align with one’s main goal, like choosing to exercise regularly to achieve a well-toned body.</li>
<li>Secondary choices demonstrate commitment to the primary goal, making sacrifices and decisions that directly support achieving the desired result.</li>
</ul>
</section>
<section id="fundamental-choice" class="level3">
<h3 class="anchored" data-anchor-id="fundamental-choice">Fundamental Choice</h3>
<ul>
<li>Fundamental choices concern one’s basic life orientation or state of being, like choosing to be healthy, free, or true to oneself.</li>
<li>They provide a foundation for making primary and secondary choices, influencing overall life direction and the fulfillment of specific goals.</li>
<li>Success and the direction of one’s life are not necessarily determined by early achievements but by these fundamental choices that guide personal and professional growth.</li>
</ul>
</section>
<section id="making-choices" class="level3">
<h3 class="anchored" data-anchor-id="making-choices">Making Choices</h3>
<ul>
<li>The process of making choices involves identifying what one truly wants (primary choice), taking steps towards it (secondary choice), and aligning these actions with a basic life orientation or state of being (fundamental choice).</li>
<li>To make effective choices, one must be honest about desires, prioritize them, and be willing to commit to actions that support these choices, whether they are long-term goals or daily decisions.</li>
<li>Fundamental choices require deep introspection and a commitment to a desired state of being, independent of external circumstances or immediate outcomes.</li>
</ul>
</section>
<section id="practical-steps" class="level3">
<h3 class="anchored" data-anchor-id="practical-steps">Practical Steps</h3>
<ol type="1">
<li><strong>List Making</strong>: Create a comprehensive list of everything you want, encompassing personal and professional desires without considering their feasibility.</li>
<li><strong>Choice Verification</strong>: Review each item by asking if you would take it if you could, adjusting the list based on true desires.</li>
<li><strong>Formal Choosing</strong>: Formally choose each item you truly want, marking the first step in the creative process towards achieving these goals.</li>
<li><strong>Secondary Support</strong>: Identify and commit to secondary choices that support your primary choices, aligning actions with goals.</li>
<li><strong>Fundamental Orientation</strong>: Reflect on and make fundamental choices about your basic life orientation, like choosing to be the predominant creative force in your own life.</li>
</ol>
</section>
<section id="the-impact-of-choices" class="level3">
<h3 class="anchored" data-anchor-id="the-impact-of-choices">The Impact of Choices</h3>
<ul>
<li>Making informed and genuine primary, secondary, and fundamental choices reorganizes life towards achieving desired results and fulfilling a preferred state of being.</li>
<li>These choices influence daily decisions, long-term goals, and the overall direction of one’s life, highlighting the power of creative orientation in personal development and achievement.</li>
</ul>
</section>
</section>
<section id="assimilation-1" class="level2">
<h2 class="anchored" data-anchor-id="assimilation-1">Assimilation</h2>
<section id="summary-13" class="level3">
<h3 class="anchored" data-anchor-id="summary-13">Summary</h3>
<p>Chapter 14 explores the concept of assimilation, a critical stage of growth and development following germination. It delves into how assimilation is a natural part of learning and development, emphasizing its importance in incorporating new skills and knowledge into our lives seamlessly. The chapter also highlights common challenges during the assimilation phase, such as frustration and the temptation to give up when progress is not immediately visible.</p>
</section>
<section id="key-concepts-9" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-9">Key Concepts</h3>
<ul>
<li><strong>Assimilation:</strong> The process of incorporating new skills and knowledge, making them a natural part of ourselves.</li>
<li><strong>Structural Tension:</strong> The discrepancy between current reality and the desired result, which drives the creative process.</li>
<li><strong>Embodiment:</strong> Living in alignment with one’s vision, beyond mere behavior, embodying the values and principles one stands for.</li>
<li><strong>Internalizing and Externalizing Phases:</strong> The two phases of assimilation, where learning is internalized and then expressed outwardly.</li>
</ul>
</section>
<section id="ideas-7" class="level3">
<h3 class="anchored" data-anchor-id="ideas-7">Ideas</h3>
<ul>
<li>Assimilation is an ongoing process throughout life, used in learning various skills from walking to professional expertise.</li>
<li>Progress in the assimilation stage may not be immediately visible, leading to feelings of frustration and the temptation to abandon efforts.</li>
<li>Understanding and patience during periods where “nothing seems to be happening” are crucial in the creative orientation.</li>
<li>Experiences of learning, such as falling off a bicycle, are moments of assimilation and not failure.</li>
<li>Moving to the next step even when feeling unprepared can enhance assimilation and learning.</li>
</ul>
</section>
<section id="noteworthy-facts-3" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-3">Noteworthy Facts</h3>
<ul>
<li>Assimilation is poorly understood despite its universal experience.</li>
<li>Emotional experiences of discomfort, frustration, and disappointment are common at the start of assimilation.</li>
<li>The creative process includes continual learning and deepening assimilation, enabling easier internalization of future learnings.</li>
<li>Assimilation contributes to structural tension by highlighting the gap between current reality and desired outcomes.</li>
</ul>
</section>
<section id="practical-implications-6" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-6">Practical Implications</h3>
<ul>
<li>Recognizing and respecting the assimilation phase can prevent premature abandonment of learning and development efforts.</li>
<li>Embracing the challenges and frustrations of early assimilation stages can lead to deeper learning and mastery.</li>
<li>Practitioners can foster assimilation by pushing boundaries and embracing more challenging tasks before perfecting current ones.</li>
<li>Understanding the internal and external phases of assimilation can enhance the ability to learn and apply new skills effectively.</li>
</ul>
</section>
<section id="recommendations-11" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-11">Recommendations</h3>
<ul>
<li>Cultivate patience and maintain effort during the invisible stages of growth to ensure continued development and mastery of new skills.</li>
<li>Embrace challenging tasks as opportunities for deeper assimilation and learning.</li>
<li>Foster an environment that encourages experimentation and learning from errors as part of the assimilation process.</li>
<li>Recognize and respect the natural cycles of growth, decay, and renewal in personal and professional life, aligning actions with these cycles for effective change and development.</li>
<li>Practice embodiment of values and visions to deepen assimilation and impact both personal growth and external achievements.</li>
</ul>
</section>
<section id="critical-analysis-7" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-7">Critical Analysis</h3>
<ul>
<li>The chapter challenges common perceptions of learning and development, emphasizing the importance of unseen stages of growth. It invites a reevaluation of how progress and success are measured, advocating for a broader understanding of learning that includes the value of setbacks and challenges as integral to the process.</li>
</ul>
</section>
<section id="additional-insights-6" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-6">Additional Insights</h3>
<ul>
<li>Assimilation as an organic process mirrors natural cycles, reminding us of the importance of aligning with these rhythms in our creative and learning endeavors.</li>
<li>The concept of embodiment as described by the experiences of historical figures like Martin Luther King Jr.&nbsp;underscores the transformative power of living in alignment with deeply held values and visions.</li>
</ul>
</section>
</section>
<section id="momentum" class="level2">
<h2 class="anchored" data-anchor-id="momentum">Momentum</h2>
<section id="summary-14" class="level3">
<h3 class="anchored" data-anchor-id="summary-14">Summary</h3>
<p>Chapter 15 explores how the process of assimilation builds momentum in learning and creative endeavors. It argues that mastering a skill or area of knowledge involves a graduated, organic process where earlier steps facilitate the assimilation of subsequent, more advanced steps, leading to exponential growth and easier learning over time. This process applies across various fields, including mathematics, sports, and the arts, and is crucial for personal and creative growth.</p>
</section>
<section id="key-concepts-10" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-10">Key Concepts</h3>
<ul>
<li><strong>Assimilation as a Graduated Process</strong>: Learning builds upon itself in a step-by-step manner, creating momentum.</li>
<li><strong>Momentum Through Learning</strong>: Early mastery leads to easier assimilation of advanced concepts, enhancing creative output and personal growth.</li>
<li><strong>The Role of Experience in Creating</strong>: Real accomplishment, rather than affirmations or self-hypnosis, instills confidence and a sense of capability.</li>
<li><strong>Continuous Learning and Mastery</strong>: Mastery in any field, including creativity, is a long-term process requiring ongoing learning and application.</li>
</ul>
</section>
<section id="practical-implications-7" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-7">Practical Implications</h3>
<ul>
<li>Learning one skill makes it easier to learn others, thanks to the process of assimilation.</li>
<li>Real confidence comes from actual achievements, not just positive thinking or affirmations.</li>
<li>Mastery takes time and is built on the accumulation of experiences and successes.</li>
</ul>
</section>
<section id="supporting-evidence-2" class="level3">
<h3 class="anchored" data-anchor-id="supporting-evidence-2">Supporting Evidence</h3>
<ul>
<li>Examples of individuals mastering languages, arts, and inventions illustrate how initial successes build momentum for further achievements.</li>
<li>The story of a successful entrepreneur demonstrates how small successes can lead to larger accomplishments through the strategic building of momentum.</li>
</ul>
</section>
<section id="recommendations-12" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-12">Recommendations</h3>
<ul>
<li><strong>Focus on Early Mastery</strong>: Concentrate on fully understanding and mastering early steps in any learning process to facilitate easier assimilation of advanced concepts.</li>
<li><strong>Learn from Every Outcome</strong>: Treat both successes and failures as learning opportunities to build momentum in your creative endeavors.</li>
<li><strong>Embrace the Long-Term Process</strong>: Recognize that mastery and creative achievement are not instantaneous but require sustained effort and learning.</li>
</ul>
</section>
<section id="additional-insights-7" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-7">Additional Insights</h3>
<ul>
<li>The concept of <strong>Structural Tension</strong> is highlighted as a key to mastering the creative process, where one must balance the vision of the desired outcome with the reality of the current situation to effectively navigate towards goals.</li>
<li>The narrative counters the notion of quick fixes or instant success, advocating for a deep, methodical approach to personal and creative development.</li>
</ul>
</section>
<section id="critical-analysis-8" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-8">Critical Analysis</h3>
<ul>
<li>Fritz challenges the prevalent culture of instant gratification, emphasizing the importance of persistence, patience, and a systematic approach to learning and creativity.</li>
<li>The chapter demystifies the creative process, showing it as accessible and achievable through structured effort rather than innate talent or luck.</li>
</ul>
</section>
</section>
<section id="strategic-moments" class="level2">
<h2 class="anchored" data-anchor-id="strategic-moments">Strategic Moments</h2>
<section id="summary-15" class="level3">
<h3 class="anchored" data-anchor-id="summary-15">Summary</h3>
<p>Chapter 16 discusses the concept of strategic moments in the creative process, emphasizing times when progress seems stalled or regressing. It illustrates the importance of recognizing and navigating these moments to achieve ultimate success. Using metaphors like a novice hiker’s journey and various personal and professional scenarios, it explores themes of perception, reality, and the significance of understanding and adapting to current circumstances.</p>
</section>
<section id="key-concepts-11" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-11">Key Concepts</h3>
<ul>
<li><strong>Strategic Moments</strong>: Periods where it appears no progress is made, critical for eventual success.</li>
<li><strong>Time Delay</strong>: The lag between initiating change and seeing results, which can lead to prematurely abandoning effective actions.</li>
<li><strong>Current Reality</strong>: The importance of accurately recognizing and accepting the present situation without resentment to leverage it creatively.</li>
<li><strong>Structural Tension</strong>: The gap between current reality and the desired outcome, serving as a driving force in the creative process.</li>
</ul>
</section>
<section id="practical-implications-8" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-8">Practical Implications</h3>
<ul>
<li>Recognizing strategic moments allows for better decision-making and perseverance through challenges.</li>
<li>Understanding time delays can prevent discouragement and cessation of effective actions.</li>
<li>Accurately assessing current reality enables more effective planning and action.</li>
<li>Leveraging structural tension can catalyze creativity and progress toward goals.</li>
</ul>
</section>
<section id="supporting-evidence-3" class="level3">
<h3 class="anchored" data-anchor-id="supporting-evidence-3">Supporting Evidence</h3>
<ul>
<li>The novice hiker’s misunderstanding of his proximity to the goal illustrates how misperceptions can occur during strategic moments.</li>
<li>The examples of the corporate executive and the assembly line training demonstrate real-world implications of time delays and misinterpretation of current reality.</li>
<li>Personal stories, like the young woman adjusting to city life, highlight the difficulties in recognizing and adapting to new realities.</li>
</ul>
</section>
<section id="recommendations-13" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-13">Recommendations</h3>
<ul>
<li><p><strong>For Individuals</strong>: Cultivate awareness of strategic moments and time delays in personal growth and creative endeavors. Practice accurately assessing and accepting current reality without resentment.</p></li>
<li><p><strong>For Leaders and Managers</strong>: Implement strategies that account for time delays in seeing results from changes or initiatives. Encourage teams to maintain actions that align with long-term goals, even when immediate results are not visible.</p></li>
<li><p><strong>For Creatives</strong>: Use the concept of structural tension as a tool to drive creative processes. Recognize and adapt to shifts in current reality to maintain momentum towards achieving creative goals.</p></li>
<li><p><strong>Navigating Strategic Moments</strong>:</p>
<ul>
<li>Pause and reassess both the goal and the current position regularly.</li>
<li>Maintain flexibility in methods while keeping the end goal clear.</li>
</ul></li>
<li><p><strong>Dealing with Delays</strong>:</p>
<ul>
<li>Cultivate patience and understand the natural lag between effort and outcome.</li>
<li>Continuously evaluate and adjust actions based on emerging results, not immediate feedback.</li>
</ul></li>
<li><p><strong>Current Reality Assessment</strong>:</p>
<ul>
<li>Practice objective evaluation of situations without letting emotions cloud judgment.</li>
<li>Use difficulties and unplanned events as feedback to refine strategies and actions.</li>
</ul></li>
<li><p><strong>Utilizing the Pivotal Technique</strong>:</p>
<ul>
<li>Clearly define the current state and desired outcome.</li>
<li>Formally choose the desired outcome, regardless of perceived obstacles.</li>
<li>Shift focus after establishing structural tension to allow subconscious processing and creativity.</li>
</ul></li>
<li><p><strong>Embracing Unwanted Situations</strong>:</p>
<ul>
<li>View challenges as opportunities to clarify and reaffirm goals.</li>
<li>Develop resilience and adaptability by embracing reality and using it as a springboard for creative action.</li>
</ul></li>
</ul>
</section>
<section id="critical-analysis-9" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-9">Critical Analysis</h3>
<ul>
<li>The emphasis on individual perception and internal processes may underplay external factors and constraints that also significantly impact goal attainment. Balancing internal strategies with external realities could provide a more holistic approach to creative problem-solving and goal achievement.</li>
</ul>
</section>
<section id="additional-insights-8" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-8">Additional Insights</h3>
<ul>
<li>The pivotal technique outlined offers a structured approach to leveraging unwanted circumstances for creative advantage. This technique emphasizes the importance of clarity in defining current reality and desired outcomes, choosing the latter explicitly, and then moving forward with an open mind to new possibilities and solutions.</li>
</ul>
</section>
</section>
<section id="completion-1" class="level2">
<h2 class="anchored" data-anchor-id="completion-1">Completion</h2>
<section id="summary-16" class="level3">
<h3 class="anchored" data-anchor-id="summary-16">Summary</h3>
<p>Chapter 17 explores the final stage of the creative cycle, emphasizing the full realization of one’s vision. It delves into the psychological dynamics associated with completion, including the paradoxical anxiety akin to the “Prisoner Syndrome” and the contrasting feelings of fulfillment and depression that can accompany the completion of creative endeavors. The chapter further discusses the importance of mastering the art of receiving and acknowledging one’s creations to fully realize the completion phase.</p>
</section>
<section id="main-ideas" class="level3">
<h3 class="anchored" data-anchor-id="main-ideas">Main Ideas</h3>
<ul>
<li><strong>Completion as the Culmination of the Creative Process</strong>: Emphasizes the importance of fully realizing one’s vision to achieve completion.</li>
<li><strong>Psychological Dynamics of Completion</strong>: Explores the complex emotions, including anticipatory anxiety and the contrasting experiences of fulfillment versus depression upon completing significant milestones.</li>
<li><strong>The Art of Receiving and Acknowledging</strong>: Highlights the necessity of being open to receiving and properly acknowledging one’s achievements as integral to the completion phase.</li>
</ul>
</section>
<section id="psychological-insights" class="level3">
<h3 class="anchored" data-anchor-id="psychological-insights">Psychological Insights</h3>
<ul>
<li><strong>Prisoner Syndrome</strong>: Describes the anxiety and stress experienced by prisoners nearing release, paralleled in everyday situations where individuals approach the realization of long-sought goals.</li>
<li><strong>Emotional Oscillation</strong>: Discusses the fluctuation between fulfillment and depression upon achieving one’s aims, with references to Virginia Wharfe’s personal experiences.</li>
</ul>
</section>
<section id="recommendations-14" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-14">Recommendations</h3>
<ul>
<li><strong>Mastering Receiving</strong>: Encourages developing the ability to fully accept and integrate the fruits of one’s creative efforts into one’s life.</li>
<li><strong>Cultivating Acknowledgment Skills</strong>: Stresses the importance of acknowledging one’s progress and creations as a distinct and crucial step toward true completion.</li>
<li><strong>Embracing the Creative Orientation</strong>: Recommends shifting towards a creative mindset where receiving and acknowledgment become natural and familiar, enhancing the ability to live with and continue creating desired outcomes.</li>
</ul>
</section>
<section id="critical-analysis-10" class="level3">
<h3 class="anchored" data-anchor-id="critical-analysis-10">Critical Analysis</h3>
<ul>
<li><p><strong>The Challenge of Emotional Management</strong>: Analyzes the necessity of managing complex emotions associated with achieving significant goals, suggesting that understanding these emotional dynamics is essential for personal growth and creativity.</p></li>
<li><p><strong>The Role of Structural Tension in Creation</strong>: Examines how the structure of one’s aspirations and the tension between current reality and the vision for the future drive the creative process.</p></li>
<li><p><strong>The Universal Relevance of Completion Dynamics</strong>: Reflects on how the insights provided in this chapter about completion, receiving, and acknowledgment apply broadly across various aspects of life and work.</p></li>
</ul>
</section>
<section id="future-perspectives-4" class="level3">
<h3 class="anchored" data-anchor-id="future-perspectives-4">Future Perspectives</h3>
<ul>
<li><strong>Beyond Completion</strong>: Contemplates the continuous nature of the creative cycle, where the completion of one phase seeds the germination of new creative endeavors, emphasizing the perpetual momentum of creation.</li>
</ul>
</section>
<section id="connection-to-broader-themes" class="level3">
<h3 class="anchored" data-anchor-id="connection-to-broader-themes">Connection to Broader Themes</h3>
<ul>
<li><strong>Human Nature as Creative Force</strong>: Discusses the inherent creative capacities of humans, drawing on Judeo-Christian narratives to underline the role of creation in human identity and purpose.</li>
<li><strong>Critical Judgment in the Creative Process</strong>: Explores the necessity of critical judgment and acknowledgment in the creative process, challenging contemporary aversions to judgmental thinking.</li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>The chapter concludes by reinforcing the idea that mastering the stage of completion is not only about achieving one’s goals but also about being able to receive and acknowledge the fruits of one’s labor, setting the stage for future creative endeavors. It posits that aligning with one’s natural instinct to create leads to a fulfilling and purpose-driven life.</p>
</section>
</section>
<section id="the-power-of-transcendence" class="level2">
<h2 class="anchored" data-anchor-id="the-power-of-transcendence">The Power of Transcendence</h2>
<section id="summary-17" class="level3">
<h3 class="anchored" data-anchor-id="summary-17">Summary</h3>
<p>Chapter 18 discusses the concept of transcendence as a powerful force enabling individuals to overcome the limitations set by their past, conditioning, genetics, social background, or any other determinants. Through transcendence, individuals can start anew, unburdened by past victories or defeats.</p>
<p>The chapter uses the story of Scrooge from Charles Dickens’ “A Christmas Carol” and the Parable of the Prodigal Son to illustrate the transformative power of transcendence. It emphasizes shifting from a reactive-responsive orientation to a creative orientation, where one becomes the predominant causal force in their life. The chapter concludes with the idea that transcendence is not only a personal principle but can also apply to civilization as a whole, suggesting a shift towards a more creative and vision-driven society.</p>
</section>
<section id="key-concepts-12" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-12">Key Concepts</h3>
<ul>
<li><strong>Transcendence</strong>: The ability to start fresh, unburdened by past experiences.</li>
<li><strong>Reactive-Responsive Orientation</strong>: A mindset where individuals feel fixed in their life patterns due to external determinants.</li>
<li><strong>Creative Orientation</strong>: An approach where individuals see themselves as the primary causal force in their lives.</li>
<li><strong>Senior Forces</strong>: Elements like fundamental choice and structural tension that take priority over lesser forces like willpower manipulation.</li>
<li><strong>The Power of the Source</strong>: The innate drive within individuals to express their life source fully.</li>
<li><strong>One-Way Bargains</strong>: Assumptions where individuals expect reciprocity without mutual agreement, often leading to disappointment.</li>
</ul>
</section>
<section id="ideas-8" class="level3">
<h3 class="anchored" data-anchor-id="ideas-8">Ideas</h3>
<ul>
<li>The concept of transcendence allows individuals to reimagine their lives, free from the constraints of their past.</li>
<li>Transitioning from a reactive-responsive orientation to a creative orientation empowers individuals to shape their destiny.</li>
<li>Senior forces, such as fundamental choice and structural tension, are crucial in overcoming lesser forces and achieving one’s true aspirations.</li>
<li>Stories like Scrooge’s transformation and the Parable of the Prodigal Son serve as metaphors for the personal journey toward transcendence.</li>
</ul>
</section>
<section id="noteworthy-facts-4" class="level3">
<h3 class="anchored" data-anchor-id="noteworthy-facts-4">Noteworthy Facts</h3>
<ul>
<li><strong>Scrooge’s Transformation</strong>: Illustrates how transcendence can lead to a fundamental change in life orientation.</li>
<li><strong>The Prodigal Son</strong>: Represents the idea that returning to one’s source, or true self, is a powerful form of personal reconciliation and transformation.</li>
<li><strong>Civilizational Transcendence</strong>: Suggests that as individuals embrace a creative orientation, society as a whole can move towards a more visionary and creative future.</li>
</ul>
</section>
<section id="practical-implications-9" class="level3">
<h3 class="anchored" data-anchor-id="practical-implications-9">Practical Implications</h3>
<ul>
<li>Individuals can apply the concept of transcendence to overcome perceived limitations and create a new life direction.</li>
<li>By embracing a creative orientation, people can become the predominant causal force in their lives, leading to more fulfillment and purpose.</li>
<li>Societies can benefit from a collective shift towards creativity and vision, potentially leading to transformative changes in civilization.</li>
</ul>
</section>
<section id="recommendations-15" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-15">Recommendations</h3>
<ul>
<li>Individuals feeling trapped by their past should explore the concept of transcendence to envision and create a new future.</li>
<li>Adopting a creative orientation can help individuals and organizations overcome structural conflicts and limitations.</li>
<li>Reflecting on stories like Scrooge and the Prodigal Son can provide insights into one’s own journey towards personal transformation and renewal.</li>
</ul>
</section>
<section id="additional-insights-9" class="level3">
<h3 class="anchored" data-anchor-id="additional-insights-9">Additional Insights</h3>
<ul>
<li>The shift towards a creative orientation requires recognizing and prioritizing senior forces over lesser forces.</li>
<li>The process of transcendence involves a realignment with one’s life source, leading to a fundamental change in how one approaches life.</li>
<li>The ability for civilization to transcend its current limitations lies in the collective shift of its individuals towards a more creative and vision-driven orientation.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>personal-growth</category>
  <category>professional-growth</category>
  <guid>christianjmills.com/posts/the-path-of-least-resistance-book-notes/</guid>
  <pubDate>Sat, 17 Feb 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Exporting Keypoint R-CNN Models from PyTorch to ONNX</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/onnx-export/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/tutorials/pytorch-train-keypoint-rcnn-series.html"><strong>Training Keypoint R-CNN Models with PyTorch</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Setting Up the Project</li>
<li>Loading the Checkpoint Data</li>
<li>Exporting the Model to ONNX</li>
<li>Performing Inference with ONNX Runtime</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome back to this series on training Keypoint R-CNN models with PyTorch. Previously, we demonstrated how to fine-tune a Keypoint R-CNN model by training it to identify the locations of human noses and faces. This tutorial builds on that by showing how to export the model to <a href="https://onnx.ai/">ONNX</a> and perform inference using <a href="https://onnxruntime.ai/docs/">ONNX Runtime</a>.</p>
<p>ONNX (Open Neural Network Exchange) is an open format to represent machine learning models and make them portable across various platforms. ONNX Runtime is a cross-platform inference accelerator that provides interfaces to hardware-specific libraries. By exporting our model to ONNX, we can deploy it to multiple devices and leverage hardware acceleration for faster inference. The Keypoint R-CNN model is computationally intensive, so any improvements to inference speed are welcome.</p>
<p>Additionally, we’ll implement the functionality to annotate images with key points without relying on PyTorch as a dependency. By the end of this tutorial, you will have an ONNX version of our Keypoint R-CNN model that you can deploy to servers and edge devices using ONNX Runtime.</p>
<div class="callout callout-style-default callout-important callout-titled" title="This post assumes the reader has completed the previous tutorial linked below:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post assumes the reader has completed the previous tutorial linked below:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../">Training Keypoint R-CNN Models with PyTorch</a></li>
</ul>
</div>
</div>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>As with the previous tutorial, the code is available as a Jupyter Notebook.</p>
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook</th>
<th>Google Colab</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/cj-mills/pytorch-keypoint-rcnn-tutorial-code/blob/main/notebooks/pytorch-keypoint-r-cnn-onnx-export.ipynb">GitHub Repository</a></td>
<td><a href="https://colab.research.google.com/github/cj-mills/pytorch-keypoint-rcnn-tutorial-code/blob/main/notebooks/pytorch-keypoint-r-cnn-onnx-export-colab.ipynb">Open In Colab</a></td>
</tr>
</tbody>
</table>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>We’ll need to add a few new libraries to our <a href="../#setting-up-your-python-environment">Python environment</a> for working with ONNX models.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>onnx</code></td>
<td>This package provides a Python API for working with ONNX models. (<a href="https://pypi.org/project/onnx/">link</a>)</td>
</tr>
<tr class="even">
<td><code>onnxruntime</code></td>
<td>ONNX Runtime is a runtime accelerator for machine learning models. (<a href="https://onnxruntime.ai/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>onnx-simplifier</code></td>
<td>This package helps simplify ONNX models. (<a href="https://pypi.org/project/onnx-simplifier/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following command to install these additional libraries:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install ONNX packages</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install onnx onnxruntime onnx-simplifier</span></code></pre></div>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>With our environment updated, we can dive into the code. First, we will import the necessary Python dependencies into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> random</span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb2-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file</span>
<span id="cb2-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> resize_img</span>
<span id="cb2-9"></span>
<span id="cb2-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb2-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb2-12"></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb2-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb2-15"></span>
<span id="cb2-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb2-17"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image, ImageDraw, ImageFont</span>
<span id="cb2-18"></span>
<span id="cb2-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb2-20"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb2-21"></span>
<span id="cb2-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Keypoint R-CNN</span></span>
<span id="cb2-23"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.models.detection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> keypointrcnn_resnet50_fpn</span>
<span id="cb2-24"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.models.detection.keypoint_rcnn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KeypointRCNNPredictor</span>
<span id="cb2-25"></span>
<span id="cb2-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import ONNX dependencies</span></span>
<span id="cb2-27"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> onnx <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the onnx module</span></span>
<span id="cb2-28"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> onnxsim <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> simplify <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the method to simplify ONNX models</span></span>
<span id="cb2-29"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> onnxruntime <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> ort <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the ONNX Runtime</span></span></code></pre></div>
</section>
<section id="setting-up-the-project" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-the-project">Setting Up the Project</h2>
<p>In this section, we’ll set the folder locations for our project and training session with the PyTorch checkpoint. Let’s also ensure we have a font file for annotating images.</p>
<section id="set-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="set-the-directory-paths">Set the Directory Paths</h3>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The name for the project</span></span>
<span id="cb3-2">project_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"pytorch-keypoint-r-cnn"</span></span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The path for the project folder</span></span>
<span id="cb3-5">project_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"./</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/"</span>)</span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the project directory if it does not already exist</span></span>
<span id="cb3-8">project_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-9"></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The path to the checkpoint folder</span></span>
<span id="cb3-11">checkpoint_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(project_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"2024-01-30_10-44-52"</span>)</span>
<span id="cb3-12"></span>
<span id="cb3-13">pd.Series({</span>
<span id="cb3-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Project Directory:"</span>: project_dir,</span>
<span id="cb3-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Checkpoint Directory:"</span>: checkpoint_dir,</span>
<span id="cb3-16">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_d7624">
<thead>
</thead>
<tbody>
<tr>
<th id="T_d7624_level0_row0" class="row_heading level0 row0">
Project Directory:
</th>
<td id="T_d7624_row0_col0" class="data row0 col0">
pytorch-keypoint-r-cnn
</td>
</tr>
<tr>
<th id="T_d7624_level0_row1" class="row_heading level0 row1">
Checkpoint Directory:
</th>
<td id="T_d7624_row1_col0" class="data row1 col0">
pytorch-keypoint-r-cnn/2024-01-30_10-44-52
</td>
</tr>
</tbody>
</table>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="I made a model checkpoint available on Hugging Face Hub in the repository linked below:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
I made a model checkpoint available on Hugging Face Hub in the repository linked below:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://huggingface.co/cj-mills/keypoint-rcnn-eyes-noses-pytorch/tree/main">cj-mills/keypoint-rcnn-eyes-noses-pytorch</a></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Those following along on Google Colab can drag the contents of their checkpoint folder into Colab's file browser. Keep in mind the model checkpoint has a large file size. ">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Those following along on Google Colab can drag the contents of their checkpoint folder into Colab’s file browser. Keep in mind the model checkpoint has a large file size.
</div>
</div>
<div class="callout-body-container callout-body">

</div>
</div>
</section>
<section id="download-a-font-file" class="level3">
<h3 class="anchored" data-anchor-id="download-a-font-file">Download a Font File</h3>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb4-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb4-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
</section>
</section>
<section id="loading-the-checkpoint-data" class="level2">
<h2 class="anchored" data-anchor-id="loading-the-checkpoint-data">Loading the Checkpoint Data</h2>
<p>Now, we can load the colormap used during training and initialize a Keypoint R-CNN model with the saved checkpoint.</p>
<section id="load-the-colormap" class="level3">
<h3 class="anchored" data-anchor-id="load-the-colormap">Load the Colormap</h3>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The colormap path</span></span>
<span id="cb5-2">colormap_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(checkpoint_dir.glob(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'*colormap.json'</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the JSON colormap data</span></span>
<span id="cb5-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(colormap_path, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>:</span>
<span id="cb5-6">        colormap_json <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> json.load(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>)</span>
<span id="cb5-7"></span>
<span id="cb5-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the JSON data to a dictionary        </span></span>
<span id="cb5-9">colormap_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {item[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>]: item[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'color'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> item <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colormap_json[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'items'</span>]}</span>
<span id="cb5-10"></span>
<span id="cb5-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the class names from the colormap</span></span>
<span id="cb5-12">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(colormap_dict.keys())</span>
<span id="cb5-13"></span>
<span id="cb5-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the colormap in integer format</span></span>
<span id="cb5-15">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colormap_dict.values()]</span></code></pre></div>
</section>
<section id="load-the-model-checkpoint" class="level3">
<h3 class="anchored" data-anchor-id="load-the-model-checkpoint">Load the Model Checkpoint</h3>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The model checkpoint path</span></span>
<span id="cb6-2">checkpoint_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(checkpoint_dir.glob(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'*.pth'</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the model checkpoint onto the CPU</span></span>
<span id="cb6-5">model_checkpoint <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(checkpoint_path, map_location<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>)</span></code></pre></div>
</section>
<section id="load-the-trained-keypoint-r-cnn-model" class="level3">
<h3 class="anchored" data-anchor-id="load-the-trained-keypoint-r-cnn-model">Load the Trained Keypoint R-CNN Model</h3>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load a pre-trained model</span></span>
<span id="cb7-2">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> keypointrcnn_resnet50_fpn(weights<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'DEFAULT'</span>)</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Replace the classifier head with the number of keypoints</span></span>
<span id="cb7-5">in_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.roi_heads.keypoint_predictor.kps_score_lowres.in_channels</span>
<span id="cb7-6">model.roi_heads.keypoint_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KeypointRCNNPredictor(in_channels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>in_features, num_keypoints<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb7-7"></span>
<span id="cb7-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the model with the checkpoint parameters and buffers</span></span>
<span id="cb7-9">model.load_state_dict(model_checkpoint)</span></code></pre></div>
<pre class="text"><code>&lt;All keys matched successfully&gt;</code></pre>
</section>
</section>
<section id="exporting-the-model-to-onnx" class="level2">
<h2 class="anchored" data-anchor-id="exporting-the-model-to-onnx">Exporting the Model to ONNX</h2>
<p>Before exporting the model, let’s ensure the model is in evaluation mode.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
<section id="prepare-the-input-tensor" class="level3">
<h3 class="anchored" data-anchor-id="prepare-the-input-tensor">Prepare the Input Tensor</h3>
<p>We need a sample input tensor for the export process.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">input_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>)</span></code></pre></div>
</section>
<section id="export-the-model-to-onnx" class="level3">
<h3 class="anchored" data-anchor-id="export-the-model-to-onnx">Export the Model to ONNX</h3>
<p>We can export the model using PyTorch’s <a href="https://pytorch.org/docs/stable/onnx.html#torch.onnx.export"><code>torch.onnx.export()</code></a> function. This function performs a single pass through the model and records all operations to generate a <a href="https://pytorch.org/docs/stable/jit.html">TorchScript graph</a>. It then exports this graph to ONNX by decomposing each graph node (which contains a PyTorch operator) into a series of ONNX operators.</p>
<p>If we want the ONNX model to support different input sizes, we must set the width and height input axes as dynamic.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set a filename for the ONNX model</span></span>
<span id="cb11-2">onnx_file_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>checkpoint_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>colormap_path<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stem<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>removesuffix(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'-colormap'</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>checkpoint_path<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stem<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.onnx"</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Export the PyTorch model to ONNX format</span></span>
<span id="cb11-5">torch.onnx.export(model.cpu(),</span>
<span id="cb11-6">                  input_tensor.cpu(),</span>
<span id="cb11-7">                  onnx_file_path,</span>
<span id="cb11-8">                  export_params<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb11-9">                  do_constant_folding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb11-10">                  input_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input'</span>],</span>
<span id="cb11-11">                  output_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'scores'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'keypoints'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'keypoints_scores'</span>],</span>
<span id="cb11-12">                  dynamic_axes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input'</span>: {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> : <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'height'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> : <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'width'</span>}}</span>
<span id="cb11-13">                 )</span></code></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The export function may return some <code>UserWarning</code> messages when we export the model. We can ignore these warnings as the exported model functions as expected.</p>
</div>
</div>
</section>
<section id="simplify-the-onnx-model" class="level3">
<h3 class="anchored" data-anchor-id="simplify-the-onnx-model">Simplify the ONNX Model</h3>
<p>The ONNX models generated by PyTorch are not always the most concise. We can use the <a href="https://pypi.org/project/onnx-simplifier/"><code>onnx-simplifier</code></a> package to tidy up the exported model.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the ONNX model from the onnx_file_name</span></span>
<span id="cb12-2">onnx_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> onnx.load(onnx_file_path)</span>
<span id="cb12-3"></span>
<span id="cb12-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simplify the model</span></span>
<span id="cb12-5">model_simp, check <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> simplify(onnx_model)</span>
<span id="cb12-6"></span>
<span id="cb12-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save the simplified model to the onnx_file_name</span></span>
<span id="cb12-8">onnx.save(model_simp, onnx_file_path)</span></code></pre></div>
</section>
</section>
<section id="performing-inference-with-onnx-runtime" class="level2">
<h2 class="anchored" data-anchor-id="performing-inference-with-onnx-runtime">Performing Inference with ONNX Runtime</h2>
<p>Now that we have our ONNX model, it’s time to test it with ONNX Runtime.</p>
<section id="create-an-inference-session" class="level3">
<h3 class="anchored" data-anchor-id="create-an-inference-session">Create an Inference Session</h3>
<p>We interact with models in ONNX Runtime through an <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#load-and-run-a-model"><code>InferenceSession</code></a> object. Here we can specify which Execution Providers to use for inference and other configuration information. <a href="https://onnxruntime.ai/docs/execution-providers/">Execution Providers</a> are the interfaces for hardware-specific inference engines like <a href="https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html">TensorRT</a> for NVIDIA and <a href="https://onnxruntime.ai/docs/execution-providers/OpenVINO-ExecutionProvider.html">OpenVINO</a> for Intel. By default, the <code>InferenceSession</code> uses the generic <code>CPUExecutionProvider</code>.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the model and create an InferenceSession</span></span>
<span id="cb13-2">session <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ort.InferenceSession(onnx_file_path, providers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'CPUExecutionProvider'</span>])</span></code></pre></div>
</section>
<section id="define-annotation-function" class="level3">
<h3 class="anchored" data-anchor-id="define-annotation-function">Define Annotation Function</h3>
<p>Next, we need to annotate images with key points. PIL includes functionality to draw circles on images.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> draw_keypoints_pil(image, keypoints, labels, colors, radius:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>):</span>
<span id="cb14-2"></span>
<span id="cb14-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Annotates an image with keypoints, each marked by a circle and associated with specific labels and colors.</span></span>
<span id="cb14-5"></span>
<span id="cb14-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function draws circles on the provided image at given keypoint coordinates. Each keypoint is associated </span></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    with a label and a color. The radius of the circles can be adjusted.</span></span>
<span id="cb14-8"></span>
<span id="cb14-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parameters:</span></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    image (PIL.Image): The input image on which annotations will be drawn.</span></span>
<span id="cb14-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    keypoints (list of tuples): A list of (x, y) tuples representing the coordinates of each keypoint.</span></span>
<span id="cb14-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    labels (list of str): A list of labels corresponding to each keypoint.</span></span>
<span id="cb14-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    colors (list of tuples): A list of RGB tuples for each keypoint, defining the color of the circle to be drawn.</span></span>
<span id="cb14-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    radius (int, optional): The radius of the circles to be drawn for each keypoint. Defaults to 5.</span></span>
<span id="cb14-15"></span>
<span id="cb14-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb14-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    annotated_image (PIL.Image): The image annotated with keypoints, each represented as a colored circle.</span></span>
<span id="cb14-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb14-19">        </span>
<span id="cb14-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a copy of the image</span></span>
<span id="cb14-21">    annotated_image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.copy()</span>
<span id="cb14-22"></span>
<span id="cb14-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create an ImageDraw object for drawing on the image</span></span>
<span id="cb14-24">    draw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ImageDraw.Draw(annotated_image)</span>
<span id="cb14-25"></span>
<span id="cb14-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Loop through the bounding boxes and labels in the 'annotation' DataFrame</span></span>
<span id="cb14-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(labels)):</span>
<span id="cb14-28">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the key point coordinates</span></span>
<span id="cb14-29">        x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> keypoints[i]</span>
<span id="cb14-30"></span>
<span id="cb14-31">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Draw a circle</span></span>
<span id="cb14-32">        draw.ellipse((x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> radius, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> radius, x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> radius, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> radius), fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i])</span>
<span id="cb14-33">        </span>
<span id="cb14-34">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> annotated_image</span></code></pre></div>
</section>
<section id="select-a-test-image" class="level3">
<h3 class="anchored" data-anchor-id="select-a-test-image">Select a Test Image</h3>
<p>We can download an image from one of my HuggingFace repositories to verify the exported model performs as expected.</p>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">test_img_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pexels-2769554-man-doing-rock-and-roll-sign.jpg"</span></span>
<span id="cb15-2">test_img_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/cj-mills/pexel-hand-gesture-test-images/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>test_img_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb15-3"></span>
<span id="cb15-4">download_file(test_img_url, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'./'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb15-5"></span>
<span id="cb15-6">test_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(test_img_name)</span>
<span id="cb15-7">display(test_img)</span>
<span id="cb15-8"></span>
<span id="cb15-9">pd.Series({</span>
<span id="cb15-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Test Image Size:"</span>: test_img.size, </span>
<span id="cb15-11">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/onnx-export/images/output_32_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_daf38">
<thead>
</thead>
<tbody>
<tr>
<th id="T_daf38_level0_row0" class="row_heading level0 row0">
Test Image Size:
</th>
<td id="T_daf38_row0_col0" class="data row0 col0">
(640, 960)
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="prepare-the-test-image" class="level3">
<h3 class="anchored" data-anchor-id="prepare-the-test-image">Prepare the Test Image</h3>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set test image size</span></span>
<span id="cb16-2">test_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span></span>
<span id="cb16-3"></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## Resize the test image</span></span>
<span id="cb16-5">input_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_img(test_img, target_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test_sz, divisor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb16-6"></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the scale between the source image and the resized image</span></span>
<span id="cb16-8">min_img_scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(test_img.size) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(input_img.size)</span>
<span id="cb16-9"></span>
<span id="cb16-10">display(input_img)</span>
<span id="cb16-11"></span>
<span id="cb16-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the prediction data as a Pandas DataFrame for easy formatting</span></span>
<span id="cb16-13">pd.Series({</span>
<span id="cb16-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image Size:"</span>: test_img.size,</span>
<span id="cb16-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Input Dims:"</span>: input_img.size,</span>
<span id="cb16-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Min Image Scale:"</span>: min_img_scale,</span>
<span id="cb16-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Input Image Size:"</span>: input_img.size</span>
<span id="cb16-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/onnx-export/images/output_34_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_54014">
<thead>
</thead>
<tbody>
<tr>
<th id="T_54014_level0_row0" class="row_heading level0 row0">
Source Image Size:
</th>
<td id="T_54014_row0_col0" class="data row0 col0">
(640, 960)
</td>
</tr>
<tr>
<th id="T_54014_level0_row1" class="row_heading level0 row1">
Input Dims:
</th>
<td id="T_54014_row1_col0" class="data row1 col0">
(512, 768)
</td>
</tr>
<tr>
<th id="T_54014_level0_row2" class="row_heading level0 row2">
Min Image Scale:
</th>
<td id="T_54014_row2_col0" class="data row2 col0">
1.250000
</td>
</tr>
<tr>
<th id="T_54014_level0_row3" class="row_heading level0 row3">
Input Image Size:
</th>
<td id="T_54014_row3_col0" class="data row3 col0">
(512, 768)
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="prepare-the-input-tensor-1" class="level3">
<h3 class="anchored" data-anchor-id="prepare-the-input-tensor-1">Prepare the Input Tensor</h3>
<p>When we convert the PIL input image to a NumPy array, we need to reorder the array values to channels-first format, scale the values from <code>[0,255]</code> to <code>[0,1]</code>, and add a batch dimension.</p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the input image to NumPy format</span></span>
<span id="cb17-2">input_tensor_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array(input_img, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float32).transpose((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span></span></code></pre></div>
</section>
<section id="compute-the-predictions" class="level3">
<h3 class="anchored" data-anchor-id="compute-the-predictions">Compute the Predictions</h3>
<p>Now, we can finally perform inference with our ONNX model.</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run inference</span></span>
<span id="cb18-2">model_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> session.run(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>: input_tensor_np})</span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the confidence threshold</span></span>
<span id="cb18-5">conf_threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span></span>
<span id="cb18-6"></span>
<span id="cb18-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Filter the output based on the confidence threshold</span></span>
<span id="cb18-8">scores_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_output[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> conf_threshold</span>
<span id="cb18-9"></span>
<span id="cb18-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract and scale the predicted keypoints</span></span>
<span id="cb18-11">predicted_keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (model_output[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>][scores_mask])[:,:,:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>min_img_scale</span>
<span id="cb18-12">predicted_keypoints</span>
<span id="cb18-13"></span>
<span id="cb18-14">labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>class_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(scores_mask).item()</span>
<span id="cb18-15"></span>
<span id="cb18-16">draw_keypoints_pil(test_img, </span>
<span id="cb18-17">                predicted_keypoints, </span>
<span id="cb18-18">                labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels,</span>
<span id="cb18-19">                colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]],</span>
<span id="cb18-20">               )</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/onnx-export/images/output_38_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The model appears to work as intended, even on this new image.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Google Colab Users
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Don’t forget to download the ONNX model from the Colab Environment’s file browser. (<a href="https://christianjmills.com/posts/google-colab-getting-started-tutorial/#working-with-data">tutorial link</a>)</li>
</ol>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Congratulations on reaching the end of this tutorial! We previously trained a Keypoint R-CNN model in PyTorch, and now we’ve exported that model to ONNX. With this, we can streamline our deployment process and leverage platform-specific hardware optimizations through ONNX Runtime.</p>
<p>As you move forward, consider exploring more about ONNX and its ecosystem. Check out the available <a href="https://onnxruntime.ai/docs/execution-providers/">Execution Providers</a> that provide flexible interfaces to different hardware acceleration libraries.</p>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>onnx</category>
  <category>keypoint-rcnn</category>
  <category>keypoint-estimation</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/onnx-export/</guid>
  <pubDate>Tue, 30 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Training Keypoint R-CNN Models with PyTorch</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../series/tutorials/pytorch-train-keypoint-rcnn-series.html"><strong>Training Keypoint R-CNN Models with PyTorch</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Setting Up the Project</li>
<li>Loading and Exploring the Dataset</li>
<li>Loading the Keypoint R-CNN Model</li>
<li>Preparing the Data</li>
<li>Fine-tuning the Model</li>
<li>Making Predictions with the Model</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to this hands-on guide to training Keypoint R-CNN models in PyTorch. Keypoint estimation models predict the locations of points on a given object or person, allowing us to recognize and interpret poses, gestures, or significant parts of objects.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/images/pytorch-keypoint-r-cnn-tutorial-hero-image.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The tutorial walks through setting up a Python environment, loading the raw keypoint annotations, annotating and augmenting images, creating a custom <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Dataset</a> class to feed samples to a model, finetuning a Keypoint R-CNN model, and performing inference.</p>
<p>This guide is suitable for beginners and experienced practitioners, providing the code, explanations, and resources needed to understand and implement each step. Upon completion, you will have a solid foundation for training custom key point estimation models for other projects.</p>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>The tutorial code is available as a <a href="https://jupyter.org/">Jupyter Notebook</a>, which you can run locally or in a cloud-based environment like <a href="https://colab.research.google.com/">Google Colab</a>. I have dedicated tutorials for those new to these platforms or who need guidance setting up:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Setup Guides">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Setup Guides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../posts/google-colab-getting-started-tutorial/"><strong>Getting Started with Google Colab</strong></a></li>
<li><a href="../../posts/mamba-getting-started-tutorial-windows/"><strong>Setting Up a Local Python Environment with Mamba for Machine Learning Projects on Windows</strong></a></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Tutorial Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tutorial Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Platform</th>
<th>Jupyter Notebook</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Google Colab</td>
<td><a href="https://colab.research.google.com/github/cj-mills/pytorch-keypoint-rcnn-tutorial-code/blob/main/notebooks/pytorch-keypoint-r-cnn-training-labelme.ipynb">Open In Colab</a></td>
</tr>
<tr class="even">
<td>Linux</td>
<td><a href="https://github.com/cj-mills/pytorch-keypoint-rcnn-tutorial-code/blob/main/notebooks/pytorch-keypoint-r-cnn-training-labelme.ipynb">GitHub Repository</a></td>
</tr>
<tr class="odd">
<td>Windows</td>
<td><a href="https://github.com/cj-mills/pytorch-keypoint-rcnn-tutorial-code/blob/main/notebooks/pytorch-keypoint-r-cnn-training-labelme-windows.ipynb">GitHub Repository</a></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>Before diving into the code, we’ll cover the steps to create a local Python environment and install the necessary dependencies.</p>
<section id="creating-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-python-environment">Creating a Python Environment</h3>
<p>First, we’ll create a Python environment using <a href="https://docs.conda.io/en/latest/">Conda</a>/<a href="https://mamba.readthedocs.io/en/latest/">Mamba</a>. Open a terminal with Conda/Mamba installed and run the following commands:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Conda</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Mamba</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.11 environment</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.11 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate pytorch-env</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.11 environment</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.11 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate pytorch-env</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="installing-pytorch">Installing PyTorch</h3>
<p>Next, we’ll install <a href="https://pytorch.org/">PyTorch</a>. Run the appropriate command for your hardware and operating system.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Linux/Windows (CUDA)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Mac</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Linux (CPU)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Windows (CPU)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch with CUDA</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cu121</span></code></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MPS (Metal Performance Shaders) acceleration is available on MacOS 12.3+</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cpu</span></code></pre></div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-additional-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-libraries">Installing Additional Libraries</h3>
<p>We also need to install some additional libraries for our project.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>jupyter</code></td>
<td>An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. (<a href="https://jupyter.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>matplotlib</code></td>
<td>This package provides a comprehensive collection of visualization tools to create high-quality plots, charts, and graphs for data exploration and presentation. (<a href="https://matplotlib.org/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>pandas</code></td>
<td>This package provides fast, powerful, and flexible data analysis and manipulation tools. (<a href="https://pandas.pydata.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>pillow</code></td>
<td>The Python Imaging Library adds image processing capabilities. (<a href="https://pillow.readthedocs.io/en/stable/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>torchtnt</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>tabulate</code></td>
<td>Pretty-print tabular data in Python. (<a href="https://pypi.org/project/tabulate/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>tqdm</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>distinctipy</code></td>
<td>A lightweight python package providing functions to generate colours that are visually distinct from one another. (<a href="https://distinctipy.readthedocs.io/en/latest/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following command to install these additional libraries:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional dependencies</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install distinctipy jupyter matplotlib pandas pillow torchtnt==0.2.0 tabulate tqdm</span></code></pre></div>
</section>
<section id="installing-utility-packages" class="level3">
<h3 class="anchored" data-anchor-id="installing-utility-packages">Installing Utility Packages</h3>
<p>We will also install some utility packages I made, which provide shortcuts for routine tasks.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>cjm_pandas_utils</code></td>
<td>Some utility functions for working with Pandas. (<a href="https://cj-mills.github.io/cjm-pandas-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_pil_utils</code></td>
<td>Some PIL utility functions I frequently use. (<a href="https://cj-mills.github.io/cjm-pil-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_psl_utils</code></td>
<td>Some utility functions using the Python Standard Library. (<a href="https://cj-mills.github.io/cjm-psl-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_pytorch_utils</code></td>
<td>Some utility functions for working with PyTorch. (<a href="https://cj-mills.github.io/cjm-pytorch-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_torchvision_tfms</code></td>
<td>Some custom Torchvision tranforms. (<a href="https://cj-mills.github.io/cjm-torchvision-tfms/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following command to install the utility packages:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional utility packages</span></span>
<span id="cb8-2">pip install cjm_pandas_utils cjm_pil_utils cjm_psl_utils cjm_pytorch_utils cjm_torchvision_tfms</span></code></pre></div>
<p>With our environment set up, we can open our Jupyter Notebook and dive into the code.</p>
</section>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python modules into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> contextlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> contextmanager</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> datetime</span>
<span id="cb9-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb9-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> glob <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> glob</span>
<span id="cb9-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb9-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math</span>
<span id="cb9-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> multiprocessing</span>
<span id="cb9-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb9-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb9-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> random</span>
<span id="cb9-12"></span>
<span id="cb9-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb9-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pandas_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> markdown_to_pandas</span>
<span id="cb9-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> resize_img, get_img_files, stack_imgs</span>
<span id="cb9-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file, file_extract</span>
<span id="cb9-17"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pytorch_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> set_seed, pil_to_tensor, tensor_to_pil, get_torch_device, denorm_img_tensor, move_data_to_device</span>
<span id="cb9-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_torchvision_tfms.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ResizeMax, PadSquare, CustomRandomIoUCrop, RandomPixelCopy</span>
<span id="cb9-19"></span>
<span id="cb9-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the distinctipy module</span></span>
<span id="cb9-21"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distinctipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> distinctipy</span>
<span id="cb9-22"></span>
<span id="cb9-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import matplotlib for creating plots</span></span>
<span id="cb9-24"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb9-25"></span>
<span id="cb9-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb9-27"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-28"></span>
<span id="cb9-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb9-30"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb9-31"></span>
<span id="cb9-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb9-33">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb9-34"></span>
<span id="cb9-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb9-36"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image</span>
<span id="cb9-37"></span>
<span id="cb9-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb9-39"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb9-40"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb9-41"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.amp <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> autocast</span>
<span id="cb9-42"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.cuda.amp <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GradScaler</span>
<span id="cb9-43"></span>
<span id="cb9-44"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DataLoader</span>
<span id="cb9-45"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchtnt.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_module_summary</span>
<span id="cb9-46"></span>
<span id="cb9-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import torchvision dependencies</span></span>
<span id="cb9-48"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision</span>
<span id="cb9-49">torchvision.disable_beta_transforms_warning()</span>
<span id="cb9-50"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BoundingBoxes</span>
<span id="cb9-51"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> draw_bounding_boxes</span>
<span id="cb9-52"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.v2  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb9-53"></span>
<span id="cb9-54"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Keypoint R-CNN</span></span>
<span id="cb9-55"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.models.detection.keypoint_rcnn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KeypointRCNNPredictor</span>
<span id="cb9-56"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.models.detection.rpn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AnchorGenerator</span>
<span id="cb9-57"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.models.detection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> keypointrcnn_resnet50_fpn</span>
<span id="cb9-58"></span>
<span id="cb9-59"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import tqdm for progress bar</span></span>
<span id="cb9-60"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm.auto <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
<p>Torchvision provides dedicated <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> subclasses for different annotation types called <a href="https://pytorch.org/vision/stable/tv_tensors.html"><code>TVTensors</code></a>. Torchvision’s V2 transforms use these subclasses to update the annotations based on the applied image augmentations. While there is currently no dedicated TVTensor class for keypoint annotations, we can use the one for <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.BoundingBoxes.html">bounding boxes</a> instead. Torchvision does include a <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_keypoints.html"><code>draw_keypoints</code></a> function, but we might as well stick with the <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function to annotate images.</p>
</section>
<section id="setting-up-the-project" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-the-project">Setting Up the Project</h2>
<p>In this section, we set up some basics for our project, such as initializing random number generators, setting the PyTorch device to run the model, and preparing the folders for our project and datasets.</p>
<section id="setting-a-random-number-seed" class="level3">
<h3 class="anchored" data-anchor-id="setting-a-random-number-seed">Setting a Random Number Seed</h3>
<p>First, we set the seed for generating random numbers using the <a href="https://cj-mills.github.io/cjm-pytorch-utils/core.html#set_seed">set_seed</a> function from the <code>cjm_pytorch_utils</code> package.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the seed for generating random numbers in PyTorch, NumPy, and Python's random module.</span></span>
<span id="cb10-2">seed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span></span>
<span id="cb10-3">set_seed(seed)</span></code></pre></div>
</section>
<section id="setting-the-device-and-data-type" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-device-and-data-type">Setting the Device and Data Type</h3>
<p>Next, we determine the device to use for training using the <a href="https://cj-mills.github.io/cjm-pytorch-utils/core.html#get_torch_device">get_torch_device</a> function from the <code>cjm_pytorch_utils</code> package and set the data type of our tensors.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_torch_device()</span>
<span id="cb11-2">dtype <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.float32</span>
<span id="cb11-3">device, dtype</span></code></pre></div>
<pre class="text"><code>('cuda', torch.float32)</code></pre>
</section>
<section id="setting-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-directory-paths">Setting the Directory Paths</h3>
<p>We can then set up a directory for our project to store our results and other related files. We also need a place to store our dataset. The following code creates the folders in the current directory (<code>./</code>). Update the path if that is not suitable for you.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The name for the project</span></span>
<span id="cb13-2">project_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"pytorch-keypoint-r-cnn"</span></span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The path for the project folder</span></span>
<span id="cb13-5">project_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"./</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/"</span>)</span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the project directory if it does not already exist</span></span>
<span id="cb13-8">project_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store datasets</span></span>
<span id="cb13-11">dataset_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./Datasets/"</span>)</span>
<span id="cb13-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the dataset directory if it does not exist</span></span>
<span id="cb13-13">dataset_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb13-14"></span>
<span id="cb13-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store archive files</span></span>
<span id="cb13-16">archive_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'../Archive'</span></span>
<span id="cb13-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the archive directory if it does not exist</span></span>
<span id="cb13-18">archive_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb13-19"></span>
<span id="cb13-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb13-21">pd.Series({</span>
<span id="cb13-22">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Project Directory:"</span>: project_dir,</span>
<span id="cb13-23">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Directory:"</span>: dataset_dir, </span>
<span id="cb13-24">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Directory:"</span>: archive_dir</span>
<span id="cb13-25">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_c7875">
<thead>
</thead>
<tbody>
<tr>
<th id="T_c7875_level0_row0" class="row_heading level0 row0">
Project Directory:
</th>
<td id="T_c7875_row0_col0" class="data row0 col0">
pytorch-keypoint-r-cnn
</td>
</tr>
<tr>
<th id="T_c7875_level0_row1" class="row_heading level0 row1">
Dataset Directory:
</th>
<td id="T_c7875_row1_col0" class="data row1 col0">
Datasets
</td>
</tr>
<tr>
<th id="T_c7875_level0_row2" class="row_heading level0 row2">
Archive Directory:
</th>
<td id="T_c7875_row2_col0" class="data row2 col0">
Datasets/../Archive
</td>
</tr>
</tbody>
</table>
</div>
<p>Double-check the project and dataset directories exist in the specified paths and that you can add files to them before continuing. At this point, our project is set up and ready to go. In the next section, we will download and explore the dataset.</p>
</section>
</section>
<section id="loading-and-exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-and-exploring-the-dataset">Loading and Exploring the Dataset</h2>
<p>I annotated a small dataset with key points for this tutorial using images from the free stock photo site <a href="https://www.pexels.com/">Pexels</a>. The dataset is available on <a href="https://huggingface.co/">HuggingFace Hub</a> at the link below:</p>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/datasets/cj-mills/labelme-keypoint-eyes-noses-dataset/tree/main">labelme-keypoint-eyes-noses-dataset</a></li>
</ul>
<p>The dataset contains 2D coordinates for eyes and noses on human faces.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Keypoint Annotation Format">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Keypoint Annotation Format
</div>
</div>
<div class="callout-body-container callout-body">
<p>The keypoints for this dataset use the <a href="https://github.com/labelmeai/labelme">LabelMe</a> annotation format. You can learn more about this format and how to work with such annotations in the tutorial linked below:</p>
<ul>
<li><a href="../../posts/torchvision-labelme-annotation-tutorials/keypoints/">Working with LabelMe Keypoint Annotations in Torchvision</a></li>
</ul>
</div>
</div>
<section id="setting-the-dataset-path" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-dataset-path">Setting the Dataset Path</h3>
<p>First, we construct the name for the Hugging Face Hub dataset and set where to download and extract the dataset.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the dataset</span></span>
<span id="cb14-2">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labelme-keypoint-eyes-noses-dataset'</span></span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb14-5">hf_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'cj-mills/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb14-8">archive_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>archive_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip'</span>)</span>
<span id="cb14-9"></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb14-11">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb14-12"></span>
<span id="cb14-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the dataset name and paths and converting it to a DataFrame for display</span></span>
<span id="cb14-14">pd.Series({</span>
<span id="cb14-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb14-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Path:"</span>: archive_path, </span>
<span id="cb14-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Path:"</span>: dataset_path</span>
<span id="cb14-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_be76c">
<thead>
</thead>
<tbody>
<tr>
<th id="T_be76c_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_be76c_row0_col0" class="data row0 col0">
cj-mills/labelme-keypoint-eyes-noses-dataset
</td>
</tr>
<tr>
<th id="T_be76c_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_be76c_row1_col0" class="data row1 col0">
Datasets/../Archive/labelme-keypoint-eyes-noses-dataset.zip
</td>
</tr>
<tr>
<th id="T_be76c_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_be76c_row2_col0" class="data row2 col0">
Datasets/labelme-keypoint-eyes-noses-dataset
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="downloading-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h3>
<p>We can now download the archive file and extract the dataset using the <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#download_file"><code>download_file</code></a> and <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#file_extract"><code>file_extract</code></a> functions from the <code>cjm_psl_utils</code> package. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb15-2">dataset_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>hf_dataset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip"</span></span>
<span id="cb15-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"HuggingFace Dataset URL: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb15-4"></span>
<span id="cb15-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb15-6">delete_archive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb15-7"></span>
<span id="cb15-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the dataset if not present</span></span>
<span id="cb15-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset_path.is_dir():</span>
<span id="cb15-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset folder already exists"</span>)</span>
<span id="cb15-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb15-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Downloading dataset..."</span>)</span>
<span id="cb15-13">    download_file(dataset_url, archive_dir)    </span>
<span id="cb15-14">    </span>
<span id="cb15-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extracting dataset..."</span>)</span>
<span id="cb15-16">    file_extract(fname<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>archive_path, dest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_dir)</span>
<span id="cb15-17">    </span>
<span id="cb15-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete the archive if specified</span></span>
<span id="cb15-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> delete_archive: archive_path.unlink()</span></code></pre></div>
</section>
<section id="get-image-file-paths" class="level3">
<h3 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h3>
<p>Next, we will make a dictionary that maps each image’s unique name to its file path, allowing us to retrieve the file path for a given image more efficiently.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of image files in the dataset</span></span>
<span id="cb16-2">img_file_paths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_img_files(dataset_path)</span>
<span id="cb16-3"></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary that maps file names to file paths</span></span>
<span id="cb16-5">img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.stem : <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> (img_file_paths)}</span>
<span id="cb16-6"></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of image files</span></span>
<span id="cb16-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Number of Images: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_dict)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb16-9"></span>
<span id="cb16-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb16-11">pd.DataFrame.from_dict(img_dict, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).head()</span></code></pre></div>
<pre class="text"><code>Number of Images: 200</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
denim-jacket-fashion-fashion-model-1848570
</th>
<td>
Datasets/labelme-keypoint-eyes-noses-dataset/denim-jacket-fashion-fashion-model-1848570.jpg
</td>
</tr>
<tr>
<th>
dried-dry-face-2965690
</th>
<td>
Datasets/labelme-keypoint-eyes-noses-dataset/dried-dry-face-2965690.jpg
</td>
</tr>
<tr>
<th>
elderly-face-old-person-2856346
</th>
<td>
Datasets/labelme-keypoint-eyes-noses-dataset/elderly-face-old-person-2856346.jpg
</td>
</tr>
<tr>
<th>
elderly-hair-man-1319289
</th>
<td>
Datasets/labelme-keypoint-eyes-noses-dataset/elderly-hair-man-1319289.jpg
</td>
</tr>
<tr>
<th>
face-facial-expression-fashion-2592000
</th>
<td>
Datasets/labelme-keypoint-eyes-noses-dataset/face-facial-expression-fashion-2592000.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="get-image-annotations">Get Image Annotations</h3>
<p>We will then read the content of the JSON annotation file associated with each image into a single Pandas DataFrame so we can easily query the annotations.</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of JSON files in the dataset</span></span>
<span id="cb18-2">annotation_file_paths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(dataset_path.glob(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'*.json'</span>))</span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a generator that yields Pandas DataFrames containing the data from each JSON file</span></span>
<span id="cb18-5">cls_dataframes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (pd.read_json(f, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).transpose() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> f <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(annotation_file_paths))</span>
<span id="cb18-6"></span>
<span id="cb18-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Concatenate the DataFrames into a single DataFrame</span></span>
<span id="cb18-8">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.concat(cls_dataframes, ignore_index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb18-9"></span>
<span id="cb18-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assign the image file name as the index for each row</span></span>
<span id="cb18-11">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> row: row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'imagePath'</span>].split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb18-12">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>)</span>
<span id="cb18-13"></span>
<span id="cb18-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Keep only the rows that correspond to the filenames in the 'img_dict' dictionary</span></span>
<span id="cb18-15">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())]</span>
<span id="cb18-16"></span>
<span id="cb18-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the first 5 rows of the DataFrame</span></span>
<span id="cb18-18">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
version
</th>
<th>
flags
</th>
<th>
shapes
</th>
<th>
imagePath
</th>
<th>
imageData
</th>
<th>
imageHeight
</th>
<th>
imageWidth
</th>
</tr>
<tr>
<th>
index
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
denim-jacket-fashion-fashion-model-1848570
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘left-eye’, ‘points’: [[329.17073170731703, 252.59756097560972]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}, {‘label’: ‘nose’, ‘points’: [[323.68292682926835, 291.0121951219512]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}, {‘label’: ‘right-eye’, ‘points’: [[260.2682926829268, 234.91463414634143]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
<td>
denim-jacket-fashion-fashion-model-1848570.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
512
</td>
</tr>
<tr>
<th>
dried-dry-face-2965690
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘right-eye’, ‘points’: [[201.7317073170732, 351.9878048780488]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}, {‘label’: ‘left-eye’, ‘points’: [[333.43902439024396, 342.23170731707313]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}, {‘label’: ‘nose’, ‘points’: [[271.2439024390244, 436.1341463414634]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
<td>
dried-dry-face-2965690.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
512
</td>
</tr>
<tr>
<th>
elderly-face-old-person-2856346
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘left-eye’, ‘points’: [[302.3414634146342, 286.1341463414634]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}, {‘label’: ‘nose’, ‘points’: [[243.80487804878055, 339.79268292682923]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}, {‘label’: ‘right-eye’, ‘points’: [[196.2439024390244, 286.7439024390244]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
<td>
elderly-face-old-person-2856346.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
512
</td>
</tr>
<tr>
<th>
elderly-hair-man-1319289
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘right-eye’, ‘points’: [[490.910569105691, 175.71544715447155]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}, {‘label’: ‘left-eye’, ‘points’: [[548.6341463414634, 167.58536585365852]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}, {‘label’: ‘nose’, ‘points’: [[526.6829268292682, 201.73170731707316]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
<td>
elderly-hair-man-1319289.jpg
</td>
<td>
None
</td>
<td>
512
</td>
<td>
768
</td>
</tr>
<tr>
<th>
face-facial-expression-fashion-2592000
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘left-eye’, ‘points’: [[301.45454545454544, 106.85561497326205]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}, {‘label’: ‘right-eye’, ‘points’: [[250.65240641711233, 115.94652406417114]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}, {‘label’: ‘nose’, ‘points’: [[272.0427807486631, 121.29411764705884]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
<td>
face-facial-expression-fashion-2592000.jpg
</td>
<td>
None
</td>
<td>
672
</td>
<td>
512
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspecting-the-class-distribution" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-the-class-distribution">Inspecting the Class Distribution</h3>
<p>Now that we have the annotation data, we can extract the unique class names and inspect the class distribution. A balanced dataset (where each class has approximately the same number of instances) is ideal for training a machine-learning model.</p>
<section id="get-image-classes" class="level4">
<h4 class="anchored" data-anchor-id="get-image-classes">Get image classes</h4>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Explode the 'shapes' column in the annotation_df dataframe</span></span>
<span id="cb19-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the pandas Series function to the 'shapes' column of the dataframe</span></span>
<span id="cb19-3">shapes_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>].explode().to_frame().shapes.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)</span>
<span id="cb19-4"></span>
<span id="cb19-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb19-6">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shapes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>].unique().tolist()</span>
<span id="cb19-7"></span>
<span id="cb19-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display labels using a Pandas DataFrame</span></span>
<span id="cb19-9">pd.DataFrame(class_names)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
left-eye
</td>
</tr>
<tr>
<th>
1
</th>
<td>
nose
</td>
</tr>
<tr>
<th>
2
</th>
<td>
right-eye
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visualize-the-class-distribution" class="level4">
<h4 class="anchored" data-anchor-id="visualize-the-class-distribution">Visualize the class distribution</h4>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the number of samples for each object class</span></span>
<span id="cb20-2">class_counts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shapes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>].value_counts()</span>
<span id="cb20-3"></span>
<span id="cb20-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the distribution</span></span>
<span id="cb20-5">class_counts.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bar'</span>)</span>
<span id="cb20-6">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class distribution'</span>)</span>
<span id="cb20-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Count'</span>)</span>
<span id="cb20-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Classes'</span>)</span>
<span id="cb20-9">plt.xticks(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_counts.index)), class_counts.index, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the x-axis tick labels</span></span>
<span id="cb20-10">plt.show()</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/images/output_26_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
<section id="visualizing-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-image-annotations">Visualizing Image Annotations</h3>
<p>In this section, we will annotate a single image with its bounding boxes using torchvision’s <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.BoundingBoxes.html"><code>BoundingBoxes</code></a> class and <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function.</p>
<section id="generate-a-color-map" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-color-map">Generate a color map</h4>
<p>First, we will generate a color map for the object classes.</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb21-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distinctipy.get_colors(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the color map in integer format</span></span>
<span id="cb21-5">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colors]</span>
<span id="cb21-6"></span>
<span id="cb21-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a color swatch to visualize the color map</span></span>
<span id="cb21-8">distinctipy.color_swatch(colors)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/images/output_30_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a font file</h4>
<p>The <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function included with torchvision uses a pretty small font size. We can increase the font size if we use a custom font. Font files are available on sites like <a href="https://fonts.google.com/">Google Fonts</a>, or we can use one included with the operating system.</p>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb22-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb22-3"></span>
<span id="cb22-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb22-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
</section>
<section id="define-the-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-the-bounding-box-annotation-function">Define the bounding box annotation function</h4>
<p>We can make a partial function using <code>draw_bounding_boxes</code> since we’ll use the same box thickness and font each time we visualize bounding boxes.</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">draw_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(draw_bounding_boxes, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, font<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>font_file, font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
</section>
</section>
<section id="annotate-sample-image" class="level3">
<h3 class="anchored" data-anchor-id="annotate-sample-image">Annotate sample image</h3>
<p>Finally, we will open a sample image and annotate it with it’s associated bounding boxes.</p>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the file ID of the first image file</span></span>
<span id="cb24-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb24-3"></span>
<span id="cb24-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the associated image file as a RGB image</span></span>
<span id="cb24-5">sample_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(img_dict[file_id]).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb24-6"></span>
<span id="cb24-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels and bounding box annotations for the sample image</span></span>
<span id="cb24-8">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb24-9">keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(np.array([shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]])).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb24-10">BBOX_DIM <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb24-11">keypoints_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((keypoints, torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(keypoints), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>BBOX_DIM), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb24-12"></span>
<span id="cb24-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb24-14">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb24-15">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sample_img), </span>
<span id="cb24-16">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torchvision.ops.box_convert(torch.Tensor(keypoints_bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>),</span>
<span id="cb24-17">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, </span>
<span id="cb24-18">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb24-19">)</span>
<span id="cb24-20"></span>
<span id="cb24-21">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/images/output_36_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
<section id="loading-the-keypoint-r-cnn-model" class="level2">
<h2 class="anchored" data-anchor-id="loading-the-keypoint-r-cnn-model">Loading the Keypoint R-CNN Model</h2>
<p>TorchVision provides <a href="https://pytorch.org/vision/stable/models.html#table-of-all-available-keypoint-detection-weights">checkpoints</a> for the Keypoint R-CNN model trained on the <a href="https://cocodataset.org/">COCO</a> (Common Objects in Context) dataset. We can initialize a model with these pretrained weights using the <a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.detection.keypointrcnn_resnet50_fpn.html?highlight=keypointrcnn_resnet50_fpn"><code>keypointrcnn_resnet50_fpn</code></a> function. We must then replace the keypoint predictor for the pretrained model with a new one for our dataset.</p>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load a pre-trained model</span></span>
<span id="cb25-2">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> keypointrcnn_resnet50_fpn(weights<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'DEFAULT'</span>)</span>
<span id="cb25-3"></span>
<span id="cb25-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Replace the classifier head with the number of keypoints</span></span>
<span id="cb25-5">in_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.roi_heads.keypoint_predictor.kps_score_lowres.in_channels</span>
<span id="cb25-6">model.roi_heads.keypoint_predictor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KeypointRCNNPredictor(in_channels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>in_features, num_keypoints<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb25-7"></span>
<span id="cb25-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the model's device and data type</span></span>
<span id="cb25-9">model.to(device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dtype)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb25-10"></span>
<span id="cb25-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add attributes to store the device and model name for later reference</span></span>
<span id="cb25-12">model.device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> device</span>
<span id="cb25-13">model.name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'keypointrcnn_resnet50_fpn'</span></span></code></pre></div>
<p>The model internally normalizes input using the mean and standard deviation values used during the pretraining process, so we do not need to keep track of them separately.</p>
<section id="summarizing-the-model" class="level3">
<h3 class="anchored" data-anchor-id="summarizing-the-model">Summarizing the Model</h3>
<p>Before moving on, let’s generate a summary of our model to get an overview of its performance characteristics. We can use this to gauge the computational requirements for deploying the model.</p>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the input to the model</span></span>
<span id="cb26-2">test_inp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>).to(device)</span>
<span id="cb26-3"></span>
<span id="cb26-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a summary of the model as a Pandas DataFrame</span></span>
<span id="cb26-5">summary_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> markdown_to_pandas(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>get_module_summary(model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>(), [test_inp])<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb26-6"></span>
<span id="cb26-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Filter the summary to only the model</span></span>
<span id="cb26-8">summary_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> summary_df[summary_df.index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb26-9"></span>
<span id="cb26-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Remove the column "Contains Uninitialized Parameters?"</span></span>
<span id="cb26-11">summary_df.drop([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'In size'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Out size'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Contains Uninitialized Parameters?'</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Type
</th>
<th>
# Parameters
</th>
<th>
# Trainable Parameters
</th>
<th>
Size (bytes)
</th>
<th>
Forward FLOPs
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
KeypointRCNN
</td>
<td>
59.0 M
</td>
<td>
58.8 M
</td>
<td>
236 M
</td>
<td>
144 G
</td>
</tr>
</tbody>
</table>
</div>
<p>The above table shows the model has approximately <code>58.8</code> million trainable parameters. It takes up <code>263</code> Megabytes and performs around <code>144</code> billion floating point operations for a single <code>256x256</code> RGB image. This model internally resizes input images and executes the same number of floating point operations for different input resolutions.</p>
<p>That completes the model setup. In the next section, we will prepare our dataset for training.</p>
</section>
</section>
<section id="preparing-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data">Preparing the Data</h2>
<p>The data preparation involves several steps, such as applying data augmentation techniques, setting up the train-validation split for the dataset, resizing and padding the images, defining the training dataset class, and initializing DataLoaders to feed data to the model.</p>
<section id="training-validation-split" class="level3">
<h3 class="anchored" data-anchor-id="training-validation-split">Training-Validation Split</h3>
<p>Let’s begin by defining the training-validation split. We’ll randomly select 90% of the available samples for the training set and use the remaining 10% for the validation set.</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the list of image IDs</span></span>
<span id="cb27-2">img_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())</span>
<span id="cb27-3"></span>
<span id="cb27-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shuffle the image IDs</span></span>
<span id="cb27-5">random.shuffle(img_keys)</span>
<span id="cb27-6"></span>
<span id="cb27-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the percentage of the images that should be used for training</span></span>
<span id="cb27-8">train_pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span></span>
<span id="cb27-9">val_pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span></span>
<span id="cb27-10"></span>
<span id="cb27-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the index at which to split the subset of image paths into training and validation sets</span></span>
<span id="cb27-12">train_split <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_keys)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>train_pct)</span>
<span id="cb27-13">val_split <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_keys)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>(train_pct<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>val_pct))</span>
<span id="cb27-14"></span>
<span id="cb27-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split the subset of image paths into training and validation sets</span></span>
<span id="cb27-16">train_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys[:train_split]</span>
<span id="cb27-17">val_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys[train_split:]</span>
<span id="cb27-18"></span>
<span id="cb27-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of images in the training and validation sets</span></span>
<span id="cb27-20">pd.Series({</span>
<span id="cb27-21">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Training Samples:"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_keys),</span>
<span id="cb27-22">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Validation Samples:"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(val_keys)</span>
<span id="cb27-23">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_39a47">
<thead>
</thead>
<tbody>
<tr>
<th id="T_39a47_level0_row0" class="row_heading level0 row0">
Training Samples:
</th>
<td id="T_39a47_row0_col0" class="data row0 col0">
180
</td>
</tr>
<tr>
<th id="T_39a47_level0_row1" class="row_heading level0 row1">
Validation Samples:
</th>
<td id="T_39a47_row1_col0" class="data row1 col0">
20
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h3>
<p>Here, we will define some data augmentations to apply to images during training. I created a few custom image transforms to help streamline the code.</p>
<p>The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#customrandomioucrop">first</a> extends the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.RandomIoUCrop.html#torchvision.transforms.v2.RandomIoUCrop"><code>RandomIoUCrop</code></a> transform included with torchvision to give the user more control over how much it crops into bounding box areas. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#resizemax">second</a> resizes images based on their largest dimension rather than their smallest. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#padsquare">third</a> applies square padding and allows the padding to be applied equally on both sides or randomly split between the two sides.</p>
<p>All three are available through the <a href="https://cj-mills.github.io/cjm-torchvision-tfms/"><code>cjm-torchvision-tfms</code></a> package.</p>
<section id="set-training-image-size" class="level4">
<h4 class="anchored" data-anchor-id="set-training-image-size">Set training image size</h4>
<p>First, we will specify the image size to use during training.</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set training image size</span></span>
<span id="cb28-2">train_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span></span></code></pre></div>
</section>
<section id="initialize-custom-transforms" class="level4">
<h4 class="anchored" data-anchor-id="initialize-custom-transforms">Initialize custom transforms</h4>
<p>Next, we can initialize the transform objects.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomIoUCrop object</span></span>
<span id="cb29-2">iou_crop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomRandomIoUCrop(min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb29-3">                               max_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, </span>
<span id="cb29-4">                               min_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, </span>
<span id="cb29-5">                               max_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, </span>
<span id="cb29-6">                               sampler_options<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb29-7">                               trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb29-8">                               jitter_factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)</span>
<span id="cb29-9"></span>
<span id="cb29-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `ResizeMax` object</span></span>
<span id="cb29-11">resize_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ResizeMax(max_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_sz)</span>
<span id="cb29-12"></span>
<span id="cb29-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `PadSquare` object</span></span>
<span id="cb29-14">pad_square <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PadSquare(shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</section>
<section id="test-the-transforms" class="level4">
<h4 class="anchored" data-anchor-id="test-the-transforms">Test the transforms</h4>
<p>Torchvision’s V2 image transforms take an image and a <code>targets</code> dictionary. The <code>targets</code> dictionary contains the annotations and labels for the image.</p>
<p>We will pass input through the <code>CustomRandomIoUCrop</code> transform first and then through <code>ResizeMax</code> and <code>PadSquare</code>. We can pass the result through a final resize operation to ensure both sides match the <code>train_sz</code> value.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always use the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.SanitizeBoundingBoxes.html#torchvision.transforms.v2.SanitizeBoundingBoxes"><code>SanitizeBoundingBoxes</code></a> transform to clean up annotations after using data augmentations that alter bounding boxes (e.g., cropping, warping, etc.).</p>
</div>
</div>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels for the sample</span></span>
<span id="cb30-2">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb30-3"></span>
<span id="cb30-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare bounding box targets</span></span>
<span id="cb30-5">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: BoundingBoxes(torchvision.ops.box_convert(keypoints_bboxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>), </span>
<span id="cb30-6">                                <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, </span>
<span id="cb30-7">                                canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), </span>
<span id="cb30-8">           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.Tensor([class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])}</span>
<span id="cb30-9"></span>
<span id="cb30-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Crop the image</span></span>
<span id="cb30-11">cropped_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iou_crop(sample_img, targets)</span>
<span id="cb30-12"></span>
<span id="cb30-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Resize the image</span></span>
<span id="cb30-14">resized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_max(cropped_img, targets)</span>
<span id="cb30-15"></span>
<span id="cb30-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pad the image</span></span>
<span id="cb30-17">padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_square(resized_img, targets)</span>
<span id="cb30-18"></span>
<span id="cb30-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the padded image is the target size</span></span>
<span id="cb30-20">resize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb30-21">resized_padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize(padded_img, targets)</span>
<span id="cb30-22">sanitized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(resized_padded_img, targets)</span>
<span id="cb30-23"></span>
<span id="cb30-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get colors for dataset sample</span></span>
<span id="cb30-25">sample_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb30-26"></span>
<span id="cb30-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb30-28">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb30-29">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sanitized_img), </span>
<span id="cb30-30">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb30-31">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb30-32">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors,</span>
<span id="cb30-33">)</span>
<span id="cb30-34"></span>
<span id="cb30-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the annotated image</span></span>
<span id="cb30-36">display(tensor_to_pil(annotated_tensor))</span>
<span id="cb30-37"></span>
<span id="cb30-38">pd.Series({</span>
<span id="cb30-39">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image:"</span>: sample_img.size,</span>
<span id="cb30-40">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cropped Image:"</span>: cropped_img.size,</span>
<span id="cb30-41">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Image:"</span>: resized_img.size,</span>
<span id="cb30-42">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Padded Image:"</span>: padded_img.size,</span>
<span id="cb30-43">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Padded Image:"</span>: resized_padded_img.size,</span>
<span id="cb30-44">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/images/output_52_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_5be68">
<thead>
</thead>
<tbody>
<tr>
<th id="T_5be68_level0_row0" class="row_heading level0 row0">
Source Image:
</th>
<td id="T_5be68_row0_col0" class="data row0 col0">
(512, 768)
</td>
</tr>
<tr>
<th id="T_5be68_level0_row1" class="row_heading level0 row1">
Cropped Image:
</th>
<td id="T_5be68_row1_col0" class="data row1 col0">
(512, 768)
</td>
</tr>
<tr>
<th id="T_5be68_level0_row2" class="row_heading level0 row2">
Resized Image:
</th>
<td id="T_5be68_row2_col0" class="data row2 col0">
(341, 511)
</td>
</tr>
<tr>
<th id="T_5be68_level0_row3" class="row_heading level0 row3">
Padded Image:
</th>
<td id="T_5be68_row3_col0" class="data row3 col0">
(511, 511)
</td>
</tr>
<tr>
<th id="T_5be68_level0_row4" class="row_heading level0 row4">
Resized Padded Image:
</th>
<td id="T_5be68_row4_col0" class="data row4 col0">
(512, 512)
</td>
</tr>
</tbody>
</table>
</div>
<p>Now that we know how to apply data augmentations, we can put all the steps we’ve covered into a custom Dataset class.</p>
</section>
</section>
<section id="training-dataset-class" class="level3">
<h3 class="anchored" data-anchor-id="training-dataset-class">Training Dataset Class</h3>
<p>The following custom Dataset class is responsible for loading a single image, preparing the associated annotations, applying any image transforms, and returning the final <code>image</code> tensor and its <code>target</code> dictionary during training.</p>
<p>We will be applying the <code>SanitizeBoundingBoxes</code> transform here as well. This transform can remove key points if a previous transform moves them outside the image dimensions. The Keypoint R-CNN model still expects values for key points even when not visible, so we will fill the target annotations with dummy values as needed.</p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> LabelMeKeypointDataset(Dataset):</span>
<span id="cb31-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A PyTorch Dataset class for handling LabelMe image keypoints.</span></span>
<span id="cb31-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb31-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This class extends PyTorch's Dataset and is designed to work with image data and</span></span>
<span id="cb31-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    associated keypoints annotations. It supports loading images and corresponding</span></span>
<span id="cb31-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    keypoints annotations, and applying transformations.</span></span>
<span id="cb31-8"></span>
<span id="cb31-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Attributes:</span></span>
<span id="cb31-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        img_keys (list): List of image keys.</span></span>
<span id="cb31-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        annotation_df (DataFrame): DataFrame containing annotations for each image.</span></span>
<span id="cb31-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        img_dict (dict): Dictionary mapping image keys to their file paths.</span></span>
<span id="cb31-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        class_to_idx (dict): Dictionary mapping class names to class indices.</span></span>
<span id="cb31-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        transforms (callable, optional): Transformations to be applied to the images and targets.</span></span>
<span id="cb31-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb31-16"></span>
<span id="cb31-17">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, img_keys, annotation_df, img_dict, class_to_idx, transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb31-18">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Initializes the LabelMeKeypointDataset with image keys, annotations, and other relevant information.</span></span>
<span id="cb31-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb31-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb31-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_keys (list): List of image keys.</span></span>
<span id="cb31-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation_df (DataFrame): DataFrame containing annotations for each image.</span></span>
<span id="cb31-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_dict (dict): Dictionary mapping image keys to their file paths.</span></span>
<span id="cb31-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            class_to_idx (dict): Dictionary mapping class names to class indices.</span></span>
<span id="cb31-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            transforms (callable, optional): Transformations to be applied to the images and targets.</span></span>
<span id="cb31-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-28">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Dataset, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb31-29">        </span>
<span id="cb31-30">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys</span>
<span id="cb31-31">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df</span>
<span id="cb31-32">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_dict</span>
<span id="cb31-33">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> class_to_idx</span>
<span id="cb31-34">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms</span>
<span id="cb31-35">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sanitize_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torchvision.transforms.v2.SanitizeBoundingBoxes()</span>
<span id="cb31-36"></span>
<span id="cb31-37">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.BBOX_DIM <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb31-38">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.DUMMY_VALUE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb31-39"></span>
<span id="cb31-40">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__len__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb31-41">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns the number of items in the dataset.</span></span>
<span id="cb31-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb31-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb31-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            int: Number of items in the dataset.</span></span>
<span id="cb31-46"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-47">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys)</span>
<span id="cb31-48">        </span>
<span id="cb31-49">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, index):</span>
<span id="cb31-50">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-51"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Retrieves an item from the dataset at the specified index.</span></span>
<span id="cb31-52"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb31-53"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb31-54"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            index (int): Index of the item to retrieve.</span></span>
<span id="cb31-55"></span>
<span id="cb31-56"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb31-57"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and its corresponding target (annotations).</span></span>
<span id="cb31-58"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-59">        img_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys[index]</span>
<span id="cb31-60">        annotation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df.loc[img_key]</span>
<span id="cb31-61">        image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._load_image_and_target(annotation)</span>
<span id="cb31-62">        </span>
<span id="cb31-63">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Applying transformations if specified</span></span>
<span id="cb31-64">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms:</span>
<span id="cb31-65">            image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms(image, target)</span>
<span id="cb31-66"></span>
<span id="cb31-67">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fill any missing keypoints with dummy values</span></span>
<span id="cb31-68">        target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._fill_and_order_target(target)</span>
<span id="cb31-69">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, target</span>
<span id="cb31-70"></span>
<span id="cb31-71">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> order_points_by_labels(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, data, label_order):</span>
<span id="cb31-72">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-73"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Extracts and orders points from a list of dictionaries based on a given order of labels.</span></span>
<span id="cb31-74"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb31-75"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        :param data: List of dictionaries containing labels and points.</span></span>
<span id="cb31-76"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        :param label_order: List of labels in the desired order.</span></span>
<span id="cb31-77"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        :return: List of points in the specified label order.</span></span>
<span id="cb31-78"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-79">        ordered_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb31-80">        label_to_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {item[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>]: item[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> item <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> data}</span>
<span id="cb31-81">    </span>
<span id="cb31-82">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> label_order:</span>
<span id="cb31-83">            points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> label_to_points.get(label)</span>
<span id="cb31-84">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> points <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb31-85">                ordered_points.extend(points)</span>
<span id="cb31-86"></span>
<span id="cb31-87">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> ordered_points</span>
<span id="cb31-88"></span>
<span id="cb31-89">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _load_image_and_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, annotation):</span>
<span id="cb31-90">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-91"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Loads an image and its corresponding target (annotations) based on the provided annotation.</span></span>
<span id="cb31-92"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb31-93"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb31-94"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation (DataFrame row): Annotation data for a specific image.</span></span>
<span id="cb31-95"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            Returns:</span></span>
<span id="cb31-96"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tuple: A tuple containing the loaded image and its corresponding target data.</span></span>
<span id="cb31-97"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-98">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the image from the file path specified in the annotations</span></span>
<span id="cb31-99">        filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict[annotation.name]</span>
<span id="cb31-100">        image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(filepath).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb31-101"></span>
<span id="cb31-102">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extracting keypoints from the annotation and converting them to a tensor</span></span>
<span id="cb31-103">        keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.order_points_by_labels(annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx.keys())</span>
<span id="cb31-104">        keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(np.array(keypoints, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float32)).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb31-105">        </span>
<span id="cb31-106">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding an offset to create bounding boxes around keypoints</span></span>
<span id="cb31-107">        keypoints_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((keypoints, torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(keypoints), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.BBOX_DIM), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb31-108">                </span>
<span id="cb31-109">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert bounding box format and create a BoundingBoxes object</span></span>
<span id="cb31-110">        bbox_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torchvision.ops.box_convert(keypoints_bboxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>)</span>
<span id="cb31-111">        boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(bbox_tensor, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb31-112">        </span>
<span id="cb31-113">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create tensor for labels based on the class indices</span></span>
<span id="cb31-114">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.Tensor([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx[label] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx.keys()])</span>
<span id="cb31-115">        </span>
<span id="cb31-116">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: boxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: labels}</span>
<span id="cb31-117"></span>
<span id="cb31-118">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _fill_and_order_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, target):</span>
<span id="cb31-119">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-120"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Fills and orders the target bounding boxes and labels based on the class index.</span></span>
<span id="cb31-121"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb31-122"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        This method ensures that each target has a bounding box and label for each class,</span></span>
<span id="cb31-123"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        even if some classes are not present in the original target. Missing classes</span></span>
<span id="cb31-124"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        are filled with dummy values.</span></span>
<span id="cb31-125"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb31-126"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb31-127"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            target (dict): A dictionary containing 'boxes' and 'labels' keys, where</span></span>
<span id="cb31-128"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                           'boxes' is a tensor of bounding boxes and 'labels' is a tensor</span></span>
<span id="cb31-129"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                           of labels corresponding to these boxes.</span></span>
<span id="cb31-130"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb31-131"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb31-132"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            dict: The updated target dictionary with boxes and labels ordered and filled</span></span>
<span id="cb31-133"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                  according to the class index.</span></span>
<span id="cb31-134"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-135">    </span>
<span id="cb31-136">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize new boxes with dummy values for each class</span></span>
<span id="cb31-137">        new_boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.full((<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>), <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.DUMMY_VALUE)</span>
<span id="cb31-138">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare labels tensor based on the class indices</span></span>
<span id="cb31-139">        new_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx.values()), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb31-140">    </span>
<span id="cb31-141">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate over each class label</span></span>
<span id="cb31-142">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(new_labels):</span>
<span id="cb31-143">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check if the current label exists in the target's labels</span></span>
<span id="cb31-144">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]:</span>
<span id="cb31-145">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Find the index of the current label in the target's labels</span></span>
<span id="cb31-146">                idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> label).nonzero(as_tuple<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb31-147">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assign the corresponding box to the new boxes tensor</span></span>
<span id="cb31-148">                new_boxes[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>][idx]</span>
<span id="cb31-149">    </span>
<span id="cb31-150">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the target dictionary with the new boxes and labels</span></span>
<span id="cb31-151">        target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_boxes</span>
<span id="cb31-152">        target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_labels</span>
<span id="cb31-153">    </span>
<span id="cb31-154">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> target</span></code></pre></div>
</section>
<section id="image-transforms" class="level3">
<h3 class="anchored" data-anchor-id="image-transforms">Image Transforms</h3>
<p>Here, we will specify and organize all the image transforms to apply during training.</p>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms for data augmentation</span></span>
<span id="cb32-2">data_aug_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose(</span>
<span id="cb32-3">    transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb32-4">        transforms.ColorJitter(</span>
<span id="cb32-5">                brightness <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.125</span>),</span>
<span id="cb32-6">                contrast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb32-7">                saturation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb32-8">                hue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>),</span>
<span id="cb32-9">        ),</span>
<span id="cb32-10">        transforms.RandomGrayscale(),</span>
<span id="cb32-11">        transforms.RandomEqualize(),</span>
<span id="cb32-12">        RandomPixelCopy(max_pct<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.025</span>),</span>
<span id="cb32-13">        transforms.RandomPerspective(distortion_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.15</span>, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">117</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">104</span>)),</span>
<span id="cb32-14">        transforms.RandomRotation(degrees<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">90</span>, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">117</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">104</span>)),</span>
<span id="cb32-15">        iou_crop,</span>
<span id="cb32-16">    ],</span>
<span id="cb32-17">)</span>
<span id="cb32-18"></span>
<span id="cb32-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to resize and pad input images</span></span>
<span id="cb32-20">resize_pad_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb32-21">    resize_max, </span>
<span id="cb32-22">    pad_square,</span>
<span id="cb32-23">    transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb32-24">])</span>
<span id="cb32-25"></span>
<span id="cb32-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to sanitize bounding boxes and normalize input data</span></span>
<span id="cb32-27">final_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb32-28">    transforms.ToImage(), </span>
<span id="cb32-29">    transforms.ToDtype(torch.float32, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb32-30">    transforms.SanitizeBoundingBoxes(),</span>
<span id="cb32-31">])</span>
<span id="cb32-32"></span>
<span id="cb32-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the transformations for training and validation datasets</span></span>
<span id="cb32-34">train_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb32-35">    data_aug_tfms, </span>
<span id="cb32-36">    resize_pad_tfm, </span>
<span id="cb32-37">    final_tfms</span>
<span id="cb32-38">])</span>
<span id="cb32-39">valid_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([resize_pad_tfm, final_tfms])</span></code></pre></div>
</section>
<section id="initialize-datasets" class="level3">
<h3 class="anchored" data-anchor-id="initialize-datasets">Initialize Datasets</h3>
<p>Now, we can create the dataset objects for the training and validation sets using the image dictionary, the annotation DataFrame, and the image transforms.</p>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mapping from class names to class indices</span></span>
<span id="cb33-2">class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {c: i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(class_names)}</span>
<span id="cb33-3"></span>
<span id="cb33-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Instantiate the dataset using the defined transformations</span></span>
<span id="cb33-5">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LabelMeKeypointDataset(train_keys, annotation_df, img_dict, class_to_idx, train_tfms)</span>
<span id="cb33-6">valid_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LabelMeKeypointDataset(val_keys, annotation_df, img_dict, class_to_idx, valid_tfms)</span>
<span id="cb33-7"></span>
<span id="cb33-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of samples in the training and validation datasets</span></span>
<span id="cb33-9">pd.Series({</span>
<span id="cb33-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training dataset size:'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataset),</span>
<span id="cb33-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Validation dataset size:'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(valid_dataset)}</span>
<span id="cb33-12">).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_408f0">
<thead>
</thead>
<tbody>
<tr>
<th id="T_408f0_level0_row0" class="row_heading level0 row0">
Training dataset size:
</th>
<td id="T_408f0_row0_col0" class="data row0 col0">
180
</td>
</tr>
<tr>
<th id="T_408f0_level0_row1" class="row_heading level0 row1">
Validation dataset size:
</th>
<td id="T_408f0_row1_col0" class="data row1 col0">
20
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspect-samples" class="level3">
<h3 class="anchored" data-anchor-id="inspect-samples">Inspect Samples</h3>
<p>Let’s verify the dataset objects work correctly by inspecting the first samples from the training and validation sets.</p>
<section id="inspect-training-set-sample" class="level4">
<h4 class="anchored" data-anchor-id="inspect-training-set-sample">Inspect training set sample</h4>
<p>Since our custom dataset fills missing annotations with dummy values, we will pass the target dictionary through the <code>SanitizeBoundingBoxes</code> function again.</p>
<div class="sourceCode" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a sample image and its target annotations</span></span>
<span id="cb34-2">dataset_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_dataset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb34-3"></span>
<span id="cb34-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sanitize bounding boxes to remove dummy values</span></span>
<span id="cb34-5">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb34-6">targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:])</span>
<span id="cb34-7">sanitized_image, sanitized_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], targets)</span>
<span id="cb34-8"></span>
<span id="cb34-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with the sanitized annotations</span></span>
<span id="cb34-10">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb34-11">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(sanitized_image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.uint8), </span>
<span id="cb34-12">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb34-13">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb34-14">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb34-15">)</span>
<span id="cb34-16"></span>
<span id="cb34-17">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/images/output_62_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="inspect-validation-set-sample" class="level4">
<h4 class="anchored" data-anchor-id="inspect-validation-set-sample">Inspect validation set sample</h4>
<div class="sourceCode" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">dataset_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> valid_dataset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb35-2"></span>
<span id="cb35-3">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb35-4">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.uint8), </span>
<span id="cb35-5">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb35-6">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb35-7">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb35-8">)</span>
<span id="cb35-9"></span>
<span id="cb35-10">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/images/output_64_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
<section id="initialize-dataloaders" class="level3">
<h3 class="anchored" data-anchor-id="initialize-dataloaders">Initialize DataLoaders</h3>
<p>The last step before training is to instantiate the DataLoaders for the training and validation sets. Try decreasing the batch size if you encounter memory limitations.</p>
<div class="sourceCode" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the training batch size</span></span>
<span id="cb36-2">bs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb36-3"></span>
<span id="cb36-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the number of worker processes for loading data. This should be the number of CPUs available.</span></span>
<span id="cb36-5">num_workers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> multiprocessing.cpu_count()</span>
<span id="cb36-6"></span>
<span id="cb36-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define parameters for DataLoader</span></span>
<span id="cb36-8">data_loader_params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb36-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'batch_size'</span>: bs,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Batch size for data loading</span></span>
<span id="cb36-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num_workers'</span>: num_workers,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of subprocesses to use for data loading</span></span>
<span id="cb36-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'persistent_workers'</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If True, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the worker dataset instances alive.</span></span>
<span id="cb36-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pin_memory'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> device,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If True, the data loader will copy Tensors into CUDA pinned memory before returning them. Useful when using GPU.</span></span>
<span id="cb36-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pin_memory_device'</span>: device <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> device <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Specifies the device where the data should be loaded. Commonly set to use the GPU.</span></span>
<span id="cb36-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'collate_fn'</span>: <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> batch: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>batch)),</span>
<span id="cb36-15">}</span>
<span id="cb36-16"></span>
<span id="cb36-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create DataLoader for training data. Data is shuffled for every epoch.</span></span>
<span id="cb36-18">train_dataloader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(train_dataset, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>data_loader_params, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb36-19"></span>
<span id="cb36-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create DataLoader for validation data. Shuffling is not necessary for validation data.</span></span>
<span id="cb36-21">valid_dataloader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(valid_dataset, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>data_loader_params)</span>
<span id="cb36-22"></span>
<span id="cb36-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of batches in the training and validation DataLoaders</span></span>
<span id="cb36-24"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Number of batches in train DataLoader: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataloader)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb36-25"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Number of batches in validation DataLoader: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(valid_dataloader)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<pre><code>Number of batches in train DataLoader: 45
Number of batches in validation DataLoader: 5</code></pre>
</section>
</section>
<section id="fine-tuning-the-model" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuning-the-model">Fine-tuning the Model</h2>
<p>In this section, we will implement the training code and fine-tune our model.</p>
<section id="define-utility-functions" class="level3">
<h3 class="anchored" data-anchor-id="define-utility-functions">Define Utility Functions</h3>
<p>First, we need to define a couple of utility functions.</p>
<section id="define-a-function-to-create-a-bounding-box-that-encapsulates-the-key-points" class="level4">
<h4 class="anchored" data-anchor-id="define-a-function-to-create-a-bounding-box-that-encapsulates-the-key-points">Define a function to create a bounding box that encapsulates the key points</h4>
<p>The Keypoint R-CNN model expects a bounding box encapsulating the points associated with a given person/object. We could include these bounding box annotations in our dataset (e.g., have bounding boxes around each face). However, dynamically making one large enough to contain the key points will suffice.</p>
<div class="sourceCode" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> keypoints_to_bbox(keypoints, offset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>):</span>
<span id="cb38-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb38-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Convert a tensor of keypoint coordinates to a bounding box.</span></span>
<span id="cb38-4"></span>
<span id="cb38-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb38-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    keypoints (Tensor): A tensor of shape (N, 2), where N is the number of keypoints.</span></span>
<span id="cb38-7"></span>
<span id="cb38-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb38-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Tensor: A tensor representing the bounding box [xmin, ymin, xmax, ymax].</span></span>
<span id="cb38-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb38-11">    x_coordinates, y_coordinates <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> keypoints[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], keypoints[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb38-12"></span>
<span id="cb38-13">    xmin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(x_coordinates)</span>
<span id="cb38-14">    ymin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(y_coordinates)</span>
<span id="cb38-15">    xmax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(x_coordinates)</span>
<span id="cb38-16">    ymax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(y_coordinates)</span>
<span id="cb38-17"></span>
<span id="cb38-18">    bbox <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([xmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>offset, ymin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>offset, xmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>offset, ymax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>offset])</span>
<span id="cb38-19"></span>
<span id="cb38-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> bbox</span></code></pre></div>
</section>
<section id="define-a-conditional-autocast-context-manager" class="level4">
<h4 class="anchored" data-anchor-id="define-a-conditional-autocast-context-manager">Define a conditional <code>autocast</code> context manager</h4>
<p>The autocast context manager that handles mixed-precision training on CPUs does not fully support the Keypoint R-CNN model. Therefore, we will only use mixed-precision training when not using the CPU.</p>
<div class="sourceCode" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@contextmanager</span></span>
<span id="cb39-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> conditional_autocast(device):</span>
<span id="cb39-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb39-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A context manager for conditional automatic mixed precision (AMP).</span></span>
<span id="cb39-5"></span>
<span id="cb39-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This context manager applies automatic mixed precision for operations if the</span></span>
<span id="cb39-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    specified device is not a CPU. It's a no-op (does nothing) if the device is a CPU.</span></span>
<span id="cb39-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Mixed precision can speed up computations and reduce memory usage on compatible</span></span>
<span id="cb39-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    hardware, primarily GPUs.</span></span>
<span id="cb39-10"></span>
<span id="cb39-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parameters:</span></span>
<span id="cb39-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    device (str): The device type, e.g., 'cuda' or 'cpu', which determines whether</span></span>
<span id="cb39-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                  autocasting is applied.</span></span>
<span id="cb39-14"></span>
<span id="cb39-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Yields:</span></span>
<span id="cb39-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    None - This function does not return any value but enables the wrapped code</span></span>
<span id="cb39-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">           block to execute under the specified precision context.</span></span>
<span id="cb39-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb39-19"></span>
<span id="cb39-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check if the specified device is not a CPU</span></span>
<span id="cb39-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> device:</span>
<span id="cb39-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If the device is not a CPU, enable autocast for the specified device type.</span></span>
<span id="cb39-23">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Autocast will automatically choose the precision (e.g., float16) for certain</span></span>
<span id="cb39-24">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># operations to improve performance.</span></span>
<span id="cb39-25">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> autocast(device_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device):</span>
<span id="cb39-26">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">yield</span></span>
<span id="cb39-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb39-28">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If the device is a CPU, autocast is not applied.</span></span>
<span id="cb39-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This yields control back to the with-block with no changes.</span></span>
<span id="cb39-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">yield</span></span></code></pre></div>
</section>
</section>
<section id="define-the-training-loop" class="level3">
<h3 class="anchored" data-anchor-id="define-the-training-loop">Define the Training Loop</h3>
<p>The following function performs a single pass through the training or validation set.</p>
<p>As mentioned earlier, the Keypoint R-CNN model expects values for key points even when not visible. We indicate which key points are visible, with a <code>1</code> for visible and a <code>0</code> for not.</p>
<p>The model has different behavior when in <code>training</code> mode versus <code>evaluation</code> mode. In training mode, it calculates the loss internally for the key point estimation task and returns a dictionary with the individual loss values. We can sum up these separate values to get the total loss.</p>
<div class="sourceCode" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to run a single training/validation epoch</span></span>
<span id="cb40-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> run_epoch(model, dataloader, optimizer, lr_scheduler, device, scaler, epoch_id, is_training):</span>
<span id="cb40-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb40-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Function to run a single training or evaluation epoch.</span></span>
<span id="cb40-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb40-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb40-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        model: A PyTorch model to train or evaluate.</span></span>
<span id="cb40-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        dataloader: A PyTorch DataLoader providing the data.</span></span>
<span id="cb40-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        optimizer: The optimizer to use for training the model.</span></span>
<span id="cb40-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        loss_func: The loss function used for training.</span></span>
<span id="cb40-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        device: The device (CPU or GPU) to run the model on.</span></span>
<span id="cb40-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        scaler: Gradient scaler for mixed-precision training.</span></span>
<span id="cb40-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        is_training: Boolean flag indicating whether the model is in training or evaluation mode.</span></span>
<span id="cb40-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb40-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb40-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The average loss for the epoch.</span></span>
<span id="cb40-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb40-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set model to training mode</span></span>
<span id="cb40-19">    model.train()</span>
<span id="cb40-20">    </span>
<span id="cb40-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the average loss for the current epoch </span></span>
<span id="cb40-22">    epoch_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb40-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize progress bar with total number of batches in the dataloader</span></span>
<span id="cb40-24">    progress_bar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tqdm(total<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(dataloader), desc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Train"</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> is_training <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Eval"</span>)</span>
<span id="cb40-25">    </span>
<span id="cb40-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate over data batches</span></span>
<span id="cb40-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> batch_id, (inputs, targets) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(dataloader):</span>
<span id="cb40-28">        </span>
<span id="cb40-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Move inputs and targets to the specified device</span></span>
<span id="cb40-30">        inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.stack(inputs).to(device)</span>
<span id="cb40-31">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the ground truth bounding boxes and labels</span></span>
<span id="cb40-32">        gt_bboxes, gt_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>[(d[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>].to(device), d[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>].to(device)) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> targets])</span>
<span id="cb40-33">        </span>
<span id="cb40-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert ground truth bounding boxes from 'xyxy' to 'cxcywh' format and only keep center coordinates</span></span>
<span id="cb40-35">        gt_keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torchvision.ops.box_convert(torch.stack(gt_bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>)[:,:,:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb40-36">        </span>
<span id="cb40-37">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize a visibility tensor with ones, indicating all keypoints are visible</span></span>
<span id="cb40-38">        visibility <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(inputs),gt_keypoints.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).to(device)</span>
<span id="cb40-39">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a visibility mask based on whether the bounding boxes are valid (greater than or equal to 0)</span></span>
<span id="cb40-40">        visibility_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (torch.stack(gt_bboxes) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>)[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].view(visibility.shape).to(device)</span>
<span id="cb40-41">        </span>
<span id="cb40-42">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Concatenate the keypoints with the visibility mask, adding a visibility channel to keypoints</span></span>
<span id="cb40-43">        gt_keypoints_with_visibility <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.concat((</span>
<span id="cb40-44">            gt_keypoints, </span>
<span id="cb40-45">            visibility<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>visibility_mask</span>
<span id="cb40-46">        ), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb40-47">        </span>
<span id="cb40-48">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert keypoints to bounding boxes for each input and move them to the specified device</span></span>
<span id="cb40-49">        gt_shelf_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.vstack([keypoints_to_bbox(keypoints) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> keypoints <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> gt_keypoints]).to(device)</span>
<span id="cb40-50">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize ground truth labels as tensor of ones and move them to the specified device</span></span>
<span id="cb40-51">        gt_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(inputs), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.int64).to(device)</span>
<span id="cb40-52">        </span>
<span id="cb40-53">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare the targets for the Keypoint R-CNN model</span></span>
<span id="cb40-54">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This includes bounding boxes, labels, and keypoints with visibility for each input image</span></span>
<span id="cb40-55">        keypoint_rcnn_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb40-56">            {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span> : boxes[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: labels[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'keypoints'</span>: keypoints[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]}</span>
<span id="cb40-57">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> boxes, labels, keypoints <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(gt_shelf_bboxes, gt_labels, gt_keypoints_with_visibility)</span>
<span id="cb40-58">        ]</span>
<span id="cb40-59"></span>
<span id="cb40-60">        </span>
<span id="cb40-61">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Forward pass with Automatic Mixed Precision (AMP) context manager</span></span>
<span id="cb40-62">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> conditional_autocast(torch.device(device).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>):</span>
<span id="cb40-63">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> is_training:</span>
<span id="cb40-64">                losses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model(inputs.to(device), move_data_to_device(keypoint_rcnn_targets, device))</span>
<span id="cb40-65">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb40-66">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb40-67">                    losses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model(inputs.to(device), move_data_to_device(keypoint_rcnn_targets, device))</span>
<span id="cb40-68">        </span>
<span id="cb40-69">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the loss</span></span>
<span id="cb40-70">            loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>([loss <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> loss <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> losses.values()])  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sum up the losses</span></span>
<span id="cb40-71">                </span>
<span id="cb40-72">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If in training mode</span></span>
<span id="cb40-73">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> is_training:</span>
<span id="cb40-74">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> scaler:</span>
<span id="cb40-75">                scaler.scale(loss).backward()</span>
<span id="cb40-76">                scaler.step(optimizer)</span>
<span id="cb40-77">                old_scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.get_scale()</span>
<span id="cb40-78">                scaler.update()</span>
<span id="cb40-79">                new_scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.get_scale()</span>
<span id="cb40-80">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> new_scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> old_scaler:</span>
<span id="cb40-81">                    lr_scheduler.step()</span>
<span id="cb40-82">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb40-83">                loss.backward()</span>
<span id="cb40-84">                optimizer.step()</span>
<span id="cb40-85">                lr_scheduler.step()</span>
<span id="cb40-86">                </span>
<span id="cb40-87">            optimizer.zero_grad()</span>
<span id="cb40-88">        </span>
<span id="cb40-89">        loss_item <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> loss.item()</span>
<span id="cb40-90">        epoch_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> loss_item</span>
<span id="cb40-91">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update progress bar</span></span>
<span id="cb40-92">        progress_bar.set_postfix(loss<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>loss_item, </span>
<span id="cb40-93">                                 avg_loss<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>epoch_loss<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(batch_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), </span>
<span id="cb40-94">                                 lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lr_scheduler.get_last_lr()[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> is_training <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>)</span>
<span id="cb40-95">        progress_bar.update()</span>
<span id="cb40-96">        </span>
<span id="cb40-97">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If loss is NaN or infinity, stop training</span></span>
<span id="cb40-98">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> is_training:</span>
<span id="cb40-99">            stop_training_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Loss is NaN or infinite at epoch </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>epoch_id<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, batch </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>batch_id<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">. Stopping training."</span></span>
<span id="cb40-100">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> math.isnan(loss_item) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> math.isfinite(loss_item), stop_training_message</span>
<span id="cb40-101">        </span>
<span id="cb40-102">    progress_bar.close()</span>
<span id="cb40-103">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> epoch_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (batch_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<p>Next, we define the <code>train_loop</code> function, which executes the main training loop. It iterates over each epoch, runs through the training and validation sets, and saves the best model based on the validation loss.</p>
<div class="sourceCode" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> train_loop(model, </span>
<span id="cb41-2">               train_dataloader, </span>
<span id="cb41-3">               valid_dataloader, </span>
<span id="cb41-4">               optimizer,  </span>
<span id="cb41-5">               lr_scheduler, </span>
<span id="cb41-6">               device, </span>
<span id="cb41-7">               epochs, </span>
<span id="cb41-8">               checkpoint_path, </span>
<span id="cb41-9">               use_scaler<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb41-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb41-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Main training loop.</span></span>
<span id="cb41-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb41-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb41-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        model: A PyTorch model to train.</span></span>
<span id="cb41-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        train_dataloader: A PyTorch DataLoader providing the training data.</span></span>
<span id="cb41-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        valid_dataloader: A PyTorch DataLoader providing the validation data.</span></span>
<span id="cb41-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        optimizer: The optimizer to use for training the model.</span></span>
<span id="cb41-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        lr_scheduler: The learning rate scheduler.</span></span>
<span id="cb41-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        device: The device (CPU or GPU) to run the model on.</span></span>
<span id="cb41-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        epochs: The number of epochs to train for.</span></span>
<span id="cb41-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        checkpoint_path: The path where to save the best model checkpoint.</span></span>
<span id="cb41-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        use_scaler: Whether to scale graidents when using a CUDA device</span></span>
<span id="cb41-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb41-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb41-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        None</span></span>
<span id="cb41-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb41-27">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize a gradient scaler for mixed-precision training if the device is a CUDA GPU</span></span>
<span id="cb41-28">    scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cuda.amp.GradScaler() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> device.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> use_scaler <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb41-29">    best_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'inf'</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the best validation loss</span></span>
<span id="cb41-30"></span>
<span id="cb41-31">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Loop over the epochs</span></span>
<span id="cb41-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(epochs), desc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Epochs"</span>):</span>
<span id="cb41-33">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run a training epoch and get the training loss</span></span>
<span id="cb41-34">        train_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> run_epoch(model, train_dataloader, optimizer, lr_scheduler, device, scaler, epoch, is_training<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb41-35">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run an evaluation epoch and get the validation loss</span></span>
<span id="cb41-36">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb41-37">            valid_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> run_epoch(model, valid_dataloader, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, device, scaler, epoch, is_training<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb41-38"></span>
<span id="cb41-39">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If the validation loss is lower than the best validation loss seen so far, save the model checkpoint</span></span>
<span id="cb41-40">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> valid_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> best_loss:</span>
<span id="cb41-41">            best_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> valid_loss</span>
<span id="cb41-42">            torch.save(model.state_dict(), checkpoint_path)</span>
<span id="cb41-43"></span>
<span id="cb41-44">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save metadata about the training process</span></span>
<span id="cb41-45">            training_metadata <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb41-46">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'epoch'</span>: epoch,</span>
<span id="cb41-47">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'train_loss'</span>: train_loss,</span>
<span id="cb41-48">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'valid_loss'</span>: valid_loss, </span>
<span id="cb41-49">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>: lr_scheduler.get_last_lr()[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb41-50">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'model_architecture'</span>: model.name</span>
<span id="cb41-51">            }</span>
<span id="cb41-52">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(Path(checkpoint_path.parent<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'training_metadata.json'</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'w'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb41-53">                json.dump(training_metadata, f)</span>
<span id="cb41-54"></span>
<span id="cb41-55">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If the device is a GPU, empty the cache</span></span>
<span id="cb41-56">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> device.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>:</span>
<span id="cb41-57">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(torch, device.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>).empty_cache()</span></code></pre></div>
</section>
<section id="set-the-model-checkpoint-path" class="level3">
<h3 class="anchored" data-anchor-id="set-the-model-checkpoint-path">Set the Model Checkpoint Path</h3>
<p>Before we proceed with training, let’s generate a timestamp for the training session and create a directory to save the checkpoints during training.</p>
<div class="sourceCode" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate timestamp for the training session (Year-Month-Day_Hour_Minute_Second)</span></span>
<span id="cb42-2">timestamp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> datetime.datetime.now().strftime(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%Y-%m-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%d</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">_%H-%M-%S"</span>)</span>
<span id="cb42-3"></span>
<span id="cb42-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a directory to store the checkpoints if it does not already exist</span></span>
<span id="cb42-5">checkpoint_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(project_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>timestamp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb42-6"></span>
<span id="cb42-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the checkpoint directory if it does not already exist</span></span>
<span id="cb42-8">checkpoint_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb42-9"></span>
<span id="cb42-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The model checkpoint path</span></span>
<span id="cb42-11">checkpoint_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pth"</span></span>
<span id="cb42-12"></span>
<span id="cb42-13"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(checkpoint_path)</span></code></pre></div>
<pre><code>pytorch-keypoint-r-cnn/2024-01-28_17-07-09/keypointrcnn_resnet50_fpn.pth</code></pre>
<p>Let’s also save a copy of the colormap for the current dataset in the training folder for future use.</p>
</section>
<section id="save-the-color-map" class="level3">
<h3 class="anchored" data-anchor-id="save-the-color-map">Save the Color Map</h3>
<div class="sourceCode" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a color map and write it to a JSON file</span></span>
<span id="cb44-2">color_map <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'items'</span>: [{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>: label, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'color'</span>: color} <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label, color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(class_names, colors)]}</span>
<span id="cb44-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>checkpoint_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_path<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-colormap.json"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"w"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>:</span>
<span id="cb44-4">    json.dump(color_map, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>)</span>
<span id="cb44-5"></span>
<span id="cb44-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the name of the file that the color map was written to</span></span>
<span id="cb44-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>checkpoint_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_path<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-colormap.json"</span>)</span></code></pre></div>
<pre><code>pytorch-keypoint-r-cnn/2024-01-28_17-07-09/labelme-keypoint-eyes-noses-dataset-colormap.json</code></pre>
</section>
<section id="configure-the-training-parameters" class="level3">
<h3 class="anchored" data-anchor-id="configure-the-training-parameters">Configure the Training Parameters</h3>
<p>Now, we can configure the parameters for training. We must specify the learning rate and number of training epochs. We will also instantiate the optimizer and learning rate scheduler.</p>
<div class="sourceCode" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Learning rate for the model</span></span>
<span id="cb46-2">lr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5e-4</span></span>
<span id="cb46-3"></span>
<span id="cb46-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of training epochs</span></span>
<span id="cb46-5">epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span></span>
<span id="cb46-6"></span>
<span id="cb46-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># AdamW optimizer; includes weight decay for regularization</span></span>
<span id="cb46-8">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lr)</span>
<span id="cb46-9"></span>
<span id="cb46-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Learning rate scheduler; adjusts the learning rate during training</span></span>
<span id="cb46-11">lr_scheduler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.lr_scheduler.OneCycleLR(optimizer, </span>
<span id="cb46-12">                                                   max_lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lr, </span>
<span id="cb46-13">                                                   total_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>epochs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataloader))</span></code></pre></div>
</section>
<section id="train-the-model" class="level3">
<h3 class="anchored" data-anchor-id="train-the-model">Train the Model</h3>
<p>Finally, we can train the model using the <code>train_loop</code> function. Training time will depend on the available hardware.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Training usually takes around 30 minutes on the free GPU tier of Google Colab.</p>
</div>
</div>
<div class="sourceCode" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">train_loop(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model, </span>
<span id="cb47-2">           train_dataloader<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_dataloader,</span>
<span id="cb47-3">           valid_dataloader<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>valid_dataloader,</span>
<span id="cb47-4">           optimizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>optimizer, </span>
<span id="cb47-5">           lr_scheduler<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lr_scheduler, </span>
<span id="cb47-6">           device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.device(device), </span>
<span id="cb47-7">           epochs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>epochs, </span>
<span id="cb47-8">           checkpoint_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>checkpoint_path,</span>
<span id="cb47-9">           use_scaler<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
<div class="callout callout-style-default callout-note callout-titled" title="Training Progress">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Training Progress
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<pre class="text"><code>Epochs: 100% |██████████| 70/70 [07:29&lt;00:00, 6.55s/it]
Train: 100% |██████████| 45/45 [00:07&lt;00:00, 8.58it/s, avg_loss=6.95, loss=6.07, lr=2.27e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 8.31it/s, avg_loss=5.17, loss=5.31, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.50it/s, avg_loss=5.42, loss=4.87, lr=3.07e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.40it/s, avg_loss=4.3, loss=4.14, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 7.09it/s, avg_loss=4.85, loss=4.88, lr=4.38e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.72it/s, avg_loss=4.54, loss=4.73, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.12it/s, avg_loss=4.55, loss=4.27, lr=6.18e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 13.73it/s, avg_loss=4.16, loss=3.78, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.77it/s, avg_loss=4.37, loss=4.64, lr=8.42e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.63it/s, avg_loss=3.79, loss=3.36, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.46it/s, avg_loss=4.53, loss=6.24, lr=0.000111]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.26it/s, avg_loss=3.81, loss=3.25, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.30it/s, avg_loss=4.39, loss=4.33, lr=0.00014]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.50it/s, avg_loss=3.93, loss=3.63, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.64it/s, avg_loss=4.2, loss=4.98, lr=0.000173]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.93it/s, avg_loss=3.85, loss=3.1, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.43it/s, avg_loss=4.37, loss=4.64, lr=0.000207]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.57it/s, avg_loss=4.49, loss=4.54, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.54it/s, avg_loss=4.26, loss=3.53, lr=0.000242]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.36it/s, avg_loss=4.11, loss=4.03, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.48it/s, avg_loss=4.38, loss=4.53, lr=0.000278]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.60it/s, avg_loss=4.34, loss=3.82, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.51it/s, avg_loss=4.58, loss=4.45, lr=0.000314]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.03it/s, avg_loss=4.42, loss=4.41, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.58it/s, avg_loss=4.47, loss=3.38, lr=0.000348]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.05it/s, avg_loss=4.24, loss=3.27, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.53it/s, avg_loss=4.44, loss=5.01, lr=0.00038]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.75it/s, avg_loss=4.22, loss=4.14, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.58it/s, avg_loss=4.54, loss=4.36, lr=0.00041]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.24it/s, avg_loss=4.02, loss=3.7, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.83it/s, avg_loss=4.55, loss=3.89, lr=0.000436]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.35it/s, avg_loss=4.04, loss=3.33, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.58it/s, avg_loss=4.57, loss=4.49, lr=0.000459]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.79it/s, avg_loss=4.68, loss=4.85, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.84it/s, avg_loss=4.57, loss=4.47, lr=0.000477]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.73it/s, avg_loss=3.98, loss=3.36, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.83it/s, avg_loss=4.4, loss=4.59, lr=0.00049]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.27it/s, avg_loss=4.11, loss=3.59, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.76it/s, avg_loss=4.59, loss=4.98, lr=0.000497]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.49it/s, avg_loss=3.98, loss=3.41, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.85it/s, avg_loss=4.35, loss=4.5, lr=0.0005]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.15it/s, avg_loss=4, loss=3.34, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.05it/s, avg_loss=4.6, loss=5.02, lr=0.000499]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 13.54it/s, avg_loss=4.14, loss=3.99, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.92it/s, avg_loss=4.5, loss=3.75, lr=0.000498]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.00it/s, avg_loss=4.38, loss=4.55, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.39it/s, avg_loss=4.25, loss=3.95, lr=0.000495]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.46it/s, avg_loss=3.72, loss=3.16, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.55it/s, avg_loss=4.26, loss=5.19, lr=0.000492]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.02it/s, avg_loss=4.54, loss=4.14, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.46it/s, avg_loss=4.15, loss=3.68, lr=0.000487]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.73it/s, avg_loss=3.94, loss=3.61, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.77it/s, avg_loss=4.3, loss=3.22, lr=0.000482]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.81it/s, avg_loss=3.71, loss=3.57, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.42it/s, avg_loss=4.08, loss=3.55, lr=0.000475]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.04it/s, avg_loss=3.88, loss=3.6, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.42it/s, avg_loss=4.18, loss=3.19, lr=0.000468]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.78it/s, avg_loss=3.84, loss=3.7, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.52it/s, avg_loss=4.09, loss=3.7, lr=0.000459]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.19it/s, avg_loss=3.91, loss=3.65, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.16it/s, avg_loss=3.93, loss=4.28, lr=0.00045]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.02it/s, avg_loss=3.8, loss=3.52, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.15it/s, avg_loss=4.04, loss=3.38, lr=0.00044]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.09it/s, avg_loss=3.88, loss=4.04, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.36it/s, avg_loss=4.1, loss=3.53, lr=0.000429]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.44it/s, avg_loss=3.7, loss=2.95, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.62it/s, avg_loss=4.05, loss=4.06, lr=0.000418]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.18it/s, avg_loss=3.78, loss=3.28, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.20it/s, avg_loss=3.95, loss=3.53, lr=0.000406]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.48it/s, avg_loss=3.44, loss=3.38, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.27it/s, avg_loss=3.86, loss=2.82, lr=0.000393]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.31it/s, avg_loss=3.63, loss=3, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.35it/s, avg_loss=3.97, loss=3.48, lr=0.000379]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.21it/s, avg_loss=3.62, loss=3.22, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.46it/s, avg_loss=3.72, loss=3.94, lr=0.000365]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.22it/s, avg_loss=3.45, loss=2.83, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.30it/s, avg_loss=3.75, loss=3.34, lr=0.000351]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.41it/s, avg_loss=3.52, loss=3.38, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.63it/s, avg_loss=3.7, loss=4.19, lr=0.000336]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.00it/s, avg_loss=3.56, loss=2.9, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.47it/s, avg_loss=3.65, loss=4.22, lr=0.000321]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.94it/s, avg_loss=3.67, loss=3.11, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.50it/s, avg_loss=3.58, loss=4.13, lr=0.000305]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.86it/s, avg_loss=3.55, loss=2.98, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.55it/s, avg_loss=3.54, loss=3.29, lr=0.00029]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.17it/s, avg_loss=3.42, loss=2.62, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.25it/s, avg_loss=3.51, loss=3.97, lr=0.000274]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.54it/s, avg_loss=3.33, loss=2.68, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.39it/s, avg_loss=3.5, loss=2.83, lr=0.000258]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.36it/s, avg_loss=3.27, loss=2.94, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.22it/s, avg_loss=3.45, loss=4.09, lr=0.000242]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.64it/s, avg_loss=3.63, loss=3.29, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.37it/s, avg_loss=3.44, loss=2.97, lr=0.000226]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 13.97it/s, avg_loss=3.44, loss=2.87, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.26it/s, avg_loss=3.35, loss=2.87, lr=0.00021]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.52it/s, avg_loss=3.35, loss=2.94, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.29it/s, avg_loss=3.32, loss=3.1, lr=0.000194]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.92it/s, avg_loss=3.58, loss=3.28, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.67it/s, avg_loss=3.21, loss=3.25, lr=0.000179]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.04it/s, avg_loss=3.36, loss=2.86, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.12it/s, avg_loss=3.29, loss=2.95, lr=0.000163]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.03it/s, avg_loss=3.36, loss=2.87, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.07it/s, avg_loss=3.21, loss=3.99, lr=0.000148]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.45it/s, avg_loss=3.32, loss=2.96, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.23it/s, avg_loss=3.21, loss=2.92, lr=0.000134]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.38it/s, avg_loss=3.15, loss=2.81, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.05it/s, avg_loss=3.13, loss=2.58, lr=0.00012]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.48it/s, avg_loss=3.39, loss=2.86, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.27it/s, avg_loss=3.07, loss=2.13, lr=0.000107]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.16it/s, avg_loss=3.15, loss=2.68, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 7.66it/s, avg_loss=3.12, loss=3.1, lr=9.39e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.06it/s, avg_loss=3.27, loss=2.85, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 7.56it/s, avg_loss=3.02, loss=3.05, lr=8.17e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.53it/s, avg_loss=3.24, loss=2.74, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.42it/s, avg_loss=2.99, loss=2.36, lr=7.02e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.08it/s, avg_loss=3.1, loss=2.56, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.24it/s, avg_loss=2.93, loss=2.53, lr=5.94e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.33it/s, avg_loss=3.21, loss=2.85, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.11it/s, avg_loss=2.98, loss=2.77, lr=4.94e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.40it/s, avg_loss=3.31, loss=2.95, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.16it/s, avg_loss=3.04, loss=3.37, lr=4.03e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.74it/s, avg_loss=3.15, loss=2.93, lr=]
Train: 100% |██████████| 45/45 [00:05&lt;00:00, 8.33it/s, avg_loss=3, loss=3.06, lr=3.2e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.16it/s, avg_loss=3.1, loss=2.8, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.36it/s, avg_loss=2.92, loss=2.94, lr=2.46e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.99it/s, avg_loss=3.23, loss=2.85, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.45it/s, avg_loss=2.86, loss=2.2, lr=1.81e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 15.14it/s, avg_loss=3.06, loss=2.78, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.53it/s, avg_loss=2.94, loss=2.69, lr=1.26e-5]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.66it/s, avg_loss=3.07, loss=2.53, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.29it/s, avg_loss=2.86, loss=2.94, lr=8.09e-6]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.19it/s, avg_loss=3.04, loss=2.48, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.56it/s, avg_loss=2.79, loss=2.45, lr=4.54e-6]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 13.92it/s, avg_loss=3.15, loss=2.65, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 7.95it/s, avg_loss=2.87, loss=2.57, lr=2.01e-6]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.27it/s, avg_loss=3.02, loss=2.29, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.31it/s, avg_loss=2.93, loss=2.63, lr=4.93e-7]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.89it/s, avg_loss=2.96, loss=2.65, lr=]
Train: 100% |██████████| 45/45 [00:06&lt;00:00, 8.32it/s, avg_loss=2.87, loss=2.75, lr=2.25e-9]
Eval: 100% |██████████| 5/5 [00:00&lt;00:00, 14.32it/s, avg_loss=3.07, loss=2.65, lr=]</code></pre>
</div>
</div>
</div>
<p>At last, we have our fine-tuned Keypoint R-CNN model. To wrap up the tutorial, we can test our model by performing inference on individual images.</p>
</section>
</section>
<section id="making-predictions-with-the-model" class="level2">
<h2 class="anchored" data-anchor-id="making-predictions-with-the-model">Making Predictions with the Model</h2>
<p>In this final part of the tutorial, we will cover how to perform inference on individual images with our Mask R-CNN model and filter the predictions.</p>
<section id="prepare-input-data" class="level3">
<h3 class="anchored" data-anchor-id="prepare-input-data">Prepare Input Data</h3>
<p>Let’s use an image from the validation set. That way, we have some ground truth annotation data to compare against. Unlike during training, we won’t stick to square input dimensions for inference.</p>
<div class="sourceCode" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Choose a random item from the validation set</span></span>
<span id="cb49-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> val_keys[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb49-3"></span>
<span id="cb49-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Retrieve the image file path associated with the file ID</span></span>
<span id="cb49-5">test_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_dict[file_id]</span>
<span id="cb49-6"></span>
<span id="cb49-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the test file</span></span>
<span id="cb49-8">test_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(test_file).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb49-9"></span>
<span id="cb49-10">input_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_img(test_img, target_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_sz, divisor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb49-11"></span>
<span id="cb49-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the scale between the source image and the resized image</span></span>
<span id="cb49-13">min_img_scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(test_img.size) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(input_img.size)</span>
<span id="cb49-14"></span>
<span id="cb49-15">display(test_img)</span>
<span id="cb49-16"></span>
<span id="cb49-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the prediction data as a Pandas DataFrame for easy formatting</span></span>
<span id="cb49-18">pd.Series({</span>
<span id="cb49-19">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image Size:"</span>: test_img.size,</span>
<span id="cb49-20">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Input Dims:"</span>: input_img.size,</span>
<span id="cb49-21">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Min Image Scale:"</span>: min_img_scale,</span>
<span id="cb49-22">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Input Image Size:"</span>: input_img.size</span>
<span id="cb49-23">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/images/output_87_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_0ac3f">
<thead>
</thead>
<tbody>
<tr>
<th id="T_0ac3f_level0_row0" class="row_heading level0 row0">
Source Image Size:
</th>
<td id="T_0ac3f_row0_col0" class="data row0 col0">
(512, 768)
</td>
</tr>
<tr>
<th id="T_0ac3f_level0_row1" class="row_heading level0 row1">
Input Dims:
</th>
<td id="T_0ac3f_row1_col0" class="data row1 col0">
(512, 768)
</td>
</tr>
<tr>
<th id="T_0ac3f_level0_row2" class="row_heading level0 row2">
Min Image Scale:
</th>
<td id="T_0ac3f_row2_col0" class="data row2 col0">
1.000000
</td>
</tr>
<tr>
<th id="T_0ac3f_level0_row3" class="row_heading level0 row3">
Input Image Size:
</th>
<td id="T_0ac3f_row3_col0" class="data row3 col0">
(512, 768)
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-target-annotation-data" class="level3">
<h3 class="anchored" data-anchor-id="get-target-annotation-data">Get Target Annotation Data</h3>
<div class="sourceCode" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the source annotations for the test image</span></span>
<span id="cb50-2">gt_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb50-3">gt_keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(np.array([shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]])).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb50-4">gt_keypoints_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((gt_keypoints, torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gt_keypoints), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>BBOX_DIM), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
</section>
<section id="pass-input-data-to-the-model" class="level3">
<h3 class="anchored" data-anchor-id="pass-input-data-to-the-model">Pass Input Data to the Model</h3>
<p>Now, we can convert the test image to a tensor and pass it to the model. Ensure the model is set to evaluation mode to get predictions instead of loss values.</p>
<div class="sourceCode" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the model to evaluation mode</span></span>
<span id="cb51-2">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb51-3"></span>
<span id="cb51-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the model and input data are on the same device</span></span>
<span id="cb51-5">model.to(device)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb51-6">input_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([transforms.ToImage(), </span>
<span id="cb51-7">                                   transforms.ToDtype(torch.float32, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)])(input_img)[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>].to(device)</span>
<span id="cb51-8"></span>
<span id="cb51-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a prediction with the model</span></span>
<span id="cb51-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb51-11">    model_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model(input_tensor)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
</section>
<section id="filter-the-model-output" class="level3">
<h3 class="anchored" data-anchor-id="filter-the-model-output">Filter the Model Output</h3>
<p>The model performs most post-processing steps internally, so we only need to filter the output based on the desired confidence threshold. The model returns predictions as a list of dictionaries. Each dictionary stores bounding boxes, label indices, confidence scores, and key points for a single sample in the input batch.</p>
<p>Since we resized the test image, we must scale the key points to the source resolution.</p>
<div class="sourceCode" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the confidence threshold</span></span>
<span id="cb52-2">conf_threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span></span>
<span id="cb52-3"></span>
<span id="cb52-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Filter the output based on the confidence threshold</span></span>
<span id="cb52-5">scores_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_output[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'scores'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> conf_threshold</span>
<span id="cb52-6"></span>
<span id="cb52-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract and scale the predicted keypoints</span></span>
<span id="cb52-8">predicted_keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (model_output[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'keypoints'</span>][scores_mask])[:,:,:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>min_img_scale</span></code></pre></div>
</section>
<section id="compare-model-predictions-with-the-source-annotations" class="level3">
<h3 class="anchored" data-anchor-id="compare-model-predictions-with-the-source-annotations">Compare Model Predictions with the Source Annotations</h3>
<p>Finally, we can compare the model predictions with the ground-truth annotations.</p>
<div class="sourceCode" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the test image with the ground-truth annotations</span></span>
<span id="cb53-2">gt_annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb53-3">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(test_img), </span>
<span id="cb53-4">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torchvision.ops.box_convert(torch.Tensor(gt_keypoints_bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>),</span>
<span id="cb53-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># labels=gt_labels, </span></span>
<span id="cb53-6">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> gt_labels]]</span>
<span id="cb53-7">)</span>
<span id="cb53-8"></span>
<span id="cb53-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare the labels and bounding box annotations for the test image</span></span>
<span id="cb53-10">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> class_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(scores_mask).item()</span>
<span id="cb53-11">keypoints_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((predicted_keypoints.cpu(), torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(predicted_keypoints), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb53-12"></span>
<span id="cb53-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the test image with the model predictions</span></span>
<span id="cb53-14">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb53-15">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(test_img), </span>
<span id="cb53-16">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torchvision.ops.box_convert(torch.Tensor(keypoints_bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>), </span>
<span id="cb53-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># labels=labels, </span></span>
<span id="cb53-18">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb53-19">)</span>
<span id="cb53-20"></span>
<span id="cb53-21">stack_imgs([tensor_to_pil(gt_annotated_tensor), tensor_to_pil(annotated_tensor)])</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/images/output_95_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The model appears to have learned to detect eyes and noses as desired.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Congratulations on completing this tutorial for training Keypoint R-CNN models in PyTorch! The skills and knowledge you acquired here provide a solid foundation for future projects.</p>
<p>As a next step, perhaps try annotating a keypoint dataset with <a href="https://github.com/labelmeai/labelme">LabelMe</a> for your own Keypoint R-CNN model or experiment with the data augmentations to see how they impact model accuracy.</p>
</section>
<section id="recommended-tutorials" class="level2">
<h2 class="anchored" data-anchor-id="recommended-tutorials">Recommended Tutorials</h2>
<ul>
<li><a href="../../posts/pytorch-train-keypoint-rcnn-tutorial/onnx-export/"><strong>Exporting Keypoint R-CNN Models from PyTorch to ONNX</strong></a><strong>:</strong> Learn how to export Keypoint R-CNN models from PyTorch to ONNX and perform inference using ONNX Runtime.</li>
<li><a href="../../posts/pytorch-train-mask-rcnn-tutorial/"><strong>Training Mask R-CNN Models with PyTorch</strong></a><strong>:</strong> Learn how to train Mask R-CNN models on custom datasets with PyTorch.</li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>keypoint-rcnn</category>
  <category>keypoint-estimation</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/pytorch-train-keypoint-rcnn-tutorial/</guid>
  <pubDate>Mon, 29 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>How to Create Custom Torchvision V2 Transforms</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/torchvision-custom-v2-transform-tutorial/</link>
  <description><![CDATA[ 




<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Loading and Exploring the Dataset</li>
<li>Examining the Transforms V2 Class</li>
<li>Creating a Random Pixel Copy Transform</li>
<li>Creating a Random Patch Copy Transform</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to this hands-on guide to creating custom <a href="https://pytorch.org/vision/stable/transforms.html#v1-or-v2-which-one-should-i-use">V2 transforms</a> in torchvision. Torchvision’s V2 <a href="https://pytorch.org/vision/stable/transforms.html#v2-api-reference-recommended">image transforms</a> support annotations for various tasks, such as <a href="../../posts/torchvision-labelme-annotation-tutorials/bounding-boxes/">bounding boxes</a> for object detection and <a href="../../posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/">segmentation masks</a> for image segmentation.</p>
<p>The tutorial walks through setting up a Python environment, loading the raw annotations into a <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a>, and creating custom data augmentations that support bounding box annotations.</p>
<p>Data augmentation is a technique that creates variations of existing training samples to prevent a model from seeing the same sample twice. The goal is to help the model learn general features versus memorizing specific examples.</p>
<p>This guide is suitable for beginners and experienced practitioners, providing the code, explanations, and resources needed to understand and implement each step. Upon completion, you will have a solid foundation for creating custom V2 image transforms in torchvision for object detection tasks.</p>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>The tutorial code is available as a <a href="https://jupyter.org/">Jupyter Notebook</a>, which you can run locally or in a cloud-based environment like <a href="https://colab.research.google.com/">Google Colab</a>. I have dedicated tutorials for those new to these platforms or who need guidance setting up:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Setup Guides">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Setup Guides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../posts/google-colab-getting-started-tutorial/"><strong>Getting Started with Google Colab</strong></a></li>
<li><a href="../../posts/mamba-getting-started-tutorial-windows/"><strong>Setting Up a Local Python Environment with Mamba for Machine Learning Projects on Windows</strong></a></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Tutorial Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tutorial Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook:</th>
<th><a href="https://github.com/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/labelme/torchvision-custom-v2-transform-tutorial.ipynb">GitHub Repository</a></th>
<th><a href="https://colab.research.google.com/github/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/labelme/torchvision-custom-v2-transform-tutorial.ipynb">Open In Colab</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>Before diving into the code, we’ll cover the steps to create a local Python environment and install the necessary dependencies.</p>
<section id="creating-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-python-environment">Creating a Python Environment</h3>
<p>First, we’ll create a Python environment using <a href="https://docs.conda.io/en/latest/">Conda</a>/<a href="https://mamba.readthedocs.io/en/latest/">Mamba</a>. Open a terminal with Conda/Mamba installed and run the following commands:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Conda</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Mamba</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.11 environment</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.11 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate pytorch-env</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.11 environment</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.11 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate pytorch-env</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="installing-pytorch">Installing PyTorch</h3>
<p>Next, we’ll install <a href="https://pytorch.org/">PyTorch</a>. Run the appropriate command for your hardware and operating system.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Linux/Windows (CUDA)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Mac</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Linux (CPU)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Windows (CPU)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch with CUDA</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cu121</span></code></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MPS (Metal Performance Shaders) acceleration is available on MacOS 12.3+</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cpu</span></code></pre></div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-additional-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-libraries">Installing Additional Libraries</h3>
<p>We also need to install some additional libraries for our project.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>jupyter</code></td>
<td>An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. (<a href="https://jupyter.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>matplotlib</code></td>
<td>This package provides a comprehensive collection of visualization tools to create high-quality plots, charts, and graphs for data exploration and presentation. (<a href="https://matplotlib.org/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>pandas</code></td>
<td>This package provides fast, powerful, and flexible data analysis and manipulation tools. (<a href="https://pandas.pydata.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>pillow</code></td>
<td>The Python Imaging Library adds image processing capabilities. (<a href="https://pillow.readthedocs.io/en/stable/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>tqdm</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>distinctipy</code></td>
<td>A lightweight python package providing functions to generate colours that are visually distinct from one another. (<a href="https://distinctipy.readthedocs.io/en/latest/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install these additional libraries:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional dependencies</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install distinctipy jupyter matplotlib pandas pillow tqdm</span></code></pre></div>
</section>
<section id="installing-utility-packages" class="level3">
<h3 class="anchored" data-anchor-id="installing-utility-packages">Installing Utility Packages</h3>
<p>We will also install some utility packages I made, which provide shortcuts for routine tasks.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>cjm_pil_utils</code></td>
<td>Some PIL utility functions I frequently use. (<a href="https://cj-mills.github.io/cjm-pil-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_psl_utils</code></td>
<td>Some utility functions using the Python Standard Library. (<a href="https://cj-mills.github.io/cjm-psl-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_pytorch_utils</code></td>
<td>Some utility functions for working with PyTorch. (<a href="https://cj-mills.github.io/cjm-pytorch-utils/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install the utility packages:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional utility packages</span></span>
<span id="cb8-2">pip install cjm_pil_utils cjm_psl_utils cjm_pytorch_utils</span></code></pre></div>
<p>With our environment set up, we can open our Jupyter Notebook and dive into the code.</p>
</section>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python packages into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb9-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Any, Dict, Optional, List, Tuple, Union</span>
<span id="cb9-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> random</span>
<span id="cb9-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> singledispatchmethod</span>
<span id="cb9-7"></span>
<span id="cb9-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb9-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_img_files</span>
<span id="cb9-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file, file_extract</span>
<span id="cb9-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pytorch_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor_to_pil</span>
<span id="cb9-12"></span>
<span id="cb9-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the distinctipy module</span></span>
<span id="cb9-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distinctipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> distinctipy</span>
<span id="cb9-15"></span>
<span id="cb9-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import matplotlib for creating plots</span></span>
<span id="cb9-17"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb9-18"></span>
<span id="cb9-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb9-20"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-21"></span>
<span id="cb9-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb9-23"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb9-24"></span>
<span id="cb9-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb9-26">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb9-27"></span>
<span id="cb9-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb9-29"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image</span>
<span id="cb9-30"></span>
<span id="cb9-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb9-32"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb9-33"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DataLoader</span>
<span id="cb9-34"></span>
<span id="cb9-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import torchvision dependencies</span></span>
<span id="cb9-36"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision</span>
<span id="cb9-37">torchvision.disable_beta_transforms_warning()</span>
<span id="cb9-38"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BoundingBoxes, Mask</span>
<span id="cb9-39"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tv_tensors</span>
<span id="cb9-40"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wrap <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> tv_wrap</span>
<span id="cb9-41"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> draw_bounding_boxes</span>
<span id="cb9-42"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.v2 <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb9-43"></span>
<span id="cb9-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import tqdm for progress bar</span></span>
<span id="cb9-45"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm.auto <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
<p>After importing the dependencies, we can load our dataset.</p>
</section>
<section id="loading-and-exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-and-exploring-the-dataset">Loading and Exploring the Dataset</h2>
<p>We will use the following toy dataset containing images from the free stock photo site <a href="https://www.pexels.com/">Pexels</a> and its bounding box annotations:</p>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/datasets/cj-mills/labelme-bounding-box-toy-dataset/tree/main">labelme-bounding-box-toy-dataset</a></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Bounding Box Annotation Format">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bounding Box Annotation Format
</div>
</div>
<div class="callout-body-container callout-body">
<p>The bounding boxes for this dataset use the <a href="https://github.com/labelmeai/labelme">LabelMe</a> annotation format. You can learn more about this format and how to work with such annotations in the tutorial linked below:</p>
<ul>
<li><a href="../../posts/torchvision-labelme-annotation-tutorials/bounding-boxes/">Working with LabelMe Bounding Box Annotations in Torchvision</a></li>
</ul>
</div>
</div>
<section id="setting-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-directory-paths">Setting the Directory Paths</h3>
<p>We first need to specify a place to store our dataset and a location to download the zip file containing it. The following code creates the folders in the current directory (<code>./</code>). Update the path if that is not suitable for you.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store datasets</span></span>
<span id="cb10-2">dataset_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./Datasets/"</span>)</span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the dataset directory if it does not exist</span></span>
<span id="cb10-4">dataset_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store archive files</span></span>
<span id="cb10-7">archive_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'../Archive'</span></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the archive directory if it does not exist</span></span>
<span id="cb10-9">archive_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb10-12">pd.Series({</span>
<span id="cb10-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Directory:"</span>: dataset_dir, </span>
<span id="cb10-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Directory:"</span>: archive_dir</span>
<span id="cb10-15">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_4e87e">
<thead>
</thead>
<tbody>
<tr>
<th id="T_4e87e_level0_row0" class="row_heading level0 row0">
Dataset Directory:
</th>
<td id="T_4e87e_row0_col0" class="data row0 col0">
Datasets
</td>
</tr>
<tr>
<th id="T_4e87e_level0_row1" class="row_heading level0 row1">
Archive Directory:
</th>
<td id="T_4e87e_row1_col0" class="data row1 col0">
Datasets/../Archive
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="setting-the-dataset-path" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-dataset-path">Setting the Dataset Path</h3>
<p>Next, we construct the name for the Hugging Face Hub dataset and set where to download and extract the dataset.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the dataset</span></span>
<span id="cb11-2">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labelme-bounding-box-toy-dataset'</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb11-5">hf_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'cj-mills/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb11-8">archive_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>archive_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip'</span>)</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb11-11">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the dataset name and paths and converting it to a DataFrame for display</span></span>
<span id="cb11-14">pd.Series({</span>
<span id="cb11-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb11-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Path:"</span>: archive_path, </span>
<span id="cb11-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Path:"</span>: dataset_path</span>
<span id="cb11-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_e1208">
<thead>
</thead>
<tbody>
<tr>
<th id="T_e1208_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_e1208_row0_col0" class="data row0 col0">
cj-mills/labelme-bounding-box-toy-dataset
</td>
</tr>
<tr>
<th id="T_e1208_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_e1208_row1_col0" class="data row1 col0">
Datasets/../Archive/labelme-bounding-box-toy-dataset.zip
</td>
</tr>
<tr>
<th id="T_e1208_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_e1208_row2_col0" class="data row2 col0">
Datasets/labelme-bounding-box-toy-dataset
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="downloading-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h3>
<p>We can now download the archive file and extract the dataset using the <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#download_file"><code>download_file</code></a> and <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#file_extract"><code>file_extract</code></a> functions from the <code>cjm_psl_utils</code> package. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb12-2">dataset_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>hf_dataset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip"</span></span>
<span id="cb12-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"HuggingFace Dataset URL: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb12-6">delete_archive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the dataset if not present</span></span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset_path.is_dir():</span>
<span id="cb12-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset folder already exists"</span>)</span>
<span id="cb12-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb12-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Downloading dataset..."</span>)</span>
<span id="cb12-13">    download_file(dataset_url, archive_dir)    </span>
<span id="cb12-14">    </span>
<span id="cb12-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extracting dataset..."</span>)</span>
<span id="cb12-16">    file_extract(fname<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>archive_path, dest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_dir)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete the archive if specified</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> delete_archive: archive_path.unlink()</span></code></pre></div>
</section>
<section id="get-image-file-paths" class="level3">
<h3 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h3>
<p>Next, we will make a dictionary that maps each image’s unique name to its file path, allowing us to retrieve the file path for a given image more efficiently.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of image files in the dataset</span></span>
<span id="cb13-2">img_file_paths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_img_files(dataset_path)</span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary that maps file names to file paths</span></span>
<span id="cb13-5">img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.stem : <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> (img_file_paths)}</span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of image files</span></span>
<span id="cb13-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Number of Images: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_dict)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb13-11">pd.DataFrame.from_dict(img_dict, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).head()</span></code></pre></div>
<pre class="text"><code>Number of Images: 28</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
adults-attractive-beautiful-1727660
</th>
<td>
Datasets/labelme-bounding-box-toy-dataset/adults-attractive-beautiful-1727660.jpg
</td>
</tr>
<tr>
<th>
balloon-launch-festival-flame-1426050
</th>
<td>
Datasets/labelme-bounding-box-toy-dataset/balloon-launch-festival-flame-1426050.jpg
</td>
</tr>
<tr>
<th>
bar-beer-celebration-3009788
</th>
<td>
Datasets/labelme-bounding-box-toy-dataset/bar-beer-celebration-3009788.jpg
</td>
</tr>
<tr>
<th>
beach-child-daughter-1438511
</th>
<td>
Datasets/labelme-bounding-box-toy-dataset/beach-child-daughter-1438511.jpg
</td>
</tr>
<tr>
<th>
cellphone-festival-girl-1408983
</th>
<td>
Datasets/labelme-bounding-box-toy-dataset/cellphone-festival-girl-1408983.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="get-image-annotations">Get Image Annotations</h3>
<p>We will then read the content of the JSON annotation file associated with each image into a single Pandas DataFrame so we can easily query the annotations.</p>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of JSON files in the dataset</span></span>
<span id="cb15-2">annotation_file_paths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(dataset_path.glob(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'*.json'</span>))</span>
<span id="cb15-3"></span>
<span id="cb15-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a generator that yields Pandas DataFrames containing the data from each JSON file</span></span>
<span id="cb15-5">cls_dataframes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (pd.read_json(f, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).transpose() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> f <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(annotation_file_paths))</span>
<span id="cb15-6"></span>
<span id="cb15-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Concatenate the DataFrames into a single DataFrame</span></span>
<span id="cb15-8">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.concat(cls_dataframes, ignore_index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb15-9"></span>
<span id="cb15-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assign the image file name as the index for each row</span></span>
<span id="cb15-11">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> row: row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'imagePath'</span>].split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb15-12">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>)</span>
<span id="cb15-13"></span>
<span id="cb15-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Keep only the rows that correspond to the filenames in the 'img_dict' dictionary</span></span>
<span id="cb15-15">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())]</span>
<span id="cb15-16"></span>
<span id="cb15-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the first 5 rows of the DataFrame</span></span>
<span id="cb15-18">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
version
</th>
<th>
flags
</th>
<th>
shapes
</th>
<th>
imagePath
</th>
<th>
imageData
</th>
<th>
imageHeight
</th>
<th>
imageWidth
</th>
</tr>
<tr>
<th>
index
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
adults-attractive-beautiful-1727660
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[450.1688537597656, 174.04931640625], [925.5413818359375, 765.6500244140625]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[1.195121951219533, 169.67073170731703], [448.7560975609756, 766.6219512195121]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
<td>
adults-attractive-beautiful-1727660.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
928
</td>
</tr>
<tr>
<th>
balloon-launch-festival-flame-1426050
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[740.9563598632812, 368.4273681640625], [1088.41552734375, 764.3656005859375]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
<td>
balloon-launch-festival-flame-1426050.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1152
</td>
</tr>
<tr>
<th>
bar-beer-celebration-3009788
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[670.41650390625, 147.376953125], [1088.8197021484375, 760.0108642578125]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[116.53658536585372, 207.47560975609753], [629.3414634146342, 766.6219512195121]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[250.68292682926835, 1.378048780487799], [455.5609756097561, 225.15853658536582]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[427.51219512195127, 2.59756097560975], [593.9756097560976, 219.67073170731703]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[647.6341463414634, 2.59756097560975], [817.7560975609756, 137.96341463414632]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[731.170731707317, 0.7682926829268231], [917.1463414634146, 221.49999999999997]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[1009.2195121951219, 19.670731707317067], [1116.5365853658536, 262.3536585365854]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
<td>
bar-beer-celebration-3009788.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1216
</td>
</tr>
<tr>
<th>
beach-child-daughter-1438511
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[393.214111328125, 317.10064697265625], [588.5502319335938, 723.3473510742188]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[578.9024390243902, 351.3780487804878], [692.9268292682926, 697.1097560975609]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
<td>
beach-child-daughter-1438511.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1120
</td>
</tr>
<tr>
<th>
cellphone-festival-girl-1408983
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[119.5823974609375, 97.06643676757812], [886.0499877929688, 763.5545654296875]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
<td>
cellphone-festival-girl-1408983.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1152
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visualizing-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-image-annotations">Visualizing Image Annotations</h3>
<p>In this section, we will annotate a single image with its bounding boxes using torchvision’s <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.BoundingBoxes.html"><code>BoundingBoxes</code></a> class and <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function.</p>
<section id="get-image-classes" class="level4">
<h4 class="anchored" data-anchor-id="get-image-classes">Get image classes</h4>
<p>First, we get the names of all the classes in our dataset.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Explode the 'shapes' column in the annotation_df dataframe</span></span>
<span id="cb16-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the resulting series to a dataframe and rename the 'shapes' column to 'shapes'</span></span>
<span id="cb16-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the pandas Series function to the 'shapes' column of the dataframe</span></span>
<span id="cb16-4">shapes_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>].explode().to_frame().shapes.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)</span>
<span id="cb16-5"></span>
<span id="cb16-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb16-7">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shapes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>].unique().tolist()</span>
<span id="cb16-8"></span>
<span id="cb16-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display labels using a Pandas DataFrame</span></span>
<span id="cb16-10">pd.DataFrame(class_names)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
person
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="generate-a-color-map" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-color-map">Generate a color map</h4>
<p>Next, we will generate a color map for the object classes.</p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb17-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distinctipy.get_colors(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb17-3"></span>
<span id="cb17-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the color map in integer format</span></span>
<span id="cb17-5">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colors]</span>
<span id="cb17-6"></span>
<span id="cb17-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a color swatch to visualize the color map</span></span>
<span id="cb17-8">distinctipy.color_swatch(colors)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-custom-v2-transform-tutorial/images/output_20_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a font file</h4>
<p>The <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function included with torchvision uses a pretty small font size. We can increase the font size if we use a custom font. Font files are available on sites like <a href="https://fonts.google.com/">Google Fonts</a>, or we can use one included with the operating system.</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb18-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb18-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
</section>
<section id="define-the-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-the-bounding-box-annotation-function">Define the bounding box annotation function</h4>
<p>We can make a partial function using <code>draw_bounding_boxes</code> since we’ll use the same box thickness and font each time we visualize bounding boxes.</p>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">draw_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(draw_bounding_boxes, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, font<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>font_file, font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
</section>
<section id="define-function-that-ensures-bounding-boxes-are-in-a-consistent-format" class="level4">
<h4 class="anchored" data-anchor-id="define-function-that-ensures-bounding-boxes-are-in-a-consistent-format">Define function that ensures bounding boxes are in a consistent format</h4>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> correct_bounding_boxes(bboxes):</span>
<span id="cb20-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure input is a NumPy array</span></span>
<span id="cb20-3">    bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.asarray(bboxes)</span>
<span id="cb20-4">    </span>
<span id="cb20-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Correct x coordinates</span></span>
<span id="cb20-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Swap the x coordinates if the top-left x is greater than the bottom-right x</span></span>
<span id="cb20-7">    x_min <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.minimum(bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb20-8">    x_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.maximum(bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb20-9">    </span>
<span id="cb20-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Correct y coordinates</span></span>
<span id="cb20-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Swap the y coordinates if the top-left y is greater than the bottom-right y</span></span>
<span id="cb20-12">    y_min <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.minimum(bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb20-13">    y_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.maximum(bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb20-14">    </span>
<span id="cb20-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the corrected bounding boxes array</span></span>
<span id="cb20-16">    corrected_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.stack([x_min, y_min, x_max, y_max], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb20-17">    </span>
<span id="cb20-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> corrected_bboxes</span></code></pre></div>
</section>
<section id="annotate-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="annotate-sample-image">Annotate sample image</h4>
<p>Finally, we will open a sample image and annotate it with it’s associated bounding boxes.</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the file ID of the first image file</span></span>
<span id="cb21-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">19</span>]</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the associated image file as a RGB image</span></span>
<span id="cb21-5">sample_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(img_dict[file_id]).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb21-6"></span>
<span id="cb21-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels and bounding box annotations for the sample image</span></span>
<span id="cb21-8">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb21-9">bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]], dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float32).reshape(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(labels),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb21-10"></span>
<span id="cb21-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb21-12">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb21-13">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sample_img), </span>
<span id="cb21-14">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>BoundingBoxes(torchvision.ops.box_convert(torch.Tensor(bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]),</span>
<span id="cb21-15">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, </span>
<span id="cb21-16">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb21-17">)</span>
<span id="cb21-18"></span>
<span id="cb21-19">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-custom-v2-transform-tutorial/images/output_26_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We have loaded the dataset and visualized the annotations for a sample image. In the next section, we will explore the V2 Transforms class.</p>
</section>
</section>
</section>
<section id="examining-the-transforms-v2-class" class="level2">
<h2 class="anchored" data-anchor-id="examining-the-transforms-v2-class">Examining the Transforms V2 Class</h2>
<p>Our custom transforms will inherit from the <a href="https://github.com/pytorch/vision/blob/315f31527e720999eecbb986679b3177d4ed5e37/torchvision/transforms/v2/_transform.py#L17"><code>transforms.v2.Transform</code></a> class, so let’s look at the source code for that class first.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Transforms V2 Class Source Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Transforms V2 Class Source Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Transform(nn.Module):</span>
<span id="cb22-2"></span>
<span id="cb22-3"></span>
<span id="cb22-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Class attribute defining transformed types. Other types are passed-through without any transformation</span></span>
<span id="cb22-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># We support both Types and callables that are able to do further checks on the type of the input.</span></span>
<span id="cb22-6">    _transformed_types: Tuple[Union[Type, Callable[[Any], <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>]], ...] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (torch.Tensor, PIL.Image.Image)</span>
<span id="cb22-7">    </span>
<span id="cb22-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb22-9">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb22-10">        _log_api_usage_once(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>)</span>
<span id="cb22-11">    </span>
<span id="cb22-12">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _check_inputs(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, flat_inputs: List[Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb22-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">pass</span></span>
<span id="cb22-14">    </span>
<span id="cb22-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _get_params(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, flat_inputs: List[Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]:</span>
<span id="cb22-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>()</span>
<span id="cb22-17">    </span>
<span id="cb22-18">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _call_kernel(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, functional: Callable, inpt: Any, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args: Any, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs: Any) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb22-19">        kernel <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _get_kernel(functional, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>(inpt), allow_passthrough<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb22-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> kernel(inpt, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span>
<span id="cb22-21">    </span>
<span id="cb22-22">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _transform(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, inpt: Any, params: Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb22-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">NotImplementedError</span></span>
<span id="cb22-24">    </span>
<span id="cb22-25">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>inputs: Any) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb22-26">        flat_inputs, spec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tree_flatten(inputs <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(inputs) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> inputs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb22-27">    </span>
<span id="cb22-28">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._check_inputs(flat_inputs)</span>
<span id="cb22-29">    </span>
<span id="cb22-30">        needs_transform_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._needs_transform_list(flat_inputs)</span>
<span id="cb22-31">        params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._get_params(</span>
<span id="cb22-32">            [inpt <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> (inpt, needs_transform) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(flat_inputs, needs_transform_list) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> needs_transform]</span>
<span id="cb22-33">        )</span>
<span id="cb22-34">    </span>
<span id="cb22-35">        flat_outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb22-36">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transform(inpt, params) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> needs_transform <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> inpt</span>
<span id="cb22-37">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> (inpt, needs_transform) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(flat_inputs, needs_transform_list)</span>
<span id="cb22-38">        ]</span>
<span id="cb22-39">    </span>
<span id="cb22-40">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> tree_unflatten(flat_outputs, spec)</span>
<span id="cb22-41">    </span>
<span id="cb22-42">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _needs_transform_list(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, flat_inputs: List[Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> List[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>]:</span>
<span id="cb22-43">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Below is a heuristic on how to deal with pure tensor inputs:</span></span>
<span id="cb22-44">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Pure tensors, i.e. tensors that are not a tv_tensor, are passed through if there is an explicit image</span></span>
<span id="cb22-45">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#    (`tv_tensors.Image` or `PIL.Image.Image`) or video (`tv_tensors.Video`) in the sample.</span></span>
<span id="cb22-46">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. If there is no explicit image or video in the sample, only the first encountered pure tensor is</span></span>
<span id="cb22-47">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#    transformed as image, while the rest is passed through. The order is defined by the returned `flat_inputs`</span></span>
<span id="cb22-48">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#    of `tree_flatten`, which recurses depth-first through the input.</span></span>
<span id="cb22-49">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#</span></span>
<span id="cb22-50">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This heuristic stems from two requirements:</span></span>
<span id="cb22-51">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. We need to keep BC for single input pure tensors and treat them as images.</span></span>
<span id="cb22-52">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. We don't want to treat all pure tensors as images, because some datasets like `CelebA` or `Widerface`</span></span>
<span id="cb22-53">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#    return supplemental numerical data as tensors that cannot be transformed as images.</span></span>
<span id="cb22-54">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#</span></span>
<span id="cb22-55">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The heuristic should work well for most people in practice. The only case where it doesn't is if someone</span></span>
<span id="cb22-56">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># tries to transform multiple pure tensors at the same time, expecting them all to be treated as images.</span></span>
<span id="cb22-57">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># However, this case wasn't supported by transforms v1 either, so there is no BC concern.</span></span>
<span id="cb22-58">    </span>
<span id="cb22-59">        needs_transform_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb22-60">        transform_pure_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> has_any(flat_inputs, tv_tensors.Image, tv_tensors.Video, PIL.Image.Image)</span>
<span id="cb22-61">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> inpt <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> flat_inputs:</span>
<span id="cb22-62">            needs_transform <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb22-63">    </span>
<span id="cb22-64">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> check_type(inpt, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transformed_types):</span>
<span id="cb22-65">                needs_transform <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb22-66">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">elif</span> is_pure_tensor(inpt):</span>
<span id="cb22-67">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> transform_pure_tensor:</span>
<span id="cb22-68">                    transform_pure_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb22-69">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb22-70">                    needs_transform <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb22-71">            needs_transform_list.append(needs_transform)</span>
<span id="cb22-72">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> needs_transform_list</span>
<span id="cb22-73">    </span>
<span id="cb22-74">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> extra_repr(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="cb22-75">        extra <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb22-76">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> name, value <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.__dict__.items():</span>
<span id="cb22-77">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> name.startswith(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">or</span> name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"training"</span>:</span>
<span id="cb22-78">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">continue</span></span>
<span id="cb22-79">    </span>
<span id="cb22-80">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(value, (<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>, enum.Enum)):</span>
<span id="cb22-81">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">continue</span></span>
<span id="cb22-82">    </span>
<span id="cb22-83">            extra.append(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>value<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb22-84">    </span>
<span id="cb22-85">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">", "</span>.join(extra)</span>
<span id="cb22-86">    </span>
<span id="cb22-87">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This attribute should be set on all transforms that have a v1 equivalent. Doing so enables two things:</span></span>
<span id="cb22-88">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. In case the v1 transform has a static `get_params` method, it will also be available under the same name on</span></span>
<span id="cb22-89">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#    the v2 transform. See `__init_subclass__` for details.</span></span>
<span id="cb22-90">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. The v2 transform will be JIT scriptable. See `_extract_params_for_v1_transform` and `__prepare_scriptable__`</span></span>
<span id="cb22-91">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#    for details.</span></span>
<span id="cb22-92">    _v1_transform_cls: Optional[Type[nn.Module]] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb22-93">    </span>
<span id="cb22-94">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init_subclass__</span>(cls) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb22-95">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Since `get_params` is a `@staticmethod`, we have to bind it to the class itself rather than to an instance.</span></span>
<span id="cb22-96">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This method is called after subclassing has happened, i.e. `cls` is the subclass, e.g. `Resize`.</span></span>
<span id="cb22-97">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> cls._v1_transform_cls <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hasattr</span>(cls._v1_transform_cls, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"get_params"</span>):</span>
<span id="cb22-98">            cls.get_params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">staticmethod</span>(cls._v1_transform_cls.get_params)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># type: ignore[attr-defined]</span></span>
<span id="cb22-99">    </span>
<span id="cb22-100">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _extract_params_for_v1_transform(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]:</span>
<span id="cb22-101">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This method is called by `__prepare_scriptable__` to instantiate the equivalent v1 transform from the current</span></span>
<span id="cb22-102">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># v2 transform instance. It extracts all available public attributes that are specific to that transform and</span></span>
<span id="cb22-103">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># not `nn.Module` in general.</span></span>
<span id="cb22-104">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Overwrite this method on the v2 transform class if the above is not sufficient. For example, this might happen</span></span>
<span id="cb22-105">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># if the v2 transform introduced new parameters that are not support by the v1 transform.</span></span>
<span id="cb22-106">        common_attrs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Module().__dict__.keys()</span>
<span id="cb22-107">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {</span>
<span id="cb22-108">            attr: value</span>
<span id="cb22-109">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> attr, value <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.__dict__.items()</span>
<span id="cb22-110">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> attr.startswith(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> attr <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> common_attrs</span>
<span id="cb22-111">        }</span>
<span id="cb22-112">    </span>
<span id="cb22-113">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> __prepare_scriptable__(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> nn.Module:</span>
<span id="cb22-114">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This method is called early on when `torch.jit.script`'ing an `nn.Module` instance. If it succeeds, the return</span></span>
<span id="cb22-115">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># value is used for scripting over the original object that should have been scripted. Since the v1 transforms</span></span>
<span id="cb22-116">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># are JIT scriptable, and we made sure that for single image inputs v1 and v2 are equivalent, we just return the</span></span>
<span id="cb22-117">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># equivalent v1 transform here. This of course only makes transforms v2 JIT scriptable as long as transforms v1</span></span>
<span id="cb22-118">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># is around.</span></span>
<span id="cb22-119">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._v1_transform_cls <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb22-120">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">RuntimeError</span>(</span>
<span id="cb22-121">                <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Transform </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> cannot be JIT scripted. "</span></span>
<span id="cb22-122">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"torchscript is only supported for backward compatibility with transforms "</span></span>
<span id="cb22-123">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"which are already in torchvision.transforms. "</span></span>
<span id="cb22-124">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"For torchscript support (on tensors only), you can use the functional API instead."</span></span>
<span id="cb22-125">            )</span>
<span id="cb22-126">    </span>
<span id="cb22-127">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._v1_transform_cls(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._extract_params_for_v1_transform())</span></code></pre></div>
</div>
</div>
</div>
<p>The above source code indicates that our custom transforms must implement the <code>_transform</code> method, which handles images and annotations.</p>
</section>
<section id="creating-a-random-pixel-copy-transform" class="level2">
<h2 class="anchored" data-anchor-id="creating-a-random-pixel-copy-transform">Creating a Random Pixel Copy Transform</h2>
<p>Our first custom transform will randomly copy and paste pixels in random locations. This one will not require updating the associated image annotations.</p>
<section id="define-the-custom-transform-class" class="level3">
<h3 class="anchored" data-anchor-id="define-the-custom-transform-class">Define the Custom Transform Class</h3>
<p>We can use Python’s <a href="https://docs.python.org/3/library/functools.html#functools.singledispatchmethod"><code>singledispatchmethod</code></a> decorator to overload the <code>_transform</code> method based on the first (non-<em>self</em> or non-<em>cls)</em> argument’s type.</p>
<p>We will implement different versions to handle PIL Images, PyTorch Tensors, and torchvision’s <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.Image.html"><code>tv_tensor.Image</code></a> class as image input types and to return annotations such as BoundingBoxes and Mask instances unaltered.</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> RandomPixelCopy(transforms.Transform):</span>
<span id="cb23-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb23-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A torchvision V2 transform that copies data from a randomly selected set of pixels to another </span></span>
<span id="cb23-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    randomly selected set of pixels of a image tensor.</span></span>
<span id="cb23-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb23-6">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,</span>
<span id="cb23-7">                 min_pct<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0025</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The minimum percentage of the tensor's pixels to be copied.</span></span>
<span id="cb23-8">                 max_pct:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The maximum percentage of the tensor's pixels to be copied.</span></span>
<span id="cb23-9">                ):</span>
<span id="cb23-10">        </span>
<span id="cb23-11">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb23-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> min_pct</span>
<span id="cb23-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_pct</span>
<span id="cb23-14"></span>
<span id="cb23-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> rand_pixel_copy(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, </span>
<span id="cb23-16">                        img_tensor:torch.Tensor, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The input image tensor.</span></span>
<span id="cb23-17">                        pct:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The percentage of the total number of pixels to be selected as the source and target sets of pixels.</span></span>
<span id="cb23-18">                       ) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> torch.Tensor : <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The modified input image tensor.</span></span>
<span id="cb23-19">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb23-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Copy data from a randomly selected set of pixels to another randomly selected set of pixels of a image tensor.</span></span>
<span id="cb23-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb23-22">        </span>
<span id="cb23-23">        src_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_tensor.dim()</span>
<span id="cb23-24">        </span>
<span id="cb23-25">        img_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_tensor.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> src_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> img_tensor</span>
<span id="cb23-26">        </span>
<span id="cb23-27">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the shape of the img_tensor</span></span>
<span id="cb23-28">        b, c, h, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_tensor.shape</span>
<span id="cb23-29">        </span>
<span id="cb23-30">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the number of pixels to be selected</span></span>
<span id="cb23-31">        num_pixels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(img_tensor[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:].numel() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> pct)</span>
<span id="cb23-32">        </span>
<span id="cb23-33">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Select the source pixel indices</span></span>
<span id="cb23-34">        source_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.LongTensor(num_pixels, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).random_(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> w)</span>
<span id="cb23-35">        source_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> source_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> w</span>
<span id="cb23-36">        source_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> source_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> w</span>
<span id="cb23-37">        </span>
<span id="cb23-38">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Select the target pixel indices</span></span>
<span id="cb23-39">        target_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.LongTensor(num_pixels, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).random_(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> w)</span>
<span id="cb23-40">        target_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> w</span>
<span id="cb23-41">        target_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> w</span>
<span id="cb23-42">        </span>
<span id="cb23-43">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the indices of the channels</span></span>
<span id="cb23-44">        c_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.arange(c).repeat(num_pixels, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).t()</span>
<span id="cb23-45">        </span>
<span id="cb23-46">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Copy the pixels</span></span>
<span id="cb23-47">        source_pixels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_tensor[:, c_indices, source_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], source_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]]</span>
<span id="cb23-48">        img_tensor[:, c_indices, target_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], target_indices[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> source_pixels</span>
<span id="cb23-49">        </span>
<span id="cb23-50">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> img_tensor.squeeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> src_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> img_tensor</span>
<span id="cb23-51"></span>
<span id="cb23-52">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@singledispatchmethod</span></span>
<span id="cb23-53">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _transform(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, inpt: Any, params: Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb23-54">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Default Behavior: Don't modify the input"""</span></span>
<span id="cb23-55">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> inpt</span>
<span id="cb23-56"></span>
<span id="cb23-57">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@_transform.register</span>(torch.Tensor)</span>
<span id="cb23-58">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@_transform.register</span>(tv_tensors.Image)</span>
<span id="cb23-59">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, inpt: Union[torch.Tensor, tv_tensors.Image], params: Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb23-60">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Apply the `rand_pixel_copy` method to the input tensor"""</span></span>
<span id="cb23-61">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.rand_pixel_copy(inpt, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_pct, random.random() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_pct))</span>
<span id="cb23-62"></span>
<span id="cb23-63">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@_transform.register</span>(Image.Image)</span>
<span id="cb23-64">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, inpt: Image.Image, params: Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb23-65">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Convert the PIL Image to a torch.Tensor to apply the transform"""</span></span>
<span id="cb23-66">        inpt_torch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.PILToTensor()(inpt)</span>
<span id="cb23-67">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> transforms.ToPILImage()(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transform(inpt_torch, params))</span>
<span id="cb23-68"></span>
<span id="cb23-69">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@_transform.register</span>(BoundingBoxes)</span>
<span id="cb23-70">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@_transform.register</span>(Mask)</span>
<span id="cb23-71">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, inpt: Union[BoundingBoxes, Mask], params: Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb23-72">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Don't modify image annotations"""</span></span>
<span id="cb23-73">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> inpt</span></code></pre></div>
<p>With our custom transform defined, we can create an instance of it and try it out.</p>
</section>
<section id="initialize-the-transform" class="level3">
<h3 class="anchored" data-anchor-id="initialize-the-transform">Initialize the Transform</h3>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomPixelCopy object</span></span>
<span id="cb24-2">rand_pixel_copy_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomPixelCopy(max_pct<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>)</span></code></pre></div>
</section>
<section id="prepare-the-annotation-targets" class="level3">
<h3 class="anchored" data-anchor-id="prepare-the-annotation-targets">Prepare the Annotation Targets</h3>
<p>The V2 image transforms take an image and a <code>targets</code> dictionary as input. The dictionary contains the annotations and labels for the image.</p>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare bounding box targets</span></span>
<span id="cb25-2">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb25-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: BoundingBoxes(torch.Tensor(bboxes), </span>
<span id="cb25-4">                           <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, </span>
<span id="cb25-5">                           canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), </span>
<span id="cb25-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.Tensor([class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])</span>
<span id="cb25-7">}</span></code></pre></div>
</section>
<section id="apply-the-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="apply-the-augmentation">Apply the Augmentation</h3>
<p>Now, we can see how our sample image looks after applying the augmentation.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" aria-controls="tabset-3-1" aria-selected="true">PIL.Image</a></li><li class="nav-item"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" aria-controls="tabset-3-2" aria-selected="false">torch.Tensor</a></li><li class="nav-item"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" aria-controls="tabset-3-3" aria-selected="false">tv_tensor.Image</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" aria-labelledby="tabset-3-1-tab">
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feed sample image and targets through the image transform</span></span>
<span id="cb26-2">augmented_img, augmented_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rand_pixel_copy_tfm(sample_img, targets)</span>
<span id="cb26-3"></span>
<span id="cb26-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb26-5">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb26-6">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(augmented_img), </span>
<span id="cb26-7">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>augmented_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb26-8">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> augmented_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb26-9">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i)] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> augmented_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb26-10">)</span>
<span id="cb26-11"></span>
<span id="cb26-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the augmented image</span></span>
<span id="cb26-13">transforms.ToPILImage()(annotated_tensor)</span></code></pre></div>
<p><img src="christianjmills.com/posts/torchvision-custom-v2-transform-tutorial/images/output_37_0.png" class="img-fluid"></p>
</div>
<div id="tabset-3-2" class="tab-pane" aria-labelledby="tabset-3-2-tab">
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feed sample image and targets through the image transform</span></span>
<span id="cb27-2">augmented_img, augmented_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rand_pixel_copy_tfm(transforms.PILToTensor()(sample_img), targets)</span>
<span id="cb27-3"></span>
<span id="cb27-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb27-5">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb27-6">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>augmented_img, </span>
<span id="cb27-7">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>augmented_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb27-8">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> augmented_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb27-9">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i)] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> augmented_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb27-10">)</span>
<span id="cb27-11"></span>
<span id="cb27-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the augmented image</span></span>
<span id="cb27-13">transforms.ToPILImage()(annotated_tensor)</span></code></pre></div>
<p><img src="christianjmills.com/posts/torchvision-custom-v2-transform-tutorial/images/output_39_0.png" class="img-fluid"></p>
</div>
<div id="tabset-3-3" class="tab-pane" aria-labelledby="tabset-3-3-tab">
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feed sample image and targets through the image transform</span></span>
<span id="cb28-2">augmented_img, augmented_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rand_pixel_copy_tfm(transforms.ToImage()(sample_img), targets)</span>
<span id="cb28-3"></span>
<span id="cb28-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb28-5">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb28-6">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>augmented_img, </span>
<span id="cb28-7">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>augmented_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb28-8">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> augmented_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb28-9">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i)] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> augmented_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb28-10">)</span>
<span id="cb28-11"></span>
<span id="cb28-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the augmented image</span></span>
<span id="cb28-13">transforms.ToPILImage()(annotated_tensor)</span></code></pre></div>
<p><img src="christianjmills.com/posts/torchvision-custom-v2-transform-tutorial/images/output_41_0.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>As intended, the transform randomly copy-pasted pixel values while leaving the bounding box annotations unchanged. In the next section, we will create a transform that requires us to update the bounding box annotations with the image.</p>
</section>
</section>
<section id="creating-a-random-patch-copy-transform" class="level2">
<h2 class="anchored" data-anchor-id="creating-a-random-patch-copy-transform">Creating a Random Patch Copy Transform</h2>
<p>Our second transform will randomly copy rectangular patches from the image and paste them in random locations. This transform may potentially occlude annotated areas, so we need to manage the associated bounding box annotations accordingly.</p>
<section id="define-the-custom-transform-class-1" class="level3">
<h3 class="anchored" data-anchor-id="define-the-custom-transform-class-1">Define the Custom Transform Class</h3>
<p>To determine if any copy-pasted patches occlude an annotated area, we will keep track of the patches for the current image and check how much they overlap with the bounding box annotations.</p>
<p>If the patches overlap a given bounding box by a certain threshold, we will set the dimensions for that bounding box to <code>0</code> so the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.SanitizeBoundingBoxes.html#torchvision.transforms.v2.SanitizeBoundingBoxes"><code>SanitizeBoundingBoxes</code></a> transform removes it. The <code>SanitizeBoundingBoxes</code> transform would also remove a segmentation mask associated with the bounding box.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> RandomPatchCopy(transforms.Transform):</span>
<span id="cb29-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb29-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A torchvision V2 transform that copies data from a randomly selected rectangular patch</span></span>
<span id="cb29-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    to another randomly selected rectangular region of an image tensor multiple times.</span></span>
<span id="cb29-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb29-6">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, </span>
<span id="cb29-7">                 pct:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The percentage of the tensor's size to be used as the side length of the square regions.</span></span>
<span id="cb29-8">                 min_num:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The minimum number of times to apply the `rand_square_copy` function.</span></span>
<span id="cb29-9">                 max_num:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The maximum number of times to apply the `rand_square_copy` function.</span></span>
<span id="cb29-10">                 iou_thresh:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The IoU threshold for bounding box suppression.</span></span>
<span id="cb29-11">                ):</span>
<span id="cb29-12">        </span>
<span id="cb29-13">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb29-14">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pct</span>
<span id="cb29-15">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_num <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> min_num</span>
<span id="cb29-16">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_num <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_num</span>
<span id="cb29-17">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.iou_thresh <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iou_thresh</span>
<span id="cb29-18">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.patches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb29-19"></span>
<span id="cb29-20"></span>
<span id="cb29-21">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> calculate_iou_multi(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,</span>
<span id="cb29-22">                            boxes1:torch.Tensor, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># An array of bounding boxes in [x1, y1, x2, y2] format.</span></span>
<span id="cb29-23">                            boxes2:torch.Tensor <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Another array of bounding boxes in [x1, y1, x2, y2] format.</span></span>
<span id="cb29-24">                           ) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> torch.Tensor: <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># A 2D array where element (i, j) is the IoU of boxes1[i] and boxes2[j].</span></span>
<span id="cb29-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb29-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Calculate the Intersection over Union (IoU) for each combination of bounding boxes in two arrays</span></span>
<span id="cb29-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        using PyTorch broadcasting.</span></span>
<span id="cb29-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb29-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Expand boxes1 and boxes2 for broadcasting</span></span>
<span id="cb29-30">        boxes1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> boxes1[:, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, :]</span>
<span id="cb29-31">        boxes2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> boxes2[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, :, :]</span>
<span id="cb29-32">    </span>
<span id="cb29-33">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate intersection coordinates</span></span>
<span id="cb29-34">        int_x1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(boxes1[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], boxes2[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb29-35">        int_y1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(boxes1[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], boxes2[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb29-36">        int_x2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(boxes1[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], boxes2[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb29-37">        int_y2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(boxes1[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>], boxes2[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb29-38">    </span>
<span id="cb29-39">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate intersection and union areas</span></span>
<span id="cb29-40">        int_area <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.clamp(int_x2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> int_x1, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> torch.clamp(int_y2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> int_y1, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb29-41">        box1_area <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (boxes1[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> boxes1[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (boxes1[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> boxes1[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb29-42">        box2_area <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (boxes2[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> boxes2[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (boxes2[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> boxes2[..., <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb29-43">        union_area <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> box1_area <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> box2_area <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> int_area</span>
<span id="cb29-44">    </span>
<span id="cb29-45">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate IoU</span></span>
<span id="cb29-46">        iou <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> int_area <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> torch.clamp(union_area, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-10</span>)</span>
<span id="cb29-47">    </span>
<span id="cb29-48">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> iou</span>
<span id="cb29-49">    </span>
<span id="cb29-50"></span>
<span id="cb29-51">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> rand_patch_copy(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, </span>
<span id="cb29-52">                        img_tensor:torch.Tensor, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The input image tensor.</span></span>
<span id="cb29-53">                        pct:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># # The percentage of the image tensor's size to be used as the side length of the patch.</span></span>
<span id="cb29-54">                       ) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> (torch.Tensor, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>): <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The modified input image tensor and coordinates of the target patch in the format [x, y, w, h].</span></span>
<span id="cb29-55">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb29-56"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Copy data from a randomly selected rectangular patch to another randomly selected </span></span>
<span id="cb29-57"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        rectangular region of an image tensor, and return the coordinates of the target patch.</span></span>
<span id="cb29-58"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Assumes the tensor is in 'channels-first' format.</span></span>
<span id="cb29-59"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb29-60">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb29-61">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pct must be between 0 and 1"</span>)</span>
<span id="cb29-62">    </span>
<span id="cb29-63">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the shape of the tensor</span></span>
<span id="cb29-64">        _, h, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_tensor.shape</span>
<span id="cb29-65">    </span>
<span id="cb29-66">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the size of the rectangle</span></span>
<span id="cb29-67">        szx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> w)</span>
<span id="cb29-68">        szy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> h)</span>
<span id="cb29-69">    </span>
<span id="cb29-70">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the top-left coordinate of the source rectangle</span></span>
<span id="cb29-71">        sty1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> random.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> szx)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># x-coordinate</span></span>
<span id="cb29-72">        stx1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> random.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> szy)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># y-coordinate</span></span>
<span id="cb29-73">    </span>
<span id="cb29-74">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the top-left coordinate of the target rectangle</span></span>
<span id="cb29-75">        sty2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> random.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> szx)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># x-coordinate</span></span>
<span id="cb29-76">        stx2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> random.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> szy)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># y-coordinate</span></span>
<span id="cb29-77">    </span>
<span id="cb29-78">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Copy the data from the source square to the target rectangle</span></span>
<span id="cb29-79">        img_tensor[:, stx2:stx2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> szy, sty2:sty2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> szx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_tensor[:, stx1:stx1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> szy, sty1:sty1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> szx]</span>
<span id="cb29-80">    </span>
<span id="cb29-81">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The coordinates of the target patch</span></span>
<span id="cb29-82">        target_patch_coords <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [sty2, stx2, sty2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> szx, stx2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> szy]</span>
<span id="cb29-83">    </span>
<span id="cb29-84">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> img_tensor, target_patch_coords</span>
<span id="cb29-85"></span>
<span id="cb29-86"></span>
<span id="cb29-87">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@singledispatchmethod</span></span>
<span id="cb29-88">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _transform(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, inpt: Any, params: Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb29-89">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Default Behavior: Don't modify the input"""</span></span>
<span id="cb29-90">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> inpt</span>
<span id="cb29-91"></span>
<span id="cb29-92">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@_transform.register</span>(torch.Tensor)</span>
<span id="cb29-93">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@_transform.register</span>(tv_tensors.Image)</span>
<span id="cb29-94">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, inpt: Union[torch.Tensor, tv_tensors.Image], params: Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb29-95">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.patches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb29-96">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Apply the `rand_square_copy` function to the input tensor multiple times"""</span></span>
<span id="cb29-97">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(random.randint(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_num, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_num)):</span>
<span id="cb29-98">            inpt, patch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.rand_patch_copy(inpt, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,random.random()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.pct))</span>
<span id="cb29-99">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.patches.append(patch)</span>
<span id="cb29-100">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> inpt</span>
<span id="cb29-101"></span>
<span id="cb29-102">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@_transform.register</span>(Image.Image)</span>
<span id="cb29-103">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, inpt: Image.Image, params: Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb29-104">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Convert the PIL Image to a torch.Tensor to apply the transform"""</span></span>
<span id="cb29-105">        inpt_torch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.PILToTensor()(inpt)    </span>
<span id="cb29-106">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> transforms.ToPILImage()(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transform(inpt_torch, params))</span>
<span id="cb29-107">    </span>
<span id="cb29-108">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@_transform.register</span>(BoundingBoxes)</span>
<span id="cb29-109">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, inpt: BoundingBoxes, params: Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb29-110">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Update the bounding box annotations based on the list of patches"""</span></span>
<span id="cb29-111">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.patches) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb29-112">            iou_matrix <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.calculate_iou_multi(inpt, torch.tensor(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.patches, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32))</span>
<span id="cb29-113">            </span>
<span id="cb29-114">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sum the IoU values for each box in boxes1</span></span>
<span id="cb29-115">            cumulative_iou <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(iou_matrix, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb29-116">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mask based on the cumulative IoU threshold</span></span>
<span id="cb29-117">            mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cumulative_iou <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.iou_thresh</span>
<span id="cb29-118">            inpt_copy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.clone(inpt)</span>
<span id="cb29-119">            inpt_copy[mask] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb29-120">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> tv_wrap(inpt_copy, like<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>inpt)</span>
<span id="cb29-121">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> inpt</span>
<span id="cb29-122"></span>
<span id="cb29-123">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@_transform.register</span>(Mask)</span>
<span id="cb29-124">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, inpt: Mask, params: Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Any:</span>
<span id="cb29-125">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Don't modify segmentation annotations"""</span></span>
<span id="cb29-126">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> inpt</span></code></pre></div>
<p>Now, let’s see how our sample image and its bounding box annotations look with this transform.</p>
</section>
<section id="initialize-the-transform-1" class="level3">
<h3 class="anchored" data-anchor-id="initialize-the-transform-1">Initialize the Transform</h3>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomPatchCopy object</span></span>
<span id="cb30-2">rand_patch_copy_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomPatchCopy(pct<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, min_num<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, max_num<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span></code></pre></div>
</section>
<section id="apply-the-augmentation-1" class="level3">
<h3 class="anchored" data-anchor-id="apply-the-augmentation-1">Apply the Augmentation</h3>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" aria-controls="tabset-4-1" aria-selected="true">PIL.Image</a></li><li class="nav-item"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" aria-controls="tabset-4-2" aria-selected="false">torch.Tensor</a></li><li class="nav-item"><a class="nav-link" id="tabset-4-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-3" aria-controls="tabset-4-3" aria-selected="false">tv_tensor.Image</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" aria-labelledby="tabset-4-1-tab">
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feed sample image and targets through the image transform</span></span>
<span id="cb31-2">augmented_img, augmented_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rand_patch_copy_tfm(sample_img, targets)</span>
<span id="cb31-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Remove degenerate/invalid bounding boxes and their corresponding labels and masks.</span></span>
<span id="cb31-4">sanitized_img, sanitized_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(augmented_img, augmented_targets)</span>
<span id="cb31-5"></span>
<span id="cb31-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb31-7">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb31-8">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sanitized_img), </span>
<span id="cb31-9">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb31-10">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb31-11">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i)] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb31-12">)</span>
<span id="cb31-13"></span>
<span id="cb31-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the augmented image</span></span>
<span id="cb31-15">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<p><img src="christianjmills.com/posts/torchvision-custom-v2-transform-tutorial/images/output_53_0.png" class="img-fluid"></p>
</div>
<div id="tabset-4-2" class="tab-pane" aria-labelledby="tabset-4-2-tab">
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feed sample image and targets through the image transform</span></span>
<span id="cb32-2">augmented_img, augmented_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rand_patch_copy_tfm(transforms.PILToTensor()(sample_img), targets)</span>
<span id="cb32-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Remove degenerate/invalid bounding boxes and their corresponding labels and masks.</span></span>
<span id="cb32-4">sanitized_img, sanitized_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(augmented_img, augmented_targets)</span>
<span id="cb32-5"></span>
<span id="cb32-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb32-7">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb32-8">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sanitized_img, </span>
<span id="cb32-9">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb32-10">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb32-11">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i)] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb32-12">)</span>
<span id="cb32-13"></span>
<span id="cb32-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the augmented image</span></span>
<span id="cb32-15">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<p><img src="christianjmills.com/posts/torchvision-custom-v2-transform-tutorial/images/output_55_0.png" class="img-fluid"></p>
</div>
<div id="tabset-4-3" class="tab-pane" aria-labelledby="tabset-4-3-tab">
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feed sample image and targets through the image transform</span></span>
<span id="cb33-2">augmented_img, augmented_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rand_patch_copy_tfm(transforms.ToImage()(sample_img), targets)</span>
<span id="cb33-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Remove degenerate/invalid bounding boxes and their corresponding labels and masks.</span></span>
<span id="cb33-4">sanitized_img, sanitized_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(augmented_img, augmented_targets)</span>
<span id="cb33-5"></span>
<span id="cb33-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb33-7">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb33-8">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sanitized_img, </span>
<span id="cb33-9">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb33-10">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb33-11">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i)] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb33-12">)</span>
<span id="cb33-13"></span>
<span id="cb33-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the augmented image</span></span>
<span id="cb33-15">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<p><img src="christianjmills.com/posts/torchvision-custom-v2-transform-tutorial/images/output_57_0.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>Here, we can see some of the patches overlapped with one of the annotated areas too much, and the <code>SanitizeBoundingBoxes</code> transform removed the relevant bounding box.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we created custom V2 image transforms in torchvision that support bounding box annotations. The knowledge acquired here provides a solid foundation for making other custom transforms.</p>
<p>As a next step, perhaps try experimenting with the transforms created here to see how they impact training performance in one of the following tutorials:</p>
<ul>
<li><a href="../../posts/pytorch-train-image-classifier-timm-hf-tutorial/">Fine-Tuning Image Classifiers with PyTorch and the timm library for Beginners</a></li>
<li><a href="../../posts/pytorch-train-object-detector-yolox-tutorial/">Training YOLOX Models for Real-Time Object Detection in PyTorch</a></li>
<li><a href="../../posts/pytorch-train-mask-rcnn-tutorial/">Training Mask R-CNN Models with PyTorch</a></li>
</ul>
<p>See how adjusting the intensity of the data augmentations impacts the model accuracy on new data.</p>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>object-detection</category>
  <category>instance-segmentation</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/torchvision-custom-v2-transform-tutorial/</guid>
  <pubDate>Tue, 23 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Working with LabelMe Segmentation Annotations in Torchvision</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/tutorials/torchvision-annotation-tutorials-series.html"><strong>Torchvision Annotation Tutorials</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Loading and Exploring the Dataset</li>
<li>Preparing the Data</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to this hands-on guide for working with segmentation annotations created with the <a href="https://github.com/labelmeai/labelme">LabelMe annotation tool</a> in <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>. Segmentation annotations indicate the pixels occupied by specific objects or areas of interest in images for training models to recognize and delineate these objects at a pixel level.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/images/segmentation-mask-hero-img.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The tutorial walks through setting up a Python environment, loading the raw annotations into a <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a>, annotating and augmenting images using torchvision’s <a href="https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py">Transforms V2 API</a>, and creating a custom <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Dataset</a> class to feed samples to a model.</p>
<p>This guide is suitable for beginners and experienced practitioners, providing the code, explanations, and resources needed to understand and implement each step. By the end, you will have a solid foundation for working with bounding box annotations made with LabelMe for instance segmentation tasks.</p>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>The tutorial code is available as a <a href="https://jupyter.org/">Jupyter Notebook</a>, which you can run locally or in a cloud-based environment like <a href="https://colab.research.google.com/">Google Colab</a>. I have dedicated tutorials for those new to these platforms or who need guidance setting up:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Setup Guides">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Setup Guides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="../../../posts/google-colab-getting-started-tutorial/"><strong>Getting Started with Google Colab</strong></a></p></li>
<li><p><a href="../../../posts/mamba-getting-started-tutorial-windows/"><strong>Setting Up a Local Python Environment with Mamba for Machine Learning Projects on Windows</strong></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Tutorial Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tutorial Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook:</th>
<th><a href="https://github.com/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/labelme/torchvision-labelme-segmentation-annotations.ipynb">GitHub Repository</a></th>
<th><a href="https://colab.research.google.com/github/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/labelme/torchvision-labelme-segmentation-annotations.ipynb">Open In Colab</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>Before diving into the code, we’ll cover the steps to create a local Python environment and install the necessary dependencies.</p>
<section id="creating-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-python-environment">Creating a Python Environment</h3>
<p>First, we’ll create a Python environment using <a href="https://docs.conda.io/en/latest/">Conda</a>/<a href="https://mamba.readthedocs.io/en/latest/">Mamba</a>. Open a terminal with Conda/Mamba installed and run the following commands:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Conda</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Mamba</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate pytorch-env</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate pytorch-env</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="installing-pytorch">Installing PyTorch</h3>
<p>Next, we’ll install <a href="https://pytorch.org/">PyTorch</a>. Run the appropriate command for your hardware and operating system.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Linux/Windows (CUDA)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Mac</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Linux (CPU)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Windows (CPU)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch with CUDA</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cu121</span></code></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MPS (Metal Performance Shaders) acceleration is available on MacOS 12.3+</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cpu</span></code></pre></div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-additional-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-libraries">Installing Additional Libraries</h3>
<p>We also need to install some additional libraries for our project.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>jupyter</code></td>
<td>An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. (<a href="https://jupyter.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>matplotlib</code></td>
<td>This package provides a comprehensive collection of visualization tools to create high-quality plots, charts, and graphs for data exploration and presentation. (<a href="https://matplotlib.org/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>pandas</code></td>
<td>This package provides fast, powerful, and flexible data analysis and manipulation tools. (<a href="https://pandas.pydata.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>pillow</code></td>
<td>The Python Imaging Library adds image processing capabilities. (<a href="https://pillow.readthedocs.io/en/stable/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>tqdm</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>distinctipy</code></td>
<td>A lightweight python package providing functions to generate colours that are visually distinct from one another. (<a href="https://distinctipy.readthedocs.io/en/latest/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install these additional libraries:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional dependencies</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install distinctipy jupyter matplotlib pandas pillow tqdm</span></code></pre></div>
</section>
<section id="installing-utility-packages" class="level3">
<h3 class="anchored" data-anchor-id="installing-utility-packages">Installing Utility Packages</h3>
<p>We will also install some utility packages I made, which provide shortcuts for routine tasks.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>cjm_pil_utils</code></td>
<td>Some PIL utility functions I frequently use. (<a href="https://cj-mills.github.io/cjm-pil-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_psl_utils</code></td>
<td>Some utility functions using the Python Standard Library. (<a href="https://cj-mills.github.io/cjm-psl-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_pytorch_utils</code></td>
<td>Some utility functions for working with PyTorch. (<a href="https://cj-mills.github.io/cjm-pytorch-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_torchvision_tfms</code></td>
<td>Some custom Torchvision tranforms. (<a href="https://cj-mills.github.io/cjm-torchvision-tfms/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install the utility packages:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional utility packages</span></span>
<span id="cb8-2">pip install cjm_pil_utils cjm_psl_utils cjm_pytorch_utils cjm_torchvision_tfms</span></code></pre></div>
<p>With our environment set up, we can open our Jupyter Notebook and dive into the code.</p>
</section>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python packages into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb9-4"></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb9-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_img_files</span>
<span id="cb9-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file, file_extract</span>
<span id="cb9-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pytorch_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor_to_pil</span>
<span id="cb9-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_torchvision_tfms.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ResizeMax, PadSquare, CustomRandomIoUCrop</span>
<span id="cb9-10"></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the distinctipy module</span></span>
<span id="cb9-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distinctipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> distinctipy</span>
<span id="cb9-13"></span>
<span id="cb9-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import matplotlib for creating plots</span></span>
<span id="cb9-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb9-16"></span>
<span id="cb9-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb9-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-19"></span>
<span id="cb9-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb9-21"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb9-22"></span>
<span id="cb9-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb9-24">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb9-25"></span>
<span id="cb9-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb9-27"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image, ImageDraw</span>
<span id="cb9-28"></span>
<span id="cb9-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb9-30"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb9-31"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DataLoader</span>
<span id="cb9-32"></span>
<span id="cb9-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import torchvision dependencies</span></span>
<span id="cb9-34"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision</span>
<span id="cb9-35">torchvision.disable_beta_transforms_warning()</span>
<span id="cb9-36"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BoundingBoxes, Mask</span>
<span id="cb9-37"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> draw_bounding_boxes, draw_segmentation_masks</span>
<span id="cb9-38"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.v2  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb9-39"></span>
<span id="cb9-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import tqdm for progress bar</span></span>
<span id="cb9-41"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm.auto <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
<p>Torchvision provides dedicated <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> subclasses for different annotation types called <a href="https://pytorch.org/vision/stable/tv_tensors.html"><code>TVTensors</code></a>. Torchvision’s V2 transforms use these subclasses to update the annotations based on the applied image augmentations. The TVTensor class for segmentation annotations is called <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.Mask.html">Mask</a>. Torchvision also includes a <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_segmentation_masks.html">draw_segmentation_masks</a> function to annotate images.</p>
</section>
<section id="loading-and-exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-and-exploring-the-dataset">Loading and Exploring the Dataset</h2>
<p>After importing the dependencies, we can start working with our data. I annotated a toy dataset with segmentation masks for this tutorial using images from the free stock photo site <a href="https://www.pexels.com/">Pexels</a>. The dataset is available on <a href="https://huggingface.co/">HuggingFace Hub</a> at the link below:</p>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/datasets/cj-mills/labelme-instance-segmentation-toy-dataset/tree/main">labelme-instance-segmentation-toy-dataset</a></li>
</ul>
<section id="setting-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-directory-paths">Setting the Directory Paths</h3>
<p>We first need to specify a place to store our dataset and a location to download the zip file containing it. The following code creates the folders in the current directory (<code>./</code>). Update the path if that is not suitable for you.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store datasets</span></span>
<span id="cb10-2">dataset_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./Datasets/"</span>)</span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the dataset directory if it does not exist</span></span>
<span id="cb10-4">dataset_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store archive files</span></span>
<span id="cb10-7">archive_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'../Archive'</span></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the archive directory if it does not exist</span></span>
<span id="cb10-9">archive_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb10-12">pd.Series({</span>
<span id="cb10-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Directory:"</span>: dataset_dir, </span>
<span id="cb10-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Directory:"</span>: archive_dir</span>
<span id="cb10-15">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_ee114">
<thead>
</thead>
<tbody>
<tr>
<th id="T_ee114_level0_row0" class="row_heading level0 row0">
Dataset Directory:
</th>
<td id="T_ee114_row0_col0" class="data row0 col0">
Datasets
</td>
</tr>
<tr>
<th id="T_ee114_level0_row1" class="row_heading level0 row1">
Archive Directory:
</th>
<td id="T_ee114_row1_col0" class="data row1 col0">
Datasets/../Archive
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="setting-the-dataset-path" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-dataset-path">Setting the Dataset Path</h3>
<p>Next, we construct the name for the Hugging Face Hub dataset and set where to download and extract the dataset.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the dataset</span></span>
<span id="cb11-2">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labelme-instance-segmentation-toy-dataset'</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb11-5">hf_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'cj-mills/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb11-8">archive_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>archive_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip'</span>)</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb11-11">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the dataset name and paths and converting it to a DataFrame for display</span></span>
<span id="cb11-14">pd.Series({</span>
<span id="cb11-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb11-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Path:"</span>: archive_path, </span>
<span id="cb11-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Path:"</span>: dataset_path</span>
<span id="cb11-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_a4f39">
<thead>
</thead>
<tbody>
<tr>
<th id="T_a4f39_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_a4f39_row0_col0" class="data row0 col0">
cj-mills/labelme-instance-segmentation-toy-dataset
</td>
</tr>
<tr>
<th id="T_a4f39_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_a4f39_row1_col0" class="data row1 col0">
Datasets/../Archive/labelme-instance-segmentation-toy-dataset.zip
</td>
</tr>
<tr>
<th id="T_a4f39_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_a4f39_row2_col0" class="data row2 col0">
Datasets/labelme-instance-segmentation-toy-dataset
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="downloading-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h3>
<p>We can now download the archive file and extract the dataset using the <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#download_file"><code>download_file</code></a> and <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#file_extract"><code>file_extract</code></a> functions from the <code>cjm_psl_utils</code> package. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb12-2">dataset_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>hf_dataset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip"</span></span>
<span id="cb12-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"HuggingFace Dataset URL: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb12-6">delete_archive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the dataset if not present</span></span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset_path.is_dir():</span>
<span id="cb12-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset folder already exists"</span>)</span>
<span id="cb12-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb12-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Downloading dataset..."</span>)</span>
<span id="cb12-13">    download_file(dataset_url, archive_dir)    </span>
<span id="cb12-14">    </span>
<span id="cb12-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extracting dataset..."</span>)</span>
<span id="cb12-16">    file_extract(fname<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>archive_path, dest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_dir)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete the archive if specified</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> delete_archive: archive_path.unlink()</span></code></pre></div>
</section>
<section id="getting-the-image-and-annotation-files" class="level3">
<h3 class="anchored" data-anchor-id="getting-the-image-and-annotation-files">Getting the Image and Annotation Files</h3>
<p>The dataset folder contains sample images and annotation files. Each sample image has its own JSON annotation file.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of image files in the dataset</span></span>
<span id="cb13-2">img_file_paths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_img_files(dataset_path)</span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of JSON files in the dataset</span></span>
<span id="cb13-5">annotation_file_paths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(dataset_path.glob(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'*.json'</span>))</span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the names of the folders using a Pandas DataFrame</span></span>
<span id="cb13-8">pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Image File"</span>: [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.name <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> img_file_paths], </span>
<span id="cb13-9">              <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annotation File"</span>:[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.name <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_file_paths]}).head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Image File
</th>
<th>
Annotation File
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
258421.jpg
</td>
<td>
258421.json
</td>
</tr>
<tr>
<th>
1
</th>
<td>
3075367.jpg
</td>
<td>
3075367.json
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3076319.jpg
</td>
<td>
3076319.json
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3145551.jpg
</td>
<td>
3145551.json
</td>
</tr>
<tr>
<th>
4
</th>
<td>
3176048.jpg
</td>
<td>
3176048.json
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-file-paths" class="level3">
<h3 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h3>
<p>Each image file has a unique name that we can use to locate the corresponding annotation data. We can make a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image more efficiently.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary that maps file names to file paths</span></span>
<span id="cb14-2">img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.stem : <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> img_file_paths}</span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of image files</span></span>
<span id="cb14-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Number of Images: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_dict)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb14-8">pd.DataFrame.from_dict(img_dict, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).head()</span></code></pre></div>
<pre><code>Number of Images: 31</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
Datasets/labelme-instance-segmentation-toy-dataset/258421.jpg
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
Datasets/labelme-instance-segmentation-toy-dataset/3075367.jpg
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
Datasets/labelme-instance-segmentation-toy-dataset/3076319.jpg
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
Datasets/labelme-instance-segmentation-toy-dataset/3145551.jpg
</td>
</tr>
<tr>
<th>
3176048
</th>
<td>
Datasets/labelme-instance-segmentation-toy-dataset/3176048.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="get-image-annotations">Get Image Annotations</h3>
<p>Next, we read the content of each JSON annotation file into a single Pandas DataFrame so we can easily query the annotations.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a generator that yields Pandas DataFrames containing the data from each JSON file</span></span>
<span id="cb16-2">cls_dataframes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (pd.read_json(f, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).transpose() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> f <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(annotation_file_paths))</span>
<span id="cb16-3"></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Concatenate the DataFrames into a single DataFrame</span></span>
<span id="cb16-5">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.concat(cls_dataframes, ignore_index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb16-6"></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assign the image file name as the index for each row</span></span>
<span id="cb16-8">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> row: row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'imagePath'</span>].split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb16-9">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>)</span>
<span id="cb16-10"></span>
<span id="cb16-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Keep only the rows that correspond to the filenames in the 'img_dict' dictionary</span></span>
<span id="cb16-12">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())]</span>
<span id="cb16-13"></span>
<span id="cb16-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the first 5 rows of the DataFrame</span></span>
<span id="cb16-15">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
version
</th>
<th>
flags
</th>
<th>
shapes
</th>
<th>
imagePath
</th>
<th>
imageData
</th>
<th>
imageHeight
</th>
<th>
imageWidth
</th>
</tr>
<tr>
<th>
index
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[404.0, 775.5], [396.5, 766.0], [411.5, 753.0], [411.5, 738.0], [416.5, 731.0], [412.5, 598.0], [419.5, 559.0], [416.0, 554.5], [404.0, 566.5], [387.0, 572.5], [375.5, 566.0], [377.5, 554.0], [405.5, 529.0], [413.5, 504.0], [414.5, 493.0], [386.5, 463.0], [388.5, 453.0], [399.0, 443.5], [413.0, 444.5], [423.5, 453.0], [457.5, 506.0], [452.5, 575.0], [458.5, 607.0], [447.5, 635.0], [444.5, 676.0], [452.5, 764.0], [443.0, 770.5]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[377.0, 775.5], [368.0, 774.5], [346.5, 764.0], [349.5, 751.0], [348.5, 707.0], [358.5, 668.0], [343.5, 651.0], [359.5, 605.0], [379.5, 583.0], [366.00692041522484, 583.3910034602076], [362.5467128027681, 575.7785467128027], [361.85467128027676, 565.3979238754325], [353.2041522491349, 557.0934256055363], [357.7024221453287, 547.4048442906574], [350.7820069204152, 532.5259515570934], [356.31833910034595, 520.7612456747405], [359.7785467128027, 481.31487889273353], [376.3875432525951, 467.47404844290656], [387.4602076124567, 469.5501730103806], [401.3010380622837, 484.08304498269894], [405.79930795847747, 501.038062283737], [394.03460207612454, 505.88235294117646], [394.72664359861585, 519.0311418685121], [399.916955017301, 531.1418685121107], [374.6574394463667, 554.3252595155709], [369.81314878892726, 571.280276816609], [374.31141868512105, 574.0484429065743], [388.152249134948, 574.39446366782], [397.49480968858126, 569.8961937716263], [402.5, 578.0], [410.5, 594.0], [412.5, 668.0], [387.0, 667.5], [375.5, 692.0], [376.5, 738.0], [380.5, 753.0], [388.5, 764.0], [386.5, 772.0]], ‘group_id’: None, ‘description’: None, ‘shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
<td>
258421.jpg
</td>
<td>
None
</td>
<td>
1152
</td>
<td>
768
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[714.0, 766.5], [664.0, 765.5], [654.0, 716.5], [640.0, 765.5], [578.5, 764.0], [578.5, 599.0], [570.5, 587.0], [592.5, 403.0], [583.5, 339.0], [525.5, 278.0], [463.5, 187.0], [423.5, 98.0], [422.5, 72.0], [444.0, 52.5], [460.5, 62.0], [458.5, 104.0], [485.5, 166.0], [581.0, 270.5], [623.0, 295.5], [644.5, 293.0], [630.5, 261.0], [642.5, 193.0], [667.0, 182.5], [707.0, 191.5], [719.5, 249.0], [709.0, 307.5], [774.0, 271.5], [848.5, 176.0], [875.5, 108.0], [867.5, 55.0], [902.0, 63.5], [908.5, 76.0], [902.5, 134.0], [858.5, 233.0], [759.5, 350.0], [736.5, 495.0], [752.5, 614.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[829.0, 466.5], [825.5, 464.0], [824.5, 455.0], [825.5, 425.0], [828.0, 419.5], [833.5, 418.0], [827.5, 417.0], [822.5, 396.0], [825.5, 327.0], [843.5, 313.0], [842.5, 296.0], [833.5, 291.0], [832.5, 270.0], [837.0, 265.5], [856.0, 264.5], [868.5, 277.0], [870.5, 306.0], [881.5, 318.0], [883.5, 329.0], [893.0, 332.5], [899.5, 340.0], [901.5, 367.0], [883.5, 382.0], [849.5, 443.0], [842.5, 448.0], [838.5, 460.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[359.0, 509.5], [355.0, 509.5], [350.5, 502.0], [353.5, 486.0], [349.5, 475.0], [349.5, 449.0], [345.5, 430.0], [339.5, 419.0], [337.5, 394.0], [327.5, 378.0], [331.5, 371.0], [332.5, 357.0], [342.5, 345.0], [345.5, 327.0], [354.0, 313.5], [365.5, 317.0], [366.5, 339.0], [385.0, 350.5], [399.5, 371.0], [398.5, 383.0], [390.0, 391.5], [390.5, 378.0], [383.0, 369.5], [379.5, 370.0], [380.5, 441.0], [376.5, 471.0], [370.0, 464.5], [364.5, 472.0], [362.5, 482.0], [364.5, 504.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}, {‘label’: ‘car’, ‘points’: [[1343.0, 764.5], [964.0, 745.5], [930.0, 764.5], [914.5, 759.0], [904.0, 722.5], [865.0, 706.5], [848.0, 735.5], [801.0, 735.5], [788.5, 699.0], [792.5, 577.0], [821.5, 476.0], [849.5, 454.0], [890.5, 382.0], [930.0, 355.5], [1021.0, 347.5], [1195.0, 358.5], [1287.0, 378.5], [1343.0, 436.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
<td>
3075367.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1344
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[590.0, 1119.0], [508.5, 1119.0], [393.5, 881.0], [363.5, 778.0], [359.5, 738.0], [377.5, 685.0], [420.5, 660.0], [388.5, 650.0], [410.5, 606.0], [412.5, 477.0], [349.5, 383.0], [364.5, 338.0], [341.5, 303.0], [369.5, 313.0], [396.5, 191.0], [449.0, 157.5], [496.0, 169.5], [524.5, 203.0], [534.5, 320.0], [577.5, 380.0], [588.5, 493.0], [635.5, 554.0], [631.5, 567.0], [687.5, 625.0], [704.5, 673.0], [698.5, 743.0], [632.5, 833.0], [618.5, 955.0], [573.5, 1096.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[262.0, 1119.0], [128.5, 1119.0], [131.5, 1089.0], [35.5, 901.0], [11.5, 772.0], [33.5, 686.0], [70.5, 663.0], [34.5, 612.0], [25.5, 569.0], [52.5, 375.0], [97.0, 332.5], [195.5, 306.0], [205.5, 255.0], [192.5, 220.0], [240.0, 154.5], [290.0, 133.5], [323.5, 153.0], [341.5, 209.0], [332.5, 279.0], [294.5, 326.0], [347.5, 357.0], [352.5, 399.0], [400.5, 459.0], [404.5, 517.0], [391.5, 631.0], [344.5, 679.0], [359.5, 719.0], [323.5, 907.0], [224.5, 1082.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
<td>
3076319.jpg
</td>
<td>
None
</td>
<td>
1120
</td>
<td>
768
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[683.0, 398.5], [675.0, 398.5], [671.5, 396.0], [673.5, 378.0], [669.5, 366.0], [669.5, 359.0], [664.5, 346.0], [663.5, 326.0], [661.5, 320.0], [661.5, 312.0], [666.5, 304.0], [662.5, 295.0], [666.0, 283.5], [673.0, 283.5], [674.5, 285.0], [676.5, 289.0], [676.5, 297.0], [681.5, 302.0], [685.5, 313.0], [686.5, 336.0], [683.5, 344.0], [685.5, 395.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[649.0, 398.5], [644.0, 398.5], [641.5, 396.0], [640.5, 387.0], [644.5, 379.0], [650.5, 358.0], [650.5, 351.0], [644.5, 335.0], [644.5, 323.0], [646.5, 316.0], [644.5, 300.0], [648.5, 291.0], [654.0, 288.5], [661.5, 295.0], [662.5, 298.0], [658.5, 309.0], [662.5, 316.0], [664.5, 324.0], [665.5, 349.0], [669.5, 364.0], [665.5, 383.0], [666.5, 396.0], [663.0, 397.5], [659.5, 392.0], [662.5, 375.0], [662.5, 364.0], [660.0, 361.5], [649.5, 383.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
<td>
3145551.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1184
</td>
</tr>
<tr>
<th>
3176048
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[661.0, 436.5], [659.5, 436.0], [660.5, 432.0], [660.5, 396.0], [659.5, 392.0], [663.5, 376.0], [661.0, 373.5], [658.0, 373.5], [650.0, 377.5], [641.0, 377.5], [640.5, 376.0], [647.0, 372.5], [651.0, 372.5], [656.0, 370.5], [666.0, 365.5], [667.5, 364.0], [667.5, 359.0], [670.0, 356.5], [674.0, 356.5], [677.5, 360.0], [676.5, 367.0], [682.5, 374.0], [683.5, 389.0], [681.0, 390.5], [678.5, 388.0], [678.5, 385.0], [677.5, 385.0], [677.5, 390.0], [673.5, 395.0], [673.5, 408.0], [671.5, 411.0], [670.5, 420.0], [668.5, 425.0], [668.5, 433.0], [669.5, 434.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[562.0, 464.5], [552.0, 464.5], [550.5, 462.0], [553.5, 454.0], [550.5, 433.0], [558.5, 402.0], [558.5, 389.0], [561.5, 380.0], [557.0, 372.5], [549.0, 374.5], [537.0, 372.5], [533.0, 377.5], [532.5, 371.0], [529.5, 368.0], [542.0, 365.5], [551.0, 366.5], [562.0, 361.5], [567.0, 361.5], [568.5, 360.0], [567.5, 346.0], [572.0, 342.5], [577.0, 342.5], [582.5, 348.0], [581.5, 360.0], [591.5, 372.0], [593.5, 386.0], [592.0, 388.5], [587.0, 388.5], [585.5, 391.0], [578.5, 419.0], [572.5, 434.0], [571.5, 445.0], [566.5, 454.0], [565.5, 462.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
<td>
3176048.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1152
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>The source JSON content corresponding to the first row in the DataFrame is available below:</p>
<div style="overflow-x:auto; max-height:500px">
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb17-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-2">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"version"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"5.3.1"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-3">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"flags"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{},</span></span>
<span id="cb17-4">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"shapes"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-6">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-7">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"points"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-8">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-9">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">404.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-10">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">775.5</span></span>
<span id="cb17-11">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-12">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-13">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">396.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-14">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">766.0</span></span>
<span id="cb17-15">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-16">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-17">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">411.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-18">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">753.0</span></span>
<span id="cb17-19">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-20">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-21">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">411.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-22">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">738.0</span></span>
<span id="cb17-23">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-24">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-25">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">416.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-26">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">731.0</span></span>
<span id="cb17-27">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-28">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-29">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">412.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-30">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">598.0</span></span>
<span id="cb17-31">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-32">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-33">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">419.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-34">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">559.0</span></span>
<span id="cb17-35">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-36">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-37">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">416.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-38">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">554.5</span></span>
<span id="cb17-39">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-40">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-41">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">404.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-42">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">566.5</span></span>
<span id="cb17-43">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-44">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-45">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">387.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-46">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">572.5</span></span>
<span id="cb17-47">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-48">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-49">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">375.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-50">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">566.0</span></span>
<span id="cb17-51">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-52">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-53">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">377.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-54">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">554.0</span></span>
<span id="cb17-55">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-56">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-57">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">405.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-58">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">529.0</span></span>
<span id="cb17-59">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-60">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-61">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">413.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-62">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">504.0</span></span>
<span id="cb17-63">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-64">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-65">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">414.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-66">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">493.0</span></span>
<span id="cb17-67">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-68">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-69">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">386.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-70">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">463.0</span></span>
<span id="cb17-71">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-72">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-73">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">388.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-74">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">453.0</span></span>
<span id="cb17-75">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-76">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-77">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">399.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-78">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">443.5</span></span>
<span id="cb17-79">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-80">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-81">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">413.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-82">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">444.5</span></span>
<span id="cb17-83">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-84">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-85">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">423.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-86">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">453.0</span></span>
<span id="cb17-87">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-88">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-89">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">457.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-90">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">506.0</span></span>
<span id="cb17-91">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-92">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-93">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">452.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-94">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">575.0</span></span>
<span id="cb17-95">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-96">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-97">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">458.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-98">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">607.0</span></span>
<span id="cb17-99">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-100">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-101">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">447.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-102">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">635.0</span></span>
<span id="cb17-103">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-104">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-105">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">444.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-106">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">676.0</span></span>
<span id="cb17-107">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-108">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-109">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">452.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-110">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">764.0</span></span>
<span id="cb17-111">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-112">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-113">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">443.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-114">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">770.5</span></span>
<span id="cb17-115">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb17-116">      <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-117">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"group_id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-118">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-119">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"shape_type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"polygon"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-120">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"flags"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{}</span></span>
<span id="cb17-121">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-122">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-123">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-124">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"points"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-125">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-126">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">377.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-127">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">775.5</span></span>
<span id="cb17-128">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-129">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-130">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">368.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-131">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">774.5</span></span>
<span id="cb17-132">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-133">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-134">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">346.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-135">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">764.0</span></span>
<span id="cb17-136">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-137">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-138">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">349.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-139">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">751.0</span></span>
<span id="cb17-140">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-141">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-142">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">348.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-143">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">707.0</span></span>
<span id="cb17-144">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-145">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-146">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">358.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-147">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">668.0</span></span>
<span id="cb17-148">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-149">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-150">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">343.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-151">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">651.0</span></span>
<span id="cb17-152">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-153">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-154">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">359.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-155">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">605.0</span></span>
<span id="cb17-156">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-157">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-158">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">379.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-159">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">583.0</span></span>
<span id="cb17-160">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-161">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-162">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">366.00692041522484</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-163">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">583.3910034602076</span></span>
<span id="cb17-164">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-165">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-166">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">362.5467128027681</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-167">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">575.7785467128027</span></span>
<span id="cb17-168">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-169">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-170">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">361.85467128027676</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-171">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">565.3979238754325</span></span>
<span id="cb17-172">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-173">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-174">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">353.2041522491349</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-175">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">557.0934256055363</span></span>
<span id="cb17-176">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-177">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-178">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">357.7024221453287</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-179">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">547.4048442906574</span></span>
<span id="cb17-180">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-181">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-182">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">350.7820069204152</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-183">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">532.5259515570934</span></span>
<span id="cb17-184">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-185">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-186">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">356.31833910034595</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-187">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">520.7612456747405</span></span>
<span id="cb17-188">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-189">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-190">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">359.7785467128027</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-191">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">481.31487889273353</span></span>
<span id="cb17-192">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-193">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-194">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">376.3875432525951</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-195">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">467.47404844290656</span></span>
<span id="cb17-196">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-197">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-198">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">387.4602076124567</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-199">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">469.5501730103806</span></span>
<span id="cb17-200">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-201">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-202">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">401.3010380622837</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-203">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">484.08304498269894</span></span>
<span id="cb17-204">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-205">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-206">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">405.79930795847747</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-207">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">501.038062283737</span></span>
<span id="cb17-208">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-209">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-210">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">394.03460207612454</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-211">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">505.88235294117646</span></span>
<span id="cb17-212">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-213">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-214">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">394.72664359861585</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-215">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">519.0311418685121</span></span>
<span id="cb17-216">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-217">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-218">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">399.916955017301</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-219">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">531.1418685121107</span></span>
<span id="cb17-220">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-221">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-222">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">374.6574394463667</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-223">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">554.3252595155709</span></span>
<span id="cb17-224">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-225">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-226">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">369.81314878892726</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-227">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">571.280276816609</span></span>
<span id="cb17-228">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-229">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-230">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">374.31141868512105</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-231">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">574.0484429065743</span></span>
<span id="cb17-232">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-233">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-234">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">388.152249134948</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-235">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">574.39446366782</span></span>
<span id="cb17-236">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-237">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-238">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">397.49480968858126</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-239">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">569.8961937716263</span></span>
<span id="cb17-240">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-241">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-242">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">402.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-243">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">578.0</span></span>
<span id="cb17-244">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-245">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-246">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">410.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-247">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">594.0</span></span>
<span id="cb17-248">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-249">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-250">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">412.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-251">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">668.0</span></span>
<span id="cb17-252">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-253">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-254">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">387.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-255">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">667.5</span></span>
<span id="cb17-256">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-257">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-258">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">375.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-259">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">692.0</span></span>
<span id="cb17-260">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-261">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-262">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">376.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-263">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">738.0</span></span>
<span id="cb17-264">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-265">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-266">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">380.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-267">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">753.0</span></span>
<span id="cb17-268">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-269">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-270">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">388.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-271">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">764.0</span></span>
<span id="cb17-272">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-273">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-274">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">386.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-275">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">772.0</span></span>
<span id="cb17-276">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb17-277">      <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-278">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"group_id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-279">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-280">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"shape_type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"polygon"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-281">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"flags"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{}</span></span>
<span id="cb17-282">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-283">  <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-284">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imagePath"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"258421.jpg"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-285">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imageData"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-286">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imageHeight"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1152</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-287">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imageWidth"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">768</span></span>
<span id="cb17-288"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
<hr>
<p>The segmentation polygon annotation are in <code>[[x1,y1], [x2,y2], ..., [xn,yn]]</code> format.</p>
<p>With the annotations loaded, we can start inspecting our dataset.</p>
</section>
<section id="inspecting-the-class-distribution" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-the-class-distribution">Inspecting the Class Distribution</h3>
<p>First, we get the names of all the classes in our dataset and inspect the distribution of samples among these classes. This step is not strictly necessary for the toy dataset but is worth doing for real-world projects. A balanced dataset (where each class has approximately the same number of instances) is ideal for training a machine-learning model.</p>
<section id="get-image-classes" class="level4">
<h4 class="anchored" data-anchor-id="get-image-classes">Get image classes</h4>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Explode the 'shapes' column in the annotation_df dataframe</span></span>
<span id="cb18-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the resulting series to a dataframe</span></span>
<span id="cb18-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the pandas Series function to the 'shapes' column of the dataframe</span></span>
<span id="cb18-4">shapes_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>].explode().to_frame().shapes.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)</span>
<span id="cb18-5"></span>
<span id="cb18-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb18-7">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shapes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>].unique().tolist()</span>
<span id="cb18-8"></span>
<span id="cb18-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display labels using a Pandas DataFrame</span></span>
<span id="cb18-10">pd.DataFrame(class_names)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
person
</td>
</tr>
<tr>
<th>
1
</th>
<td>
car
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visualize-the-class-distribution" class="level4">
<h4 class="anchored" data-anchor-id="visualize-the-class-distribution">Visualize the class distribution</h4>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the number of samples for each object class</span></span>
<span id="cb19-2">class_counts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shapes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>].value_counts()</span>
<span id="cb19-3"></span>
<span id="cb19-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the distribution</span></span>
<span id="cb19-5">class_counts.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bar'</span>)</span>
<span id="cb19-6">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class distribution'</span>)</span>
<span id="cb19-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Count'</span>)</span>
<span id="cb19-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Classes'</span>)</span>
<span id="cb19-9">plt.xticks(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_counts.index)), class_counts.index, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the x-axis tick labels</span></span>
<span id="cb19-10">plt.show()</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/images/output_21_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Note the class distribution is quite imbalanced between the <code>person</code> and <code>car</code> classes. For a real dataset, you would want these to be much closer.</p>
</section>
</section>
<section id="visualizing-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-image-annotations">Visualizing Image Annotations</h3>
<p>In this section, we will annotate a single image with its segmentation masks and bounding boxes using torchvision’s <code>BoundingBoxes</code> and <code>Mask</code> classes and <code>draw_bounding_boxes</code> and <code>draw_segmentation_masks</code> function.</p>
<section id="generate-a-color-map" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-color-map">Generate a color map</h4>
<p>While not required, assigning a unique color to bounding boxes and segmentation masks for each object class enhances visual distinction, allowing for easier identification of different objects in the scene. We can use the <a href="https://distinctipy.readthedocs.io/en/latest/"><code>distinctipy</code></a> package to generate a visually distinct colormap.</p>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb20-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distinctipy.get_colors(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb20-3"></span>
<span id="cb20-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the color map in integer format</span></span>
<span id="cb20-5">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colors]</span>
<span id="cb20-6"></span>
<span id="cb20-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a color swatch to visualize the color map</span></span>
<span id="cb20-8">distinctipy.color_swatch(colors)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/images/output_24_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a font file</h4>
<p>The <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function included with torchvision uses a pretty small font size. We can increase the font size if we use a custom font. Font files are available on sites like <a href="https://fonts.google.com/">Google Fonts</a>, or we can use one included with the operating system.</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb21-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb21-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
<pre><code>The file ./KFOlCnqEu92Fr1MmEU9vAw.ttf already exists and overwrite is set to False.</code></pre>
</section>
<section id="define-the-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-the-bounding-box-annotation-function">Define the bounding box annotation function</h4>
<p>We can make a partial function using <code>draw_bounding_boxes</code> since we’ll use the same box thickness and font each time we visualize bounding boxes.</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">draw_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(draw_bounding_boxes, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, font<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>font_file, font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
</section>
</section>
<section id="selecting-a-sample-image" class="level3">
<h3 class="anchored" data-anchor-id="selecting-a-sample-image">Selecting a Sample Image</h3>
<p>We can use the unique ID for an image in the image dictionary to get the image file path and the associated annotations from the annotation DataFrame.</p>
<section id="load-the-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="load-the-sample-image">Load the sample image</h4>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the file ID of the first image file</span></span>
<span id="cb24-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb24-3"></span>
<span id="cb24-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the associated image file as a RGB image</span></span>
<span id="cb24-5">sample_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(img_dict[file_id]).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb24-6"></span>
<span id="cb24-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the dimensions of the image</span></span>
<span id="cb24-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Image Dims: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sample_img<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>size<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb24-9"></span>
<span id="cb24-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Show the image</span></span>
<span id="cb24-11">sample_img</span></code></pre></div>
<pre><code>Image Dims: (768, 1152)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/images/output_31_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="inspect-the-corresponding-annotation-data" class="level4">
<h4 class="anchored" data-anchor-id="inspect-the-corresponding-annotation-data">Inspect the corresponding annotation data</h4>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'</span></span>
<span id="cb26-2">annotation_df.loc[file_id].to_frame()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
258421
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
version
</th>
<td>
5.3.1
</td>
</tr>
<tr>
<th>
flags
</th>
<td>
{}
</td>
</tr>
<tr>
<th>
shapes
</th>
<td>
[{‘label’: ‘person’, ‘points’: [[404.0, 775.5], [396.5, 766.0], [411.5, 753.0], [411.5, 738.0], [416.5, 731.0], [412.5, 598.0], [419.5, 559.0], [416.0, 554.5], [404.0, 566.5], [387.0, 572.5], [375.5, 566.0], [377.5, 554.0], [405.5, 529.0], [413.5, 504.0], [414.5, 493.0], [386.5, 463.0], [388.5, 453.0], [399.0, 443.5], [413.0, 444.5], [423.5, 453.0], [457.5, 506.0], [452.5, 575.0], [458.5, 607.0], [447.5, 635.0], [444.5, 676.0], [452.5, 764.0], [443.0, 770.5]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘polygon’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[377.0, 775.5], [368.0, 774.5], [346.5, 764.0], [349.5, 751.0], [348.5, 707.0], [358.5, 668.0], [343.5, 651.0], [359.5, 605.0], [379.5, 583.0], [366.00692041522484, 583.3910034602076], [362.5467128027681, 575.7785467128027], [361.85467128027676, 565.3979238754325], [353.2041522491349, 557.0934256055363], [357.7024221453287, 547.4048442906574], [350.7820069204152, 532.5259515570934], [356.31833910034595, 520.7612456747405], [359.7785467128027, 481.31487889273353], [376.3875432525951, 467.47404844290656], [387.4602076124567, 469.5501730103806], [401.3010380622837, 484.08304498269894], [405.79930795847747, 501.038062283737], [394.03460207612454, 505.88235294117646], [394.72664359861585, 519.0311418685121], [399.916955017301, 531.1418685121107], [374.6574394463667, 554.3252595155709], [369.81314878892726, 571.280276816609], [374.31141868512105, 574.0484429065743], [388.152249134948, 574.39446366782], [397.49480968858126, 569.8961937716263], [402.5, 578.0], [410.5, 594.0], [412.5, 668.0], [387.0, 667.5], [375.5, 692.0], [376.5, 738.0], [380.5, 753.0], [388.5, 764.0], [386.5, 772.0]], ‘group_id’: None, ‘description’: None, ‘shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
</tr>
<tr>
<th>
imagePath
</th>
<td>
258421.jpg
</td>
</tr>
<tr>
<th>
imageData
</th>
<td>
None
</td>
</tr>
<tr>
<th>
imageHeight
</th>
<td>
1152
</td>
</tr>
<tr>
<th>
imageWidth
</th>
<td>
768
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>The lists of point coordinates in the segmentation annotations are the vertices of a polygon for the individual segmentation masks. We can use these to generate images for each segmentation mask.</p>
</section>
<section id="define-a-function-to-convert-segmentation-polygons-to-images" class="level4">
<h4 class="anchored" data-anchor-id="define-a-function-to-convert-segmentation-polygons-to-images">Define a function to convert segmentation polygons to images</h4>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> create_polygon_mask(image_size, vertices):</span>
<span id="cb27-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb27-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Create a grayscale image with a white polygonal area on a black background.</span></span>
<span id="cb27-4"></span>
<span id="cb27-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parameters:</span></span>
<span id="cb27-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - image_size (tuple): A tuple representing the dimensions (width, height) of the image.</span></span>
<span id="cb27-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - vertices (list): A list of tuples, each containing the x, y coordinates of a vertex</span></span>
<span id="cb27-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                        of the polygon. Vertices should be in clockwise or counter-clockwise order.</span></span>
<span id="cb27-9"></span>
<span id="cb27-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb27-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - PIL.Image.Image: A PIL Image object containing the polygonal mask.</span></span>
<span id="cb27-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb27-13"></span>
<span id="cb27-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new black image with the given dimensions</span></span>
<span id="cb27-15">    mask_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.new(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'L'</span>, image_size, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb27-16">    </span>
<span id="cb27-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Draw the polygon on the image. The area inside the polygon will be white (255).</span></span>
<span id="cb27-18">    ImageDraw.Draw(mask_img, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'L'</span>).polygon(vertices, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>))</span>
<span id="cb27-19"></span>
<span id="cb27-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the image with the drawn polygon</span></span>
<span id="cb27-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> mask_img</span></code></pre></div>
</section>
<section id="annotate-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="annotate-sample-image">Annotate sample image</h4>
<p>We can now generate the segmentation mask images and feed those to the <code>draw_segmentation_mask</code> function.</p>
<p>We can use the <a href="https://pytorch.org/vision/stable/generated/torchvision.ops.masks_to_boxes.html#torchvision.ops.masks_to_boxes"><code>masks_to_boxes</code></a> function included with torchvision to generate bounding box annotations in the <code>[top-left X, top-left Y, bottom-right X, bottom-right Y]</code> format from the segmentation masks. That is the same format the <code>draw_bounding_boxes</code> function expects so we can use the output directly.</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels for the sample</span></span>
<span id="cb28-2">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb28-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the polygon points for segmentation mask</span></span>
<span id="cb28-4">shape_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb28-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Format polygon points for PIL</span></span>
<span id="cb28-6">xy_coords <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(p) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> points] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> points <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> shape_points]</span>
<span id="cb28-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate mask images from polygons</span></span>
<span id="cb28-8">mask_imgs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [create_polygon_mask(sample_img.size, xy) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> xy <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> xy_coords]</span>
<span id="cb28-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert mask images to tensors</span></span>
<span id="cb28-10">masks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.concat([Mask(transforms.PILToTensor()(mask_img), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> mask_img <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> mask_imgs])</span>
<span id="cb28-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate bounding box annotations from segmentation masks</span></span>
<span id="cb28-12">bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torchvision.ops.masks_to_boxes(masks)</span>
<span id="cb28-13"></span>
<span id="cb28-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with segmentation masks</span></span>
<span id="cb28-15">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_segmentation_masks(</span>
<span id="cb28-16">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sample_img), </span>
<span id="cb28-17">    masks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>masks, </span>
<span id="cb28-18">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb28-19">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb28-20">)</span>
<span id="cb28-21"></span>
<span id="cb28-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb28-23">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb28-24">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>annotated_tensor, </span>
<span id="cb28-25">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>bboxes, </span>
<span id="cb28-26">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, </span>
<span id="cb28-27">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb28-28">)</span>
<span id="cb28-29"></span>
<span id="cb28-30">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/images/output_37_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We have loaded the dataset, inspected its class distribution, and visualized the annotations for a sample image. In the final section, we will cover how to augment images using torchvision’s Transforms V2 API and create a custom Dataset class for training.</p>
</section>
</section>
</section>
<section id="preparing-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data">Preparing the Data</h2>
<p>In this section, we will first walk through a single example of how to apply augmentations to a single annotated image using torchvision’s Transforms V2 API before putting everything together in a custom Dataset class.</p>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h3>
<p>Here, we will define some data augmentations to apply to images during training. I created a few custom image transforms to help streamline the code.</p>
<p>The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#customrandomioucrop">first</a> extends the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.RandomIoUCrop.html#torchvision.transforms.v2.RandomIoUCrop"><code>RandomIoUCrop</code></a> transform included with torchvision to give the user more control over how much it crops into bounding box areas. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#resizemax">second</a> resizes images based on their largest dimension rather than their smallest. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#padsquare">third</a> applies square padding and allows the padding to be applied equally on both sides or randomly split between the two sides.</p>
<p>All three are available through the <a href="https://cj-mills.github.io/cjm-torchvision-tfms/"><code>cjm-torchvision-tfms</code></a> package.</p>
<section id="set-training-image-size" class="level4">
<h4 class="anchored" data-anchor-id="set-training-image-size">Set training image size</h4>
<p>Next, we will specify the image size to use during training.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set training image size</span></span>
<span id="cb29-2">train_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span></span></code></pre></div>
</section>
<section id="initialize-custom-transforms" class="level4">
<h4 class="anchored" data-anchor-id="initialize-custom-transforms">Initialize custom transforms</h4>
<p>Now, we can initialize the transform objects.</p>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomIoUCrop object</span></span>
<span id="cb30-2">iou_crop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomRandomIoUCrop(min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb30-3">                               max_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, </span>
<span id="cb30-4">                               min_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, </span>
<span id="cb30-5">                               max_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, </span>
<span id="cb30-6">                               sampler_options<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb30-7">                               trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb30-8">                               jitter_factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)</span>
<span id="cb30-9"></span>
<span id="cb30-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `ResizeMax` object</span></span>
<span id="cb30-11">resize_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ResizeMax(max_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_sz)</span>
<span id="cb30-12"></span>
<span id="cb30-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `PadSquare` object</span></span>
<span id="cb30-14">pad_square <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PadSquare(shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
</section>
<section id="test-the-transforms" class="level4">
<h4 class="anchored" data-anchor-id="test-the-transforms">Test the transforms</h4>
<p>Torchvision’s V2 image transforms take an image and a <code>targets</code> dictionary. The <code>targets</code> dictionary contains the annotations and labels for the image.</p>
<p>We will pass input through the <code>CustomRandomIoUCrop</code> transform first and then through <code>ResizeMax</code> and <code>PadSquare</code>. We can pass the result through a final resize operation to ensure both sides match the <code>train_sz</code> value.</p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels for the sample</span></span>
<span id="cb31-2">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb31-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the polygon points for segmentation mask</span></span>
<span id="cb31-4">shape_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb31-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Format polygon points for PIL</span></span>
<span id="cb31-6">xy_coords <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(p) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> points] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> points <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> shape_points]</span>
<span id="cb31-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate mask images from polygons</span></span>
<span id="cb31-8">mask_imgs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [create_polygon_mask(sample_img.size, xy) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> xy <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> xy_coords]</span>
<span id="cb31-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert mask images to tensors</span></span>
<span id="cb31-10">masks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.concat([Mask(transforms.PILToTensor()(mask_img), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> mask_img <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> mask_imgs])</span>
<span id="cb31-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate bounding box annotations from segmentation masks</span></span>
<span id="cb31-12">bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torchvision.ops.masks_to_boxes(masks), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb31-13"></span>
<span id="cb31-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get colors for dataset sample</span></span>
<span id="cb31-15">sample_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb31-16"></span>
<span id="cb31-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare mask and bounding box targets</span></span>
<span id="cb31-18">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb31-19">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>: Mask(masks), </span>
<span id="cb31-20">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: bboxes, </span>
<span id="cb31-21">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.Tensor([class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])</span>
<span id="cb31-22">}</span>
<span id="cb31-23"></span>
<span id="cb31-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Crop the image</span></span>
<span id="cb31-25">cropped_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iou_crop(sample_img, targets)</span>
<span id="cb31-26"></span>
<span id="cb31-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Resize the image</span></span>
<span id="cb31-28">resized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_max(cropped_img, targets)</span>
<span id="cb31-29"></span>
<span id="cb31-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pad the image</span></span>
<span id="cb31-31">padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_square(resized_img, targets)</span>
<span id="cb31-32"></span>
<span id="cb31-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the padded image is the target size</span></span>
<span id="cb31-34">resize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb31-35">resized_padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize(padded_img, targets)</span>
<span id="cb31-36">sanitized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(resized_padded_img, targets)</span>
<span id="cb31-37"></span>
<span id="cb31-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with segmentation masks</span></span>
<span id="cb31-39">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_segmentation_masks(</span>
<span id="cb31-40">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sanitized_img), </span>
<span id="cb31-41">    masks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>], </span>
<span id="cb31-42">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb31-43">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors</span>
<span id="cb31-44">)</span>
<span id="cb31-45"></span>
<span id="cb31-46"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb31-47">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb31-48">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>annotated_tensor, </span>
<span id="cb31-49">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb31-50">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb31-51">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors</span>
<span id="cb31-52">)</span>
<span id="cb31-53"></span>
<span id="cb31-54"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># # Display the annotated image</span></span>
<span id="cb31-55">display(tensor_to_pil(annotated_tensor))</span>
<span id="cb31-56"></span>
<span id="cb31-57">pd.Series({</span>
<span id="cb31-58">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image:"</span>: sample_img.size,</span>
<span id="cb31-59">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cropped Image:"</span>: cropped_img.size,</span>
<span id="cb31-60">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Image:"</span>: resized_img.size,</span>
<span id="cb31-61">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Padded Image:"</span>: padded_img.size,</span>
<span id="cb31-62">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Padded Image:"</span>: resized_padded_img.size,</span>
<span id="cb31-63">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/images/output_45_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_6ce5b">
<thead>
</thead>
<tbody>
<tr>
<th id="T_6ce5b_level0_row0" class="row_heading level0 row0">
Source Image:
</th>
<td id="T_6ce5b_row0_col0" class="data row0 col0">
(768, 1152)
</td>
</tr>
<tr>
<th id="T_6ce5b_level0_row1" class="row_heading level0 row1">
Cropped Image:
</th>
<td id="T_6ce5b_row1_col0" class="data row1 col0">
(403, 484)
</td>
</tr>
<tr>
<th id="T_6ce5b_level0_row2" class="row_heading level0 row2">
Resized Image:
</th>
<td id="T_6ce5b_row2_col0" class="data row2 col0">
(426, 511)
</td>
</tr>
<tr>
<th id="T_6ce5b_level0_row3" class="row_heading level0 row3">
Padded Image:
</th>
<td id="T_6ce5b_row3_col0" class="data row3 col0">
(511, 511)
</td>
</tr>
<tr>
<th id="T_6ce5b_level0_row4" class="row_heading level0 row4">
Resized Padded Image:
</th>
<td id="T_6ce5b_row4_col0" class="data row4 col0">
(512, 512)
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Now that we know how to apply data augmentations, we can put all the steps we’ve covered into a custom Dataset class.</p>
</section>
</section>
<section id="training-dataset-class" class="level3">
<h3 class="anchored" data-anchor-id="training-dataset-class">Training Dataset Class</h3>
<p>The following custom Dataset class is responsible for loading a single image, preparing the associated annotations, applying any image transforms, and returning the final <code>image</code> tensor and its <code>target</code> dictionary during training.</p>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> LabelMeInstSegDataset(Dataset):</span>
<span id="cb32-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A PyTorch Dataset class for handling LabelMe instance segmentation data.</span></span>
<span id="cb32-4"></span>
<span id="cb32-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Attributes:</span></span>
<span id="cb32-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _img_keys (list): A list of image keys identifying the images.</span></span>
<span id="cb32-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _annotation_df (DataFrame): A pandas DataFrame containing the annotations for each image.</span></span>
<span id="cb32-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _img_dict (dict): A dictionary mapping image keys to their corresponding file paths.</span></span>
<span id="cb32-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _class_to_idx (dict): A dictionary mapping class names to their respective indices.</span></span>
<span id="cb32-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _transforms (callable, optional): A function/transform that takes in an image and its target</span></span>
<span id="cb32-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                                           and returns a transformed version.</span></span>
<span id="cb32-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb32-13"></span>
<span id="cb32-14">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, img_keys, annotation_df, img_dict, class_to_idx, transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb32-15">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Initializes the LabelMeInstSegDataset object with images, annotations, and optional transforms.</span></span>
<span id="cb32-17"></span>
<span id="cb32-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb32-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_keys (list): List of image keys.</span></span>
<span id="cb32-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation_df (DataFrame): DataFrame with annotations for each image.</span></span>
<span id="cb32-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_dict (dict): Dictionary mapping image keys to image file paths.</span></span>
<span id="cb32-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            class_to_idx (dict): Dictionary mapping class names to class indices.</span></span>
<span id="cb32-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            transforms (callable, optional): Optional transforms to be applied on the images.</span></span>
<span id="cb32-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb32-25">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Dataset, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb32-26">        </span>
<span id="cb32-27">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys</span>
<span id="cb32-28">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df</span>
<span id="cb32-29">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_dict</span>
<span id="cb32-30">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> class_to_idx</span>
<span id="cb32-31">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms</span>
<span id="cb32-32">        </span>
<span id="cb32-33">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__len__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb32-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Returns the total number of items in the dataset."""</span></span>
<span id="cb32-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys)</span>
<span id="cb32-36">        </span>
<span id="cb32-37">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, index):</span>
<span id="cb32-38">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Retrieves an image and its corresponding target (annotations) by index.</span></span>
<span id="cb32-40"></span>
<span id="cb32-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb32-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            index (int): The index of the item.</span></span>
<span id="cb32-43"></span>
<span id="cb32-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb32-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and its target (a dictionary with keys 'masks', 'boxes', 'labels').</span></span>
<span id="cb32-46"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb32-47">        img_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys[index]</span>
<span id="cb32-48">        annotation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df.loc[img_key]</span>
<span id="cb32-49">        image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._load_image_and_target(annotation)</span>
<span id="cb32-50">        </span>
<span id="cb32-51">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms:</span>
<span id="cb32-52">            image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms(image, target)</span>
<span id="cb32-53">        </span>
<span id="cb32-54">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, target</span>
<span id="cb32-55"></span>
<span id="cb32-56">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _load_image_and_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, annotation):</span>
<span id="cb32-57">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-58"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Loads an image and its corresponding target data based on the given annotation.</span></span>
<span id="cb32-59"></span>
<span id="cb32-60"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb32-61"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation (DataFrame row): The annotation row corresponding to an image.</span></span>
<span id="cb32-62"></span>
<span id="cb32-63"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb32-64"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and its target (a dictionary with keys 'masks', 'boxes', 'labels').</span></span>
<span id="cb32-65"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb32-66">        filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict[annotation.name]</span>
<span id="cb32-67">        image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(filepath).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb32-68">        </span>
<span id="cb32-69">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract labels for each shape in the annotation and convert them to tensor</span></span>
<span id="cb32-70">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb32-71">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.Tensor([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx[label] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])</span>
<span id="cb32-72">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> labels.to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.int64)</span>
<span id="cb32-73"></span>
<span id="cb32-74">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Process shape points to create masks</span></span>
<span id="cb32-75">        shape_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb32-76">        xy_coords <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(p) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> points] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> points <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> shape_points]</span>
<span id="cb32-77">        mask_imgs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [create_polygon_mask(image.size, xy) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> xy <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> xy_coords]</span>
<span id="cb32-78">        masks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Mask(torch.concat([Mask(transforms.PILToTensor()(mask_img), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> mask_img <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> mask_imgs]))</span>
<span id="cb32-79"></span>
<span id="cb32-80">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create bounding boxes from masks</span></span>
<span id="cb32-81">        bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torchvision.ops.masks_to_boxes(masks), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb32-82"></span>
<span id="cb32-83">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>: masks, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: bboxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: labels}</span></code></pre></div>
</section>
<section id="image-transforms" class="level3">
<h3 class="anchored" data-anchor-id="image-transforms">Image Transforms</h3>
<p>Here, we will specify and organize all the image transforms to apply during training.</p>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms for data augmentation</span></span>
<span id="cb33-2">data_aug_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose(</span>
<span id="cb33-3">    transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb33-4">        iou_crop,</span>
<span id="cb33-5">        transforms.ColorJitter(</span>
<span id="cb33-6">                brightness <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.875</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.125</span>),</span>
<span id="cb33-7">                contrast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb33-8">                saturation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb33-9">                hue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>),</span>
<span id="cb33-10">        ),</span>
<span id="cb33-11">        transforms.RandomGrayscale(),</span>
<span id="cb33-12">        transforms.RandomEqualize(),</span>
<span id="cb33-13">        transforms.RandomPosterize(bits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb33-14">        transforms.RandomHorizontalFlip(p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb33-15">    ],</span>
<span id="cb33-16">)</span>
<span id="cb33-17"></span>
<span id="cb33-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to resize and pad input images</span></span>
<span id="cb33-19">resize_pad_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb33-20">    resize_max, </span>
<span id="cb33-21">    pad_square,</span>
<span id="cb33-22">    transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb33-23">])</span>
<span id="cb33-24"></span>
<span id="cb33-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to sanitize bounding boxes and normalize input data</span></span>
<span id="cb33-26">final_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb33-27">    transforms.ToImage(), </span>
<span id="cb33-28">    transforms.ToDtype(torch.float32, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb33-29">    transforms.SanitizeBoundingBoxes(),</span>
<span id="cb33-30">])</span>
<span id="cb33-31"></span>
<span id="cb33-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the transformations for training and validation datasets</span></span>
<span id="cb33-33">train_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb33-34">    data_aug_tfms, </span>
<span id="cb33-35">    resize_pad_tfm, </span>
<span id="cb33-36">    final_tfms</span>
<span id="cb33-37">])</span></code></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always use the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.SanitizeBoundingBoxes.html#torchvision.transforms.v2.SanitizeBoundingBoxes"><code>SanitizeBoundingBoxes</code></a> transform to clean up annotations after using data augmentations that alter bounding boxes (e.g., cropping, warping, etc.).</p>
</div>
</div>
</section>
<section id="initialize-dataset" class="level3">
<h3 class="anchored" data-anchor-id="initialize-dataset">Initialize Dataset</h3>
<p>Now, we can create the dataset object using the image dictionary, the annotation DataFrame, and the image transforms.</p>
<div class="sourceCode" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mapping from class names to class indices</span></span>
<span id="cb34-2">class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {c: i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(class_names)}</span>
<span id="cb34-3"></span>
<span id="cb34-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Instantiate the dataset using the defined transformations</span></span>
<span id="cb34-5">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LabelMeInstSegDataset(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys()), annotation_df, img_dict, class_to_idx, train_tfms)</span>
<span id="cb34-6"></span>
<span id="cb34-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of samples in the training and validation datasets</span></span>
<span id="cb34-8">pd.Series({</span>
<span id="cb34-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training dataset size:'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataset),</span>
<span id="cb34-10">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_bc8cc">
<thead>
</thead>
<tbody>
<tr>
<th id="T_bc8cc_level0_row0" class="row_heading level0 row0">
Training dataset size:
</th>
<td id="T_bc8cc_row0_col0" class="data row0 col0">
31
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspect-samples" class="level3">
<h3 class="anchored" data-anchor-id="inspect-samples">Inspect Samples</h3>
<p>To close out, we should verify the dataset object works as intended by inspecting the first sample.</p>
<section id="inspect-training-set-sample" class="level4">
<h4 class="anchored" data-anchor-id="inspect-training-set-sample">Inspect training set sample</h4>
<div class="sourceCode" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">dataset_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_dataset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb35-2"></span>
<span id="cb35-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get colors for dataset sample</span></span>
<span id="cb35-4">sample_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb35-5"></span>
<span id="cb35-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with segmentation masks</span></span>
<span id="cb35-7">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_segmentation_masks( </span>
<span id="cb35-8">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.uint8), </span>
<span id="cb35-9">    masks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>], </span>
<span id="cb35-10">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb35-11">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors</span>
<span id="cb35-12">)</span>
<span id="cb35-13"></span>
<span id="cb35-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with bounding boxes</span></span>
<span id="cb35-15">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb35-16">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>annotated_tensor, </span>
<span id="cb35-17">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb35-18">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb35-19">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors</span>
<span id="cb35-20">)</span>
<span id="cb35-21"></span>
<span id="cb35-22">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/images/output_54_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we covered how to load custom segmentation annotations made with the LabelMe annotation tool and work with them using torchvision’s Transforms V2 API. The skills and knowledge you acquired here provide a solid foundation for future instance segmentation projects.</p>
<p>As a next step, perhaps try annotating a custom instance segmentation dataset with LabelMe and loading it with this tutorial’s code. Once you’re comfortable with that, try adapting the code in the following tutorial to train an instance segmentation model on your custom dataset.</p>
<ul>
<li><a href="../../../posts/pytorch-train-mask-rcnn-tutorial/">Training Mask R-CNN Models with PyTorch</a></li>
</ul>
</section>
<section id="recommended-tutorials" class="level2">
<h2 class="anchored" data-anchor-id="recommended-tutorials">Recommended Tutorials</h2>
<ul>
<li><a href="../../../posts/torchvision-labelme-annotation-tutorials/bounding-boxes/"><strong>Working with LabelMe Bounding Box Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with LabelMe bounding box annotations in torchvision for object detection tasks.</li>
<li><a href="http://localhost:3847/posts/torchvision-labelme-annotation-tutorials/keypoints/"><strong>Working with LabelMe Keypoint Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with LabelMe keypoint annotations in torchvision for keypoint estimation tasks.</li>
<li><a href="http://localhost:3847/posts/pytorch-train-mask-rcnn-tutorial/"><strong>Training Mask R-CNN Models with PyTorch</strong></a><strong>:</strong> Learn how to train Mask R-CNN models on custom datasets with PyTorch.</li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>image-annotation</category>
  <category>object-detection</category>
  <category>instance-segmentation</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/</guid>
  <pubDate>Sun, 21 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Working with LabelMe Keypoint Annotations in Torchvision</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/torchvision-labelme-annotation-tutorials/keypoints/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/tutorials/torchvision-annotation-tutorials-series.html"><strong>Torchvision Annotation Tutorials</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Loading and Exploring the Dataset</li>
<li>Preparing the Data</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to this hands-on guide for working with keypoint annotations created with the <a href="https://github.com/labelmeai/labelme">LabelMe annotation tool</a> in <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>. Keypoint annotations mark specific points of interest on an object in an image for training models to recognize and interpret poses, gestures, or significant parts of objects.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/keypoints/images/keypoint-hero-img.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The tutorial walks through setting up a Python environment, loading the raw annotations into a <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a>, annotating and augmenting images using torchvision’s <a href="https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py">Transforms V2 API</a>, and creating a custom <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Dataset</a> class to feed samples to a model.</p>
<p>This guide is suitable for beginners and experienced practitioners, providing the code, explanations, and resources needed to understand and implement each step. By the end, you will have a solid foundation for working with keypoint annotations made with LabelMe for keypoint estimation tasks.</p>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>The tutorial code is available as a <a href="https://jupyter.org/">Jupyter Notebook</a>, which you can run locally or in a cloud-based environment like <a href="https://colab.research.google.com/">Google Colab</a>. I have dedicated tutorials for those new to these platforms or who need guidance setting up:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Setup Guides">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Setup Guides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="../../../posts/google-colab-getting-started-tutorial/"><strong>Getting Started with Google Colab</strong></a></p></li>
<li><p><a href="../../../posts/mamba-getting-started-tutorial-windows/"><strong>Setting Up a Local Python Environment with Mamba for Machine Learning Projects on Windows</strong></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Tutorial Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tutorial Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook:</th>
<th><a href="https://github.com/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/labelme/torchvision-labelme-keypoint-annotations.ipynb">GitHub Repository</a></th>
<th><a href="https://colab.research.google.com/github/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/labelme/torchvision-labelme-keypoint-annotations.ipynb">Open In Colab</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>Before diving into the code, we’ll cover the steps to create a local Python environment and install the necessary dependencies.</p>
<section id="creating-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-python-environment">Creating a Python Environment</h3>
<p>First, we’ll create a Python environment using <a href="https://docs.conda.io/en/latest/">Conda</a>/<a href="https://mamba.readthedocs.io/en/latest/">Mamba</a>. Open a terminal with Conda/Mamba installed and run the following commands:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Conda</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Mamba</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate pytorch-env</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate pytorch-env</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="installing-pytorch">Installing PyTorch</h3>
<p>Next, we’ll install <a href="https://pytorch.org/">PyTorch</a>. Run the appropriate command for your hardware and operating system.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Linux/Windows (CUDA)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Mac</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Linux (CPU)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Windows (CPU)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch with CUDA</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cu121</span></code></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MPS (Metal Performance Shaders) acceleration is available on MacOS 12.3+</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cpu</span></code></pre></div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-additional-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-libraries">Installing Additional Libraries</h3>
<p>We also need to install some additional libraries for our project.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>jupyter</code></td>
<td>An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. (<a href="https://jupyter.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>matplotlib</code></td>
<td>This package provides a comprehensive collection of visualization tools to create high-quality plots, charts, and graphs for data exploration and presentation. (<a href="https://matplotlib.org/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>pandas</code></td>
<td>This package provides fast, powerful, and flexible data analysis and manipulation tools. (<a href="https://pandas.pydata.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>pillow</code></td>
<td>The Python Imaging Library adds image processing capabilities. (<a href="https://pillow.readthedocs.io/en/stable/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>tqdm</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>distinctipy</code></td>
<td>A lightweight python package providing functions to generate colours that are visually distinct from one another. (<a href="https://distinctipy.readthedocs.io/en/latest/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install these additional libraries:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional dependencies</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install distinctipy jupyter matplotlib pandas pillow tqdm</span></code></pre></div>
</section>
<section id="installing-utility-packages" class="level3">
<h3 class="anchored" data-anchor-id="installing-utility-packages">Installing Utility Packages</h3>
<p>We will also install some utility packages I made, which provide shortcuts for routine tasks.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>cjm_pil_utils</code></td>
<td>Some PIL utility functions I frequently use. (<a href="https://cj-mills.github.io/cjm-pil-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_psl_utils</code></td>
<td>Some utility functions using the Python Standard Library. (<a href="https://cj-mills.github.io/cjm-psl-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_pytorch_utils</code></td>
<td>Some utility functions for working with PyTorch. (<a href="https://cj-mills.github.io/cjm-pytorch-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_torchvision_tfms</code></td>
<td>Some custom Torchvision tranforms. (<a href="https://cj-mills.github.io/cjm-torchvision-tfms/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install the utility packages:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional utility packages</span></span>
<span id="cb8-2">pip install cjm_pil_utils cjm_psl_utils cjm_pytorch_utils cjm_torchvision_tfms</span></code></pre></div>
<p>With our environment set up, we can open our Jupyter Notebook and dive into the code.</p>
</section>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python packages into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb9-4"></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb9-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_img_files</span>
<span id="cb9-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file, file_extract</span>
<span id="cb9-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pytorch_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor_to_pil</span>
<span id="cb9-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_torchvision_tfms.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ResizeMax, PadSquare, CustomRandomIoUCrop</span>
<span id="cb9-10"></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the distinctipy module</span></span>
<span id="cb9-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distinctipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> distinctipy</span>
<span id="cb9-13"></span>
<span id="cb9-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import matplotlib for creating plots</span></span>
<span id="cb9-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb9-16"></span>
<span id="cb9-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb9-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-19"></span>
<span id="cb9-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb9-21"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb9-22"></span>
<span id="cb9-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb9-24">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb9-25"></span>
<span id="cb9-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb9-27"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image</span>
<span id="cb9-28"></span>
<span id="cb9-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb9-30"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb9-31"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DataLoader</span>
<span id="cb9-32"></span>
<span id="cb9-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import torchvision dependencies</span></span>
<span id="cb9-34"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision</span>
<span id="cb9-35">torchvision.disable_beta_transforms_warning()</span>
<span id="cb9-36"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BoundingBoxes</span>
<span id="cb9-37"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> draw_bounding_boxes</span>
<span id="cb9-38"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.v2  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb9-39"></span>
<span id="cb9-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import tqdm for progress bar</span></span>
<span id="cb9-41"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm.auto <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
<p>Torchvision provides dedicated <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> subclasses for different annotation types called <a href="https://pytorch.org/vision/stable/tv_tensors.html"><code>TVTensors</code></a>. Torchvision’s V2 transforms use these subclasses to update the annotations based on the applied image augmentations. While there is currently no dedicated TVTensor class for keypoint annotations, we can use the one for <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.BoundingBoxes.html">bounding boxes</a> instead. Torchvision does include a <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_keypoints.html"><code>draw_keypoints</code></a> function, but we might as well stick with the <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function to annotate images.</p>
</section>
<section id="loading-and-exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-and-exploring-the-dataset">Loading and Exploring the Dataset</h2>
<p>After importing the dependencies, we can start working with our data. I annotated a toy dataset with keypoints for this tutorial using images from the free stock photo site <a href="https://www.pexels.com/">Pexels</a>. The dataset is available on <a href="https://huggingface.co/">HuggingFace Hub</a> at the link below:</p>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/datasets/cj-mills/labelme-keypoint-toy-dataset/tree/main">labelme-keypoint-toy-dataset</a></li>
</ul>
<section id="setting-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-directory-paths">Setting the Directory Paths</h3>
<p>We first need to specify a place to store our dataset and a location to download the zip file containing it. The following code creates the folders in the current directory (<code>./</code>). Update the path if that is not suitable for you.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store datasets</span></span>
<span id="cb10-2">dataset_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./Datasets/"</span>)</span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the dataset directory if it does not exist</span></span>
<span id="cb10-4">dataset_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store archive files</span></span>
<span id="cb10-7">archive_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'../Archive'</span></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the archive directory if it does not exist</span></span>
<span id="cb10-9">archive_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb10-12">pd.Series({</span>
<span id="cb10-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Directory:"</span>: dataset_dir, </span>
<span id="cb10-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Directory:"</span>: archive_dir</span>
<span id="cb10-15">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_792fe">
<thead>
</thead>
<tbody>
<tr>
<th id="T_792fe_level0_row0" class="row_heading level0 row0">
Dataset Directory:
</th>
<td id="T_792fe_row0_col0" class="data row0 col0">
Datasets
</td>
</tr>
<tr>
<th id="T_792fe_level0_row1" class="row_heading level0 row1">
Archive Directory:
</th>
<td id="T_792fe_row1_col0" class="data row1 col0">
Datasets/../Archive
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="setting-the-dataset-path" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-dataset-path">Setting the Dataset Path</h3>
<p>Next, we construct the name for the Hugging Face Hub dataset and set where to download and extract the dataset.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the dataset</span></span>
<span id="cb11-2">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labelme-keypoint-toy-dataset'</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb11-5">hf_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'cj-mills/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb11-8">archive_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>archive_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip'</span>)</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb11-11">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the dataset name and paths and converting it to a DataFrame for display</span></span>
<span id="cb11-14">pd.Series({</span>
<span id="cb11-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb11-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Path:"</span>: archive_path, </span>
<span id="cb11-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Path:"</span>: dataset_path</span>
<span id="cb11-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_5c071">
<thead>
</thead>
<tbody>
<tr>
<th id="T_5c071_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_5c071_row0_col0" class="data row0 col0">
cj-mills/labelme-keypoint-toy-dataset
</td>
</tr>
<tr>
<th id="T_5c071_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_5c071_row1_col0" class="data row1 col0">
Datasets/../Archive/labelme-keypoint-toy-dataset.zip
</td>
</tr>
<tr>
<th id="T_5c071_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_5c071_row2_col0" class="data row2 col0">
Datasets/labelme-keypoint-toy-dataset
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="downloading-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h3>
<p>We can now download the archive file and extract the dataset using the <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#download_file"><code>download_file</code></a> and <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#file_extract"><code>file_extract</code></a> functions from the <code>cjm_psl_utils</code> package. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb12-2">dataset_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>hf_dataset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip"</span></span>
<span id="cb12-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"HuggingFace Dataset URL: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb12-6">delete_archive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the dataset if not present</span></span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset_path.is_dir():</span>
<span id="cb12-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset folder already exists"</span>)</span>
<span id="cb12-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb12-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Downloading dataset..."</span>)</span>
<span id="cb12-13">    download_file(dataset_url, archive_dir)    </span>
<span id="cb12-14">    </span>
<span id="cb12-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extracting dataset..."</span>)</span>
<span id="cb12-16">    file_extract(fname<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>archive_path, dest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_dir)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete the archive if specified</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> delete_archive: archive_path.unlink()</span></code></pre></div>
</section>
<section id="getting-the-image-and-annotation-files" class="level3">
<h3 class="anchored" data-anchor-id="getting-the-image-and-annotation-files">Getting the Image and Annotation Files</h3>
<p>The dataset folder contains sample images and annotation files. Each sample image has its own JSON annotation file.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of image files in the dataset</span></span>
<span id="cb13-2">img_file_paths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_img_files(dataset_path)</span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of JSON files in the dataset</span></span>
<span id="cb13-5">annotation_file_paths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(dataset_path.glob(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'*.json'</span>))</span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the names of the folders using a Pandas DataFrame</span></span>
<span id="cb13-8">pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Image File"</span>: [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.name <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> img_file_paths], </span>
<span id="cb13-9">              <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annotation File"</span>:[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.name <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_file_paths]}).head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Image File
</th>
<th>
Annotation File
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
133196.jpg
</td>
<td>
133196.json
</td>
</tr>
<tr>
<th>
1
</th>
<td>
245035.jpg
</td>
<td>
245035.json
</td>
</tr>
<tr>
<th>
2
</th>
<td>
245036.jpg
</td>
<td>
245036.json
</td>
</tr>
<tr>
<th>
3
</th>
<td>
247937.jpg
</td>
<td>
247937.json
</td>
</tr>
<tr>
<th>
4
</th>
<td>
3172614.jpg
</td>
<td>
3172614.json
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-file-paths" class="level3">
<h3 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h3>
<p>Each image file has a unique name that we can use to locate the corresponding annotation data. We can make a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image more efficiently.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary that maps file names to file paths</span></span>
<span id="cb14-2">img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.stem : <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> img_file_paths}</span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of image files</span></span>
<span id="cb14-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Number of Images: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_dict)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb14-8">pd.DataFrame.from_dict(img_dict, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).head()</span></code></pre></div>
<pre class="text"><code>Number of Images: 38</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
133196
</th>
<td>
Datasets/labelme-keypoint-toy-dataset/133196.jpg
</td>
</tr>
<tr>
<th>
245035
</th>
<td>
Datasets/labelme-keypoint-toy-dataset/245035.jpg
</td>
</tr>
<tr>
<th>
245036
</th>
<td>
Datasets/labelme-keypoint-toy-dataset/245036.jpg
</td>
</tr>
<tr>
<th>
247937
</th>
<td>
Datasets/labelme-keypoint-toy-dataset/247937.jpg
</td>
</tr>
<tr>
<th>
3172614
</th>
<td>
Datasets/labelme-keypoint-toy-dataset/3172614.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="get-image-annotations">Get Image Annotations</h3>
<p>Next, we read the content of each JSON annotation file into a single Pandas DataFrame so we can easily query the annotations.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a generator that yields Pandas DataFrames containing the data from each JSON file</span></span>
<span id="cb16-2">cls_dataframes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (pd.read_json(f, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).transpose() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> f <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(annotation_file_paths))</span>
<span id="cb16-3"></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Concatenate the DataFrames into a single DataFrame</span></span>
<span id="cb16-5">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.concat(cls_dataframes, ignore_index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb16-6"></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assign the image file name as the index for each row</span></span>
<span id="cb16-8">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> row: row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'imagePath'</span>].split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb16-9">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>)</span>
<span id="cb16-10"></span>
<span id="cb16-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Keep only the rows that correspond to the filenames in the 'img_dict' dictionary</span></span>
<span id="cb16-12">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())]</span>
<span id="cb16-13"></span>
<span id="cb16-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the first 5 rows of the DataFrame</span></span>
<span id="cb16-15">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
version
</th>
<th>
flags
</th>
<th>
shapes
</th>
<th>
imagePath
</th>
<th>
imageData
</th>
<th>
imageHeight
</th>
<th>
imageWidth
</th>
</tr>
<tr>
<th>
index
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
133196
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘nose’, ‘points’: [[386.70731707317077, 297.109756097561]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
<td>
133196.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
960
</td>
</tr>
<tr>
<th>
245035
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘nose’, ‘points’: [[334.4587155963303, 319.57798165137615]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
<td>
245035.jpg
</td>
<td>
None
</td>
<td>
1152
</td>
<td>
768
</td>
</tr>
<tr>
<th>
245036
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘nose’, ‘points’: [[226.8571428571429, 240.80357142857144]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
<td>
245036.jpg
</td>
<td>
None
</td>
<td>
1120
</td>
<td>
768
</td>
</tr>
<tr>
<th>
247937
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘nose’, ‘points’: [[454.6585365853659, 230.03658536585363]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
<td>
247937.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1152
</td>
</tr>
<tr>
<th>
3172614
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘nose’, ‘points’: [[539.4146341463414, 608.0853658536585]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
<td>
3172614.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1152
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>The source JSON content corresponding to the first row in the DataFrame is available below:</p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb17-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-2">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"version"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"5.3.1"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-3">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"flags"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{},</span></span>
<span id="cb17-4">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"shapes"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-6">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nose"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-7">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"points"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-8">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-9">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">386.70731707317077</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-10">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">297.109756097561</span></span>
<span id="cb17-11">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb17-12">      <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-13">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"group_id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-14">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-15">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"shape_type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"point"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-16">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"flags"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{}</span></span>
<span id="cb17-17">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-18">  <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-19">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imagePath"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"133196.jpg"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-20">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imageData"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-21">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imageHeight"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">768</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-22">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imageWidth"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">960</span></span>
<span id="cb17-23"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>With the annotations loaded, we can start inspecting our dataset.</p>
</section>
<section id="inspecting-the-class-distribution" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-the-class-distribution">Inspecting the Class Distribution</h3>
<p>First, we get the names of all the classes in our dataset and inspect the distribution of samples among these classes. This step won’t yield any insights for the toy dataset but is worth doing for real-world projects. A balanced dataset (where each class has approximately the same number of instances) is ideal for training a machine-learning model.</p>
<section id="get-image-classes" class="level4">
<h4 class="anchored" data-anchor-id="get-image-classes">Get image classes</h4>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Explode the 'shapes' column in the annotation_df dataframe</span></span>
<span id="cb18-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the resulting series to a dataframe and rename the 'shapes' column to 'shapes'</span></span>
<span id="cb18-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the pandas Series function to the 'shapes' column of the dataframe</span></span>
<span id="cb18-4">shapes_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>].explode().to_frame().shapes.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)</span>
<span id="cb18-5"></span>
<span id="cb18-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb18-7">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shapes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>].unique().tolist()</span>
<span id="cb18-8"></span>
<span id="cb18-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display labels using a Pandas DataFrame</span></span>
<span id="cb18-10">pd.DataFrame(class_names)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
nose
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visualize-the-class-distribution" class="level4">
<h4 class="anchored" data-anchor-id="visualize-the-class-distribution">Visualize the class distribution</h4>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the number of samples for each object class</span></span>
<span id="cb19-2">class_counts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shapes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>].value_counts()</span>
<span id="cb19-3"></span>
<span id="cb19-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the distribution</span></span>
<span id="cb19-5">class_counts.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bar'</span>)</span>
<span id="cb19-6">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class distribution'</span>)</span>
<span id="cb19-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Count'</span>)</span>
<span id="cb19-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Classes'</span>)</span>
<span id="cb19-9">plt.xticks(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_counts.index)), class_counts.index, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the x-axis tick labels</span></span>
<span id="cb19-10">plt.show()</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/keypoints/images/output_21_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
<section id="visualizing-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-image-annotations">Visualizing Image Annotations</h3>
<p>In this section, we will annotate a single image with its keypoints using torchvision’s <code>BoundingBoxes</code> class and <code>draw_bounding_boxes</code> function.</p>
<section id="generate-a-color-map" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-color-map">Generate a color map</h4>
<p>While not required, assigning a unique color to keypoints for each object class enhances visual distinction, allowing for easier identification of different objects in the scene. We can use the <a href="https://distinctipy.readthedocs.io/en/latest/"><code>distinctipy</code></a> package to generate a visually distinct colormap.</p>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb20-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distinctipy.get_colors(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb20-3"></span>
<span id="cb20-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the color map in integer format</span></span>
<span id="cb20-5">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colors]</span>
<span id="cb20-6"></span>
<span id="cb20-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a color swatch to visualize the color map</span></span>
<span id="cb20-8">distinctipy.color_swatch(colors)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/keypoints/images/output_25_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a font file</h4>
<p>The <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function included with torchvision uses a pretty small font size. We can increase the font size if we use a custom font. Font files are available on sites like <a href="https://fonts.google.com/">Google Fonts</a>, or we can use one included with the operating system.</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb21-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb21-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
</section>
<section id="define-the-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-the-bounding-box-annotation-function">Define the bounding box annotation function</h4>
<p>We can make a partial function using <code>draw_bounding_boxes</code> since we’ll use the same box thickness and font each time we visualize bounding boxes.</p>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">draw_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(draw_bounding_boxes, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, font<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>font_file, font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
</section>
</section>
<section id="selecting-a-sample-image" class="level3">
<h3 class="anchored" data-anchor-id="selecting-a-sample-image">Selecting a Sample Image</h3>
<p>We can use the unique ID for an image in the image dictionary to get the image file path and the associated annotations from the annotation DataFrame.</p>
<section id="load-the-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="load-the-sample-image">Load the sample image</h4>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the file ID of the first image file</span></span>
<span id="cb23-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb23-3"></span>
<span id="cb23-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the associated image file as a RGB image</span></span>
<span id="cb23-5">sample_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(img_dict[file_id]).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb23-6"></span>
<span id="cb23-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the dimensions of the image</span></span>
<span id="cb23-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Image Dims: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sample_img<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>size<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb23-9"></span>
<span id="cb23-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Show the image</span></span>
<span id="cb23-11">sample_img</span></code></pre></div>
<pre class="text"><code>Image Dims: (960, 768)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/keypoints/images/output_33_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="inspect-the-corresponding-annotation-data" class="level4">
<h4 class="anchored" data-anchor-id="inspect-the-corresponding-annotation-data">Inspect the corresponding annotation data</h4>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'</span></span>
<span id="cb25-2">annotation_df.loc[file_id].to_frame()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
133196
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
version
</th>
<td>
5.3.1
</td>
</tr>
<tr>
<th>
flags
</th>
<td>
{}
</td>
</tr>
<tr>
<th>
shapes
</th>
<td>
[{‘label’: ‘nose’, ‘points’: [[386.70731707317077, 297.109756097561]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘point’, ‘flags’: {}}]
</td>
</tr>
<tr>
<th>
imagePath
</th>
<td>
133196.jpg
</td>
</tr>
<tr>
<th>
imageData
</th>
<td>
None
</td>
</tr>
<tr>
<th>
imageHeight
</th>
<td>
768
</td>
</tr>
<tr>
<th>
imageWidth
</th>
<td>
960
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="annotate-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="annotate-sample-image">Annotate sample image</h4>
<p>We can convert our keypoint annotations to bounding boxes by adding values for box width and height, making it <code>[center-x, center-y, width, height]</code> format</p>
<p>The <code>draw_bounding_boxes</code> function expects bounding box annotations in <code>[top-left X, top-left Y, bottom-right X, bottom-right Y]</code> format, so we’ll use the <a href="https://pytorch.org/vision/stable/generated/torchvision.ops.box_convert.html#torchvision.ops.box_convert"><code>box_convert</code></a> function included with torchvision to convert the bounding box annotations from <code>[cx,cy,w,h]</code> to <code>[x,y,x,y]</code> format.</p>
<p>We can reverse this process during training to extract the target keypoints for calculating the loss.</p>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels and keypoint annotations for the sample image</span></span>
<span id="cb26-2">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb26-3">keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(np.array([shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]])).reshape(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb26-4">keypoints_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((keypoints, torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(keypoints), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb26-5"></span>
<span id="cb26-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb26-7">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb26-8">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sample_img), </span>
<span id="cb26-9">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torchvision.ops.box_convert(torch.Tensor(keypoints_bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>),</span>
<span id="cb26-10">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, </span>
<span id="cb26-11">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb26-12">)</span>
<span id="cb26-13"></span>
<span id="cb26-14">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/keypoints/images/output_37_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We have loaded the dataset, inspected its class distribution, and visualized the annotations for a sample image. In the final section, we will cover how to augment images using torchvision’s Transforms V2 API and create a custom Dataset class for training.</p>
</section>
</section>
</section>
<section id="preparing-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data">Preparing the Data</h2>
<p>In this section, we will first walk through a single example of how to apply augmentations to a single annotated image using torchvision’s Transforms V2 API before putting everything together in a custom Dataset class.</p>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h3>
<p>Here, we will define some data augmentations to apply to images during training. I created a few custom image transforms to help streamline the code.</p>
<p>The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#customrandomioucrop">first</a> extends the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.RandomIoUCrop.html#torchvision.transforms.v2.RandomIoUCrop"><code>RandomIoUCrop</code></a> transform included with torchvision to give the user more control over how much it crops into bounding box areas. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#resizemax">second</a> resizes images based on their largest dimension rather than their smallest. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#padsquare">third</a> applies square padding and allows the padding to be applied equally on both sides or randomly split between the two sides.</p>
<p>All three are available through the <a href="https://cj-mills.github.io/cjm-torchvision-tfms/"><code>cjm-torchvision-tfms</code></a> package.</p>
<section id="set-training-image-size" class="level4">
<h4 class="anchored" data-anchor-id="set-training-image-size">Set training image size</h4>
<p>Next, we will specify the image size to use during training.</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set training image size</span></span>
<span id="cb27-2">train_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span></span></code></pre></div>
</section>
<section id="initialize-custom-transforms" class="level4">
<h4 class="anchored" data-anchor-id="initialize-custom-transforms">Initialize custom transforms</h4>
<p>Now, we can initialize the transform objects.</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomIoUCrop object</span></span>
<span id="cb28-2">iou_crop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomRandomIoUCrop(min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb28-3">                               max_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, </span>
<span id="cb28-4">                               min_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, </span>
<span id="cb28-5">                               max_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, </span>
<span id="cb28-6">                               sampler_options<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb28-7">                               trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb28-8">                               jitter_factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)</span>
<span id="cb28-9"></span>
<span id="cb28-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `ResizeMax` object</span></span>
<span id="cb28-11">resize_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ResizeMax(max_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_sz)</span>
<span id="cb28-12"></span>
<span id="cb28-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `PadSquare` object</span></span>
<span id="cb28-14">pad_square <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PadSquare(shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</section>
<section id="test-the-transforms" class="level4">
<h4 class="anchored" data-anchor-id="test-the-transforms">Test the transforms</h4>
<p>Torchvision’s V2 image transforms take an image and a <code>targets</code> dictionary. The <code>targets</code> dictionary contains the annotations and labels for the image.</p>
<p>We will pass input through the <code>CustomRandomIoUCrop</code> transform first and then through <code>ResizeMax</code> and <code>PadSquare</code>. We can pass the result through a final resize operation to ensure both sides match the <code>train_sz</code> value.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare bounding box targets</span></span>
<span id="cb29-2">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb29-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: BoundingBoxes(torchvision.ops.box_convert(keypoints_bboxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>), </span>
<span id="cb29-4">                           <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, </span>
<span id="cb29-5">                           canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), </span>
<span id="cb29-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.Tensor([class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])</span>
<span id="cb29-7">}</span>
<span id="cb29-8"></span>
<span id="cb29-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Crop the image</span></span>
<span id="cb29-10">cropped_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iou_crop(sample_img, targets)</span>
<span id="cb29-11"></span>
<span id="cb29-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Resize the image</span></span>
<span id="cb29-13">resized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_max(cropped_img, targets)</span>
<span id="cb29-14"></span>
<span id="cb29-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pad the image</span></span>
<span id="cb29-16">padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_square(resized_img, targets)</span>
<span id="cb29-17"></span>
<span id="cb29-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the padded image is the target size</span></span>
<span id="cb29-19">resize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb29-20">resized_padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize(padded_img, targets)</span>
<span id="cb29-21">sanitized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(resized_padded_img, targets)</span>
<span id="cb29-22"></span>
<span id="cb29-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb29-24">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb29-25">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sanitized_img), </span>
<span id="cb29-26">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb29-27">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb29-28">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb29-29">)</span>
<span id="cb29-30"></span>
<span id="cb29-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the annotated image</span></span>
<span id="cb29-32">display(tensor_to_pil(annotated_tensor))</span>
<span id="cb29-33"></span>
<span id="cb29-34">pd.Series({</span>
<span id="cb29-35">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image:"</span>: sample_img.size,</span>
<span id="cb29-36">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cropped Image:"</span>: cropped_img.size,</span>
<span id="cb29-37">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Image:"</span>: resized_img.size,</span>
<span id="cb29-38">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Padded Image:"</span>: padded_img.size,</span>
<span id="cb29-39">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Padded Image:"</span>: resized_padded_img.size,</span>
<span id="cb29-40">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/keypoints/images/output_45_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_f49db">
<thead>
</thead>
<tbody>
<tr>
<th id="T_f49db_level0_row0" class="row_heading level0 row0">
Source Image:
</th>
<td id="T_f49db_row0_col0" class="data row0 col0">
(960, 768)
</td>
</tr>
<tr>
<th id="T_f49db_level0_row1" class="row_heading level0 row1">
Cropped Image:
</th>
<td id="T_f49db_row1_col0" class="data row1 col0">
(960, 768)
</td>
</tr>
<tr>
<th id="T_f49db_level0_row2" class="row_heading level0 row2">
Resized Image:
</th>
<td id="T_f49db_row2_col0" class="data row2 col0">
(383, 307)
</td>
</tr>
<tr>
<th id="T_f49db_level0_row3" class="row_heading level0 row3">
Padded Image:
</th>
<td id="T_f49db_row3_col0" class="data row3 col0">
(383, 383)
</td>
</tr>
<tr>
<th id="T_f49db_level0_row4" class="row_heading level0 row4">
Resized Padded Image:
</th>
<td id="T_f49db_row4_col0" class="data row4 col0">
(384, 384)
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Now that we know how to apply data augmentations, we can put all the steps we’ve covered into a custom Dataset class.</p>
</section>
</section>
<section id="training-dataset-class" class="level3">
<h3 class="anchored" data-anchor-id="training-dataset-class">Training Dataset Class</h3>
<p>The following custom Dataset class is responsible for loading a single image, preparing the associated annotations, applying any image transforms, and returning the final <code>image</code> tensor and its <code>target</code> dictionary during training.</p>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> LabelMeKeypointDataset(Dataset):</span>
<span id="cb30-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb30-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A PyTorch Dataset class for handling LabelMe image keypoints.</span></span>
<span id="cb30-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb30-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This class extends PyTorch's Dataset and is designed to work with image data and</span></span>
<span id="cb30-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    associated keypoints annotations. It supports loading images and corresponding</span></span>
<span id="cb30-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    keypoints annotations, and applying transformations.</span></span>
<span id="cb30-8"></span>
<span id="cb30-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Attributes:</span></span>
<span id="cb30-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        img_keys (list): List of image keys.</span></span>
<span id="cb30-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        annotation_df (DataFrame): DataFrame containing annotations for each image.</span></span>
<span id="cb30-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        img_dict (dict): Dictionary mapping image keys to their file paths.</span></span>
<span id="cb30-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        class_to_idx (dict): Dictionary mapping class names to class indices.</span></span>
<span id="cb30-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        transforms (callable, optional): Transformations to be applied to the images and targets.</span></span>
<span id="cb30-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb30-16"></span>
<span id="cb30-17">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, img_keys, annotation_df, img_dict, class_to_idx, transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb30-18">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb30-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Initializes the LabelMeKeypointDataset with image keys, annotations, and other relevant information.</span></span>
<span id="cb30-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb30-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb30-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_keys (list): List of image keys.</span></span>
<span id="cb30-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation_df (DataFrame): DataFrame containing annotations for each image.</span></span>
<span id="cb30-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_dict (dict): Dictionary mapping image keys to their file paths.</span></span>
<span id="cb30-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            class_to_idx (dict): Dictionary mapping class names to class indices.</span></span>
<span id="cb30-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            transforms (callable, optional): Transformations to be applied to the images and targets.</span></span>
<span id="cb30-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb30-28">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Dataset, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb30-29">        </span>
<span id="cb30-30">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys</span>
<span id="cb30-31">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df</span>
<span id="cb30-32">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_dict</span>
<span id="cb30-33">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> class_to_idx</span>
<span id="cb30-34">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms</span>
<span id="cb30-35"></span>
<span id="cb30-36">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.BBOX_DIM <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb30-37"></span>
<span id="cb30-38">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__len__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb30-39">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb30-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns the number of items in the dataset.</span></span>
<span id="cb30-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb30-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb30-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            int: Number of items in the dataset.</span></span>
<span id="cb30-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb30-45">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys)</span>
<span id="cb30-46">        </span>
<span id="cb30-47">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, index):</span>
<span id="cb30-48">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb30-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Retrieves an item from the dataset at the specified index.</span></span>
<span id="cb30-50"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb30-51"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb30-52"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            index (int): Index of the item to retrieve.</span></span>
<span id="cb30-53"></span>
<span id="cb30-54"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb30-55"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and its corresponding target (annotations).</span></span>
<span id="cb30-56"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb30-57">        img_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys[index]</span>
<span id="cb30-58">        annotation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df.loc[img_key]</span>
<span id="cb30-59">        image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._load_image_and_target(annotation)</span>
<span id="cb30-60">        </span>
<span id="cb30-61">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Applying transformations if specified</span></span>
<span id="cb30-62">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms:</span>
<span id="cb30-63">            image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms(image, target)</span>
<span id="cb30-64"></span>
<span id="cb30-65">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fill any missing keypoints with dummy values</span></span>
<span id="cb30-66">        target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._fill_and_order_target(target)</span>
<span id="cb30-67">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, target</span>
<span id="cb30-68"></span>
<span id="cb30-69">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> order_points_by_labels(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, data, label_order):</span>
<span id="cb30-70">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb30-71"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Extracts and orders points from a list of dictionaries based on a given order of labels.</span></span>
<span id="cb30-72"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb30-73"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        :param data: List of dictionaries containing labels and points.</span></span>
<span id="cb30-74"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        :param label_order: List of labels in the desired order.</span></span>
<span id="cb30-75"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        :return: List of points in the specified label order.</span></span>
<span id="cb30-76"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb30-77">        ordered_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb30-78">        label_to_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {item[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>]: item[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> item <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> data}</span>
<span id="cb30-79">    </span>
<span id="cb30-80">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> label_order:</span>
<span id="cb30-81">            points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> label_to_points.get(label)</span>
<span id="cb30-82">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> points <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb30-83">                ordered_points.extend(points)</span>
<span id="cb30-84"></span>
<span id="cb30-85">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> ordered_points</span>
<span id="cb30-86"></span>
<span id="cb30-87">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _load_image_and_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, annotation):</span>
<span id="cb30-88">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb30-89"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Loads an image and its corresponding target (annotations) based on the provided annotation.</span></span>
<span id="cb30-90"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb30-91"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb30-92"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation (DataFrame row): Annotation data for a specific image.</span></span>
<span id="cb30-93"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            Returns:</span></span>
<span id="cb30-94"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tuple: A tuple containing the loaded image and its corresponding target data.</span></span>
<span id="cb30-95"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb30-96">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the image from the file path specified in the annotations</span></span>
<span id="cb30-97">        filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict[annotation.name]</span>
<span id="cb30-98">        image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(filepath).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb30-99"></span>
<span id="cb30-100">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extracting keypoints from the annotation and converting them to a tensor</span></span>
<span id="cb30-101">        keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.order_points_by_labels(annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>], class_to_idx.keys())</span>
<span id="cb30-102">        keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(np.array(keypoints, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float32)).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb30-103">        </span>
<span id="cb30-104">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding an offset to create bounding boxes around keypoints</span></span>
<span id="cb30-105">        keypoints_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((keypoints, torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(keypoints), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.BBOX_DIM), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb30-106">                </span>
<span id="cb30-107">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert bounding box format and create a BoundingBoxes object</span></span>
<span id="cb30-108">        bbox_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torchvision.ops.box_convert(keypoints_bboxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>)</span>
<span id="cb30-109">        boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(bbox_tensor, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb30-110">        </span>
<span id="cb30-111">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create tensor for labels based on the class indices</span></span>
<span id="cb30-112">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.Tensor([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx[label] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> class_to_idx.keys()])</span>
<span id="cb30-113">        </span>
<span id="cb30-114">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: boxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: labels}</span>
<span id="cb30-115"></span>
<span id="cb30-116">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _fill_and_order_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, target):</span>
<span id="cb30-117">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb30-118"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Fills and orders the target bounding boxes and labels based on the class index.</span></span>
<span id="cb30-119"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb30-120"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        This method ensures that each target has a bounding box and label for each class,</span></span>
<span id="cb30-121"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        even if some classes are not present in the original target. Missing classes</span></span>
<span id="cb30-122"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        are filled with dummy values.</span></span>
<span id="cb30-123"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb30-124"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb30-125"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            target (dict): A dictionary containing 'boxes' and 'labels' keys, where</span></span>
<span id="cb30-126"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                           'boxes' is a tensor of bounding boxes and 'labels' is a tensor</span></span>
<span id="cb30-127"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                           of labels corresponding to these boxes.</span></span>
<span id="cb30-128"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb30-129"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb30-130"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            dict: The updated target dictionary with boxes and labels ordered and filled</span></span>
<span id="cb30-131"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                  according to the class index.</span></span>
<span id="cb30-132"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb30-133">    </span>
<span id="cb30-134">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize new boxes with dummy values (-1.0) for each class</span></span>
<span id="cb30-135">        new_boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.full((<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>), <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>)</span>
<span id="cb30-136">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare labels tensor based on the class indices</span></span>
<span id="cb30-137">        new_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx.values()), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb30-138">    </span>
<span id="cb30-139">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate over each class label</span></span>
<span id="cb30-140">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(new_labels):</span>
<span id="cb30-141">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check if the current label exists in the target's labels</span></span>
<span id="cb30-142">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]:</span>
<span id="cb30-143">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Find the index of the current label in the target's labels</span></span>
<span id="cb30-144">                idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> label).nonzero(as_tuple<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb30-145">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assign the corresponding box to the new boxes tensor</span></span>
<span id="cb30-146">                new_boxes[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>][idx]</span>
<span id="cb30-147">    </span>
<span id="cb30-148">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the target dictionary with the new boxes and labels</span></span>
<span id="cb30-149">        target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_boxes</span>
<span id="cb30-150">        target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_labels</span>
<span id="cb30-151">    </span>
<span id="cb30-152">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> target</span></code></pre></div>
</section>
<section id="image-transforms" class="level3">
<h3 class="anchored" data-anchor-id="image-transforms">Image Transforms</h3>
<p>Here, we will specify and organize all the image transforms to apply during training.</p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms for data augmentation</span></span>
<span id="cb31-2">data_aug_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose(</span>
<span id="cb31-3">    transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb31-4">        iou_crop,</span>
<span id="cb31-5">        transforms.ColorJitter(</span>
<span id="cb31-6">                brightness <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.875</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.125</span>),</span>
<span id="cb31-7">                contrast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb31-8">                saturation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb31-9">                hue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>),</span>
<span id="cb31-10">        ),</span>
<span id="cb31-11">        transforms.RandomGrayscale(),</span>
<span id="cb31-12">        transforms.RandomEqualize(),</span>
<span id="cb31-13">        transforms.RandomPosterize(bits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb31-14">        transforms.RandomHorizontalFlip(p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb31-15">    ],</span>
<span id="cb31-16">)</span>
<span id="cb31-17"></span>
<span id="cb31-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to resize and pad input images</span></span>
<span id="cb31-19">resize_pad_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb31-20">    resize_max, </span>
<span id="cb31-21">    pad_square,</span>
<span id="cb31-22">    transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb31-23">])</span>
<span id="cb31-24"></span>
<span id="cb31-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to sanitize bounding boxes and normalize input data</span></span>
<span id="cb31-26">final_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb31-27">    transforms.ToImage(), </span>
<span id="cb31-28">    transforms.ToDtype(torch.float32, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb31-29">    transforms.SanitizeBoundingBoxes(),</span>
<span id="cb31-30">])</span>
<span id="cb31-31"></span>
<span id="cb31-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the transformations for training and validation datasets</span></span>
<span id="cb31-33">train_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb31-34">    data_aug_tfms, </span>
<span id="cb31-35">    resize_pad_tfm, </span>
<span id="cb31-36">    final_tfms</span>
<span id="cb31-37">])</span></code></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always use the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.SanitizeBoundingBoxes.html#torchvision.transforms.v2.SanitizeBoundingBoxes"><code>SanitizeBoundingBoxes</code></a> transform to clean up annotations after using data augmentations that alter bounding boxes (e.g., cropping, warping, etc.).</p>
</div>
</div>
</section>
<section id="initialize-dataset" class="level3">
<h3 class="anchored" data-anchor-id="initialize-dataset">Initialize Dataset</h3>
<p>Now, we can create the dataset object using the image dictionary, the annotation DataFrame, and the image transforms.</p>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mapping from class names to class indices</span></span>
<span id="cb32-2">class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {c: i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(class_names)}</span>
<span id="cb32-3"></span>
<span id="cb32-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Instantiate the dataset using the defined transformations</span></span>
<span id="cb32-5">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LabelMeKeypointDataset(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys()), annotation_df, img_dict, class_to_idx, train_tfms)</span>
<span id="cb32-6"></span>
<span id="cb32-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of samples in the training dataset</span></span>
<span id="cb32-8">pd.Series({</span>
<span id="cb32-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training dataset size:'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataset),</span>
<span id="cb32-10">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_1c8b9">
<thead>
</thead>
<tbody>
<tr>
<th id="T_1c8b9_level0_row0" class="row_heading level0 row0">
Training dataset size:
</th>
<td id="T_1c8b9_row0_col0" class="data row0 col0">
38
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspect-samples" class="level3">
<h3 class="anchored" data-anchor-id="inspect-samples">Inspect Samples</h3>
<p>To close out, we should verify the dataset object works as intended by inspecting the first sample.</p>
<section id="inspect-training-set-sample" class="level4">
<h4 class="anchored" data-anchor-id="inspect-training-set-sample">Inspect training set sample</h4>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a sample image and its target annotations</span></span>
<span id="cb33-2">dataset_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_dataset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb33-3"></span>
<span id="cb33-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sanitize bounding boxes to remove dummy values</span></span>
<span id="cb33-5">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb33-6">targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:])</span>
<span id="cb33-7">sanitized_image, sanitized_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], targets)</span>
<span id="cb33-8"></span>
<span id="cb33-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with the sanitized annotations</span></span>
<span id="cb33-10">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb33-11">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(sanitized_image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.uint8), </span>
<span id="cb33-12">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb33-13">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb33-14">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb33-15">)</span>
<span id="cb33-16"></span>
<span id="cb33-17">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/keypoints/images/output_54_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we covered how to load custom keypoint annotations made with the LabelMe annotation tool and work with them using torchvision’s Transforms V2 API. The skills and knowledge you acquired here provide a solid foundation for future keypoint estimation projects.</p>
<p>As a next step, perhaps try annotating a custom keypoint estimation dataset with LabelMe and loading it with this tutorial’s code. Once you’re comfortable with that, try adapting the code in the following tutorial to train a keypoint estimation model on your custom dataset.</p>
<ul>
<li><a href="../../../posts/pytorch-train-keypoint-rcnn-tutorial">Training Keypoint R-CNN Models with PyTorch</a></li>
</ul>
</section>
<section id="recommended-tutorials" class="level2">
<h2 class="anchored" data-anchor-id="recommended-tutorials">Recommended Tutorials</h2>
<ul>
<li><a href="../../../posts/torchvision-labelme-annotation-tutorials/bounding-boxes/"><strong>Working with LabelMe Bounding Box Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with LabelMe bounding box annotations in torchvision for object detection tasks.</li>
<li><a href="http://localhost:3847/posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/"><strong>Working with LabelMe Segmentation Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with LabelMe segmentation annotations in torchvision for instance segmentation tasks.</li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>image-annotation</category>
  <category>keypoint-estimation</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/torchvision-labelme-annotation-tutorials/keypoints/</guid>
  <pubDate>Sun, 21 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Working with LabelMe Bounding Box Annotations in Torchvision</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/torchvision-labelme-annotation-tutorials/bounding-boxes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/tutorials/torchvision-annotation-tutorials-series.html"><strong>Torchvision Annotation Tutorials</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Loading and Exploring the Dataset</li>
<li>Preparing the Data</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to this hands-on guide for working with bounding box annotations created with the <a href="https://github.com/labelmeai/labelme">LabelMe annotation tool</a> in <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>. Bounding box annotations specify rectangular frames around objects in images to identify and locate them for training object detection models.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/bounding-boxes/images/bounding-box-hero-img.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The tutorial walks through setting up a Python environment, loading the raw annotations into a <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a>, annotating and augmenting images using torchvision’s <a href="https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py">Transforms V2 API</a>, and creating a custom <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Dataset</a> class to feed samples to a model.</p>
<p>This guide is suitable for beginners and experienced practitioners, providing the code, explanations, and resources needed to understand and implement each step. By the end, you will have a solid foundation for working with bounding box annotations made with LabelMe for object detection tasks.</p>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>The tutorial code is available as a <a href="https://jupyter.org/">Jupyter Notebook</a>, which you can run locally or in a cloud-based environment like <a href="https://colab.research.google.com/">Google Colab</a>. I have dedicated tutorials for those new to these platforms or who need guidance setting up:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Setup Guides">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Setup Guides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="../../../posts/google-colab-getting-started-tutorial/"><strong>Getting Started with Google Colab</strong></a></p></li>
<li><p><a href="../../../posts/mamba-getting-started-tutorial-windows/"><strong>Setting Up a Local Python Environment with Mamba for Machine Learning Projects on Windows</strong></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Tutorial Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tutorial Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook:</th>
<th><a href="https://github.com/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/labelme/torchvision-labelme-bounding-box-annotations.ipynb">GitHub Repository</a></th>
<th><a href="https://colab.research.google.com/github/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/labelme/torchvision-labelme-bounding-box-annotations.ipynb">Open In Colab</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>Before diving into the code, we’ll cover the steps to create a local Python environment and install the necessary dependencies.</p>
<section id="creating-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-python-environment">Creating a Python Environment</h3>
<p>First, we’ll create a Python environment using <a href="https://docs.conda.io/en/latest/">Conda</a>/<a href="https://mamba.readthedocs.io/en/latest/">Mamba</a>. Open a terminal with Conda/Mamba installed and run the following commands:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Conda</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Mamba</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate pytorch-env</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate pytorch-env</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="installing-pytorch">Installing PyTorch</h3>
<p>Next, we’ll install <a href="https://pytorch.org/">PyTorch</a>. Run the appropriate command for your hardware and operating system.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Linux/Windows (CUDA)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Mac</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Linux (CPU)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Windows (CPU)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch with CUDA</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cu121</span></code></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MPS (Metal Performance Shaders) acceleration is available on MacOS 12.3+</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cpu</span></code></pre></div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-additional-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-libraries">Installing Additional Libraries</h3>
<p>We also need to install some additional libraries for our project.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>jupyter</code></td>
<td>An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. (<a href="https://jupyter.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>matplotlib</code></td>
<td>This package provides a comprehensive collection of visualization tools to create high-quality plots, charts, and graphs for data exploration and presentation. (<a href="https://matplotlib.org/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>pandas</code></td>
<td>This package provides fast, powerful, and flexible data analysis and manipulation tools. (<a href="https://pandas.pydata.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>pillow</code></td>
<td>The Python Imaging Library adds image processing capabilities. (<a href="https://pillow.readthedocs.io/en/stable/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>tqdm</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>distinctipy</code></td>
<td>A lightweight python package providing functions to generate colours that are visually distinct from one another. (<a href="https://distinctipy.readthedocs.io/en/latest/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install these additional libraries:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional dependencies</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install distinctipy jupyter matplotlib pandas pillow tqdm</span></code></pre></div>
</section>
<section id="installing-utility-packages" class="level3">
<h3 class="anchored" data-anchor-id="installing-utility-packages">Installing Utility Packages</h3>
<p>We will also install some utility packages I made, which provide shortcuts for routine tasks.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>cjm_pil_utils</code></td>
<td>Some PIL utility functions I frequently use. (<a href="https://cj-mills.github.io/cjm-pil-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_psl_utils</code></td>
<td>Some utility functions using the Python Standard Library. (<a href="https://cj-mills.github.io/cjm-psl-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_pytorch_utils</code></td>
<td>Some utility functions for working with PyTorch. (<a href="https://cj-mills.github.io/cjm-pytorch-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_torchvision_tfms</code></td>
<td>Some custom Torchvision tranforms. (<a href="https://cj-mills.github.io/cjm-torchvision-tfms/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install the utility packages:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional utility packages</span></span>
<span id="cb8-2">pip install cjm_pil_utils cjm_psl_utils cjm_pytorch_utils cjm_torchvision_tfms</span></code></pre></div>
<p>With our environment set up, we can open our Jupyter Notebook and dive into the code.</p>
</section>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python packages into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb9-4"></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb9-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_img_files</span>
<span id="cb9-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file, file_extract</span>
<span id="cb9-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pytorch_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor_to_pil</span>
<span id="cb9-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_torchvision_tfms.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ResizeMax, PadSquare, CustomRandomIoUCrop</span>
<span id="cb9-10"></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the distinctipy module</span></span>
<span id="cb9-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distinctipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> distinctipy</span>
<span id="cb9-13"></span>
<span id="cb9-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import matplotlib for creating plots</span></span>
<span id="cb9-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb9-16"></span>
<span id="cb9-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb9-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-19"></span>
<span id="cb9-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb9-21"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb9-22"></span>
<span id="cb9-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb9-24">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb9-25"></span>
<span id="cb9-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb9-27"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image</span>
<span id="cb9-28"></span>
<span id="cb9-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb9-30"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb9-31"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DataLoader</span>
<span id="cb9-32"></span>
<span id="cb9-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import torchvision dependencies</span></span>
<span id="cb9-34"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision</span>
<span id="cb9-35">torchvision.disable_beta_transforms_warning()</span>
<span id="cb9-36"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BoundingBoxes</span>
<span id="cb9-37"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> draw_bounding_boxes</span>
<span id="cb9-38"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.v2  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb9-39"></span>
<span id="cb9-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import tqdm for progress bar</span></span>
<span id="cb9-41"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm.auto <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
<p>Torchvision provides dedicated <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> subclasses for different annotation types called <a href="https://pytorch.org/vision/stable/tv_tensors.html"><code>TVTensors</code></a>. Torchvision’s V2 transforms use these subclasses to update the annotations based on the applied image augmentations. The TVTensor class for bounding box annotations is called <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.BoundingBoxes.html"><code>BoundingBoxes</code></a>. Torchvision also includes a <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function to annotate images.</p>
</section>
<section id="loading-and-exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-and-exploring-the-dataset">Loading and Exploring the Dataset</h2>
<p>After importing the dependencies, we can start working with our data. I annotated a toy dataset with bounding boxes for this tutorial using images from the free stock photo site <a href="https://www.pexels.com/">Pexels</a>. The dataset is available on <a href="https://huggingface.co/">HuggingFace Hub</a> at the link below:</p>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/datasets/cj-mills/labelme-bounding-box-toy-dataset/tree/main">labelme-bounding-box-toy-dataset</a></li>
</ul>
<section id="setting-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-directory-paths">Setting the Directory Paths</h3>
<p>We first need to specify a place to store our dataset and a location to download the zip file containing it. The following code creates the folders in the current directory (<code>./</code>). Update the path if that is not suitable for you.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store datasets</span></span>
<span id="cb10-2">dataset_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./Datasets/"</span>)</span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the dataset directory if it does not exist</span></span>
<span id="cb10-4">dataset_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store archive files</span></span>
<span id="cb10-7">archive_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'../Archive'</span></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the archive directory if it does not exist</span></span>
<span id="cb10-9">archive_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb10-12">pd.Series({</span>
<span id="cb10-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Directory:"</span>: dataset_dir, </span>
<span id="cb10-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Directory:"</span>: archive_dir</span>
<span id="cb10-15">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_4e87e">
<thead>
</thead>
<tbody>
<tr>
<th id="T_4e87e_level0_row0" class="row_heading level0 row0">
Dataset Directory:
</th>
<td id="T_4e87e_row0_col0" class="data row0 col0">
Datasets
</td>
</tr>
<tr>
<th id="T_4e87e_level0_row1" class="row_heading level0 row1">
Archive Directory:
</th>
<td id="T_4e87e_row1_col0" class="data row1 col0">
Datasets/../Archive
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="setting-the-dataset-path" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-dataset-path">Setting the Dataset Path</h3>
<p>Next, we construct the name for the Hugging Face Hub dataset and set where to download and extract the dataset.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the dataset</span></span>
<span id="cb11-2">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labelme-bounding-box-toy-dataset'</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb11-5">hf_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'cj-mills/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb11-8">archive_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>archive_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip'</span>)</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb11-11">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the dataset name and paths and converting it to a DataFrame for display</span></span>
<span id="cb11-14">pd.Series({</span>
<span id="cb11-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb11-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Path:"</span>: archive_path, </span>
<span id="cb11-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Path:"</span>: dataset_path</span>
<span id="cb11-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_e1208">
<thead>
</thead>
<tbody>
<tr>
<th id="T_e1208_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_e1208_row0_col0" class="data row0 col0">
cj-mills/labelme-bounding-box-toy-dataset
</td>
</tr>
<tr>
<th id="T_e1208_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_e1208_row1_col0" class="data row1 col0">
Datasets/../Archive/labelme-bounding-box-toy-dataset.zip
</td>
</tr>
<tr>
<th id="T_e1208_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_e1208_row2_col0" class="data row2 col0">
Datasets/labelme-bounding-box-toy-dataset
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="downloading-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h3>
<p>We can now download the archive file and extract the dataset using the <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#download_file"><code>download_file</code></a> and <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#file_extract"><code>file_extract</code></a> functions from the <code>cjm_psl_utils</code> package. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb12-2">dataset_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>hf_dataset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip"</span></span>
<span id="cb12-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"HuggingFace Dataset URL: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb12-6">delete_archive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the dataset if not present</span></span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset_path.is_dir():</span>
<span id="cb12-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset folder already exists"</span>)</span>
<span id="cb12-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb12-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Downloading dataset..."</span>)</span>
<span id="cb12-13">    download_file(dataset_url, archive_dir)    </span>
<span id="cb12-14">    </span>
<span id="cb12-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extracting dataset..."</span>)</span>
<span id="cb12-16">    file_extract(fname<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>archive_path, dest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_dir)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete the archive if specified</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> delete_archive: archive_path.unlink()</span></code></pre></div>
</section>
<section id="getting-the-image-and-annotation-files" class="level3">
<h3 class="anchored" data-anchor-id="getting-the-image-and-annotation-files">Getting the Image and Annotation Files</h3>
<p>The dataset folder contains sample images and annotation files. Each sample image has its own JSON annotation file.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of image files in the dataset</span></span>
<span id="cb13-2">img_file_paths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_img_files(dataset_path)</span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of JSON files in the dataset</span></span>
<span id="cb13-5">annotation_file_paths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(dataset_path.glob(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'*.json'</span>))</span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the names of the folders using a Pandas DataFrame</span></span>
<span id="cb13-8">pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Image File"</span>: [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.name <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> img_file_paths], </span>
<span id="cb13-9">              <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annotation File"</span>:[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.name <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_file_paths]}).head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Image File
</th>
<th>
Annotation File
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
258421.jpg
</td>
<td>
258421.json
</td>
</tr>
<tr>
<th>
1
</th>
<td>
3075367.jpg
</td>
<td>
3075367.json
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3076319.jpg
</td>
<td>
3076319.json
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3145551.jpg
</td>
<td>
3145551.json
</td>
</tr>
<tr>
<th>
4
</th>
<td>
3176048.jpg
</td>
<td>
3176048.json
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-file-paths" class="level3">
<h3 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h3>
<p>Each image file has a unique name that we can use to locate the corresponding annotation data. We can make a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image more efficiently.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary that maps file names to file paths</span></span>
<span id="cb14-2">img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.stem : <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> img_file_paths}</span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of image files</span></span>
<span id="cb14-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Number of Images: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_dict)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb14-8">pd.DataFrame.from_dict(img_dict, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).head()</span></code></pre></div>
<pre class="text"><code>Number of Images: 29</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
Datasets/labelme-bounding-box-toy-dataset/258421.jpg
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
Datasets/labelme-bounding-box-toy-dataset/3075367.jpg
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
Datasets/labelme-bounding-box-toy-dataset/3076319.jpg
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
Datasets/labelme-bounding-box-toy-dataset/3145551.jpg
</td>
</tr>
<tr>
<th>
3176048
</th>
<td>
Datasets/labelme-bounding-box-toy-dataset/3176048.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="get-image-annotations">Get Image Annotations</h3>
<p>Next, we read the content of each JSON annotation file into a single Pandas DataFrame so we can easily query the annotations.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a generator that yields Pandas DataFrames containing the data from each JSON file</span></span>
<span id="cb16-2">cls_dataframes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (pd.read_json(f, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).transpose() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> f <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(annotation_file_paths))</span>
<span id="cb16-3"></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Concatenate the DataFrames into a single DataFrame</span></span>
<span id="cb16-5">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.concat(cls_dataframes, ignore_index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb16-6"></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assign the image file name as the index for each row</span></span>
<span id="cb16-8">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> row: row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'imagePath'</span>].split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb16-9">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>)</span>
<span id="cb16-10"></span>
<span id="cb16-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Keep only the rows that correspond to the filenames in the 'img_dict' dictionary</span></span>
<span id="cb16-12">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())]</span>
<span id="cb16-13"></span>
<span id="cb16-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the first 5 rows of the DataFrame</span></span>
<span id="cb16-15">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
version
</th>
<th>
flags
</th>
<th>
shapes
</th>
<th>
imagePath
</th>
<th>
imageData
</th>
<th>
imageHeight
</th>
<th>
imageWidth
</th>
</tr>
<tr>
<th>
index
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[340.2519836425781, 466.943359375], [418.9939880371094, 777.34423828125]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[386.076124567474, 443.94463667820065], [460.81660899653974, 777.1626297577855]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
<td>
258421.jpg
</td>
<td>
None
</td>
<td>
1152
</td>
<td>
768
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[413.31866455078125, 41.2171630859375], [919.8128051757812, 763.16552734375]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
<td>
3075367.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1344
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[335.30731201171875, 151.749755859375], [711.2194213867188, 1117.489013671875]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[8.10714285714289, 131.87500000000003], [404.2032880329769, 1119.0]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
<td>
3076319.jpg
</td>
<td>
None
</td>
<td>
1120
</td>
<td>
768
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[658.6324462890625, 281.2455139160156], [687.085693359375, 398.6059265136719]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[642.0, 289.8510638297872], [669.6595744680851, 398.8936170212766]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
<td>
3145551.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1184
</td>
</tr>
<tr>
<th>
3176048
</th>
<td>
5.3.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘person’, ‘points’: [[518.2313232421875, 338.9653015136719], [594.632080078125, 466.0799865722656]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[683.419689119171, 356.47668393782385], [638.860103626943, 437.8238341968912]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
<td>
3176048.jpg
</td>
<td>
None
</td>
<td>
768
</td>
<td>
1152
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Let’s examine the source JSON content corresponding to the first row in the DataFrame:</p>
<div style="overflow-x:auto; max-height:500px">
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb17-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-2">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"version"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"5.3.1"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-3">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"flags"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{},</span></span>
<span id="cb17-4">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"shapes"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-6">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-7">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"points"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-8">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-9">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">340.2519836425781</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-10">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">466.943359375</span></span>
<span id="cb17-11">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-12">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-13">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">418.9939880371094</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-14">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">777.34423828125</span></span>
<span id="cb17-15">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb17-16">      <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-17">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"group_id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-18">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-19">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"shape_type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rectangle"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-20">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"flags"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{}</span></span>
<span id="cb17-21">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-22">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-23">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"label"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-24">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"points"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-25">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-26">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">386.076124567474</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-27">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">443.94463667820065</span></span>
<span id="cb17-28">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">],</span></span>
<span id="cb17-29">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-30">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">460.81660899653974</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-31">          <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">777.1626297577855</span></span>
<span id="cb17-32">        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb17-33">      <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-34">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"group_id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-35">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-36">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"shape_type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rectangle"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-37">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"flags"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{}</span></span>
<span id="cb17-38">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-39">  <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-40">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imagePath"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"258421.jpg"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-41">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imageData"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-42">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imageHeight"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1152</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-43">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"imageWidth"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">768</span></span>
<span id="cb17-44"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
<hr>
<p>The bounding box annotations are in <code>[[Top-Left X, Top-Left Y],[Bottom-Right X, Bottom-Right Y]]</code> format.</p>
<section id="fill-empty-annotations" class="level4">
<h4 class="anchored" data-anchor-id="fill-empty-annotations">Fill empty annotations</h4>
<p>Next, we will fill empty entries for images without bounding box annotations with a default value.</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define a default value for empty annotations</span></span>
<span id="cb18-2">EMPTY_BBOX_FILL <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>: [[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>], [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>]], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'group_id'</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'description'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shape_type'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rectangle'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'flags'</span>: {}}]</span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fill empty annotations</span></span>
<span id="cb18-5">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: EMPTY_BBOX_FILL <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> x <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> x)</span>
<span id="cb18-6"></span>
<span id="cb18-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Annotations Filled: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> EMPTY_BBOX_FILL)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<pre class="text"><code>    Annotations Filled: 1</code></pre>
<p>With the annotations loaded, we can start inspecting our dataset.</p>
</section>
</section>
<section id="inspecting-the-class-distribution" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-the-class-distribution">Inspecting the Class Distribution</h3>
<p>First, we get the names of all the classes in our dataset and inspect the distribution of samples among these classes. This step won’t yield any insights for the toy dataset but is worth doing for real-world projects. A balanced dataset (where each class has approximately the same number of instances) is ideal for training a machine-learning model.</p>
<section id="get-image-classes" class="level4">
<h4 class="anchored" data-anchor-id="get-image-classes">Get image classes</h4>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Explode the 'shapes' column in the annotation_df dataframe</span></span>
<span id="cb20-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the resulting series to a dataframe</span></span>
<span id="cb20-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the pandas Series function to the 'shapes' column of the dataframe</span></span>
<span id="cb20-4">shapes_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>].explode().to_frame().shapes.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)</span>
<span id="cb20-5"></span>
<span id="cb20-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb20-7">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shapes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>].unique().tolist()</span>
<span id="cb20-8"></span>
<span id="cb20-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display labels using a Pandas DataFrame</span></span>
<span id="cb20-10">pd.DataFrame(class_names)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
person
</td>
</tr>
<tr>
<th>
1
</th>
<td>
none
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visualize-the-class-distribution" class="level4">
<h4 class="anchored" data-anchor-id="visualize-the-class-distribution">Visualize the class distribution</h4>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the number of samples for each object class</span></span>
<span id="cb21-2">class_counts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shapes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>].value_counts()</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the distribution</span></span>
<span id="cb21-5">class_counts.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bar'</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb21-6">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class distribution'</span>)</span>
<span id="cb21-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Count'</span>)</span>
<span id="cb21-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Classes'</span>)</span>
<span id="cb21-9">plt.xticks(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_counts.index)), class_counts.index, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the x-axis tick labels</span></span>
<span id="cb21-10">plt.show()</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/bounding-boxes/images/output_24_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
<section id="visualizing-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-image-annotations">Visualizing Image Annotations</h3>
<p>In this section, we will annotate a single image with its bounding boxes using torchvision’s <code>BoundingBoxes</code> class and <code>draw_bounding_boxes</code> function.</p>
<section id="generate-a-color-map" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-color-map">Generate a color map</h4>
<p>While not required, assigning a unique color to bounding boxes for each object class enhances visual distinction, allowing for easier identification of different objects in the scene. We can use the <a href="https://distinctipy.readthedocs.io/en/latest/"><code>distinctipy</code></a> package to generate a visually distinct colormap.</p>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb22-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distinctipy.get_colors(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb22-3"></span>
<span id="cb22-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the color map in integer format</span></span>
<span id="cb22-5">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colors]</span>
<span id="cb22-6"></span>
<span id="cb22-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a color swatch to visualize the color map</span></span>
<span id="cb22-8">distinctipy.color_swatch(colors)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/bounding-boxes/images/output_28_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a font file</h4>
<p>The <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function included with torchvision uses a pretty small font size. We can increase the font size if we use a custom font. Font files are available on sites like <a href="https://fonts.google.com/">Google Fonts</a>, or we can use one included with the operating system.</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb23-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb23-3"></span>
<span id="cb23-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb23-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
</section>
<section id="define-the-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-the-bounding-box-annotation-function">Define the bounding box annotation function</h4>
<p>We can make a partial function using <code>draw_bounding_boxes</code> since we’ll use the same box thickness and font each time we visualize bounding boxes.</p>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">draw_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(draw_bounding_boxes, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, font<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>font_file, font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
</section>
</section>
<section id="selecting-a-sample-image" class="level3">
<h3 class="anchored" data-anchor-id="selecting-a-sample-image">Selecting a Sample Image</h3>
<p>We can use the unique ID for an image in the image dictionary to get the image file path and the associated annotations from the annotation DataFrame.</p>
<section id="load-the-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="load-the-sample-image">Load the sample image</h4>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the file ID of the first image file</span></span>
<span id="cb25-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb25-3"></span>
<span id="cb25-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the associated image file as a RGB image</span></span>
<span id="cb25-5">sample_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(img_dict[file_id]).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb25-6"></span>
<span id="cb25-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the dimensions of the image</span></span>
<span id="cb25-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Image Dims: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sample_img<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>size<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb25-9"></span>
<span id="cb25-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Show the image</span></span>
<span id="cb25-11">sample_img</span></code></pre></div>
<pre class="text"><code>Image Dims: (768, 1152)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/bounding-boxes/images/output_33_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="inspect-the-corresponding-annotation-data" class="level4">
<h4 class="anchored" data-anchor-id="inspect-the-corresponding-annotation-data">Inspect the corresponding annotation data</h4>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'</span></span>
<span id="cb27-2">annotation_df.loc[file_id].to_frame()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
258421
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
version
</th>
<td>
5.3.1
</td>
</tr>
<tr>
<th>
flags
</th>
<td>
{}
</td>
</tr>
<tr>
<th>
shapes
</th>
<td>
[{‘label’: ‘person’, ‘points’: [[340.2519836425781, 466.943359375], [418.9939880371094, 777.34423828125]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}, {‘label’: ‘person’, ‘points’: [[386.076124567474, 443.94463667820065], [460.81660899653974, 777.1626297577855]], ‘group_id’: None, ‘description’: ’‘, ’shape_type’: ‘rectangle’, ‘flags’: {}}]
</td>
</tr>
<tr>
<th>
imagePath
</th>
<td>
258421.jpg
</td>
</tr>
<tr>
<th>
imageData
</th>
<td>
None
</td>
</tr>
<tr>
<th>
imageHeight
</th>
<td>
1152
</td>
</tr>
<tr>
<th>
imageWidth
</th>
<td>
768
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="define-function-that-ensures-bounding-boxes-are-in-a-consistent-format" class="level4">
<h4 class="anchored" data-anchor-id="define-function-that-ensures-bounding-boxes-are-in-a-consistent-format">Define function that ensures bounding boxes are in a consistent format</h4>
<p>LabelMe does not enforce a consistent order for storing the (x,y) coordinates for bounding box annotations. The order depends on how you initiate the bounding box annotation. Therefore, we will create a function that ensures the order is in [top-left x, top-left y, bottom-right x, bottom-right y] format.</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> correct_bounding_boxes(bboxes):</span>
<span id="cb28-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure input is a NumPy array</span></span>
<span id="cb28-3">    bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.asarray(bboxes)</span>
<span id="cb28-4">    </span>
<span id="cb28-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Correct x coordinates</span></span>
<span id="cb28-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Swap the x coordinates if the top-left x is greater than the bottom-right x</span></span>
<span id="cb28-7">    x_min <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.minimum(bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb28-8">    x_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.maximum(bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb28-9">    </span>
<span id="cb28-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Correct y coordinates</span></span>
<span id="cb28-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Swap the y coordinates if the top-left y is greater than the bottom-right y</span></span>
<span id="cb28-12">    y_min <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.minimum(bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb28-13">    y_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.maximum(bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], bboxes[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb28-14">    </span>
<span id="cb28-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the corrected bounding boxes array</span></span>
<span id="cb28-16">    corrected_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.stack([x_min, y_min, x_max, y_max], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb28-17">    </span>
<span id="cb28-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> corrected_bboxes</span></code></pre></div>
</section>
<section id="annotate-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="annotate-sample-image">Annotate sample image</h4>
<p>The <code>draw_bounding_boxes</code> function expects bounding box annotations in <code>[top-left X, top-left Y, bottom-right X, bottom-right Y]</code> format, so we don’t need to convert the annotation values.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels and bounding box annotations for the sample image</span></span>
<span id="cb29-2">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb29-3">bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]).reshape(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(labels),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb29-4">bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> correct_bounding_boxes(bboxes)</span>
<span id="cb29-5"></span>
<span id="cb29-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb29-7">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb29-8">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sample_img), </span>
<span id="cb29-9">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>BoundingBoxes(torch.Tensor(bboxes), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]),</span>
<span id="cb29-10">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, </span>
<span id="cb29-11">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb29-12">)</span>
<span id="cb29-13"></span>
<span id="cb29-14">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/bounding-boxes/images/output_37_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We have loaded the dataset, inspected its class distribution, and visualized the annotations for a sample image. In the final section, we will cover how to augment images using torchvision’s Transforms V2 API and create a custom Dataset class for training.</p>
</section>
</section>
</section>
<section id="preparing-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data">Preparing the Data</h2>
<p>In this section, we will first walk through a single example of how to apply augmentations to a single annotated image using torchvision’s Transforms V2 API before putting everything together in a custom Dataset class.</p>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h3>
<p>Here, we will define some data augmentations to apply to images during training. I created a few custom image transforms to help streamline the code.</p>
<p>The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#customrandomioucrop">first</a> extends the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.RandomIoUCrop.html#torchvision.transforms.v2.RandomIoUCrop"><code>RandomIoUCrop</code></a> transform included with torchvision to give the user more control over how much it crops into bounding box areas. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#resizemax">second</a> resizes images based on their largest dimension rather than their smallest. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#padsquare">third</a> applies square padding and allows the padding to be applied equally on both sides or randomly split between the two sides.</p>
<p>All three are available through the <a href="https://cj-mills.github.io/cjm-torchvision-tfms/"><code>cjm-torchvision-tfms</code></a> package.</p>
<section id="set-training-image-size" class="level4">
<h4 class="anchored" data-anchor-id="set-training-image-size">Set training image size</h4>
<p>Next, we will specify the image size to use during training.</p>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set training image size</span></span>
<span id="cb30-2">train_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span></span></code></pre></div>
</section>
<section id="initialize-custom-transforms" class="level4">
<h4 class="anchored" data-anchor-id="initialize-custom-transforms">Initialize custom transforms</h4>
<p>Now, we can initialize the transform objects.</p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomIoUCrop object</span></span>
<span id="cb31-2">iou_crop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomRandomIoUCrop(min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb31-3">                               max_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, </span>
<span id="cb31-4">                               min_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, </span>
<span id="cb31-5">                               max_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, </span>
<span id="cb31-6">                               sampler_options<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb31-7">                               trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb31-8">                               jitter_factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)</span>
<span id="cb31-9"></span>
<span id="cb31-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `ResizeMax` object</span></span>
<span id="cb31-11">resize_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ResizeMax(max_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_sz)</span>
<span id="cb31-12"></span>
<span id="cb31-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `PadSquare` object</span></span>
<span id="cb31-14">pad_square <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PadSquare(shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</section>
<section id="test-the-transforms" class="level4">
<h4 class="anchored" data-anchor-id="test-the-transforms">Test the transforms</h4>
<p>Torchvision’s V2 image transforms take an image and a <code>targets</code> dictionary. The <code>targets</code> dictionary contains the annotations and labels for the image.</p>
<p>We will pass input through the <code>CustomRandomIoUCrop</code> transform first and then through <code>ResizeMax</code> and <code>PadSquare</code>. We can pass the result through a final resize operation to ensure both sides match the <code>train_sz</code> value.</p>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare bounding box targets</span></span>
<span id="cb32-2">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb32-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: BoundingBoxes(torch.Tensor(bboxes), </span>
<span id="cb32-4">                           <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, </span>
<span id="cb32-5">                           canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), </span>
<span id="cb32-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.Tensor([class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])</span>
<span id="cb32-7">}</span>
<span id="cb32-8"></span>
<span id="cb32-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Crop the image</span></span>
<span id="cb32-10">cropped_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iou_crop(sample_img, targets)</span>
<span id="cb32-11"></span>
<span id="cb32-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Resize the image</span></span>
<span id="cb32-13">resized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_max(cropped_img, targets)</span>
<span id="cb32-14"></span>
<span id="cb32-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pad the image</span></span>
<span id="cb32-16">padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_square(resized_img, targets)</span>
<span id="cb32-17"></span>
<span id="cb32-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the padded image is the target size</span></span>
<span id="cb32-19">resize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb32-20">resized_padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize(padded_img, targets)</span>
<span id="cb32-21">sanitized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(resized_padded_img, targets)</span>
<span id="cb32-22"></span>
<span id="cb32-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb32-24">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb32-25">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sanitized_img), </span>
<span id="cb32-26">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb32-27">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb32-28">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb32-29">)</span>
<span id="cb32-30"></span>
<span id="cb32-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the annotated image</span></span>
<span id="cb32-32">display(tensor_to_pil(annotated_tensor))</span>
<span id="cb32-33"></span>
<span id="cb32-34">pd.Series({</span>
<span id="cb32-35">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image:"</span>: sample_img.size,</span>
<span id="cb32-36">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cropped Image:"</span>: cropped_img.size,</span>
<span id="cb32-37">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Image:"</span>: resized_img.size,</span>
<span id="cb32-38">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Padded Image:"</span>: padded_img.size,</span>
<span id="cb32-39">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Padded Image:"</span>: resized_padded_img.size,</span>
<span id="cb32-40">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/bounding-boxes/images/output_45_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_c2ef8">
<thead>
</thead>
<tbody>
<tr>
<th id="T_c2ef8_level0_row0" class="row_heading level0 row0">
Source Image:
</th>
<td id="T_c2ef8_row0_col0" class="data row0 col0">
(768, 1152)
</td>
</tr>
<tr>
<th id="T_c2ef8_level0_row1" class="row_heading level0 row1">
Cropped Image:
</th>
<td id="T_c2ef8_row1_col0" class="data row1 col0">
(768, 1152)
</td>
</tr>
<tr>
<th id="T_c2ef8_level0_row2" class="row_heading level0 row2">
Resized Image:
</th>
<td id="T_c2ef8_row2_col0" class="data row2 col0">
(256, 384)
</td>
</tr>
<tr>
<th id="T_c2ef8_level0_row3" class="row_heading level0 row3">
Padded Image:
</th>
<td id="T_c2ef8_row3_col0" class="data row3 col0">
(384, 384)
</td>
</tr>
<tr>
<th id="T_c2ef8_level0_row4" class="row_heading level0 row4">
Resized Padded Image:
</th>
<td id="T_c2ef8_row4_col0" class="data row4 col0">
(384, 384)
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Now that we know how to apply data augmentations, we can put all the steps we’ve covered into a custom Dataset class.</p>
</section>
</section>
<section id="training-dataset-class" class="level3">
<h3 class="anchored" data-anchor-id="training-dataset-class">Training Dataset Class</h3>
<p>The following custom Dataset class is responsible for loading a single image, preparing the associated annotations, applying any image transforms, and returning the final <code>image</code> tensor and its <code>target</code> dictionary during training.</p>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> LabelMeBBoxDataset(Dataset):</span>
<span id="cb33-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb33-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A custom dataset class for handling LabelMe bounding box datasets.</span></span>
<span id="cb33-4"></span>
<span id="cb33-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This class is designed to work with datasets where annotations are</span></span>
<span id="cb33-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    provided in a DataFrame and images are referenced by keys.</span></span>
<span id="cb33-7"></span>
<span id="cb33-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Attributes:</span></span>
<span id="cb33-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _img_keys (list): A list of image keys identifying each image.</span></span>
<span id="cb33-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _annotation_df (DataFrame): A DataFrame containing image annotations.</span></span>
<span id="cb33-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _img_dict (dict): A dictionary mapping image keys to image file paths.</span></span>
<span id="cb33-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _class_to_idx (dict): A dictionary mapping class names to class indices.</span></span>
<span id="cb33-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _transforms (function): A function or series of functions to apply transformations to the images and targets.</span></span>
<span id="cb33-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb33-15"></span>
<span id="cb33-16">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, img_keys, annotation_df, img_dict, class_to_idx, transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb33-17">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb33-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Initializes the dataset with image keys, annotation data, image dictionary, class indices, and transforms.</span></span>
<span id="cb33-19"></span>
<span id="cb33-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb33-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_keys (list): A list of image keys.</span></span>
<span id="cb33-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation_df (DataFrame): A DataFrame containing image annotations.</span></span>
<span id="cb33-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_dict (dict): A dictionary mapping image keys to image file paths.</span></span>
<span id="cb33-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            class_to_idx (dict): A dictionary mapping class names to class indices.</span></span>
<span id="cb33-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            transforms (function, optional): A function for transforming images and targets. Defaults to None.</span></span>
<span id="cb33-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb33-27">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Dataset, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb33-28">        </span>
<span id="cb33-29">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys</span>
<span id="cb33-30">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df</span>
<span id="cb33-31">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_dict</span>
<span id="cb33-32">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> class_to_idx</span>
<span id="cb33-33">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms</span>
<span id="cb33-34"></span>
<span id="cb33-35">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__len__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb33-36">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb33-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns the total number of items in the dataset.</span></span>
<span id="cb33-38"></span>
<span id="cb33-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb33-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            int: The total number of images in the dataset.</span></span>
<span id="cb33-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb33-42">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys)</span>
<span id="cb33-43">        </span>
<span id="cb33-44">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, index):</span>
<span id="cb33-45">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb33-46"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Retrieves an image and its corresponding target (annotations) at the specified index.</span></span>
<span id="cb33-47"></span>
<span id="cb33-48"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb33-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            index (int): The index of the item to retrieve.</span></span>
<span id="cb33-50"></span>
<span id="cb33-51"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb33-52"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and its corresponding target (annotations).</span></span>
<span id="cb33-53"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb33-54">        img_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys[index]</span>
<span id="cb33-55">        annotation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df.loc[img_key]</span>
<span id="cb33-56">        image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._load_image_and_target(annotation)</span>
<span id="cb33-57">        </span>
<span id="cb33-58">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply transformations if any</span></span>
<span id="cb33-59">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms:</span>
<span id="cb33-60">            image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms(image, target)</span>
<span id="cb33-61">        </span>
<span id="cb33-62">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, target</span>
<span id="cb33-63"></span>
<span id="cb33-64">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _load_image_and_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, annotation):</span>
<span id="cb33-65">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb33-66"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Loads an image and its corresponding target (annotations) based on the given annotation.</span></span>
<span id="cb33-67"></span>
<span id="cb33-68"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb33-69"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation (Series): A pandas Series containing the annotation data for a single image.</span></span>
<span id="cb33-70"></span>
<span id="cb33-71"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb33-72"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and its corresponding target (annotations).</span></span>
<span id="cb33-73"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb33-74">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the image from the filepath</span></span>
<span id="cb33-75">        filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict[annotation.name]</span>
<span id="cb33-76">        image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(filepath).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb33-77"></span>
<span id="cb33-78">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Process bounding box annotations</span></span>
<span id="cb33-79">        bbox_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]).reshape(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb33-80">        bbox_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> correct_bounding_boxes(bbox_list)</span>
<span id="cb33-81">        bbox_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.Tensor(bbox_list)</span>
<span id="cb33-82">        boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(bbox_tensor, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb33-83"></span>
<span id="cb33-84">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Process label annotations</span></span>
<span id="cb33-85">        annotation_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [shape[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> shape <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'shapes'</span>]]</span>
<span id="cb33-86">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.Tensor([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx[label] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_labels])</span>
<span id="cb33-87"></span>
<span id="cb33-88">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: boxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: labels}</span></code></pre></div>
</section>
<section id="image-transforms" class="level3">
<h3 class="anchored" data-anchor-id="image-transforms">Image Transforms</h3>
<p>Here, we will specify and organize all the image transforms to apply during training.</p>
<div class="sourceCode" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms for data augmentation</span></span>
<span id="cb34-2">data_aug_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose(</span>
<span id="cb34-3">    transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb34-4">        iou_crop,</span>
<span id="cb34-5">        transforms.ColorJitter(</span>
<span id="cb34-6">                brightness <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.875</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.125</span>),</span>
<span id="cb34-7">                contrast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb34-8">                saturation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb34-9">                hue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>),</span>
<span id="cb34-10">        ),</span>
<span id="cb34-11">        transforms.RandomGrayscale(),</span>
<span id="cb34-12">        transforms.RandomEqualize(),</span>
<span id="cb34-13">        transforms.RandomPosterize(bits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb34-14">        transforms.RandomHorizontalFlip(p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb34-15">    ],</span>
<span id="cb34-16">)</span>
<span id="cb34-17"></span>
<span id="cb34-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to resize and pad input images</span></span>
<span id="cb34-19">resize_pad_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb34-20">    resize_max, </span>
<span id="cb34-21">    pad_square,</span>
<span id="cb34-22">    transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb34-23">])</span>
<span id="cb34-24"></span>
<span id="cb34-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to sanitize bounding boxes and normalize input data</span></span>
<span id="cb34-26">final_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb34-27">    transforms.ToImage(), </span>
<span id="cb34-28">    transforms.ToDtype(torch.float32, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb34-29">    transforms.SanitizeBoundingBoxes(),</span>
<span id="cb34-30">])</span>
<span id="cb34-31"></span>
<span id="cb34-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the transformations for training and validation datasets</span></span>
<span id="cb34-33">train_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb34-34">    data_aug_tfms, </span>
<span id="cb34-35">    resize_pad_tfm, </span>
<span id="cb34-36">    final_tfms</span>
<span id="cb34-37">])</span></code></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always use the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.SanitizeBoundingBoxes.html#torchvision.transforms.v2.SanitizeBoundingBoxes"><code>SanitizeBoundingBoxes</code></a> transform to clean up annotations after using data augmentations that alter bounding boxes (e.g., cropping, warping, etc.).</p>
</div>
</div>
</section>
<section id="initialize-dataset" class="level3">
<h3 class="anchored" data-anchor-id="initialize-dataset">Initialize Dataset</h3>
<p>Now, we can create the dataset object using the image dictionary, the annotation DataFrame, and the image transforms.</p>
<div class="sourceCode" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mapping from class names to class indices</span></span>
<span id="cb35-2">class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {c: i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(class_names)}</span>
<span id="cb35-3"></span>
<span id="cb35-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Instantiate the dataset using the defined transformations</span></span>
<span id="cb35-5">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LabelMeBBoxDataset(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys()), annotation_df, img_dict, class_to_idx, train_tfms)</span>
<span id="cb35-6"></span>
<span id="cb35-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of samples in the training dataset</span></span>
<span id="cb35-8">pd.Series({</span>
<span id="cb35-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training dataset size:'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataset),</span>
<span id="cb35-10">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_b3d5b">
<thead>
</thead>
<tbody>
<tr>
<th id="T_b3d5b_level0_row0" class="row_heading level0 row0">
Training dataset size:
</th>
<td id="T_b3d5b_row0_col0" class="data row0 col0">
29
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspect-samples" class="level3">
<h3 class="anchored" data-anchor-id="inspect-samples">Inspect Samples</h3>
<p>To close out, we should verify the dataset object works as intended by inspecting the first sample.</p>
<section id="inspect-training-set-sample" class="level4">
<h4 class="anchored" data-anchor-id="inspect-training-set-sample">Inspect training set sample</h4>
<div class="sourceCode" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">dataset_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_dataset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb36-2"></span>
<span id="cb36-3">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb36-4">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.uint8), </span>
<span id="cb36-5">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb36-6">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb36-7">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb36-8">)</span>
<span id="cb36-9"></span>
<span id="cb36-10">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-labelme-annotation-tutorials/bounding-boxes/images/output_54_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we covered how to load custom bounding box annotations made with the LabelMe annotation tool and work with them using torchvision’s Transforms V2 API. The skills and knowledge you acquired here provide a solid foundation for future object detection projects.</p>
<p>As a next step, perhaps try annotating a custom object detection dataset with LabelMe and loading it with this tutorial’s code. Once you’re comfortable with that, try adapting the code in the following tutorial to train an object detection model on your custom dataset.</p>
<ul>
<li><a href="../../../posts/pytorch-train-object-detector-yolox-tutorial">Training YOLOX Models for Real-Time Object Detection in PyTorch</a></li>
</ul>
</section>
<section id="recommended-tutorials" class="level2">
<h2 class="anchored" data-anchor-id="recommended-tutorials">Recommended Tutorials</h2>
<ul>
<li><a href="../../../posts/torchvision-labelme-annotation-tutorials/keypoints/"><strong>Working with LabelMe Keypoint Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with LabelMe keypoint annotations in torchvision for keypoint estimation tasks.</li>
<li><a href="../../../posts/torchvision-labelme-annotation-tutorials/segmentation-polygons/"><strong>Working with LabelMe Segmentation Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with LabelMe segmentation annotations in torchvision for instance segmentation tasks.</li>
<li><a href="http://localhost:3847/posts/pytorch-train-object-detector-yolox-tutorial"><strong>Training YOLOX Models for Real-Time Object Detection in PyTorch</strong></a><strong>:</strong> Learn how to train YOLOX models for real-time object detection in PyTorch by creating a hand gesture detection model.</li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>image-annotation</category>
  <category>object-detection</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/torchvision-labelme-annotation-tutorials/bounding-boxes/</guid>
  <pubDate>Sun, 21 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Working with CVAT Segmentation Annotations in Torchvision</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/tutorials/torchvision-annotation-tutorials-series.html"><strong>Torchvision Annotation Tutorials</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Loading and Exploring the Dataset</li>
<li>Preparing the Data</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to this hands-on guide for working with segmentation annotations created with the <a href="https://github.com/opencv/cvat">CVAT annotation tool</a> in <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>. Segmentation annotations indicate the pixels occupied by specific objects or areas of interest in images for training models to recognize and delineate these objects at a pixel level.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/images/segmentation-mask-hero-img.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The tutorial walks through setting up a Python environment, loading the raw annotations into a <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a>, annotating and augmenting images using torchvision’s <a href="https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py">Transforms V2 API</a>, and creating a custom <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Dataset</a> class to feed samples to a model.</p>
<p>This guide is suitable for beginners and experienced practitioners, providing the code, explanations, and resources needed to understand and implement each step. By the end, you will have a solid foundation for working with segmentation annotations made with CVAT for instance segmentation tasks.</p>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>The tutorial code is available as a <a href="https://jupyter.org/">Jupyter Notebook</a>, which you can run locally or in a cloud-based environment like <a href="https://colab.research.google.com/">Google Colab</a>. I have dedicated tutorials for those new to these platforms or who need guidance setting up:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Setup Guides">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Setup Guides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="../../../posts/google-colab-getting-started-tutorial/"><strong>Getting Started with Google Colab</strong></a></p></li>
<li><p><a href="../../../posts/mamba-getting-started-tutorial-windows/"><strong>Setting Up a Local Python Environment with Mamba for Machine Learning Projects on Windows</strong></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Tutorial Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tutorial Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook:</th>
<th><a href="https://github.com/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/cvat/torchvision-cvat-segmentation-annotations.ipynb">GitHub Repository</a></th>
<th><a href="https://colab.research.google.com/github/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/cvat/torchvision-cvat-segmentation-annotations.ipynb">Open In Colab</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>Before diving into the code, we’ll cover the steps to create a local Python environment and install the necessary dependencies.</p>
<section id="creating-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-python-environment">Creating a Python Environment</h3>
<p>First, we’ll create a Python environment using <a href="https://docs.conda.io/en/latest/">Conda</a>/<a href="https://mamba.readthedocs.io/en/latest/">Mamba</a>. Open a terminal with Conda/Mamba installed and run the following commands:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Conda</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Mamba</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate pytorch-env</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate pytorch-env</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="installing-pytorch">Installing PyTorch</h3>
<p>Next, we’ll install <a href="https://pytorch.org/">PyTorch</a>. Run the appropriate command for your hardware and operating system.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Linux/Windows (CUDA)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Mac</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Linux (CPU)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Windows (CPU)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch with CUDA</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cu121</span></code></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MPS (Metal Performance Shaders) acceleration is available on MacOS 12.3+</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cpu</span></code></pre></div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-additional-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-libraries">Installing Additional Libraries</h3>
<p>We also need to install some additional libraries for our project.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>jupyter</code></td>
<td>An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. (<a href="https://jupyter.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>matplotlib</code></td>
<td>This package provides a comprehensive collection of visualization tools to create high-quality plots, charts, and graphs for data exploration and presentation. (<a href="https://matplotlib.org/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>pandas</code></td>
<td>This package provides fast, powerful, and flexible data analysis and manipulation tools. (<a href="https://pandas.pydata.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>pillow</code></td>
<td>The Python Imaging Library adds image processing capabilities. (<a href="https://pillow.readthedocs.io/en/stable/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>tqdm</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>distinctipy</code></td>
<td>A lightweight python package providing functions to generate colours that are visually distinct from one another. (<a href="https://distinctipy.readthedocs.io/en/latest/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install these additional libraries:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional dependencies</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install distinctipy jupyter matplotlib pandas pillow tqdm</span></code></pre></div>
</section>
<section id="installing-utility-packages" class="level3">
<h3 class="anchored" data-anchor-id="installing-utility-packages">Installing Utility Packages</h3>
<p>We will also install some utility packages I made, which provide shortcuts for routine tasks.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>cjm_pil_utils</code></td>
<td>Some PIL utility functions I frequently use. (<a href="https://cj-mills.github.io/cjm-pil-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_psl_utils</code></td>
<td>Some utility functions using the Python Standard Library. (<a href="https://cj-mills.github.io/cjm-psl-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_pytorch_utils</code></td>
<td>Some utility functions for working with PyTorch. (<a href="https://cj-mills.github.io/cjm-pytorch-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_torchvision_tfms</code></td>
<td>Some custom Torchvision tranforms. (<a href="https://cj-mills.github.io/cjm-torchvision-tfms/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install the utility packages:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional utility packages</span></span>
<span id="cb8-2">pip install cjm_pil_utils cjm_psl_utils cjm_pytorch_utils cjm_torchvision_tfms</span></code></pre></div>
<p>With our environment set up, we can open our Jupyter Notebook and dive into the code.</p>
</section>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python packages into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb9-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> xml.etree.ElementTree <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> ET</span>
<span id="cb9-5"></span>
<span id="cb9-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb9-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_img_files</span>
<span id="cb9-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file, file_extract</span>
<span id="cb9-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pytorch_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor_to_pil</span>
<span id="cb9-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_torchvision_tfms.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ResizeMax, PadSquare, CustomRandomIoUCrop</span>
<span id="cb9-11"></span>
<span id="cb9-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the distinctipy module</span></span>
<span id="cb9-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distinctipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> distinctipy</span>
<span id="cb9-14"></span>
<span id="cb9-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import matplotlib for creating plots</span></span>
<span id="cb9-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb9-17"></span>
<span id="cb9-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb9-19"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-20"></span>
<span id="cb9-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb9-22"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb9-23"></span>
<span id="cb9-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb9-25">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb9-26"></span>
<span id="cb9-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb9-28"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image, ImageDraw</span>
<span id="cb9-29"></span>
<span id="cb9-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb9-31"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb9-32"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DataLoader</span>
<span id="cb9-33"></span>
<span id="cb9-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import torchvision dependencies</span></span>
<span id="cb9-35"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision</span>
<span id="cb9-36">torchvision.disable_beta_transforms_warning()</span>
<span id="cb9-37"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BoundingBoxes, Mask</span>
<span id="cb9-38"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> draw_bounding_boxes, draw_segmentation_masks</span>
<span id="cb9-39"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.v2  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb9-40"></span>
<span id="cb9-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import tqdm for progress bar</span></span>
<span id="cb9-42"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm.auto <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
<p>Torchvision provides dedicated <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> subclasses for different annotation types called <a href="https://pytorch.org/vision/stable/tv_tensors.html"><code>TVTensors</code></a>. Torchvision’s V2 transforms use these subclasses to update the annotations based on the applied image augmentations. The TVTensor class for segmentation annotations is called <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.Mask.html">Mask</a>. Torchvision also includes a <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_segmentation_masks.html">draw_segmentation_masks</a> function to annotate images.</p>
</section>
<section id="loading-and-exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-and-exploring-the-dataset">Loading and Exploring the Dataset</h2>
<p>After importing the dependencies, we can start working with our data. I annotated a toy dataset with segmentation masks for this tutorial using images from the free stock photo site <a href="https://www.pexels.com/">Pexels</a>. The dataset is available on <a href="https://huggingface.co/">HuggingFace Hub</a> at the link below:</p>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/datasets/cj-mills/cvat-instance-segmentation-toy-dataset/tree/main">cvat-instance-segmentation-toy-dataset</a></li>
</ul>
<section id="setting-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-directory-paths">Setting the Directory Paths</h3>
<p>We first need to specify a place to store our dataset and a location to download the zip file containing it. The following code creates the folders in the current directory (<code>./</code>). Update the path if that is not suitable for you.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store datasets</span></span>
<span id="cb10-2">dataset_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./Datasets/"</span>)</span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the dataset directory if it does not exist</span></span>
<span id="cb10-4">dataset_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store archive files</span></span>
<span id="cb10-7">archive_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'../Archive'</span></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the archive directory if it does not exist</span></span>
<span id="cb10-9">archive_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb10-12">pd.Series({</span>
<span id="cb10-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Directory:"</span>: dataset_dir, </span>
<span id="cb10-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Directory:"</span>: archive_dir</span>
<span id="cb10-15">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_f4094">
<thead>
</thead>
<tbody>
<tr>
<th id="T_f4094_level0_row0" class="row_heading level0 row0">
Dataset Directory:
</th>
<td id="T_f4094_row0_col0" class="data row0 col0">
Datasets
</td>
</tr>
<tr>
<th id="T_f4094_level0_row1" class="row_heading level0 row1">
Archive Directory:
</th>
<td id="T_f4094_row1_col0" class="data row1 col0">
Datasets/../Archive
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="setting-the-dataset-path" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-dataset-path">Setting the Dataset Path</h3>
<p>Next, we construct the name for the Hugging Face Hub dataset and set where to download and extract the dataset.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the dataset</span></span>
<span id="cb11-2">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cvat-instance-segmentation-toy-dataset'</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb11-5">hf_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'cj-mills/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb11-8">archive_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>archive_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip'</span>)</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb11-11">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the dataset name and paths and converting it to a DataFrame for display</span></span>
<span id="cb11-14">pd.Series({</span>
<span id="cb11-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb11-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Path:"</span>: archive_path, </span>
<span id="cb11-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Path:"</span>: dataset_path</span>
<span id="cb11-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_38429">
<thead>
</thead>
<tbody>
<tr>
<th id="T_38429_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_38429_row0_col0" class="data row0 col0">
cj-mills/cvat-instance-segmentation-toy-dataset
</td>
</tr>
<tr>
<th id="T_38429_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_38429_row1_col0" class="data row1 col0">
Datasets/../Archive/cvat-instance-segmentation-toy-dataset.zip
</td>
</tr>
<tr>
<th id="T_38429_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_38429_row2_col0" class="data row2 col0">
Datasets/cvat-instance-segmentation-toy-dataset
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="downloading-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h3>
<p>We can now download the archive file and extract the dataset using the <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#download_file"><code>download_file</code></a> and <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#file_extract"><code>file_extract</code></a> functions from the <code>cjm_psl_utils</code> package. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb12-2">dataset_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>hf_dataset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip"</span></span>
<span id="cb12-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"HuggingFace Dataset URL: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb12-6">delete_archive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the dataset if not present</span></span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset_path.is_dir():</span>
<span id="cb12-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset folder already exists"</span>)</span>
<span id="cb12-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb12-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Downloading dataset..."</span>)</span>
<span id="cb12-13">    download_file(dataset_url, archive_dir)    </span>
<span id="cb12-14">    </span>
<span id="cb12-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extracting dataset..."</span>)</span>
<span id="cb12-16">    file_extract(fname<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>archive_path, dest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_dir)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete the archive if specified</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> delete_archive: archive_path.unlink()</span></code></pre></div>
</section>
<section id="getting-the-images-and-annotations" class="level3">
<h3 class="anchored" data-anchor-id="getting-the-images-and-annotations">Getting the Images and Annotations</h3>
<p>The dataset has a folder containing the sample images and an XML file containing the annotations.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming the images are stored in a subfolder named 'default'</span></span>
<span id="cb13-2">img_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'images/default'</span></span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming annotation file is in XML format and located in any subdirectory of the dataset</span></span>
<span id="cb13-5">annotation_file_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'annotations.xml'</span></span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb13-8">pd.Series({</span>
<span id="cb13-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Image Folder"</span>: img_dir, </span>
<span id="cb13-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annotation File"</span>: annotation_file_path}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_c53a2">
<thead>
</thead>
<tbody>
<tr>
<th id="T_c53a2_level0_row0" class="row_heading level0 row0">
Image Folder
</th>
<td id="T_c53a2_row0_col0" class="data row0 col0">
Datasets/cvat-instance-segmentation-toy-dataset/images/default
</td>
</tr>
<tr>
<th id="T_c53a2_level0_row1" class="row_heading level0 row1">
Annotation File
</th>
<td id="T_c53a2_row1_col0" class="data row1 col0">
Datasets/cvat-instance-segmentation-toy-dataset/annotations.xml
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-file-paths" class="level3">
<h3 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h3>
<p>Each image file has a unique name that we can use to locate the corresponding annotation data. We can make a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image more efficiently.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get all image files in the 'img_dir' directory</span></span>
<span id="cb14-2">img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb14-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.stem.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] : <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary that maps file names to file paths</span></span>
<span id="cb14-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> get_img_files(img_dir) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of image files in each image folder</span></span>
<span id="cb14-5">}</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of image files</span></span>
<span id="cb14-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Number of Images: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_dict)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb14-9"></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb14-11">pd.DataFrame.from_dict(img_dict, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).head()</span></code></pre></div>
<pre class="text"><code>Number of Images: 31</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
adults-affection-attractive-2760688
</th>
<td>
Datasets/cvat-instance-segmentation-toy-dataset/images/default/adults-affection-attractive-2760688.jpg
</td>
</tr>
<tr>
<th>
258421
</th>
<td>
Datasets/cvat-instance-segmentation-toy-dataset/images/default/258421.jpg
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
Datasets/cvat-instance-segmentation-toy-dataset/images/default/3075367.jpg
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
Datasets/cvat-instance-segmentation-toy-dataset/images/default/3076319.jpg
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
Datasets/cvat-instance-segmentation-toy-dataset/images/default/3145551.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="get-image-annotations">Get Image Annotations</h3>
<p>Next, we read the content of the XML annotation file into a Pandas DataFrame so we can easily query the annotations.</p>
<section id="define-a-function-to-parse-the-cvat-xml-annotations" class="level4">
<h4 class="anchored" data-anchor-id="define-a-function-to-parse-the-cvat-xml-annotations">Define a function to parse the CVAT XML annotations</h4>
<p>The following helper function parses the raw XML content into a Pandas DataFrame.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> parse_cvat_segmentation_xml(xml_content):</span>
<span id="cb16-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb16-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parses an XML string representing image segmentation data from CVAT and converts it into a pandas DataFrame.</span></span>
<span id="cb16-4"></span>
<span id="cb16-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    The function expects an XML string with a structure containing 'image' elements, each with 'id', 'name', 'width', </span></span>
<span id="cb16-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    and 'height' attributes, and nested 'polygon' elements with 'label' and 'points' attributes. It processes this </span></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    XML content to extract relevant data and organizes it into a structured DataFrame.</span></span>
<span id="cb16-8"></span>
<span id="cb16-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parameters:</span></span>
<span id="cb16-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    xml_content (str): A string containing the XML data to be parsed.</span></span>
<span id="cb16-11"></span>
<span id="cb16-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb16-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    pandas.DataFrame: A DataFrame where each row represents an image and contains the following columns:</span></span>
<span id="cb16-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                      'Image ID', 'Image Name', 'Width', 'Height', and 'Polygons'.</span></span>
<span id="cb16-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                      'Polygons' is a list of dictionaries, each representing a polygon with 'Label' and 'Points'.</span></span>
<span id="cb16-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb16-17"></span>
<span id="cb16-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Parse the XML content from the provided string.</span></span>
<span id="cb16-19">    root <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ET.fromstring(xml_content)</span>
<span id="cb16-20">    data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb16-21"></span>
<span id="cb16-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> image <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> root.findall(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image'</span>):</span>
<span id="cb16-23">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract attributes for each image.</span></span>
<span id="cb16-24">        image_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>)</span>
<span id="cb16-25">        image_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>)</span>
<span id="cb16-26">        width <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'width'</span>)</span>
<span id="cb16-27">        height <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'height'</span>)</span>
<span id="cb16-28"></span>
<span id="cb16-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize a dictionary to store image data.</span></span>
<span id="cb16-30">        image_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb16-31">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image ID'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(image_id),</span>
<span id="cb16-32">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image Name'</span>: image_name,</span>
<span id="cb16-33">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Width'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(width),</span>
<span id="cb16-34">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Height'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(height),</span>
<span id="cb16-35">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Polygons'</span>: []</span>
<span id="cb16-36">        }</span>
<span id="cb16-37"></span>
<span id="cb16-38">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate over each polygon element within the current image.</span></span>
<span id="cb16-39">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> polygon <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> image.findall(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'polygon'</span>):</span>
<span id="cb16-40">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the label and points of the polygon.</span></span>
<span id="cb16-41">            label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> polygon.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>)</span>
<span id="cb16-42">            </span>
<span id="cb16-43">            points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">','</span>.join(polygon.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>).split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">';'</span>))</span>
<span id="cb16-44">            points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(point) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> point <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> points.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">','</span>)]</span>
<span id="cb16-45">            </span>
<span id="cb16-46">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary to store the polygon data.</span></span>
<span id="cb16-47">            points_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb16-48">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>: label,</span>
<span id="cb16-49">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Points'</span>: points</span>
<span id="cb16-50">            }</span>
<span id="cb16-51">            image_data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Polygons'</span>].append(points_data)</span>
<span id="cb16-52"></span>
<span id="cb16-53">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add the processed image data to the main data dictionary.</span></span>
<span id="cb16-54">        data[image_id] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image_data</span>
<span id="cb16-55"></span>
<span id="cb16-56">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the data dictionary into a pandas DataFrame and return it.</span></span>
<span id="cb16-57">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> pd.DataFrame.from_dict(data, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>)</span></code></pre></div>
</section>
<section id="load-cvat-xml-annotations-into-a-dataframe" class="level4">
<h4 class="anchored" data-anchor-id="load-cvat-xml-annotations-into-a-dataframe">Load CVAT XML annotations into a DataFrame</h4>
<p>After parsing the XML content, we will change the index for the <code>annotation_df</code> DataFrame to match the keys in the <code>img_dict</code> dictionary, allowing us to retrieve both the image paths and annotation data using the same index key.</p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Read the XML file</span></span>
<span id="cb17-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(annotation_file_path, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'utf-8'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>:</span>
<span id="cb17-3">    xml_content <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.read()</span>
<span id="cb17-4"></span>
<span id="cb17-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Parse the XML content</span></span>
<span id="cb17-6">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parse_cvat_segmentation_xml(xml_content)</span>
<span id="cb17-7"></span>
<span id="cb17-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add a new column 'Image ID' by extracting it from 'Image Name'</span></span>
<span id="cb17-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This assumes that the 'Image ID' is the part of the 'Image Name' before the first period</span></span>
<span id="cb17-10">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image ID'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image Name'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: x.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb17-11"></span>
<span id="cb17-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the new 'Image ID' column as the index of the DataFrame</span></span>
<span id="cb17-13">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image ID'</span>)</span>
<span id="cb17-14"></span>
<span id="cb17-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first few rows of the DataFrame</span></span>
<span id="cb17-16">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Image Name
</th>
<th>
Width
</th>
<th>
Height
</th>
<th>
Polygons
</th>
</tr>
<tr>
<th>
Image ID
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
258421.jpg
</td>
<td>
768
</td>
<td>
1152
</td>
<td>
[{‘Label’: ‘person’, ‘Points’: [377.0, 775.5, 368.0, 774.5, 346.5, 764.0, 349.5, 751.0, 348.5, 707.0, 358.5, 668.0, 343.5, 651.0, 359.5, 605.0, 379.5, 583.0, 366.01, 583.39, 362.55, 575.78, 361.85, 565.4, 353.2, 557.09, 357.7, 547.4, 350.78, 532.53, 356.32, 520.76, 359.78, 481.31, 376.39, 467.47, 387.46, 469.55, 401.3, 484.08, 405.8, 501.04, 394.03, 505.88, 394.73, 519.03, 399.92, 531.14, 374.66, 554.33, 369.81, 571.28, 374.31, 574.05, 388.15, 574.39, 397.49, 569.9, 402.5, 578.0, 410.5, 594.0, 412.5, 668.0, 387.0, 667.5, 375.5, 692.0, 376.5, 738.0, 380.5, 753.0, 388.5, 764.0, 386.5, 772.0]}, {‘Label’: ‘person’, ‘Points’: [404.0, 775.5, 396.5, 766.0, 411.5, 753.0, 411.5, 738.0, 416.5, 731.0, 412.5, 598.0, 419.5, 559.0, 416.0, 554.5, 404.0, 566.5, 387.0, 572.5, 375.5, 566.0, 377.5, 554.0, 405.5, 529.0, 413.5, 504.0, 414.5, 493.0, 386.5, 463.0, 388.5, 453.0, 399.0, 443.5, 413.0, 444.5, 423.5, 453.0, 457.5, 506.0, 452.5, 575.0, 458.5, 607.0, 447.5, 635.0, 444.5, 676.0, 452.5, 764.0, 443.0, 770.5]}]
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
3075367.jpg
</td>
<td>
1344
</td>
<td>
768
</td>
<td>
[{‘Label’: ‘person’, ‘Points’: [829.0, 466.5, 825.5, 464.0, 824.5, 455.0, 825.5, 425.0, 828.0, 419.5, 833.5, 418.0, 827.5, 417.0, 822.5, 396.0, 825.5, 327.0, 843.5, 313.0, 842.5, 296.0, 833.5, 291.0, 832.5, 270.0, 837.0, 265.5, 856.0, 264.5, 868.5, 277.0, 870.5, 306.0, 881.5, 318.0, 883.5, 329.0, 893.0, 332.5, 899.5, 340.0, 901.5, 367.0, 883.5, 382.0, 849.5, 443.0, 842.5, 448.0, 838.5, 460.0]}, {‘Label’: ‘person’, ‘Points’: [714.0, 766.5, 664.0, 765.5, 654.0, 716.5, 640.0, 765.5, 578.5, 764.0, 578.5, 599.0, 570.5, 587.0, 592.5, 403.0, 583.5, 339.0, 525.5, 278.0, 463.5, 187.0, 423.5, 98.0, 422.5, 72.0, 444.0, 52.5, 460.5, 62.0, 458.5, 104.0, 485.5, 166.0, 581.0, 270.5, 623.0, 295.5, 644.5, 293.0, 630.5, 261.0, 642.5, 193.0, 667.0, 182.5, 707.0, 191.5, 719.5, 249.0, 709.0, 307.5, 774.0, 271.5, 848.5, 176.0, 875.5, 108.0, 867.5, 55.0, 902.0, 63.5, 908.5, 76.0, 902.5, 134.0, 858.5, 233.0, 759.5, 350.0, 736.5, 495.0, 752.5, 614.0]}, {‘Label’: ‘person’, ‘Points’: [359.0, 509.5, 355.0, 509.5, 350.5, 502.0, 353.5, 486.0, 349.5, 475.0, 349.5, 449.0, 345.5, 430.0, 339.5, 419.0, 337.5, 394.0, 327.5, 378.0, 331.5, 371.0, 332.5, 357.0, 342.5, 345.0, 345.5, 327.0, 354.0, 313.5, 365.5, 317.0, 366.5, 339.0, 385.0, 350.5, 399.5, 371.0, 398.5, 383.0, 390.0, 391.5, 390.5, 378.0, 383.0, 369.5, 379.5, 370.0, 380.5, 441.0, 376.5, 471.0, 370.0, 464.5, 364.5, 472.0, 362.5, 482.0, 364.5, 504.0]}, {‘Label’: ‘car’, ‘Points’: [1343.0, 764.5, 964.0, 745.5, 930.0, 764.5, 914.5, 759.0, 904.0, 722.5, 865.0, 706.5, 848.0, 735.5, 801.0, 735.5, 788.5, 699.0, 792.5, 577.0, 821.5, 476.0, 849.5, 454.0, 890.5, 382.0, 930.0, 355.5, 1021.0, 347.5, 1195.0, 358.5, 1287.0, 378.5, 1343.0, 436.0]}]
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
3076319.jpg
</td>
<td>
768
</td>
<td>
1120
</td>
<td>
[{‘Label’: ‘person’, ‘Points’: [590.0, 1119.0, 508.5, 1119.0, 393.5, 881.0, 363.5, 778.0, 359.5, 738.0, 377.5, 685.0, 420.5, 660.0, 388.5, 650.0, 410.5, 606.0, 412.5, 477.0, 349.5, 383.0, 364.5, 338.0, 341.5, 303.0, 369.5, 313.0, 396.5, 191.0, 449.0, 157.5, 496.0, 169.5, 524.5, 203.0, 534.5, 320.0, 577.5, 380.0, 588.5, 493.0, 635.5, 554.0, 631.5, 567.0, 687.5, 625.0, 704.5, 673.0, 698.5, 743.0, 632.5, 833.0, 618.5, 955.0, 573.5, 1096.0]}, {‘Label’: ‘person’, ‘Points’: [262.0, 1119.0, 128.5, 1119.0, 131.5, 1089.0, 35.5, 901.0, 11.5, 772.0, 33.5, 686.0, 70.5, 663.0, 34.5, 612.0, 25.5, 569.0, 52.5, 375.0, 97.0, 332.5, 195.5, 306.0, 205.5, 255.0, 192.5, 220.0, 240.0, 154.5, 290.0, 133.5, 323.5, 153.0, 341.5, 209.0, 332.5, 279.0, 294.5, 326.0, 347.5, 357.0, 352.5, 399.0, 400.5, 459.0, 404.5, 517.0, 391.5, 631.0, 344.5, 679.0, 359.5, 719.0, 323.5, 907.0, 224.5, 1082.0]}]
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
3145551.jpg
</td>
<td>
1184
</td>
<td>
768
</td>
<td>
[{‘Label’: ‘person’, ‘Points’: [683.0, 398.5, 675.0, 398.5, 671.5, 396.0, 673.5, 378.0, 669.5, 366.0, 669.5, 359.0, 664.5, 346.0, 663.5, 326.0, 661.5, 320.0, 661.5, 312.0, 666.5, 304.0, 662.5, 295.0, 666.0, 283.5, 673.0, 283.5, 674.5, 285.0, 676.5, 289.0, 676.5, 297.0, 681.5, 302.0, 685.5, 313.0, 686.5, 336.0, 683.5, 344.0, 685.5, 395.0]}, {‘Label’: ‘person’, ‘Points’: [649.0, 398.5, 644.0, 398.5, 641.5, 396.0, 640.5, 387.0, 644.5, 379.0, 650.5, 358.0, 650.5, 351.0, 644.5, 335.0, 644.5, 323.0, 646.5, 316.0, 644.5, 300.0, 648.5, 291.0, 654.0, 288.5, 661.5, 295.0, 662.5, 298.0, 658.5, 309.0, 662.5, 316.0, 664.5, 324.0, 665.5, 349.0, 669.5, 364.0, 665.5, 383.0, 666.5, 396.0, 663.0, 397.5, 659.5, 392.0, 662.5, 375.0, 662.5, 364.0, 660.0, 361.5, 649.5, 383.0]}]
</td>
</tr>
<tr>
<th>
3176048
</th>
<td>
3176048.jpg
</td>
<td>
1152
</td>
<td>
768
</td>
<td>
[{‘Label’: ‘person’, ‘Points’: [562.0, 464.5, 552.0, 464.5, 550.5, 462.0, 553.5, 454.0, 550.5, 433.0, 558.5, 402.0, 558.5, 389.0, 561.5, 380.0, 557.0, 372.5, 549.0, 374.5, 537.0, 372.5, 533.0, 377.5, 532.5, 371.0, 529.5, 368.0, 542.0, 365.5, 551.0, 366.5, 562.0, 361.5, 567.0, 361.5, 568.5, 360.0, 567.5, 346.0, 572.0, 342.5, 577.0, 342.5, 582.5, 348.0, 581.5, 360.0, 591.5, 372.0, 593.5, 386.0, 592.0, 388.5, 587.0, 388.5, 585.5, 391.0, 578.5, 419.0, 572.5, 434.0, 571.5, 445.0, 566.5, 454.0, 565.5, 462.0]}, {‘Label’: ‘person’, ‘Points’: [661.0, 436.5, 659.5, 436.0, 660.5, 432.0, 660.5, 396.0, 659.5, 392.0, 663.5, 376.0, 661.0, 373.5, 658.0, 373.5, 650.0, 377.5, 641.0, 377.5, 640.5, 376.0, 647.0, 372.5, 651.0, 372.5, 656.0, 370.5, 666.0, 365.5, 667.5, 364.0, 667.5, 359.0, 670.0, 356.5, 674.0, 356.5, 677.5, 360.0, 676.5, 367.0, 682.5, 374.0, 683.5, 389.0, 681.0, 390.5, 678.5, 388.0, 678.5, 385.0, 677.5, 385.0, 677.5, 390.0, 673.5, 395.0, 673.5, 408.0, 671.5, 411.0, 670.5, 420.0, 668.5, 425.0, 668.5, 433.0, 669.5, 434.0]}]
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>The source XML content corresponding to the first row in the DataFrame is available below:</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode xml code-with-copy"><code class="sourceCode xml"><span id="cb18-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">&lt;?xml</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> version=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1.0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> encoding=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"utf-8"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">?&gt;</span></span>
<span id="cb18-2">&lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">annotations</span>&gt;</span>
<span id="cb18-3">  &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">version</span>&gt;1.1&lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">version</span>&gt;</span>
<span id="cb18-4">  &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">meta</span>&gt;</span>
<span id="cb18-5">  &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">meta</span>&gt;</span>
<span id="cb18-6">  &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">image</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> id=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> name=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"258421.jpg"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> subset=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"default"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> task_id=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"9"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> width=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"768"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> height=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1152"</span>&gt;</span>
<span id="cb18-7">    &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">polygon</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> label=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> source=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"file"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> occluded=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> points=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"377.00,775.50;368.00,774.50;346.50,764.00;349.50,751.00;348.50,707.00;358.50,668.00;343.50,651.00;359.50,605.00;379.50,583.00;366.01,583.39;362.55,575.78;361.85,565.40;353.20,557.09;357.70,547.40;350.78,532.53;356.32,520.76;359.78,481.31;376.39,467.47;387.46,469.55;401.30,484.08;405.80,501.04;394.03,505.88;394.73,519.03;399.92,531.14;374.66,554.33;369.81,571.28;374.31,574.05;388.15,574.39;397.49,569.90;402.50,578.00;410.50,594.00;412.50,668.00;387.00,667.50;375.50,692.00;376.50,738.00;380.50,753.00;388.50,764.00;386.50,772.00"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> z_order=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span>&gt;</span>
<span id="cb18-8">    &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">polygon</span>&gt;</span>
<span id="cb18-9">    &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">polygon</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> label=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> source=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"file"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> occluded=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> points=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"404.00,775.50;396.50,766.00;411.50,753.00;411.50,738.00;416.50,731.00;412.50,598.00;419.50,559.00;416.00,554.50;404.00,566.50;387.00,572.50;375.50,566.00;377.50,554.00;405.50,529.00;413.50,504.00;414.50,493.00;386.50,463.00;388.50,453.00;399.00,443.50;413.00,444.50;423.50,453.00;457.50,506.00;452.50,575.00;458.50,607.00;447.50,635.00;444.50,676.00;452.50,764.00;443.00,770.50"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> z_order=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span>&gt;</span>
<span id="cb18-10">    &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">polygon</span>&gt;</span>
<span id="cb18-11">  &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">image</span>&gt;</span>
<span id="cb18-12">&lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">annotations</span>&gt;</span></code></pre></div>
<p>The segmentation polygon annotations in <code>[x1,y1, x2,y2, ..., xn,yn]</code> format.</p>
<p>With the annotations loaded, we can start inspecting our dataset.</p>
</section>
</section>
<section id="inspecting-the-class-distribution" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-the-class-distribution">Inspecting the Class Distribution</h3>
<p>First, we get the names of all the classes in our dataset and inspect the distribution of samples among these classes. This step is not strictly necessary for the toy dataset but is worth doing for real-world projects. A balanced dataset (where each class has approximately the same number of instances) is ideal for training a machine-learning model.</p>
<section id="get-image-classes" class="level4">
<h4 class="anchored" data-anchor-id="get-image-classes">Get image classes</h4>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Explode the 'boxes_df' column in the annotation_df dataframe</span></span>
<span id="cb19-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the resulting series to a dataframe and rename the 'boxes_df' column to 'boxes_df'</span></span>
<span id="cb19-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the pandas Series function to the 'boxes_df' column of the dataframe</span></span>
<span id="cb19-4">polygon_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Polygons'</span>].explode().to_frame().Polygons.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)</span>
<span id="cb19-5"></span>
<span id="cb19-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb19-7">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> polygon_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>].unique().tolist()</span>
<span id="cb19-8"></span>
<span id="cb19-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display labels using a Pandas DataFrame</span></span>
<span id="cb19-10">pd.DataFrame(class_names)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
person
</td>
</tr>
<tr>
<th>
1
</th>
<td>
car
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visualize-the-class-distribution" class="level4">
<h4 class="anchored" data-anchor-id="visualize-the-class-distribution">Visualize the class distribution</h4>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the number of samples for each object class</span></span>
<span id="cb20-2">class_counts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> polygon_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>].value_counts()</span>
<span id="cb20-3"></span>
<span id="cb20-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the distribution</span></span>
<span id="cb20-5">class_counts.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bar'</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb20-6">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class distribution'</span>)</span>
<span id="cb20-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Count'</span>)</span>
<span id="cb20-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Classes'</span>)</span>
<span id="cb20-9">plt.xticks(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_counts.index)), class_counts.index, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the x-axis tick labels</span></span>
<span id="cb20-10">plt.show()</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/images/output_24_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Note the class distribution is quite imbalanced between the <code>person</code> and <code>car</code> classes. For a real dataset, you would want these to be much closer.</p>
</section>
</section>
<section id="visualizing-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-image-annotations">Visualizing Image Annotations</h3>
<p>In this section, we will annotate a single image with its segmentation masks and bounding boxes using torchvision’s <code>BoundingBoxes</code> and <code>Mask</code> classes and <code>draw_bounding_boxes</code> and <code>draw_segmentation_masks</code> function.</p>
<section id="generate-a-color-map" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-color-map">Generate a color map</h4>
<p>While not required, assigning a unique color to bounding boxes for each object class enhances visual distinction, allowing for easier identification of different objects in the scene. We can use the <a href="https://distinctipy.readthedocs.io/en/latest/"><code>distinctipy</code></a> package to generate a visually distinct colormap.</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb21-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distinctipy.get_colors(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the color map in integer format</span></span>
<span id="cb21-5">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colors]</span>
<span id="cb21-6"></span>
<span id="cb21-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a color swatch to visualize the color map</span></span>
<span id="cb21-8">distinctipy.color_swatch(colors)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/images/output_28_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a font file</h4>
<p>The <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function included with torchvision uses a pretty small font size. We can increase the font size if we use a custom font. Font files are available on sites like <a href="https://fonts.google.com/">Google Fonts</a>, or we can use one included with the operating system.</p>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb22-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb22-3"></span>
<span id="cb22-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb22-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
</section>
<section id="define-the-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-the-bounding-box-annotation-function">Define the bounding box annotation function</h4>
<p>We can make a partial function using <code>draw_bounding_boxes</code> since we’ll use the same box thickness and font each time we visualize bounding boxes.</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">draw_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(draw_bounding_boxes, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, font<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>font_file, font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
</section>
</section>
<section id="selecting-a-sample-image" class="level3">
<h3 class="anchored" data-anchor-id="selecting-a-sample-image">Selecting a Sample Image</h3>
<p>We can use the unique ID for an image in the image dictionary to get the image file path and the associated annotations from the annotation DataFrame.</p>
<section id="load-the-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="load-the-sample-image">Load the sample image</h4>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the file ID of the first image file</span></span>
<span id="cb24-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb24-3"></span>
<span id="cb24-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the associated image file as a RGB image</span></span>
<span id="cb24-5">sample_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(img_dict[file_id]).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb24-6"></span>
<span id="cb24-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the dimensions of the image</span></span>
<span id="cb24-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Image Dims: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sample_img<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>size<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb24-9"></span>
<span id="cb24-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Show the image</span></span>
<span id="cb24-11">sample_img</span></code></pre></div>
<pre class="text"><code>Image Dims: (768, 1152)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/images/output_35_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="inspect-the-corresponding-annotation-data" class="level4">
<h4 class="anchored" data-anchor-id="inspect-the-corresponding-annotation-data">Inspect the corresponding annotation data</h4>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'</span></span>
<span id="cb26-2">annotation_df.loc[file_id].to_frame()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
adults-affection-attractive-2760688
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
Image Name
</th>
<td>
adults-affection-attractive-2760688.jpg
</td>
</tr>
<tr>
<th>
Width
</th>
<td>
768
</td>
</tr>
<tr>
<th>
Height
</th>
<td>
1152
</td>
</tr>
<tr>
<th>
Polygons
</th>
<td>
[{‘Label’: ‘person’, ‘Points’: [389.0, 1151.0, 34.5, 1151.0, 82.5, 992.0, 103.0, 965.5, 147.5, 953.0, 135.5, 848.0, 104.5, 763.0, 97.5, 672.0, 129.5, 581.0, 186.5, 519.0, 127.5, 466.0, 106.5, 422.0, 118.5, 369.0, 181.0, 306.5, 258.0, 325.5, 301.5, 412.0, 285.5, 566.0, 291.5, 594.0, 323.5, 610.0, 335.5, 714.0, 366.5, 777.0, 341.5, 848.0, 337.5, 944.0]}, {‘Label’: ‘person’, ‘Points’: [532.0, 1151.0, 397.5, 1151.0, 345.5, 958.0, 345.5, 855.0, 369.5, 776.0, 340.5, 720.0, 344.5, 678.0, 325.5, 647.0, 326.5, 608.0, 296.5, 592.0, 294.5, 540.0, 298.0, 519.5, 341.5, 493.0, 273.5, 329.0, 284.5, 283.0, 332.0, 249.5, 385.0, 260.5, 411.5, 287.0, 431.5, 338.0, 434.0, 411.5, 449.0, 407.5, 486.0, 440.5, 601.0, 461.5, 671.5, 580.0, 698.5, 786.0, 681.5, 1090.0, 663.0, 1137.5, 549.0, 1127.5]}]
</td>
</tr>
</tbody>
</table>
</div>
<p>The lists of point coordinates in the segmentation annotations are the vertices of a polygon for the individual segmentation masks. We can use these to generate images for each segmentation mask.</p>
</section>
<section id="define-a-function-to-convert-segmentation-polygons-to-images" class="level4">
<h4 class="anchored" data-anchor-id="define-a-function-to-convert-segmentation-polygons-to-images">Define a function to convert segmentation polygons to images</h4>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> create_polygon_mask(image_size, vertices):</span>
<span id="cb27-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb27-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Create a grayscale image with a white polygonal area on a black background.</span></span>
<span id="cb27-4"></span>
<span id="cb27-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parameters:</span></span>
<span id="cb27-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - image_size (tuple): A tuple representing the dimensions (width, height) of the image.</span></span>
<span id="cb27-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - vertices (list): A list of tuples, each containing the x, y coordinates of a vertex</span></span>
<span id="cb27-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                        of the polygon. Vertices should be in clockwise or counter-clockwise order.</span></span>
<span id="cb27-9"></span>
<span id="cb27-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb27-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - PIL.Image.Image: A PIL Image object containing the polygonal mask.</span></span>
<span id="cb27-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb27-13"></span>
<span id="cb27-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new black image with the given dimensions</span></span>
<span id="cb27-15">    mask_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.new(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'L'</span>, image_size, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb27-16">    </span>
<span id="cb27-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Draw the polygon on the image. The area inside the polygon will be white (255).</span></span>
<span id="cb27-18">    ImageDraw.Draw(mask_img, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'L'</span>).polygon(vertices, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>))</span>
<span id="cb27-19"></span>
<span id="cb27-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the image with the drawn polygon</span></span>
<span id="cb27-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> mask_img</span></code></pre></div>
</section>
<section id="annotate-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="annotate-sample-image">Annotate sample image</h4>
<p>We can now generate the segmentation mask images and feed those to the <code>draw_segmentation_mask</code> function.</p>
<p>We can use the <a href="https://pytorch.org/vision/stable/generated/torchvision.ops.masks_to_boxes.html#torchvision.ops.masks_to_boxes"><code>masks_to_boxes</code></a> function included with torchvision to generate bounding box annotations in the <code>[top-left X, top-left Y, bottom-right X, bottom-right Y]</code> format from the segmentation masks. That is the same format the <code>draw_bounding_boxes</code> function expects so we can use the output directly.</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the polygon points for segmentation mask</span></span>
<span id="cb28-2">polygon_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Polygons'</span>]</span>
<span id="cb28-3"></span>
<span id="cb28-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate mask images from polygons</span></span>
<span id="cb28-5">mask_imgs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [create_polygon_mask(sample_img.size, polygon[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Points'</span>]) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> polygon <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> polygon_points]</span>
<span id="cb28-6"></span>
<span id="cb28-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert mask images to tensors</span></span>
<span id="cb28-8">masks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.concat([Mask(transforms.PILToTensor()(mask_img), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> mask_img <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> mask_imgs])</span>
<span id="cb28-9"></span>
<span id="cb28-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels and bounding box annotations for the sample image</span></span>
<span id="cb28-11">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [polygon[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> polygon <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Polygons'</span>]]</span>
<span id="cb28-12">bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torchvision.ops.masks_to_boxes(masks)</span>
<span id="cb28-13"></span>
<span id="cb28-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with segmentation masks</span></span>
<span id="cb28-15">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_segmentation_masks(</span>
<span id="cb28-16">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sample_img), </span>
<span id="cb28-17">    masks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>masks, </span>
<span id="cb28-18">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb28-19">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb28-20">)</span>
<span id="cb28-21"></span>
<span id="cb28-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb28-23">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb28-24">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>annotated_tensor, </span>
<span id="cb28-25">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>bboxes,</span>
<span id="cb28-26">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, </span>
<span id="cb28-27">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb28-28">)</span>
<span id="cb28-29"></span>
<span id="cb28-30">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/images/output_41_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We have loaded the dataset, inspected its class distribution, and visualized the annotations for a sample image. In the final section, we will cover how to augment images using torchvision’s Transforms V2 API and create a custom Dataset class for training.</p>
</section>
</section>
</section>
<section id="preparing-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data">Preparing the Data</h2>
<p>In this section, we will first walk through a single example of how to apply augmentations to a single annotated image using torchvision’s Transforms V2 API before putting everything together in a custom Dataset class.</p>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h3>
<p>Here, we will define some data augmentations to apply to images during training. I created a few custom image transforms to help streamline the code.</p>
<p>The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#customrandomioucrop">first</a> extends the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.RandomIoUCrop.html#torchvision.transforms.v2.RandomIoUCrop"><code>RandomIoUCrop</code></a> transform included with torchvision to give the user more control over how much it crops into bounding box areas. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#resizemax">second</a> resizes images based on their largest dimension rather than their smallest. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#padsquare">third</a> applies square padding and allows the padding to be applied equally on both sides or randomly split between the two sides.</p>
<p>All three are available through the <a href="https://cj-mills.github.io/cjm-torchvision-tfms/"><code>cjm-torchvision-tfms</code></a> package.</p>
<section id="set-training-image-size" class="level4">
<h4 class="anchored" data-anchor-id="set-training-image-size">Set training image size</h4>
<p>Next, we will specify the image size to use during training.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set training image size</span></span>
<span id="cb29-2">train_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span></span></code></pre></div>
</section>
<section id="initialize-custom-transforms" class="level4">
<h4 class="anchored" data-anchor-id="initialize-custom-transforms">Initialize custom transforms</h4>
<p>Now, we can initialize the transform objects.</p>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomIoUCrop object</span></span>
<span id="cb30-2">iou_crop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomRandomIoUCrop(min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb30-3">                               max_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, </span>
<span id="cb30-4">                               min_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, </span>
<span id="cb30-5">                               max_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, </span>
<span id="cb30-6">                               sampler_options<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb30-7">                               trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb30-8">                               jitter_factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)</span>
<span id="cb30-9"></span>
<span id="cb30-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `ResizeMax` object</span></span>
<span id="cb30-11">resize_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ResizeMax(max_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_sz)</span>
<span id="cb30-12"></span>
<span id="cb30-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `PadSquare` object</span></span>
<span id="cb30-14">pad_square <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PadSquare(shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
</section>
<section id="test-the-transforms" class="level4">
<h4 class="anchored" data-anchor-id="test-the-transforms">Test the transforms</h4>
<p>Torchvision’s V2 image transforms take an image and a <code>targets</code> dictionary. The <code>targets</code> dictionary contains the annotations and labels for the image.</p>
<p>We will pass input through the <code>CustomRandomIoUCrop</code> transform first and then through <code>ResizeMax</code> and <code>PadSquare</code>. We can pass the result through a final resize operation to ensure both sides match the <code>train_sz</code> value.</p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get colors for dataset sample</span></span>
<span id="cb31-2">sample_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb31-3"></span>
<span id="cb31-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare mask and bounding box targets</span></span>
<span id="cb31-5">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb31-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>: Mask(masks), </span>
<span id="cb31-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: BoundingBoxes(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>bboxes, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), </span>
<span id="cb31-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.Tensor([class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])</span>
<span id="cb31-9">}</span>
<span id="cb31-10"></span>
<span id="cb31-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Crop the image</span></span>
<span id="cb31-12">cropped_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iou_crop(sample_img, targets)</span>
<span id="cb31-13"></span>
<span id="cb31-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Resize the image</span></span>
<span id="cb31-15">resized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_max(cropped_img, targets)</span>
<span id="cb31-16"></span>
<span id="cb31-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pad the image</span></span>
<span id="cb31-18">padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_square(resized_img, targets)</span>
<span id="cb31-19"></span>
<span id="cb31-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the padded image is the target size</span></span>
<span id="cb31-21">resize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb31-22">resized_padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize(padded_img, targets)</span>
<span id="cb31-23">sanitized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(resized_padded_img, targets)</span>
<span id="cb31-24"></span>
<span id="cb31-25">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_segmentation_masks(</span>
<span id="cb31-26">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sanitized_img), </span>
<span id="cb31-27">    masks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>], </span>
<span id="cb31-28">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb31-29">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors</span>
<span id="cb31-30">)</span>
<span id="cb31-31"></span>
<span id="cb31-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb31-33">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb31-34">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>annotated_tensor, </span>
<span id="cb31-35">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb31-36">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb31-37">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb31-38">)</span>
<span id="cb31-39"></span>
<span id="cb31-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the annotated image</span></span>
<span id="cb31-41">display(tensor_to_pil(annotated_tensor))</span>
<span id="cb31-42"></span>
<span id="cb31-43">pd.Series({</span>
<span id="cb31-44">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image:"</span>: sample_img.size,</span>
<span id="cb31-45">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cropped Image:"</span>: cropped_img.size,</span>
<span id="cb31-46">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Image:"</span>: resized_img.size,</span>
<span id="cb31-47">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Padded Image:"</span>: padded_img.size,</span>
<span id="cb31-48">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Padded Image:"</span>: resized_padded_img.size,</span>
<span id="cb31-49">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/images/output_49_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_45284">
<thead>
</thead>
<tbody>
<tr>
<th id="T_45284_level0_row0" class="row_heading level0 row0">
Source Image:
</th>
<td id="T_45284_row0_col0" class="data row0 col0">
(768, 1152)
</td>
</tr>
<tr>
<th id="T_45284_level0_row1" class="row_heading level0 row1">
Cropped Image:
</th>
<td id="T_45284_row1_col0" class="data row1 col0">
(434, 751)
</td>
</tr>
<tr>
<th id="T_45284_level0_row2" class="row_heading level0 row2">
Resized Image:
</th>
<td id="T_45284_row2_col0" class="data row2 col0">
(221, 382)
</td>
</tr>
<tr>
<th id="T_45284_level0_row3" class="row_heading level0 row3">
Padded Image:
</th>
<td id="T_45284_row3_col0" class="data row3 col0">
(382, 382)
</td>
</tr>
<tr>
<th id="T_45284_level0_row4" class="row_heading level0 row4">
Resized Padded Image:
</th>
<td id="T_45284_row4_col0" class="data row4 col0">
(384, 384)
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Now that we know how to apply data augmentations, we can put all the steps we’ve covered into a custom Dataset class.</p>
</section>
</section>
<section id="training-dataset-class" class="level3">
<h3 class="anchored" data-anchor-id="training-dataset-class">Training Dataset Class</h3>
<p>The following custom Dataset class is responsible for loading a single image, preparing the associated annotations, applying any image transforms, and returning the final <code>image</code> tensor and its <code>target</code> dictionary during training.</p>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> CVATInstSegDataset(Dataset):</span>
<span id="cb32-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This class represents a PyTorch Dataset for a collection of images and their annotations.</span></span>
<span id="cb32-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    The class is designed to load images along with their corresponding bounding box annotations and labels.</span></span>
<span id="cb32-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb32-6">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, img_keys, annotation_df, img_dict, class_to_idx, transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb32-7">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Constructor for the CVATInstSegDataset class.</span></span>
<span id="cb32-9"></span>
<span id="cb32-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb32-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        img_keys (list): List of unique identifiers for images.</span></span>
<span id="cb32-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        annotation_df (DataFrame): DataFrame containing the image annotations.</span></span>
<span id="cb32-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        img_dict (dict): Dictionary mapping image identifiers to image file paths.</span></span>
<span id="cb32-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        class_to_idx (dict): Dictionary mapping class labels to indices.</span></span>
<span id="cb32-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        transforms (callable, optional): Optional transform to be applied on a sample.</span></span>
<span id="cb32-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb32-17">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Dataset, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb32-18">        </span>
<span id="cb32-19">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># List of image keys</span></span>
<span id="cb32-20">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># DataFrame containing annotations</span></span>
<span id="cb32-21">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_dict  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dictionary mapping image keys to image paths</span></span>
<span id="cb32-22">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> class_to_idx  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dictionary mapping class names to class indices</span></span>
<span id="cb32-23">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Image transforms to be applied</span></span>
<span id="cb32-24">        </span>
<span id="cb32-25">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__len__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb32-26">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns the length of the dataset.</span></span>
<span id="cb32-28"></span>
<span id="cb32-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb32-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        int: The number of items in the dataset.</span></span>
<span id="cb32-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb32-32">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys)</span>
<span id="cb32-33">        </span>
<span id="cb32-34">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, index):</span>
<span id="cb32-35">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Fetch an item from the dataset at the specified index.</span></span>
<span id="cb32-37"></span>
<span id="cb32-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb32-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        index (int): Index of the item to fetch from the dataset.</span></span>
<span id="cb32-40"></span>
<span id="cb32-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb32-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tuple: A tuple containing the image and its associated target (annotations).</span></span>
<span id="cb32-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb32-44">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Retrieve the key for the image at the specified index</span></span>
<span id="cb32-45">        img_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys[index]</span>
<span id="cb32-46">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the annotations for this image</span></span>
<span id="cb32-47">        annotation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df.loc[img_key]</span>
<span id="cb32-48">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the image and its target (bounding boxes and labels)</span></span>
<span id="cb32-49">        image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._load_image_and_target(annotation)</span>
<span id="cb32-50">        </span>
<span id="cb32-51">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the transformations, if any</span></span>
<span id="cb32-52">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms:</span>
<span id="cb32-53">            image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms(image, target)</span>
<span id="cb32-54">        </span>
<span id="cb32-55">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, target</span>
<span id="cb32-56"></span>
<span id="cb32-57">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _load_image_and_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, annotation):</span>
<span id="cb32-58">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-59"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Load an image and its target (bounding boxes and labels).</span></span>
<span id="cb32-60"></span>
<span id="cb32-61"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb32-62"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        annotation (pandas.Series): The annotations for an image.</span></span>
<span id="cb32-63"></span>
<span id="cb32-64"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb32-65"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tuple: A tuple containing the image and a dictionary with 'boxes' and 'labels' keys.</span></span>
<span id="cb32-66"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb32-67">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Retrieve the file path of the image</span></span>
<span id="cb32-68">        filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict[annotation.name]</span>
<span id="cb32-69">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the image file and convert it to RGB</span></span>
<span id="cb32-70">        image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(filepath).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb32-71"></span>
<span id="cb32-72">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the polygon points for segmentation mask</span></span>
<span id="cb32-73">        polygon_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Polygons'</span>]</span>
<span id="cb32-74">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate mask images from polygons</span></span>
<span id="cb32-75">        mask_imgs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [create_polygon_mask(image.size, polygon[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Points'</span>]) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> polygon <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> polygon_points]</span>
<span id="cb32-76">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert mask images to tensors</span></span>
<span id="cb32-77">        masks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Mask(torch.concat([Mask(transforms.PILToTensor()(mask_img), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> mask_img <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> mask_imgs]))</span>
<span id="cb32-78">        </span>
<span id="cb32-79">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate bounding box annotations from segmentation masks</span></span>
<span id="cb32-80">        bbox_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torchvision.ops.masks_to_boxes(masks)</span>
<span id="cb32-81">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a BoundingBoxes object with the bounding boxes</span></span>
<span id="cb32-82">        boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(bbox_tensor, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb32-83">        </span>
<span id="cb32-84">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the class labels to indices</span></span>
<span id="cb32-85">        annotation_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> box <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Polygons'</span>]]</span>
<span id="cb32-86">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.Tensor([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx[label] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_labels])</span>
<span id="cb32-87">        </span>
<span id="cb32-88">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>: masks,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: boxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: labels}</span></code></pre></div>
</section>
<section id="image-transforms" class="level3">
<h3 class="anchored" data-anchor-id="image-transforms">Image Transforms</h3>
<p>Here, we will specify and organize all the image transforms to apply during training.</p>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms for data augmentation</span></span>
<span id="cb33-2">data_aug_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose(</span>
<span id="cb33-3">    transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb33-4">        iou_crop,</span>
<span id="cb33-5">        transforms.ColorJitter(</span>
<span id="cb33-6">                brightness <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.875</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.125</span>),</span>
<span id="cb33-7">                contrast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb33-8">                saturation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb33-9">                hue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>),</span>
<span id="cb33-10">        ),</span>
<span id="cb33-11">        transforms.RandomGrayscale(),</span>
<span id="cb33-12">        transforms.RandomEqualize(),</span>
<span id="cb33-13">        transforms.RandomPosterize(bits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb33-14">        transforms.RandomHorizontalFlip(p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb33-15">    ],</span>
<span id="cb33-16">)</span>
<span id="cb33-17"></span>
<span id="cb33-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to resize and pad input images</span></span>
<span id="cb33-19">resize_pad_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb33-20">    resize_max, </span>
<span id="cb33-21">    pad_square,</span>
<span id="cb33-22">    transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb33-23">])</span>
<span id="cb33-24"></span>
<span id="cb33-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to sanitize bounding boxes and normalize input data</span></span>
<span id="cb33-26">final_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb33-27">    transforms.ToImage(), </span>
<span id="cb33-28">    transforms.ToDtype(torch.float32, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb33-29">    transforms.SanitizeBoundingBoxes(),</span>
<span id="cb33-30">])</span>
<span id="cb33-31"></span>
<span id="cb33-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the transformations for training and validation datasets</span></span>
<span id="cb33-33">train_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb33-34">    data_aug_tfms, </span>
<span id="cb33-35">    resize_pad_tfm, </span>
<span id="cb33-36">    final_tfms</span>
<span id="cb33-37">])</span></code></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always use the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.SanitizeBoundingBoxes.html#torchvision.transforms.v2.SanitizeBoundingBoxes"><code>SanitizeBoundingBoxes</code></a> transform to clean up annotations after using data augmentations that alter bounding boxes (e.g., cropping, warping, etc.).</p>
</div>
</div>
</section>
<section id="initialize-dataset" class="level3">
<h3 class="anchored" data-anchor-id="initialize-dataset">Initialize Dataset</h3>
<p>Now, we can create the dataset object using the image dictionary, the annotation DataFrame, and the image transforms.</p>
<div class="sourceCode" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mapping from class names to class indices</span></span>
<span id="cb34-2">class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {c: i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(class_names)}</span>
<span id="cb34-3"></span>
<span id="cb34-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Instantiate the dataset using the defined transformations</span></span>
<span id="cb34-5">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CVATInstSegDataset(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys()), annotation_df, img_dict, class_to_idx, train_tfms)</span>
<span id="cb34-6"></span>
<span id="cb34-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of samples in the training dataset</span></span>
<span id="cb34-8">pd.Series({</span>
<span id="cb34-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training dataset size:'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataset),</span>
<span id="cb34-10">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_5167f">
<thead>
</thead>
<tbody>
<tr>
<th id="T_5167f_level0_row0" class="row_heading level0 row0">
Training dataset size:
</th>
<td id="T_5167f_row0_col0" class="data row0 col0">
31
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspect-samples" class="level3">
<h3 class="anchored" data-anchor-id="inspect-samples">Inspect Samples</h3>
<p>To close out, we should verify the dataset object works as intended by inspecting the first sample.</p>
<section id="inspect-training-set-sample" class="level4">
<h4 class="anchored" data-anchor-id="inspect-training-set-sample">Inspect training set sample</h4>
<div class="sourceCode" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">dataset_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_dataset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb35-2"></span>
<span id="cb35-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get colors for dataset sample</span></span>
<span id="cb35-4">sample_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb35-5"></span>
<span id="cb35-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with segmentation masks</span></span>
<span id="cb35-7">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_segmentation_masks( </span>
<span id="cb35-8">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.uint8), </span>
<span id="cb35-9">    masks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>], </span>
<span id="cb35-10">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb35-11">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors</span>
<span id="cb35-12">)</span>
<span id="cb35-13"></span>
<span id="cb35-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with bounding boxes</span></span>
<span id="cb35-15">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb35-16">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>annotated_tensor, </span>
<span id="cb35-17">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb35-18">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb35-19">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors</span>
<span id="cb35-20">)</span>
<span id="cb35-21"></span>
<span id="cb35-22">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/images/output_60_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we covered how to load custom segmentation annotations made with the CVAT annotation tool and work with them using torchvision’s Transforms V2 API. The skills and knowledge you acquired here provide a solid foundation for future instance segmentation projects.</p>
<p>As a next step, perhaps try annotating a custom instance segmentation dataset with CVAT and loading it with this tutorial’s code. Once you’re comfortable with that, try adapting the code in the following tutorial to train an instance segmentation model on your custom dataset.</p>
<ul>
<li><a href="../../../posts/pytorch-train-mask-rcnn-tutorial/">Training Mask R-CNN Models with PyTorch</a></li>
</ul>
</section>
<section id="recommended-tutorials" class="level2">
<h2 class="anchored" data-anchor-id="recommended-tutorials">Recommended Tutorials</h2>
<ul>
<li><a href="../../../posts/torchvision-cvat-annotation-tutorials/bounding-boxes/"><strong>Working with CVAT Bounding Box Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with CVAT bounding box annotations in torchvision for object detection tasks.</li>
<li><a href="../../../posts/torchvision-cvat-annotation-tutorials/keypoints/"><strong>Working with CVAT Keypoint Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with CVAT keypoint annotations in torchvision for keypoint estimation tasks.</li>
<li><a href="http://localhost:3847/posts/pytorch-train-mask-rcnn-tutorial/"><strong>Training Mask R-CNN Models with PyTorch</strong></a><strong>:</strong> Learn how to train Mask R-CNN models on custom datasets with PyTorch.</li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>image-annotation</category>
  <category>instance-segmentation</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/</guid>
  <pubDate>Sun, 21 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Working with CVAT Keypoint Annotations in Torchvision</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/torchvision-cvat-annotation-tutorials/keypoints/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/tutorials/torchvision-annotation-tutorials-series.html"><strong>Torchvision Annotation Tutorials</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Loading and Exploring the Dataset</li>
<li>Preparing the Data</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to this hands-on guide for working with keypoint annotations created with the <a href="https://github.com/opencv/cvat">CVAT annotation tool</a> in <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>. Keypoint annotations mark specific points of interest on an object in an image for training models to recognize and interpret poses, gestures, or significant parts of objects.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/keypoints/images/keypoint-hero-img.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The tutorial walks through setting up a Python environment, loading the raw annotations into a <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a>, annotating and augmenting images using torchvision’s <a href="https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py">Transforms V2 API</a>, and creating a custom <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Dataset</a> class to feed samples to a model.</p>
<p>This guide is suitable for beginners and experienced practitioners, providing the code, explanations, and resources needed to understand and implement each step. By the end, you will have a solid foundation for working with keypoint annotations made with CVAT for keypoint estimation tasks.</p>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>The tutorial code is available as a <a href="https://jupyter.org/">Jupyter Notebook</a>, which you can run locally or in a cloud-based environment like <a href="https://colab.research.google.com/">Google Colab</a>. I have dedicated tutorials for those new to these platforms or who need guidance setting up:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Setup Guides">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Setup Guides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="../../../posts/google-colab-getting-started-tutorial/"><strong>Getting Started with Google Colab</strong></a></p></li>
<li><p><a href="../../../posts/mamba-getting-started-tutorial-windows/"><strong>Setting Up a Local Python Environment with Mamba for Machine Learning Projects on Windows</strong></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Tutorial Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tutorial Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook:</th>
<th><a href="https://github.com/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/cvat/torchvision-cvat-keypoint-annotations.ipynb">GitHub Repository</a></th>
<th><a href="https://colab.research.google.com/github/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/cvat/torchvision-cvat-keypoint-annotations.ipynb">Open In Colab</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>Before diving into the code, we’ll cover the steps to create a local Python environment and install the necessary dependencies.</p>
<section id="creating-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-python-environment">Creating a Python Environment</h3>
<p>First, we’ll create a Python environment using <a href="https://docs.conda.io/en/latest/">Conda</a>/<a href="https://mamba.readthedocs.io/en/latest/">Mamba</a>. Open a terminal with Conda/Mamba installed and run the following commands:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Conda</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Mamba</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate pytorch-env</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate pytorch-env</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="installing-pytorch">Installing PyTorch</h3>
<p>Next, we’ll install <a href="https://pytorch.org/">PyTorch</a>. Run the appropriate command for your hardware and operating system.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Linux/Windows (CUDA)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Mac</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Linux (CPU)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Windows (CPU)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch with CUDA</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cu121</span></code></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MPS (Metal Performance Shaders) acceleration is available on MacOS 12.3+</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cpu</span></code></pre></div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-additional-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-libraries">Installing Additional Libraries</h3>
<p>We also need to install some additional libraries for our project.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>jupyter</code></td>
<td>An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. (<a href="https://jupyter.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>matplotlib</code></td>
<td>This package provides a comprehensive collection of visualization tools to create high-quality plots, charts, and graphs for data exploration and presentation. (<a href="https://matplotlib.org/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>pandas</code></td>
<td>This package provides fast, powerful, and flexible data analysis and manipulation tools. (<a href="https://pandas.pydata.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>pillow</code></td>
<td>The Python Imaging Library adds image processing capabilities. (<a href="https://pillow.readthedocs.io/en/stable/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>tqdm</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>distinctipy</code></td>
<td>A lightweight python package providing functions to generate colours that are visually distinct from one another. (<a href="https://distinctipy.readthedocs.io/en/latest/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install these additional libraries:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional dependencies</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install distinctipy jupyter matplotlib pandas pillow tqdm</span></code></pre></div>
</section>
<section id="installing-utility-packages" class="level3">
<h3 class="anchored" data-anchor-id="installing-utility-packages">Installing Utility Packages</h3>
<p>We will also install some utility packages I made, which provide shortcuts for routine tasks.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>cjm_pil_utils</code></td>
<td>Some PIL utility functions I frequently use. (<a href="https://cj-mills.github.io/cjm-pil-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_psl_utils</code></td>
<td>Some utility functions using the Python Standard Library. (<a href="https://cj-mills.github.io/cjm-psl-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_pytorch_utils</code></td>
<td>Some utility functions for working with PyTorch. (<a href="https://cj-mills.github.io/cjm-pytorch-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_torchvision_tfms</code></td>
<td>Some custom Torchvision tranforms. (<a href="https://cj-mills.github.io/cjm-torchvision-tfms/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install the utility packages:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional utility packages</span></span>
<span id="cb8-2">pip install cjm_pil_utils cjm_psl_utils cjm_pytorch_utils cjm_torchvision_tfms</span></code></pre></div>
<p>With our environment set up, we can open our Jupyter Notebook and dive into the code.</p>
</section>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python packages into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb9-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> xml.etree.ElementTree <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> ET</span>
<span id="cb9-5"></span>
<span id="cb9-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb9-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_img_files</span>
<span id="cb9-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file, file_extract</span>
<span id="cb9-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pytorch_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor_to_pil</span>
<span id="cb9-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_torchvision_tfms.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ResizeMax, PadSquare, CustomRandomIoUCrop</span>
<span id="cb9-11"></span>
<span id="cb9-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the distinctipy module</span></span>
<span id="cb9-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distinctipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> distinctipy</span>
<span id="cb9-14"></span>
<span id="cb9-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import matplotlib for creating plots</span></span>
<span id="cb9-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb9-17"></span>
<span id="cb9-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb9-19"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-20"></span>
<span id="cb9-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb9-22"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb9-23"></span>
<span id="cb9-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb9-25">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb9-26"></span>
<span id="cb9-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb9-28"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image, ImageDraw</span>
<span id="cb9-29"></span>
<span id="cb9-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb9-31"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb9-32"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DataLoader</span>
<span id="cb9-33"></span>
<span id="cb9-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import torchvision dependencies</span></span>
<span id="cb9-35"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision</span>
<span id="cb9-36">torchvision.disable_beta_transforms_warning()</span>
<span id="cb9-37"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BoundingBoxes</span>
<span id="cb9-38"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> draw_bounding_boxes</span>
<span id="cb9-39"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.v2  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb9-40"></span>
<span id="cb9-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import tqdm for progress bar</span></span>
<span id="cb9-42"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm.auto <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
<p>Torchvision provides dedicated <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> subclasses for different annotation types called <a href="https://pytorch.org/vision/stable/tv_tensors.html"><code>TVTensors</code></a>. Torchvision’s V2 transforms use these subclasses to update the annotations based on the applied image augmentations. While there is currently no dedicated TVTensor class for keypoint annotations, we can use the one for bounding boxes instead. Torchvision does include a <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_keypoints.html"><code>draw_keypoints</code></a> function, but we might as well stick with the <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function to annotate images.</p>
</section>
<section id="loading-and-exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-and-exploring-the-dataset">Loading and Exploring the Dataset</h2>
<p>After importing the dependencies, we can start working with our data. I annotated a toy dataset with keypoints for this tutorial using images from the free stock photo site <a href="https://www.pexels.com/">Pexels</a>. The dataset is available on <a href="https://huggingface.co/">HuggingFace Hub</a> at the link below:</p>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/datasets/cj-mills/cvat-keypoint-toy-dataset/tree/main">cvat-keypoint-toy-dataset</a></li>
</ul>
<section id="setting-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-directory-paths">Setting the Directory Paths</h3>
<p>We first need to specify a place to store our dataset and a location to download the zip file containing it. The following code creates the folders in the current directory (<code>./</code>). Update the path if that is not suitable for you.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store datasets</span></span>
<span id="cb10-2">dataset_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./Datasets/"</span>)</span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the dataset directory if it does not exist</span></span>
<span id="cb10-4">dataset_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store archive files</span></span>
<span id="cb10-7">archive_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'../Archive'</span></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the archive directory if it does not exist</span></span>
<span id="cb10-9">archive_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb10-12">pd.Series({</span>
<span id="cb10-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Directory:"</span>: dataset_dir, </span>
<span id="cb10-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Directory:"</span>: archive_dir</span>
<span id="cb10-15">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_2f713">
<thead>
</thead>
<tbody>
<tr>
<th id="T_2f713_level0_row0" class="row_heading level0 row0">
Dataset Directory:
</th>
<td id="T_2f713_row0_col0" class="data row0 col0">
Datasets
</td>
</tr>
<tr>
<th id="T_2f713_level0_row1" class="row_heading level0 row1">
Archive Directory:
</th>
<td id="T_2f713_row1_col0" class="data row1 col0">
Datasets/../Archive
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="setting-the-dataset-path" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-dataset-path">Setting the Dataset Path</h3>
<p>Next, we construct the name for the Hugging Face Hub dataset and set where to download and extract the dataset.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the dataset</span></span>
<span id="cb11-2">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cvat-keypoint-toy-dataset'</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb11-5">hf_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'cj-mills/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb11-8">archive_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>archive_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip'</span>)</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb11-11">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the dataset name and paths and converting it to a DataFrame for display</span></span>
<span id="cb11-14">pd.Series({</span>
<span id="cb11-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb11-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Path:"</span>: archive_path, </span>
<span id="cb11-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Path:"</span>: dataset_path</span>
<span id="cb11-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_01a4c">
<thead>
</thead>
<tbody>
<tr>
<th id="T_01a4c_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_01a4c_row0_col0" class="data row0 col0">
cj-mills/cvat-keypoint-toy-dataset
</td>
</tr>
<tr>
<th id="T_01a4c_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_01a4c_row1_col0" class="data row1 col0">
Datasets/../Archive/cvat-keypoint-toy-dataset.zip
</td>
</tr>
<tr>
<th id="T_01a4c_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_01a4c_row2_col0" class="data row2 col0">
Datasets/cvat-keypoint-toy-dataset
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="downloading-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h3>
<p>We can now download the archive file and extract the dataset using the <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#download_file"><code>download_file</code></a> and <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#file_extract"><code>file_extract</code></a> functions from the <code>cjm_psl_utils</code> package. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb12-2">dataset_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>hf_dataset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip"</span></span>
<span id="cb12-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"HuggingFace Dataset URL: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb12-6">delete_archive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the dataset if not present</span></span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset_path.is_dir():</span>
<span id="cb12-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset folder already exists"</span>)</span>
<span id="cb12-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb12-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Downloading dataset..."</span>)</span>
<span id="cb12-13">    download_file(dataset_url, archive_dir)    </span>
<span id="cb12-14">    </span>
<span id="cb12-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extracting dataset..."</span>)</span>
<span id="cb12-16">    file_extract(fname<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>archive_path, dest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_dir)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete the archive if specified</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> delete_archive: archive_path.unlink()</span></code></pre></div>
</section>
<section id="getting-the-images-and-annotations" class="level3">
<h3 class="anchored" data-anchor-id="getting-the-images-and-annotations">Getting the Images and Annotations</h3>
<p>The dataset has a folder containing the sample images and an XML file containing the annotations.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming the images are stored in a subfolder named 'images'</span></span>
<span id="cb13-2">img_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'images/'</span></span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming annotation file is in XML format and located in any subdirectory of the dataset</span></span>
<span id="cb13-5">annotation_file_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'annotations.xml'</span></span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb13-8">pd.Series({</span>
<span id="cb13-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Image Folder"</span>: img_dir, </span>
<span id="cb13-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annotation File"</span>: annotation_file_path}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_5d6a1">
<thead>
</thead>
<tbody>
<tr>
<th id="T_5d6a1_level0_row0" class="row_heading level0 row0">
Image Folder
</th>
<td id="T_5d6a1_row0_col0" class="data row0 col0">
Datasets/cvat-keypoint-toy-dataset/images
</td>
</tr>
<tr>
<th id="T_5d6a1_level0_row1" class="row_heading level0 row1">
Annotation File
</th>
<td id="T_5d6a1_row1_col0" class="data row1 col0">
Datasets/cvat-keypoint-toy-dataset/annotations.xml
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-file-paths" class="level3">
<h3 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h3>
<p>Each image file has a unique name that we can use to locate the corresponding annotation data. We can make a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image more efficiently.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get all image files in the 'img_dir' directory</span></span>
<span id="cb14-2">img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb14-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.stem : <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary that maps file names to file paths</span></span>
<span id="cb14-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> get_img_files(img_dir) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of image files in the image directory</span></span>
<span id="cb14-5">}</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of image files</span></span>
<span id="cb14-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Number of Images: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_dict)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb14-9"></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb14-11">pd.DataFrame.from_dict(img_dict, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).head()</span></code></pre></div>
<pre class="text"><code>Number of Images: 38</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
adorable-animal-blur-988551
</th>
<td>
Datasets/cvat-keypoint-toy-dataset/images/adorable-animal-blur-988551.jpg
</td>
</tr>
<tr>
<th>
133196
</th>
<td>
Datasets/cvat-keypoint-toy-dataset/images/133196.jpg
</td>
</tr>
<tr>
<th>
245035
</th>
<td>
Datasets/cvat-keypoint-toy-dataset/images/245035.jpg
</td>
</tr>
<tr>
<th>
245036
</th>
<td>
Datasets/cvat-keypoint-toy-dataset/images/245036.jpg
</td>
</tr>
<tr>
<th>
247937
</th>
<td>
Datasets/cvat-keypoint-toy-dataset/images/247937.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="get-image-annotations">Get Image Annotations</h3>
<p>Next, we read the content of the XML annotation file into a Pandas DataFrame so we can easily query the annotations.</p>
<section id="define-a-function-to-parse-the-cvat-xml-annotations" class="level4">
<h4 class="anchored" data-anchor-id="define-a-function-to-parse-the-cvat-xml-annotations">Define a function to parse the CVAT XML annotations</h4>
<p>The following helper function parses the raw XML content into a Pandas DataFrame.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> parse_cvat_keypoint_xml(xml_content):</span>
<span id="cb16-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb16-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parses a CVAT XML content for keypoints and converts it into a Pandas DataFrame.</span></span>
<span id="cb16-4"></span>
<span id="cb16-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function processes an XML file used in Computer Vision Annotation Tool (CVAT) format. </span></span>
<span id="cb16-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    It extracts key information such as image ID, image name, dimensions, and keypoints.</span></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb16-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb16-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    xml_content (str): A string representation of the CVAT XML content.</span></span>
<span id="cb16-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb16-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb16-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    pandas.DataFrame: A DataFrame where each row represents an image and its associated data </span></span>
<span id="cb16-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                      including image ID, image name, dimensions, and keypoints.</span></span>
<span id="cb16-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb16-15">    </span>
<span id="cb16-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Parse the XML content</span></span>
<span id="cb16-17">    root <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ET.fromstring(xml_content)</span>
<span id="cb16-18">    data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb16-19"></span>
<span id="cb16-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterating through each image element in the XML</span></span>
<span id="cb16-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> image <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> root.findall(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image'</span>):</span>
<span id="cb16-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extracting basic image information</span></span>
<span id="cb16-23">        image_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>)</span>
<span id="cb16-24">        image_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>)</span>
<span id="cb16-25">        width <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'width'</span>)</span>
<span id="cb16-26">        height <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'height'</span>)</span>
<span id="cb16-27"></span>
<span id="cb16-28">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Structuring image data</span></span>
<span id="cb16-29">        image_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb16-30">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image ID'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(image_id),</span>
<span id="cb16-31">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image Name'</span>: image_name,</span>
<span id="cb16-32">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Width'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(width),</span>
<span id="cb16-33">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Height'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(height),</span>
<span id="cb16-34">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Keypoints'</span>: []</span>
<span id="cb16-35">        }</span>
<span id="cb16-36"></span>
<span id="cb16-37">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterating through keypoints within each image</span></span>
<span id="cb16-38">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> points <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> image.findall(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>):</span>
<span id="cb16-39">            label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> points.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>)</span>
<span id="cb16-40">            keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> points.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'points'</span>).split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">','</span>)</span>
<span id="cb16-41">            x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(keypoints[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb16-42">            y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(keypoints[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb16-43"></span>
<span id="cb16-44">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Structuring keypoints data</span></span>
<span id="cb16-45">            keypoints_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb16-46">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>: label,</span>
<span id="cb16-47">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>: x,</span>
<span id="cb16-48">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>: y</span>
<span id="cb16-49">            }</span>
<span id="cb16-50">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding keypoints data to the image data</span></span>
<span id="cb16-51">            image_data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Keypoints'</span>].append(keypoints_data)</span>
<span id="cb16-52"></span>
<span id="cb16-53">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding image data to the overall data dictionary</span></span>
<span id="cb16-54">        data[image_id] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image_data</span>
<span id="cb16-55"></span>
<span id="cb16-56">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Converting the data dictionary to a Pandas DataFrame</span></span>
<span id="cb16-57">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> pd.DataFrame.from_dict(data, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>)</span></code></pre></div>
</section>
<section id="load-cvat-xml-annotations-into-a-dataframe" class="level4">
<h4 class="anchored" data-anchor-id="load-cvat-xml-annotations-into-a-dataframe">Load CVAT XML annotations into a DataFrame</h4>
<p>After parsing the XML content, we will change the index for the <code>annotation_df</code> DataFrame to match the keys in the <code>img_dict</code> dictionary, allowing us to retrieve both the image paths and annotation data using the same index key.</p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Read the XML file</span></span>
<span id="cb17-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(annotation_file_path, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'utf-8'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>:</span>
<span id="cb17-3">    xml_content <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.read()</span>
<span id="cb17-4"></span>
<span id="cb17-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Parse the XML content</span></span>
<span id="cb17-6">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parse_cvat_keypoint_xml(xml_content)</span>
<span id="cb17-7"></span>
<span id="cb17-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add a new column 'Image ID' by extracting it from 'Image Name'</span></span>
<span id="cb17-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This assumes that the 'Image ID' is the part of the 'Image Name' before the first period</span></span>
<span id="cb17-10">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image ID'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image Name'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: x.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb17-11"></span>
<span id="cb17-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the new 'Image ID' column as the index of the DataFrame</span></span>
<span id="cb17-13">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image ID'</span>)</span>
<span id="cb17-14"></span>
<span id="cb17-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first few rows of the DataFrame</span></span>
<span id="cb17-16">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Image Name
</th>
<th>
Width
</th>
<th>
Height
</th>
<th>
Keypoints
</th>
</tr>
<tr>
<th>
Image ID
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
133196
</th>
<td>
133196.jpg
</td>
<td>
960
</td>
<td>
768
</td>
<td>
[{‘Label’: ‘nose’, ‘x’: 386.71, ‘y’: 297.11}]
</td>
</tr>
<tr>
<th>
245035
</th>
<td>
245035.jpg
</td>
<td>
768
</td>
<td>
1152
</td>
<td>
[{‘Label’: ‘nose’, ‘x’: 334.46, ‘y’: 319.58}]
</td>
</tr>
<tr>
<th>
245036
</th>
<td>
245036.jpg
</td>
<td>
768
</td>
<td>
1120
</td>
<td>
[{‘Label’: ‘nose’, ‘x’: 226.86, ‘y’: 240.8}]
</td>
</tr>
<tr>
<th>
247937
</th>
<td>
247937.jpg
</td>
<td>
1152
</td>
<td>
768
</td>
<td>
[{‘Label’: ‘nose’, ‘x’: 454.66, ‘y’: 230.04}]
</td>
</tr>
<tr>
<th>
3172614
</th>
<td>
3172614.jpg
</td>
<td>
1152
</td>
<td>
768
</td>
<td>
[{‘Label’: ‘nose’, ‘x’: 539.41, ‘y’: 608.09}]
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>The source XML content corresponding to the first row in the DataFrame is available below:</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode xml code-with-copy"><code class="sourceCode xml"><span id="cb18-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">&lt;?xml</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> version=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1.0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> encoding=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"utf-8"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">?&gt;</span></span>
<span id="cb18-2">&lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">annotations</span>&gt;</span>
<span id="cb18-3">  &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">version</span>&gt;1.1&lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">version</span>&gt;</span>
<span id="cb18-4">  &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">meta</span>&gt;</span>
<span id="cb18-5">  &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">meta</span>&gt;</span>
<span id="cb18-6">  &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">image</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> id=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> name=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"133196.jpg"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> width=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"960"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> height=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"768"</span>&gt;</span>
<span id="cb18-7">    &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">points</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> label=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nose"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> source=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"file"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> occluded=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> points=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"386.71,297.11"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> z_order=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span>&gt;</span>
<span id="cb18-8">    &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">points</span>&gt;</span>
<span id="cb18-9">  &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">image</span>&gt;</span>
<span id="cb18-10">&lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">annotations</span>&gt;</span></code></pre></div>
<p>With the annotations loaded, we can start inspecting our dataset.</p>
</section>
</section>
<section id="inspecting-the-class-distribution" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-the-class-distribution">Inspecting the Class Distribution</h3>
<p>First, we get the names of all the classes in our dataset and inspect the distribution of samples among these classes. This step won’t yield any insights for the toy dataset but is worth doing for real-world projects. A balanced dataset (where each class has approximately the same number of instances) is ideal for training a machine-learning model.</p>
<section id="get-image-classes" class="level4">
<h4 class="anchored" data-anchor-id="get-image-classes">Get image classes</h4>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Explode the 'boxes_df' column in the annotation_df dataframe</span></span>
<span id="cb19-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the resulting series to a dataframe and rename the 'boxes_df' column to 'boxes_df'</span></span>
<span id="cb19-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the pandas Series function to the 'boxes_df' column of the dataframe</span></span>
<span id="cb19-4">keypoints_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Keypoints'</span>].explode().to_frame().Keypoints.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)</span>
<span id="cb19-5"></span>
<span id="cb19-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb19-7">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> keypoints_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>].unique().tolist()</span>
<span id="cb19-8"></span>
<span id="cb19-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display labels using a Pandas DataFrame</span></span>
<span id="cb19-10">pd.DataFrame(class_names)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
nose
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visualize-the-class-distribution" class="level4">
<h4 class="anchored" data-anchor-id="visualize-the-class-distribution">Visualize the class distribution</h4>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the number of samples for each object class</span></span>
<span id="cb20-2">class_counts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> keypoints_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>].value_counts()</span>
<span id="cb20-3"></span>
<span id="cb20-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the distribution</span></span>
<span id="cb20-5">class_counts.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bar'</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb20-6">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class distribution'</span>)</span>
<span id="cb20-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Count'</span>)</span>
<span id="cb20-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Classes'</span>)</span>
<span id="cb20-9">plt.xticks(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_counts.index)), class_counts.index, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the x-axis tick labels</span></span>
<span id="cb20-10">plt.show()</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/keypoints/images/output_24_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
<section id="visualizing-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-image-annotations">Visualizing Image Annotations</h3>
<p>In this section, we will annotate a single image with its keypoints using torchvision’s <code>BoundingBoxes</code> class and <code>draw_bounding_boxes</code> function.</p>
<section id="generate-a-color-map" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-color-map">Generate a color map</h4>
<p>While not required, assigning a unique color to keypoints for each object class enhances visual distinction, allowing for easier identification of different objects in the scene. We can use the <a href="https://distinctipy.readthedocs.io/en/latest/"><code>distinctipy</code></a> package to generate a visually distinct colormap.</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb21-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distinctipy.get_colors(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the color map in integer format</span></span>
<span id="cb21-5">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colors]</span>
<span id="cb21-6"></span>
<span id="cb21-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a color swatch to visualize the color map</span></span>
<span id="cb21-8">distinctipy.color_swatch(colors)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/keypoints/images/output_27_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a font file</h4>
<p>The <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function included with torchvision uses a pretty small font size. We can increase the font size if we use a custom font. Font files are available on sites like <a href="https://fonts.google.com/">Google Fonts</a>, or we can use one included with the operating system.</p>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb22-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb22-3"></span>
<span id="cb22-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb22-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
</section>
<section id="define-the-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-the-bounding-box-annotation-function">Define the bounding box annotation function</h4>
<p>We can make a partial function using <code>draw_bounding_boxes</code> since we’ll use the same box thickness and font each time we visualize bounding boxes.</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">draw_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(draw_bounding_boxes, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, font<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>font_file, font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
</section>
</section>
<section id="selecting-a-sample-image" class="level3">
<h3 class="anchored" data-anchor-id="selecting-a-sample-image">Selecting a Sample Image</h3>
<p>We can use the unique ID for an image in the image dictionary to get the image file path and the associated annotations from the annotation DataFrame.</p>
<section id="load-the-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="load-the-sample-image">Load the sample image</h4>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the file ID of the first image file</span></span>
<span id="cb24-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb24-3"></span>
<span id="cb24-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the associated image file as a RGB image</span></span>
<span id="cb24-5">sample_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(img_dict[file_id]).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb24-6"></span>
<span id="cb24-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the dimensions of the image</span></span>
<span id="cb24-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Image Dims: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sample_img<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>size<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb24-9"></span>
<span id="cb24-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Show the image</span></span>
<span id="cb24-11">sample_img</span></code></pre></div>
<pre class="text"><code>Image Dims: (1152, 768)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/keypoints/images/output_35_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="inspect-the-corresponding-annotation-data" class="level4">
<h4 class="anchored" data-anchor-id="inspect-the-corresponding-annotation-data">Inspect the corresponding annotation data</h4>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'</span></span>
<span id="cb26-2">annotation_df.loc[file_id].to_frame()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
adorable-animal-blur-988551
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
Image Name
</th>
<td>
adorable-animal-blur-988551.jpg
</td>
</tr>
<tr>
<th>
Width
</th>
<td>
1152
</td>
</tr>
<tr>
<th>
Height
</th>
<td>
768
</td>
</tr>
<tr>
<th>
Keypoints
</th>
<td>
[{‘Label’: ‘nose’, ‘x’: 349.17, ‘y’: 520.89}]
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="annotate-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="annotate-sample-image">Annotate sample image</h4>
<p>We can convert our keypoint annotations to bounding boxes by adding values for box width and height, making it <code>[center-x, center-y, width, height]</code> format</p>
<p>The <code>draw_bounding_boxes</code> function expects bounding box annotations in <code>[top-left X, top-left Y, bottom-right X, bottom-right Y]</code> format, so we’ll use the <a href="https://pytorch.org/vision/stable/generated/torchvision.ops.box_convert.html#torchvision.ops.box_convert"><code>box_convert</code></a> function included with torchvision to convert the bounding box annotations from <code>[cx,cy,w,h]</code> to <code>[x,y,x,y]</code> format.</p>
<p>We can reverse this process during training to extract the target keypoints for calculating the loss.</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels and keypoint annotations for the sample image</span></span>
<span id="cb27-2">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [keypoint[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> keypoint <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Keypoints'</span>]]</span>
<span id="cb27-3">keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[keypoint[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>], keypoint[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>]] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> keypoint <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Keypoints'</span>]])</span>
<span id="cb27-4">keypoints_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((torch.tensor(keypoints), torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(keypoints), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb27-5"></span>
<span id="cb27-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb27-7">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb27-8">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sample_img), </span>
<span id="cb27-9">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torchvision.ops.box_convert(torch.Tensor(keypoints_bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>), </span>
<span id="cb27-10">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, </span>
<span id="cb27-11">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb27-12">)</span>
<span id="cb27-13"></span>
<span id="cb27-14">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/keypoints/images/output_39_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We have loaded the dataset, inspected its class distribution, and visualized the annotations for a sample image. In the final section, we will cover how to augment images using torchvision’s Transforms V2 API and create a custom Dataset class for training.</p>
</section>
</section>
</section>
<section id="preparing-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data">Preparing the Data</h2>
<p>In this section, we will first walk through a single example of how to apply augmentations to a single annotated image using torchvision’s Transforms V2 API before putting everything together in a custom Dataset class.</p>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h3>
<p>Here, we will define some data augmentations to apply to images during training. I created a few custom image transforms to help streamline the code.</p>
<p>The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#customrandomioucrop">first</a> extends the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.RandomIoUCrop.html#torchvision.transforms.v2.RandomIoUCrop"><code>RandomIoUCrop</code></a> transform included with torchvision to give the user more control over how much it crops into bounding box areas. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#resizemax">second</a> resizes images based on their largest dimension rather than their smallest. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#padsquare">third</a> applies square padding and allows the padding to be applied equally on both sides or randomly split between the two sides.</p>
<p>All three are available through the <a href="https://cj-mills.github.io/cjm-torchvision-tfms/"><code>cjm-torchvision-tfms</code></a> package.</p>
<section id="set-training-image-size" class="level4">
<h4 class="anchored" data-anchor-id="set-training-image-size">Set training image size</h4>
<p>Next, we will specify the image size to use during training.</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set training image size</span></span>
<span id="cb28-2">train_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span></span></code></pre></div>
</section>
<section id="initialize-custom-transforms" class="level4">
<h4 class="anchored" data-anchor-id="initialize-custom-transforms">Initialize custom transforms</h4>
<p>Now, we can initialize the transform objects.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomIoUCrop object</span></span>
<span id="cb29-2">iou_crop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomRandomIoUCrop(min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb29-3">                               max_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, </span>
<span id="cb29-4">                               min_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, </span>
<span id="cb29-5">                               max_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, </span>
<span id="cb29-6">                               sampler_options<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb29-7">                               trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb29-8">                               jitter_factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)</span>
<span id="cb29-9"></span>
<span id="cb29-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `ResizeMax` object</span></span>
<span id="cb29-11">resize_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ResizeMax(max_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_sz)</span>
<span id="cb29-12"></span>
<span id="cb29-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `PadSquare` object</span></span>
<span id="cb29-14">pad_square <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PadSquare(shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</section>
<section id="test-the-transforms" class="level4">
<h4 class="anchored" data-anchor-id="test-the-transforms">Test the transforms</h4>
<p>Torchvision’s V2 image transforms take an image and a <code>targets</code> dictionary. The <code>targets</code> dictionary contains the annotations and labels for the image.</p>
<p>We will pass input through the <code>CustomRandomIoUCrop</code> transform first and then through <code>ResizeMax</code> and <code>PadSquare</code>. We can pass the result through a final resize operation to ensure both sides match the <code>train_sz</code> value.</p>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare bounding box targets</span></span>
<span id="cb30-2">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb30-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: BoundingBoxes(torchvision.ops.box_convert(keypoints_bboxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>), </span>
<span id="cb30-4">                           <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, </span>
<span id="cb30-5">                           canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), </span>
<span id="cb30-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.Tensor([class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])</span>
<span id="cb30-7">}</span>
<span id="cb30-8"></span>
<span id="cb30-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Crop the image</span></span>
<span id="cb30-10">cropped_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iou_crop(sample_img, targets)</span>
<span id="cb30-11"></span>
<span id="cb30-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Resize the image</span></span>
<span id="cb30-13">resized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_max(cropped_img, targets)</span>
<span id="cb30-14"></span>
<span id="cb30-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pad the image</span></span>
<span id="cb30-16">padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_square(resized_img, targets)</span>
<span id="cb30-17"></span>
<span id="cb30-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the padded image is the target size</span></span>
<span id="cb30-19">resize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb30-20">resized_padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize(padded_img, targets)</span>
<span id="cb30-21">sanitized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(resized_padded_img, targets)</span>
<span id="cb30-22"></span>
<span id="cb30-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb30-24">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb30-25">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sanitized_img), </span>
<span id="cb30-26">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb30-27">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb30-28">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb30-29">)</span>
<span id="cb30-30"></span>
<span id="cb30-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the annotated image</span></span>
<span id="cb30-32">display(tensor_to_pil(annotated_tensor))</span>
<span id="cb30-33"></span>
<span id="cb30-34">pd.Series({</span>
<span id="cb30-35">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image:"</span>: sample_img.size,</span>
<span id="cb30-36">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cropped Image:"</span>: cropped_img.size,</span>
<span id="cb30-37">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Image:"</span>: resized_img.size,</span>
<span id="cb30-38">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Padded Image:"</span>: padded_img.size,</span>
<span id="cb30-39">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Padded Image:"</span>: resized_padded_img.size,</span>
<span id="cb30-40">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/keypoints/images/output_47_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_5e985">
<thead>
</thead>
<tbody>
<tr>
<th id="T_5e985_level0_row0" class="row_heading level0 row0">
Source Image:
</th>
<td id="T_5e985_row0_col0" class="data row0 col0">
(1152, 768)
</td>
</tr>
<tr>
<th id="T_5e985_level0_row1" class="row_heading level0 row1">
Cropped Image:
</th>
<td id="T_5e985_row1_col0" class="data row1 col0">
(1152, 768)
</td>
</tr>
<tr>
<th id="T_5e985_level0_row2" class="row_heading level0 row2">
Resized Image:
</th>
<td id="T_5e985_row2_col0" class="data row2 col0">
(384, 256)
</td>
</tr>
<tr>
<th id="T_5e985_level0_row3" class="row_heading level0 row3">
Padded Image:
</th>
<td id="T_5e985_row3_col0" class="data row3 col0">
(384, 384)
</td>
</tr>
<tr>
<th id="T_5e985_level0_row4" class="row_heading level0 row4">
Resized Padded Image:
</th>
<td id="T_5e985_row4_col0" class="data row4 col0">
(384, 384)
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Now that we know how to apply data augmentations, we can put all the steps we’ve covered into a custom Dataset class.</p>
</section>
</section>
<section id="training-dataset-class" class="level3">
<h3 class="anchored" data-anchor-id="training-dataset-class">Training Dataset Class</h3>
<p>The following custom Dataset class is responsible for loading a single image, preparing the associated annotations, applying any image transforms, and returning the final <code>image</code> tensor and its <code>target</code> dictionary during training.</p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> CVATKeypointDataset(Dataset):</span>
<span id="cb31-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A dataset class for handling CVAT annotated images and keypoints.</span></span>
<span id="cb31-4"></span>
<span id="cb31-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Attributes:</span></span>
<span id="cb31-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _img_keys (list): List of image keys.</span></span>
<span id="cb31-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _annotation_df (DataFrame): DataFrame containing annotations.</span></span>
<span id="cb31-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _img_dict (dict): Dictionary mapping image keys to image file paths.</span></span>
<span id="cb31-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _class_to_idx (dict): Dictionary mapping class names to class indices.</span></span>
<span id="cb31-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _transforms (function): Transformation functions to be applied to images and targets.</span></span>
<span id="cb31-11"></span>
<span id="cb31-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb31-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        img_keys (list): List of image keys.</span></span>
<span id="cb31-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        annotation_df (DataFrame): DataFrame containing annotations.</span></span>
<span id="cb31-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        img_dict (dict): Dictionary mapping image keys to image file paths.</span></span>
<span id="cb31-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        class_to_idx (dict): Dictionary mapping class names to class indices.</span></span>
<span id="cb31-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        transforms (function, optional): Transformation functions for images and targets.</span></span>
<span id="cb31-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb31-19">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, img_keys, annotation_df, img_dict, class_to_idx, transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb31-20">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb31-21">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys</span>
<span id="cb31-22">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df</span>
<span id="cb31-23">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_dict</span>
<span id="cb31-24">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> class_to_idx</span>
<span id="cb31-25">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms</span>
<span id="cb31-26"></span>
<span id="cb31-27">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.BBOX_DIM <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb31-28">        </span>
<span id="cb31-29">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__len__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb31-30">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns the number of items in the dataset.</span></span>
<span id="cb31-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb31-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb31-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            int: Number of items in the dataset.</span></span>
<span id="cb31-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-36">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys)</span>
<span id="cb31-37">        </span>
<span id="cb31-38">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, index):</span>
<span id="cb31-39">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Retrieves an item from the dataset at the specified index.</span></span>
<span id="cb31-41"></span>
<span id="cb31-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb31-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            index (int): Index of the item to retrieve.</span></span>
<span id="cb31-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb31-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb31-46"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and its corresponding target dictionary.</span></span>
<span id="cb31-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-48">        img_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys[index]</span>
<span id="cb31-49">        annotation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df.loc[img_key]</span>
<span id="cb31-50">        image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._load_image_and_target(annotation)</span>
<span id="cb31-51">        </span>
<span id="cb31-52">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms:</span>
<span id="cb31-53">            image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms(image, target)</span>
<span id="cb31-54"></span>
<span id="cb31-55">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fill any missing keypoints with dummy values</span></span>
<span id="cb31-56">        target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._fill_and_order_target(target)</span>
<span id="cb31-57">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, target</span>
<span id="cb31-58"></span>
<span id="cb31-59">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _load_image_and_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, annotation):</span>
<span id="cb31-60">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-61"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Loads an image and its corresponding target based on the annotation.</span></span>
<span id="cb31-62"></span>
<span id="cb31-63"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb31-64"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation (DataFrame row): Annotation data for the image.</span></span>
<span id="cb31-65"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb31-66"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb31-67"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and its target dictionary.</span></span>
<span id="cb31-68"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-69">        filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict[annotation.name]</span>
<span id="cb31-70">        image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(filepath).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb31-71">        </span>
<span id="cb31-72">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract keypoints from the annotation and create bounding boxes for torchvision augmentations</span></span>
<span id="cb31-73">        keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Keypoints'</span>]</span>
<span id="cb31-74">        keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {keypoint[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>]: [keypoint[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>], keypoint[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>]] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> keypoint <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> keypoints}</span>
<span id="cb31-75">        keypoints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([keypoints[name] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> name <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> class_names], dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float32)</span>
<span id="cb31-76">        keypoints_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((torch.tensor(keypoints), torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(keypoints), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb31-77">        keypoints_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((torch.tensor(keypoints), torch.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(keypoints), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.BBOX_DIM), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb31-78">    </span>
<span id="cb31-79">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert from center x, center y, width, height format to xmin, ymin, xmax, ymax format</span></span>
<span id="cb31-80">        bbox_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torchvision.ops.box_convert(keypoints_bboxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cxcywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>)</span>
<span id="cb31-81">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create BoundingBoxes object with the converted bounding boxes</span></span>
<span id="cb31-82">        boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(bbox_tensor, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb31-83">    </span>
<span id="cb31-84">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract labels for keypoints and convert them to tensor</span></span>
<span id="cb31-85">        annotation_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [keypoint[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> keypoint <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Keypoints'</span>]]</span>
<span id="cb31-86">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx[label] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_labels])</span>
<span id="cb31-87">    </span>
<span id="cb31-88">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: boxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: labels}</span>
<span id="cb31-89"></span>
<span id="cb31-90">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _fill_and_order_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, target):</span>
<span id="cb31-91">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-92"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Fills and orders the target bounding boxes and labels based on the class index.</span></span>
<span id="cb31-93"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb31-94"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        This method ensures that each target has a bounding box and label for each class,</span></span>
<span id="cb31-95"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        even if some classes are not present in the original target. Missing classes</span></span>
<span id="cb31-96"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        are filled with dummy values.</span></span>
<span id="cb31-97"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb31-98"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb31-99"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            target (dict): A dictionary containing 'boxes' and 'labels' keys, where</span></span>
<span id="cb31-100"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                           'boxes' is a tensor of bounding boxes and 'labels' is a tensor</span></span>
<span id="cb31-101"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                           of labels corresponding to these boxes.</span></span>
<span id="cb31-102"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb31-103"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb31-104"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            dict: The updated target dictionary with boxes and labels ordered and filled</span></span>
<span id="cb31-105"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                  according to the class index.</span></span>
<span id="cb31-106"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-107">    </span>
<span id="cb31-108">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize new boxes with dummy values (-1.0) for each class</span></span>
<span id="cb31-109">        new_boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.full((<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>), <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>)</span>
<span id="cb31-110">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare labels tensor based on the class indices</span></span>
<span id="cb31-111">        new_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx.values()), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb31-112">    </span>
<span id="cb31-113">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate over each class label</span></span>
<span id="cb31-114">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(new_labels):</span>
<span id="cb31-115">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check if the current label exists in the target's labels</span></span>
<span id="cb31-116">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]:</span>
<span id="cb31-117">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Find the index of the current label in the target's labels</span></span>
<span id="cb31-118">                idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> label).nonzero(as_tuple<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb31-119">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assign the corresponding box to the new boxes tensor</span></span>
<span id="cb31-120">                new_boxes[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>][idx]</span>
<span id="cb31-121">    </span>
<span id="cb31-122">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the target dictionary with the new boxes and labels</span></span>
<span id="cb31-123">        target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_boxes</span>
<span id="cb31-124">        target[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_labels</span>
<span id="cb31-125">    </span>
<span id="cb31-126">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> target</span></code></pre></div>
</section>
<section id="image-transforms" class="level3">
<h3 class="anchored" data-anchor-id="image-transforms">Image Transforms</h3>
<p>Here, we will specify and organize all the image transforms to apply during training.</p>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms for data augmentation</span></span>
<span id="cb32-2">data_aug_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose(</span>
<span id="cb32-3">    transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb32-4">        iou_crop,</span>
<span id="cb32-5">        transforms.ColorJitter(</span>
<span id="cb32-6">                brightness <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.875</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.125</span>),</span>
<span id="cb32-7">                contrast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb32-8">                saturation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb32-9">                hue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>),</span>
<span id="cb32-10">        ),</span>
<span id="cb32-11">        transforms.RandomGrayscale(),</span>
<span id="cb32-12">        transforms.RandomEqualize(),</span>
<span id="cb32-13">        transforms.RandomPosterize(bits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb32-14">        transforms.RandomHorizontalFlip(p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb32-15">    ],</span>
<span id="cb32-16">)</span>
<span id="cb32-17"></span>
<span id="cb32-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to resize and pad input images</span></span>
<span id="cb32-19">resize_pad_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb32-20">    resize_max, </span>
<span id="cb32-21">    pad_square,</span>
<span id="cb32-22">    transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb32-23">])</span>
<span id="cb32-24"></span>
<span id="cb32-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to sanitize bounding boxes and normalize input data</span></span>
<span id="cb32-26">final_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb32-27">    transforms.ToImage(), </span>
<span id="cb32-28">    transforms.ToDtype(torch.float32, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb32-29">    transforms.SanitizeBoundingBoxes(),</span>
<span id="cb32-30">])</span>
<span id="cb32-31"></span>
<span id="cb32-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the transformations for training and validation datasets</span></span>
<span id="cb32-33">train_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb32-34">    data_aug_tfms, </span>
<span id="cb32-35">    resize_pad_tfm, </span>
<span id="cb32-36">    final_tfms</span>
<span id="cb32-37">])</span></code></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always use the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.SanitizeBoundingBoxes.html#torchvision.transforms.v2.SanitizeBoundingBoxes"><code>SanitizeBoundingBoxes</code></a> transform to clean up annotations after using data augmentations that alter bounding boxes (e.g., cropping, warping, etc.).</p>
</div>
</div>
</section>
<section id="initialize-dataset" class="level3">
<h3 class="anchored" data-anchor-id="initialize-dataset">Initialize Dataset</h3>
<p>Now, we can create the dataset object using the image dictionary, the annotation DataFrame, and the image transforms.</p>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mapping from class names to class indices</span></span>
<span id="cb33-2">class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {c: i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(class_names)}</span>
<span id="cb33-3"></span>
<span id="cb33-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Instantiate the dataset using the defined transformations</span></span>
<span id="cb33-5">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CVATKeypointDataset(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys()), annotation_df, img_dict, class_to_idx, train_tfms)</span>
<span id="cb33-6"></span>
<span id="cb33-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of samples in the training dataset</span></span>
<span id="cb33-8">pd.Series({</span>
<span id="cb33-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training dataset size:'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataset),</span>
<span id="cb33-10">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_a73b1">
<thead>
</thead>
<tbody>
<tr>
<th id="T_a73b1_level0_row0" class="row_heading level0 row0">
Training dataset size:
</th>
<td id="T_a73b1_row0_col0" class="data row0 col0">
38
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspect-samples" class="level3">
<h3 class="anchored" data-anchor-id="inspect-samples">Inspect Samples</h3>
<p>To close out, we should verify the dataset object works as intended by inspecting the first sample.</p>
<section id="inspect-training-set-sample" class="level4">
<h4 class="anchored" data-anchor-id="inspect-training-set-sample">Inspect training set sample</h4>
<div class="sourceCode" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a sample image and its target annotations</span></span>
<span id="cb34-2">dataset_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_dataset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb34-3"></span>
<span id="cb34-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sanitize bounding boxes to remove dummy values</span></span>
<span id="cb34-5">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb34-6">targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:])</span>
<span id="cb34-7">sanitized_image, sanitized_targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], targets)</span>
<span id="cb34-8"></span>
<span id="cb34-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with the sanitized annotations</span></span>
<span id="cb34-10">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb34-11">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(sanitized_image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.uint8), </span>
<span id="cb34-12">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb34-13">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb34-14">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sanitized_targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb34-15">)</span>
<span id="cb34-16"></span>
<span id="cb34-17">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/keypoints/images/output_56_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we covered how to load custom keypoint annotations made with the CVAT annotation tool and work with them using torchvision’s Transforms V2 API. The skills and knowledge you acquired here provide a solid foundation for future keypoint estimation projects.</p>
<p>As a next step, perhaps try annotating a custom keypoint estimation dataset with CVAT and loading it with this tutorial’s code.</p>
</section>
<section id="recommended-tutorials" class="level2">
<h2 class="anchored" data-anchor-id="recommended-tutorials">Recommended Tutorials</h2>
<ul>
<li><a href="../../../posts/torchvision-cvat-annotation-tutorials/bounding-boxes/"><strong>Working with CVAT Bounding Box Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with CVAT bounding box annotations in torchvision for object detection tasks.</li>
<li><a href="../../../posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/"><strong>Working with CVAT Segmentation Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with CVAT segmentation annotations in torchvision for instance segmentation tasks.</li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>image-annotation</category>
  <category>keypoint-estimation</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/torchvision-cvat-annotation-tutorials/keypoints/</guid>
  <pubDate>Sun, 21 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Working with CVAT Bounding Box Annotations in Torchvision</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/torchvision-cvat-annotation-tutorials/bounding-boxes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/tutorials/torchvision-annotation-tutorials-series.html"><strong>Torchvision Annotation Tutorials</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Loading and Exploring the Dataset</li>
<li>Preparing the Data</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to this hands-on guide for working with bounding box annotations created with the <a href="https://github.com/opencv/cvat">CVAT annotation tool</a> in <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>. Bounding box annotations specify rectangular frames around objects in images to identify and locate them for training object detection models.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/bounding-boxes/images/bounding-box-hero-img.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The tutorial walks through setting up a Python environment, loading the raw annotations into a <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a>, annotating and augmenting images using torchvision’s <a href="https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py">Transforms V2 API</a>, and creating a custom <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Dataset</a> class to feed samples to a model.</p>
<p>This guide is suitable for beginners and experienced practitioners, providing the code, explanations, and resources needed to understand and implement each step. By the end, you will have a solid foundation for working with bounding box annotations made with CVAT for object detection tasks.</p>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>The tutorial code is available as a <a href="https://jupyter.org/">Jupyter Notebook</a>, which you can run locally or in a cloud-based environment like <a href="https://colab.research.google.com/">Google Colab</a>. I have dedicated tutorials for those new to these platforms or who need guidance setting up:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Setup Guides">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Setup Guides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="../../../posts/google-colab-getting-started-tutorial/"><strong>Getting Started with Google Colab</strong></a></p></li>
<li><p><a href="../../../posts/mamba-getting-started-tutorial-windows/"><strong>Setting Up a Local Python Environment with Mamba for Machine Learning Projects on Windows</strong></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Tutorial Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tutorial Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook:</th>
<th><a href="https://github.com/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/cvat/torchvision-cvat-bounding-box-annotations.ipynb">GitHub Repository</a></th>
<th><a href="https://colab.research.google.com/github/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/cvat/torchvision-cvat-bounding-box-annotations.ipynb">Open In Colab</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>Before diving into the code, we’ll cover the steps to create a local Python environment and install the necessary dependencies.</p>
<section id="creating-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-python-environment">Creating a Python Environment</h3>
<p>First, we’ll create a Python environment using <a href="https://docs.conda.io/en/latest/">Conda</a>/<a href="https://mamba.readthedocs.io/en/latest/">Mamba</a>. Open a terminal with Conda/Mamba installed and run the following commands:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Conda</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Mamba</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate pytorch-env</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate pytorch-env</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="installing-pytorch">Installing PyTorch</h3>
<p>Next, we’ll install <a href="https://pytorch.org/">PyTorch</a>. Run the appropriate command for your hardware and operating system.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Linux/Windows (CUDA)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Mac</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Linux (CPU)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Windows (CPU)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch with CUDA</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cu121</span></code></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MPS (Metal Performance Shaders) acceleration is available on MacOS 12.3+</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cpu</span></code></pre></div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-additional-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-libraries">Installing Additional Libraries</h3>
<p>We also need to install some additional libraries for our project.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>jupyter</code></td>
<td>An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. (<a href="https://jupyter.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>matplotlib</code></td>
<td>This package provides a comprehensive collection of visualization tools to create high-quality plots, charts, and graphs for data exploration and presentation. (<a href="https://matplotlib.org/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>pandas</code></td>
<td>This package provides fast, powerful, and flexible data analysis and manipulation tools. (<a href="https://pandas.pydata.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>pillow</code></td>
<td>The Python Imaging Library adds image processing capabilities. (<a href="https://pillow.readthedocs.io/en/stable/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>tqdm</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>distinctipy</code></td>
<td>A lightweight python package providing functions to generate colours that are visually distinct from one another. (<a href="https://distinctipy.readthedocs.io/en/latest/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install these additional libraries:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional dependencies</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install distinctipy jupyter matplotlib pandas pillow tqdm</span></code></pre></div>
</section>
<section id="installing-utility-packages" class="level3">
<h3 class="anchored" data-anchor-id="installing-utility-packages">Installing Utility Packages</h3>
<p>We will also install some utility packages I made, which provide shortcuts for routine tasks.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>cjm_pil_utils</code></td>
<td>Some PIL utility functions I frequently use. (<a href="https://cj-mills.github.io/cjm-pil-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_psl_utils</code></td>
<td>Some utility functions using the Python Standard Library. (<a href="https://cj-mills.github.io/cjm-psl-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_pytorch_utils</code></td>
<td>Some utility functions for working with PyTorch. (<a href="https://cj-mills.github.io/cjm-pytorch-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_torchvision_tfms</code></td>
<td>Some custom Torchvision tranforms. (<a href="https://cj-mills.github.io/cjm-torchvision-tfms/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install the utility packages:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional utility packages</span></span>
<span id="cb8-2">pip install cjm_pil_utils cjm_psl_utils cjm_pytorch_utils cjm_torchvision_tfms</span></code></pre></div>
<p>With our environment set up, we can open our Jupyter Notebook and dive into the code.</p>
</section>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python packages into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb9-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> xml.etree.ElementTree <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> ET</span>
<span id="cb9-5"></span>
<span id="cb9-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb9-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_img_files</span>
<span id="cb9-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file, file_extract</span>
<span id="cb9-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pytorch_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor_to_pil</span>
<span id="cb9-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_torchvision_tfms.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ResizeMax, PadSquare, CustomRandomIoUCrop</span>
<span id="cb9-11"></span>
<span id="cb9-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the distinctipy module</span></span>
<span id="cb9-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distinctipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> distinctipy</span>
<span id="cb9-14"></span>
<span id="cb9-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import matplotlib for creating plots</span></span>
<span id="cb9-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb9-17"></span>
<span id="cb9-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb9-19"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-20"></span>
<span id="cb9-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb9-22"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb9-23"></span>
<span id="cb9-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb9-25">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb9-26"></span>
<span id="cb9-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb9-28"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image</span>
<span id="cb9-29"></span>
<span id="cb9-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb9-31"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb9-32"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DataLoader</span>
<span id="cb9-33"></span>
<span id="cb9-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import torchvision dependencies</span></span>
<span id="cb9-35"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision</span>
<span id="cb9-36">torchvision.disable_beta_transforms_warning()</span>
<span id="cb9-37"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BoundingBoxes</span>
<span id="cb9-38"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> draw_bounding_boxes</span>
<span id="cb9-39"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.v2  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb9-40"></span>
<span id="cb9-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import tqdm for progress bar</span></span>
<span id="cb9-42"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm.auto <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
<p>Torchvision provides dedicated <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> subclasses for different annotation types called <a href="https://pytorch.org/vision/stable/tv_tensors.html"><code>TVTensors</code></a>. Torchvision’s V2 transforms use these subclasses to update the annotations based on the applied image augmentations. The TVTensor class for bounding box annotations is called <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.BoundingBoxes.html"><code>BoundingBoxes</code></a>. Torchvision also includes a <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function to annotate images.</p>
</section>
<section id="loading-and-exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-and-exploring-the-dataset">Loading and Exploring the Dataset</h2>
<p>After importing the dependencies, we can start working with our data. I annotated a toy dataset with bounding boxes for this tutorial using images from the free stock photo site <a href="https://www.pexels.com/">Pexels</a>. The dataset is available on <a href="https://huggingface.co/">HuggingFace Hub</a> at the link below:</p>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/datasets/cj-mills/cvat-bounding-box-toy-dataset/tree/main">cvat-bounding-box-toy-dataset</a></li>
</ul>
<section id="setting-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-directory-paths">Setting the Directory Paths</h3>
<p>We first need to specify a place to store our dataset and a location to download the zip file containing it. The following code creates the folders in the current directory (<code>./</code>). Update the path if that is not suitable for you.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store datasets</span></span>
<span id="cb10-2">dataset_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./Datasets/"</span>)</span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the dataset directory if it does not exist</span></span>
<span id="cb10-4">dataset_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store archive files</span></span>
<span id="cb10-7">archive_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'../Archive'</span></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the archive directory if it does not exist</span></span>
<span id="cb10-9">archive_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb10-12">pd.Series({</span>
<span id="cb10-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Directory:"</span>: dataset_dir, </span>
<span id="cb10-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Directory:"</span>: archive_dir</span>
<span id="cb10-15">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_1e715">
<thead>
</thead>
<tbody>
<tr>
<th id="T_1e715_level0_row0" class="row_heading level0 row0">
Dataset Directory:
</th>
<td id="T_1e715_row0_col0" class="data row0 col0">
Datasets
</td>
</tr>
<tr>
<th id="T_1e715_level0_row1" class="row_heading level0 row1">
Archive Directory:
</th>
<td id="T_1e715_row1_col0" class="data row1 col0">
Datasets/../Archive
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="setting-the-dataset-path" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-dataset-path">Setting the Dataset Path</h3>
<p>Next, we construct the name for the Hugging Face Hub dataset and set where to download and extract the dataset.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the dataset</span></span>
<span id="cb11-2">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cvat-bounding-box-toy-dataset'</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb11-5">hf_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'cj-mills/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb11-8">archive_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>archive_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip'</span>)</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb11-11">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the dataset name and paths and converting it to a DataFrame for display</span></span>
<span id="cb11-14">pd.Series({</span>
<span id="cb11-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb11-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Path:"</span>: archive_path, </span>
<span id="cb11-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Path:"</span>: dataset_path</span>
<span id="cb11-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_954b0">
<thead>
</thead>
<tbody>
<tr>
<th id="T_954b0_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_954b0_row0_col0" class="data row0 col0">
cj-mills/cvat-bounding-box-toy-dataset
</td>
</tr>
<tr>
<th id="T_954b0_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_954b0_row1_col0" class="data row1 col0">
Datasets/../Archive/cvat-bounding-box-toy-dataset.zip
</td>
</tr>
<tr>
<th id="T_954b0_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_954b0_row2_col0" class="data row2 col0">
Datasets/cvat-bounding-box-toy-dataset
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="downloading-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h3>
<p>We can now download the archive file and extract the dataset using the <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#download_file"><code>download_file</code></a> and <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#file_extract"><code>file_extract</code></a> functions from the <code>cjm_psl_utils</code> package. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb12-2">dataset_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>hf_dataset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip"</span></span>
<span id="cb12-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"HuggingFace Dataset URL: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb12-6">delete_archive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the dataset if not present</span></span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset_path.is_dir():</span>
<span id="cb12-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset folder already exists"</span>)</span>
<span id="cb12-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb12-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Downloading dataset..."</span>)</span>
<span id="cb12-13">    download_file(dataset_url, archive_dir)    </span>
<span id="cb12-14">    </span>
<span id="cb12-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extracting dataset..."</span>)</span>
<span id="cb12-16">    file_extract(fname<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>archive_path, dest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_dir)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete the archive if specified</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> delete_archive: archive_path.unlink()</span></code></pre></div>
</section>
<section id="getting-the-images-and-annotations" class="level3">
<h3 class="anchored" data-anchor-id="getting-the-images-and-annotations">Getting the Images and Annotations</h3>
<p>The dataset has a folder containing the sample images and an XML file containing the annotations.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming the images are stored in a subfolder named 'default'</span></span>
<span id="cb13-2">img_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'images/default'</span></span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming annotation file is in XML format and located in any subdirectory of the dataset</span></span>
<span id="cb13-5">annotation_file_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'annotations.xml'</span></span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb13-8">pd.Series({</span>
<span id="cb13-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Image Folder"</span>: img_dir, </span>
<span id="cb13-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annotation File"</span>: annotation_file_path}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_13cf3">
<thead>
</thead>
<tbody>
<tr>
<th id="T_13cf3_level0_row0" class="row_heading level0 row0">
Image Folder
</th>
<td id="T_13cf3_row0_col0" class="data row0 col0">
Datasets/cvat-bounding-box-toy-dataset/images/default
</td>
</tr>
<tr>
<th id="T_13cf3_level0_row1" class="row_heading level0 row1">
Annotation File
</th>
<td id="T_13cf3_row1_col0" class="data row1 col0">
Datasets/cvat-bounding-box-toy-dataset/annotations.xml
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-file-paths" class="level3">
<h3 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h3>
<p>Each image file has a unique name that we can use to locate the corresponding annotation data. We can make a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image more efficiently.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get all image files in the 'img_dir' directory</span></span>
<span id="cb14-2">img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb14-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.stem : <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary that maps file names to file paths</span></span>
<span id="cb14-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> get_img_files(img_dir) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of image files in the image directory</span></span>
<span id="cb14-5">}</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of image files</span></span>
<span id="cb14-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Number of Images: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_dict)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb14-9"></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb14-11">pd.DataFrame.from_dict(img_dict, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).head()</span></code></pre></div>
<pre class="text"><code>Number of Images: 28</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
Datasets/cvat-bounding-box-toy-dataset/images/default/258421.jpg
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
Datasets/cvat-bounding-box-toy-dataset/images/default/3075367.jpg
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
Datasets/cvat-bounding-box-toy-dataset/images/default/3076319.jpg
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
Datasets/cvat-bounding-box-toy-dataset/images/default/3145551.jpg
</td>
</tr>
<tr>
<th>
3176048
</th>
<td>
Datasets/cvat-bounding-box-toy-dataset/images/default/3176048.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="get-image-annotations">Get Image Annotations</h3>
<p>Next, we read the content of the XML annotation file into a Pandas DataFrame so we can easily query the annotations.</p>
<section id="define-a-function-to-parse-the-cvat-xml-annotations" class="level4">
<h4 class="anchored" data-anchor-id="define-a-function-to-parse-the-cvat-xml-annotations">Define a function to parse the CVAT XML annotations</h4>
<p>The following helper function parses the raw XML content into a Pandas DataFrame.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> parse_cvat_bbox_xml(xml_content):</span>
<span id="cb16-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb16-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parse the given XML content of a CVAT bounding box annotation file and</span></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    convert it into a pandas DataFrame.</span></span>
<span id="cb16-5"></span>
<span id="cb16-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function processes the XML content to extract information about each</span></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    image and its associated bounding boxes. The data is then structured into</span></span>
<span id="cb16-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    a DataFrame for easier manipulation and analysis.</span></span>
<span id="cb16-9"></span>
<span id="cb16-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parameters:</span></span>
<span id="cb16-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    xml_content (str): A string containing the XML content from a CVAT bounding box</span></span>
<span id="cb16-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                       annotation file.</span></span>
<span id="cb16-13"></span>
<span id="cb16-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb16-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    pandas.DataFrame: A DataFrame where each row represents an image and contains</span></span>
<span id="cb16-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                      the following columns:</span></span>
<span id="cb16-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                      - Image ID (int): The unique identifier of the image.</span></span>
<span id="cb16-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                      - Image Name (str): The name of the image.</span></span>
<span id="cb16-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                      - Width (int): The width of the image in pixels.</span></span>
<span id="cb16-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                      - Height (int): The height of the image in pixels.</span></span>
<span id="cb16-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                      - Boxes (list): A list of dictionaries, where each dictionary</span></span>
<span id="cb16-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                                      represents a bounding box with keys 'Label',</span></span>
<span id="cb16-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                                      'xtl', 'ytl', 'xbr', and 'ybr' indicating the</span></span>
<span id="cb16-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                                      label and coordinates of the box.</span></span>
<span id="cb16-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb16-26"></span>
<span id="cb16-27">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Parse the XML content</span></span>
<span id="cb16-28">    root <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ET.fromstring(xml_content)</span>
<span id="cb16-29">    data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb16-30"></span>
<span id="cb16-31">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate through each image element in the XML</span></span>
<span id="cb16-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> image <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> root.findall(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image'</span>):</span>
<span id="cb16-33">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract image attributes</span></span>
<span id="cb16-34">        image_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>)</span>
<span id="cb16-35">        image_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>)</span>
<span id="cb16-36">        width <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'width'</span>)</span>
<span id="cb16-37">        height <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'height'</span>)</span>
<span id="cb16-38"></span>
<span id="cb16-39">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize a dictionary to store image data</span></span>
<span id="cb16-40">        image_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb16-41">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image ID'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(image_id),</span>
<span id="cb16-42">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image Name'</span>: image_name,</span>
<span id="cb16-43">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Width'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(width),</span>
<span id="cb16-44">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Height'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(height),</span>
<span id="cb16-45">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Boxes'</span>: []</span>
<span id="cb16-46">        }</span>
<span id="cb16-47"></span>
<span id="cb16-48">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate through each bounding box element within the image</span></span>
<span id="cb16-49">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> box <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> image.findall(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>):</span>
<span id="cb16-50">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract box attributes</span></span>
<span id="cb16-51">            label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> box.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>)</span>
<span id="cb16-52">            xtl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(box.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xtl'</span>))</span>
<span id="cb16-53">            ytl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(box.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ytl'</span>))</span>
<span id="cb16-54">            xbr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(box.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xbr'</span>))</span>
<span id="cb16-55">            ybr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(box.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ybr'</span>))</span>
<span id="cb16-56"></span>
<span id="cb16-57">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct a dictionary for the box data</span></span>
<span id="cb16-58">            box_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb16-59">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>: label,</span>
<span id="cb16-60">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xtl'</span>: xtl,</span>
<span id="cb16-61">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ytl'</span>: ytl,</span>
<span id="cb16-62">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xbr'</span>: xbr,</span>
<span id="cb16-63">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ybr'</span>: ybr</span>
<span id="cb16-64">            }</span>
<span id="cb16-65"></span>
<span id="cb16-66">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Append the box data to the image's 'Boxes' list</span></span>
<span id="cb16-67">            image_data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Boxes'</span>].append(box_data)</span>
<span id="cb16-68"></span>
<span id="cb16-69">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Map the image data to its ID in the data dictionary</span></span>
<span id="cb16-70">        data[image_id] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image_data</span>
<span id="cb16-71"></span>
<span id="cb16-72">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the data dictionary to a DataFrame and return</span></span>
<span id="cb16-73">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> pd.DataFrame.from_dict(data, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>)</span></code></pre></div>
</section>
<section id="load-cvat-xml-annotations-into-a-dataframe" class="level4">
<h4 class="anchored" data-anchor-id="load-cvat-xml-annotations-into-a-dataframe">Load CVAT XML annotations into a DataFrame</h4>
<p>After parsing the XML content, we will change the index for the <code>annotation_df</code> DataFrame to match the keys in the <code>img_dict</code> dictionary, allowing us to retrieve both the image paths and annotation data using the same index key.</p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Read the XML file</span></span>
<span id="cb17-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(annotation_file_path, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'utf-8'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>:</span>
<span id="cb17-3">    xml_content <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.read()</span>
<span id="cb17-4"></span>
<span id="cb17-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Parse the XML content</span></span>
<span id="cb17-6">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parse_cvat_bbox_xml(xml_content)</span>
<span id="cb17-7"></span>
<span id="cb17-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add a new column 'Image ID' by extracting it from 'Image Name'</span></span>
<span id="cb17-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This assumes that the 'Image ID' is the part of the 'Image Name' before the first period</span></span>
<span id="cb17-10">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image ID'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image Name'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: x.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb17-11"></span>
<span id="cb17-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the new 'Image ID' column as the index of the DataFrame</span></span>
<span id="cb17-13">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Image ID'</span>)</span>
<span id="cb17-14"></span>
<span id="cb17-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first few rows of the DataFrame</span></span>
<span id="cb17-16">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Image Name
</th>
<th>
Width
</th>
<th>
Height
</th>
<th>
Boxes
</th>
</tr>
<tr>
<th>
Image ID
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
258421.jpg
</td>
<td>
768
</td>
<td>
1152
</td>
<td>
[{‘Label’: ‘person’, ‘xtl’: 386.08, ‘ytl’: 443.94, ‘xbr’: 460.82, ‘ybr’: 777.16}, {‘Label’: ‘person’, ‘xtl’: 340.25, ‘ytl’: 466.94, ‘xbr’: 418.99, ‘ybr’: 777.34}]
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
3075367.jpg
</td>
<td>
1344
</td>
<td>
768
</td>
<td>
[{‘Label’: ‘person’, ‘xtl’: 413.32, ‘ytl’: 41.22, ‘xbr’: 919.81, ‘ybr’: 763.17}]
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
3076319.jpg
</td>
<td>
768
</td>
<td>
1120
</td>
<td>
[{‘Label’: ‘person’, ‘xtl’: 335.31, ‘ytl’: 151.75, ‘xbr’: 711.22, ‘ybr’: 1117.49}, {‘Label’: ‘person’, ‘xtl’: 8.11, ‘ytl’: 131.88, ‘xbr’: 404.2, ‘ybr’: 1119.0}]
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
3145551.jpg
</td>
<td>
1184
</td>
<td>
768
</td>
<td>
[{‘Label’: ‘person’, ‘xtl’: 642.0, ‘ytl’: 289.85, ‘xbr’: 669.66, ‘ybr’: 398.89}, {‘Label’: ‘person’, ‘xtl’: 658.63, ‘ytl’: 281.25, ‘xbr’: 687.09, ‘ybr’: 398.61}]
</td>
</tr>
<tr>
<th>
3176048
</th>
<td>
3176048.jpg
</td>
<td>
1152
</td>
<td>
768
</td>
<td>
[{‘Label’: ‘person’, ‘xtl’: 518.23, ‘ytl’: 338.97, ‘xbr’: 594.63, ‘ybr’: 466.08}, {‘Label’: ‘person’, ‘xtl’: 683.42, ‘ytl’: 356.48, ‘xbr’: 638.86, ‘ybr’: 437.82}]
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>The source XML content corresponding to the first row in the DataFrame is available below:</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode xml code-with-copy"><code class="sourceCode xml"><span id="cb18-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">&lt;?xml</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> version=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1.0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> encoding=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"utf-8"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">?&gt;</span></span>
<span id="cb18-2">&lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">annotations</span>&gt;</span>
<span id="cb18-3">  &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">version</span>&gt;1.1&lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">version</span>&gt;</span>
<span id="cb18-4">  &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">meta</span>&gt;</span>
<span id="cb18-5">  &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">meta</span>&gt;</span>
<span id="cb18-6">  &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">image</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> id=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> name=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"258421.jpg"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> subset=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"default"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> task_id=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"7"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> width=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"768"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> height=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1152"</span>&gt;</span>
<span id="cb18-7">    &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">box</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> label=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> source=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"file"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> occluded=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> xtl=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"386.08"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> ytl=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"443.94"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> xbr=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"460.82"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> ybr=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"777.16"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> z_order=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span>&gt;</span>
<span id="cb18-8">    &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">box</span>&gt;</span>
<span id="cb18-9">    &lt;<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">box</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> label=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> source=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"file"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> occluded=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> xtl=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"340.25"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> ytl=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"466.94"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> xbr=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"418.99"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> ybr=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"777.34"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;"> z_order=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span>&gt;</span>
<span id="cb18-10">    &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">box</span>&gt;</span>
<span id="cb18-11">  &lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">image</span>&gt;</span>
<span id="cb18-12">&lt;/<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">annotations</span>&gt;</span></code></pre></div>
<p>The the <code>xtl</code>, <code>ytl</code>, <code>xbr</code>, and <code>ybr</code> values indicate the bounding box annotations are in <code>[Top-Left X, Top-Left Y, Bottom-Right X, Bottom-Right Y]</code> format.</p>
<p>With the annotations loaded, we can start inspecting our dataset.</p>
</section>
</section>
<section id="inspecting-the-class-distribution" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-the-class-distribution">Inspecting the Class Distribution</h3>
<p>First, we get the names of all the classes in our dataset and inspect the distribution of samples among these classes. This step won’t yield any insights for the toy dataset but is worth doing for real-world projects. A balanced dataset (where each class has approximately the same number of instances) is ideal for training a machine-learning model.</p>
<section id="get-image-classes" class="level4">
<h4 class="anchored" data-anchor-id="get-image-classes">Get image classes</h4>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Explode the 'boxes_df' column in the annotation_df dataframe</span></span>
<span id="cb19-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the resulting series to a dataframe and rename the 'boxes_df' column to 'boxes_df'</span></span>
<span id="cb19-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the pandas Series function to the 'boxes_df' column of the dataframe</span></span>
<span id="cb19-4">boxes_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Boxes'</span>].explode().to_frame().Boxes.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)</span>
<span id="cb19-5"></span>
<span id="cb19-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb19-7">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> boxes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>].unique().tolist()</span>
<span id="cb19-8"></span>
<span id="cb19-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display labels using a Pandas DataFrame</span></span>
<span id="cb19-10">pd.DataFrame(class_names)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
person
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visualize-the-class-distribution" class="level4">
<h4 class="anchored" data-anchor-id="visualize-the-class-distribution">Visualize the class distribution</h4>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the number of samples for each object class</span></span>
<span id="cb20-2">class_counts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> boxes_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>].value_counts()</span>
<span id="cb20-3"></span>
<span id="cb20-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the distribution</span></span>
<span id="cb20-5">class_counts.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bar'</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb20-6">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class distribution'</span>)</span>
<span id="cb20-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Count'</span>)</span>
<span id="cb20-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Classes'</span>)</span>
<span id="cb20-9">plt.xticks(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_counts.index)), class_counts.index, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the x-axis tick labels</span></span>
<span id="cb20-10">plt.show()</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/bounding-boxes/images/output_25_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
<section id="visualizing-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-image-annotations">Visualizing Image Annotations</h3>
<p>In this section, we will annotate a single image with its bounding boxes using torchvision’s <code>BoundingBoxes</code> class and <code>draw_bounding_boxes</code> function.</p>
<section id="generate-a-color-map" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-color-map">Generate a color map</h4>
<p>While not required, assigning a unique color to bounding boxes for each object class enhances visual distinction, allowing for easier identification of different objects in the scene. We can use the <a href="https://distinctipy.readthedocs.io/en/latest/"><code>distinctipy</code></a> package to generate a visually distinct colormap.</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb21-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distinctipy.get_colors(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the color map in integer format</span></span>
<span id="cb21-5">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colors]</span>
<span id="cb21-6"></span>
<span id="cb21-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a color swatch to visualize the color map</span></span>
<span id="cb21-8">distinctipy.color_swatch(colors)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/bounding-boxes/images/output_29_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a font file</h4>
<p>The <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function included with torchvision uses a pretty small font size. We can increase the font size if we use a custom font. Font files are available on sites like <a href="https://fonts.google.com/">Google Fonts</a>, or we can use one included with the operating system.</p>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb22-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb22-3"></span>
<span id="cb22-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb22-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
</section>
<section id="define-the-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-the-bounding-box-annotation-function">Define the bounding box annotation function</h4>
<p>We can make a partial function using <code>draw_bounding_boxes</code> since we’ll use the same box thickness and font each time we visualize bounding boxes.</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">draw_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(draw_bounding_boxes, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, font<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>font_file, font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
</section>
</section>
<section id="selecting-a-sample-image" class="level3">
<h3 class="anchored" data-anchor-id="selecting-a-sample-image">Selecting a Sample Image</h3>
<p>We can use the unique ID for an image in the image dictionary to get the image file path and the associated annotations from the annotation DataFrame.</p>
<section id="load-the-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="load-the-sample-image">Load the sample image</h4>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the file ID of the first image file</span></span>
<span id="cb24-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb24-3"></span>
<span id="cb24-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the associated image file as a RGB image</span></span>
<span id="cb24-5">sample_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(img_dict[file_id]).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb24-6"></span>
<span id="cb24-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the dimensions of the image</span></span>
<span id="cb24-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Image Dims: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sample_img<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>size<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb24-9"></span>
<span id="cb24-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Show the image</span></span>
<span id="cb24-11">sample_img</span></code></pre></div>
<pre class="text"><code>Image Dims: (768, 1152)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/bounding-boxes/images/output_37_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="inspect-the-corresponding-annotation-data" class="level4">
<h4 class="anchored" data-anchor-id="inspect-the-corresponding-annotation-data">Inspect the corresponding annotation data</h4>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'</span></span>
<span id="cb26-2">annotation_df.loc[file_id].to_frame()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
258421
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
Image Name
</th>
<td>
258421.jpg
</td>
</tr>
<tr>
<th>
Width
</th>
<td>
768
</td>
</tr>
<tr>
<th>
Height
</th>
<td>
1152
</td>
</tr>
<tr>
<th>
Boxes
</th>
<td>
[{‘Label’: ‘person’, ‘xtl’: 386.08, ‘ytl’: 443.94, ‘xbr’: 460.82, ‘ybr’: 777.16}, {‘Label’: ‘person’, ‘xtl’: 340.25, ‘ytl’: 466.94, ‘xbr’: 418.99, ‘ybr’: 777.34}]
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="annotate-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="annotate-sample-image">Annotate sample image</h4>
<p>The <code>draw_bounding_boxes</code> function expects bounding box annotations in <code>[top-left X, top-left Y, bottom-right X, bottom-right Y]</code> format, so we don’t need to convert the annotation values.</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels and bounding box annotations for the sample image</span></span>
<span id="cb27-2">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> box <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Boxes'</span>]]</span>
<span id="cb27-3">bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xtl'</span>], box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ytl'</span>], box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xbr'</span>], box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ybr'</span>]] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> box <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Boxes'</span>]]).reshape(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(labels),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb27-4"></span>
<span id="cb27-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb27-6">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb27-7">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sample_img), </span>
<span id="cb27-8">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>BoundingBoxes(torch.Tensor(bboxes), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]),</span>
<span id="cb27-9">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, </span>
<span id="cb27-10">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb27-11">)</span>
<span id="cb27-12"></span>
<span id="cb27-13">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/bounding-boxes/images/output_41_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We have loaded the dataset, inspected its class distribution, and visualized the annotations for a sample image. In the final section, we will cover how to augment images using torchvision’s Transforms V2 API and create a custom Dataset class for training.</p>
</section>
</section>
</section>
<section id="preparing-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data">Preparing the Data</h2>
<p>In this section, we will first walk through a single example of how to apply augmentations to a single annotated image using torchvision’s Transforms V2 API before putting everything together in a custom Dataset class.</p>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h3>
<p>Here, we will define some data augmentations to apply to images during training. I created a few custom image transforms to help streamline the code.</p>
<p>The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#customrandomioucrop">first</a> extends the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.RandomIoUCrop.html#torchvision.transforms.v2.RandomIoUCrop"><code>RandomIoUCrop</code></a> transform included with torchvision to give the user more control over how much it crops into bounding box areas. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#resizemax">second</a> resizes images based on their largest dimension rather than their smallest. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#padsquare">third</a> applies square padding and allows the padding to be applied equally on both sides or randomly split between the two sides.</p>
<p>All three are available through the <a href="https://cj-mills.github.io/cjm-torchvision-tfms/"><code>cjm-torchvision-tfms</code></a> package.</p>
<section id="set-training-image-size" class="level4">
<h4 class="anchored" data-anchor-id="set-training-image-size">Set training image size</h4>
<p>Next, we will specify the image size to use during training.</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set training image size</span></span>
<span id="cb28-2">train_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span></span></code></pre></div>
</section>
<section id="initialize-custom-transforms" class="level4">
<h4 class="anchored" data-anchor-id="initialize-custom-transforms">Initialize custom transforms</h4>
<p>Now, we can initialize the transform objects.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomIoUCrop object</span></span>
<span id="cb29-2">iou_crop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomRandomIoUCrop(min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb29-3">                               max_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, </span>
<span id="cb29-4">                               min_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, </span>
<span id="cb29-5">                               max_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, </span>
<span id="cb29-6">                               sampler_options<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb29-7">                               trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb29-8">                               jitter_factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)</span>
<span id="cb29-9"></span>
<span id="cb29-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `ResizeMax` object</span></span>
<span id="cb29-11">resize_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ResizeMax(max_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_sz)</span>
<span id="cb29-12"></span>
<span id="cb29-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `PadSquare` object</span></span>
<span id="cb29-14">pad_square <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PadSquare(shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</section>
<section id="test-the-transforms" class="level4">
<h4 class="anchored" data-anchor-id="test-the-transforms">Test the transforms</h4>
<p>Torchvision’s V2 image transforms take an image and a <code>targets</code> dictionary. The <code>targets</code> dictionary contains the annotations and labels for the image.</p>
<p>We will pass input through the <code>CustomRandomIoUCrop</code> transform first and then through <code>ResizeMax</code> and <code>PadSquare</code>. We can pass the result through a final resize operation to ensure both sides match the <code>train_sz</code> value.</p>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare bounding box targets</span></span>
<span id="cb30-2">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb30-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: BoundingBoxes(torch.Tensor(bboxes), </span>
<span id="cb30-4">                           <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, </span>
<span id="cb30-5">                           canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), </span>
<span id="cb30-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.Tensor([class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])</span>
<span id="cb30-7">}</span>
<span id="cb30-8"></span>
<span id="cb30-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Crop the image</span></span>
<span id="cb30-10">cropped_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iou_crop(sample_img, targets)</span>
<span id="cb30-11"></span>
<span id="cb30-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Resize the image</span></span>
<span id="cb30-13">resized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_max(cropped_img, targets)</span>
<span id="cb30-14"></span>
<span id="cb30-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pad the image</span></span>
<span id="cb30-16">padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_square(resized_img, targets)</span>
<span id="cb30-17"></span>
<span id="cb30-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the padded image is the target size</span></span>
<span id="cb30-19">resize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb30-20">resized_padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize(padded_img, targets)</span>
<span id="cb30-21">sanitized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(resized_padded_img, targets)</span>
<span id="cb30-22"></span>
<span id="cb30-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb30-24">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb30-25">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sanitized_img), </span>
<span id="cb30-26">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb30-27">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb30-28">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb30-29">)</span>
<span id="cb30-30"></span>
<span id="cb30-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the annotated image</span></span>
<span id="cb30-32">display(tensor_to_pil(annotated_tensor))</span>
<span id="cb30-33"></span>
<span id="cb30-34">pd.Series({</span>
<span id="cb30-35">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image:"</span>: sample_img.size,</span>
<span id="cb30-36">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cropped Image:"</span>: cropped_img.size,</span>
<span id="cb30-37">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Image:"</span>: resized_img.size,</span>
<span id="cb30-38">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Padded Image:"</span>: padded_img.size,</span>
<span id="cb30-39">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Padded Image:"</span>: resized_padded_img.size,</span>
<span id="cb30-40">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/bounding-boxes/images/output_50_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_62824">
<thead>
</thead>
<tbody>
<tr>
<th id="T_62824_level0_row0" class="row_heading level0 row0">
Source Image:
</th>
<td id="T_62824_row0_col0" class="data row0 col0">
(768, 1152)
</td>
</tr>
<tr>
<th id="T_62824_level0_row1" class="row_heading level0 row1">
Cropped Image:
</th>
<td id="T_62824_row1_col0" class="data row1 col0">
(768, 1152)
</td>
</tr>
<tr>
<th id="T_62824_level0_row2" class="row_heading level0 row2">
Resized Image:
</th>
<td id="T_62824_row2_col0" class="data row2 col0">
(256, 384)
</td>
</tr>
<tr>
<th id="T_62824_level0_row3" class="row_heading level0 row3">
Padded Image:
</th>
<td id="T_62824_row3_col0" class="data row3 col0">
(384, 384)
</td>
</tr>
<tr>
<th id="T_62824_level0_row4" class="row_heading level0 row4">
Resized Padded Image:
</th>
<td id="T_62824_row4_col0" class="data row4 col0">
(384, 384)
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Now that we know how to apply data augmentations, we can put all the steps we’ve covered into a custom Dataset class.</p>
</section>
</section>
<section id="training-dataset-class" class="level3">
<h3 class="anchored" data-anchor-id="training-dataset-class">Training Dataset Class</h3>
<p>The following custom Dataset class is responsible for loading a single image, preparing the associated annotations, applying any image transforms, and returning the final <code>image</code> tensor and its <code>target</code> dictionary during training.</p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> CVATBBoxDataset(Dataset):</span>
<span id="cb31-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A custom dataset class for handling bounding box annotations from CVAT.</span></span>
<span id="cb31-4"></span>
<span id="cb31-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This dataset class is designed to work with bounding box annotations exported</span></span>
<span id="cb31-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    from the CVAT annotation tool. It allows for loading images and their corresponding</span></span>
<span id="cb31-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    bounding box annotations for use in training machine learning models.</span></span>
<span id="cb31-8"></span>
<span id="cb31-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Attributes:</span></span>
<span id="cb31-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _img_keys (list): A list of image keys.</span></span>
<span id="cb31-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _annotation_df (pandas.DataFrame): A DataFrame containing annotations.</span></span>
<span id="cb31-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _img_dict (dict): A dictionary mapping image keys to image file paths.</span></span>
<span id="cb31-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _class_to_idx (dict): A dictionary mapping class names to class indices.</span></span>
<span id="cb31-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _transforms (callable, optional): A function/transform that takes in an image</span></span>
<span id="cb31-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            and a target, and returns a transformed version.</span></span>
<span id="cb31-16"></span>
<span id="cb31-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb31-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        img_keys (list): List of image keys.</span></span>
<span id="cb31-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        annotation_df (pandas.DataFrame): DataFrame containing annotations.</span></span>
<span id="cb31-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        img_dict (dict): Dictionary mapping image keys to image paths.</span></span>
<span id="cb31-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        class_to_idx (dict): Dictionary mapping class names to class indices.</span></span>
<span id="cb31-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        transforms (callable, optional): Optional transform to be applied on a sample.</span></span>
<span id="cb31-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb31-24"></span>
<span id="cb31-25">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, img_keys, annotation_df, img_dict, class_to_idx, transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb31-26">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Dataset, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb31-27"></span>
<span id="cb31-28">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys</span>
<span id="cb31-29">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df</span>
<span id="cb31-30">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_dict</span>
<span id="cb31-31">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> class_to_idx</span>
<span id="cb31-32">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms</span>
<span id="cb31-33"></span>
<span id="cb31-34">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__len__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb31-35">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns the total number of items in the dataset.</span></span>
<span id="cb31-37"></span>
<span id="cb31-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb31-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            int: Total number of items.</span></span>
<span id="cb31-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-41">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys)</span>
<span id="cb31-42"></span>
<span id="cb31-43">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, index):</span>
<span id="cb31-44">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Retrieves an image and its associated target (bounding boxes and labels) at the specified index.</span></span>
<span id="cb31-46"></span>
<span id="cb31-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb31-48"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            index (int): The index of the item.</span></span>
<span id="cb31-49"></span>
<span id="cb31-50"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb31-51"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing an image and its corresponding target.</span></span>
<span id="cb31-52"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-53">        img_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys[index]</span>
<span id="cb31-54">        annotation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df.loc[img_key]</span>
<span id="cb31-55">        image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._load_image_and_target(annotation)</span>
<span id="cb31-56">        </span>
<span id="cb31-57">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms:</span>
<span id="cb31-58">            image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms(image, target)</span>
<span id="cb31-59"></span>
<span id="cb31-60">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, target</span>
<span id="cb31-61"></span>
<span id="cb31-62">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _load_image_and_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, annotation):</span>
<span id="cb31-63">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-64"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Loads an image and its corresponding target data (bounding boxes and labels) based on the provided annotation.</span></span>
<span id="cb31-65"></span>
<span id="cb31-66"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb31-67"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation (pandas.Series): The annotation data for a specific image.</span></span>
<span id="cb31-68"></span>
<span id="cb31-69"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb31-70"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and a dictionary with 'boxes' and 'labels'.</span></span>
<span id="cb31-71"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb31-72">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Retrieve the file path from the image dictionary using the annotation's name as the key.</span></span>
<span id="cb31-73">        filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict[annotation.name]</span>
<span id="cb31-74"></span>
<span id="cb31-75">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the image file and convert it to RGB.</span></span>
<span id="cb31-76">        image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(filepath).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb31-77"></span>
<span id="cb31-78">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract bounding box coordinates from the annotation and convert them to a numpy array.</span></span>
<span id="cb31-79">        bbox_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xtl'</span>], box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ytl'</span>], box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xbr'</span>], box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ybr'</span>]] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> box <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Boxes'</span>]]).reshape(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Boxes'</span>]), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb31-80"></span>
<span id="cb31-81">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the numpy array of bounding boxes to a PyTorch tensor.</span></span>
<span id="cb31-82">        bbox_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.Tensor(bbox_list)</span>
<span id="cb31-83"></span>
<span id="cb31-84">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create bounding box objects with the tensor, specifying the format and canvas size.</span></span>
<span id="cb31-85">        boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(bbox_tensor, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb31-86"></span>
<span id="cb31-87">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract labels from the annotation and map them to their corresponding indices.</span></span>
<span id="cb31-88">        annotation_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [box[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Label'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> box <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Boxes'</span>]]</span>
<span id="cb31-89">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.Tensor([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx[label] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_labels])</span>
<span id="cb31-90"></span>
<span id="cb31-91">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the image and a dictionary containing the bounding boxes and labels.</span></span>
<span id="cb31-92">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: boxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: labels}</span></code></pre></div>
</section>
<section id="image-transforms" class="level3">
<h3 class="anchored" data-anchor-id="image-transforms">Image Transforms</h3>
<p>Here, we will specify and organize all the image transforms to apply during training.</p>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms for data augmentation</span></span>
<span id="cb32-2">data_aug_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose(</span>
<span id="cb32-3">    transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb32-4">        iou_crop,</span>
<span id="cb32-5">        transforms.ColorJitter(</span>
<span id="cb32-6">                brightness <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.875</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.125</span>),</span>
<span id="cb32-7">                contrast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb32-8">                saturation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb32-9">                hue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>),</span>
<span id="cb32-10">        ),</span>
<span id="cb32-11">        transforms.RandomGrayscale(),</span>
<span id="cb32-12">        transforms.RandomEqualize(),</span>
<span id="cb32-13">        transforms.RandomPosterize(bits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb32-14">        transforms.RandomHorizontalFlip(p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb32-15">    ],</span>
<span id="cb32-16">)</span>
<span id="cb32-17"></span>
<span id="cb32-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to resize and pad input images</span></span>
<span id="cb32-19">resize_pad_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb32-20">    resize_max, </span>
<span id="cb32-21">    pad_square,</span>
<span id="cb32-22">    transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb32-23">])</span>
<span id="cb32-24"></span>
<span id="cb32-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to sanitize bounding boxes and normalize input data</span></span>
<span id="cb32-26">final_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb32-27">    transforms.ToImage(), </span>
<span id="cb32-28">    transforms.ToDtype(torch.float32, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb32-29">    transforms.SanitizeBoundingBoxes(),</span>
<span id="cb32-30">])</span>
<span id="cb32-31"></span>
<span id="cb32-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the transformations for training and validation datasets</span></span>
<span id="cb32-33">train_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb32-34">    data_aug_tfms, </span>
<span id="cb32-35">    resize_pad_tfm, </span>
<span id="cb32-36">    final_tfms</span>
<span id="cb32-37">])</span></code></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always use the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.SanitizeBoundingBoxes.html#torchvision.transforms.v2.SanitizeBoundingBoxes"><code>SanitizeBoundingBoxes</code></a> transform to clean up annotations after using data augmentations that alter bounding boxes (e.g., cropping, warping, etc.).</p>
</div>
</div>
</section>
<section id="initialize-dataset" class="level3">
<h3 class="anchored" data-anchor-id="initialize-dataset">Initialize Dataset</h3>
<p>Now, we can create the dataset object using the image dictionary, the annotation DataFrame, and the image transforms.</p>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mapping from class names to class indices</span></span>
<span id="cb33-2">class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {c: i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(class_names)}</span>
<span id="cb33-3"></span>
<span id="cb33-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Instantiate the dataset using the defined transformations</span></span>
<span id="cb33-5">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CVATBBoxDataset(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys()), annotation_df, img_dict, class_to_idx, train_tfms)</span>
<span id="cb33-6"></span>
<span id="cb33-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of samples in the training dataset</span></span>
<span id="cb33-8">pd.Series({</span>
<span id="cb33-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training dataset size:'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataset),</span>
<span id="cb33-10">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_a69db">
<thead>
</thead>
<tbody>
<tr>
<th id="T_a69db_level0_row0" class="row_heading level0 row0">
Training dataset size:
</th>
<td id="T_a69db_row0_col0" class="data row0 col0">
28
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspect-samples" class="level3">
<h3 class="anchored" data-anchor-id="inspect-samples">Inspect Samples</h3>
<p>To close out, we should verify the dataset object works as intended by inspecting the first sample.</p>
<section id="inspect-training-set-sample" class="level4">
<h4 class="anchored" data-anchor-id="inspect-training-set-sample">Inspect training set sample</h4>
<div class="sourceCode" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">dataset_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_dataset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb34-2"></span>
<span id="cb34-3">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb34-4">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.uint8), </span>
<span id="cb34-5">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb34-6">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb34-7">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb34-8">)</span>
<span id="cb34-9"></span>
<span id="cb34-10">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-cvat-annotation-tutorials/bounding-boxes/images/output_59_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we covered how to load custom bounding box annotations made with the CVAT annotation tool and work with them using torchvision’s Transforms V2 API. The skills and knowledge you acquired here provide a solid foundation for future object detection projects.</p>
<p>As a next step, perhaps try annotating a custom object detection dataset with CVAT and loading it with this tutorial’s code. Once you’re comfortable with that, try adapting the code in the following tutorial to train an object detection model on your custom dataset.</p>
<ul>
<li><a href="../../../posts/pytorch-train-object-detector-yolox-tutorial">Training YOLOX Models for Real-Time Object Detection in PyTorch</a></li>
</ul>
</section>
<section id="recommended-tutorials" class="level2">
<h2 class="anchored" data-anchor-id="recommended-tutorials">Recommended Tutorials</h2>
<ul>
<li><a href="../../../posts/torchvision-cvat-annotation-tutorials/keypoints/"><strong>Working with CVAT Keypoint Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with CVAT keypoint annotations in torchvision for keypoint estimation tasks.</li>
<li><a href="../../../posts/torchvision-cvat-annotation-tutorials/segmentation-polygons/"><strong>Working with CVAT Segmentation Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with CVAT segmentation annotations in torchvision for instance segmentation tasks.</li>
<li><a href="http://localhost:3847/posts/pytorch-train-object-detector-yolox-tutorial"><strong>Training YOLOX Models for Real-Time Object Detection in PyTorch</strong></a><strong>:</strong> Learn how to train YOLOX models for real-time object detection in PyTorch by creating a hand gesture detection model.</li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>image-annotation</category>
  <category>object-detection</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/torchvision-cvat-annotation-tutorials/bounding-boxes/</guid>
  <pubDate>Sun, 21 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Working with COCO Segmentation Annotations in Torchvision</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/torchvision-coco-annotation-tutorials/segmentation-polygons/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/tutorials/torchvision-annotation-tutorials-series.html"><strong>Torchvision Annotation Tutorials</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Loading and Exploring the Dataset</li>
<li>Preparing the Data</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to this hands-on guide for working with <a href="https://cocodataset.org/#format-data">COCO-formatted</a> segmentation annotations in <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>. Segmentation annotations indicate the pixels occupied by specific objects or areas of interest in images for training models to recognize and delineate these objects at a pixel level.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/segmentation-polygons/images/segmentation-mask-hero-img.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The tutorial walks through setting up a Python environment, loading the raw annotations into a <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a>, annotating and augmenting images using torchvision’s <a href="https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py">Transforms V2 API</a>, and creating a custom <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Dataset</a> class to feed samples to a model.</p>
<p>This guide is suitable for beginners and experienced practitioners, providing the code, explanations, and resources needed to understand and implement each step. By the end, you will have a solid foundation for working with COCO segmentation annotations in torchvision for instance segmentation tasks.</p>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>The tutorial code is available as a <a href="https://jupyter.org/">Jupyter Notebook</a>, which you can run locally or in a cloud-based environment like <a href="https://colab.research.google.com/">Google Colab</a>. I have dedicated tutorials for those new to these platforms or who need guidance setting up:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Setup Guides">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Setup Guides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="../../../posts/google-colab-getting-started-tutorial/"><strong>Getting Started with Google Colab</strong></a></p></li>
<li><p><a href="../../../posts/mamba-getting-started-tutorial-windows/"><strong>Setting Up a Local Python Environment with Mamba for Machine Learning Projects on Windows</strong></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Tutorial Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tutorial Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook:</th>
<th><a href="https://github.com/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/coco/torchvision-coco-segmentation-annotations.ipynb">GitHub Repository</a></th>
<th><a href="https://colab.research.google.com/github/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/coco/torchvision-coco-segmentation-annotations.ipynb">Open In Colab</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>Before diving into the code, we’ll cover the steps to create a local Python environment and install the necessary dependencies.</p>
<section id="creating-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-python-environment">Creating a Python Environment</h3>
<p>First, we’ll create a Python environment using <a href="https://docs.conda.io/en/latest/">Conda</a>/<a href="https://mamba.readthedocs.io/en/latest/">Mamba</a>. Open a terminal with Conda/Mamba installed and run the following commands:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Conda</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Mamba</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate pytorch-env</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate pytorch-env</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="installing-pytorch">Installing PyTorch</h3>
<p>Next, we’ll install <a href="https://pytorch.org/">PyTorch</a>. Run the appropriate command for your hardware and operating system.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Linux/Windows (CUDA)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Mac</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Linux (CPU)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Windows (CPU)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch with CUDA</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cu121</span></code></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MPS (Metal Performance Shaders) acceleration is available on MacOS 12.3+</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cpu</span></code></pre></div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-additional-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-libraries">Installing Additional Libraries</h3>
<p>We also need to install some additional libraries for our project.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>jupyter</code></td>
<td>An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. (<a href="https://jupyter.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>matplotlib</code></td>
<td>This package provides a comprehensive collection of visualization tools to create high-quality plots, charts, and graphs for data exploration and presentation. (<a href="https://matplotlib.org/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>pandas</code></td>
<td>This package provides fast, powerful, and flexible data analysis and manipulation tools. (<a href="https://pandas.pydata.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>pillow</code></td>
<td>The Python Imaging Library adds image processing capabilities. (<a href="https://pillow.readthedocs.io/en/stable/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>tqdm</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>distinctipy</code></td>
<td>A lightweight python package providing functions to generate colours that are visually distinct from one another. (<a href="https://distinctipy.readthedocs.io/en/latest/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install these additional libraries:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional dependencies</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install distinctipy jupyter matplotlib pandas pillow tqdm</span></code></pre></div>
</section>
<section id="installing-utility-packages" class="level3">
<h3 class="anchored" data-anchor-id="installing-utility-packages">Installing Utility Packages</h3>
<p>We will also install some utility packages I made, which provide shortcuts for routine tasks.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>cjm_pil_utils</code></td>
<td>Some PIL utility functions I frequently use. (<a href="https://cj-mills.github.io/cjm-pil-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_psl_utils</code></td>
<td>Some utility functions using the Python Standard Library. (<a href="https://cj-mills.github.io/cjm-psl-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_pytorch_utils</code></td>
<td>Some utility functions for working with PyTorch. (<a href="https://cj-mills.github.io/cjm-pytorch-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_torchvision_tfms</code></td>
<td>Some custom Torchvision tranforms. (<a href="https://cj-mills.github.io/cjm-torchvision-tfms/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install the utility packages:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional utility packages</span></span>
<span id="cb8-2">pip install cjm_pil_utils cjm_psl_utils cjm_pytorch_utils cjm_torchvision_tfms</span></code></pre></div>
<p>With our environment set up, we can open our Jupyter Notebook and dive into the code.</p>
</section>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python packages into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb9-4"></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb9-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_img_files</span>
<span id="cb9-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file, file_extract</span>
<span id="cb9-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pytorch_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor_to_pil</span>
<span id="cb9-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_torchvision_tfms.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ResizeMax, PadSquare, CustomRandomIoUCrop</span>
<span id="cb9-10"></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the distinctipy module</span></span>
<span id="cb9-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distinctipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> distinctipy</span>
<span id="cb9-13"></span>
<span id="cb9-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import matplotlib for creating plots</span></span>
<span id="cb9-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb9-16"></span>
<span id="cb9-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb9-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-19"></span>
<span id="cb9-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb9-21"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb9-22"></span>
<span id="cb9-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb9-24">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb9-25"></span>
<span id="cb9-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb9-27"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image, ImageDraw</span>
<span id="cb9-28"></span>
<span id="cb9-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb9-30"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb9-31"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DataLoader</span>
<span id="cb9-32"></span>
<span id="cb9-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import torchvision dependencies</span></span>
<span id="cb9-34"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision</span>
<span id="cb9-35">torchvision.disable_beta_transforms_warning()</span>
<span id="cb9-36"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BoundingBoxes, Mask</span>
<span id="cb9-37"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> draw_bounding_boxes, draw_segmentation_masks</span>
<span id="cb9-38"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.v2  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb9-39"></span>
<span id="cb9-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import tqdm for progress bar</span></span>
<span id="cb9-41"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm.auto <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
<p>Torchvision provides dedicated <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> subclasses for different annotation types called <a href="https://pytorch.org/vision/stable/tv_tensors.html"><code>TVTensors</code></a>. Torchvision’s V2 transforms use these subclasses to update the annotations based on the applied image augmentations. The TVTensor class for segmentation annotations is called <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.Mask.html">Mask</a>. Torchvision also includes a <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_segmentation_masks.html">draw_segmentation_masks</a> function to annotate images.</p>
</section>
<section id="loading-and-exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-and-exploring-the-dataset">Loading and Exploring the Dataset</h2>
<p>After importing the dependencies, we can start working with our data. I annotated a toy dataset with segmentation masks for this tutorial using images from the free stock photo site <a href="https://www.pexels.com/">Pexels</a>. The dataset is available on <a href="https://huggingface.co/">HuggingFace Hub</a> at the link below:</p>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/datasets/cj-mills/coco-instance-segmentation-toy-dataset/tree/main">coco-instance-segmentation-toy-dataset</a></li>
</ul>
<section id="setting-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-directory-paths">Setting the Directory Paths</h3>
<p>We first need to specify a place to store our dataset and a location to download the zip file containing it. The following code creates the folders in the current directory (<code>./</code>). Update the path if that is not suitable for you.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store datasets</span></span>
<span id="cb10-2">dataset_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./Datasets/"</span>)</span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the dataset directory if it does not exist</span></span>
<span id="cb10-4">dataset_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store archive files</span></span>
<span id="cb10-7">archive_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'../Archive'</span></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the archive directory if it does not exist</span></span>
<span id="cb10-9">archive_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb10-12">pd.Series({</span>
<span id="cb10-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Directory:"</span>: dataset_dir, </span>
<span id="cb10-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Directory:"</span>: archive_dir</span>
<span id="cb10-15">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_193c3">
<thead>
</thead>
<tbody>
<tr>
<th id="T_193c3_level0_row0" class="row_heading level0 row0">
Dataset Directory:
</th>
<td id="T_193c3_row0_col0" class="data row0 col0">
Datasets
</td>
</tr>
<tr>
<th id="T_193c3_level0_row1" class="row_heading level0 row1">
Archive Directory:
</th>
<td id="T_193c3_row1_col0" class="data row1 col0">
Datasets/../Archive
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="setting-the-dataset-path" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-dataset-path">Setting the Dataset Path</h3>
<p>Next, we construct the name for the Hugging Face Hub dataset and set where to download and extract the dataset.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the dataset</span></span>
<span id="cb11-2">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coco-instance-segmentation-toy-dataset'</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb11-5">hf_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'cj-mills/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb11-8">archive_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>archive_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip'</span>)</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb11-11">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the dataset name and paths and converting it to a DataFrame for display</span></span>
<span id="cb11-14">pd.Series({</span>
<span id="cb11-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb11-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Path:"</span>: archive_path, </span>
<span id="cb11-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Path:"</span>: dataset_path</span>
<span id="cb11-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_47273">
<thead>
</thead>
<tbody>
<tr>
<th id="T_47273_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_47273_row0_col0" class="data row0 col0">
cj-mills/coco-instance-segmentation-toy-dataset
</td>
</tr>
<tr>
<th id="T_47273_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_47273_row1_col0" class="data row1 col0">
Datasets/../Archive/coco-instance-segmentation-toy-dataset.zip
</td>
</tr>
<tr>
<th id="T_47273_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_47273_row2_col0" class="data row2 col0">
Datasets/coco-instance-segmentation-toy-dataset
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="downloading-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h3>
<p>We can now download the archive file and extract the dataset using the <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#download_file"><code>download_file</code></a> and <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#file_extract"><code>file_extract</code></a> functions from the <code>cjm_psl_utils</code> package. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb12-2">dataset_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>hf_dataset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip"</span></span>
<span id="cb12-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"HuggingFace Dataset URL: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb12-6">delete_archive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the dataset if not present</span></span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset_path.is_dir():</span>
<span id="cb12-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset folder already exists"</span>)</span>
<span id="cb12-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb12-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Downloading dataset..."</span>)</span>
<span id="cb12-13">    download_file(dataset_url, archive_dir)    </span>
<span id="cb12-14">    </span>
<span id="cb12-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extracting dataset..."</span>)</span>
<span id="cb12-16">    file_extract(fname<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>archive_path, dest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_dir)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete the archive if specified</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> delete_archive: archive_path.unlink()</span></code></pre></div>
</section>
<section id="getting-the-image-and-annotation-folders" class="level3">
<h3 class="anchored" data-anchor-id="getting-the-image-and-annotation-folders">Getting the Image and Annotation Folders</h3>
<p>The dataset has two folders containing the sample images and annotations. The image folder organizes all samples together. The annotations are in a single JSON file.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming the images are stored in a subfolder named 'images'</span></span>
<span id="cb13-2">img_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'images/'</span></span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming the annotation file is in JSON format and located in a subdirectory of the dataset</span></span>
<span id="cb13-5">annotation_file_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(dataset_path.glob(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'*/*.json'</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb13-8">pd.Series({</span>
<span id="cb13-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Image Folder"</span>: img_dir, </span>
<span id="cb13-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annotation File"</span>: annotation_file_path}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_16f35">
<thead>
</thead>
<tbody>
<tr>
<th id="T_16f35_level0_row0" class="row_heading level0 row0">
Image Folder
</th>
<td id="T_16f35_row0_col0" class="data row0 col0">
Datasets/coco-instance-segmentation-toy-dataset/images
</td>
</tr>
<tr>
<th id="T_16f35_level0_row1" class="row_heading level0 row1">
Annotation File
</th>
<td id="T_16f35_row1_col0" class="data row1 col0">
Datasets/coco-instance-segmentation-toy-dataset/annotations/instances_default.json
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-file-paths" class="level3">
<h3 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h3>
<p>Each image file has a unique name that we can use to locate the corresponding annotation data. We can make a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image more efficiently.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get all image files in the 'img_dir' directory</span></span>
<span id="cb14-2">img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb14-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.stem : <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary that maps file names to file paths</span></span>
<span id="cb14-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> get_img_files(img_dir) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of image files in the image directory</span></span>
<span id="cb14-5">}</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of image files</span></span>
<span id="cb14-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Number of Images: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_dict)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb14-9"></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb14-11">pd.DataFrame.from_dict(img_dict, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).head()</span></code></pre></div>
<pre class="text"><code>Number of Images: 31</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
adults-affection-attractive-2760688
</th>
<td>
Datasets/coco-instance-segmentation-toy-dataset/images/adults-affection-attractive-2760688.jpg
</td>
</tr>
<tr>
<th>
258421
</th>
<td>
Datasets/coco-instance-segmentation-toy-dataset/images/258421.jpg
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
Datasets/coco-instance-segmentation-toy-dataset/images/3075367.jpg
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
Datasets/coco-instance-segmentation-toy-dataset/images/3076319.jpg
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
Datasets/coco-instance-segmentation-toy-dataset/images/3145551.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="get-image-annotations">Get Image Annotations</h3>
<p>Next, we read the content of the JSON annotation file into a Pandas DataFrame so we can easily query the annotations.</p>
<section id="load-the-annotation-file-into-a-dataframe" class="level4">
<h4 class="anchored" data-anchor-id="load-the-annotation-file-into-a-dataframe">Load the annotation file into a DataFrame</h4>
<p>We will transpose the DataFrame to store each section in the JSON file in a separate column.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Read the JSON file into a DataFrame, assuming the JSON is oriented by index</span></span>
<span id="cb16-2">annotation_file_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_json(annotation_file_path, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).transpose()</span>
<span id="cb16-3">annotation_file_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
licenses
</th>
<th>
info
</th>
<th>
categories
</th>
<th>
images
</th>
<th>
annotations
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
{‘name’: ’‘, ’id’: 0, ‘url’: ’’}
</td>
<td>
contributor
</td>
<td>
{‘id’: 1, ‘name’: ‘person’, ‘supercategory’: ’’}
</td>
<td>
{‘id’: 1, ‘width’: 768, ‘height’: 1152, ‘file_name’: ‘258421.jpg’, ‘license’: 0, ‘flickr_url’: ’‘, ’coco_url’: ’‘, ’date_captured’: 0}
</td>
<td>
{‘id’: 1, ‘image_id’: 1, ‘category_id’: 1, ‘segmentation’: [[377.0, 775.5, 368.0, 774.5, 346.5, 764.0, 349.5, 751.0, 348.5, 707.0, 358.5, 668.0, 343.5, 651.0, 359.5, 605.0, 379.5, 583.0, 366.01, 583.39, 362.55, 575.78, 361.85, 565.4, 353.2, 557.09, 357.7, 547.4, 350.78, 532.53, 356.32, 520.76, 359.78, 481.31, 376.39, 467.47, 387.46, 469.55, 401.3, 484.08, 405.8, 501.04, 394.03, 505.88, 394.73, 519.03, 399.92, 531.14, 374.66, 554.33, 369.81, 571.28, 374.31, 574.05, 388.15, 574.39, 397.49, 569.9, 402.5, 578.0, 410.5, 594.0, 412.5, 668.0, 387.0, 667.5, 375.5, 692.0, 376.5, 738.0, 380.5, 753.0, 388.5, 764.0, 386.5, 772.0]], ‘area’: 11461.0, ‘bbox’: [343.5, 467.47, 69.0, 308.03], ‘iscrowd’: 0, ‘attributes’: {‘occluded’: False}}
</td>
</tr>
<tr>
<th>
1
</th>
<td>
None
</td>
<td>
date_created
</td>
<td>
{‘id’: 2, ‘name’: ‘car’, ‘supercategory’: ’’}
</td>
<td>
{‘id’: 2, ‘width’: 1344, ‘height’: 768, ‘file_name’: ‘3075367.jpg’, ‘license’: 0, ‘flickr_url’: ’‘, ’coco_url’: ’‘, ’date_captured’: 0}
</td>
<td>
{‘id’: 2, ‘image_id’: 1, ‘category_id’: 1, ‘segmentation’: [[404.0, 775.5, 396.5, 766.0, 411.5, 753.0, 411.5, 738.0, 416.5, 731.0, 412.5, 598.0, 419.5, 559.0, 416.0, 554.5, 404.0, 566.5, 387.0, 572.5, 375.5, 566.0, 377.5, 554.0, 405.5, 529.0, 413.5, 504.0, 414.5, 493.0, 386.5, 463.0, 388.5, 453.0, 399.0, 443.5, 413.0, 444.5, 423.5, 453.0, 457.5, 506.0, 452.5, 575.0, 458.5, 607.0, 447.5, 635.0, 444.5, 676.0, 452.5, 764.0, 443.0, 770.5]], ‘area’: 13476.0, ‘bbox’: [375.5, 443.5, 83.0, 332.0], ‘iscrowd’: 0, ‘attributes’: {‘occluded’: False}}
</td>
</tr>
<tr>
<th>
2
</th>
<td>
None
</td>
<td>
description
</td>
<td>
None
</td>
<td>
{‘id’: 3, ‘width’: 768, ‘height’: 1120, ‘file_name’: ‘3076319.jpg’, ‘license’: 0, ‘flickr_url’: ’‘, ’coco_url’: ’‘, ’date_captured’: 0}
</td>
<td>
{‘id’: 3, ‘image_id’: 2, ‘category_id’: 1, ‘segmentation’: [[829.0, 466.5, 825.5, 464.0, 824.5, 455.0, 825.5, 425.0, 828.0, 419.5, 833.5, 418.0, 827.5, 417.0, 822.5, 396.0, 825.5, 327.0, 843.5, 313.0, 842.5, 296.0, 833.5, 291.0, 832.5, 270.0, 837.0, 265.5, 856.0, 264.5, 868.5, 277.0, 870.5, 306.0, 881.5, 318.0, 883.5, 329.0, 893.0, 332.5, 899.5, 340.0, 901.5, 367.0, 883.5, 382.0, 849.5, 443.0, 842.5, 448.0, 838.5, 460.0]], ‘area’: 8982.0, ‘bbox’: [822.5, 264.5, 79.0, 202.0], ‘iscrowd’: 0, ‘attributes’: {‘occluded’: False}}
</td>
</tr>
<tr>
<th>
3
</th>
<td>
None
</td>
<td>
url
</td>
<td>
None
</td>
<td>
{‘id’: 4, ‘width’: 1184, ‘height’: 768, ‘file_name’: ‘3145551.jpg’, ‘license’: 0, ‘flickr_url’: ’‘, ’coco_url’: ’‘, ’date_captured’: 0}
</td>
<td>
{‘id’: 4, ‘image_id’: 2, ‘category_id’: 1, ‘segmentation’: [[714.0, 766.5, 664.0, 765.5, 654.0, 716.5, 640.0, 765.5, 578.5, 764.0, 578.5, 599.0, 570.5, 587.0, 592.5, 403.0, 583.5, 339.0, 525.5, 278.0, 463.5, 187.0, 423.5, 98.0, 422.5, 72.0, 444.0, 52.5, 460.5, 62.0, 458.5, 104.0, 485.5, 166.0, 581.0, 270.5, 623.0, 295.5, 644.5, 293.0, 630.5, 261.0, 642.5, 193.0, 667.0, 182.5, 707.0, 191.5, 719.5, 249.0, 709.0, 307.5, 774.0, 271.5, 848.5, 176.0, 875.5, 108.0, 867.5, 55.0, 902.0, 63.5, 908.5, 76.0, 902.5, 134.0, 858.5, 233.0, 759.5, 350.0, 736.5, 495.0, 752.5, 614.0]], ‘area’: 106549.0, ‘bbox’: [422.5, 52.5, 486.0, 714.0], ‘iscrowd’: 0, ‘attributes’: {‘occluded’: False}}
</td>
</tr>
<tr>
<th>
4
</th>
<td>
None
</td>
<td>
version
</td>
<td>
None
</td>
<td>
{‘id’: 5, ‘width’: 1152, ‘height’: 768, ‘file_name’: ‘3176048.jpg’, ‘license’: 0, ‘flickr_url’: ’‘, ’coco_url’: ’‘, ’date_captured’: 0}
</td>
<td>
{‘id’: 5, ‘image_id’: 2, ‘category_id’: 1, ‘segmentation’: [[359.0, 509.5, 355.0, 509.5, 350.5, 502.0, 353.5, 486.0, 349.5, 475.0, 349.5, 449.0, 345.5, 430.0, 339.5, 419.0, 337.5, 394.0, 327.5, 378.0, 331.5, 371.0, 332.5, 357.0, 342.5, 345.0, 345.5, 327.0, 354.0, 313.5, 365.5, 317.0, 366.5, 339.0, 385.0, 350.5, 399.5, 371.0, 398.5, 383.0, 390.0, 391.5, 390.5, 378.0, 383.0, 369.5, 379.5, 370.0, 380.5, 441.0, 376.5, 471.0, 370.0, 464.5, 364.5, 472.0, 362.5, 482.0, 364.5, 504.0]], ‘area’: 6422.0, ‘bbox’: [327.5, 313.5, 72.0, 196.0], ‘iscrowd’: 0, ‘attributes’: {‘occluded’: False}}
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>The source JSON content corresponding to the first row in the DataFrame is available below:</p>
<div style="overflow-x:auto; max-height:500px">
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb17-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"licenses"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-3">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-4">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-5">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-6">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"url"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb17-7">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-8">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-9">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"info"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-10">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"contributor"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-11">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"date_created"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-12">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-13">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"url"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-14">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"version"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-15">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"year"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb17-16">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb17-17">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"categories"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-18">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-19">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-20">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-21">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"supercategory"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb17-22">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-23">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-24">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-25">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"car"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-26">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"supercategory"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb17-27">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-28">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-29">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"images"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-30">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-31">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-32">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"width"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">768</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-33">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"height"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1152</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-34">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"file_name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"258421.jpg"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-35">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"license"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-36">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"flickr_url"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-37">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"coco_url"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-38">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"date_captured"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb17-39">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-40">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-41">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"annotations"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-42">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-43">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-44">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"image_id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-45">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"category_id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-46">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"segmentation"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-47">                <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-48">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">377.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-49">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">775.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-50">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">368.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-51">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">774.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-52">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">346.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-53">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">764.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-54">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">349.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-55">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">751.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-56">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">348.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-57">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">707.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-58">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">358.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-59">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">668.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-60">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">343.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-61">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">651.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-62">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">359.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-63">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">605.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-64">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">379.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-65">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">583.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-66">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">366.01</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-67">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">583.39</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-68">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">362.55</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-69">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">575.78</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-70">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">361.85</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-71">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">565.4</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-72">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">353.2</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-73">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">557.09</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-74">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">357.7</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-75">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">547.4</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-76">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">350.78</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-77">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">532.53</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-78">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">356.32</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-79">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">520.76</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-80">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">359.78</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-81">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">481.31</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-82">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">376.39</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-83">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">467.47</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-84">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">387.46</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-85">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">469.55</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-86">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">401.3</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-87">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">484.08</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-88">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">405.8</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-89">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">501.04</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-90">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">394.03</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-91">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">505.88</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-92">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">394.73</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-93">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">519.03</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-94">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">399.92</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-95">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">531.14</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-96">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">374.66</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-97">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">554.33</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-98">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">369.81</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-99">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">571.28</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-100">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">374.31</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-101">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">574.05</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-102">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">388.15</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-103">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">574.39</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-104">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">397.49</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-105">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">569.9</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-106">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">402.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-107">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">578.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-108">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">410.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-109">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">594.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-110">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">412.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-111">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">668.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-112">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">387.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-113">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">667.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-114">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">375.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-115">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">692.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-116">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">376.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-117">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">738.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-118">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">380.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-119">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">753.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-120">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">388.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-121">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">764.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-122">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">386.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-123">                    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">772.0</span></span>
<span id="cb17-124">                <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb17-125">            <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-126">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"area"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">11461.0</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-127">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"bbox"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-128">                <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">343.5</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-129">                <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">467.47</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-130">                <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">69.0</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-131">                <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">308.03</span></span>
<span id="cb17-132">            <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-133">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"iscrowd"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-134">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"attributes"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-135">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"occluded"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span></span>
<span id="cb17-136">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-137">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-138">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb17-139"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
<hr>
<p>The most relevant information for our purposes is in the following sections:</p>
<ul>
<li><code>categories</code>: Stores the class names for the various object types in the dataset. Note that this toy dataset only has one object type.</li>
<li><code>images</code>: Stores the dimensions and file names for each image.</li>
<li><code>annotations</code>: Stores the image IDs, category IDs, the segmentation polygon annotations in <code>[[x1,y1, x2,y2, ..., xn,yn]]</code> format, and the encapsulating bounding box annotations in <code>[Top-Left X, Top-Left Y, Width, Height]</code> format.</li>
</ul>
</section>
<section id="extract-the-image-informationextract-the-object-classes" class="level4">
<h4 class="anchored" data-anchor-id="extract-the-image-informationextract-the-object-classes">Extract the image informationExtract the object classes</h4>
<p>We first need to extract the class names from the <code>categories</code> column of the DataFrame.</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract and transform the 'categories' section of the data</span></span>
<span id="cb18-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This DataFrame contains category details like category ID and name</span></span>
<span id="cb18-3">categories_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_file_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'categories'</span>].dropna().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)</span>
<span id="cb18-4">categories_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb18-5">categories_df</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
name
</th>
<th>
supercategory
</th>
</tr>
<tr>
<th>
id
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
person
</td>
<td>
</td>
</tr>
<tr>
<th>
2
</th>
<td>
car
</td>
<td>
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>This toy dataset only contains a two object classes, named <code>person</code> and <code>car</code>.</p>
</section>
<section id="extract-the-image-information" class="level4">
<h4 class="anchored" data-anchor-id="extract-the-image-information">Extract the image information</h4>
<p>Next, we will extract the file names, image dimensions, and Image IDs from the <code>images</code> column of the DataFrame.</p>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract and transform the 'images' section of the data</span></span>
<span id="cb19-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This DataFrame contains image details like file name, height, width, and image ID</span></span>
<span id="cb19-3">images_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_file_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'images'</span>].to_frame()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'images'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'file_name'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'height'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'width'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>]]</span>
<span id="cb19-4">images_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
file_name
</th>
<th>
height
</th>
<th>
width
</th>
<th>
id
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
<td>
2.0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3076319.jpg
</td>
<td>
1120.0
</td>
<td>
768.0
</td>
<td>
3.0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3145551.jpg
</td>
<td>
768.0
</td>
<td>
1184.0
</td>
<td>
4.0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
3176048.jpg
</td>
<td>
768.0
</td>
<td>
1152.0
</td>
<td>
5.0
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="extract-the-annotation-information" class="level4">
<h4 class="anchored" data-anchor-id="extract-the-annotation-information">Extract the annotation information</h4>
<p>Last, we must extract the Image IDs, segmentation annotations, bounding box annotations, and Category IDs from the <code>annotations</code> column in the DataFrame.</p>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract and transform the 'annotations' section of the data</span></span>
<span id="cb20-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This DataFrame contains annotation details like image ID, segmentation points, bounding box, and category ID</span></span>
<span id="cb20-3">annotations_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_file_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'annotations'</span>].to_frame()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'annotations'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image_id'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'segmentation'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bbox'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'category_id'</span>]]</span>
<span id="cb20-4">annotations_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
image_id
</th>
<th>
segmentation
</th>
<th>
bbox
</th>
<th>
category_id
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
[[377.0, 775.5, 368.0, 774.5, 346.5, 764.0, 349.5, 751.0, 348.5, 707.0, 358.5, 668.0, 343.5, 651.0, 359.5, 605.0, 379.5, 583.0, 366.01, 583.39, 362.55, 575.78, 361.85, 565.4, 353.2, 557.09, 357.7, 547.4, 350.78, 532.53, 356.32, 520.76, 359.78, 481.31, 376.39, 467.47, 387.46, 469.55, 401.3, 484.08, 405.8, 501.04, 394.03, 505.88, 394.73, 519.03, 399.92, 531.14, 374.66, 554.33, 369.81, 571.28, 374.31, 574.05, 388.15, 574.39, 397.49, 569.9, 402.5, 578.0, 410.5, 594.0, 412.5, 668.0, 387.0, 667.5, 375.5, 692.0, 376.5, 738.0, 380.5, 753.0, 388.5, 764.0, 386.5, 772.0]]
</td>
<td>
[343.5, 467.47, 69.0, 308.03]
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
[[404.0, 775.5, 396.5, 766.0, 411.5, 753.0, 411.5, 738.0, 416.5, 731.0, 412.5, 598.0, 419.5, 559.0, 416.0, 554.5, 404.0, 566.5, 387.0, 572.5, 375.5, 566.0, 377.5, 554.0, 405.5, 529.0, 413.5, 504.0, 414.5, 493.0, 386.5, 463.0, 388.5, 453.0, 399.0, 443.5, 413.0, 444.5, 423.5, 453.0, 457.5, 506.0, 452.5, 575.0, 458.5, 607.0, 447.5, 635.0, 444.5, 676.0, 452.5, 764.0, 443.0, 770.5]]
</td>
<td>
[375.5, 443.5, 83.0, 332.0]
</td>
<td>
1
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
[[829.0, 466.5, 825.5, 464.0, 824.5, 455.0, 825.5, 425.0, 828.0, 419.5, 833.5, 418.0, 827.5, 417.0, 822.5, 396.0, 825.5, 327.0, 843.5, 313.0, 842.5, 296.0, 833.5, 291.0, 832.5, 270.0, 837.0, 265.5, 856.0, 264.5, 868.5, 277.0, 870.5, 306.0, 881.5, 318.0, 883.5, 329.0, 893.0, 332.5, 899.5, 340.0, 901.5, 367.0, 883.5, 382.0, 849.5, 443.0, 842.5, 448.0, 838.5, 460.0]]
</td>
<td>
[822.5, 264.5, 79.0, 202.0]
</td>
<td>
1
</td>
</tr>
<tr>
<th>
3
</th>
<td>
2
</td>
<td>
[[714.0, 766.5, 664.0, 765.5, 654.0, 716.5, 640.0, 765.5, 578.5, 764.0, 578.5, 599.0, 570.5, 587.0, 592.5, 403.0, 583.5, 339.0, 525.5, 278.0, 463.5, 187.0, 423.5, 98.0, 422.5, 72.0, 444.0, 52.5, 460.5, 62.0, 458.5, 104.0, 485.5, 166.0, 581.0, 270.5, 623.0, 295.5, 644.5, 293.0, 630.5, 261.0, 642.5, 193.0, 667.0, 182.5, 707.0, 191.5, 719.5, 249.0, 709.0, 307.5, 774.0, 271.5, 848.5, 176.0, 875.5, 108.0, 867.5, 55.0, 902.0, 63.5, 908.5, 76.0, 902.5, 134.0, 858.5, 233.0, 759.5, 350.0, 736.5, 495.0, 752.5, 614.0]]
</td>
<td>
[422.5, 52.5, 486.0, 714.0]
</td>
<td>
1
</td>
</tr>
<tr>
<th>
4
</th>
<td>
2
</td>
<td>
[[359.0, 509.5, 355.0, 509.5, 350.5, 502.0, 353.5, 486.0, 349.5, 475.0, 349.5, 449.0, 345.5, 430.0, 339.5, 419.0, 337.5, 394.0, 327.5, 378.0, 331.5, 371.0, 332.5, 357.0, 342.5, 345.0, 345.5, 327.0, 354.0, 313.5, 365.5, 317.0, 366.5, 339.0, 385.0, 350.5, 399.5, 371.0, 398.5, 383.0, 390.0, 391.5, 390.5, 378.0, 383.0, 369.5, 379.5, 370.0, 380.5, 441.0, 376.5, 471.0, 370.0, 464.5, 364.5, 472.0, 362.5, 482.0, 364.5, 504.0]]
</td>
<td>
[327.5, 313.5, 72.0, 196.0]
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Now that we have extracted the relevant information from the JSON file, we can recombine it into a single DataFrame for convenience.</p>
</section>
<section id="add-the-class-names-to-the-annotations" class="level4">
<h4 class="anchored" data-anchor-id="add-the-class-names-to-the-annotations">Add the class names to the annotations</h4>
<p>We will first add a new <code>label</code> column to the <code>annotations_df</code> DataFrame containing the corresponding class name from the <code>categories_df</code> DataFrame for each bounding box annotation.</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Map 'category_id' in annotations DataFrame to category name using categories DataFrame</span></span>
<span id="cb21-2">annotations_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotations_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'category_id'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: categories_df.loc[x][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>])</span>
<span id="cb21-3">annotations_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
image_id
</th>
<th>
segmentation
</th>
<th>
bbox
</th>
<th>
category_id
</th>
<th>
label
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
[[377.0, 775.5, 368.0, 774.5, 346.5, 764.0, 349.5, 751.0, 348.5, 707.0, 358.5, 668.0, 343.5, 651.0, 359.5, 605.0, 379.5, 583.0, 366.01, 583.39, 362.55, 575.78, 361.85, 565.4, 353.2, 557.09, 357.7, 547.4, 350.78, 532.53, 356.32, 520.76, 359.78, 481.31, 376.39, 467.47, 387.46, 469.55, 401.3, 484.08, 405.8, 501.04, 394.03, 505.88, 394.73, 519.03, 399.92, 531.14, 374.66, 554.33, 369.81, 571.28, 374.31, 574.05, 388.15, 574.39, 397.49, 569.9, 402.5, 578.0, 410.5, 594.0, 412.5, 668.0, 387.0, 667.5, 375.5, 692.0, 376.5, 738.0, 380.5, 753.0, 388.5, 764.0, 386.5, 772.0]]
</td>
<td>
[343.5, 467.47, 69.0, 308.03]
</td>
<td>
1
</td>
<td>
person
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
[[404.0, 775.5, 396.5, 766.0, 411.5, 753.0, 411.5, 738.0, 416.5, 731.0, 412.5, 598.0, 419.5, 559.0, 416.0, 554.5, 404.0, 566.5, 387.0, 572.5, 375.5, 566.0, 377.5, 554.0, 405.5, 529.0, 413.5, 504.0, 414.5, 493.0, 386.5, 463.0, 388.5, 453.0, 399.0, 443.5, 413.0, 444.5, 423.5, 453.0, 457.5, 506.0, 452.5, 575.0, 458.5, 607.0, 447.5, 635.0, 444.5, 676.0, 452.5, 764.0, 443.0, 770.5]]
</td>
<td>
[375.5, 443.5, 83.0, 332.0]
</td>
<td>
1
</td>
<td>
person
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
[[829.0, 466.5, 825.5, 464.0, 824.5, 455.0, 825.5, 425.0, 828.0, 419.5, 833.5, 418.0, 827.5, 417.0, 822.5, 396.0, 825.5, 327.0, 843.5, 313.0, 842.5, 296.0, 833.5, 291.0, 832.5, 270.0, 837.0, 265.5, 856.0, 264.5, 868.5, 277.0, 870.5, 306.0, 881.5, 318.0, 883.5, 329.0, 893.0, 332.5, 899.5, 340.0, 901.5, 367.0, 883.5, 382.0, 849.5, 443.0, 842.5, 448.0, 838.5, 460.0]]
</td>
<td>
[822.5, 264.5, 79.0, 202.0]
</td>
<td>
1
</td>
<td>
person
</td>
</tr>
<tr>
<th>
3
</th>
<td>
2
</td>
<td>
[[714.0, 766.5, 664.0, 765.5, 654.0, 716.5, 640.0, 765.5, 578.5, 764.0, 578.5, 599.0, 570.5, 587.0, 592.5, 403.0, 583.5, 339.0, 525.5, 278.0, 463.5, 187.0, 423.5, 98.0, 422.5, 72.0, 444.0, 52.5, 460.5, 62.0, 458.5, 104.0, 485.5, 166.0, 581.0, 270.5, 623.0, 295.5, 644.5, 293.0, 630.5, 261.0, 642.5, 193.0, 667.0, 182.5, 707.0, 191.5, 719.5, 249.0, 709.0, 307.5, 774.0, 271.5, 848.5, 176.0, 875.5, 108.0, 867.5, 55.0, 902.0, 63.5, 908.5, 76.0, 902.5, 134.0, 858.5, 233.0, 759.5, 350.0, 736.5, 495.0, 752.5, 614.0]]
</td>
<td>
[422.5, 52.5, 486.0, 714.0]
</td>
<td>
1
</td>
<td>
person
</td>
</tr>
<tr>
<th>
4
</th>
<td>
2
</td>
<td>
[[359.0, 509.5, 355.0, 509.5, 350.5, 502.0, 353.5, 486.0, 349.5, 475.0, 349.5, 449.0, 345.5, 430.0, 339.5, 419.0, 337.5, 394.0, 327.5, 378.0, 331.5, 371.0, 332.5, 357.0, 342.5, 345.0, 345.5, 327.0, 354.0, 313.5, 365.5, 317.0, 366.5, 339.0, 385.0, 350.5, 399.5, 371.0, 398.5, 383.0, 390.0, 391.5, 390.5, 378.0, 383.0, 369.5, 379.5, 370.0, 380.5, 441.0, 376.5, 471.0, 370.0, 464.5, 364.5, 472.0, 362.5, 482.0, 364.5, 504.0]]
</td>
<td>
[327.5, 313.5, 72.0, 196.0]
</td>
<td>
1
</td>
<td>
person
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="merge-the-image-and-annotation-information" class="level4">
<h4 class="anchored" data-anchor-id="merge-the-image-and-annotation-information">Merge the image and annotation information</h4>
<p>Next, we will add the data from the <code>images_df</code> DataFrame and match it to the annotations using the Image IDs.</p>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Merge annotations DataFrame with images DataFrame on their image ID</span></span>
<span id="cb22-2">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.merge(annotations_df, images_df, left_on<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image_id'</span>, right_on<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>)</span>
<span id="cb22-3">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
image_id
</th>
<th>
segmentation
</th>
<th>
bbox
</th>
<th>
category_id
</th>
<th>
label
</th>
<th>
file_name
</th>
<th>
height
</th>
<th>
width
</th>
<th>
id
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
[[377.0, 775.5, 368.0, 774.5, 346.5, 764.0, 349.5, 751.0, 348.5, 707.0, 358.5, 668.0, 343.5, 651.0, 359.5, 605.0, 379.5, 583.0, 366.01, 583.39, 362.55, 575.78, 361.85, 565.4, 353.2, 557.09, 357.7, 547.4, 350.78, 532.53, 356.32, 520.76, 359.78, 481.31, 376.39, 467.47, 387.46, 469.55, 401.3, 484.08, 405.8, 501.04, 394.03, 505.88, 394.73, 519.03, 399.92, 531.14, 374.66, 554.33, 369.81, 571.28, 374.31, 574.05, 388.15, 574.39, 397.49, 569.9, 402.5, 578.0, 410.5, 594.0, 412.5, 668.0, 387.0, 667.5, 375.5, 692.0, 376.5, 738.0, 380.5, 753.0, 388.5, 764.0, 386.5, 772.0]]
</td>
<td>
[343.5, 467.47, 69.0, 308.03]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
[[404.0, 775.5, 396.5, 766.0, 411.5, 753.0, 411.5, 738.0, 416.5, 731.0, 412.5, 598.0, 419.5, 559.0, 416.0, 554.5, 404.0, 566.5, 387.0, 572.5, 375.5, 566.0, 377.5, 554.0, 405.5, 529.0, 413.5, 504.0, 414.5, 493.0, 386.5, 463.0, 388.5, 453.0, 399.0, 443.5, 413.0, 444.5, 423.5, 453.0, 457.5, 506.0, 452.5, 575.0, 458.5, 607.0, 447.5, 635.0, 444.5, 676.0, 452.5, 764.0, 443.0, 770.5]]
</td>
<td>
[375.5, 443.5, 83.0, 332.0]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
[[829.0, 466.5, 825.5, 464.0, 824.5, 455.0, 825.5, 425.0, 828.0, 419.5, 833.5, 418.0, 827.5, 417.0, 822.5, 396.0, 825.5, 327.0, 843.5, 313.0, 842.5, 296.0, 833.5, 291.0, 832.5, 270.0, 837.0, 265.5, 856.0, 264.5, 868.5, 277.0, 870.5, 306.0, 881.5, 318.0, 883.5, 329.0, 893.0, 332.5, 899.5, 340.0, 901.5, 367.0, 883.5, 382.0, 849.5, 443.0, 842.5, 448.0, 838.5, 460.0]]
</td>
<td>
[822.5, 264.5, 79.0, 202.0]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
<td>
2.0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
2
</td>
<td>
[[714.0, 766.5, 664.0, 765.5, 654.0, 716.5, 640.0, 765.5, 578.5, 764.0, 578.5, 599.0, 570.5, 587.0, 592.5, 403.0, 583.5, 339.0, 525.5, 278.0, 463.5, 187.0, 423.5, 98.0, 422.5, 72.0, 444.0, 52.5, 460.5, 62.0, 458.5, 104.0, 485.5, 166.0, 581.0, 270.5, 623.0, 295.5, 644.5, 293.0, 630.5, 261.0, 642.5, 193.0, 667.0, 182.5, 707.0, 191.5, 719.5, 249.0, 709.0, 307.5, 774.0, 271.5, 848.5, 176.0, 875.5, 108.0, 867.5, 55.0, 902.0, 63.5, 908.5, 76.0, 902.5, 134.0, 858.5, 233.0, 759.5, 350.0, 736.5, 495.0, 752.5, 614.0]]
</td>
<td>
[422.5, 52.5, 486.0, 714.0]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
<td>
2.0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
2
</td>
<td>
[[359.0, 509.5, 355.0, 509.5, 350.5, 502.0, 353.5, 486.0, 349.5, 475.0, 349.5, 449.0, 345.5, 430.0, 339.5, 419.0, 337.5, 394.0, 327.5, 378.0, 331.5, 371.0, 332.5, 357.0, 342.5, 345.0, 345.5, 327.0, 354.0, 313.5, 365.5, 317.0, 366.5, 339.0, 385.0, 350.5, 399.5, 371.0, 398.5, 383.0, 390.0, 391.5, 390.5, 378.0, 383.0, 369.5, 379.5, 370.0, 380.5, 441.0, 376.5, 471.0, 370.0, 464.5, 364.5, 472.0, 362.5, 482.0, 364.5, 504.0]]
</td>
<td>
[327.5, 313.5, 72.0, 196.0]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
<td>
2.0
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="use-the-image-name-as-the-index" class="level4">
<h4 class="anchored" data-anchor-id="use-the-image-name-as-the-index">Use the image name as the index</h4>
<p>Then, we will change the index for the <code>annotations_df</code> DataFrame to match the keys in the <code>img_dict</code> dictionary, allowing us to retrieve both the image paths and annotation data using the same index key.</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Remove old 'id' column post-merge</span></span>
<span id="cb23-2">annotation_df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb23-3"></span>
<span id="cb23-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the image_id from the file_name (assuming file_name contains the image_id)</span></span>
<span id="cb23-5">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image_id'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'file_name'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: x.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb23-6"></span>
<span id="cb23-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set 'image_id' as the index for the DataFrame</span></span>
<span id="cb23-8">annotation_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image_id'</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb23-9">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
segmentation
</th>
<th>
bbox
</th>
<th>
category_id
</th>
<th>
label
</th>
<th>
file_name
</th>
<th>
height
</th>
<th>
width
</th>
</tr>
<tr>
<th>
image_id
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
[[377.0, 775.5, 368.0, 774.5, 346.5, 764.0, 349.5, 751.0, 348.5, 707.0, 358.5, 668.0, 343.5, 651.0, 359.5, 605.0, 379.5, 583.0, 366.01, 583.39, 362.55, 575.78, 361.85, 565.4, 353.2, 557.09, 357.7, 547.4, 350.78, 532.53, 356.32, 520.76, 359.78, 481.31, 376.39, 467.47, 387.46, 469.55, 401.3, 484.08, 405.8, 501.04, 394.03, 505.88, 394.73, 519.03, 399.92, 531.14, 374.66, 554.33, 369.81, 571.28, 374.31, 574.05, 388.15, 574.39, 397.49, 569.9, 402.5, 578.0, 410.5, 594.0, 412.5, 668.0, 387.0, 667.5, 375.5, 692.0, 376.5, 738.0, 380.5, 753.0, 388.5, 764.0, 386.5, 772.0]]
</td>
<td>
[343.5, 467.47, 69.0, 308.03]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
</tr>
<tr>
<th>
258421
</th>
<td>
[[404.0, 775.5, 396.5, 766.0, 411.5, 753.0, 411.5, 738.0, 416.5, 731.0, 412.5, 598.0, 419.5, 559.0, 416.0, 554.5, 404.0, 566.5, 387.0, 572.5, 375.5, 566.0, 377.5, 554.0, 405.5, 529.0, 413.5, 504.0, 414.5, 493.0, 386.5, 463.0, 388.5, 453.0, 399.0, 443.5, 413.0, 444.5, 423.5, 453.0, 457.5, 506.0, 452.5, 575.0, 458.5, 607.0, 447.5, 635.0, 444.5, 676.0, 452.5, 764.0, 443.0, 770.5]]
</td>
<td>
[375.5, 443.5, 83.0, 332.0]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
[[829.0, 466.5, 825.5, 464.0, 824.5, 455.0, 825.5, 425.0, 828.0, 419.5, 833.5, 418.0, 827.5, 417.0, 822.5, 396.0, 825.5, 327.0, 843.5, 313.0, 842.5, 296.0, 833.5, 291.0, 832.5, 270.0, 837.0, 265.5, 856.0, 264.5, 868.5, 277.0, 870.5, 306.0, 881.5, 318.0, 883.5, 329.0, 893.0, 332.5, 899.5, 340.0, 901.5, 367.0, 883.5, 382.0, 849.5, 443.0, 842.5, 448.0, 838.5, 460.0]]
</td>
<td>
[822.5, 264.5, 79.0, 202.0]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
[[714.0, 766.5, 664.0, 765.5, 654.0, 716.5, 640.0, 765.5, 578.5, 764.0, 578.5, 599.0, 570.5, 587.0, 592.5, 403.0, 583.5, 339.0, 525.5, 278.0, 463.5, 187.0, 423.5, 98.0, 422.5, 72.0, 444.0, 52.5, 460.5, 62.0, 458.5, 104.0, 485.5, 166.0, 581.0, 270.5, 623.0, 295.5, 644.5, 293.0, 630.5, 261.0, 642.5, 193.0, 667.0, 182.5, 707.0, 191.5, 719.5, 249.0, 709.0, 307.5, 774.0, 271.5, 848.5, 176.0, 875.5, 108.0, 867.5, 55.0, 902.0, 63.5, 908.5, 76.0, 902.5, 134.0, 858.5, 233.0, 759.5, 350.0, 736.5, 495.0, 752.5, 614.0]]
</td>
<td>
[422.5, 52.5, 486.0, 714.0]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
[[359.0, 509.5, 355.0, 509.5, 350.5, 502.0, 353.5, 486.0, 349.5, 475.0, 349.5, 449.0, 345.5, 430.0, 339.5, 419.0, 337.5, 394.0, 327.5, 378.0, 331.5, 371.0, 332.5, 357.0, 342.5, 345.0, 345.5, 327.0, 354.0, 313.5, 365.5, 317.0, 366.5, 339.0, 385.0, 350.5, 399.5, 371.0, 398.5, 383.0, 390.0, 391.5, 390.5, 378.0, 383.0, 369.5, 379.5, 370.0, 380.5, 441.0, 376.5, 471.0, 370.0, 464.5, 364.5, 472.0, 362.5, 482.0, 364.5, 504.0]]
</td>
<td>
[327.5, 313.5, 72.0, 196.0]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="group-annotations-by-image" class="level4">
<h4 class="anchored" data-anchor-id="group-annotations-by-image">Group annotations by image</h4>
<p>Each segmentation annotation is currently in a separate row in the DataFrame. We will want to group the annotations for each image into a single row for use with PyTorch and torchvision.</p>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Group the data by 'image_id' and aggregate information</span></span>
<span id="cb24-2">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image_id'</span>).agg({</span>
<span id="cb24-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'segmentation'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>,</span>
<span id="cb24-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bbox'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>, </span>
<span id="cb24-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'category_id'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>,</span>
<span id="cb24-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span> :<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>,</span>
<span id="cb24-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'file_name'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'first'</span>, </span>
<span id="cb24-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'height'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'first'</span>, </span>
<span id="cb24-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'width'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'first'</span></span>
<span id="cb24-10">})</span>
<span id="cb24-11"></span>
<span id="cb24-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Rename columns for clarity </span></span>
<span id="cb24-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 'bbox' is renamed to 'bboxes' and 'label' to 'labels'</span></span>
<span id="cb24-14">annotation_df.rename(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bbox'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bboxes'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>}, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb24-15">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
segmentation
</th>
<th>
bboxes
</th>
<th>
category_id
</th>
<th>
labels
</th>
<th>
file_name
</th>
<th>
height
</th>
<th>
width
</th>
</tr>
<tr>
<th>
image_id
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
[[[377.0, 775.5, 368.0, 774.5, 346.5, 764.0, 349.5, 751.0, 348.5, 707.0, 358.5, 668.0, 343.5, 651.0, 359.5, 605.0, 379.5, 583.0, 366.01, 583.39, 362.55, 575.78, 361.85, 565.4, 353.2, 557.09, 357.7, 547.4, 350.78, 532.53, 356.32, 520.76, 359.78, 481.31, 376.39, 467.47, 387.46, 469.55, 401.3, 484.08, 405.8, 501.04, 394.03, 505.88, 394.73, 519.03, 399.92, 531.14, 374.66, 554.33, 369.81, 571.28, 374.31, 574.05, 388.15, 574.39, 397.49, 569.9, 402.5, 578.0, 410.5, 594.0, 412.5, 668.0, 387.0, 667.5, 375.5, 692.0, 376.5, 738.0, 380.5, 753.0, 388.5, 764.0, 386.5, 772.0]], [[404.0, 775.5, 396.5, 766.0, 411.5, 753.0, 411.5, 738.0, 416.5, 731.0, 412.5, 598.0, 419.5, 559.0, 416.0, 554.5, 404.0, 566.5, 387.0, 572.5, 375.5, 566.0, 377.5, 554.0, 405.5, 529.0, 413.5, 504.0, 414.5, 493.0, 386.5, 463.0, 388.5, 453.0, 399.0, 443.5, 413.0, 444.5, 423.5, 453.0, 457.5, 506.0, 452.5, 575.0, 458.5, 607.0, 447.5, 635.0, 444.5, 676.0, 452.5, 764.0, 443.0, 770.5]]]
</td>
<td>
[[343.5, 467.47, 69.0, 308.03], [375.5, 443.5, 83.0, 332.0]]
</td>
<td>
[1, 1]
</td>
<td>
[person, person]
</td>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
[[[829.0, 466.5, 825.5, 464.0, 824.5, 455.0, 825.5, 425.0, 828.0, 419.5, 833.5, 418.0, 827.5, 417.0, 822.5, 396.0, 825.5, 327.0, 843.5, 313.0, 842.5, 296.0, 833.5, 291.0, 832.5, 270.0, 837.0, 265.5, 856.0, 264.5, 868.5, 277.0, 870.5, 306.0, 881.5, 318.0, 883.5, 329.0, 893.0, 332.5, 899.5, 340.0, 901.5, 367.0, 883.5, 382.0, 849.5, 443.0, 842.5, 448.0, 838.5, 460.0]], [[714.0, 766.5, 664.0, 765.5, 654.0, 716.5, 640.0, 765.5, 578.5, 764.0, 578.5, 599.0, 570.5, 587.0, 592.5, 403.0, 583.5, 339.0, 525.5, 278.0, 463.5, 187.0, 423.5, 98.0, 422.5, 72.0, 444.0, 52.5, 460.5, 62.0, 458.5, 104.0, 485.5, 166.0, 581.0, 270.5, 623.0, 295.5, 644.5, 293.0, 630.5, 261.0, 642.5, 193.0, 667.0, 182.5, 707.0, 191.5, 719.5, 249.0, 709.0, 307.5, 774.0, 271.5, 848.5, 176.0, 875.5, 108.0, 867.5, 55.0, 902.0, 63.5, 908.5, 76.0, 902.5, 134.0, 858.5, 233.0, 759.5, 350.0, 736.5, 495.0, 752.5, 614.0]], [[359.0, 509.5, 355.0, 509.5, 350.5, 502.0, 353.5, 486.0, 349.5, 475.0, 349.5, 449.0, 345.5, 430.0, 339.5, 419.0, 337.5, 394.0, 327.5, 378.0, 331.5, 371.0, 332.5, 357.0, 342.5, 345.0, 345.5, 327.0, 354.0, 313.5, 365.5, 317.0, 366.5, 339.0, 385.0, 350.5, 399.5, 371.0, 398.5, 383.0, 390.0, 391.5, 390.5, 378.0, 383.0, 369.5, 379.5, 370.0, 380.5, 441.0, 376.5, 471.0, 370.0, 464.5, 364.5, 472.0, 362.5, 482.0, 364.5, 504.0]], [[1343.0, 764.5, 964.0, 745.5, 930.0, 764.5, 914.5, 759.0, 904.0, 722.5, 865.0, 706.5, 848.0, 735.5, 801.0, 735.5, 788.5, 699.0, 792.5, 577.0, 821.5, 476.0, 849.5, 454.0, 890.5, 382.0, 930.0, 355.5, 1021.0, 347.5, 1195.0, 358.5, 1287.0, 378.5, 1343.0, 436.0]]]
</td>
<td>
[[822.5, 264.5, 79.0, 202.0], [422.5, 52.5, 486.0, 714.0], [327.5, 313.5, 72.0, 196.0], [788.5, 347.5, 554.5, 417.0]]
</td>
<td>
[1, 1, 1, 2]
</td>
<td>
[person, person, person, car]
</td>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
[[[590.0, 1119.0, 508.5, 1119.0, 393.5, 881.0, 363.5, 778.0, 359.5, 738.0, 377.5, 685.0, 420.5, 660.0, 388.5, 650.0, 410.5, 606.0, 412.5, 477.0, 349.5, 383.0, 364.5, 338.0, 341.5, 303.0, 369.5, 313.0, 396.5, 191.0, 449.0, 157.5, 496.0, 169.5, 524.5, 203.0, 534.5, 320.0, 577.5, 380.0, 588.5, 493.0, 635.5, 554.0, 631.5, 567.0, 687.5, 625.0, 704.5, 673.0, 698.5, 743.0, 632.5, 833.0, 618.5, 955.0, 573.5, 1096.0]], [[262.0, 1119.0, 128.5, 1119.0, 131.5, 1089.0, 35.5, 901.0, 11.5, 772.0, 33.5, 686.0, 70.5, 663.0, 34.5, 612.0, 25.5, 569.0, 52.5, 375.0, 97.0, 332.5, 195.5, 306.0, 205.5, 255.0, 192.5, 220.0, 240.0, 154.5, 290.0, 133.5, 323.5, 153.0, 341.5, 209.0, 332.5, 279.0, 294.5, 326.0, 347.5, 357.0, 352.5, 399.0, 400.5, 459.0, 404.5, 517.0, 391.5, 631.0, 344.5, 679.0, 359.5, 719.0, 323.5, 907.0, 224.5, 1082.0]]]
</td>
<td>
[[341.5, 157.5, 363.0, 961.5], [11.5, 133.5, 393.0, 985.5]]
</td>
<td>
[1, 1]
</td>
<td>
[person, person]
</td>
<td>
3076319.jpg
</td>
<td>
1120.0
</td>
<td>
768.0
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
[[[683.0, 398.5, 675.0, 398.5, 671.5, 396.0, 673.5, 378.0, 669.5, 366.0, 669.5, 359.0, 664.5, 346.0, 663.5, 326.0, 661.5, 320.0, 661.5, 312.0, 666.5, 304.0, 662.5, 295.0, 666.0, 283.5, 673.0, 283.5, 674.5, 285.0, 676.5, 289.0, 676.5, 297.0, 681.5, 302.0, 685.5, 313.0, 686.5, 336.0, 683.5, 344.0, 685.5, 395.0]], [[649.0, 398.5, 644.0, 398.5, 641.5, 396.0, 640.5, 387.0, 644.5, 379.0, 650.5, 358.0, 650.5, 351.0, 644.5, 335.0, 644.5, 323.0, 646.5, 316.0, 644.5, 300.0, 648.5, 291.0, 654.0, 288.5, 661.5, 295.0, 662.5, 298.0, 658.5, 309.0, 662.5, 316.0, 664.5, 324.0, 665.5, 349.0, 669.5, 364.0, 665.5, 383.0, 666.5, 396.0, 663.0, 397.5, 659.5, 392.0, 662.5, 375.0, 662.5, 364.0, 660.0, 361.5, 649.5, 383.0]]]
</td>
<td>
[[661.5, 283.5, 25.0, 115.0], [640.5, 288.5, 29.0, 110.0]]
</td>
<td>
[1, 1]
</td>
<td>
[person, person]
</td>
<td>
3145551.jpg
</td>
<td>
768.0
</td>
<td>
1184.0
</td>
</tr>
<tr>
<th>
3176048
</th>
<td>
[[[562.0, 464.5, 552.0, 464.5, 550.5, 462.0, 553.5, 454.0, 550.5, 433.0, 558.5, 402.0, 558.5, 389.0, 561.5, 380.0, 557.0, 372.5, 549.0, 374.5, 537.0, 372.5, 533.0, 377.5, 532.5, 371.0, 529.5, 368.0, 542.0, 365.5, 551.0, 366.5, 562.0, 361.5, 567.0, 361.5, 568.5, 360.0, 567.5, 346.0, 572.0, 342.5, 577.0, 342.5, 582.5, 348.0, 581.5, 360.0, 591.5, 372.0, 593.5, 386.0, 592.0, 388.5, 587.0, 388.5, 585.5, 391.0, 578.5, 419.0, 572.5, 434.0, 571.5, 445.0, 566.5, 454.0, 565.5, 462.0]], [[661.0, 436.5, 659.5, 436.0, 660.5, 432.0, 660.5, 396.0, 659.5, 392.0, 663.5, 376.0, 661.0, 373.5, 658.0, 373.5, 650.0, 377.5, 641.0, 377.5, 640.5, 376.0, 647.0, 372.5, 651.0, 372.5, 656.0, 370.5, 666.0, 365.5, 667.5, 364.0, 667.5, 359.0, 670.0, 356.5, 674.0, 356.5, 677.5, 360.0, 676.5, 367.0, 682.5, 374.0, 683.5, 389.0, 681.0, 390.5, 678.5, 388.0, 678.5, 385.0, 677.5, 385.0, 677.5, 390.0, 673.5, 395.0, 673.5, 408.0, 671.5, 411.0, 670.5, 420.0, 668.5, 425.0, 668.5, 433.0, 669.5, 434.0]]]
</td>
<td>
[[529.5, 342.5, 64.0, 122.0], [640.5, 356.5, 43.0, 80.0]]
</td>
<td>
[1, 1]
</td>
<td>
[person, person]
</td>
<td>
3176048.jpg
</td>
<td>
768.0
</td>
<td>
1152.0
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>With the annotations loaded, we can start inspecting our dataset.</p>
</section>
</section>
<section id="inspecting-the-class-distribution" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-the-class-distribution">Inspecting the Class Distribution</h3>
<p>First, we get the names of all the classes in our dataset and inspect the distribution of samples among these classes. This step is not strictly necessary for the toy dataset but is worth doing for real-world projects. A balanced dataset (where each class has approximately the same number of instances) is ideal for training a machine-learning model.</p>
<section id="get-image-classes" class="level4">
<h4 class="anchored" data-anchor-id="get-image-classes">Get image classes</h4>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb25-2">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>].explode().unique().tolist()</span>
<span id="cb25-3"></span>
<span id="cb25-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display labels using a Pandas DataFrame</span></span>
<span id="cb25-5">pd.DataFrame(class_names)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
person
</td>
</tr>
<tr>
<th>
1
</th>
<td>
car
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visualize-the-class-distribution" class="level4">
<h4 class="anchored" data-anchor-id="visualize-the-class-distribution">Visualize the class distribution</h4>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the number of samples for each object class</span></span>
<span id="cb26-2">class_counts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>].explode().tolist()).value_counts()<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#.sort_index()</span></span>
<span id="cb26-3"></span>
<span id="cb26-4">plot_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [index[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> index <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> class_counts.index]</span>
<span id="cb26-5"></span>
<span id="cb26-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the distribution</span></span>
<span id="cb26-7">class_counts.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bar'</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb26-8">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class distribution'</span>)</span>
<span id="cb26-9">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Count'</span>)</span>
<span id="cb26-10">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Classes'</span>)</span>
<span id="cb26-11">plt.xticks(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_counts.index)), plot_labels, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the x-axis tick labels</span></span>
<span id="cb26-12">plt.show()</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/segmentation-polygons/images/output_37_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Note the class distribution is quite imbalanced between the <code>person</code> and <code>car</code> classes. For a real dataset, you would want these to be much closer.</p>
</section>
</section>
<section id="visualizing-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-image-annotations">Visualizing Image Annotations</h3>
<p>In this section, we will annotate a single image with its segmentation masks and bounding boxes using torchvision’s <code>BoundingBoxes</code> and <code>Mask</code> classes and <code>draw_bounding_boxes</code> and <code>draw_segmentation_masks</code> function.</p>
<section id="generate-a-color-map" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-color-map">Generate a color map</h4>
<p>While not required, assigning a unique color to bounding boxes and segmentation masks for each object class enhances visual distinction, allowing for easier identification of different objects in the scene. We can use the <a href="https://distinctipy.readthedocs.io/en/latest/"><code>distinctipy</code></a> package to generate a visually distinct colormap.</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb27-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distinctipy.get_colors(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb27-3"></span>
<span id="cb27-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the color map in integer format</span></span>
<span id="cb27-5">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colors]</span>
<span id="cb27-6"></span>
<span id="cb27-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a color swatch to visualize the color map</span></span>
<span id="cb27-8">distinctipy.color_swatch(colors)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/segmentation-polygons/images/output_41_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a font file</h4>
<p>The <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function included with torchvision uses a pretty small font size. We can increase the font size if we use a custom font. Font files are available on sites like <a href="https://fonts.google.com/">Google Fonts</a>, or we can use one included with the operating system.</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb28-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb28-3"></span>
<span id="cb28-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb28-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
</section>
<section id="define-the-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-the-bounding-box-annotation-function">Define the bounding box annotation function</h4>
<p>We can make a partial function using <code>draw_bounding_boxes</code> since we’ll use the same box thickness and font each time we visualize bounding boxes.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">draw_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(draw_bounding_boxes, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, font<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>font_file, font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
</section>
</section>
<section id="selecting-a-sample-image" class="level3">
<h3 class="anchored" data-anchor-id="selecting-a-sample-image">Selecting a Sample Image</h3>
<p>We can use the unique ID for an image in the image dictionary to get the image file path and the associated annotations from the annotation DataFrame.</p>
<section id="load-the-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="load-the-sample-image">Load the sample image</h4>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the file ID of the first image file</span></span>
<span id="cb30-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb30-3"></span>
<span id="cb30-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the associated image file as a RGB image</span></span>
<span id="cb30-5">sample_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(img_dict[file_id]).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb30-6"></span>
<span id="cb30-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the dimensions of the image</span></span>
<span id="cb30-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Image Dims: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sample_img<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>size<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb30-9"></span>
<span id="cb30-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Show the image</span></span>
<span id="cb30-11">sample_img</span></code></pre></div>
<pre class="text"><code>Image Dims: (768, 1152)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/segmentation-polygons/images/output_48_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="inspect-the-corresponding-annotation-data" class="level4">
<h4 class="anchored" data-anchor-id="inspect-the-corresponding-annotation-data">Inspect the corresponding annotation data</h4>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'</span></span>
<span id="cb32-2">annotation_df.loc[file_id].to_frame()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
adults-affection-attractive-2760688
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
segmentation
</th>
<td>
[[[389.0, 1151.0, 34.5, 1151.0, 82.5, 992.0, 103.0, 965.5, 147.5, 953.0, 135.5, 848.0, 104.5, 763.0, 97.5, 672.0, 129.5, 581.0, 186.5, 519.0, 127.5, 466.0, 106.5, 422.0, 118.5, 369.0, 181.0, 306.5, 258.0, 325.5, 301.5, 412.0, 285.5, 566.0, 291.5, 594.0, 323.5, 610.0, 335.5, 714.0, 366.5, 777.0, 341.5, 848.0, 337.5, 944.0]], [[532.0, 1151.0, 397.5, 1151.0, 345.5, 958.0, 345.5, 855.0, 369.5, 776.0, 340.5, 720.0, 344.5, 678.0, 325.5, 647.0, 326.5, 608.0, 296.5, 592.0, 294.5, 540.0, 298.0, 519.5, 341.5, 493.0, 273.5, 329.0, 284.5, 283.0, 332.0, 249.5, 385.0, 260.5, 411.5, 287.0, 431.5, 338.0, 434.0, 411.5, 449.0, 407.5, 486.0, 440.5, 601.0, 461.5, 671.5, 580.0, 698.5, 786.0, 681.5, 1090.0, 663.0, 1137.5, 549.0, 1127.5]]]
</td>
</tr>
<tr>
<th>
bboxes
</th>
<td>
[[34.5, 306.5, 354.5, 844.5], [273.5, 249.5, 425.0, 901.5]]
</td>
</tr>
<tr>
<th>
category_id
</th>
<td>
[1, 1]
</td>
</tr>
<tr>
<th>
labels
</th>
<td>
[person, person]
</td>
</tr>
<tr>
<th>
file_name
</th>
<td>
adults-affection-attractive-2760688.jpg
</td>
</tr>
<tr>
<th>
height
</th>
<td>
1152.0
</td>
</tr>
<tr>
<th>
width
</th>
<td>
768.0
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>The lists of point coordinates in the segmentation annotations are the vertices of a polygon for the individual segmentation masks. We can use these to generate images for each segmentation mask.</p>
</section>
<section id="define-a-function-to-convert-segmentation-polygons-to-images" class="level4">
<h4 class="anchored" data-anchor-id="define-a-function-to-convert-segmentation-polygons-to-images">Define a function to convert segmentation polygons to images</h4>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> create_polygon_mask(image_size, vertices):</span>
<span id="cb33-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb33-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Create a grayscale image with a white polygonal area on a black background.</span></span>
<span id="cb33-4"></span>
<span id="cb33-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parameters:</span></span>
<span id="cb33-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - image_size (tuple): A tuple representing the dimensions (width, height) of the image.</span></span>
<span id="cb33-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - vertices (list): A list of tuples, each containing the x, y coordinates of a vertex</span></span>
<span id="cb33-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                        of the polygon. Vertices should be in clockwise or counter-clockwise order.</span></span>
<span id="cb33-9"></span>
<span id="cb33-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb33-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - PIL.Image.Image: A PIL Image object containing the polygonal mask.</span></span>
<span id="cb33-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb33-13"></span>
<span id="cb33-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new black image with the given dimensions</span></span>
<span id="cb33-15">    mask_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.new(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'L'</span>, image_size, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb33-16">    </span>
<span id="cb33-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Draw the polygon on the image. The area inside the polygon will be white (255).</span></span>
<span id="cb33-18">    ImageDraw.Draw(mask_img, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'L'</span>).polygon(vertices, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>))</span>
<span id="cb33-19"></span>
<span id="cb33-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the image with the drawn polygon</span></span>
<span id="cb33-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> mask_img</span></code></pre></div>
</section>
<section id="annotate-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="annotate-sample-image">Annotate sample image</h4>
<p>We can now generate the segmentation mask images and feed those to the <code>draw_segmentation_mask</code> function.</p>
<p>The <code>draw_bounding_boxes</code> function expects bounding box annotations in <code>[top-left X, top-left Y, bottom-right X, bottom-right Y]</code> format, so we’ll use the <a href="https://pytorch.org/vision/stable/generated/torchvision.ops.box_convert.html#torchvision.ops.box_convert"><code>box_convert</code></a> function included with torchvision to convert the bounding box annotations from <code>[x,y,w,h]</code> to <code>[x,y,x,y]</code> format.</p>
<div class="sourceCode" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the polygon points for segmentation mask</span></span>
<span id="cb34-2">polygon_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'segmentation'</span>]</span>
<span id="cb34-3"></span>
<span id="cb34-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate mask images from polygons</span></span>
<span id="cb34-5">mask_imgs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [create_polygon_mask(sample_img.size, polygon[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> polygon <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> polygon_points]</span>
<span id="cb34-6"></span>
<span id="cb34-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert mask images to tensors</span></span>
<span id="cb34-8">masks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.concat([Mask(transforms.PILToTensor()(mask_img), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> mask_img <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> mask_imgs])</span>
<span id="cb34-9"></span>
<span id="cb34-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels and bounding box annotations for the sample image</span></span>
<span id="cb34-11">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]</span>
<span id="cb34-12">bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bboxes'</span>]</span>
<span id="cb34-13"></span>
<span id="cb34-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with segmentation masks</span></span>
<span id="cb34-15">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_segmentation_masks(</span>
<span id="cb34-16">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sample_img), </span>
<span id="cb34-17">    masks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>masks, </span>
<span id="cb34-18">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb34-19">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb34-20">)</span>
<span id="cb34-21"></span>
<span id="cb34-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb34-23">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb34-24">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>annotated_tensor, </span>
<span id="cb34-25">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torchvision.ops.box_convert(torch.Tensor(bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>),</span>
<span id="cb34-26">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, </span>
<span id="cb34-27">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb34-28">)</span>
<span id="cb34-29"></span>
<span id="cb34-30">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/segmentation-polygons/images/output_54_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We have loaded the dataset, inspected its class distribution, and visualized the annotations for a sample image. In the final section, we will cover how to augment images using torchvision’s Transforms V2 API and create a custom Dataset class for training.</p>
</section>
</section>
</section>
<section id="preparing-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data">Preparing the Data</h2>
<p>In this section, we will first walk through a single example of how to apply augmentations to a single annotated image using torchvision’s Transforms V2 API before putting everything together in a custom Dataset class.</p>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h3>
<p>Here, we will define some data augmentations to apply to images during training. I created a few custom image transforms to help streamline the code.</p>
<p>The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#customrandomioucrop">first</a> extends the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.RandomIoUCrop.html#torchvision.transforms.v2.RandomIoUCrop"><code>RandomIoUCrop</code></a> transform included with torchvision to give the user more control over how much it crops into bounding box areas. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#resizemax">second</a> resizes images based on their largest dimension rather than their smallest. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#padsquare">third</a> applies square padding and allows the padding to be applied equally on both sides or randomly split between the two sides.</p>
<p>All three are available through the <a href="https://cj-mills.github.io/cjm-torchvision-tfms/"><code>cjm-torchvision-tfms</code></a> package.</p>
<section id="set-training-image-size" class="level4">
<h4 class="anchored" data-anchor-id="set-training-image-size">Set training image size</h4>
<p>Next, we will specify the image size to use during training.</p>
<div class="sourceCode" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set training image size</span></span>
<span id="cb35-2">train_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span></span></code></pre></div>
</section>
<section id="initialize-the-custom-transforms" class="level4">
<h4 class="anchored" data-anchor-id="initialize-the-custom-transforms">Initialize the custom transforms</h4>
<p>Now, we can initialize the transform objects.</p>
<div class="sourceCode" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomIoUCrop object</span></span>
<span id="cb36-2">iou_crop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomRandomIoUCrop(min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb36-3">                               max_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, </span>
<span id="cb36-4">                               min_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, </span>
<span id="cb36-5">                               max_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, </span>
<span id="cb36-6">                               sampler_options<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb36-7">                               trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb36-8">                               jitter_factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)</span>
<span id="cb36-9"></span>
<span id="cb36-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `ResizeMax` object</span></span>
<span id="cb36-11">resize_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ResizeMax(max_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_sz)</span>
<span id="cb36-12"></span>
<span id="cb36-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `PadSquare` object</span></span>
<span id="cb36-14">pad_square <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PadSquare(shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
</section>
<section id="test-the-transforms" class="level4">
<h4 class="anchored" data-anchor-id="test-the-transforms">Test the transforms</h4>
<p>Torchvision’s V2 image transforms take an image and a <code>targets</code> dictionary. The <code>targets</code> dictionary contains the annotations and labels for the image.</p>
<p>We will pass input through the <code>CustomRandomIoUCrop</code> transform first and then through <code>ResizeMax</code> and <code>PadSquare</code>. We can pass the result through a final resize operation to ensure both sides match the <code>train_sz</code> value.</p>
<div class="sourceCode" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get colors for dataset sample</span></span>
<span id="cb37-2">sample_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb37-3"></span>
<span id="cb37-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare bounding box targets</span></span>
<span id="cb37-5">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb37-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>: Mask(masks), </span>
<span id="cb37-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: BoundingBoxes(torchvision.ops.box_convert(torch.Tensor(bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>), </span>
<span id="cb37-8">                           <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, </span>
<span id="cb37-9">                           canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), </span>
<span id="cb37-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.Tensor([class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])</span>
<span id="cb37-11">}</span>
<span id="cb37-12"></span>
<span id="cb37-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Crop the image</span></span>
<span id="cb37-14">cropped_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iou_crop(sample_img, targets)</span>
<span id="cb37-15"></span>
<span id="cb37-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Resize the image</span></span>
<span id="cb37-17">resized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_max(cropped_img, targets)</span>
<span id="cb37-18"></span>
<span id="cb37-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pad the image</span></span>
<span id="cb37-20">padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_square(resized_img, targets)</span>
<span id="cb37-21"></span>
<span id="cb37-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the padded image is the target size</span></span>
<span id="cb37-23">resize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb37-24">resized_padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize(padded_img, targets)</span>
<span id="cb37-25">sanitized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(resized_padded_img, targets)</span>
<span id="cb37-26"></span>
<span id="cb37-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with segmentation masks</span></span>
<span id="cb37-28">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_segmentation_masks(</span>
<span id="cb37-29">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sanitized_img), </span>
<span id="cb37-30">    masks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>], </span>
<span id="cb37-31">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb37-32">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors</span>
<span id="cb37-33">)</span>
<span id="cb37-34"></span>
<span id="cb37-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb37-36">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb37-37">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>annotated_tensor, </span>
<span id="cb37-38">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb37-39">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb37-40">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb37-41">)</span>
<span id="cb37-42"></span>
<span id="cb37-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the annotated image</span></span>
<span id="cb37-44">display(tensor_to_pil(annotated_tensor))</span>
<span id="cb37-45"></span>
<span id="cb37-46">pd.Series({</span>
<span id="cb37-47">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image:"</span>: sample_img.size,</span>
<span id="cb37-48">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cropped Image:"</span>: cropped_img.size,</span>
<span id="cb37-49">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Image:"</span>: resized_img.size,</span>
<span id="cb37-50">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Padded Image:"</span>: padded_img.size,</span>
<span id="cb37-51">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Padded Image:"</span>: resized_padded_img.size,</span>
<span id="cb37-52">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/segmentation-polygons/images/output_62_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_86ef5">
<thead>
</thead>
<tbody>
<tr>
<th id="T_86ef5_level0_row0" class="row_heading level0 row0">
Source Image:
</th>
<td id="T_86ef5_row0_col0" class="data row0 col0">
(768, 1152)
</td>
</tr>
<tr>
<th id="T_86ef5_level0_row1" class="row_heading level0 row1">
Cropped Image:
</th>
<td id="T_86ef5_row1_col0" class="data row1 col0">
(382, 665)
</td>
</tr>
<tr>
<th id="T_86ef5_level0_row2" class="row_heading level0 row2">
Resized Image:
</th>
<td id="T_86ef5_row2_col0" class="data row2 col0">
(220, 382)
</td>
</tr>
<tr>
<th id="T_86ef5_level0_row3" class="row_heading level0 row3">
Padded Image:
</th>
<td id="T_86ef5_row3_col0" class="data row3 col0">
(382, 382)
</td>
</tr>
<tr>
<th id="T_86ef5_level0_row4" class="row_heading level0 row4">
Resized Padded Image:
</th>
<td id="T_86ef5_row4_col0" class="data row4 col0">
(384, 384)
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Now that we know how to apply data augmentations, we can put all the steps we’ve covered into a custom Dataset class.</p>
</section>
</section>
<section id="training-dataset-class" class="level3">
<h3 class="anchored" data-anchor-id="training-dataset-class">Training Dataset Class</h3>
<p>The following custom Dataset class is responsible for loading a single image, preparing the associated annotations, applying any image transforms, and returning the final <code>image</code> tensor and its <code>target</code> dictionary during training.</p>
<div class="sourceCode" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> COCOInstSegDataset(Dataset):</span>
<span id="cb38-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb38-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A PyTorch Dataset class for COCO-style instance segmentation.</span></span>
<span id="cb38-4"></span>
<span id="cb38-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This class is designed to handle datasets for instance segmentation tasks, specifically</span></span>
<span id="cb38-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    formatted in the style of COCO (Common Objects in Context) annotations. It supports</span></span>
<span id="cb38-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    loading images along with their corresponding segmentation masks and bounding boxes.</span></span>
<span id="cb38-8"></span>
<span id="cb38-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Attributes:</span></span>
<span id="cb38-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    _img_keys : list</span></span>
<span id="cb38-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        List of image keys (identifiers).</span></span>
<span id="cb38-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    _annotation_df : pandas.DataFrame</span></span>
<span id="cb38-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        DataFrame containing annotations for images.</span></span>
<span id="cb38-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    _img_dict : dict</span></span>
<span id="cb38-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Dictionary mapping image keys to their file paths.</span></span>
<span id="cb38-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    _class_to_idx : dict</span></span>
<span id="cb38-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Dictionary mapping class names to class indices.</span></span>
<span id="cb38-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    _transforms : torchvision.transforms (optional)</span></span>
<span id="cb38-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Transformations to be applied to the images and targets.</span></span>
<span id="cb38-20"></span>
<span id="cb38-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Methods:</span></span>
<span id="cb38-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    __init__(self, img_keys, annotation_df, img_dict, class_to_idx, transforms=None):</span></span>
<span id="cb38-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Initializes the dataset with image keys, annotations, image dictionary,</span></span>
<span id="cb38-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        class mappings, and optional transforms.</span></span>
<span id="cb38-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    __len__(self):</span></span>
<span id="cb38-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns the total number of items in the dataset.</span></span>
<span id="cb38-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    __getitem__(self, index):</span></span>
<span id="cb38-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Retrieves an image and its corresponding target (masks, boxes, labels) by index.</span></span>
<span id="cb38-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    _load_image_and_target(self, annotation):</span></span>
<span id="cb38-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Loads an image and its corresponding target data based on the providedannotation.</span></span>
<span id="cb38-31"></span>
<span id="cb38-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb38-33"></span>
<span id="cb38-34">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, img_keys, annotation_df, img_dict, class_to_idx, transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb38-35">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb38-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Initializes the COCOInstSegDataset instance.</span></span>
<span id="cb38-37"></span>
<span id="cb38-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb38-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_keys (list): List of image keys.</span></span>
<span id="cb38-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation_df (DataFrame): DataFrame containing image annotations.</span></span>
<span id="cb38-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_dict (dict): Dictionary mapping image keys to file paths.</span></span>
<span id="cb38-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            class_to_idx (dict): Dictionary mapping class names to indices.</span></span>
<span id="cb38-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            transforms (callable, optional): Optional transform to be applied on a sample.</span></span>
<span id="cb38-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb38-45">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Dataset, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb38-46">        </span>
<span id="cb38-47">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># List of image keys</span></span>
<span id="cb38-48">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># DataFrame containing annotations</span></span>
<span id="cb38-49">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_dict  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dictionary mapping image keys to image paths</span></span>
<span id="cb38-50">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> class_to_idx  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dictionary mapping class names to class indices</span></span>
<span id="cb38-51">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Image transforms to be applied</span></span>
<span id="cb38-52"></span>
<span id="cb38-53">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__len__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb38-54">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Returns the number of items in the dataset</span></span>
<span id="cb38-55">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys)</span>
<span id="cb38-56">        </span>
<span id="cb38-57">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, index):</span>
<span id="cb38-58">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Retrieves an image and its corresponding target by index</span></span>
<span id="cb38-59">        img_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys[index]</span>
<span id="cb38-60">        annotation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df.loc[img_key]</span>
<span id="cb38-61">        image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._load_image_and_target(annotation)</span>
<span id="cb38-62">        </span>
<span id="cb38-63">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply transformations if any</span></span>
<span id="cb38-64">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms:</span>
<span id="cb38-65">            image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms(image, target)</span>
<span id="cb38-66">        </span>
<span id="cb38-67">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, target</span>
<span id="cb38-68"></span>
<span id="cb38-69">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _load_image_and_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, annotation):</span>
<span id="cb38-70">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Loads an image and its corresponding target data (masks, boxes, labels)</span></span>
<span id="cb38-71">        filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict[annotation.name]</span>
<span id="cb38-72">        image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(filepath).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb38-73"></span>
<span id="cb38-74">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Process segmentation polygons</span></span>
<span id="cb38-75">        polygon_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'segmentation'</span>]</span>
<span id="cb38-76">        mask_imgs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [create_polygon_mask(image.size, polygon[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> polygon <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> polygon_points]</span>
<span id="cb38-77">        masks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Mask(torch.concat([Mask(transforms.PILToTensor()(mask_img), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> mask_img <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> mask_imgs]))</span>
<span id="cb38-78">        </span>
<span id="cb38-79">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert bounding boxes to tensor format</span></span>
<span id="cb38-80">        bbox_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bboxes'</span>]</span>
<span id="cb38-81">        bbox_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torchvision.ops.box_convert(torch.Tensor(bbox_list), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>)</span>
<span id="cb38-82">        boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(bbox_tensor, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb38-83">        </span>
<span id="cb38-84">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Map labels to their corresponding indices</span></span>
<span id="cb38-85">        annotation_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]</span>
<span id="cb38-86">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.Tensor([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx[label] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_labels])</span>
<span id="cb38-87">        </span>
<span id="cb38-88">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>: masks, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: boxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: labels}</span></code></pre></div>
</section>
<section id="image-transforms" class="level3">
<h3 class="anchored" data-anchor-id="image-transforms">Image Transforms</h3>
<p>Here, we will specify and organize all the image transforms to apply during training.</p>
<div class="sourceCode" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms for data augmentation</span></span>
<span id="cb39-2">data_aug_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose(</span>
<span id="cb39-3">    transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb39-4">        iou_crop,</span>
<span id="cb39-5">        transforms.ColorJitter(</span>
<span id="cb39-6">                brightness <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.875</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.125</span>),</span>
<span id="cb39-7">                contrast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb39-8">                saturation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb39-9">                hue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>),</span>
<span id="cb39-10">        ),</span>
<span id="cb39-11">        transforms.RandomGrayscale(),</span>
<span id="cb39-12">        transforms.RandomEqualize(),</span>
<span id="cb39-13">        transforms.RandomPosterize(bits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb39-14">        transforms.RandomHorizontalFlip(p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb39-15">    ],</span>
<span id="cb39-16">)</span>
<span id="cb39-17"></span>
<span id="cb39-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to resize and pad input images</span></span>
<span id="cb39-19">resize_pad_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb39-20">    resize_max, </span>
<span id="cb39-21">    pad_square,</span>
<span id="cb39-22">    transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb39-23">])</span>
<span id="cb39-24"></span>
<span id="cb39-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to sanitize bounding boxes and normalize input data</span></span>
<span id="cb39-26">final_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb39-27">    transforms.ToImage(), </span>
<span id="cb39-28">    transforms.ToDtype(torch.float32, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb39-29">    transforms.SanitizeBoundingBoxes(),</span>
<span id="cb39-30">])</span>
<span id="cb39-31"></span>
<span id="cb39-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the transformations for training and validation datasets</span></span>
<span id="cb39-33">train_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb39-34">    data_aug_tfms, </span>
<span id="cb39-35">    resize_pad_tfm, </span>
<span id="cb39-36">    final_tfms</span>
<span id="cb39-37">])</span></code></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always use the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.SanitizeBoundingBoxes.html#torchvision.transforms.v2.SanitizeBoundingBoxes"><code>SanitizeBoundingBoxes</code></a> transform to clean up annotations after using data augmentations that alter bounding boxes (e.g., cropping, warping, etc.).</p>
</div>
</div>
</section>
<section id="initialize-dataset" class="level3">
<h3 class="anchored" data-anchor-id="initialize-dataset">Initialize Dataset</h3>
<p>Now, we can create the dataset object using the image dictionary, the annotation DataFrame, and the image transforms.</p>
<div class="sourceCode" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mapping from class names to class indices</span></span>
<span id="cb40-2">class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {c: i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(class_names)}</span>
<span id="cb40-3"></span>
<span id="cb40-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Instantiate the dataset using the defined transformations</span></span>
<span id="cb40-5">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> COCOInstSegDataset(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys()), annotation_df, img_dict, class_to_idx, train_tfms)</span>
<span id="cb40-6"></span>
<span id="cb40-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of samples in the training dataset</span></span>
<span id="cb40-8">pd.Series({</span>
<span id="cb40-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training dataset size:'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataset),</span>
<span id="cb40-10">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_7b3e4">
<thead>
</thead>
<tbody>
<tr>
<th id="T_7b3e4_level0_row0" class="row_heading level0 row0">
Training dataset size:
</th>
<td id="T_7b3e4_row0_col0" class="data row0 col0">
31
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspect-samples" class="level3">
<h3 class="anchored" data-anchor-id="inspect-samples">Inspect Samples</h3>
<p>To close out, we should verify the dataset object works as intended by inspecting the first sample.</p>
<section id="inspect-training-set-sample" class="level4">
<h4 class="anchored" data-anchor-id="inspect-training-set-sample">Inspect training set sample</h4>
<div class="sourceCode" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">dataset_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_dataset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb41-2"></span>
<span id="cb41-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get colors for dataset sample</span></span>
<span id="cb41-4">sample_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb41-5"></span>
<span id="cb41-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with segmentation masks</span></span>
<span id="cb41-7">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_segmentation_masks( </span>
<span id="cb41-8">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.uint8), </span>
<span id="cb41-9">    masks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'masks'</span>], </span>
<span id="cb41-10">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb41-11">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors</span>
<span id="cb41-12">)</span>
<span id="cb41-13"></span>
<span id="cb41-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with bounding boxes</span></span>
<span id="cb41-15">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb41-16">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>annotated_tensor, </span>
<span id="cb41-17">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb41-18">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb41-19">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_colors</span>
<span id="cb41-20">)</span>
<span id="cb41-21"></span>
<span id="cb41-22">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/segmentation-polygons/images/output_71_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we covered how to load custom COCO segmentation annotations and work with them using torchvision’s Transforms V2 API. The skills and knowledge you acquired here provide a solid foundation for future instance segmentation projects.</p>
<p>As a next step, perhaps try annotating a custom COCO segmentation dataset with a tool like <a href="https://github.com/opencv/cvat">CVAT</a> and loading it with this tutorial’s code. Once you’re comfortable with that, try adapting the code in the following tutorial to train an instance segmentation model on your custom dataset.</p>
<ul>
<li><a href="../../../posts/pytorch-train-mask-rcnn-tutorial/">Training Mask R-CNN Models with PyTorch</a></li>
</ul>
</section>
<section id="recommended-tutorials" class="level2">
<h2 class="anchored" data-anchor-id="recommended-tutorials">Recommended Tutorials</h2>
<ul>
<li><a href="../../../posts/torchvision-coco-annotation-tutorials/bounding-boxes/"><strong>Working with COCO Bounding Box Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with COCO bounding box annotations in torchvision for object detection tasks.</li>
<li><a href="../../../posts/pytorch-train-mask-rcnn-tutorial/"><strong>Training Mask R-CNN Models with PyTorch</strong></a><strong>:</strong> Learn how to train Mask R-CNN models on custom datasets with PyTorch.</li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>image-annotation</category>
  <category>instance-segmentation</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/torchvision-coco-annotation-tutorials/segmentation-polygons/</guid>
  <pubDate>Sun, 21 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Working with COCO Bounding Box Annotations in Torchvision</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/torchvision-coco-annotation-tutorials/bounding-boxes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/tutorials/torchvision-annotation-tutorials-series.html"><strong>Torchvision Annotation Tutorials</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Getting Started with the Code</li>
<li>Setting Up Your Python Environment</li>
<li>Importing the Required Dependencies</li>
<li>Loading and Exploring the Dataset</li>
<li>Preparing the Data</li>
<li>Conclusion</li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to this hands-on guide for working with <a href="https://cocodataset.org/#format-data">COCO-formatted</a> bounding box annotations in <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>. Bounding box annotations specify rectangular frames around objects in images to identify and locate them for training object detection models.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/bounding-boxes/images/bounding-box-hero-img.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>The tutorial walks through setting up a Python environment, loading the raw annotations into a <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Pandas DataFrame</a>, annotating and augmenting images using torchvision’s <a href="https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py">Transforms V2 API</a>, and creating a custom <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Dataset</a> class to feed samples to a model.</p>
<p>This guide is suitable for beginners and experienced practitioners, providing the code, explanations, and resources needed to understand and implement each step. By the end, you will have a solid foundation for working with COCO bounding box annotations in torchvision for object detection tasks.</p>
</section>
<section id="getting-started-with-the-code" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h2>
<p>The tutorial code is available as a <a href="https://jupyter.org/">Jupyter Notebook</a>, which you can run locally or in a cloud-based environment like <a href="https://colab.research.google.com/">Google Colab</a>. I have dedicated tutorials for those new to these platforms or who need guidance setting up:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Setup Guides">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Setup Guides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="../../../posts/google-colab-getting-started-tutorial/"><strong>Getting Started with Google Colab</strong></a></p></li>
<li><p><a href="../../../posts/mamba-getting-started-tutorial-windows/"><strong>Setting Up a Local Python Environment with Mamba for Machine Learning Projects on Windows</strong></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Tutorial Code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tutorial Code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook:</th>
<th><a href="https://github.com/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/coco/torchvision-coco-bounding-box-annotations.ipynb">GitHub Repository</a></th>
<th><a href="https://colab.research.google.com/github/cj-mills/torchvision-annotation-tutorials/blob/main/notebooks/coco/torchvision-coco-bounding-box-annotations.ipynb">Open In Colab</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="setting-up-your-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-python-environment">Setting Up Your Python Environment</h2>
<p>Before diving into the code, we’ll cover the steps to create a local Python environment and install the necessary dependencies.</p>
<section id="creating-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-python-environment">Creating a Python Environment</h3>
<p>First, we’ll create a Python environment using <a href="https://docs.conda.io/en/latest/">Conda</a>/<a href="https://mamba.readthedocs.io/en/latest/">Mamba</a>. Open a terminal with Conda/Mamba installed and run the following commands:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">Conda</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Mamba</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conda</span> activate pytorch-env</span></code></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new Python 3.10 environment</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> pytorch-env python=3.10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Activate the environment</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate pytorch-env</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="installing-pytorch">Installing PyTorch</h3>
<p>Next, we’ll install <a href="https://pytorch.org/">PyTorch</a>. Run the appropriate command for your hardware and operating system.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">Linux/Windows (CUDA)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Mac</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Linux (CPU)</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Windows (CPU)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch with CUDA</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cu121</span></code></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MPS (Metal Performance Shaders) acceleration is available on MacOS 12.3+</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--index-url</span> https://download.pytorch.org/whl/cpu</span></code></pre></div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install PyTorch for CPU only</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch torchvision torchaudio</span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="installing-additional-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-libraries">Installing Additional Libraries</h3>
<p>We also need to install some additional libraries for our project.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>jupyter</code></td>
<td>An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. (<a href="https://jupyter.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>matplotlib</code></td>
<td>This package provides a comprehensive collection of visualization tools to create high-quality plots, charts, and graphs for data exploration and presentation. (<a href="https://matplotlib.org/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>pandas</code></td>
<td>This package provides fast, powerful, and flexible data analysis and manipulation tools. (<a href="https://pandas.pydata.org/">link</a>)</td>
</tr>
<tr class="even">
<td><code>pillow</code></td>
<td>The Python Imaging Library adds image processing capabilities. (<a href="https://pillow.readthedocs.io/en/stable/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>tqdm</code></td>
<td>A Python library that provides fast, extensible progress bars for loops and other iterable objects in Python. (<a href="https://tqdm.github.io/">link</a>)</td>
</tr>
<tr class="even">
<td><code>distinctipy</code></td>
<td>A lightweight python package providing functions to generate colours that are visually distinct from one another. (<a href="https://distinctipy.readthedocs.io/en/latest/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install these additional libraries:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional dependencies</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install distinctipy jupyter matplotlib pandas pillow tqdm</span></code></pre></div>
</section>
<section id="installing-utility-packages" class="level3">
<h3 class="anchored" data-anchor-id="installing-utility-packages">Installing Utility Packages</h3>
<p>We will also install some utility packages I made, which provide shortcuts for routine tasks.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Package Descriptions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Package Descriptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="table">
<thead>
<tr class="header">
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>cjm_pil_utils</code></td>
<td>Some PIL utility functions I frequently use. (<a href="https://cj-mills.github.io/cjm-pil-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_psl_utils</code></td>
<td>Some utility functions using the Python Standard Library. (<a href="https://cj-mills.github.io/cjm-psl-utils/">link</a>)</td>
</tr>
<tr class="odd">
<td><code>cjm_pytorch_utils</code></td>
<td>Some utility functions for working with PyTorch. (<a href="https://cj-mills.github.io/cjm-pytorch-utils/">link</a>)</td>
</tr>
<tr class="even">
<td><code>cjm_torchvision_tfms</code></td>
<td>Some custom Torchvision tranforms. (<a href="https://cj-mills.github.io/cjm-torchvision-tfms/">link</a>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Run the following commands to install the utility packages:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install additional utility packages</span></span>
<span id="cb8-2">pip install cjm_pil_utils cjm_psl_utils cjm_pytorch_utils cjm_torchvision_tfms</span></code></pre></div>
<p>With our environment set up, we can open our Jupyter Notebook and dive into the code.</p>
</section>
</section>
<section id="importing-the-required-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python packages into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import Python Standard Library dependencies</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb9-4"></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb9-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pil_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_img_files</span>
<span id="cb9-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_psl_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> download_file, file_extract</span>
<span id="cb9-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_pytorch_utils.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor_to_pil</span>
<span id="cb9-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> cjm_torchvision_tfms.core <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ResizeMax, PadSquare, CustomRandomIoUCrop</span>
<span id="cb9-10"></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the distinctipy module</span></span>
<span id="cb9-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distinctipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> distinctipy</span>
<span id="cb9-13"></span>
<span id="cb9-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import matplotlib for creating plots</span></span>
<span id="cb9-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb9-16"></span>
<span id="cb9-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import numpy</span></span>
<span id="cb9-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-19"></span>
<span id="cb9-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb9-21"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb9-22"></span>
<span id="cb9-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb9-24">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb9-25"></span>
<span id="cb9-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PIL for image manipulation</span></span>
<span id="cb9-27"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image</span>
<span id="cb9-28"></span>
<span id="cb9-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import PyTorch dependencies</span></span>
<span id="cb9-30"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb9-31"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DataLoader</span>
<span id="cb9-32"></span>
<span id="cb9-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import torchvision dependencies</span></span>
<span id="cb9-34"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision</span>
<span id="cb9-35">torchvision.disable_beta_transforms_warning()</span>
<span id="cb9-36"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.tv_tensors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BoundingBoxes</span>
<span id="cb9-37"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> draw_bounding_boxes</span>
<span id="cb9-38"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.v2  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb9-39"></span>
<span id="cb9-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import tqdm for progress bar</span></span>
<span id="cb9-41"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm.auto <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
<p>Torchvision provides dedicated <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> subclasses for different annotation types called <a href="https://pytorch.org/vision/stable/tv_tensors.html"><code>TVTensors</code></a>. Torchvision’s V2 transforms use these subclasses to update the annotations based on the applied image augmentations. The TVTensor class for bounding box annotations is called <a href="https://pytorch.org/vision/stable/generated/torchvision.tv_tensors.BoundingBoxes.html"><code>BoundingBoxes</code></a>. Torchvision also includes a <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function to annotate images.</p>
</section>
<section id="loading-and-exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-and-exploring-the-dataset">Loading and Exploring the Dataset</h2>
<p>After importing the dependencies, we can start working with our data. I annotated a toy dataset with bounding boxes for this tutorial using images from the free stock photo site <a href="https://www.pexels.com/">Pexels</a>. The dataset is available on <a href="https://huggingface.co/">HuggingFace Hub</a> at the link below:</p>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/datasets/cj-mills/coco-bounding-box-toy-dataset/tree/main">coco-bounding-box-toy-dataset</a></li>
</ul>
<section id="setting-the-directory-paths" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-directory-paths">Setting the Directory Paths</h3>
<p>We first need to specify a place to store our dataset and a location to download the zip file containing it. The following code creates the folders in the current directory (<code>./</code>). Update the path if that is not suitable for you.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store datasets</span></span>
<span id="cb10-2">dataset_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./Datasets/"</span>)</span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the dataset directory if it does not exist</span></span>
<span id="cb10-4">dataset_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define path to store archive files</span></span>
<span id="cb10-7">archive_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'../Archive'</span></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the archive directory if it does not exist</span></span>
<span id="cb10-9">archive_dir.mkdir(parents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb10-12">pd.Series({</span>
<span id="cb10-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Directory:"</span>: dataset_dir, </span>
<span id="cb10-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Directory:"</span>: archive_dir</span>
<span id="cb10-15">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_5502a">
<thead>
</thead>
<tbody>
<tr>
<th id="T_5502a_level0_row0" class="row_heading level0 row0">
Dataset Directory:
</th>
<td id="T_5502a_row0_col0" class="data row0 col0">
Datasets
</td>
</tr>
<tr>
<th id="T_5502a_level0_row1" class="row_heading level0 row1">
Archive Directory:
</th>
<td id="T_5502a_row1_col0" class="data row1 col0">
Datasets/../Archive
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="setting-the-dataset-path" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-dataset-path">Setting the Dataset Path</h3>
<p>Next, we construct the name for the Hugging Face Hub dataset and set where to download and extract the dataset.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the dataset</span></span>
<span id="cb11-2">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coco-bounding-box-toy-dataset'</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb11-5">hf_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'cj-mills/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb11-8">archive_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>archive_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip'</span>)</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb11-11">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_dir<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the dataset name and paths and converting it to a DataFrame for display</span></span>
<span id="cb11-14">pd.Series({</span>
<span id="cb11-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb11-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Archive Path:"</span>: archive_path, </span>
<span id="cb11-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset Path:"</span>: dataset_path</span>
<span id="cb11-18">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_6f643">
<thead>
</thead>
<tbody>
<tr>
<th id="T_6f643_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_6f643_row0_col0" class="data row0 col0">
cj-mills/coco-bounding-box-toy-dataset
</td>
</tr>
<tr>
<th id="T_6f643_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_6f643_row1_col0" class="data row1 col0">
Datasets/../Archive/coco-bounding-box-toy-dataset.zip
</td>
</tr>
<tr>
<th id="T_6f643_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_6f643_row2_col0" class="data row2 col0">
Datasets/coco-bounding-box-toy-dataset
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="downloading-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h3>
<p>We can now download the archive file and extract the dataset using the <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#download_file"><code>download_file</code></a> and <a href="https://cj-mills.github.io/cjm-psl-utils/core.html#file_extract"><code>file_extract</code></a> functions from the <code>cjm_psl_utils</code> package. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb12-2">dataset_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://huggingface.co/datasets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>hf_dataset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/resolve/main/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.zip"</span></span>
<span id="cb12-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"HuggingFace Dataset URL: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb12-6">delete_archive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the dataset if not present</span></span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset_path.is_dir():</span>
<span id="cb12-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dataset folder already exists"</span>)</span>
<span id="cb12-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb12-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Downloading dataset..."</span>)</span>
<span id="cb12-13">    download_file(dataset_url, archive_dir)    </span>
<span id="cb12-14">    </span>
<span id="cb12-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extracting dataset..."</span>)</span>
<span id="cb12-16">    file_extract(fname<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>archive_path, dest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_dir)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete the archive if specified</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> delete_archive: archive_path.unlink()</span></code></pre></div>
</section>
<section id="getting-the-image-and-annotation-folders" class="level3">
<h3 class="anchored" data-anchor-id="getting-the-image-and-annotation-folders">Getting the Image and Annotation Folders</h3>
<p>The dataset has two folders containing the sample images and annotations. The image folder organizes all samples together. The annotations are in a single JSON file.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming the images are stored in a subfolder named 'images'</span></span>
<span id="cb13-2">img_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'images/'</span></span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming the annotation file is in JSON format and located in a subdirectory of the dataset</span></span>
<span id="cb13-5">annotation_file_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(dataset_path.glob(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'*/*.json'</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a Series with the paths and converting it to a DataFrame for display</span></span>
<span id="cb13-8">pd.Series({</span>
<span id="cb13-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Image Folder"</span>: img_dir, </span>
<span id="cb13-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annotation File"</span>: annotation_file_path}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_3ae81">
<thead>
</thead>
<tbody>
<tr>
<th id="T_3ae81_level0_row0" class="row_heading level0 row0">
Image Folder
</th>
<td id="T_3ae81_row0_col0" class="data row0 col0">
Datasets/coco-bounding-box-toy-dataset/images
</td>
</tr>
<tr>
<th id="T_3ae81_level0_row1" class="row_heading level0 row1">
Annotation File
</th>
<td id="T_3ae81_row1_col0" class="data row1 col0">
Datasets/coco-bounding-box-toy-dataset/annotations/instances_default.json
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-file-paths" class="level3">
<h3 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h3>
<p>Each image file has a unique name that we can use to locate the corresponding annotation data. We can make a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image more efficiently.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get all image files in the 'img_dir' directory</span></span>
<span id="cb14-2">img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb14-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.stem : <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dictionary that maps file names to file paths</span></span>
<span id="cb14-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> get_img_files(img_dir) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of image files in the image directory</span></span>
<span id="cb14-5">}</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of image files</span></span>
<span id="cb14-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Number of Images: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(img_dict)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb14-9"></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb14-11">pd.DataFrame.from_dict(img_dict, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).head()</span></code></pre></div>
<pre class="text"><code>Number of Images: 28</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
Datasets/coco-bounding-box-toy-dataset/images/258421.jpg
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
Datasets/coco-bounding-box-toy-dataset/images/3075367.jpg
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
Datasets/coco-bounding-box-toy-dataset/images/3076319.jpg
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
Datasets/coco-bounding-box-toy-dataset/images/3145551.jpg
</td>
</tr>
<tr>
<th>
3176048
</th>
<td>
Datasets/coco-bounding-box-toy-dataset/images/3176048.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="get-image-annotations">Get Image Annotations</h3>
<p>Next, we read the content of the JSON annotation file into a Pandas DataFrame so we can easily query the annotations.</p>
<section id="load-the-annotation-file-into-a-dataframe" class="level4">
<h4 class="anchored" data-anchor-id="load-the-annotation-file-into-a-dataframe">Load the annotation file into a DataFrame</h4>
<p>We will transpose the DataFrame to store each section in the JSON file in a separate column.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Read the JSON file into a DataFrame, assuming the JSON is oriented by index</span></span>
<span id="cb16-2">annotation_file_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_json(annotation_file_path, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>).transpose()</span>
<span id="cb16-3">annotation_file_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
licenses
</th>
<th>
info
</th>
<th>
categories
</th>
<th>
images
</th>
<th>
annotations
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
{‘name’: ’‘, ’id’: 0, ‘url’: ’’}
</td>
<td>
contributor
</td>
<td>
{‘id’: 1, ‘name’: ‘person’, ‘supercategory’: ’’}
</td>
<td>
{‘id’: 1, ‘width’: 768, ‘height’: 1152, ‘file_name’: ‘258421.jpg’, ‘license’: 0, ‘flickr_url’: ’‘, ’coco_url’: ’‘, ’date_captured’: 0}
</td>
<td>
{‘id’: 1, ‘image_id’: 1, ‘category_id’: 1, ‘segmentation’: [], ‘area’: 24904.862800000003, ‘bbox’: [386.08, 443.94, 74.74, 333.22], ‘iscrowd’: 0, ‘attributes’: {‘occluded’: False, ‘rotation’: 0.0}}
</td>
</tr>
<tr>
<th>
1
</th>
<td>
None
</td>
<td>
date_created
</td>
<td>
None
</td>
<td>
{‘id’: 2, ‘width’: 1344, ‘height’: 768, ‘file_name’: ‘3075367.jpg’, ‘license’: 0, ‘flickr_url’: ’‘, ’coco_url’: ’‘, ’date_captured’: 0}
</td>
<td>
{‘id’: 2, ‘image_id’: 1, ‘category_id’: 1, ‘segmentation’: [], ‘area’: 24440.896000000004, ‘bbox’: [340.25, 466.94, 78.74, 310.4], ‘iscrowd’: 0, ‘attributes’: {‘occluded’: False, ‘rotation’: 0.0}}
</td>
</tr>
<tr>
<th>
2
</th>
<td>
None
</td>
<td>
description
</td>
<td>
None
</td>
<td>
{‘id’: 3, ‘width’: 768, ‘height’: 1120, ‘file_name’: ‘3076319.jpg’, ‘license’: 0, ‘flickr_url’: ’‘, ’coco_url’: ’‘, ’date_captured’: 0}
</td>
<td>
{‘id’: 3, ‘image_id’: 2, ‘category_id’: 1, ‘segmentation’: [], ‘area’: 365660.4554999999, ‘bbox’: [413.32, 41.22, 506.49, 721.95], ‘iscrowd’: 0, ‘attributes’: {‘occluded’: False, ‘rotation’: 0.0}}
</td>
</tr>
<tr>
<th>
3
</th>
<td>
None
</td>
<td>
url
</td>
<td>
None
</td>
<td>
{‘id’: 4, ‘width’: 1184, ‘height’: 768, ‘file_name’: ‘3145551.jpg’, ‘license’: 0, ‘flickr_url’: ’‘, ’coco_url’: ’‘, ’date_captured’: 0}
</td>
<td>
{‘id’: 4, ‘image_id’: 3, ‘category_id’: 1, ‘segmentation’: [], ‘area’: 363031.32340000005, ‘bbox’: [335.31, 151.75, 375.91, 965.74], ‘iscrowd’: 0, ‘attributes’: {‘occluded’: False, ‘rotation’: 0.0}}
</td>
</tr>
<tr>
<th>
4
</th>
<td>
None
</td>
<td>
version
</td>
<td>
None
</td>
<td>
{‘id’: 5, ‘width’: 1152, ‘height’: 768, ‘file_name’: ‘3176048.jpg’, ‘license’: 0, ‘flickr_url’: ’‘, ’coco_url’: ’‘, ’date_captured’: 0}
</td>
<td>
{‘id’: 5, ‘image_id’: 3, ‘category_id’: 1, ‘segmentation’: [], ‘area’: 390988.36079999997, ‘bbox’: [8.11, 131.88, 396.09, 987.12], ‘iscrowd’: 0, ‘attributes’: {‘occluded’: False, ‘rotation’: 0.0}}
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Let’s examine the source JSON content corresponding to the first row in the DataFrame.</p>
<div style="overflow-x:auto; max-height:500px">
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb17-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"licenses"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-3">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-4">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-5">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-6">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"url"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb17-7">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-8">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-9">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"info"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-10">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"contributor"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-11">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"date_created"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-12">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-13">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"url"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-14">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"version"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-15">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"year"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb17-16">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb17-17">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"categories"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-18">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-19">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-20">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-21">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"supercategory"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb17-22">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-23">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-24">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"images"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-25">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-26">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-27">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"width"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">768</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-28">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"height"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1152</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-29">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"file_name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"258421.jpg"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-30">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"license"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-31">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"flickr_url"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-32">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"coco_url"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-33">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"date_captured"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb17-34">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-35">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-36">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"annotations"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-37">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-38">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-39">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"image_id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-40">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"category_id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-41">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"segmentation"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-42">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"area"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">24904.862800000003</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-43">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"bbox"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-44">                <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">386.08</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-45">                <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">443.94</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-46">                <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">74.74</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-47">                <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">333.22</span></span>
<span id="cb17-48">            <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-49">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"iscrowd"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-50">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"attributes"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-51">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"occluded"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-52">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"rotation"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">.</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb17-53">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-54">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-55">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb17-56"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
<hr>
<p>The most relevant information for our purposes is in the following sections:</p>
<ul>
<li><code>categories</code>: Stores the class names for the various object types in the dataset. Note that this toy dataset only has one object type.</li>
<li><code>images</code>: Stores the dimensions and file names for each image.</li>
<li><code>annotations</code>: Stores the image IDs, category IDs, and the bounding box annotations in <code>[Top-Left X, Top-Left Y, Width, Height]</code> format.</li>
</ul>
</section>
<section id="extract-the-object-classes" class="level4">
<h4 class="anchored" data-anchor-id="extract-the-object-classes">Extract the object classes</h4>
<p>We first need to extract the class names from the <code>categories</code> column of the DataFrame.</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract and transform the 'categories' section of the data</span></span>
<span id="cb18-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This DataFrame contains category details like category ID and name</span></span>
<span id="cb18-3">categories_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_file_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'categories'</span>].dropna().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)</span>
<span id="cb18-4">categories_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb18-5">categories_df</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
name
</th>
<th>
supercategory
</th>
</tr>
<tr>
<th>
id
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
person
</td>
<td>
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>This toy dataset only contains a single object class, named <code>person</code>.</p>
</section>
<section id="extract-the-image-information" class="level4">
<h4 class="anchored" data-anchor-id="extract-the-image-information">Extract the image information</h4>
<p>Next, we will extract the file names, image dimensions, and Image IDs from the <code>images</code> column of the DataFrame.</p>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract and transform the 'images' section of the data</span></span>
<span id="cb19-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This DataFrame contains image details like file name, height, width, and image ID</span></span>
<span id="cb19-3">images_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_file_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'images'</span>].to_frame()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'images'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'file_name'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'height'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'width'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>]]</span>
<span id="cb19-4">images_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
file_name
</th>
<th>
height
</th>
<th>
width
</th>
<th>
id
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
<td>
2.0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3076319.jpg
</td>
<td>
1120.0
</td>
<td>
768.0
</td>
<td>
3.0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3145551.jpg
</td>
<td>
768.0
</td>
<td>
1184.0
</td>
<td>
4.0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
3176048.jpg
</td>
<td>
768.0
</td>
<td>
1152.0
</td>
<td>
5.0
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="extract-the-annotation-information" class="level4">
<h4 class="anchored" data-anchor-id="extract-the-annotation-information">Extract the annotation information</h4>
<p>Last, we must extract the Image IDs, bounding box annotations, and Category IDs from the <code>annotations</code> column in the DataFrame.</p>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract and transform the 'annotations' section of the data</span></span>
<span id="cb20-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This DataFrame contains annotation details like image ID, bounding box, and category ID</span></span>
<span id="cb20-3">annotations_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_file_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'annotations'</span>].to_frame()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'annotations'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(pd.Series)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image_id'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bbox'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'category_id'</span>]]</span>
<span id="cb20-4">annotations_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
image_id
</th>
<th>
bbox
</th>
<th>
category_id
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
[386.08, 443.94, 74.74, 333.22]
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
[340.25, 466.94, 78.74, 310.4]
</td>
<td>
1
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
[413.32, 41.22, 506.49, 721.95]
</td>
<td>
1
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
[335.31, 151.75, 375.91, 965.74]
</td>
<td>
1
</td>
</tr>
<tr>
<th>
4
</th>
<td>
3
</td>
<td>
[8.11, 131.88, 396.09, 987.12]
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Now that we have extracted the relevant information from the JSON file, we can recombine it into a single DataFrame for convenience.</p>
</section>
<section id="add-the-class-names-to-the-annotations" class="level4">
<h4 class="anchored" data-anchor-id="add-the-class-names-to-the-annotations">Add the class names to the annotations</h4>
<p>We will first add a new <code>label</code> column to the <code>annotations_df</code> DataFrame containing the corresponding class name from the <code>categories_df</code> DataFrame for each bounding box annotation.</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Map 'category_id' in annotations DataFrame to category name using categories DataFrame</span></span>
<span id="cb21-2">annotations_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotations_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'category_id'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: categories_df.loc[x][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>])</span>
<span id="cb21-3">annotations_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
image_id
</th>
<th>
bbox
</th>
<th>
category_id
</th>
<th>
label
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
[386.08, 443.94, 74.74, 333.22]
</td>
<td>
1
</td>
<td>
person
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
[340.25, 466.94, 78.74, 310.4]
</td>
<td>
1
</td>
<td>
person
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
[413.32, 41.22, 506.49, 721.95]
</td>
<td>
1
</td>
<td>
person
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
[335.31, 151.75, 375.91, 965.74]
</td>
<td>
1
</td>
<td>
person
</td>
</tr>
<tr>
<th>
4
</th>
<td>
3
</td>
<td>
[8.11, 131.88, 396.09, 987.12]
</td>
<td>
1
</td>
<td>
person
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="merge-the-image-and-annotation-information" class="level4">
<h4 class="anchored" data-anchor-id="merge-the-image-and-annotation-information">Merge the image and annotation information</h4>
<p>Next, we will add the data from the <code>images_df</code> DataFrame and match it to the bounding box annotations using the Image IDs.</p>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Merge annotations DataFrame with images DataFrame on their image ID</span></span>
<span id="cb22-2">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.merge(annotations_df, images_df, left_on<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image_id'</span>, right_on<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>)</span>
<span id="cb22-3">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
image_id
</th>
<th>
bbox
</th>
<th>
category_id
</th>
<th>
label
</th>
<th>
file_name
</th>
<th>
height
</th>
<th>
width
</th>
<th>
id
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
[386.08, 443.94, 74.74, 333.22]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
[340.25, 466.94, 78.74, 310.4]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
[413.32, 41.22, 506.49, 721.95]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
<td>
2.0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
[335.31, 151.75, 375.91, 965.74]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3076319.jpg
</td>
<td>
1120.0
</td>
<td>
768.0
</td>
<td>
3.0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
3
</td>
<td>
[8.11, 131.88, 396.09, 987.12]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3076319.jpg
</td>
<td>
1120.0
</td>
<td>
768.0
</td>
<td>
3.0
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="use-the-image-name-as-the-index" class="level4">
<h4 class="anchored" data-anchor-id="use-the-image-name-as-the-index">Use the image name as the index</h4>
<p>Then, we will change the index for the <code>annotations_df</code> DataFrame to match the keys in the <code>img_dict</code> dictionary, allowing us to retrieve both the image paths and annotation data using the same index key.</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Remove old 'id' column post-merge</span></span>
<span id="cb23-2">annotation_df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb23-3"></span>
<span id="cb23-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the image_id from the file_name (assuming file_name contains the image_id)</span></span>
<span id="cb23-5">annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image_id'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'file_name'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: x.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb23-6"></span>
<span id="cb23-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set 'image_id' as the index for the DataFrame</span></span>
<span id="cb23-8">annotation_df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image_id'</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb23-9">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
bbox
</th>
<th>
category_id
</th>
<th>
label
</th>
<th>
file_name
</th>
<th>
height
</th>
<th>
width
</th>
</tr>
<tr>
<th>
image_id
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
[386.08, 443.94, 74.74, 333.22]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
</tr>
<tr>
<th>
258421
</th>
<td>
[340.25, 466.94, 78.74, 310.4]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
[413.32, 41.22, 506.49, 721.95]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
[335.31, 151.75, 375.91, 965.74]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3076319.jpg
</td>
<td>
1120.0
</td>
<td>
768.0
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
[8.11, 131.88, 396.09, 987.12]
</td>
<td>
1
</td>
<td>
person
</td>
<td>
3076319.jpg
</td>
<td>
1120.0
</td>
<td>
768.0
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="group-annotations-by-image" class="level4">
<h4 class="anchored" data-anchor-id="group-annotations-by-image">Group annotations by image</h4>
<p>Each bounding box annotation is currently in a separate row in the DataFrame. We will want to group the annotations for each image into a single row for use with PyTorch and torchvision.</p>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Group the data by 'image_id' and aggregate information</span></span>
<span id="cb24-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This results in each image ID having a list of bounding boxes, category IDs, labels, and the respective file name, height, and width</span></span>
<span id="cb24-3">annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'image_id'</span>).agg({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bbox'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>, </span>
<span id="cb24-4">                                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'category_id'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>,</span>
<span id="cb24-5">                                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span> :<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>,</span>
<span id="cb24-6">                                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'file_name'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'first'</span>, </span>
<span id="cb24-7">                                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'height'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'first'</span>, </span>
<span id="cb24-8">                                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'width'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'first'</span></span>
<span id="cb24-9">                                                      })</span>
<span id="cb24-10"></span>
<span id="cb24-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Rename columns for clarity </span></span>
<span id="cb24-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 'bbox' is renamed to 'bboxes' and 'label' to 'labels'</span></span>
<span id="cb24-13">annotation_df.rename(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bbox'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bboxes'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>}, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb24-14">annotation_df.head()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
bboxes
</th>
<th>
category_id
</th>
<th>
labels
</th>
<th>
file_name
</th>
<th>
height
</th>
<th>
width
</th>
</tr>
<tr>
<th>
image_id
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
258421
</th>
<td>
[[386.08, 443.94, 74.74, 333.22], [340.25, 466.94, 78.74, 310.4]]
</td>
<td>
[1, 1]
</td>
<td>
[person, person]
</td>
<td>
258421.jpg
</td>
<td>
1152.0
</td>
<td>
768.0
</td>
</tr>
<tr>
<th>
3075367
</th>
<td>
[[413.32, 41.22, 506.49, 721.95]]
</td>
<td>
[1]
</td>
<td>
[person]
</td>
<td>
3075367.jpg
</td>
<td>
768.0
</td>
<td>
1344.0
</td>
</tr>
<tr>
<th>
3076319
</th>
<td>
[[335.31, 151.75, 375.91, 965.74], [8.11, 131.88, 396.09, 987.12]]
</td>
<td>
[1, 1]
</td>
<td>
[person, person]
</td>
<td>
3076319.jpg
</td>
<td>
1120.0
</td>
<td>
768.0
</td>
</tr>
<tr>
<th>
3145551
</th>
<td>
[[642.0, 289.85, 27.66, 109.04], [658.63, 281.25, 28.46, 117.36]]
</td>
<td>
[1, 1]
</td>
<td>
[person, person]
</td>
<td>
3145551.jpg
</td>
<td>
768.0
</td>
<td>
1184.0
</td>
</tr>
<tr>
<th>
3176048
</th>
<td>
[[518.23, 338.97, 76.4, 127.11], [683.42, 356.48, -44.56, 81.34]]
</td>
<td>
[1, 1]
</td>
<td>
[person, person]
</td>
<td>
3176048.jpg
</td>
<td>
768.0
</td>
<td>
1152.0
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>With the annotations loaded, we can start inspecting our dataset.</p>
</section>
</section>
<section id="inspecting-the-class-distribution" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-the-class-distribution">Inspecting the Class Distribution</h3>
<p>First, we get the names of all the classes in our dataset and inspect the distribution of samples among these classes. This step won’t yield any insights for the toy dataset but is worth doing for real-world projects. A balanced dataset (where each class has approximately the same number of instances) is ideal for training a machine-learning model.</p>
<section id="get-image-classes" class="level4">
<h4 class="anchored" data-anchor-id="get-image-classes">Get image classes</h4>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb25-2">class_names <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>].explode().unique().tolist()</span>
<span id="cb25-3"></span>
<span id="cb25-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display labels using a Pandas DataFrame</span></span>
<span id="cb25-5">pd.DataFrame(class_names)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
person
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visualize-the-class-distribution" class="level4">
<h4 class="anchored" data-anchor-id="visualize-the-class-distribution">Visualize the class distribution</h4>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the number of samples for each object class</span></span>
<span id="cb26-2">class_counts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(annotation_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>].explode().tolist()).value_counts()</span>
<span id="cb26-3"></span>
<span id="cb26-4">plot_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [index[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> index <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> class_counts.index]</span>
<span id="cb26-5"></span>
<span id="cb26-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the distribution</span></span>
<span id="cb26-7">class_counts.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bar'</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb26-8">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class distribution'</span>)</span>
<span id="cb26-9">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Count'</span>)</span>
<span id="cb26-10">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Classes'</span>)</span>
<span id="cb26-11">plt.xticks(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_counts.index)), plot_labels, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the x-axis tick labels</span></span>
<span id="cb26-12">plt.show()</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/bounding-boxes/images/output_37_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
<section id="visualizing-image-annotations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-image-annotations">Visualizing Image Annotations</h3>
<p>In this section, we will annotate a single image with its bounding boxes using torchvision’s <code>BoundingBoxes</code> class and <code>draw_bounding_boxes</code> function.</p>
<section id="generate-a-color-map" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-color-map">Generate a color map</h4>
<p>While not required, assigning a unique color to bounding boxes for each object class enhances visual distinction, allowing for easier identification of different objects in the scene. We can use the <a href="https://distinctipy.readthedocs.io/en/latest/"><code>distinctipy</code></a> package to generate a visually distinct colormap.</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb27-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distinctipy.get_colors(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(class_names))</span>
<span id="cb27-3"></span>
<span id="cb27-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make a copy of the color map in integer format</span></span>
<span id="cb27-5">int_colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> color) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> color <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> colors]</span>
<span id="cb27-6"></span>
<span id="cb27-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a color swatch to visualize the color map</span></span>
<span id="cb27-8">distinctipy.color_swatch(colors)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/bounding-boxes/images/output_41_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a font file</h4>
<p>The <a href="https://pytorch.org/vision/stable/generated/torchvision.utils.draw_bounding_boxes.html"><code>draw_bounding_boxes</code></a> function included with torchvision uses a pretty small font size. We can increase the font size if we use a custom font. Font files are available on sites like <a href="https://fonts.google.com/">Google Fonts</a>, or we can use one included with the operating system.</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the name of the font file</span></span>
<span id="cb28-2">font_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb28-3"></span>
<span id="cb28-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the font file</span></span>
<span id="cb28-5">download_file(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>font_file<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./"</span>)</span></code></pre></div>
</section>
<section id="define-the-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-the-bounding-box-annotation-function">Define the bounding box annotation function</h4>
<p>We can make a partial function using <code>draw_bounding_boxes</code> since we’ll use the same box thickness and font each time we visualize bounding boxes.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">draw_bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(draw_bounding_boxes, fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, font<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>font_file, font_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>)</span></code></pre></div>
</section>
</section>
<section id="selecting-a-sample-image" class="level3">
<h3 class="anchored" data-anchor-id="selecting-a-sample-image">Selecting a Sample Image</h3>
<p>We can use the unique ID for an image in the image dictionary to get the image file path and the associated annotations from the annotation DataFrame.</p>
<section id="load-the-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="load-the-sample-image">Load the sample image</h4>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the file ID of the first image file</span></span>
<span id="cb30-2">file_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys())[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb30-3"></span>
<span id="cb30-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Open the associated image file as a RGB image</span></span>
<span id="cb30-5">sample_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(img_dict[file_id]).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb30-6"></span>
<span id="cb30-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the dimensions of the image</span></span>
<span id="cb30-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Image Dims: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sample_img<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>size<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb30-9"></span>
<span id="cb30-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Show the image</span></span>
<span id="cb30-11">sample_img</span></code></pre></div>
<pre class="text"><code>Image Dims: (768, 1152)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/bounding-boxes/images/output_48_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="inspect-the-corresponding-annotation-data" class="level4">
<h4 class="anchored" data-anchor-id="inspect-the-corresponding-annotation-data">Inspect the corresponding annotation data</h4>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'</span></span>
<span id="cb32-2">annotation_df.loc[file_id].to_frame()</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
258421
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
bboxes
</th>
<td>
[[386.08, 443.94, 74.74, 333.22], [340.25, 466.94, 78.74, 310.4]]
</td>
</tr>
<tr>
<th>
category_id
</th>
<td>
[1, 1]
</td>
</tr>
<tr>
<th>
labels
</th>
<td>
[person, person]
</td>
</tr>
<tr>
<th>
file_name
</th>
<td>
258421.jpg
</td>
</tr>
<tr>
<th>
height
</th>
<td>
1152.0
</td>
</tr>
<tr>
<th>
width
</th>
<td>
768.0
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="annotate-sample-image" class="level4">
<h4 class="anchored" data-anchor-id="annotate-sample-image">Annotate sample image</h4>
<p>The <code>draw_bounding_boxes</code> function expects bounding box annotations in <code>[top-left X, top-left Y, bottom-right X, bottom-right Y]</code> format, so we’ll use the <a href="https://pytorch.org/vision/stable/generated/torchvision.ops.box_convert.html#torchvision.ops.box_convert"><code>box_convert</code></a> function included with torchvision to convert the bounding box annotations from <code>[x,y,w,h]</code> to <code>[x,y,x,y]</code> format.</p>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the labels and bounding box annotations for the sample image</span></span>
<span id="cb33-2">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]</span>
<span id="cb33-3">bboxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df.loc[file_id][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bboxes'</span>]</span>
<span id="cb33-4"></span>
<span id="cb33-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the sample image with labels and bounding boxes</span></span>
<span id="cb33-6">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb33-7">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sample_img), </span>
<span id="cb33-8">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torchvision.ops.box_convert(torch.Tensor(bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>),</span>
<span id="cb33-9">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, </span>
<span id="cb33-10">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb33-11">)</span>
<span id="cb33-12"></span>
<span id="cb33-13">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/bounding-boxes/images/output_52_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We have loaded the dataset, inspected its class distribution, and visualized the annotations for a sample image. In the final section, we will cover how to augment images using torchvision’s Transforms V2 API and create a custom Dataset class for training.</p>
</section>
</section>
</section>
<section id="preparing-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data">Preparing the Data</h2>
<p>In this section, we will first walk through a single example of how to apply augmentations to a single annotated image using torchvision’s Transforms V2 API before putting everything together in a custom Dataset class.</p>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h3>
<p>Here, we will define some data augmentations to apply to images during training. I created a few custom image transforms to help streamline the code.</p>
<p>The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#customrandomioucrop">first</a> extends the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.RandomIoUCrop.html#torchvision.transforms.v2.RandomIoUCrop"><code>RandomIoUCrop</code></a> transform included with torchvision to give the user more control over how much it crops into bounding box areas. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#resizemax">second</a> resizes images based on their largest dimension rather than their smallest. The <a href="https://cj-mills.github.io/cjm-torchvision-tfms/core.html#padsquare">third</a> applies square padding and allows the padding to be applied equally on both sides or randomly split between the two sides.</p>
<p>All three are available through the <a href="https://cj-mills.github.io/cjm-torchvision-tfms/"><code>cjm-torchvision-tfms</code></a> package.</p>
<section id="set-training-image-size" class="level4">
<h4 class="anchored" data-anchor-id="set-training-image-size">Set training image size</h4>
<p>Next, we will specify the image size to use during training.</p>
<div class="sourceCode" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set training image size</span></span>
<span id="cb34-2">train_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span></span></code></pre></div>
</section>
<section id="initialize-custom-transforms" class="level4">
<h4 class="anchored" data-anchor-id="initialize-custom-transforms">Initialize custom transforms</h4>
<p>Now, we can initialize the transform objects.</p>
<div class="sourceCode" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a RandomIoUCrop object</span></span>
<span id="cb35-2">iou_crop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomRandomIoUCrop(min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb35-3">                               max_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, </span>
<span id="cb35-4">                               min_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, </span>
<span id="cb35-5">                               max_aspect_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, </span>
<span id="cb35-6">                               sampler_options<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb35-7">                               trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb35-8">                               jitter_factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)</span>
<span id="cb35-9"></span>
<span id="cb35-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `ResizeMax` object</span></span>
<span id="cb35-11">resize_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ResizeMax(max_sz<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_sz)</span>
<span id="cb35-12"></span>
<span id="cb35-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a `PadSquare` object</span></span>
<span id="cb35-14">pad_square <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PadSquare(shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</section>
<section id="test-the-transforms" class="level4">
<h4 class="anchored" data-anchor-id="test-the-transforms">Test the transforms</h4>
<p>Torchvision’s V2 image transforms take an image and a <code>targets</code> dictionary. The <code>targets</code> dictionary contains the annotations and labels for the image.</p>
<p>We will pass input through the <code>CustomRandomIoUCrop</code> transform first and then through <code>ResizeMax</code> and <code>PadSquare</code>. We can pass the result through a final resize operation to ensure both sides match the <code>train_sz</code> value.</p>
<div class="sourceCode" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare bounding box targets</span></span>
<span id="cb36-2">targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb36-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: BoundingBoxes(torchvision.ops.box_convert(torch.Tensor(bboxes), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>), </span>
<span id="cb36-4">                           <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, </span>
<span id="cb36-5">                           canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sample_img.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), </span>
<span id="cb36-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.Tensor([class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels])</span>
<span id="cb36-7">}</span>
<span id="cb36-8"></span>
<span id="cb36-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Crop the image</span></span>
<span id="cb36-10">cropped_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iou_crop(sample_img, targets)</span>
<span id="cb36-11"></span>
<span id="cb36-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Resize the image</span></span>
<span id="cb36-13">resized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize_max(cropped_img, targets)</span>
<span id="cb36-14"></span>
<span id="cb36-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pad the image</span></span>
<span id="cb36-16">padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_square(resized_img, targets)</span>
<span id="cb36-17"></span>
<span id="cb36-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the padded image is the target size</span></span>
<span id="cb36-19">resize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb36-20">resized_padded_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> resize(padded_img, targets)</span>
<span id="cb36-21">sanitized_img, targets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.SanitizeBoundingBoxes()(resized_padded_img, targets)</span>
<span id="cb36-22"></span>
<span id="cb36-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the augmented image with updated labels and bounding boxes</span></span>
<span id="cb36-24">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb36-25">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transforms.PILToTensor()(sanitized_img), </span>
<span id="cb36-26">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb36-27">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(label.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> targets[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb36-28">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> [class_names.index(label) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> labels]]</span>
<span id="cb36-29">)</span>
<span id="cb36-30"></span>
<span id="cb36-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the annotated image</span></span>
<span id="cb36-32">display(tensor_to_pil(annotated_tensor))</span>
<span id="cb36-33"></span>
<span id="cb36-34">pd.Series({</span>
<span id="cb36-35">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Source Image:"</span>: sample_img.size,</span>
<span id="cb36-36">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cropped Image:"</span>: cropped_img.size,</span>
<span id="cb36-37">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Image:"</span>: resized_img.size,</span>
<span id="cb36-38">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Padded Image:"</span>: padded_img.size,</span>
<span id="cb36-39">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Resized Padded Image:"</span>: resized_padded_img.size,</span>
<span id="cb36-40">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/bounding-boxes/images/output_60_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_cc3ae">
<thead>
</thead>
<tbody>
<tr>
<th id="T_cc3ae_level0_row0" class="row_heading level0 row0">
Source Image:
</th>
<td id="T_cc3ae_row0_col0" class="data row0 col0">
(768, 1152)
</td>
</tr>
<tr>
<th id="T_cc3ae_level0_row1" class="row_heading level0 row1">
Cropped Image:
</th>
<td id="T_cc3ae_row1_col0" class="data row1 col0">
(653, 941)
</td>
</tr>
<tr>
<th id="T_cc3ae_level0_row2" class="row_heading level0 row2">
Resized Image:
</th>
<td id="T_cc3ae_row2_col0" class="data row2 col0">
(266, 383)
</td>
</tr>
<tr>
<th id="T_cc3ae_level0_row3" class="row_heading level0 row3">
Padded Image:
</th>
<td id="T_cc3ae_row3_col0" class="data row3 col0">
(383, 383)
</td>
</tr>
<tr>
<th id="T_cc3ae_level0_row4" class="row_heading level0 row4">
Resized Padded Image:
</th>
<td id="T_cc3ae_row4_col0" class="data row4 col0">
(384, 384)
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Now that we know how to apply data augmentations, we can put all the steps we’ve covered into a custom Dataset class.</p>
</section>
</section>
<section id="training-dataset-class" class="level3">
<h3 class="anchored" data-anchor-id="training-dataset-class">Training Dataset Class</h3>
<p>The following custom Dataset class is responsible for loading a single image, preparing the associated annotations, applying any image transforms, and returning the final <code>image</code> tensor and its <code>target</code> dictionary during training.</p>
<div class="sourceCode" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> COCOBBoxDataset(Dataset):</span>
<span id="cb37-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb37-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A dataset class for COCO-style datasets with bounding box annotations.</span></span>
<span id="cb37-4"></span>
<span id="cb37-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This class is designed to handle datasets where images are annotated with bounding boxes,</span></span>
<span id="cb37-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    such as object detection tasks. It supports loading images, applying transformations, </span></span>
<span id="cb37-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    and retrieving the associated bounding box annotations.</span></span>
<span id="cb37-8"></span>
<span id="cb37-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Attributes:</span></span>
<span id="cb37-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _img_keys (list): A list of keys (identifiers) for each image in the dataset.</span></span>
<span id="cb37-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _annotation_df (DataFrame): A DataFrame containing annotations for the images. </span></span>
<span id="cb37-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                                    Each row corresponds to an image, indexed by its key.</span></span>
<span id="cb37-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _img_dict (dict): A dictionary mapping image keys to their file paths.</span></span>
<span id="cb37-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _class_to_idx (dict): A dictionary mapping class names to their corresponding indices.</span></span>
<span id="cb37-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _transforms (callable, optional): Optional transform to be applied on a sample.</span></span>
<span id="cb37-16"></span>
<span id="cb37-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Methods:</span></span>
<span id="cb37-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        __len__: Returns the number of images in the dataset.</span></span>
<span id="cb37-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        __getitem__: Retrieves an image and its corresponding target (bounding boxes and labels) </span></span>
<span id="cb37-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                     by index.</span></span>
<span id="cb37-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _load_image_and_target: Helper function to load an image and its corresponding target.</span></span>
<span id="cb37-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb37-23"></span>
<span id="cb37-24">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, img_keys, annotation_df, img_dict, class_to_idx, transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb37-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb37-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Initializes the COCOBBoxDataset instance.</span></span>
<span id="cb37-27"></span>
<span id="cb37-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb37-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_keys (list): List of image keys.</span></span>
<span id="cb37-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation_df (DataFrame): DataFrame containing image annotations.</span></span>
<span id="cb37-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            img_dict (dict): Dictionary mapping image keys to file paths.</span></span>
<span id="cb37-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            class_to_idx (dict): Dictionary mapping class names to indices.</span></span>
<span id="cb37-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            transforms (callable, optional): Optional transform to be applied on a sample.</span></span>
<span id="cb37-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb37-35">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Dataset, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb37-36">        </span>
<span id="cb37-37">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_keys  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># List of image keys</span></span>
<span id="cb37-38">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation_df  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># DataFrame containing annotations</span></span>
<span id="cb37-39">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img_dict  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dictionary mapping image keys to image paths</span></span>
<span id="cb37-40">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> class_to_idx  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dictionary mapping class names to class indices</span></span>
<span id="cb37-41">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Image transforms to be applied</span></span>
<span id="cb37-42">        </span>
<span id="cb37-43">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__len__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb37-44">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb37-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns the total number of images in the dataset.</span></span>
<span id="cb37-46"></span>
<span id="cb37-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb37-48"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            int: The number of images in the dataset.</span></span>
<span id="cb37-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb37-50">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys)</span>
<span id="cb37-51">        </span>
<span id="cb37-52">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, index):</span>
<span id="cb37-53">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb37-54"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Retrieves an image and its corresponding target (bounding boxes and labels) by index.</span></span>
<span id="cb37-55"></span>
<span id="cb37-56"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb37-57"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            index (int): The index of the image in the dataset.</span></span>
<span id="cb37-58"></span>
<span id="cb37-59"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb37-60"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and its target. The target is a dictionary with </span></span>
<span id="cb37-61"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                   keys 'boxes' and 'labels'.</span></span>
<span id="cb37-62"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb37-63">        img_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_keys[index]</span>
<span id="cb37-64">        annotation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._annotation_df.loc[img_key]</span>
<span id="cb37-65">        image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._load_image_and_target(annotation)</span>
<span id="cb37-66">        </span>
<span id="cb37-67">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms:</span>
<span id="cb37-68">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the specified transformations to the image and target</span></span>
<span id="cb37-69">            image, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._transforms(image, target)</span>
<span id="cb37-70">        </span>
<span id="cb37-71">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, target</span>
<span id="cb37-72"></span>
<span id="cb37-73">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _load_image_and_target(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, annotation):</span>
<span id="cb37-74">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb37-75"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Helper function to load an image and its corresponding target.</span></span>
<span id="cb37-76"></span>
<span id="cb37-77"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The target includes bounding boxes and labels for the image.</span></span>
<span id="cb37-78"></span>
<span id="cb37-79"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb37-80"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            annotation (pandas.Series): The annotation data for the image, typically a row from the DataFrame.</span></span>
<span id="cb37-81"></span>
<span id="cb37-82"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb37-83"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple: A tuple containing the image and its target, where the target is a dictionary </span></span>
<span id="cb37-84"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                   with keys 'boxes' and 'labels'.</span></span>
<span id="cb37-85"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb37-86">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the image file using the path from the image dictionary</span></span>
<span id="cb37-87">        filepath <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._img_dict[annotation.name]</span>
<span id="cb37-88">        image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(filepath).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGB'</span>)</span>
<span id="cb37-89"></span>
<span id="cb37-90">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract bounding box data from the annotations and convert to the desired format</span></span>
<span id="cb37-91">        bbox_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bboxes'</span>]</span>
<span id="cb37-92">        bbox_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torchvision.ops.box_convert(torch.Tensor(bbox_list), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xywh'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>)</span>
<span id="cb37-93">        boxes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BoundingBoxes(bbox_tensor, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xyxy'</span>, canvas_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image.size[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb37-94"></span>
<span id="cb37-95">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert class labels in the annotation to their corresponding indices</span></span>
<span id="cb37-96">        annotation_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> annotation[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]</span>
<span id="cb37-97">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.Tensor([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_to_idx[label] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> label <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> annotation_labels])</span>
<span id="cb37-98"></span>
<span id="cb37-99">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> image, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>: boxes, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: labels}</span></code></pre></div>
</section>
<section id="image-transforms" class="level3">
<h3 class="anchored" data-anchor-id="image-transforms">Image Transforms</h3>
<p>Here, we will specify and organize all the image transforms to apply during training.</p>
<div class="sourceCode" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms for data augmentation</span></span>
<span id="cb38-2">data_aug_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose(</span>
<span id="cb38-3">    transforms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb38-4">        iou_crop,</span>
<span id="cb38-5">        transforms.ColorJitter(</span>
<span id="cb38-6">                brightness <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.875</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.125</span>),</span>
<span id="cb38-7">                contrast <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb38-8">                saturation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>),</span>
<span id="cb38-9">                hue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>),</span>
<span id="cb38-10">        ),</span>
<span id="cb38-11">        transforms.RandomGrayscale(),</span>
<span id="cb38-12">        transforms.RandomEqualize(),</span>
<span id="cb38-13">        transforms.RandomPosterize(bits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb38-14">        transforms.RandomHorizontalFlip(p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb38-15">    ],</span>
<span id="cb38-16">)</span>
<span id="cb38-17"></span>
<span id="cb38-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to resize and pad input images</span></span>
<span id="cb38-19">resize_pad_tfm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb38-20">    resize_max, </span>
<span id="cb38-21">    pad_square,</span>
<span id="cb38-22">    transforms.Resize([train_sz] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb38-23">])</span>
<span id="cb38-24"></span>
<span id="cb38-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compose transforms to sanitize bounding boxes and normalize input data</span></span>
<span id="cb38-26">final_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb38-27">    transforms.ToImage(), </span>
<span id="cb38-28">    transforms.ToDtype(torch.float32, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb38-29">    transforms.SanitizeBoundingBoxes(),</span>
<span id="cb38-30">])</span>
<span id="cb38-31"></span>
<span id="cb38-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the transformations for training and validation datasets</span></span>
<span id="cb38-33">train_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb38-34">    data_aug_tfms, </span>
<span id="cb38-35">    resize_pad_tfm, </span>
<span id="cb38-36">    final_tfms</span>
<span id="cb38-37">])</span></code></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always use the <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.v2.SanitizeBoundingBoxes.html#torchvision.transforms.v2.SanitizeBoundingBoxes"><code>SanitizeBoundingBoxes</code></a> transform to clean up annotations after using data augmentations that alter bounding boxes (e.g., cropping, warping, etc.).</p>
</div>
</div>
</section>
<section id="initialize-dataset" class="level3">
<h3 class="anchored" data-anchor-id="initialize-dataset">Initialize Dataset</h3>
<p>Now, we can create the dataset object using the image dictionary, the annotation DataFrame, and the image transforms.</p>
<div class="sourceCode" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mapping from class names to class indices</span></span>
<span id="cb39-2">class_to_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {c: i <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(class_names)}</span>
<span id="cb39-3"></span>
<span id="cb39-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Instantiate the dataset using the defined transformations</span></span>
<span id="cb39-5">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> COCOBBoxDataset(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(img_dict.keys()), annotation_df, img_dict, class_to_idx, train_tfms)</span>
<span id="cb39-6"></span>
<span id="cb39-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the number of samples in the training dataset</span></span>
<span id="cb39-8">pd.Series({</span>
<span id="cb39-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training dataset size:'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_dataset),</span>
<span id="cb39-10">}).to_frame().style.hide(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'columns'</span>)</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_69f73">
<thead>
</thead>
<tbody>
<tr>
<th id="T_69f73_level0_row0" class="row_heading level0 row0">
Training dataset size:
</th>
<td id="T_69f73_row0_col0" class="data row0 col0">
28
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspect-samples" class="level3">
<h3 class="anchored" data-anchor-id="inspect-samples">Inspect Samples</h3>
<p>To close out, we should verify the dataset object works as intended by inspecting the first sample.</p>
<section id="inspect-training-set-sample" class="level4">
<h4 class="anchored" data-anchor-id="inspect-training-set-sample">Inspect training set sample</h4>
<div class="sourceCode" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">dataset_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_dataset[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb40-2"></span>
<span id="cb40-3">annotated_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> draw_bboxes(</span>
<span id="cb40-4">    image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.uint8), </span>
<span id="cb40-5">    boxes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'boxes'</span>], </span>
<span id="cb40-6">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[class_names[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]], </span>
<span id="cb40-7">    colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[int_colors[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(i.item())] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> dataset_sample[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>]]</span>
<span id="cb40-8">)</span>
<span id="cb40-9"></span>
<span id="cb40-10">tensor_to_pil(annotated_tensor)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="christianjmills.com/posts/torchvision-coco-annotation-tutorials/bounding-boxes/images/output_69_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we covered how to load custom COCO bounding box annotations and work with them using torchvision’s Transforms V2 API. The skills and knowledge you acquired here provide a solid foundation for future object detection projects.</p>
<p>As a next step, perhaps try annotating a custom COCO object detection dataset with a tool like <a href="https://github.com/opencv/cvat">CVAT</a> and loading it with this tutorial’s code. Once you’re comfortable with that, try adapting the code in the following tutorial to train an object detection model on your custom dataset.</p>
<ul>
<li><a href="../../../posts/pytorch-train-object-detector-yolox-tutorial">Training YOLOX Models for Real-Time Object Detection in PyTorch</a></li>
</ul>
</section>
<section id="recommended-tutorials" class="level2">
<h2 class="anchored" data-anchor-id="recommended-tutorials">Recommended Tutorials</h2>
<ul>
<li><a href="../../../posts/torchvision-coco-annotation-tutorials/segmentation-polygons/"><strong>Working with COCO Segmentation Annotations in Torchvision</strong></a><strong>:</strong> Learn how to work with COCO segmentation annotations in torchvision for instance segmentation tasks.<br>
</li>
<li><a href="../../../posts/pytorch-train-object-detector-yolox-tutorial"><strong>Training YOLOX Models for Real-Time Object Detection in PyTorch</strong></a><strong>:</strong> Learn how to train YOLOX models for real-time object detection in PyTorch by creating a hand gesture detection model.</li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Next Steps">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next Steps
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
<li>If you would like to explore my services for your project, you can reach out via email at <a href="mailto:christian@christianjmills.com">christian@christianjmills.com</a></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <category>pytorch</category>
  <category>image-annotation</category>
  <category>object-detection</category>
  <category>tutorial</category>
  <guid>christianjmills.com/posts/torchvision-coco-annotation-tutorials/bounding-boxes/</guid>
  <pubDate>Sun, 21 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Chip War Part 8: The Chip Choke</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/chip-war-book-notes/part-8/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/chip-war-book-notes.html"><strong>Chip War: The Fight for the World’s Most Critical Technology</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>“Everything We’re Competing On”</li>
<li>Fujian Jinhua</li>
<li>The Assault on Huawei</li>
<li>China’s Sputnik Moment?</li>
<li>Shortages and Supply Chains</li>
<li>The Taiwan Dilemma</li>
</ul>
<section id="everything-were-competing-on" class="level2">
<h2 class="anchored" data-anchor-id="everything-were-competing-on">“Everything We’re Competing On”</h2>
<p>Chapter 49 addresses the growing concerns in the U.S. about China’s advances in the semiconductor industry. Intel CEO Brian Krzanich, in his role as chairman of the Semiconductor Industry Association in 2015, expressed anxiety over China’s push to seize a larger share of the global chip industry. The chapter discusses the U.S. semiconductor firms’ dilemma of relying on China as a crucial market while facing the threat of being cut out of China’s supply chain due to its massive semiconductor subsidies. The chapter also touches on the Obama administration’s slow response to the semiconductor issue, the Pentagon’s concerns over China’s computing power in new weapons systems, and the shift in U.S. policy under the Trump administration towards a more combative approach to technology policy.</p>
<section id="ideas" class="level3">
<h3 class="anchored" data-anchor-id="ideas">Ideas</h3>
<ol type="1">
<li>The U.S. semiconductor industry’s increasing anxiety over China’s growing presence in the global chip market.</li>
<li>The complex relationship between U.S. chip firms and China, where China is both a key market and a competitive threat.</li>
<li>China’s formal policy to reduce reliance on foreign semiconductors and develop its own chip industry.</li>
<li>The Obama administration’s initial underestimation of the importance of semiconductors in geopolitical competition.</li>
<li>The Pentagon’s concern over China’s use of computing power in developing new weapons systems.</li>
<li>The Trump administration’s shift to a more aggressive stance on technology policy, particularly regarding China.</li>
<li>The strategic importance of semiconductors in global power dynamics and the U.S.-China rivalry.</li>
<li>The semiconductor industry’s fear of Chinese retaliation and the dilemma faced by U.S. firms operating in China.</li>
<li>The perceived need for stronger export control regimes to prevent technological leakage to China.</li>
<li>The increasing focus of the U.S. government on semiconductors as a critical component of national security and global competitiveness.</li>
</ol>
</section>
<section id="facts" class="level3">
<h3 class="anchored" data-anchor-id="facts">Facts</h3>
<ol type="1">
<li>The U.S. semiconductor industry is increasingly concerned about China’s growing influence in the global chip market.</li>
<li>U.S. semiconductor firms face a complex dynamic with China, balancing market opportunities with competitive threats.</li>
<li>China’s government has implemented policies aimed at reducing reliance on foreign semiconductors.</li>
<li>The U.S. government initially underestimated the strategic importance of semiconductors in global competition.</li>
<li>The Pentagon is concerned about China’s application of computing power in new military technologies.</li>
<li>The Trump administration adopted a more aggressive technology policy stance towards China.</li>
<li>Semiconductors are increasingly viewed as critical to national security and global power dynamics.</li>
<li>U.S. semiconductor firms are cautious about Chinese retaliation and face dilemmas in their operations in China.</li>
<li>The U.S. government has recognized the need for stronger export controls to limit technological transfer to China.</li>
<li>Semiconductors have become a central focus of U.S. national security and competitiveness strategies.</li>
</ol>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<ol type="1">
<li>Analyze the strategic implications of China’s growing influence in the semiconductor industry for U.S. firms and national security.</li>
<li>Study the evolving U.S. government policies towards semiconductor technology and export controls in response to China’s advances.</li>
<li>Investigate the role of semiconductors in the U.S.-China technology rivalry and its impact on global power dynamics.</li>
<li>Examine the challenges faced by U.S. semiconductor companies operating in the Chinese market.</li>
<li>Assess the impact of China’s semiconductor development on the global technology landscape.</li>
<li>Explore the implications of semiconductor technology on military and intelligence applications in the context of U.S.-China competition.</li>
<li>Consider the effectiveness of U.S. strategies in maintaining a competitive edge in semiconductor technology.</li>
<li>Understand the complexities of the semiconductor supply chain and its geopolitical significance.</li>
<li>Reflect on the broader implications of the semiconductor industry’s evolution for global economic and technological leadership.</li>
<li>Evaluate the long-term consequences of the U.S.-China semiconductor rivalry on the global technology industry.</li>
</ol>
</section>
</section>
<section id="fujian-jinhua" class="level2">
<h2 class="anchored" data-anchor-id="fujian-jinhua">Fujian Jinhua</h2>
<p>Chapter 50 recounts the espionage incident involving Micron Technology, an American semiconductor company, and Fujian Jinhua, a Chinese state-backed firm. Kenny Wang, an employee at Micron’s Taiwan facility, downloaded confidential files related to Micron’s DRAM technology and transferred them to Google Drive before moving to United Microelectronics Corporation (UMC), which was in partnership with Fujian Jinhua. This case highlights the intense competition and espionage activities in the semiconductor industry, reflecting broader geopolitical tensions and the strategic importance of advanced technology in global power dynamics.</p>
<section id="ideas-1" class="level3">
<h3 class="anchored" data-anchor-id="ideas-1">Ideas</h3>
<ol type="1">
<li>The theft of Micron’s DRAM technology by Fujian Jinhua illustrates the high stakes and aggressive tactics in the semiconductor industry.</li>
<li>Kenny Wang’s role in downloading and transferring Micron’s confidential information to UMC and subsequently to Fujian Jinhua.</li>
<li>Fujian Jinhua’s strategy of partnering with UMC to acquire DRAM technology, despite UMC not being in the DRAM business.</li>
<li>The involvement of multiple employees from Micron’s Taiwan facility in the espionage, highlighting the vulnerability of intellectual property in global companies.</li>
<li>The Taiwanese government’s response to Micron’s complaint about the intellectual property theft.</li>
<li>The broader context of China’s efforts to develop its semiconductor industry and reduce reliance on foreign technology.</li>
<li>The implications of the case for U.S.-China relations and the semiconductor industry’s global landscape.</li>
<li>The impact of intellectual property theft on the competitive dynamics of the semiconductor industry.</li>
<li>The strategic importance of DRAM technology and its role in the global semiconductor market.</li>
<li>The case as an example of the complex interplay between corporate espionage, international law, and global technology competition.</li>
</ol>
</section>
<section id="facts-1" class="level3">
<h3 class="anchored" data-anchor-id="facts-1">Facts</h3>
<ol type="1">
<li>Fujian Jinhua, a Chinese state-backed semiconductor firm, was involved in the theft of DRAM technology from Micron Technology.</li>
<li>Kenny Wang, a former employee at Micron’s Taiwan facility, played a key role in downloading and transferring confidential information.</li>
<li>UMC partnered with Fujian Jinhua to acquire DRAM technology, despite not being in the DRAM business.</li>
<li>The case involved multiple individuals from Micron’s Taiwan facility, suggesting a coordinated effort to acquire Micron’s technology.</li>
<li>The incident led to legal actions and raised serious concerns about intellectual property theft in the semiconductor industry.</li>
<li>The case reflects the intense competition and strategic importance of semiconductor technology in global markets.</li>
<li>China’s efforts to develop its semiconductor industry involve significant state investment and strategies to acquire foreign technology.</li>
<li>The incident has implications for U.S.-China relations and the global semiconductor industry.</li>
<li>DRAM technology is a critical component in the global semiconductor market, with significant competitive implications.</li>
<li>The case exemplifies the challenges of protecting intellectual property in a globalized and highly competitive technological environment.</li>
</ol>
</section>
<section id="recommendations-1" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-1">Recommendations</h3>
<ol type="1">
<li>Analyze the strategic implications of intellectual property theft in the semiconductor industry.</li>
<li>Study the legal and geopolitical aspects of the Fujian Jinhua case and its impact on U.S.-China relations.</li>
<li>Investigate the role of state-backed companies in China’s semiconductor strategy.</li>
<li>Examine the challenges faced by global companies like Micron in protecting their intellectual property.</li>
<li>Assess the importance of DRAM technology in the competitive landscape of the semiconductor industry.</li>
<li>Explore the broader implications of corporate espionage on international trade and technology competition.</li>
<li>Consider the impact of such incidents on global semiconductor market dynamics and company strategies.</li>
<li>Reflect on the role of technology in national security and global power dynamics.</li>
<li>Understand the complexities of intellectual property protection in a highly competitive and globalized industry.</li>
<li>Evaluate the long-term effects of state-backed industrial strategies on global technology markets and competition.</li>
</ol>
</section>
</section>
<section id="the-assault-on-huawei" class="level2">
<h2 class="anchored" data-anchor-id="the-assault-on-huawei">The Assault on Huawei</h2>
<p>Chapter 51 focuses on the U.S. government’s actions against Huawei, a leading Chinese technology company. The chapter outlines the Trump administration’s efforts to restrict Huawei’s access to U.S. technology, particularly semiconductors, citing national security concerns and allegations of Huawei’s involvement in espionage. It discusses the broader context of the U.S.-China technology rivalry, Huawei’s significant role in global telecom infrastructure, and the geopolitical implications of the U.S.’s actions. The chapter also explores the global reactions to the U.S. campaign against Huawei, including varying responses from allies, and the impact on Huawei’s business operations and China’s technological ambitions.</p>
<section id="ideas-2" class="level3">
<h3 class="anchored" data-anchor-id="ideas-2">Ideas</h3>
<ol type="1">
<li>Huawei became a focal point in the U.S.-China technology rivalry, with the U.S. government citing national security concerns.</li>
<li>President Trump’s administration took significant steps to restrict Huawei’s access to American technology, particularly in the semiconductor sector.</li>
<li>Huawei’s critical role in global telecom infrastructure, particularly in 5G networks, was a key factor in the U.S.’s actions.</li>
<li>The U.S.’s campaign against Huawei reflected broader efforts to curb China’s technological rise and influence.</li>
<li>The restrictions on Huawei had significant implications for the company’s operations, including its smartphone and server businesses.</li>
<li>The U.S. government’s actions were part of a broader strategy to maintain technological superiority over China.</li>
<li>Huawei’s position as a leading global tech firm made it a target for U.S. efforts to limit China’s access to advanced technology.</li>
<li>The global response to the U.S. campaign against Huawei varied, with some countries following the U.S.’s lead and others resisting.</li>
<li>The chapter discusses the impact of U.S. restrictions on the global semiconductor ecosystem and supply chains.</li>
<li>The U.S. actions against Huawei were seen as a move to send a message worldwide, influencing other countries’ technology policies and alliances.</li>
</ol>
</section>
<section id="facts-2" class="level3">
<h3 class="anchored" data-anchor-id="facts-2">Facts</h3>
<ol type="1">
<li>The U.S. government targeted Huawei with restrictions, citing national security concerns.</li>
<li>Huawei is a major player in the global telecom infrastructure, especially in 5G technology.</li>
<li>The Trump administration’s actions against Huawei were part of a broader U.S.-China technology rivalry.</li>
<li>The restrictions had a significant impact on Huawei’s business operations and its ability to access critical semiconductor technology.</li>
<li>The U.S. aimed to maintain its technological superiority and curb China’s technological advancements.</li>
<li>Huawei’s global influence made it a strategic target in the U.S.’s efforts to limit China’s technological rise.</li>
<li>Responses to the U.S. campaign against Huawei varied globally, affecting international technology policies and alliances.</li>
<li>The U.S. restrictions influenced the global semiconductor ecosystem and supply chains.</li>
<li>The U.S.’s actions against Huawei were intended to influence other countries’ technology policies and alliances.</li>
<li>The U.S. strategy against Huawei was part of a broader effort to control key points in the global technology supply chain.</li>
</ol>
</section>
<section id="recommendations-2" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-2">Recommendations</h3>
<ol type="1">
<li>Analyze the strategic reasons behind the U.S. government’s actions against Huawei.</li>
<li>Study the impact of U.S. restrictions on Huawei’s business and the global semiconductor industry.</li>
<li>Investigate the role of Huawei in the global telecom infrastructure and its significance in the U.S.-China technology rivalry.</li>
<li>Examine the global responses to the U.S. campaign against Huawei and their implications for international technology alliances.</li>
<li>Assess the broader implications of the U.S.-China technology rivalry on global technological advancement and supply chains.</li>
<li>Explore the impact of national security concerns on technology policies and the semiconductor industry.</li>
<li>Consider the effectiveness of U.S. strategies in maintaining technological superiority over China.</li>
<li>Understand the complexities of the global technology market and the geopolitical implications of U.S. actions against Huawei.</li>
<li>Reflect on the broader context of U.S.-China relations and their impact on global technology dynamics.</li>
<li>Evaluate the long-term consequences of the U.S. campaign against Huawei on the global technology industry and international relations.</li>
</ol>
</section>
</section>
<section id="chinas-sputnik-moment" class="level2">
<h2 class="anchored" data-anchor-id="chinas-sputnik-moment">China’s Sputnik Moment?</h2>
<p>Chapter 52 explores China’s ambitious efforts to develop its semiconductor industry, especially during the COVID-19 pandemic. The chapter focuses on Yangtze Memory Technologies Corporation (YMTC) in Wuhan, China’s leading NAND memory producer, as a symbol of China’s push for technological independence. Despite the pandemic lockdown, YMTC continued operations, reflecting the government’s prioritization of semiconductor development. The chapter also touches on China’s response to U.S. export controls, viewing them as a catalyst for accelerating its quest for tech dominance. The narrative delves into the risks and challenges China faces in this endeavor, highlighting failed projects and the complexities of achieving technological independence in the semiconductor industry.</p>
<section id="ideas-3" class="level3">
<h3 class="anchored" data-anchor-id="ideas-3">Ideas</h3>
<ol type="1">
<li>YMTC’s continued operation during the COVID-19 lockdown in Wuhan illustrates China’s commitment to semiconductor development.</li>
<li>U.S. export controls on semiconductor technology have spurred China’s efforts to boost its domestic chip industry.</li>
<li>The chapter suggests that China’s response to these controls mirrors the U.S.’s reaction to the Soviet Union’s Sputnik launch, triggering significant investment in technology.</li>
<li>Despite substantial government support, including billions in funding, China’s path to semiconductor independence faces hurdles, including failed projects and technological challenges.</li>
<li>The narrative questions whether China’s massive investment in semiconductors will yield successful technological advancement or lead to wasteful expenditure.</li>
<li>China’s goal of technological independence is complicated by the multinational nature of the semiconductor supply chain and the country’s current technological capabilities.</li>
<li>The chapter discusses China’s interest in developing alternative architectures, like RISC-V, to reduce reliance on foreign technology.</li>
<li>China’s semiconductor strategy involves not only cutting-edge technology but also investment in older process technologies and emerging materials like silicon carbide and gallium nitride.</li>
<li>The chapter analyzes the geopolitical implications of China’s semiconductor ambitions and their potential impact on the global technology landscape.</li>
<li>The narrative explores the intersection of China’s national goals and commercial interests in the semiconductor sector, highlighting the government’s influence on chip companies.</li>
</ol>
</section>
</section>
<section id="facts-3" class="level2">
<h2 class="anchored" data-anchor-id="facts-3">Facts</h2>
<ol type="1">
<li>YMTC in Wuhan symbolizes China’s focus on developing its semiconductor industry.</li>
<li>U.S. export controls have intensified China’s efforts to establish technological independence in semiconductors.</li>
<li>China’s response to these controls is likened to the U.S.’s reaction to the Sputnik launch.</li>
<li>Despite heavy investment, China’s semiconductor independence efforts face significant challenges.</li>
<li>The narrative questions the effectiveness of China’s massive investment in the semiconductor industry.</li>
<li>China’s pursuit of technological independence is hindered by the global nature of the semiconductor supply chain.</li>
<li>China is exploring alternative architectures like RISC-V to reduce foreign dependency.</li>
<li>China’s strategy includes investment in various semiconductor technologies and materials.</li>
<li>The chapter highlights the geopolitical implications of China’s ambitions in the semiconductor field.</li>
<li>The government’s influence in China’s semiconductor sector is a key theme in the chapter.</li>
</ol>
<section id="recommendations-3" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-3">Recommendations</h3>
<ol type="1">
<li>Study the strategic implications of China’s semiconductor industry development, particularly in response to U.S. export controls.</li>
<li>Analyze the challenges and risks associated with China’s massive investment in semiconductor technology.</li>
<li>Investigate the role of companies like YMTC in China’s quest for technological independence.</li>
<li>Explore the geopolitical and economic impacts of China’s semiconductor ambitions.</li>
<li>Assess the potential of alternative semiconductor architectures and materials in reducing China’s reliance on foreign technology.</li>
<li>Consider the effectiveness of China’s national strategies in achieving semiconductor independence.</li>
<li>Examine the global semiconductor industry dynamics in the context of China’s technological efforts.</li>
<li>Reflect on the broader implications of China’s semiconductor strategy for international technology competition.</li>
<li>Understand the complexities and potential outcomes of China’s investment in the semiconductor sector.</li>
<li>Evaluate the long-term effects of China’s pursuit of semiconductor independence on global technology leadership and market dynamics.</li>
</ol>
</section>
</section>
<section id="shortages-and-supply-chains" class="level2">
<h2 class="anchored" data-anchor-id="shortages-and-supply-chains">Shortages and Supply Chains</h2>
<p>Chapter 53 discusses the semiconductor shortages and supply chain issues, particularly during the COVID-19 pandemic. It highlights President Biden’s emphasis on the need for the U.S. to boost its investments in technology to compete globally. The chapter delves into the semiconductor supply chain problems, exacerbated by the pandemic and strategic stockpiling by countries like China. It also covers the impact of these shortages on various industries, especially the automotive sector, and the U.S. government’s response to address these challenges. The chapter underscores the complex dynamics of the global semiconductor industry, including geopolitical aspects and the shifting landscape of chip manufacturing.</p>
<section id="ideas-4" class="level3">
<h3 class="anchored" data-anchor-id="ideas-4">Ideas</h3>
<ol type="1">
<li>The COVID-19 pandemic revealed the fragility and significance of semiconductor supply chains.</li>
<li>President Biden’s focus on strengthening U.S. investments in technology to maintain global competitiveness.</li>
<li>The impact of semiconductor shortages on industries like automotive, leading to significant production and revenue losses.</li>
<li>China’s strategic stockpiling of chips and the U.S.’s export controls contributing to global semiconductor shortages.</li>
<li>The shift in demand for various types of chips during the pandemic, including a surge in demand for PCs and servers.</li>
<li>The U.S. government’s interpretation of the chip shortage as a supply chain problem and its efforts to address it.</li>
<li>The broader implications of semiconductor supply chain issues for the global economy and technological advancement.</li>
<li>The dynamics between different countries and regions in the semiconductor industry, including the U.S., China, South Korea, and Taiwan.</li>
<li>The role of national policies and government interventions in shaping the semiconductor market and supply chains.</li>
<li>The challenges and strategies of semiconductor companies in navigating the complex and changing landscape of chip manufacturing and supply.</li>
</ol>
</section>
<section id="facts-4" class="level3">
<h3 class="anchored" data-anchor-id="facts-4">Facts</h3>
<ol type="1">
<li>The COVID-19 pandemic significantly impacted semiconductor supply chains.</li>
<li>The U.S. government, under President Biden, focused on addressing technology investment to compete globally.</li>
<li>The automotive industry faced substantial losses due to semiconductor shortages.</li>
<li>China’s stockpiling and U.S. export controls contributed to global chip shortages.</li>
<li>There was a significant increase in demand for chips used in PCs and servers during the pandemic.</li>
<li>The U.S. government interpreted the chip shortage as a supply chain issue and initiated measures to address it.</li>
<li>The semiconductor shortage highlighted the interconnected nature of global supply chains.</li>
<li>The global semiconductor industry experienced a record production year in 2021.</li>
<li>National policies and government interventions play a crucial role in the semiconductor market.</li>
<li>The global reliance on Taiwanese semiconductor production continues to increase.</li>
</ol>
</section>
<section id="recommendations-4" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-4">Recommendations</h3>
<ol type="1">
<li>Analyze the impact of the COVID-19 pandemic on global semiconductor supply chains.</li>
<li>Study the U.S. government’s response to semiconductor shortages and its strategy to enhance technology investments.</li>
<li>Investigate the causes and consequences of semiconductor shortages in various industries.</li>
<li>Explore the geopolitical aspects of semiconductor production and</li>
</ol>
<p>trade, especially between the U.S. and China.</p>
<ol start="5" type="1">
<li>Assess the effectiveness of national policies and government interventions in addressing semiconductor supply chain issues.</li>
<li>Consider the changing demand dynamics for different types of semiconductor chips during the pandemic.</li>
<li>Examine the role of Taiwan in the global semiconductor industry and the implications of its central position.</li>
<li>Reflect on the broader implications of semiconductor shortages for global economic stability and technological advancement.</li>
<li>Understand the complexities of managing semiconductor supply chains in a globalized economy.</li>
<li>Evaluate the long-term effects of the pandemic on the semiconductor industry and global technology markets.</li>
</ol>
</section>
</section>
<section id="the-taiwan-dilemma" class="level2">
<h2 class="anchored" data-anchor-id="the-taiwan-dilemma">The Taiwan Dilemma</h2>
<p>Chapter 54 discusses the geopolitical tensions surrounding Taiwan, focusing on its critical role in the global semiconductor industry. The chapter highlights TSMC (Taiwan Semiconductor Manufacturing Company), the world’s largest contract chipmaker, as a central figure in these tensions. It delves into the risks posed by China’s increasing military activities near Taiwan and the potential implications of a conflict for the global semiconductor supply chain. The narrative explores various scenarios of how a conflict over Taiwan could unfold, emphasizing the strategic importance of the island due to its semiconductor production capabilities and the global reliance on these technologies.</p>
<section id="ideas-5" class="level3">
<h3 class="anchored" data-anchor-id="ideas-5">Ideas</h3>
<ol type="1">
<li>TSMC’s pivotal role in the global semiconductor industry makes Taiwan a focal point in U.S.-China geopolitical tensions.</li>
<li>China’s military activities near Taiwan, including exercises and drills, heighten the risk of conflict and global economic disruption.</li>
<li>The potential scenarios for a conflict over Taiwan range from a full-scale invasion to limited military pressure.</li>
<li>The global economy’s dependency on Taiwan’s semiconductor industry is a significant factor in the geopolitical calculus of the U.S. and China.</li>
<li>The chapter discusses the strategic importance of TSMC’s chip manufacturing facilities and the risks posed by their location in a geopolitically sensitive area.</li>
<li>A conflict involving Taiwan could severely disrupt global semiconductor supply chains, impacting a wide range of industries.</li>
<li>The U.S. and China’s military strategies in the region are influenced by the strategic value of Taiwan’s semiconductor production.</li>
<li>The chapter examines the challenges in ensuring the security of Taiwan and its semiconductor industry.</li>
<li>The implications of Taiwan’s geopolitical situation extend beyond military concerns to global technological and economic stability.</li>
<li>The narrative explores the complex interplay between global technology markets, military strategy, and geopolitical dynamics centered around Taiwan.</li>
</ol>
</section>
<section id="facts-5" class="level3">
<h3 class="anchored" data-anchor-id="facts-5">Facts</h3>
<ol type="1">
<li>Taiwan, home to TSMC, is crucial to the global semiconductor industry.</li>
<li>The island is a focal point in the geopolitical tensions between the U.S. and China.</li>
<li>China’s military activities near Taiwan raise the risk of conflict.</li>
<li>The global economy heavily depends on Taiwan’s semiconductor production.</li>
<li>TSMC is the largest contract chipmaker in the world.</li>
<li>A conflict involving Taiwan could disrupt global semiconductor supply chains.</li>
<li>The U.S. and China’s military strategies consider the strategic value of Taiwan’s semiconductor industry.</li>
<li>Taiwan’s geopolitical situation is complex and has far-reaching implications.</li>
<li>The security of Taiwan’s semiconductor industry is a significant global concern.</li>
<li>The stability of global technology markets is closely tied to Taiwan’s geopolitical situation.</li>
</ol>
</section>
<section id="recommendations-5" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-5">Recommendations</h3>
<ol type="1">
<li>Study the strategic implications of Taiwan’s role in the global semiconductor industry.</li>
<li>Analyze the potential impact of geopolitical tensions involving Taiwan on</li>
</ol>
<p>global technology markets.</p>
<ol start="3" type="1">
<li>Explore the scenarios and consequences of a military conflict over Taiwan.</li>
<li>Assess the global economic risks associated with disruptions in Taiwan’s semiconductor production.</li>
<li>Investigate the strategies of the U.S. and China regarding Taiwan and its semiconductor industry.</li>
<li>Examine the challenges in ensuring the security and stability of Taiwan’s semiconductor supply chain.</li>
<li>Consider the broader implications of Taiwan’s geopolitical situation for global technology and economic stability.</li>
<li>Reflect on the interplay of military strategy, technology markets, and geopolitics in the context of Taiwan.</li>
<li>Understand the complexities of managing global technology supply chains in a geopolitically sensitive environment.</li>
<li>Evaluate the long-term effects of Taiwan’s situation on global semiconductor production and technology leadership.</li>
</ol>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>history</category>
  <guid>christianjmills.com/posts/chip-war-book-notes/part-8/</guid>
  <pubDate>Tue, 21 Nov 2023 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Chip War Part 7: China’s Challenge</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/chip-war-book-notes/part-7/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/chip-war-book-notes.html"><strong>Chip War: The Fight for the World’s Most Critical Technology</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>Made in China</li>
<li>Call Forth the Assault</li>
<li>Technology Transfer</li>
<li>“Merges Are Bound to Happen”</li>
<li>The Rise of Huawei</li>
<li>The 5G Future</li>
<li>The Next Offset</li>
</ul>
<section id="made-in-china" class="level2">
<h2 class="anchored" data-anchor-id="made-in-china">Made in China</h2>
<p>Chapter 42 explores China’s ambitious strategy to become a leader in the global semiconductor industry. The chapter delves into Xi Jinping’s policies emphasizing cybersecurity and informatization as pillars of national security and modernization. It highlights China’s reliance on foreign technologies, especially in semiconductors, despite its success in building large Internet companies. Xi’s efforts to reduce this dependence and achieve technological self-reliance are discussed, including strategies to develop domestic chip manufacturing capabilities and reduce reliance on foreign chips, particularly from the U.S. and its allies.</p>
<section id="ideas" class="level3">
<h3 class="anchored" data-anchor-id="ideas">Ideas</h3>
<ol type="1">
<li>Xi Jinping emphasized the critical importance of cybersecurity and informatization for China’s national security and modernization.</li>
<li>China’s technological development, particularly in the digital realm, was heavily reliant on imported semiconductors, despite the success of its internet companies.</li>
<li>Xi aimed to reduce China’s dependence on foreign technologies and enhance its self-reliance in core technologies, including semiconductors.</li>
<li>China’s efforts to build its semiconductor industry involved strategies like government investment, luring home trained scientists and engineers, and technology transfer partnerships.</li>
<li>The chapter illustrates China’s approach to leveraging its market size to negotiate technology transfers and training from foreign firms.</li>
<li>Xi’s policies were driven by a sense of vulnerability regarding China’s reliance on foreign, particularly American, technology.</li>
<li>The chapter discusses the disparity between China’s success in software and its reliance on foreign hardware for critical technologies.</li>
<li>China’s ambition to become a semiconductor powerhouse was part of a broader strategy to ascend to great power status and achieve national rejuvenation.</li>
<li>The semiconductor industry was seen as a key area where China could gain a competitive edge and reduce vulnerabilities in its supply chain.</li>
<li>China’s leaders recognized the strategic importance of domestically produced semiconductors in supporting its growing technological infrastructure.</li>
<li>The development of China’s semiconductor industry was seen as essential to avoid supply chain vulnerabilities and assert technological independence.</li>
<li>China’s aspiration to produce core technologies aimed to transform its economic model from low-profit manufacturing to high-value technology production.</li>
<li>The chapter reflects on China’s historical context and current strategies to develop a competitive semiconductor industry.</li>
<li>Xi Jinping’s leadership was pivotal in driving China’s focus on technological development, particularly in semiconductors.</li>
<li>The chapter underscores the geopolitical implications of China’s pursuit of semiconductor independence and its impact on global technology dynamics.</li>
</ol>
</section>
<section id="facts" class="level3">
<h3 class="anchored" data-anchor-id="facts">Facts</h3>
<ol type="1">
<li>Xi Jinping emphasized the importance of cybersecurity and informatization for China’s national security.</li>
<li>China’s digital economy and technological advancements are heavily reliant on imported semiconductors.</li>
<li>China aims to reduce its dependence on foreign technologies and enhance self-reliance in semiconductors.</li>
<li>Strategies to develop China’s semiconductor industry include government investment, talent repatriation, technology transfer, and leveraging market size.</li>
<li>China’s reliance on foreign technology is seen as a vulnerability and a barrier to achieving greater economic and technological independence.</li>
<li>Xi Jinping’s leadership focused on transforming China’s economic model to high-value technology production.</li>
<li>The development of a domestic semiconductor industry is a strategic priority for China.</li>
<li>China’s pursuit of semiconductor independence has significant geopolitical implications.</li>
</ol>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<ol type="1">
<li>Study the strategic importance of cybersecurity and informatization in national security policies, particularly in China.</li>
<li>Analyze the implications of China’s reliance on imported semiconductors and its efforts to develop domestic capabilities.</li>
<li>Explore the geopolitical and economic impacts of China’s ambition to become a semiconductor powerhouse.</li>
<li>Assess the effectiveness of China’s strategies to develop its semiconductor industry, including government investment and technology partnerships.</li>
<li>Consider the role of leadership in driving national technological agendas, as exemplified by Xi Jinping’s focus on semiconductors.</li>
<li>Reflect on the global implications of China’s pursuit of technological self-reliance and independence.</li>
<li>Investigate the challenges and opportunities in China’s transformation from a manufacturing-based economy to a technology-driven one.</li>
<li>Examine the impact of China’s technological ambitions on global supply chains and trade dynamics.</li>
<li>Understand the broader context of China’s technological development within its national rejuvenation goals.</li>
<li>Evaluate the potential outcomes of China’s efforts to achieve semiconductor independence on the global technology landscape.</li>
</ol>
</section>
</section>
<section id="call-forth-the-assault" class="level2">
<h2 class="anchored" data-anchor-id="call-forth-the-assault">Call Forth the Assault</h2>
<p>Chapter 43 discusses China’s ambitious goal to achieve semiconductor independence under Xi Jinping’s leadership. It contrasts Xi’s international rhetoric of economic openness with his domestic emphasis on self-reliance in core technologies, particularly semiconductors. The chapter outlines China’s heavy reliance on imported chips, despite its significant advancements in the digital realm. Xi’s call for a technological assault emphasizes the urgency to develop domestic chip production capabilities, reduce foreign dependence, and gain a competitive edge in the global market.</p>
<section id="ideas-1" class="level3">
<h3 class="anchored" data-anchor-id="ideas-1">Ideas</h3>
<ol type="1">
<li>Xi Jinping’s vision for China includes a strong emphasis on cybersecurity and informatization as pillars of national security.</li>
<li>Despite its success in creating large internet companies, China remains heavily reliant on imported semiconductors.</li>
<li>Xi aims to reduce China’s dependence on foreign technology, particularly in the semiconductor sector.</li>
<li>The chapter details China’s strategies to develop its semiconductor industry, including attracting talent, forming technology partnerships, and leveraging its market size.</li>
<li>Xi’s rhetoric underscores a vulnerability and strategic need to build more chips domestically.</li>
<li>The disparity between China’s software success and hardware dependence is highlighted.</li>
<li>China’s ambition to become a semiconductor leader is part of a broader strategy for national rejuvenation and technological independence.</li>
<li>The chapter discusses the importance of domestically produced semiconductors for China’s growing technological infrastructure.</li>
<li>China’s efforts to produce core technologies aim to transform its economy from low-profit manufacturing to high-tech production.</li>
<li>The geopolitical implications of China’s push for semiconductor independence are explored, emphasizing its impact on global technology dynamics.</li>
</ol>
</section>
<section id="facts-1" class="level3">
<h3 class="anchored" data-anchor-id="facts-1">Facts</h3>
<ol type="1">
<li>Xi Jinping has placed significant emphasis on cybersecurity and informatization for China’s national security.</li>
<li>China heavily relies on imported semiconductors, despite having large internet companies.</li>
<li>Xi is focused on reducing China’s dependence on foreign technology and enhancing self-reliance in semiconductors.</li>
<li>China’s strategies for developing its semiconductor industry involve government investment, technology transfer partnerships, and leveraging its market size.</li>
<li>There is a strategic need for China to increase its domestic chip production.</li>
<li>China’s semiconductor ambition is part of its broader strategy for national rejuvenation.</li>
<li>The development of China’s semiconductor industry is seen as essential to avoid supply chain vulnerabilities.</li>
<li>China aims to transform from a low-profit manufacturing economy to a high-tech production model.</li>
<li>The geopolitical implications of China’s semiconductor independence efforts are significant.</li>
</ol>
</section>
<section id="recommendations-1" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-1">Recommendations</h3>
<ol type="1">
<li><p>Examine the strategic importance of cybersecurity and informatization in national security, with a focus on China’s policies.</p></li>
<li><p>Analyze the challenges and strategies in reducing China’s reliance on imported semiconductors and achieving technological self-reliance.</p></li>
<li><p>Investigate the geopolitical and economic impacts of China’s ambition to become a global semiconductor leader.</p></li>
<li><p>Explore the implications of China’s heavy dependence on foreign chips for its technological infrastructure.</p></li>
<li><p>Consider the role of leadership in shaping national technology agendas, using Xi Jinping’s focus on semiconductors as a case study.</p></li>
<li><p>Assess the impact of China’s technological ambitions on global supply chains and trade dynamics.</p></li>
<li><p>Study the effectiveness of China’s strategies in developing its semiconductor industry, including talent attraction and technology partnerships.</p></li>
<li><p>Reflect on the broader context of China’s technological development and its impact on global technology dynamics.</p></li>
<li><p>Understand the challenges in transforming China’s economy from manufacturing-based to technology-driven.</p></li>
<li><p>Evaluate the potential outcomes of China’s efforts to achieve semiconductor independence and its implications for the global technology landscape.</p></li>
</ol>
</section>
</section>
<section id="technology-transfer" class="level2">
<h2 class="anchored" data-anchor-id="technology-transfer">Technology Transfer</h2>
<p>Chapter 44 discusses the complex dynamics of technology transfer between U.S. tech firms and China. It focuses on China’s efforts to gain access to advanced semiconductor technology, highlighting the strategies employed by major U.S. companies like IBM, Qualcomm, and AMD in navigating this landscape. The chapter sheds light on the delicate balance these companies struck between accessing the lucrative Chinese market and protecting their technological assets. It also touches on the geopolitical implications of these technology transfers and their impact on the global semiconductor industry.</p>
<section id="ideas-2" class="level3">
<h3 class="anchored" data-anchor-id="ideas-2">Ideas</h3>
<ol type="1">
<li>China’s strategy to become a semiconductor leader involves acquiring technology from foreign companies.</li>
<li>U.S. tech firms, like IBM, Qualcomm, and AMD, have engaged in various forms of technology transfer with China.</li>
<li>IBM’s approach included offering semiconductor technology to enhance cooperation in integrated circuit development with Chinese partners.</li>
<li>Qualcomm’s joint venture with a Chinese company to develop server chips represented a strategic move to gain a foothold in China’s market.</li>
<li>AMD’s controversial deal to license the production of modified x86 chips for the Chinese market exemplifies the complexities of technology transfer.</li>
<li>The chapter highlights the challenges faced by U.S. companies in balancing business interests with national security concerns.</li>
<li>Intel’s reluctance to engage in similar deals with China contrasts with other American firms’ strategies.</li>
<li>China’s strong-arming tactics to pressure U.S. companies into technology transfers are discussed.</li>
<li>The chapter explores the broader implications of technology transfers on U.S. competitiveness and China’s semiconductor ambitions.</li>
<li>The geopolitical tension arising from these technology transfers and their impact on the U.S.-China technological rivalry is a key theme.</li>
</ol>
</section>
<section id="facts-2" class="level3">
<h3 class="anchored" data-anchor-id="facts-2">Facts</h3>
<ol type="1">
<li>China is aggressively pursuing technology transfer to develop its semiconductor industry.</li>
<li>U.S. tech firms, including IBM, Qualcomm, and AMD, have engaged in technology transfer with Chinese entities.</li>
<li>IBM’s strategy involved offering semiconductor technology to Chinese partners for integrated circuit development.</li>
<li>Qualcomm’s joint venture in China was aimed at developing server chips.</li>
<li>AMD’s deal to license x86 chip production in China was controversial and seen as a risk to U.S. interests.</li>
<li>U.S. companies face challenges in balancing market access in China with national security concerns.</li>
<li>China employs strong-arming tactics to acquire foreign technology.</li>
<li>The technology transfers are part of China’s broader strategy to reduce dependence on foreign semiconductors.</li>
<li>These activities have significant implications for the global semiconductor industry and U.S.-China relations.</li>
<li>The impact of these technology transfers extends to geopolitical tensions and the technological rivalry between the U.S. and China.</li>
</ol>
</section>
<section id="recommendations-2" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-2">Recommendations</h3>
<ol type="1">
<li>Analyze the strategic motivations behind China’s pursuit of foreign semiconductor technology.</li>
<li>Study the approaches of U.S. tech firms like IBM, Qualcomm, and AMD in managing technology transfer to China.</li>
<li>Examine the balance between market access and technological protection for U.S. companies in China.</li>
<li>Assess the</li>
</ol>
<p>geopolitical implications of technology transfers in the U.S.-China semiconductor rivalry.</p>
<ol start="5" type="1">
<li>Investigate the impact of these transfers on global semiconductor industry dynamics.</li>
<li>Explore the challenges and opportunities faced by U.S. tech firms in the Chinese market.</li>
<li>Consider the role of national security concerns in shaping U.S. tech firms’ strategies in China.</li>
<li>Reflect on the broader implications of China’s semiconductor ambitions for global technology leadership.</li>
<li>Understand the complexities of U.S.-China relations in the context of technology transfers.</li>
<li>Evaluate the long-term effects of these technology transfers on the competitiveness of the U.S. semiconductor industry.</li>
</ol>
</section>
</section>
<section id="merges-are-bound-to-happen" class="level2">
<h2 class="anchored" data-anchor-id="merges-are-bound-to-happen">“Merges Are Bound to Happen”</h2>
<p>Chapter 45 covers Zhao Weiguo’s journey from a rural upbringing to becoming a chip billionaire in China. Zhao, who attended Tsinghua University, later shifted from a technical role to investment, eventually leading Tsinghua Uni Group. The group, linked to the university, was involved in various investments, including real estate, but later focused on semiconductor technology. Zhao’s aggressive strategy in the semiconductor industry involved acquiring several Chinese and international chip companies, reflecting China’s broader ambition to become a global leader in this field. His actions aligned with Xi Jinping’s call for technological self-reliance, especially in semiconductors.</p>
<section id="ideas-3" class="level3">
<h3 class="anchored" data-anchor-id="ideas-3">Ideas</h3>
<ol type="1">
<li>Zhao Weiguo’s rise from a rural background to a leading figure in China’s semiconductor industry.</li>
<li>Tsinghua Uni Group’s transformation under Zhao from a university-affiliated investment group to a major player in the semiconductor sector.</li>
<li>The strategic acquisitions of Chinese and foreign semiconductor firms by Tsinghua Uni Group as part of China’s national priority in chip technology.</li>
<li>Zhao’s partnership with Intel aimed at combining wireless modem and smartphone processor technologies.</li>
<li>The aggressive investment and expansion approach of Tsinghua Uni Group in the semiconductor industry, including a failed bid for Micron and other U.S. firms.</li>
<li>The geopolitical and economic implications of China’s push for semiconductor independence and its impact on global technology dynamics.</li>
<li>Zhao’s role in aligning Tsinghua Uni Group’s strategies with Xi Jinping’s national directive for technological self-reliance.</li>
<li>The challenges and controversies surrounding Tsinghua Uni Group’s investments and acquisitions in the semiconductor industry.</li>
<li>The broader context of China’s state-backed investment strategies in pursuing global semiconductor leadership.</li>
<li>Zhao’s perspective on the inevitability of mergers between big U.S. and Chinese companies in the semiconductor sector.</li>
</ol>
</section>
<section id="facts-3" class="level3">
<h3 class="anchored" data-anchor-id="facts-3">Facts</h3>
<ol type="1">
<li>Zhao Weiguo rose from a humble background to lead Tsinghua Uni Group.</li>
<li>Tsinghua Uni Group shifted its focus under Zhao to become a key player in the semiconductor industry.</li>
<li>The group made strategic acquisitions and investments in the semiconductor sector, both domestically and internationally.</li>
<li>Zhao’s approach aligned with Xi Jinping’s directive for China to achieve technological self-reliance.</li>
<li>Tsinghua Uni Group’s strategies in the semiconductor industry reflect China’s broader national ambitions.</li>
<li>The group’s investment activities have significant geopolitical and economic implications.</li>
<li>China’s pursuit of semiconductor independence has led to aggressive investment and acquisition strategies.</li>
<li>Tsinghua Uni Group’s activities in the semiconductor sector have been controversial and faced challenges.</li>
<li>The push for semiconductor independence is part of China’s larger goal to become a global technology leader.</li>
<li>Zhao Weiguo’s actions in the semiconductor industry are reflective of the Chinese government’s strategic objectives.</li>
</ol>
</section>
<section id="resources" class="level3">
<h3 class="anchored" data-anchor-id="resources">Resources</h3>
<ol type="1">
<li>Person: Zhao Weiguo and his leadership in China’s semiconductor industry.</li>
<li>Company: Tsinghua Uni Group and its role in China’s semiconductor strategy.</li>
<li>Industry Trend: China’s national priority in semiconductor technology.</li>
<li>Geopolitical Context: The implications of China’s semiconductor strategy on global technology dynamics.</li>
<li>Economic Strategy: China’s investment and acquisition strategies in the semiconductor sector.</li>
<li>Technology: The importance of semiconductors in China’s technological infrastructure.</li>
<li>Market Dynamics: The global semiconductor industry and China’s role in it.</li>
<li>National Policy: China’s directive for technological self-reliance and its impact on the semiconductor industry.</li>
<li>Industry Evolution: The changing landscape of the global semiconductor industry due to China’s strategies.</li>
<li>Geopolitical Implications: The impact of China’s actions in the semiconductor sector on international relations and trade.</li>
</ol>
</section>
<section id="recommendations-3" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-3">Recommendations</h3>
<ol type="1">
<li><p>Study the impact of individual leadership, like Zhao Weiguo’s, on national technology strategies.</p></li>
<li><p>Analyze the role of companies like Tsinghua Uni Group in shaping China’s semiconductor industry.</p></li>
<li><p>Explore the geopolitical and economic implications of China’s aggressive semiconductor strategy.</p></li>
<li><p>Assess the impact of China’s push for semiconductor independence on global technology dynamics.</p></li>
<li><p>Investigate the broader context of China’s state-backed investment strategies in the semiconductor sector.</p></li>
<li><p>Consider the challenges and controversies surrounding investment and acquisition strategies in the semiconductor industry.</p></li>
<li><p>Reflect on the global implications of China’s pursuit of semiconductor leadership.</p></li>
<li><p>Understand the complexities of national directives like technological self-reliance in shaping industry strategies.</p></li>
<li><p>Examine the role of China in the global semiconductor industry and its impact on market dynamics.</p></li>
<li><p>Evaluate the long-term effects of China’s semiconductor strategies on international technology leadership and competition.</p></li>
</ol>
</section>
</section>
<section id="the-rise-of-huawei" class="level2">
<h2 class="anchored" data-anchor-id="the-rise-of-huawei">The Rise of Huawei</h2>
<p>Chapter 46 delves into the story of Ren Zhengfei and the growth of Huawei as a global technology powerhouse. The chapter outlines Huawei’s journey from a small telecom equipment provider to one of the world’s largest providers of mobile internet infrastructure and smartphones. It highlights Huawei’s strategy of producing high-quality technology at lower costs and its aggressive global expansion. The chapter also discusses the controversies surrounding Huawei, including allegations of intellectual property theft and its complex relationship with the Chinese government.</p>
<section id="ideas-4" class="level3">
<h3 class="anchored" data-anchor-id="ideas-4">Ideas</h3>
<ol type="1">
<li>Ren Zhengfei’s transformation of Huawei from a small importer of telecom switches to a global technology leader.</li>
<li>Huawei’s role in the global telecom infrastructure, rivalling giants like Nokia and Ericsson.</li>
<li>The company’s success in the smartphone market, competing with Apple and Samsung.</li>
<li>Allegations of intellectual property theft and espionage against Huawei, contributing to its controversial reputation.</li>
<li>Huawei’s adoption of efficient manufacturing processes and emphasis on R&amp;D spending.</li>
<li>The company’s unique business model, differing significantly from other Chinese tech firms.</li>
<li>Huawei’s global orientation, contrasting with the domestic focus of other Chinese tech giants.</li>
<li>The impact of Western consulting firms, particularly IBM, on Huawei’s development and business processes.</li>
<li>The role of the Chinese government in supporting Huawei’s expansion.</li>
<li>Huawei’s investment in R&amp;D, positioning it as a major player in the tech ecosystem.</li>
</ol>
</section>
<section id="facts-4" class="level3">
<h3 class="anchored" data-anchor-id="facts-4">Facts</h3>
<ol type="1">
<li>Huawei, founded by Ren Zhengfei, grew from a small telecom equipment importer to a global tech leader.</li>
<li>Huawei competes globally in the mobile internet infrastructure and smartphone markets.</li>
<li>The company has been embroiled in controversies, including allegations of intellectual property theft.</li>
<li>Huawei is known for its efficient manufacturing processes and high R&amp;D expenditure.</li>
<li>The company’s business model and global orientation differ from other Chinese tech firms.</li>
<li>Huawei received support from Western consulting firms like IBM and the Chinese government.</li>
<li>The company’s R&amp;D investment positions it as a key player in the global tech ecosystem.</li>
</ol>
</section>
<section id="recommendations-4" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-4">Recommendations</h3>
<ol type="1">
<li>Study the transformation of Huawei from a regional player to a global tech leader.</li>
<li>Analyze Huawei’s strategies for competing in the global telecom and smartphone markets.</li>
<li>Investigate the controversies surrounding Huawei, including intellectual property issues.</li>
<li>Explore the impact of R&amp;D investment on Huawei’s growth and market position.</li>
<li>Examine the role of government support and international partnerships in Huawei’s expansion.</li>
<li>Assess the unique business model of Huawei and its differentiation from other Chinese tech firms.</li>
<li>Consider the implications of Huawei’s growth for global tech dynamics and competition.</li>
<li>Reflect on the lessons from Huawei’s adoption of Western business practices.</li>
<li>Understand the geopolitical context of Huawei’s expansion and the responses from various governments.</li>
<li>Evaluate the long-term impact of Huawei’s strategies on the global technology landscape.</li>
</ol>
</section>
</section>
<section id="the-5g-future" class="level2">
<h2 class="anchored" data-anchor-id="the-5g-future">The 5G Future</h2>
<p>Chapter 47 explores the evolution and significance of 5G technology, focusing on its transformative impact on computing and the pivotal role of semiconductors. The chapter traces the history of mobile networking from its early stages to the advanced 5G networks, emphasizing the steady increase in data transmission capabilities. It discusses how 5G technology, driven by sophisticated semiconductors, is not just about improving phone capabilities but reshaping the landscape of mobile computing and connectivity. The chapter also highlights the role of companies like Huawei and Tesla in integrating advanced semiconductors into their products, illustrating the broader implications of 5G technology in various industries.</p>
<section id="ideas-5" class="level3">
<h3 class="anchored" data-anchor-id="ideas-5">Ideas</h3>
<ol type="1">
<li>5G technology represents a significant leap in mobile networking, enhancing data transmission capabilities and reshaping mobile computing.</li>
<li>The evolution of mobile networks from 1G to 5G reflects the steady increase in data transmission and the growing complexity of technology.</li>
<li>Advanced semiconductors are fundamental to the functioning of 5G networks, enabling more efficient data transmission and processing.</li>
<li>5G networks will facilitate a broader range of applications, including the Internet of Things (IoT), by connecting a vast array of devices.</li>
<li>The chapter discusses the transformative impact of 5G on industries like automotive, agriculture, and healthcare, where data collection and processing are crucial.</li>
<li>Huawei’s leading role in 5G technology development and deployment is highlighted, despite the controversies surrounding the company.</li>
<li>Tesla’s use of custom-designed chips for its electric and autonomous vehicles is an example of the growing integration of advanced semiconductors in various products.</li>
<li>The chapter explores the geopolitical implications of the race for 5G dominance, particularly between China and the U.S.</li>
<li>5G technology is expected to drive significant changes in consumer behavior and expectations regarding mobile and connected devices.</li>
<li>The development of 5G networks is seen as a critical factor in the future of global connectivity and technological advancement.</li>
</ol>
</section>
<section id="facts-5" class="level3">
<h3 class="anchored" data-anchor-id="facts-5">Facts</h3>
<ol type="1">
<li>5G technology represents a major advancement in mobile networking, offering significantly enhanced data transmission capabilities.</li>
<li>The evolution of mobile networks from 1G to 5G has been marked by increasing complexity and data transmission efficiency.</li>
<li>Semiconductors play a crucial role in the functioning and advancement of 5G networks.</li>
<li>5G technology is expected to transform various industries by enabling the connection of a wide range of devices and facilitating data-intensive applications.</li>
<li>Companies like Huawei and Tesla are integrating advanced semiconductors into their products, demonstrating the impact of 5G in different sectors.</li>
<li>The development of 5G technology has significant geopolitical implications, particularly in the context of the U.S.-China technology race.</li>
<li>The deployment of 5G networks is poised to change consumer behaviors and expectations regarding mobile and connected technologies.</li>
<li>The future of global connectivity and technological progress is closely tied to the development and implementation of 5G networks.</li>
</ol>
</section>
<section id="recommendations-5" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-5">Recommendations</h3>
<ol type="1">
<li>Study the technological advancements and implications of 5G mobile networking.</li>
<li>Analyze the role of semiconductors in the development and functioning of 5G networks.</li>
<li>Explore the impact of 5G on various industries and its potential to transform consumer behavior.</li>
<li>Investigate the geopolitical dynamics surrounding the global race for 5G technology dominance.</li>
<li>Examine the integration of advanced semiconductor technology in products like electric vehicles and smartphones.</li>
<li>Assess the future prospects of global connectivity and technological advancement in the 5G era.</li>
<li>Consider the economic and strategic implications of companies like Huawei and Tesla in the 5G landscape.</li>
<li>Reflect on the changing consumer expectations and market dynamics in the context of 5G deployment.</li>
<li>Understand the potential of 5G technology in driving significant changes in industries such as healthcare, agriculture, and automotive.</li>
<li>Evaluate the long-term effects of 5G technology on global technological progress and connectivity.</li>
</ol>
</section>
</section>
<section id="the-next-offset" class="level2">
<h2 class="anchored" data-anchor-id="the-next-offset">The Next Offset</h2>
<p>Chapter 48 discusses the evolving nature of warfare and the crucial role of computing power in modern military strategy. It focuses on how advancements in semiconductors and artificial intelligence (AI) are reshaping the dynamics of global military power, particularly between the U.S. and China. The chapter details China’s investment in high-tech weaponry and its efforts to match or surpass U.S. capabilities in areas like AI and cybersecurity. It also highlights the importance of semiconductor technology in various military applications, from autonomous drones to cyber warfare, and the strategic implications of these developments.</p>
<section id="ideas-6" class="level3">
<h3 class="anchored" data-anchor-id="ideas-6">Ideas</h3>
<ol type="1">
<li>Modern warfare is increasingly defined by computing power, with semiconductors playing a central role.</li>
<li>China has heavily invested in high-tech weaponry, aiming to offset U.S. military advantages.</li>
<li>The development and deployment of AI in military systems are a key focus for both the U.S. and China.</li>
<li>Semiconductor technology underpins various advanced military applications, including autonomous drones and cyber warfare capabilities.</li>
<li>The U.S. military’s historical technological edge is being challenged by China’s advancements.</li>
<li>China’s military strategies involve leveraging AI and computing power to gain a competitive advantage.</li>
<li>The chapter discusses the geopolitical ramifications of the race for technological superiority in military applications.</li>
<li>The U.S. seeks to maintain its military advantage through innovation in AI and autonomous systems.</li>
<li>China’s approach to military modernization reflects its broader ambitions for global technological leadership.</li>
<li>The intersection of military needs and semiconductor technology highlights the strategic importance of chip manufacturing and design.</li>
</ol>
</section>
<section id="facts-6" class="level3">
<h3 class="anchored" data-anchor-id="facts-6">Facts</h3>
<ol type="1">
<li>The nature of warfare is evolving, with a growing emphasis on computing power and technology.</li>
<li>China’s military modernization includes a focus on high-tech weaponry and AI.</li>
<li>The U.S. and China are engaged in a strategic race to develop advanced military technologies.</li>
<li>Semiconductors are crucial in various military technologies, including drones and cyber warfare systems.</li>
<li>The U.S. military’s technological superiority is being challenged by China’s advancements.</li>
<li>AI and computing power are central to modern military strategies and capabilities.</li>
<li>The global military balance is influenced by advancements in semiconductor technology.</li>
<li>China’s military strategies are part of its broader ambition for technological and geopolitical leadership.</li>
<li>The U.S. seeks to maintain its military edge through innovation in technology.</li>
<li>The race for technological superiority in military applications has significant geopolitical implications.</li>
</ol>
</section>
<section id="recommendations-6" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-6">Recommendations</h3>
<ol type="1">
<li>Study the impact of computing power and AI on the evolution of modern warfare.</li>
<li>Analyze the strategic importance of semiconductors in military technology.</li>
<li>Explore the geopolitical implications of the U.S.-China rivalry in military technology development.</li>
<li>Assess the role of technological advancements in shaping global military power dynamics.</li>
<li>Investigate the significance of AI and autonomous systems in military strategies.</li>
<li>Consider the challenges and opportunities in developing advanced military technologies.</li>
<li>Examine the impact of organizations like DARPA</li>
</ol>
<p>on innovation in military technology.</p>
<ol start="8" type="1">
<li>Reflect on the global competition for technological superiority in military applications.</li>
<li>Understand the strategic implications of military technology advancements for national security.</li>
<li>Evaluate the long-term effects of the race for technological dominance on global military balance and security.</li>
</ol>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>history</category>
  <guid>christianjmills.com/posts/chip-war-book-notes/part-7/</guid>
  <pubDate>Tue, 21 Nov 2023 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Chip War Part 6: Offshore Innovation?</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/chip-war-book-notes/part-6/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/chip-war-book-notes.html"><strong>Chip War: The Fight for the World’s Most Critical Technology</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>“Real Men Have Fabs”</li>
<li>The Fabless Revolution</li>
<li>Morris Chang’s Grand Alliance</li>
<li>Apple Silicon</li>
<li>EUV</li>
<li>There Is No Plan B</li>
<li>How Intel Forgot Innovation</li>
</ul>
<section id="real-men-have-fabs" class="level2">
<h2 class="anchored" data-anchor-id="real-men-have-fabs">“Real Men Have Fabs”</h2>
<p>Chapter 35 explores Jerry Sanders’ philosophy regarding semiconductor fabrication. Sanders, the founder of AMD, strongly believed in the importance of maintaining in-house manufacturing capabilities, contrasting with the rising trend of outsourcing to foundries like TSMC. The chapter discusses the economic and strategic implications of this philosophy, highlighting the evolution of the semiconductor industry and the shift towards fabless manufacturing.</p>
<section id="ideas" class="level3">
<h3 class="anchored" data-anchor-id="ideas">Ideas</h3>
<ol type="1">
<li><strong>Sanders’ Belief in In-house Manufacturing</strong>: Jerry Sanders’ strong stance on the strategic importance of owning semiconductor fabrication plants.</li>
<li><strong>Shift to Outsourcing with Foundries like TSMC</strong>: The significant industry shift towards outsourcing manufacturing to foundries.</li>
<li><strong>Challenges of Maintaining Fabs</strong>: The economic and technological hurdles of sustaining fabs, particularly with increasing costs.</li>
<li><strong>Contrast with Fabless Trend</strong>: Sanders’ philosophy as a contrast to the emerging trend of fabless companies focusing on design and outsourcing production.</li>
<li><strong>Evolution Reflecting Globalization and Strategic Models</strong>: How the semiconductor industry’s evolution mirrors broader trends in globalization and strategic business approaches.</li>
<li><strong>Differing Views on Competitiveness and Innovation</strong>: The varied perspectives on the best path to competitiveness in the semiconductor industry, whether through maintaining or divesting fabs.</li>
<li><strong>Importance of Control Over Production</strong>: Sanders’ approach emphasizing control over the manufacturing process.</li>
<li><strong>Fabless Model and Design Innovation</strong>: How the fabless business model enables a focus on design innovation without manufacturing complexities.</li>
<li><strong>Shift to Fabless Manufacturing Impacting Innovation</strong>: The significant change in innovation and production approaches with the industry’s move to fabless manufacturing.</li>
<li><strong>Economic Implications of Fabs</strong>: Discussion of the high costs and risks associated with maintaining fabs.</li>
</ol>
</section>
<section id="facts" class="level3">
<h3 class="anchored" data-anchor-id="facts">Facts</h3>
<ol type="1">
<li>Jerry Sanders, founder of AMD, was known for his strong belief in the importance of owning semiconductor fabs.</li>
<li>The rise of foundries like TSMC marked a significant shift in the semiconductor industry towards outsourcing manufacturing.</li>
<li>Maintaining semiconductor fabs became increasingly expensive with each generation of technological improvement.</li>
<li>The fabless business model, focusing on chip design and outsourcing manufacturing, emerged as a significant trend in the semiconductor industry.</li>
<li>The chapter discusses the strategic and economic considerations in the decision to maintain or divest fabs in the semiconductor industry.</li>
<li>Texas Instruments is highlighted as the biggest analog chip maker today.</li>
<li>The memory market, particularly DRAM and NAND, has seen a push towards offshoring production, primarily in East Asia.</li>
<li>The number of firms capable of fabricating advanced logic chips has decreased due to the high costs and technological complexities involved.</li>
<li>The shift towards fabless manufacturing represents a broader trend of specialization and efficiency in the global economy.</li>
</ol>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<ol type="1">
<li>Analyze the strategic implications of owning versus outsourcing semiconductor fabrication facilities.</li>
<li>Explore the economic and technological challenges associated with maintaining fabs in the semiconductor industry.</li>
<li>Consider the impact of the fabless business model on innovation and competitiveness in the semiconductor industry.</li>
<li>Study the evolution of the semiconductor industry, particularly the shift towards fabless manufacturing and its broader implications.</li>
<li>Reflect on the decisions of traditional semiconductor companies like AMD in contrast to new fabless companies.</li>
<li>Investigate the role of foundries like TSMC in transforming the semiconductor manufacturing landscape.</li>
<li>Assess the strategic and economic considerations of offshoring production in the semiconductor industry.</li>
<li>Examine the implications of the increasing cost and complexity of semiconductor fabrication on industry dynamics.</li>
<li>Understand the broader trends of specialization and efficiency in the global economy as exemplified by the semiconductor industry.</li>
<li>Consider the perspectives of industry figures like Jerry Sanders on the future of manufacturing and innovation in semiconductors.</li>
</ol>
</section>
</section>
<section id="the-fabless-revolution" class="level2">
<h2 class="anchored" data-anchor-id="the-fabless-revolution">The Fabless Revolution</h2>
<p>Chapter 36 discusses the rise of fabless semiconductor companies in Silicon Valley. It chronicles the journey of companies like Nvidia and Qualcomm, which designed chips in-house but outsourced manufacturing, primarily to TSMC. The chapter highlights the impact of this model on the semiconductor industry, emphasizing the shift from traditional fabrication methods to innovative approaches in chip design and the strategic use of foundries.</p>
<section id="ideas-1" class="level3">
<h3 class="anchored" data-anchor-id="ideas-1">Ideas</h3>
<ol type="1">
<li><strong>Rise of the Fabless Semiconductor Model</strong>: The revolution in the industry led by companies like Nvidia and Qualcomm focusing on in-house design and outsourcing manufacturing.</li>
<li><strong>Innovation and Growth through Fabless Model</strong>: This model’s contribution to rapid growth and innovation in the semiconductor sector, particularly in fields like computer graphics and mobile communications.</li>
<li><strong>Emphasis on Design Over Manufacturing</strong>: The significant operational change in semiconductor companies, emphasizing design rather than traditional manufacturing.</li>
<li><strong>Success of Nvidia in GPUs</strong>: The potential of the fabless model demonstrated by Nvidia’s achievements in graphics processor units.</li>
<li><strong>Qualcomm’s Mobile Communications Technology</strong>: The company’s pivotal role in advancing mobile communications technology through the fabless model.</li>
<li><strong>Democratization of Chip Design</strong>: How the emergence of fabless companies lowered barriers for startups and encouraged competition.</li>
<li><strong>Leveraging Manufacturing Expertise of Foundries</strong>: The ability of companies to focus on design and innovation while utilizing the manufacturing capabilities of foundries like TSMC.</li>
<li><strong>Importance of Parallel Processing</strong>: Nvidia’s expansion beyond graphics into applications like CUDA software.</li>
<li><strong>Rapid Innovation in Mobile Phone Technology</strong>: Qualcomm’s success in mobile technology as a testament to the fabless model’s efficiency.</li>
<li><strong>Expansion of Semiconductor Industry Scope</strong>: The fabless revolution’s role in developing new chip categories and technologies, broadening the semiconductor industry’s impact.</li>
</ol>
</section>
<section id="facts-1" class="level3">
<h3 class="anchored" data-anchor-id="facts-1">Facts</h3>
<ol type="1">
<li><p>Nvidia and Qualcomm are examples of successful fabless semiconductor companies.</p></li>
<li><p>Nvidia specialized in GPUs for computer graphics and gaming, later expanding into parallel processing with CUDA.</p></li>
<li><p>Qualcomm played a pivotal role in the development of mobile communications technology, significantly contributing to 2G and later generations.</p></li>
<li><p>The fabless business model allowed for significant reductions in startup costs and entry barriers in the semiconductor industry.</p></li>
<li><p>The emergence of semiconductor foundries like TSMC facilitated the growth of fabless companies by providing manufacturing services.</p></li>
<li><p>Fabless companies contributed to the evolution of new computing paradigms, such as advanced mobile phones and graphics processing.</p></li>
<li><p>Field-programmable gate arrays, an innovation in chip technology, were developed by fabless companies like Xilinx and Altera.</p></li>
<li><p>The fabless model led to a democratization of chip design, enabling more companies to compete in the semiconductor industry.</p></li>
<li><p>The chapter discusses the impact of the fabless model on the global semiconductor supply chain and manufacturing landscape.</p></li>
<li><p>The success of fabless firms like Nvidia and Qualcomm highlights the shift in the semiconductor industry towards design innovation.</p></li>
</ol>
</section>
<section id="recommendations-1" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-1">Recommendations</h3>
<ol type="1">
<li>Study the strategic advantages and challenges of the fabless semiconductor model in the industry.</li>
<li>Analyze the impact of companies like Nvidia and Qualcomm on the evolution of the semiconductor sector.</li>
<li>Explore the role of foundries like TSMC in enabling the growth of fabless companies.</li>
<li>Consider the implications of the fabless model for innovation and competition in the semiconductor industry.</li>
<li>Examine the technological advancements brought about by fabless companies, especially in fields like mobile communications and graphics processing.</li>
<li>Assess the economic and technological shifts that led to the rise of the fabless model in the semiconductor industry.</li>
<li>Investigate the role of new technologies like field-programmable gate arrays in the evolution of chip design.</li>
<li>Reflect on the impact of the fabless model on global semiconductor supply chains and manufacturing landscapes.</li>
<li>Understand the broader trends of specialization and efficiency in the global economy as reflected in the semiconductor industry.</li>
<li>Evaluate the long-term effects of the shift towards design-centric approaches in the semiconductor sector.</li>
</ol>
</section>
</section>
<section id="morris-changs-grand-alliance" class="level2">
<h2 class="anchored" data-anchor-id="morris-changs-grand-alliance">Morris Chang’s Grand Alliance</h2>
<p>Chapter 37 focuses on the visionary leadership of Morris Chang, the founder of TSMC. It contrasts the fading era of semiconductor pioneers like Jerry Sanders of AMD with the rise of a new generation of leaders who embraced the fabless model. The chapter highlights Chang’s strategic foresight in recognizing the potential of smartphones and his commitment to maintaining TSMC’s leadership in the foundry business, especially during the financial crisis of 2008-2009.</p>
<section id="ideas-2" class="level3">
<h3 class="anchored" data-anchor-id="ideas-2">Ideas</h3>
<ol type="1">
<li><strong>Morris Chang’s Pivotal Leadership at TSMC</strong>: Chang’s influence in transitioning the industry to a foundry-based model.</li>
<li><strong>Vision for the Impact of Mobile Devices</strong>: Anticipating the significance of mobile computing in the semiconductor sector.</li>
<li><strong>Contrast with Traditional Semiconductor Approaches</strong>: The differing approaches of companies like AMD with in-house fabrication versus TSMC’s fabless model.</li>
<li><strong>Chang’s “Grand Alliance” Strategy</strong>: Building a cooperative ecosystem through collaboration with various companies.</li>
<li><strong>Transition in Semiconductor Leadership</strong>: The shift from pioneers like Jerry Sanders to new executives with different business models.</li>
<li><strong>Strategic Investment During Economic Downturns</strong>: Chang’s decision to invest heavily during the financial crisis, reflecting his belief in the industry’s growth.</li>
<li><strong>Innovation and Capacity Expansion at TSMC</strong>: Commitment to maintaining market leadership through continuous innovation.</li>
<li><strong>Technological Advancements in Manufacturing</strong>: The shift to advanced manufacturing technologies like FinFET transistors.</li>
<li><strong>Chang’s Investment Focus Over Cost-Cutting</strong>: Prioritizing R&amp;D and capacity investment over traditional cost-cutting measures.</li>
<li><strong>TSMC’s Role as a Neutral Industry Player</strong>: Its ability to collaborate effectively without direct competition.</li>
</ol>
</section>
<section id="facts-2" class="level3">
<h3 class="anchored" data-anchor-id="facts-2">Facts</h3>
<ol type="1">
<li>Morris Chang was a visionary leader in the semiconductor industry, founding TSMC.</li>
<li>Chang’s Grand Alliance strategy involved collaboration with a wide network of companies in the semiconductor ecosystem.</li>
<li>TSMC played a central role in the shift towards the fable</li>
</ol>
<p>ss semiconductor model.</p>
<ol start="4" type="1">
<li>Chang’s strategic decisions during the 2008-2009 financial crisis were crucial in maintaining TSMC’s industry leadership.</li>
<li>TSMC’s approach under Chang’s leadership focused on innovation, R&amp;D investment, and expanding manufacturing capacity.</li>
<li>The chapter discusses the evolution of semiconductor manufacturing technology, including the introduction of FinFET transistors.</li>
<li>Morris Chang’s return to active leadership at TSMC was a response to the challenges faced during the financial crisis.</li>
<li>TSMC’s strategy focused on being a neutral player in the industry, manufacturing chips for a wide range of clients.</li>
<li>Chang emphasized the importance of collaboration and innovation within TSMC’s ecosystem.</li>
<li>The shift in semiconductor industry leadership from founders like Jerry Sanders of AMD to a new generation of executives is highlighted.</li>
</ol>
</section>
<section id="recommendations-2" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-2">Recommendations</h3>
<ol type="1">
<li>Study the impact of leadership styles and strategic decisions on the success of companies in the semiconductor industry.</li>
<li>Analyze the role of foundries like TSMC in the evolution of the semiconductor manufacturing model.</li>
<li>Explore the technological advancements in semiconductor manufacturing, such as FinFET transistors.</li>
<li>Consider the implications of the 2008-2009 financial crisis on strategic decision-making in high-tech industries.</li>
<li>Reflect on the importance of collaboration and innovation in sustaining industry leadership.</li>
<li>Assess the shift in industry dynamics from integrated manufacturing to a foundry-based model.</li>
<li>Investigate the strategic importance of maintaining R&amp;D investment and capacity expansion during economic downturns.</li>
<li>Examine the role of TSMC’s Grand Alliance strategy in fostering a cooperative semiconductor ecosystem.</li>
<li>Understand the changing landscape of the semiconductor industry and the challenges faced by traditional companies.</li>
<li>Evaluate the long-term impacts of visionary leadership and strategic foresight in the semiconductor sector.</li>
</ol>
</section>
</section>
<section id="apple-silicon" class="level2">
<h2 class="anchored" data-anchor-id="apple-silicon">Apple Silicon</h2>
<p>Chapter 38 examines Apple’s strategic shift in designing its own silicon chips for devices like the iPhone and iPad. The chapter highlights Apple’s evolution from outsourcing chip design and production to Samsung, to acquiring PA Semi and developing its own A4 processor. This move underscored the significance of controlling hardware and software integration, a vision Steve Jobs had since Apple’s early days. Apple’s investment in chip design, particularly in facilities in Bavaria, Israel, and Silicon Valley, is discussed, along with the role of foundries like TSMC in fabricating Apple’s processors.</p>
<section id="ideas-3" class="level3">
<h3 class="anchored" data-anchor-id="ideas-3">Ideas</h3>
<ol type="1">
<li><strong>Strategic Shift to In-House Chip Design</strong>: Apple’s transition to designing its own silicon chips to enhance hardware and software integration.</li>
<li><strong>Foundation of Steve Jobs’ Vision</strong>: The integral role of Jobs’ vision in integrating software and hardware in Apple’s product development.</li>
<li><strong>Significance of PA Semi Acquisition</strong>: Apple’s pivotal move in acquiring PA Semi to advance its in-house chip design capabilities.</li>
<li><strong>Milestone with A4 Processor Development</strong>: The creation of the A4 processor as a key step in Apple’s journey towards chip self-reliance.</li>
<li><strong>Contrast with Other Smartphone Companies</strong>: Apple’s distinct strategy compared to competitors relying on external chip suppliers.</li>
<li><strong>Global Investment in Chip Design Facilities</strong>: The importance of Apple’s R&amp;D and design facilities worldwide for silicon innovation.</li>
<li><strong>Partnership with TSMC for Fabrication</strong>: Apple’s processors, designed in-house but fabricated by TSMC, showcasing global semiconductor manufacturing dynamics.</li>
<li><strong>Role of Specialized Silicon in Apple Products</strong>: The impact of proprietary chip technology on the performance and efficiency of Apple devices.</li>
<li><strong>Fabless Model Adoption by Apple</strong>: The significance of Apple’s approach to design innovation in the semiconductor industry.</li>
<li><strong>Strategic Advantage in Smartphone Market</strong>: Apple’s in-house chip design as a key competitive edge in the smartphone industry.</li>
</ol>
</section>
<section id="facts-3" class="level3">
<h3 class="anchored" data-anchor-id="facts-3">Facts</h3>
<ol type="1">
<li>Apple’s transition to designing its own silicon chips was significant in the technology industry.</li>
<li>The company acquired PA Semi for its expertise in energy-efficient processing, which led to the development of the A4 processor.</li>
<li>Apple’s in-house chip design efforts differentiated its products in the competitive smartphone market.</li>
<li>The company invested heavily in R&amp;D and chip design facilities in various global locations.</li>
<li>TSMC plays a critical role in fabricating Apple’s processors.</li>
<li>Apple’s strategic move to design its own chips contributed to its dominance in smartphone profits.</li>
<li>The chapter highlights the global nature of semiconductor manufacturing and supply chains.</li>
<li>Apple’s approach to chip design and fabrication reflects a broader trend in the electronics industry.</li>
<li>The company designs not only the main processors for its devices but also ancillary chips for accessories.</li>
<li>Apple’s strategy in chip design is part</li>
</ol>
<p>of its larger vision for integrating hardware and software.</p>
</section>
<section id="recommendations-3" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-3">Recommendations</h3>
<ol type="1">
<li>Study the impact of in-house chip design on a technology company’s competitive advantage in the market.</li>
<li>Analyze the role of foundries like TSMC in the global semiconductor manufacturing ecosystem.</li>
<li>Explore the strategic implications of Apple’s shift from outsourcing chip design to developing its own processors.</li>
<li>Consider the effects of proprietary chip technology on product performance and market dominance.</li>
<li>Examine the importance of global R&amp;D and chip design facilities in driving technological innovation.</li>
<li>Assess the impact of the fabless model on the semiconductor industry’s business strategies.</li>
<li>Investigate the changing dynamics of the smartphone market and the role of chip design in market competition.</li>
<li>Reflect on the broader trends in the electronics industry, such as the integration of hardware and software.</li>
<li>Understand the complexities of global semiconductor supply chains and their implications for technology companies.</li>
<li>Evaluate the long-term effects of strategic decisions in chip design on a company’s success in the technology sector.</li>
</ol>
</section>
</section>
<section id="euv" class="level2">
<h2 class="anchored" data-anchor-id="euv">EUV</h2>
<p>Chapter 39 delves into the development of extreme ultraviolet (EUV) lithography, a critical technology in semiconductor manufacturing. It focuses on ASML, the Dutch lithography company, and its nearly two-decade journey to make EUV lithography functional. The chapter highlights the complex global supply chain and the collaboration of companies and national labs across the world. It discusses the enormous technological challenges and investments from major players like Intel, Samsung, and TSMC in ASML to develop this groundbreaking technology.</p>
<section id="ideas-4" class="level3">
<h3 class="anchored" data-anchor-id="ideas-4">Ideas</h3>
<ol type="1">
<li><strong>EUV as a Technological Leap in Semiconductor Manufacturing</strong>: The significance of EUV lithography in creating smaller, more efficient chips.</li>
<li><strong>Global Collaboration in Developing EUV</strong>: ASML’s worldwide sourcing and collaboration to develop EUV technology.</li>
<li><strong>High-Stakes Investments from Industry Giants</strong>: The enormous investment from leading semiconductor companies like Intel, Samsung, and TSMC in EUV development.</li>
<li><strong>Overcoming Technical Challenges</strong>: The transition from visible light to EUV lithography involved overcoming numerous technical barriers.</li>
<li><strong>Innovation in Laser Technology</strong>: Developing new types of powerful, precision lasers for EUV lithography.</li>
<li><strong>Complexity of EUV Lithography Tools</strong>: Illustrating the advanced state of modern semiconductor manufacturing through the complexity of EUV tools.</li>
<li><strong>Crucial Role of EUV Mirrors by Zeiss</strong>: The development of mirrors capable of reflecting EUV light, a critical component in the technology.</li>
<li><strong>ASML’s Supply Chain Expertise</strong>: The success of EUV attributed to ASML’s ability to manage a complex, global supply chain.</li>
<li><strong>Interdependence in the Semiconductor Industry</strong>: The collaborative and global nature of the industry, as showcased by the development of EUV technology.</li>
<li><strong>Milestone in Semiconductor Manufacturing</strong>: The transition to EUV marking a significant advancement in meeting modern electronics demands.</li>
</ol>
</section>
<section id="facts-4" class="level3">
<h3 class="anchored" data-anchor-id="facts-4">Facts</h3>
<ol type="1">
<li><p>ASML, a Dutch company, has been instrumental in developing EUV lithography technology over two decades.</p></li>
<li><p>EUV lithography is essential for creating smaller, more efficient semiconductor chips.</p></li>
<li><p>Significant investments were made by major semiconductor companies like Intel, Samsung, and TSMC in ASML to develop EUV technology.</p></li>
<li><p>The development of EUV lithography involved global collaboration and a complex supply chain.</p></li>
<li><p>Producing EUV light required new technological innovations, including the use of high-powered lasers to create plasma from tin droplets.</p></li>
<li><p>German companies like Trumpf and Zeiss played crucial roles in developing components for EUV technology, including powerful lasers and advanced mirrors.</p></li>
<li><p>The complexity and cost of EUV lithography tools are unprecedented in the history of mass-produced machine tools.</p></li>
<li><p>The development of EUV technology involved overcoming numerous technical challenges, such as creating mirrors capable of reflecting EUV light.</p></li>
<li><p>ASML’s success in EUV lithography is attributed to its expertise in supply chain management and collaboration with global partners.</p></li>
<li><p>The EUV lithography tool represents a multinational effort, with crucial components sourced from various countries.</p></li>
</ol>
</section>
<section id="recommendations-4" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-4">Recommendations</h3>
<ol type="1">
<li>Study the role of EUV lithography in advancing semiconductor technology and its impact on the industry.</li>
<li>Analyze the collaborative nature of technological innovations like EUV lithography and the role of global supply chains.</li>
<li>Reflect on the strategic importance of investments in cutting-edge technologies by leading semiconductor companies.</li>
<li>Explore the technical challenges and innovations involved in developing EUV lithography.</li>
<li>Consider the impact of multinational contributions in the development of advanced manufacturing technologies.</li>
<li>Examine the role of companies like Trumpf and Zeiss in supporting the development of key components for EUV technology.</li>
<li>Assess the significance of ASML’s expertise in supply chain management for the successful development of EUV lithography.</li>
<li>Investigate the economic and technological implications of the transition from traditional to EUV lithography in chip manufacturing.</li>
<li>Understand the complexities and costs associated with developing and implementing breakthrough technologies like EUV lithography.</li>
<li>Evaluate the long-term impacts of EUV technology on the global semiconductor industry and its future direction.</li>
</ol>
</section>
</section>
<section id="there-is-no-plan-b" class="level2">
<h2 class="anchored" data-anchor-id="there-is-no-plan-b">There Is No Plan B</h2>
<p>Chapter 40 focuses on the pivotal role of extreme ultraviolet (EUV) lithography in the semiconductor industry. It highlights Tony Yen’s contributions, who after joining TSMC in the late 1990s, played a key role in the development of EUV lithography. The chapter underscores the high stakes involved in developing EUV technology, with significant investments from industry leaders like TSMC, Intel, Samsung, and GlobalFoundries. It also touches on the challenges and decisions faced by GlobalFoundries, which eventually abandoned its EUV program due to financial constraints.</p>
<section id="ideas-5" class="level3">
<h3 class="anchored" data-anchor-id="ideas-5">Ideas</h3>
<ol type="1">
<li><strong>EUV Lithography as a Technological Leap</strong>: The critical role of EUV lithography in enabling smaller transistor fabrication and sustaining Moore’s Law.</li>
<li><strong>Tony Yen’s Impact at TSMC</strong>: Yen’s significant role in advancing lithography technology at TSMC.</li>
<li><strong>Collaborative Development of EUV Technology</strong>: The necessity of multi-company collaboration and substantial financial investment in EUV.</li>
<li><strong>Intel’s Major Investment in ASML</strong>: Highlighting the strategic value of EUV lithography through Intel’s significant financial commitment.</li>
<li><strong>Transitioning from DUV to EUV Lithography</strong>: The array of technical hurdles faced in moving from deep ultraviolet to EUV lithography.</li>
<li><strong>EUV as the Only Viable Path Forward</strong>: EUV lithography’s role as the singular path for continued miniaturization in semiconductor manufacturing.</li>
<li><strong>Morris Chang’s Visionary Bet on EUV</strong>: TSMC’s substantial investment in EUV technology reflecting Chang’s foresight.</li>
<li><strong>GlobalFoundries’ Challenges with EUV</strong>: The financial and technical difficulties smaller foundries face in adopting cutting-edge technologies.</li>
<li><strong>Financial and Strategic Divergence in EUV Adoption</strong>: Contrasting financial positions and strategies of major semiconductor companies regarding EUV technology.</li>
<li><strong>Consolidation in Semiconductor Manufacturing</strong>: The decline in the number of companies capable of fabricating leading-edge logic chips.</li>
</ol>
</section>
<section id="facts-5" class="level3">
<h3 class="anchored" data-anchor-id="facts-5">Facts</h3>
<ol type="1">
<li>EUV lithography was critical for the continued miniaturization of semiconductor components.</li>
<li>Tony Yen’s work at TSMC significantly contributed to the advancement of EUV technology.</li>
<li>Intel’s investment in ASML for EUV development was a major financial commitment to semiconductor technology.</li>
<li>The transition from deep ultraviolet to EUV lithography required overcoming several technical challenges.</li>
<li>TSMC, under Morris Chang, heavily invested in EUV technology.</li>
<li>GlobalFoundries eventually abandoned its EUV program due to financial constraints.</li>
<li>The development of EUV technology marked a significant technological advancement in semiconductor manufacturing.</li>
<li>The semiconductor industry faced intense competition and pressure to innovate, especially in lithography technology.</li>
<li>EUV technology was crucial for maintaining the pace of Moore’s Law.</li>
<li>The semiconductor industry saw consolidation, with a reduction in the</li>
</ol>
<p>number of companies capable of fabricating leading-edge logic chips.</p>
</section>
<section id="recommendations-5" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-5">Recommendations</h3>
<ol type="1">
<li>Study the strategic importance of EUV lithography in the semiconductor industry and its impact on technological advancement.</li>
<li>Analyze the role of major semiconductor companies and their investments in EUV technology development.</li>
<li>Reflect on the technical challenges and innovations involved in transitioning from deep ultraviolet to EUV lithography.</li>
<li>Consider the financial and strategic implications for semiconductor companies in adopting cutting-edge technologies like EUV.</li>
<li>Explore the competitive dynamics in the semiconductor industry, particularly in the area of lithography technology.</li>
<li>Assess the impact of industry consolidation on the development and implementation of advanced technologies.</li>
<li>Investigate the role of global collaboration and supply chains in the development of EUV lithography.</li>
<li>Examine the factors contributing to the decisions of companies like GlobalFoundries to abandon their EUV programs.</li>
<li>Understand the broader trends in semiconductor manufacturing, including the pressure to continuously innovate.</li>
<li>Evaluate the long-term effects of technological advancements like EUV lithography on the global semiconductor industry.</li>
</ol>
</section>
</section>
<section id="how-intel-forgot-innovation" class="level2">
<h2 class="anchored" data-anchor-id="how-intel-forgot-innovation">How Intel Forgot Innovation</h2>
<p>Chapter 41 examines the decline of Intel’s leadership in the semiconductor industry. It focuses on Intel’s challenges in adapting to new technologies and market shifts, particularly in artificial intelligence (AI) and data center processors. The chapter contrasts Intel’s struggles with the rise of competitors like Nvidia, who embraced AI and developed GPUs optimized for this purpose. Intel’s foray into the foundry business and its failure to keep up with advancements in manufacturing processes like EUV lithography are also discussed, highlighting the company’s missed opportunities and strategic missteps.</p>
<section id="ideas-6" class="level3">
<h3 class="anchored" data-anchor-id="ideas-6">Ideas</h3>
<ol type="1">
<li><strong>Intel’s Missed Technological Shifts</strong>: Intel’s decline due to its failure to adapt to emerging technologies, particularly in AI and data centers.</li>
<li><strong>Limited Focus on CPUs Over GPUs</strong>: Intel’s limited competitiveness owing to its continued focus on CPUs, while GPUs gained prominence in AI and parallel processing.</li>
<li><strong>Nvidia’s Successful Pivot to AI</strong>: Nvidia’s strategic success in GPU design for AI, highlighting Intel’s missed opportunities.</li>
<li><strong>Integrated Model Becoming a Liability</strong>: The shift in the industry making Intel’s integrated chip design and manufacturing model less advantageous.</li>
<li><strong>Struggles in the Foundry Business</strong>: Intel’s unsuccessful foray into the foundry business and difficulties in adapting to its open, service-oriented nature.</li>
<li><strong>Delay in Adopting EUV Lithography</strong>: Intel falling behind in manufacturing technology due to its delayed adoption of EUV lithography.</li>
<li><strong>Intel’s Internal Bureaucratic Stagnation</strong>: Challenges within Intel, including bureaucratic hurdles and a lack of innovation.</li>
<li><strong>Decline in Market Share and Influence</strong>: Intel’s diminishing influence and market share amid delays and technical issues in its manufacturing processes.</li>
<li><strong>Shift in Global Semiconductor Landscape</strong>: The rise of Asian foundries and the decline of American manufacturing prowess.</li>
<li><strong>Importance of Continuous Innovation</strong>: Intel’s struggles underscoring the necessity for continuous innovation and adaptability in the tech industry.</li>
</ol>
</section>
<section id="facts-6" class="level3">
<h3 class="anchored" data-anchor-id="facts-6">Facts</h3>
<ol type="1">
<li><p>Intel, once a leader in the semiconductor industry, struggled to adapt to new technologies and market shifts.</p></li>
<li><p>The company’s focus on CPUs became a limitation with the rise of AI and the need for GPUs.</p></li>
<li><p>Nvidia successfully adapted to the AI market, leveraging its GPU technology.</p></li>
<li><p>Intel’s integrated model of chip design and manufacturing became less effective in a changing industry.</p></li>
<li><p>Intel’s foray into the foundry business was unsuccessful, contrasting with the success of foundries like TSMC.</p></li>
<li><p>The company faced significant delays and technical challenges in advancing its manufacturing processes.</p></li>
<li><p>Intel’s delay in adopting EUV lithography was a critical factor in its technological lag.</p></li>
<li><p>Intel’s internal challenges included bureaucracy and a lack of innovation.</p></li>
<li><p>The company’s market share and influence in the semiconductor industry declined over time.</p></li>
<li><p>The global semiconductor landscape shifted, with Asian foundries rising and American manufacturing losing ground.</p></li>
</ol>
</section>
<section id="recommendations-6" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-6">Recommendations</h3>
<ol type="1">
<li>Analyze the impact of technological shifts on leading semiconductor companies like Intel.</li>
<li>Study the strategic importance of adapting to market changes, such as the rise of AI in computing.</li>
<li>Reflect on the challenges and opportunities in transitioning from traditional CPU manufacturing to GPU and specialized processors.</li>
<li>Consider the role of continuous innovation in maintaining competitiveness in the semiconductor industry.</li>
<li>Explore the implications of internal corporate challenges, like bureaucracy and innovation stagnation, on a company’s market position.</li>
<li>Assess the strategic decisions of companies like Nvidia in pivoting towards AI and GPU technology.</li>
<li>Investigate the impact of manufacturing technology advancements, like EUV lithography, on the semiconductor industry.</li>
<li>Examine the global dynamics of the semiconductor industry, particularly the rise of Asian manufacturing and the decline of American manufacturing.</li>
<li>Understand the broader trends in computing demands, such as the need for efficient AI processing.</li>
<li>Evaluate the potential future directions for companies like Intel in regaining their leadership in semiconductor technology.</li>
</ol>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>history</category>
  <guid>christianjmills.com/posts/chip-war-book-notes/part-6/</guid>
  <pubDate>Tue, 21 Nov 2023 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Chip War Part 5: Integrated Circuits, Integrated World?</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>christianjmills.com/posts/chip-war-book-notes/part-5/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/chip-war-book-notes.html"><strong>Chip War: The Fight for the World’s Most Critical Technology</strong></a></li>
</ul>
</div>
</div>
<ul>
<li>We Want a Semiconductor Industry in Taiwan</li>
<li>All People Must Make Semiconductors</li>
<li>“Sharing God’s Love With the Chinese”</li>
<li>Lithography Wars</li>
<li>The Innovator’s Dilemma</li>
<li>Running Faster?</li>
</ul>
<section id="we-want-a-semiconductor-industry-in-taiwan" class="level2">
<h2 class="anchored" data-anchor-id="we-want-a-semiconductor-industry-in-taiwan">We Want a Semiconductor Industry in Taiwan</h2>
<p>Chapter Twenty-Nine narrates Taiwan’s ascent as a semiconductor powerhouse. It focuses on Morris Chang’s role in leading Taiwan Semiconductor Manufacturing Company (TSMC) and Taiwan’s deliberate strategy to integrate into global semiconductor supply chains. The chapter highlights Taiwan’s transition from assembling devices to producing advanced chips, supported by government investment and collaboration with the U.S. semiconductor industry. It underscores Taiwan’s strategic positioning in the semiconductor market, driven by Chang’s vision and the government’s backing.</p>
<section id="ideas" class="level3">
<h3 class="anchored" data-anchor-id="ideas">Ideas</h3>
<ol type="1">
<li>Taiwan’s government, particularly Minister K.T. Lee, identified semiconductors as a strategic industry and actively promoted its development.</li>
<li>Morris Chang, a former Texas Instruments executive, played a central role in Taiwan’s semiconductor industry, leading TSMC.</li>
<li>Taiwan’s entry into the semiconductor market was part of a broader strategy for economic growth and technological advancement.</li>
<li>The government’s significant investment and support were crucial in the establishment and success of TSMC.</li>
<li>Collaboration with U.S. firms and technology transfer were key factors in Taiwan’s rise as a semiconductor hub.</li>
<li>Taiwan’s shift from assembly to chip fabrication marked a significant technological leap.</li>
<li>TSMC’s foundry model, focusing on manufacturing chips designed by customers, was a novel approach that reshaped the industry.</li>
<li>The success of TSMC and Taiwan’s semiconductor industry is a testament to strategic planning, governmental support, and entrepreneurial vision.</li>
<li>Taiwan’s emergence as a leading semiconductor producer had significant implications for global technology and economics.</li>
<li>The chapter illustrates how a small nation strategically positioned itself in a critical global industry through innovation and government-industry collaboration.</li>
</ol>
</section>
<section id="facts" class="level3">
<h3 class="anchored" data-anchor-id="facts">Facts</h3>
<ol type="1">
<li>Taiwan’s government, led by Minister K.T. Lee, played a pivotal role in developing the country’s semiconductor industry.</li>
<li>Morris Chang was instrumental in leading TSMC and shaping Taiwan’s semiconductor sector.</li>
<li>Taiwan’s strategy involved transitioning from assembly to advanced chip production.</li>
<li>The Taiwanese government provided significant investment and support for TSMC.</li>
<li>Collaboration with U.S. companies and technology transfer were crucial in Taiwan’s semiconductor industry development.</li>
<li>TSMC’s foundry model, focusing on manufacturing customer-designed chips, was innovative and influential.</li>
<li>Taiwan’s rise as a semiconductor hub was a result of strategic planning and government-industry collaboration.</li>
<li>TSMC and Taiwan’s success in semiconductors had major global technological and economic implications.</li>
<li>The Taiwanese semiconductor industry’s growth was marked by strategic government support and entrepreneurial vision.</li>
<li>Taiwan’s emergence as a leading semiconductor producer significantly impacted the global technology landscape.</li>
</ol>
</section>
</section>
<section id="all-people-must-make-semiconductors" class="level2">
<h2 class="anchored" data-anchor-id="all-people-must-make-semiconductors">All People Must Make Semiconductors</h2>
<p>Chapter 30 contrasts the semiconductor industry’s evolution in Taiwan and China. It highlights Taiwan’s technological advancement through TSMC and the founding of Huawei in China, emphasizing the impact of political and economic policies on the development of the semiconductor industry in both regions.</p>
<section id="ideas-1" class="level3">
<h3 class="anchored" data-anchor-id="ideas-1">Ideas</h3>
<ol type="1">
<li>Taiwan’s advancement in semiconductor technology was rapid and significant, largely due to TSMC.</li>
<li>China’s technological development in the semiconductor industry was initially slow due to political and economic constraints.</li>
<li>Political policies, particularly in China, had a profound impact on the development of the semiconductor industry.</li>
<li>Taiwan and China’s approaches to technology and semiconductor development were markedly different.</li>
<li>The founding of TSMC and Huawei represented different strategies in technology adoption and development.</li>
<li>Taiwan’s semiconductor success was aided by its connection to global tech companies and educated engineers.</li>
<li>China’s initial backwardness in technology was a result of its isolationist policies and political turmoil.</li>
<li>The Chinese government’s late realization of the importance of semiconductors changed its approach to technology.</li>
<li>Taiwan leveraged its skilled workforce and international connections to excel in semiconductor manufacturing.</li>
<li>The Cultural Revolution in China severely hampered technological progress, particularly in the semiconductor industry.</li>
</ol>
</section>
<section id="facts-1" class="level3">
<h3 class="anchored" data-anchor-id="facts-1">Facts</h3>
<ol type="1">
<li>TSMC was founded in Taiwan in 1987 by Morris Chang.</li>
<li>Huawei, a major telecommunications company, was established in China in 1987 by Ren Zhengfei.</li>
<li>Taiwan’s success in the semiconductor industry is partly due to its skilled engineers educated at top universities like Stanford and Berkeley.</li>
<li>China’s semiconductor industry lagged due to its political and economic isolation.</li>
<li>The Chinese government, under Jiang Zemin, identified electronics as a priority in the 1980s.</li>
<li>China’s technological capabilities in the 1980s were over a decade behind the global cutting edge.</li>
<li>Mao Zedong’s policies, especially the Cultural Revolution, hindered China’s technological advancement.</li>
<li>Taiwan’s economic strategies significantly differed from China’s, leading to a more advanced semiconductor industry.</li>
<li>The development of the semiconductor industry in East Asia was heavily influenced by political decisions and global economics.</li>
<li>Deng Xiaoping’s policy changes in the late 1970s marked a shift towards modernization in China, impacting its technological development.</li>
</ol>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<ol type="1">
<li>Study the history of Taiwan’s semiconductor industry to understand its success.</li>
<li>Examine the impact of China’s political policies on its technological development.</li>
<li>Understand the significance of key figures like Morris Chang and Ren Zhengfei in the tech industry.</li>
<li>Consider the role of education and global connections in technological advancement.</li>
<li>Analyze the effects of political turmoil, like the Cultural Revolution, on scientific progress.</li>
<li>Explore how national policies can drastically impact technological industries.</li>
<li>Recognize the strategic importance of the semiconductor industry in global power dynamics.</li>
<li>Consider the implications of global economic forces on technological development and national policies.</li>
<li>Observe how late policy shifts, like those under Deng Xiaoping, can transform a country’s technological landscape.</li>
<li>Understand the pivotal role of semiconductors in modern technology and global politics.</li>
</ol>
</section>
</section>
<section id="sharing-gods-love-with-the-chinese" class="level2">
<h2 class="anchored" data-anchor-id="sharing-gods-love-with-the-chinese">“Sharing God’s Love With the Chinese”</h2>
<p>Chapter 31 focuses on Richard Chang’s efforts to establish a semiconductor industry in China, contrasting the different approaches and challenges faced by East Asian countries in semiconductor production. It highlights the geopolitical and economic shifts in chip fabrication, detailing the roles of TSMC, Huawei, and other major players in shaping the industry.</p>
<section id="ideas-2" class="level3">
<h3 class="anchored" data-anchor-id="ideas-2">Ideas</h3>
<ol type="1">
<li>Richard Chang’s vision for semiconductor manufacturing in China was driven by a mix of personal conviction and economic strategy.</li>
<li>The global geography of chip fabrication shifted significantly from the 1990s to the 2000s, with East Asian countries becoming more prominent.</li>
<li>U.S. dominance in chip production declined over two decades, while Asian countries increased their market share.</li>
<li>The growth of the semiconductor industry in countries like South Korea, Singapore, and Taiwan was fueled by government investment and strategic partnerships.</li>
<li>China’s approach to building a semiconductor industry included a mix of government subsidies, foreign investment, and technology transfer attempts.</li>
<li>The complexity and cost of semiconductor production require significant financial backing and technological expertise.</li>
<li>Samsung’s success in the memory chip market illustrates the competitive nature of the semiconductor industry.</li>
<li>The semiconductor industry’s evolution reflects broader trends in globalization and technological advancement.</li>
<li>The entry of China into semiconductor manufacturing marked a significant shift in the global tech landscape.</li>
<li>Political and economic decisions play a crucial role in shaping the semiconductor industry.</li>
</ol>
</section>
<section id="facts-2" class="level3">
<h3 class="anchored" data-anchor-id="facts-2">Facts</h3>
<ol type="1">
<li>Richard Chang played a pivotal role in establishing China’s semiconductor industry.</li>
<li>The U.S. share of global chip production declined from 37% in 1990 to 13% in 2010.</li>
<li>Asian countries, particularly South Korea, Singapore, and Taiwan, increased their chip production significantly.</li>
<li>Samsung became the world leader in memory chip production in 1992.</li>
<li>The semiconductor industry requires substantial investment and often relies on government support.</li>
<li>China’s chip manufacturing capabilities in the 1990s were significantly behind those of Taiwan and South Korea.</li>
<li>SMIC, founded by Richard Chang, received substantial investment from both Chinese and international sources, including U.S. investors.</li>
<li>The development of China’s semiconductor industry involved significant technology transfer and overseas hiring.</li>
<li>SMIC’s strategy mirrored that of TSMC, focusing on hiring skilled engineers and acquiring the best available tools.</li>
<li>The semiconductor industry’s growth is intertwined with the rise of smartphones and fabless semiconductor designers.</li>
</ol>
</section>
<section id="recommendations-1" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-1">Recommendations</h3>
<ol type="1">
<li>Examine the strategic importance of semiconductor technology in national economies.</li>
<li>Analyze the impact of government policies and subsidies on the semiconductor industry.</li>
<li>Consider the role of key individuals like Richard Chang in shaping the semiconductor landscape.</li>
<li>Study the competitive dynamics of the semiconductor market, including the DRAM sector.</li>
<li>Observe the impact of globalization on the semiconductor industry.</li>
<li>Understand the technological and financial challenges in semiconductor manufacturing.</li>
<li>Recognize the significance of semiconductor technology in the rise of smartphones and modern devices.</li>
<li>Explore the role of international collaboration and investment in semiconductor industry growth.</li>
<li>Assess the geopolitical implications of the semiconductor industry’s development in East Asia.</li>
<li>Reflect on the broader economic and technological trends influencing the semiconductor industry.</li>
</ol>
</section>
</section>
<section id="lithography-wars" class="level2">
<h2 class="anchored" data-anchor-id="lithography-wars">Lithography Wars</h2>
<p>Chapter 32 discusses the technological and financial challenges Intel faced in developing extreme ultraviolet (EUV) lithography. It narrates John Carruthers’ quest for funding from Intel CEO Andy Grove and the strategic decisions that led to ASML becoming the dominant player in the EUV lithography market, highlighting the geopolitical implications of these developments.</p>
<section id="ideas-3" class="level3">
<h3 class="anchored" data-anchor-id="ideas-3">Ideas</h3>
<ol type="1">
<li>The development of EUV lithography was a significant technological challenge, requiring substantial investment and innovation.</li>
<li>Intel’s commitment to Moore’s Law drove its investment in advanced lithography technologies.</li>
<li>The shift from deep ultraviolet to EUV lithography was essential for maintaining the pace of semiconductor miniaturization.</li>
<li>The lithography industry experienced a period of intense competition and technological experimentation.</li>
<li>ASML’s rise as a dominant player in the lithography market illustrates the importance of strategic partnerships and global supply chains.</li>
<li>The semiconductor industry’s evolution reflects broader trends in globalization, technological advancement, and corporate strategy.</li>
<li>The decline of U.S. dominance in lithography equipment manufacturing had significant geopolitical implications.</li>
<li>The collaboration between ASML and TSMC was pivotal in advancing semiconductor technology.</li>
<li>The concentration of advanced lithography technology in a few companies raised concerns about supply chain security and technological sovereignty.</li>
<li>Intel’s funding decisions reflected the complex interplay of science, business, and politics in the semiconductor industry.</li>
</ol>
</section>
<section id="facts-3" class="level3">
<h3 class="anchored" data-anchor-id="facts-3">Facts</h3>
<ol type="1">
<li>Intel invested heavily in developing EUV lithography, a key technology for semiconductor manufacturing.</li>
<li>By 1992, Intel had regained its position as the world’s biggest chipmaker.</li>
<li>The shift from deep ultraviolet to EUV lithography was critical for producing smaller and more efficient semiconductors.</li>
<li>ASML, a Dutch company, emerged as a key player in the advanced lithography market.</li>
<li>The development of EUV lithography required global collaboration and significant financial investment.</li>
<li>U.S. chipmakers lost their dominance in lithography tool manufacturing to international competitors.</li>
<li>The U.S. government’s policy decisions influenced the development and export of lithography technology.</li>
<li>The concentration of lithography technology in a few companies raised concerns about global supply chain security.</li>
<li>The collaboration between ASML and TSMC was crucial for advancing semiconductor technology.</li>
<li>The development of EUV lithography involved challenges in engineering, business, and geopolitics.</li>
</ol>
</section>
<section id="recommendations-2" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-2">Recommendations</h3>
<ol type="1">
<li>Explore the strategic importance of advanced lithography technology in semiconductor manufacturing.</li>
<li>Analyze the impact of corporate investment and government policies on technological innovation.</li>
<li>Study the evolution of the lithography industry and the rise of companies like ASML.</li>
<li>Consider the geopolitical implications of shifts in technological leadership and supply chain control.</li>
<li>Understand the importance of international collaboration in advancing semiconductor technology.</li>
<li>Reflect on the role of technological sovereignty and supply chain security in global technology development.</li>
<li>Examine the challenges and opportunities presented by the globalization of the semiconductor industry.</li>
<li>Recognize the importance of strategic partnerships, like that between ASML and TSMC, in technological advancement.</li>
<li>Investigate the impact of financial investment and research and development on technological progress.</li>
<li>Consider the long-term implications of the “lithography wars” on the global semiconductor industry.</li>
</ol>
</section>
</section>
<section id="the-innovators-dilemma" class="level2">
<h2 class="anchored" data-anchor-id="the-innovators-dilemma">The Innovator’s Dilemma</h2>
<p>Chapter 33 explores Intel’s strategic decisions and missed opportunities in the semiconductor industry. It highlights the contrast between Intel’s focus on x86 architecture for PCs and servers and the rise of mobile devices. The chapter illustrates how Intel’s prioritization of profit margins and its reluctance to embrace new technologies like ARM architecture led to missed opportunities in the rapidly evolving mobile market, exemplified by Intel’s decision to decline Apple’s iPhone chip contract.</p>
<section id="ideas-4" class="level3">
<h3 class="anchored" data-anchor-id="ideas-4">Ideas</h3>
<ol type="1">
<li><strong>Intel’s Business Strategy and x86 Architecture</strong>: The heavy influence of Intel’s commitment to x86 architecture and high profit margins on its business strategy.</li>
<li><strong>Missed Opportunities in Mobile Markets</strong>: Intel’s focus on PCs and servers leading to overlooked opportunities in the burgeoning mobile device sector.</li>
<li><strong>Short-term Financial Goals vs.&nbsp;Long-term Innovation</strong>: The prioritization of short-term financial goals over long-term technological innovation under CEO Paul Otellini.</li>
<li><strong>Shift from Engineering to Management-Driven Decisions</strong>: The transition at Intel impacting its adaptability to new market trends.</li>
<li><strong>Strategic Misstep with Apple’s iPhone</strong>: Intel’s significant strategic error in declining to produce chips for Apple’s iPhone.</li>
<li><strong>Underestimating Mobile Market Growth</strong>: The failure to recognize the rapid growth and importance of the mobile market in the semiconductor industry.</li>
<li><strong>Cultural Shift Impacting Market Position</strong>: The shift from engineering innovation to financial management within Intel and its profound market implications.</li>
<li><strong>The Innovator’s Dilemma in Intel’s Context</strong>: The challenges established companies like Intel face in adapting to technological shifts.</li>
<li><strong>Conservative Approach to Innovation Risks</strong>: The risks of Intel’s conservative approach to innovation in a rapidly evolving industry.</li>
<li><strong>Paradigm Shift in Semiconductor Industry</strong>: The rise of mobile computing representing a paradigm shift that Intel was slow to recognize and capitalize on.</li>
</ol>
</section>
<section id="facts-4" class="level3">
<h3 class="anchored" data-anchor-id="facts-4">Facts</h3>
<ol type="1">
<li>Intel’s dominance in the PC and server chip market was heavily reliant on its x86 architecture.</li>
<li>Intel’s leadership, especially under CEO Paul Otellini, focused more on financial management than engineering innovation.</li>
<li>Intel missed the opportunity to produce chips for Apple’s iPhone, which later proved to be a significant market.</li>
<li>ARM architecture, which Intel had considered but rejected, became dominant in the mobile device market.</li>
<li>Intel’s conservative approach to innovation led to missed opportunities in the rapidly evolving semiconductor industry.</li>
<li>The rise of mobile devices represented a major shift in the semiconductor industry, which Intel was slow to adapt to.</li>
<li>Intel’s focus on maintaining high profit margins influenced its reluctance to invest in new technologies.</li>
<li>The partnership between Intel and Apple for Mac computers was a notable success, but did not extend to mobile devices.</li>
<li>Intel’s market position was challenged by its conservative approach to embracing new market trends and technologies.</li>
<li>The semiconductor industry’s evolution required companies to be agile and forward-thinking, a challenge for Intel’s traditional business</li>
</ol>
<p>strategy.</p>
</section>
<section id="recommendations-3" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-3">Recommendations</h3>
<ol type="1">
<li>Study the impact of corporate culture on a company’s ability to innovate and adapt to new market trends.</li>
<li>Explore the strategic implications of focusing on traditional profitable lines versus investing in emerging technologies.</li>
<li>Understand the importance of agile decision-making in rapidly evolving industries like the semiconductor market.</li>
<li>Analyze the impact of leadership styles on a company’s technological and market position.</li>
<li>Consider the risks and opportunities associated with the innovator’s dilemma in technology companies.</li>
<li>Examine the evolution of the semiconductor industry, particularly the shift towards mobile computing.</li>
<li>Reflect on the strategic decisions of companies like Intel and Apple and their long-term market implications.</li>
<li>Investigate the importance of technological adaptability in maintaining market leadership in the semiconductor industry.</li>
<li>Assess the influence of technological trends, such as ARM architecture, on the global semiconductor market.</li>
<li>Explore the role of strategic partnerships in shaping a company’s position in the technology industry.</li>
</ol>
</section>
</section>
<section id="running-faster" class="level2">
<h2 class="anchored" data-anchor-id="running-faster">Running Faster?</h2>
<p>Chapter 34 focuses on Andy Grove’s perspective on offshoring in the semiconductor industry. It details Grove’s concerns about the offshoring of advanced manufacturing jobs and the U.S.’s diminishing role in semiconductor manufacturing. The chapter highlights the strategic and geopolitical implications of these trends, with a particular focus on the rise of China’s semiconductor capabilities and the U.S.’s reliance on foreign manufacturing.</p>
<section id="ideas-5" class="level3">
<h3 class="anchored" data-anchor-id="ideas-5">Ideas</h3>
<ol type="1">
<li><strong>Grove’s Concerns About Offshoring</strong>: Andy Grove’s worries about the risks of losing domestic advanced manufacturing capabilities.</li>
<li><strong>Shift of Manufacturing to Asia</strong>: The relocation of semiconductor manufacturing from the U.S. to Asia, particularly China and Taiwan, and its strategic and economic implications.</li>
<li><strong>Globalization in High-Tech Industries</strong>: Reflection on the broader implications of globalization in the high-tech sector.</li>
<li><strong>Importance of Domestic Manufacturing</strong>: Grove’s emphasis on the necessity of a strong domestic manufacturing base for strategic industries.</li>
<li><strong>Rise of China’s Semiconductor Industry</strong>: The significant shift in global technological dynamics marked by the development of China’s semiconductor sector.</li>
<li><strong>U.S. Policies Impacting the Industry</strong>: How U.S. government policies on technology exports and trade shaped the semiconductor industry.</li>
<li><strong>Contrast in Manufacturing Approaches</strong>: The differences between the U.S. and China’s strategies in semiconductor manufacturing, highlighting diverse economic and strategic priorities.</li>
<li><strong>Grove’s Skepticism of Offshoring</strong>: Challenge to the prevailing views on the long-term benefits of offshoring.</li>
<li><strong>Risks in Global Supply Chains</strong>: The dependence on key facilities in Taiwan for chip manufacturing and its risks to global supply chains.</li>
<li><strong>Balancing Economic Efficiency and Strategy</strong>: The complexities of aligning economic efficiency with strategic considerations in global manufacturing.</li>
</ol>
</section>
<section id="facts-5" class="level3">
<h3 class="anchored" data-anchor-id="facts-5">Facts</h3>
<ol type="1">
<li>Andy Grove was a key figure at Intel and had concerns about the impact of offshoring on U.S. manufacturing.</li>
<li>The shift in semiconductor manufacturing from the U.S. to Asia, particularly to China, was significant.</li>
<li>The rise of China’s semiconductor industry, including companies like SMIC, indicated a major shift in global technology dynamics.</li>
<li>The U.S. government’s approach to technology exports and trade agreements played a role in the semiconductor industry’s globalization.</li>
<li>The reliance on a few facilities in Taiwan for semiconductor manufacturing created vulnerabilities in global supply chains.</li>
<li>The chapter discusses the economic and strategic implications of offshoring in high-tech industries.</li>
<li>Andy Grove’s perspective challenges the prevailing attitudes toward globalization in the semiconductor industry.</li>
<li>The U.S.’s position in the global semiconductor industry was changing, with potential implications for its technological leadership.</li>
<li>The debate over technology exports from the U.S. highlighted tensions between economic interests and national security.</li>
<li>The narrative illustrates the complexities and risks associated with the global semiconductor supply chain.</li>
</ol>
</section>
<section id="recommendations-4" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-4">Recommendations</h3>
<ol type="1">
<li>Consider the strategic importance of maintaining domestic manufacturing capabilities in critical industries.</li>
<li>Analyze the impact of globalization on high-tech industries, particularly semiconductor manufacturing.</li>
<li>Reflect on the implications of the U.S.’s diminishing role in semiconductor manufacturing for its technological leadership.</li>
<li>Explore the contrasting approaches of the U.S. and China in the semiconductor industry and their economic and strategic outcomes.</li>
<li>Examine the vulnerabilities created by global semiconductor supply chains and the reliance on a few key manufacturing locations.</li>
<li>Debate the merits and risks of offshoring in the context of national security and economic resilience.</li>
<li>Assess the long-term impacts of the U.S.’s policies on technology exports and trade agreements in the semiconductor industry.</li>
<li>Investigate the changing landscape of the global semiconductor industry and the evolving position of the U.S. within it.</li>
<li>Evaluate the perspectives and predictions of industry figures like Andy Grove on the future of manufacturing and innovation.</li>
<li>Study the balance between economic efficiency and strategic considerations in global manufacturing decisions.</li>
</ol>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>history</category>
  <guid>christianjmills.com/posts/chip-war-book-notes/part-5/</guid>
  <pubDate>Tue, 21 Nov 2023 08:00:00 GMT</pubDate>
  <media:content url="christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
</channel>
</rss>
