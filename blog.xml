<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Christian Mills</title>
<link>https://christianjmills.com/blog.html</link>
<atom:link href="https://christianjmills.com/blog.xml" rel="self" type="application/rss+xml"/>
<description>This is Christian Mills&#39; personal Blog.</description>
<image>
<url>https://christianjmills.com/images/logo.png</url>
<title>Christian Mills</title>
<link>https://christianjmills.com/blog.html</link>
<height>144</height>
<width>144</width>
</image>
<generator>quarto-1.4.555</generator>
<lastBuildDate>Sun, 01 Sep 2024 07:00:00 GMT</lastBuildDate>
<item>
  <title>CUDA MODE Lecture 5: Going Further with CUDA for Python Programmers</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/cuda-mode-notes/lecture-005/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/cuda-mode-notes.html"><strong>CUDA Mode Lecture Notes</strong></a>: My notes from the <strong>CUDA MODE</strong> reading group lectures run by <strong>Andreas Kopf</strong> and <strong>Mark Saroufim</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Introduction and Overview</li>
<li>Resources and Setup</li>
<li>Matrix Multiplication Example<br>
</li>
<li>Optimizing with Shared Memory<br>
</li>
<li>Implementing Tiling with Numba</li>
<li>Q&amp;A Session</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Resource Links:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resource Links:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>YouTube Recording:</strong> <a href="https://www.youtube.com/watch?v=wVsR-YhaHlM">Lecture 5: Going Further with CUDA for Python Programmers</a></li>
<li><strong>Jupyter Notebook:</strong> <a href="https://github.com/cuda-mode/lectures/blob/main/lecture_005/matmul_l5.ipynb">lecture_005/matmul_l5.ipynb</a></li>
<li><strong>utils.py:</strong> <a href="https://github.com/cuda-mode/lectures/blob/main/utils.py">utils.py</a></li>
</ul>
</div>
</div>
<section id="introduction-and-overview" class="level2">
<h2 class="anchored" data-anchor-id="introduction-and-overview">Introduction and Overview</h2>
<ul>
<li><strong>Going Further with CUDA for Python Programmers:</strong> This lecture builds upon the foundational knowledge presented in “<a href="https://www.youtube.com/watch?v=4sgKnKbR-WE">Getting Started with CUDA for Python Programmers</a>” and focuses on optimizing CUDA code for performance by leveraging fast memory.</li>
<li><strong>Prerequisites:</strong> Familiarity with basic CUDA concepts and Python programming, including thread utilization.</li>
<li><strong>Recommended Resources:</strong>
<ul>
<li>“<a href="https://www.amazon.com/Programming-Massively-Parallel-Processors-Hands/dp/0323912311/">Programming Massively Parallel Processes</a>” (book), Chapter 5.</li>
<li><a href="https://www.youtube.com/watch?v=lTmYrKwjSOU">CUDA Mode lecture by Thomas Viehmann</a> (covers Chapter 4 &amp; 5).</li>
</ul></li>
<li><strong>Lecture Focus:</strong> Utilizing <strong>shared memory</strong>, a faster memory type within the GPU, to improve performance.</li>
<li><strong>Memory Hierarchy:</strong>
<ul>
<li><strong>Global Memory:</strong> Default memory used in CUDA, relatively fast but not the fastest.
<ul>
<li>Accessed by all threads.</li>
<li>(e.g., with <code>tensor.cuda()</code> in PyTorch)</li>
</ul></li>
<li><strong>Shared Memory:</strong> Significantly faster than global memory (about 10x).
<ul>
<li>Accessible only by threads within a specific <strong>block</strong> (on a streaming multiprocessor).</li>
</ul></li>
</ul></li>
<li><strong>Importance of Memory Access Speed:</strong> Due to the high processing speed of GPUs, memory access becomes a performance bottleneck. Utilizing shared memory effectively is crucial for optimization.</li>
</ul>
</section>
<section id="resources-and-setup" class="level2">
<h2 class="anchored" data-anchor-id="resources-and-setup">Resources and Setup</h2>
<ul>
<li><p><strong>Repository:</strong> CUDA Mode lectures repository, specifically lecture 5 notebook.</p>
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/cuda-mode/lectures">https://github.com/cuda-mode/lectures</a></li>
</ul></li>
<li><p><strong><a href="https://github.com/cuda-mode/lectures/blob/main/utils.py">utils.py</a>:</strong> Contains helper functions (e.g., ceiling division, CUDA code loading, prefix for CUDA code).</p></li>
<li><p><strong><code>dim3</code>:</strong> Python namedtuple representing a 3D grid (x, y, z) for blocks and threads, mirroring CUDA’s Dim3 structure.</p></li>
<li><p><strong>Debugging Tools:</strong> Wurlitzer for printing from CUDA kernels, CUDA launch blocking for debugging.</p></li>
<li><p><strong>Setup Code:</strong></p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Operating system interfaces</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Mathematical functions</span></span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> sys     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># System-specific parameters and functions</span></span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># PyTorch library for tensor computations and neural networks</span></span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> re      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Regular expression operations</span></span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># NumPy library for numerical computations</span></span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> types <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SimpleNamespace <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> ns  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Allows creation of attribute-accessible objects</span></span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> collections <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> namedtuple  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Factory function for creating tuple subclasses with named fields</span></span></code></pre></div>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define a custom 3D dimension namedtuple with default values</span></span>
<span id="cb2-2">dim3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> namedtuple(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dim3'</span>, [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'z'</span>], defaults<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span></code></pre></div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a 2D dimension instance</span></span>
<span id="cb3-2">d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim3(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the full dimension object</span></span>
<span id="cb3-5">d</span></code></pre></div>
<pre class="text"><code>dim3(x=2, y=3, z=1)</code></pre>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display x and y components of the dimension</span></span>
<span id="cb5-2">d.x, d.y</span></code></pre></div>
<pre class="text"><code>(2, 3)</code></pre>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Configure NumPy print options for cleaner output</span></span>
<span id="cb7-2">np.set_printoptions(precision<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>)</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Configure PyTorch print options for cleaner output and disable scientific notation</span></span>
<span id="cb7-5">torch.set_printoptions(precision<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>, sci_mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import utility functions</span></span>
<span id="cb8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> show_img, load_cuda, cuda_begin, cdiv</span></code></pre></div>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the wurlitzer IPython extension for capturing C-level output</span></span>
<span id="cb9-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>load_ext wurlitzer</span></code></pre></div>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set a random seed for reproducibility</span></span>
<span id="cb10-2">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span></code></pre></div>
<pre class="text"><code>&lt;torch._C.Generator at 0x728ffff23630&gt;</code></pre></li>
</ul>
</section>
<section id="matrix-multiplication-example" class="level2">
<h2 class="anchored" data-anchor-id="matrix-multiplication-example">Matrix Multiplication Example</h2>
<ul>
<li><p><strong>Problem:</strong> Multiplying a 5120x256 matrix (M1) by a 256x5120 matrix (M2).</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a large random tensor (5120x256)</span></span>
<span id="cb12-2">m1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5120</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>)</span>
<span id="cb12-3"></span>
<span id="cb12-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the first 4 rows of m1</span></span>
<span id="cb12-5">m1s <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m1[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span>
<span id="cb12-6"></span>
<span id="cb12-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create another large random tensor (256x5120)</span></span>
<span id="cb12-8">m2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5120</span>)</span>
<span id="cb12-9"></span>
<span id="cb12-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the first 4 columns of m2</span></span>
<span id="cb12-11">m2s <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m2[:, :<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span></code></pre></div></li>
</ul>
<section id="previous-approaches-recap" class="level3">
<h3 class="anchored" data-anchor-id="previous-approaches-recap">Previous Approaches (Recap)</h3>
<ul>
<li><p><strong>Naive Matrix Multiplication Kernel:</strong></p>
<ul>
<li>Calculates dot product for each element in the output matrix.</li>
<li>Accesses global memory repeatedly within the inner loop, leading to performance issues.</li>
</ul></li>
<li><p><strong>Pure Python Baseline:</strong> Extremely slow, uses a small sample of the matrices (4x4) for demonstration.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> blk_kernel2d(f, blocks, threads, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args):</span>
<span id="cb13-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb13-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Simulate a 2D GPU kernel execution on CPU.</span></span>
<span id="cb13-4"></span>
<span id="cb13-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function emulates the behavior of a 2D GPU kernel by iterating over</span></span>
<span id="cb13-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    blocks and threads in a nested loop structure.</span></span>
<span id="cb13-7"></span>
<span id="cb13-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb13-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        f (function): The kernel function to be executed.</span></span>
<span id="cb13-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blocks (dim3): The number of blocks in x and y dimensions.</span></span>
<span id="cb13-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        threads (dim3): The number of threads per block in x and y dimensions.</span></span>
<span id="cb13-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        *args: Additional arguments to be passed to the kernel function.</span></span>
<span id="cb13-13"></span>
<span id="cb13-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb13-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        None</span></span>
<span id="cb13-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb13-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i0 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blocks.y):</span>
<span id="cb13-18">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i1 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blocks.x):</span>
<span id="cb13-19">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j0 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(threads.y):</span>
<span id="cb13-20">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j1 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(threads.x):</span>
<span id="cb13-21">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Execute the kernel function for each thread</span></span>
<span id="cb13-22">                    f(dim3(i1,i0), dim3(j1,j0), threads, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args)</span></code></pre></div>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_bk(blockIdx, threadIdx, blockDim, m, n, out, h, w, k):</span>
<span id="cb14-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb14-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform matrix multiplication for a single element in the output matrix.</span></span>
<span id="cb14-4"></span>
<span id="cb14-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function calculates one element of the output matrix by multiplying</span></span>
<span id="cb14-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    a row from the first matrix with a column from the second matrix.</span></span>
<span id="cb14-7"></span>
<span id="cb14-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb14-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockIdx (dim3): The current block index.</span></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        threadIdx (dim3): The current thread index within the block.</span></span>
<span id="cb14-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockDim (dim3): The dimensions of the block.</span></span>
<span id="cb14-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        m (Tensor): Flattened first input matrix.</span></span>
<span id="cb14-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (Tensor): Flattened second input matrix.</span></span>
<span id="cb14-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        out (Tensor): Flattened output matrix.</span></span>
<span id="cb14-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        h (int): Height of the output matrix.</span></span>
<span id="cb14-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        w (int): Width of the output matrix.</span></span>
<span id="cb14-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        k (int): Common dimension of input matrices.</span></span>
<span id="cb14-18"></span>
<span id="cb14-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb14-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        None</span></span>
<span id="cb14-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb14-22">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate global thread indices</span></span>
<span id="cb14-23">    r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> blockIdx.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockDim.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> threadIdx.y</span>
<span id="cb14-24">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> blockIdx.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockDim.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> threadIdx.x</span>
<span id="cb14-25"></span>
<span id="cb14-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check if the thread is within the output matrix dimensions</span></span>
<span id="cb14-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">or</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> w):</span>
<span id="cb14-28">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span></span>
<span id="cb14-29"></span>
<span id="cb14-30">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Perform dot product of row from m and column from n</span></span>
<span id="cb14-31">    o <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb14-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(k):</span>
<span id="cb14-33">        o <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> m[r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> n[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>c]</span>
<span id="cb14-34"></span>
<span id="cb14-35">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Store the result in the output matrix</span></span>
<span id="cb14-36">    out[r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>c] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> o</span></code></pre></div>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_2d(m, n):</span>
<span id="cb15-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb15-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform matrix multiplication using a simulated 2D GPU kernel.</span></span>
<span id="cb15-4"></span>
<span id="cb15-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function sets up the execution configuration and launches the</span></span>
<span id="cb15-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    matrix multiplication kernel.</span></span>
<span id="cb15-7"></span>
<span id="cb15-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb15-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        m (Tensor): First input matrix.</span></span>
<span id="cb15-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (Tensor): Second input matrix.</span></span>
<span id="cb15-11"></span>
<span id="cb15-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb15-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Tensor: Result of matrix multiplication.</span></span>
<span id="cb15-14"></span>
<span id="cb15-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Raises:</span></span>
<span id="cb15-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        AssertionError: If the inner dimensions of input matrices don't match.</span></span>
<span id="cb15-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb15-18">    h, k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m.shape</span>
<span id="cb15-19">    k2, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n.shape</span>
<span id="cb15-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> k2, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Size mismatch!"</span></span>
<span id="cb15-21"></span>
<span id="cb15-22">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize output matrix</span></span>
<span id="cb15-23">    output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(h, w, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m.dtype)</span>
<span id="cb15-24"></span>
<span id="cb15-25">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up thread and block dimensions</span></span>
<span id="cb15-26">    tpb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim3(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Threads per block</span></span>
<span id="cb15-27">    blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim3(cdiv(w, tpb.x), cdiv(h, tpb.y))  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of blocks</span></span>
<span id="cb15-28"></span>
<span id="cb15-29">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Launch the kernel</span></span>
<span id="cb15-30">    blk_kernel2d(matmul_bk, blocks, tpb,</span>
<span id="cb15-31">                 m.flatten(), n.flatten(), output.flatten(), h, w, k)</span>
<span id="cb15-32"></span>
<span id="cb15-33">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> output</span></code></pre></div>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify the result by comparing with PyTorch's built-in matrix multiplication</span></span>
<span id="cb16-2">torch.isclose(matmul_2d(m1s, m2s), m1s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2s).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True)</code></pre>
<ul>
<li><strong>Simple Kernel Runner:</strong> Iterates through simulated blocks and threads, calling a kernel function (not a real CUDA kernel).</li>
</ul></li>
<li><p><strong>CUDA Kernel Runner:</strong> Similar to the simple kernel runner but uses CUDA’s syntax for launching kernels (triple angle brackets).</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA kernel definition and PyTorch C++ extension implementation</span></span>
<span id="cb18-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb18-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">__global__ void matmul_k(float* m, float* n, float* out, int h, int w, int k) {</span></span>
<span id="cb18-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Calculate global thread indices</span></span>
<span id="cb18-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int r = blockIdx.y*blockDim.y + threadIdx.y;</span></span>
<span id="cb18-6"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int c = blockIdx.x*blockDim.x + threadIdx.x;</span></span>
<span id="cb18-7"></span>
<span id="cb18-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Check if thread is within matrix bounds</span></span>
<span id="cb18-9"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    if (r &gt;= h || c &gt;= w) return;</span></span>
<span id="cb18-10"></span>
<span id="cb18-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Perform dot product for this element</span></span>
<span id="cb18-12"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    float o = 0;</span></span>
<span id="cb18-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    for (int i = 0; i &lt; k; ++i) o += m[r*k+i] * n[i*w+c];</span></span>
<span id="cb18-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    out[r*w+c] = o;</span></span>
<span id="cb18-15"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb18-16"></span>
<span id="cb18-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor matmul(torch::Tensor m, torch::Tensor n) {</span></span>
<span id="cb18-18"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(m); CHECK_INPUT(n);</span></span>
<span id="cb18-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int h = m.size(0);</span></span>
<span id="cb18-20"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int w = n.size(1);</span></span>
<span id="cb18-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int k = m.size(1);</span></span>
<span id="cb18-22"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    TORCH_CHECK(k==n.size(0), "Size mismatch!");</span></span>
<span id="cb18-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    auto output = torch::zeros({h, w}, m.options());</span></span>
<span id="cb18-24"></span>
<span id="cb18-25"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Define thread block and grid dimensions</span></span>
<span id="cb18-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 tpb(16,16);</span></span>
<span id="cb18-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));</span></span>
<span id="cb18-28"></span>
<span id="cb18-29"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Launch CUDA kernel</span></span>
<span id="cb18-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    matmul_k&lt;&lt;&lt;blocks, tpb&gt;&gt;&gt;(</span></span>
<span id="cb18-31"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        m.data_ptr&lt;float&gt;(), n.data_ptr&lt;float&gt;(), output.data_ptr&lt;float&gt;(), h, w, k);</span></span>
<span id="cb18-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    C10_CUDA_KERNEL_LAUNCH_CHECK();</span></span>
<span id="cb18-33"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb18-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb18-35"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span></code></pre></div>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">fname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'matmul'</span></span></code></pre></div>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> get_sig(fname, src):</span>
<span id="cb20-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb20-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Extract the function signature from the source code.</span></span>
<span id="cb20-4"></span>
<span id="cb20-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb20-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        fname (str): The name of the function to extract.</span></span>
<span id="cb20-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        src (str): The source code to search.</span></span>
<span id="cb20-8"></span>
<span id="cb20-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb20-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        str: The function signature with a semicolon appended, or None if not found.</span></span>
<span id="cb20-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb20-12">    res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> re.findall(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">rf'^(.+\s+</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fname<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">\(.*?\))\s*</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">{{</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">?\s*$'</span>, src, re.MULTILINE)</span>
<span id="cb20-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> res[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">';'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> res <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span></code></pre></div>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_sig(fname, cuda_src)</span>
<span id="cb21-2">cpp_src</span></code></pre></div>
<pre class="text"><code>'torch::Tensor matmul(torch::Tensor m, torch::Tensor n);'</code></pre>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the CUDA module</span></span>
<span id="cb23-2">module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_cuda(cuda_src, cpp_src, [fname])</span></code></pre></div>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Move tensors to GPU and ensure they are contiguous</span></span>
<span id="cb24-2">m1c, m2c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m1.contiguous().cuda(), m2.contiguous().cuda()</span></code></pre></div>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check the shape of the output</span></span>
<span id="cb25-2">module.matmul(m1c, m2c).shape</span></code></pre></div>
<pre class="text"><code>torch.Size([5120, 5120])</code></pre>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify correctness by comparing with PyTorch's built-in matrix multiplication</span></span>
<span id="cb27-2">torch.isclose(module.matmul(m1c, m2c), m1c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2c).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True, device='cuda:0')</code></pre>
<ul>
<li><strong>CUDA Kernel (Naive):</strong> ChatGPT-generated CUDA code based on the naive Python kernel.</li>
</ul></li>
<li><p><strong>Performance:</strong> CUDA version is significantly faster than pure Python.</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb29-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Benchmark the custom CUDA matmul implementation</span></span>
<span id="cb29-3">module.matmul(m1c, m2c)</span>
<span id="cb29-4">torch.cuda.synchronize()</span></code></pre></div>
<pre class="text"><code>3 ms ± 177 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre></li>
</ul>
</section>
</section>
<section id="optimizing-with-shared-memory" class="level2">
<h2 class="anchored" data-anchor-id="optimizing-with-shared-memory">Optimizing with Shared Memory</h2>
<section id="tiling" class="level3">
<h3 class="anchored" data-anchor-id="tiling">Tiling</h3>
<ul>
<li><strong>Problem:</strong> Repeated global memory access in the inner loop of the matrix multiplication kernel.</li>
<li><strong>Solution:</strong> <strong>Tiling</strong> – dividing the matrices into smaller <strong>tiles</strong> and performing the multiplication tile-by-tile.</li>
<li><strong>Tile Width (TW):</strong> The dimension of a square tile (e.g., 16x16).</li>
<li><strong>Process:</strong>
<ol type="1">
<li>Load a tile from <code>m1</code> and a tile from <code>m2</code> into shared memory.</li>
<li>Calculate the partial dot products for all elements within the output tile using the shared memory tiles.</li>
<li>Repeat for all tiles, accumulating the partial dot products to get the final result.</li>
</ol></li>
<li><strong>Benefits:</strong>
<ul>
<li>Each input element is read from global memory only once.</li>
<li>Dot products are calculated using much faster shared memory.</li>
</ul></li>
</ul>
</section>
<section id="implementing-tiling-in-python" class="level3">
<h3 class="anchored" data-anchor-id="implementing-tiling-in-python">Implementing Tiling in Python</h3>
<ul>
<li><p><strong>Dynamic Shared Memory Simulation:</strong> Using NumPy or PyTorch tensor views to simulate dynamic shared memory allocation in CUDA.</p></li>
<li><p><strong>Shared Memory Kernel Runner:</strong></p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> blk_kernel2d_shar(f, blocks, threads, sh_sz, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb31-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb31-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Execute a 2D block kernel with shared memory.</span></span>
<span id="cb31-4"></span>
<span id="cb31-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb31-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        f (function): The kernel function to execute</span></span>
<span id="cb31-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blocks (dim3): Number of blocks in x and y dimensions</span></span>
<span id="cb31-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        threads (dim3): Number of threads per block</span></span>
<span id="cb31-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        sh_sz (int): Size of shared memory</span></span>
<span id="cb31-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        *args: Additional positional arguments for the kernel function</span></span>
<span id="cb31-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        **kwargs: Additional keyword arguments for the kernel function</span></span>
<span id="cb31-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb31-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i0 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blocks.y):</span>
<span id="cb31-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i1 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blocks.x):</span>
<span id="cb31-15">            shared <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(sh_sz)</span>
<span id="cb31-16">            f(dim3(i1, i0), threads, shared, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span></code></pre></div>
<ul>
<li>Iterates through blocks.</li>
<li>Creates a simulated shared memory array.</li>
<li>Calls the kernel function, passing the shared memory.</li>
</ul></li>
<li><p><strong>Tiled Matrix Multiplication Kernel (Python):</strong></p>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_tiled_bk(blockIdx, blockDim, shared, m, n, out, h, w, k, tw):</span>
<span id="cb32-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform tiled matrix multiplication using block-wise computation.</span></span>
<span id="cb32-4"></span>
<span id="cb32-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb32-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockIdx (dim3): Current block index</span></span>
<span id="cb32-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockDim (dim3): Block dimensions</span></span>
<span id="cb32-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        shared (Tensor): Shared memory tensor</span></span>
<span id="cb32-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        m (Tensor): First input matrix (flattened)</span></span>
<span id="cb32-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (Tensor): Second input matrix (flattened)</span></span>
<span id="cb32-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        out (Tensor): Output matrix (flattened)</span></span>
<span id="cb32-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        h (int): Height of the first matrix</span></span>
<span id="cb32-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        w (int): Width of the second matrix</span></span>
<span id="cb32-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        k (int): Shared dimension of the two matrices</span></span>
<span id="cb32-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tw (int): Tile width</span></span>
<span id="cb32-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb32-17">    shar_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> tw</span>
<span id="cb32-18">    ms, ns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shared[:shar_sz], shared[shar_sz:]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split shared memory for both matrices</span></span>
<span id="cb32-19"></span>
<span id="cb32-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> ph <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(cdiv(k, tw)):</span>
<span id="cb32-21">        idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ph <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> tw</span>
<span id="cb32-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fill shared memory with tiles from input matrices</span></span>
<span id="cb32-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> tr <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blockDim.y):</span>
<span id="cb32-24">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> tc <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blockDim.x):</span>
<span id="cb32-25">                r, c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> blockIdx.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockDim.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tr, blockIdx.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockDim.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tc</span>
<span id="cb32-26">                ms[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m[tc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>k] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> k <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb32-27">                ns[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n[(tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>idx)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> c] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> w <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> k <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb32-28"></span>
<span id="cb32-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute dot products using shared memory</span></span>
<span id="cb32-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> tr <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blockDim.y):</span>
<span id="cb32-31">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> tc <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blockDim.x):</span>
<span id="cb32-32">                r, c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> blockIdx.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockDim.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tr, blockIdx.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockDim.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tc</span>
<span id="cb32-33">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(tw):</span>
<span id="cb32-34">                    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(out):</span>
<span id="cb32-35">                        out[r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>c] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> ms[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> ns[tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc]</span></code></pre></div>
<ul>
<li><strong>Fill Shared Memory:</strong>
<ul>
<li>Loops through each tile.</li>
<li>Calculates the starting index (<strong>idx</strong>) of the tile in the original matrix.</li>
<li>Loops through threads within the tile.</li>
<li>Calculates the row (<strong>r</strong>) and column (<strong>c</strong>) in the original matrix based on the tile index and thread index.</li>
<li>Copies the corresponding elements from the input matrices to the shared memory tiles (<code>ms</code>, <code>ns</code>).</li>
<li><strong>Padding:</strong> Fills elements outside the matrix boundaries with zeros.</li>
</ul></li>
<li><strong>Dot Product from Shared Memory:</strong>
<ul>
<li>Loops through threads within the tile.</li>
<li>Calculates the row and column in the output matrix.</li>
<li>Performs the dot product using elements from the shared memory tiles.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_2d(m, n, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>):</span>
<span id="cb33-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb33-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform 2D matrix multiplication using tiled block-wise computation.</span></span>
<span id="cb33-4"></span>
<span id="cb33-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb33-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        m (Tensor): First input matrix</span></span>
<span id="cb33-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (Tensor): Second input matrix</span></span>
<span id="cb33-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tw (int, optional): Tile width. Defaults to 16.</span></span>
<span id="cb33-9"></span>
<span id="cb33-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb33-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Tensor: Result of matrix multiplication</span></span>
<span id="cb33-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb33-13">    h, k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m.shape</span>
<span id="cb33-14">    k2, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n.shape</span>
<span id="cb33-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> k2, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Size mismatch!"</span></span>
<span id="cb33-16"></span>
<span id="cb33-17">    output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(h, w, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m.dtype)</span>
<span id="cb33-18">    tpb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim3(tw, tw)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Threads per block</span></span>
<span id="cb33-19">    blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim3(cdiv(w, tpb.x), cdiv(h, tpb.y))  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of blocks</span></span>
<span id="cb33-20"></span>
<span id="cb33-21">    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb33-22">                      m.flatten(), n.flatten(), output.flatten(),</span>
<span id="cb33-23">                      h, w, k, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tw)</span>
<span id="cb33-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> output</span></code></pre></div>
<div class="sourceCode" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize a tensor 'a' with 5 zeros</span></span>
<span id="cb34-2">a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb34-3"></span>
<span id="cb34-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split 'a' into two parts: 'b' (first 3 elements) and 'c' (last 2 elements)</span></span>
<span id="cb34-5">b, c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>], a[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>:]</span></code></pre></div>
<div class="sourceCode" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Modify specific elements in 'b' and 'c'</span></span>
<span id="cb35-2">b[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb35-3">c[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span></span>
<span id="cb35-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The value of 'a' is now implicitly modified due to tensor slicing</span></span>
<span id="cb35-5">a</span></code></pre></div>
<pre class="text"><code>tensor([0., 2., 0., 6., 0.])</code></pre>
<div class="sourceCode" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check shapes of matrices m1s and m2s</span></span>
<span id="cb37-2">m1s.shape, m2.shape</span></code></pre></div>
<div class="sourceCode" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">(torch.Size([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>]), torch.Size([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5120</span>]))</span></code></pre></div></li>
<li><p><strong>Result:</strong> The Python tiled matrix multiplication produces the same result as the previous versions.</p>
<div class="sourceCode" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify if the custom matmul_2d function produces the same result as PyTorch's built-in matrix multiplication</span></span>
<span id="cb39-2">torch.isclose(matmul_2d(m1s, m2s, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>), m1s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2s).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True)</code></pre></li>
</ul>
</section>
<section id="refactoring-the-python-kernel" class="level3">
<h3 class="anchored" data-anchor-id="refactoring-the-python-kernel">Refactoring the Python Kernel</h3>
<ul>
<li><p><strong><code>run_threads</code> Function:</strong> Introduced to abstract the looping through threads within a tile.</p>
<div class="sourceCode" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> run_threads(f, blockDim, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb41-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb41-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Simulate thread execution in a 2D block.</span></span>
<span id="cb41-4"></span>
<span id="cb41-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb41-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        f (callable): Function to be executed by each thread.</span></span>
<span id="cb41-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockDim (object): Object containing x and y dimensions of the block.</span></span>
<span id="cb41-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        *args: Variable length argument list to be passed to f.</span></span>
<span id="cb41-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        **kwargs: Arbitrary keyword arguments to be passed to f.</span></span>
<span id="cb41-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb41-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i0 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blockDim.y):</span>
<span id="cb41-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i1 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blockDim.x):</span>
<span id="cb41-13">            f(i0, i1, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Execute function for each thread</span></span></code></pre></div></li>
<li><p><strong>Refactored Kernel:</strong></p>
<div class="sourceCode" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_tiled_bk(blockIdx, blockDim, shared, m, n, out, h, w, k, tw):</span>
<span id="cb42-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb42-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform tiled matrix multiplication for a single block.</span></span>
<span id="cb42-4"></span>
<span id="cb42-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb42-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockIdx (object): Block index in the grid.</span></span>
<span id="cb42-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockDim (object): Dimensions of the block.</span></span>
<span id="cb42-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        shared (list): Shared memory for the block.</span></span>
<span id="cb42-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        m (Tensor): First input matrix.</span></span>
<span id="cb42-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (Tensor): Second input matrix.</span></span>
<span id="cb42-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        out (Tensor): Output matrix.</span></span>
<span id="cb42-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        h (int): Height of the output matrix.</span></span>
<span id="cb42-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        w (int): Width of the output matrix.</span></span>
<span id="cb42-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        k (int): Common dimension of input matrices.</span></span>
<span id="cb42-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tw (int): Tile width.</span></span>
<span id="cb42-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb42-17">    shar_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw</span>
<span id="cb42-18">    ms, ns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shared[:shar_sz], shared[shar_sz:]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split shared memory for matrices m and n</span></span>
<span id="cb42-19"></span>
<span id="cb42-20">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> get_rc(tr, tc):</span>
<span id="cb42-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Calculate global row and column indices from thread indices."""</span></span>
<span id="cb42-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> blockIdx.y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>blockDim.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tr, blockIdx.x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>blockDim.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tc</span>
<span id="cb42-23"></span>
<span id="cb42-24">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> fill_shared_tk(tr, tc, ph):</span>
<span id="cb42-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Fill shared memory with a tile of input matrices."""</span></span>
<span id="cb42-26">        r, c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_rc(tr, tc)</span>
<span id="cb42-27">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load elements from matrix m, use 0 if out of bounds</span></span>
<span id="cb42-28">        ms[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m[tc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>k] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> (ph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> k <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb42-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load elements from matrix n, use 0 if out of bounds</span></span>
<span id="cb42-30">        ns[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n[(tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> c] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> w <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> (ph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tr) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> k <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb42-31"></span>
<span id="cb42-32">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> dotprod_tk(tr, tc):</span>
<span id="cb42-33">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Compute partial dot product for a tile."""</span></span>
<span id="cb42-34">        r, c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_rc(tr, tc)</span>
<span id="cb42-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(tw):</span>
<span id="cb42-36">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(out):</span>
<span id="cb42-37">                out[r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>c] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> ms[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> ns[tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Accumulate dot product</span></span>
<span id="cb42-38"></span>
<span id="cb42-39">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate over tiles in the k dimension</span></span>
<span id="cb42-40">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> ph <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(math.ceil(k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>tw))):</span>
<span id="cb42-41">        run_threads(fill_shared_tk, blockDim, ph)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load tile into shared memory</span></span>
<span id="cb42-42">        run_threads(dotprod_tk, blockDim)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute partial dot products</span></span></code></pre></div>
<ul>
<li>Uses <code>run_threads</code> to simplify the code and make it more readable.</li>
<li>Separates the “fill shared memory” and “dot product” logic into distinct functions.</li>
</ul>
<div class="sourceCode" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_2d(m, n, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>):</span>
<span id="cb43-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb43-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform 2D matrix multiplication using tiled algorithm.</span></span>
<span id="cb43-4"></span>
<span id="cb43-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb43-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        m (Tensor): First input matrix.</span></span>
<span id="cb43-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (Tensor): Second input matrix.</span></span>
<span id="cb43-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tw (int, optional): Tile width. Defaults to 16.</span></span>
<span id="cb43-9"></span>
<span id="cb43-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb43-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Tensor: Result of matrix multiplication.</span></span>
<span id="cb43-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb43-13">    h, k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m.shape</span>
<span id="cb43-14">    k2, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n.shape</span>
<span id="cb43-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> k2, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Size mismatch!"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure matrices can be multiplied</span></span>
<span id="cb43-16"></span>
<span id="cb43-17">    output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(h, w, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m.dtype)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize output matrix</span></span>
<span id="cb43-18">    tpb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim3(tw, tw)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define threads per block</span></span>
<span id="cb43-19">    blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim3(cdiv(w, tpb.x), cdiv(h, tpb.y))  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate number of blocks needed</span></span>
<span id="cb43-20"></span>
<span id="cb43-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Launch kernel for tiled matrix multiplication</span></span>
<span id="cb43-22">    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb43-23">                      m.flatten(), n.flatten(), output.flatten(),</span>
<span id="cb43-24">                      h, w, k, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tw)</span>
<span id="cb43-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> output</span></code></pre></div></li>
<li><p><strong>Result:</strong> The refactored kernel is functionally equivalent to the previous version.</p>
<div class="sourceCode" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check shapes of input matrices</span></span>
<span id="cb44-2">m1s.shape, m2s.shape</span></code></pre></div>
<pre class="text"><code>(torch.Size([4, 256]), torch.Size([256, 4]))</code></pre>
<div class="sourceCode" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify the result of matmul_2d against PyTorch's built-in matrix multiplication</span></span>
<span id="cb46-2">torch.isclose(matmul_2d(m1s, m2s, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>), m1s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2s).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True)</code></pre></li>
</ul>
</section>
<section id="cuda-like-python-implementation-with-threads" class="level3">
<h3 class="anchored" data-anchor-id="cuda-like-python-implementation-with-threads">CUDA-Like Python Implementation with Threads</h3>
<ul>
<li><p><strong>Motivation:</strong> CUDA kernels don’t have explicit loops for threads; threads are executed concurrently.</p></li>
<li><p><strong>Simulating Concurrent Threads:</strong> Python’s <code>threading</code> library is used to simulate concurrent thread execution.</p>
<div class="sourceCode" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> threading</span>
<span id="cb48-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> threading <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Barrier, Thread  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># For thread synchronization and creation</span></span>
<span id="cb48-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> concurrent.futures <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ThreadPoolExecutor  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># For managing a pool of worker threads</span></span></code></pre></div>
<div class="sourceCode" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> g(x, sb):</span>
<span id="cb49-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb49-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A function that prints a number, its negative, and its tenfold value using a synchronization barrier.</span></span>
<span id="cb49-4"></span>
<span id="cb49-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb49-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        x (int): The input number to be processed.</span></span>
<span id="cb49-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        sb (threading.Barrier): A synchronization barrier to coordinate threads.</span></span>
<span id="cb49-8"></span>
<span id="cb49-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function demonstrates the use of a barrier for thread synchronization.</span></span>
<span id="cb49-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb49-11">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(x)</span>
<span id="cb49-12">    sb.wait()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Wait for all threads to reach this point</span></span>
<span id="cb49-13">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>x)</span>
<span id="cb49-14">    sb.wait()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Wait again for all threads to reach this point</span></span>
<span id="cb49-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span></code></pre></div>
<div class="sourceCode" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the number of threads to use</span></span>
<span id="cb50-2">num <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb50-3"></span>
<span id="cb50-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a Barrier object for synchronizing 'num' threads</span></span>
<span id="cb50-5">sb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Barrier(num)</span>
<span id="cb50-6"></span>
<span id="cb50-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use a ThreadPoolExecutor to manage a pool of worker threads</span></span>
<span id="cb50-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> ThreadPoolExecutor(num) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> ex:</span>
<span id="cb50-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Execute the function g for each number in range(1, num+1) using the thread pool</span></span>
<span id="cb50-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The lambda function is used to pass both the number and the Barrier object to g</span></span>
<span id="cb50-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># list() is used to force immediate execution of all tasks</span></span>
<span id="cb50-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(ex.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> i: g(i, sb), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, num<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)))</span></code></pre></div>
<pre class="text"><code>1
2
3
-3
-1
-2
10
20
30</code></pre></li>
<li><p><strong>Synchronization Barrier:</strong> A <code>Barrier</code> object is used to synchronize threads, ensuring that all threads complete the “fill shared memory” step before proceeding to the “dot product” step.</p></li>
<li><p><strong>Kernel Runner:</strong></p>
<div class="sourceCode" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> blk_kernel2d_shar(f, blocks, tpb, sh_sz, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb52-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb52-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Execute a 2D block kernel function with shared memory.</span></span>
<span id="cb52-4"></span>
<span id="cb52-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb52-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        f (function): The kernel function to be executed.</span></span>
<span id="cb52-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blocks (dim3): The number of blocks in x and y dimensions.</span></span>
<span id="cb52-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tpb (dim3): Threads per block in x and y dimensions.</span></span>
<span id="cb52-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        sh_sz (int): Size of shared memory.</span></span>
<span id="cb52-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        *args: Variable length argument list for the kernel function.</span></span>
<span id="cb52-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        **kwargs: Arbitrary keyword arguments for the kernel function.</span></span>
<span id="cb52-12"></span>
<span id="cb52-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function creates a grid of threads to execute the given kernel function.</span></span>
<span id="cb52-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb52-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i0 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blocks.y):</span>
<span id="cb52-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i1 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blocks.x):</span>
<span id="cb52-17">            shar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(sh_sz)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shared memory for the block</span></span>
<span id="cb52-18">            syncb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Barrier(tpb.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> tpb.x)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Synchronization barrier for threads in a block</span></span>
<span id="cb52-19"></span>
<span id="cb52-20">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create threads for each element in the block</span></span>
<span id="cb52-21">            threads <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [Thread(target<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>f, args<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(dim3(i1,i0), dim3(p,o), tpb, shar, syncb, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args), kwargs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>kwargs)</span>
<span id="cb52-22">                       <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> o <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(tpb.y) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(tpb.x)]</span>
<span id="cb52-23"></span>
<span id="cb52-24">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Start and join all threads in the block</span></span>
<span id="cb52-25">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> tr <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> threads: tr.start()</span>
<span id="cb52-26">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> tr <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> threads: tr.join()</span></code></pre></div>
<ul>
<li>Creates a synchronization barrier.</li>
<li>Creates a thread for each element within a tile.</li>
<li>Passes the block index, thread index, shared memory, synchronization barrier, and kernel arguments to each thread.</li>
</ul></li>
<li><p><strong>Kernel (Python with Threads):</strong></p>
<div class="sourceCode" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_tiled_bk(blockIdx, threadIdx, blockDim, shared, syncb, m, n, out, h, w, k, tw):</span>
<span id="cb53-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb53-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform tiled matrix multiplication for a single block.</span></span>
<span id="cb53-4"></span>
<span id="cb53-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb53-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockIdx (dim3): Block index in the grid.</span></span>
<span id="cb53-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        threadIdx (dim3): Thread index within the block.</span></span>
<span id="cb53-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockDim (dim3): Dimensions of the block.</span></span>
<span id="cb53-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        shared (torch.Tensor): Shared memory for the block.</span></span>
<span id="cb53-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        syncb (threading.Barrier): Synchronization barrier for threads in the block.</span></span>
<span id="cb53-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        m (torch.Tensor): First input matrix (flattened).</span></span>
<span id="cb53-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (torch.Tensor): Second input matrix (flattened).</span></span>
<span id="cb53-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        out (torch.Tensor): Output matrix (flattened).</span></span>
<span id="cb53-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        h (int): Height of the first matrix.</span></span>
<span id="cb53-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        w (int): Width of the second matrix.</span></span>
<span id="cb53-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        k (int): Shared dimension of the matrices.</span></span>
<span id="cb53-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tw (int): Tile width.</span></span>
<span id="cb53-18"></span>
<span id="cb53-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function computes a portion of the matrix multiplication result for a single block.</span></span>
<span id="cb53-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb53-21">    tc, tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> threadIdx.x, threadIdx.y</span>
<span id="cb53-22">    r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> blockIdx.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockDim.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tr</span>
<span id="cb53-23">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> blockIdx.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockDim.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tc</span>
<span id="cb53-24">    shar_sz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> tw</span>
<span id="cb53-25">    ms, ns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shared[:shar_sz], shared[shar_sz:]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split shared memory for two matrices</span></span>
<span id="cb53-26">    p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb53-27"></span>
<span id="cb53-28">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> ph <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(cdiv(k, tw)):</span>
<span id="cb53-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load data into shared memory</span></span>
<span id="cb53-30">        ms[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m[tc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>k] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> (ph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> k <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb53-31">        ns[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n[(tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> ph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> c] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> w <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> (ph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tr) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> k <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb53-32">        syncb.wait()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Synchronize threads after loading data</span></span>
<span id="cb53-33"></span>
<span id="cb53-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute partial dot product</span></span>
<span id="cb53-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(tw):</span>
<span id="cb53-36">            p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> ms[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> ns[tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc]</span>
<span id="cb53-37">        syncb.wait()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Synchronize threads before next iteration</span></span>
<span id="cb53-38"></span>
<span id="cb53-39">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> w):</span>
<span id="cb53-40">        out[r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> c] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> p  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Store the result in the output matrix</span></span></code></pre></div>
<ul>
<li>Calculates row and column in the output matrix based on block and thread indices.</li>
<li>Fills shared memory (same as before).</li>
<li>Waits at the synchronization barrier (<code>syncb.wait()</code>).</li>
<li>Performs the dot product using shared memory.</li>
<li>Waits at the synchronization barrier again.</li>
</ul>
<div class="sourceCode" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_2d(m, n, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>):</span>
<span id="cb54-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb54-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform 2D matrix multiplication using tiled algorithm.</span></span>
<span id="cb54-4"></span>
<span id="cb54-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb54-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        m (torch.Tensor): First input matrix.</span></span>
<span id="cb54-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (torch.Tensor): Second input matrix.</span></span>
<span id="cb54-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        tw (int, optional): Tile width. Defaults to 16.</span></span>
<span id="cb54-9"></span>
<span id="cb54-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb54-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        torch.Tensor: Result of matrix multiplication.</span></span>
<span id="cb54-12"></span>
<span id="cb54-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function orchestrates the tiled matrix multiplication using block kernels.</span></span>
<span id="cb54-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb54-15">    h, k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m.shape</span>
<span id="cb54-16">    k2, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n.shape</span>
<span id="cb54-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> k2, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Size mismatch!"</span></span>
<span id="cb54-18"></span>
<span id="cb54-19">    output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(h, w, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m.dtype)</span>
<span id="cb54-20">    tpb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim3(tw, tw)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Threads per block</span></span>
<span id="cb54-21">    blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim3(cdiv(w, tpb.x), cdiv(h, tpb.y))  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of blocks</span></span>
<span id="cb54-22"></span>
<span id="cb54-23">    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb54-24">                      m.flatten(), n.flatten(), output.flatten(),</span>
<span id="cb54-25">                      h, w, k, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tw)</span>
<span id="cb54-26">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> output</span></code></pre></div></li>
<li><p><strong>Result:</strong> The Python implementation using threads simulates CUDA’s concurrent thread execution and produces the same result.</p>
<div class="sourceCode" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify the correctness of the implementation</span></span>
<span id="cb55-2">torch.isclose(matmul_2d(m1s, m2s, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>), m1s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2s).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True)</code></pre></li>
</ul>
</section>
<section id="implementing-tiling-in-cuda" class="level3">
<h3 class="anchored" data-anchor-id="implementing-tiling-in-cuda">Implementing Tiling in CUDA</h3>
<ul>
<li><p><strong>CUDA Kernel (Tiled):</strong> ChatGPT-generated CUDA code based on the tiled Python kernel.</p>
<blockquote class="blockquote">
<p>Code auto-generated by ChatGPT 4, using the following prompt:</p>
<blockquote class="blockquote">
<p>Convert the following python code to CUDA C, keeping formatting and variable names the same where possible. You can remove <code>blockIdx, threadIdx, blockDim, shared</code> from the argument list, since they’re already provided by CUDA. Change <code>syncb.wait()</code> to <code>__syncthreads</code>. Use <code>extern __shared__ float shared[]</code> to create the <code>shared</code> array. Use the C ternary operator to replace the Python equivalent where appropriate. If the Python code uses any non-standard functions, you can assume the same functions are also available to the translated C code with the same name and signature.</p>
</blockquote>
<p>The generated code worked first time, although we did some minor cleanups afterwards (e.g.&nbsp;renaming <code>shared</code> to <code>ms</code>).</p>
</blockquote></li>
<li><p><strong>Dynamic Shared Memory Allocation:</strong> Uses <code>extern __shared__ float ms[];</code> to declare shared memory dynamically. The size is specified when launching the kernel.</p>
<div class="sourceCode" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA kernel code for matrix multiplication</span></span>
<span id="cb57-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb57-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb57-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @brief CUDA kernel for matrix multiplication.</span></span>
<span id="cb57-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * </span></span>
<span id="cb57-6"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param m Pointer to the first input matrix</span></span>
<span id="cb57-7"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param n Pointer to the second input matrix</span></span>
<span id="cb57-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param out Pointer to the output matrix</span></span>
<span id="cb57-9"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param h Height of the first matrix</span></span>
<span id="cb57-10"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param w Width of the second matrix</span></span>
<span id="cb57-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param k Width of the first matrix / Height of the second matrix</span></span>
<span id="cb57-12"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param tw Tile width for shared memory optimization</span></span>
<span id="cb57-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb57-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k, int tw) {</span></span>
<span id="cb57-15"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int tc=threadIdx.x, tr=threadIdx.y;</span></span>
<span id="cb57-16"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;</span></span>
<span id="cb57-17"></span>
<span id="cb57-18"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    extern __shared__ float ms[];  // Shared memory for the first matrix</span></span>
<span id="cb57-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    float *ns = &amp;ms[tw*tw];  // Shared memory for the second matrix</span></span>
<span id="cb57-20"></span>
<span id="cb57-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    float p = 0.0f;  // Accumulator for the dot product</span></span>
<span id="cb57-22"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    for (int ph = 0; ph &lt; cdiv(k,tw); ++ph) {</span></span>
<span id="cb57-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        int idx = ph*tw;</span></span>
<span id="cb57-24"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Load data into shared memory, with bounds checking</span></span>
<span id="cb57-25"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        ms[tr*tw + tc] = r&lt;h &amp;&amp; idx+tc&lt;k ? m[ tc+idx + r*k ] : 0.0f;</span></span>
<span id="cb57-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        ns[tr*tw + tc] = c&lt;w &amp;&amp; idx+tr&lt;k ? n[(tr+idx)*w + c] : 0.0f;</span></span>
<span id="cb57-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        __syncthreads();  // Ensure all threads have loaded data</span></span>
<span id="cb57-28"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Compute partial dot product</span></span>
<span id="cb57-29"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        for (int i=0; i&lt;tw; ++i) p += ms[tr*tw + i] * ns[tw*i + tc];</span></span>
<span id="cb57-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        __syncthreads();  // Ensure all threads have finished computation</span></span>
<span id="cb57-31"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb57-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Write result to global memory</span></span>
<span id="cb57-33"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    if (r&lt;h &amp;&amp; c&lt;w) out[r*w + c] = p;</span></span>
<span id="cb57-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb57-35"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span></code></pre></div>
<div class="sourceCode" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># PyTorch C++ extension for dynamic matrix multiplication</span></span>
<span id="cb58-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb58-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb58-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @brief Perform matrix multiplication using CUDA.</span></span>
<span id="cb58-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * </span></span>
<span id="cb58-6"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param m First input tensor</span></span>
<span id="cb58-7"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param n Second input tensor</span></span>
<span id="cb58-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @return torch::Tensor Result of matrix multiplication</span></span>
<span id="cb58-9"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb58-10"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor matmul_dyn(torch::Tensor m, torch::Tensor n) {</span></span>
<span id="cb58-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(m); CHECK_INPUT(n);</span></span>
<span id="cb58-12"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int h=m.size(0), w=n.size(1), k=m.size(1);</span></span>
<span id="cb58-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    TORCH_CHECK(k==n.size(0), "Size mismatch!");</span></span>
<span id="cb58-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    auto output = torch::zeros({h, w}, m.options());</span></span>
<span id="cb58-15"></span>
<span id="cb58-16"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    /*</span></span>
<span id="cb58-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Commented out section demonstrating basic idea of dynamic size calculation</span></span>
<span id="cb58-18"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    cudaDeviceProp devProp;</span></span>
<span id="cb58-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CUDA_ERR(cudaGetDeviceProperties(&amp;devProp, 0));</span></span>
<span id="cb58-20"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int maxThreads = devProp.maxThreadsPerBlock;</span></span>
<span id="cb58-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    size_t requiredSize = static_cast&lt;size_t&gt;(maxThreads) * 2 * sizeof(float);</span></span>
<span id="cb58-22"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    size_t size = min(devProp.sharedMemPerBlock, requiredSize);</span></span>
<span id="cb58-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int TW = std::sqrt(maxThreads);</span></span>
<span id="cb58-24"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    */</span></span>
<span id="cb58-25"></span>
<span id="cb58-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Fixed size configuration</span></span>
<span id="cb58-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int TW = 16;  // Tile width</span></span>
<span id="cb58-28"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    size_t size = TW*TW * 2 * sizeof(float);  // Shared memory size</span></span>
<span id="cb58-29"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 tpb(TW,TW);  // Threads per block</span></span>
<span id="cb58-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));  // Number of blocks</span></span>
<span id="cb58-31"></span>
<span id="cb58-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Launch CUDA kernel</span></span>
<span id="cb58-33"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    matmul_k&lt;&lt;&lt;blocks,tpb,size&gt;&gt;&gt;(</span></span>
<span id="cb58-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        m.data_ptr&lt;float&gt;(), n.data_ptr&lt;float&gt;(), output.data_ptr&lt;float&gt;(), h, w, k, TW);</span></span>
<span id="cb58-35"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    C10_CUDA_KERNEL_LAUNCH_CHECK();</span></span>
<span id="cb58-36"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb58-37"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb58-38"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span></code></pre></div>
<div class="sourceCode" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Name of the function to be called</span></span>
<span id="cb59-2">fname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'matmul_dyn'</span></span></code></pre></div>
<div class="sourceCode" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate C++ function signature</span></span>
<span id="cb60-2">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_sig(fname, cuda_src)</span></code></pre></div>
<div class="sourceCode" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1">module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_cuda(cuda_src, cpp_src, [fname], opt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
<pre><code># Test for correctness by comparing with PyTorch's built-in matrix multiplication
torch.isclose(module.matmul_dyn(m1c,m2c), m1c@m2c).all()</code></pre>
<pre class="text"><code>tensor(True, device='cuda:0')</code></pre></li>
<li><p><strong>Static Shared Memory Allocation:</strong> Declares shared memory arrays with fixed sizes at compile time (e.g., <code>__shared__ float ms[tw][tw];</code>).</p>
<div class="sourceCode" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA kernel and PyTorch extension for efficient matrix multiplication</span></span>
<span id="cb64-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb64-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">constexpr int tw = 16;  // Tile width for shared memory optimization</span></span>
<span id="cb64-4"></span>
<span id="cb64-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb64-6"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * CUDA kernel for matrix multiplication using shared memory tiling.</span></span>
<span id="cb64-7"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> *</span></span>
<span id="cb64-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param m Pointer to the first input matrix</span></span>
<span id="cb64-9"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param n Pointer to the second input matrix</span></span>
<span id="cb64-10"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param out Pointer to the output matrix</span></span>
<span id="cb64-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param h Height of the first input matrix and output matrix</span></span>
<span id="cb64-12"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param w Width of the second input matrix and output matrix</span></span>
<span id="cb64-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param k Width of the first input matrix / Height of the second input matrix</span></span>
<span id="cb64-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb64-15"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">__global__ void matmul_ks(float *m, float *n, float *out, int h, int w, int k) {</span></span>
<span id="cb64-16"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    __shared__ float ms[tw][tw], ns[tw][tw];  // Shared memory for tiling</span></span>
<span id="cb64-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int tc = threadIdx.x, tr = threadIdx.y;</span></span>
<span id="cb64-18"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int r = blockIdx.y * blockDim.y + tr, c = blockIdx.x * blockDim.x + tc;</span></span>
<span id="cb64-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    float p = 0.0f;  // Accumulator for dot product</span></span>
<span id="cb64-20"></span>
<span id="cb64-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Iterate over tiles</span></span>
<span id="cb64-22"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    for (int ph = 0; ph &lt; cdiv(k, tw); ++ph) {</span></span>
<span id="cb64-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        int idx = ph * tw;</span></span>
<span id="cb64-24"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Load data into shared memory, with bounds checking</span></span>
<span id="cb64-25"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        ms[tr][tc] = r &lt; h &amp;&amp; idx + tc &lt; k ? m[tc + idx + r * k] : 0.0f;</span></span>
<span id="cb64-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        ns[tr][tc] = c &lt; w &amp;&amp; idx + tr &lt; k ? n[(tr + idx) * w + c] : 0.0f;</span></span>
<span id="cb64-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        __syncthreads();  // Ensure all threads have loaded data</span></span>
<span id="cb64-28"></span>
<span id="cb64-29"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Compute partial dot product for this tile</span></span>
<span id="cb64-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        for (int i = 0; i &lt; tw; ++i) p += ms[tr][i] * ns[i][tc];</span></span>
<span id="cb64-31"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        __syncthreads();  // Ensure computation is complete before next iteration</span></span>
<span id="cb64-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb64-33"></span>
<span id="cb64-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Write result to global memory</span></span>
<span id="cb64-35"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    if (r &lt; h &amp;&amp; c &lt; w) out[r * w + c] = p;</span></span>
<span id="cb64-36"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb64-37"></span>
<span id="cb64-38"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb64-39"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * PyTorch extension for static matrix multiplication using CUDA.</span></span>
<span id="cb64-40"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> *</span></span>
<span id="cb64-41"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param m First input tensor</span></span>
<span id="cb64-42"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param n Second input tensor</span></span>
<span id="cb64-43"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @return Resulting tensor from matrix multiplication</span></span>
<span id="cb64-44"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb64-45"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor matmul_static(torch::Tensor m, torch::Tensor n) {</span></span>
<span id="cb64-46"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(m); CHECK_INPUT(n);  // Validate input tensors</span></span>
<span id="cb64-47"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int h = m.size(0), w = n.size(1), k = m.size(1);</span></span>
<span id="cb64-48"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    TORCH_CHECK(k == n.size(0), "Size mismatch!");  // Ensure matrices can be multiplied</span></span>
<span id="cb64-49"></span>
<span id="cb64-50"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    auto output = torch::zeros({h, w}, m.options());  // Initialize output tensor</span></span>
<span id="cb64-51"></span>
<span id="cb64-52"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Set up CUDA kernel launch parameters</span></span>
<span id="cb64-53"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 tpb(tw, tw);  // Threads per block</span></span>
<span id="cb64-54"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));  // Number of blocks</span></span>
<span id="cb64-55"></span>
<span id="cb64-56"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Launch CUDA kernel</span></span>
<span id="cb64-57"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    matmul_ks&lt;&lt;&lt;blocks, tpb&gt;&gt;&gt;(m.data_ptr&lt;float&gt;(), n.data_ptr&lt;float&gt;(), output.data_ptr&lt;float&gt;(), h, w, k);</span></span>
<span id="cb64-58"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    C10_CUDA_KERNEL_LAUNCH_CHECK();  // Check for CUDA errors</span></span>
<span id="cb64-59"></span>
<span id="cb64-60"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb64-61"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb64-62"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span></code></pre></div>
<div class="sourceCode" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Name of the function to be exported</span></span>
<span id="cb65-2">fname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'matmul_static'</span></span>
<span id="cb65-3"></span>
<span id="cb65-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate C++ source code for the CUDA extension</span></span>
<span id="cb65-5">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_sig(fname, cuda_src)</span>
<span id="cb65-6"></span>
<span id="cb65-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the CUDA module</span></span>
<span id="cb65-8">module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_cuda(cuda_src, cpp_src, [fname])</span>
<span id="cb65-9"></span>
<span id="cb65-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify correctness by comparing with PyTorch's built-in matrix multiplication</span></span>
<span id="cb65-11">torch.isclose(module.matmul_static(m1c, m2c), m1c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> m2c).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True, device='cuda:0')</code></pre></li>
<li><p><strong>Synchronization:</strong> <code>__syncthreads();</code> ensures all threads within a block have finished a step before proceeding to the next.</p></li>
<li><p><strong>Performance:</strong></p>
<ul>
<li><p>Dynamic shared memory version is unexpectedly slower than the naive CUDA version.</p>
<div class="sourceCode" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb67-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Benchmark the custom CUDA matrix multiplication</span></span>
<span id="cb67-3">module.matmul_dyn(m1c,m2c)</span>
<span id="cb67-4">torch.cuda.synchronize()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure CUDA operations are completed before timing</span></span></code></pre></div>
<pre class="text"><code>3.2 ms ± 57.5 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre></li>
<li><p>Static shared memory version with a fixed tile width is faster.</p>
<div class="sourceCode" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb69-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Benchmark the custom matrix multiplication</span></span>
<span id="cb69-3">module.matmul_static(m1c, m2c)</span>
<span id="cb69-4">torch.cuda.synchronize()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure CUDA operations are complete before timing</span></span></code></pre></div>
<pre class="text"><code>2.1 ms ± 23.9 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre></li>
</ul></li>
</ul>
</section>
<section id="dynamic-shared-memory-performance-issue-and-solution-update-from-the-future" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-shared-memory-performance-issue-and-solution-update-from-the-future">Dynamic Shared Memory Performance Issue and Solution (Update from the Future)</h3>
<ul>
<li><p><strong>Cause:</strong> CUDA struggles to optimize dynamic shared memory allocation when the tile width is not known at compile time, leading to slower performance.</p></li>
<li><p><strong>Solution:</strong> Use C++ templates to make the tile width a template parameter, enabling the compiler to generate optimized code for specific tile widths.</p></li>
<li><p><strong>Implementation:</strong></p>
<div class="sourceCode" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA kernel for matrix multiplication</span></span>
<span id="cb71-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb71-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">template&lt;int tw&gt;</span></span>
<span id="cb71-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k) {</span></span>
<span id="cb71-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Thread and block indices</span></span>
<span id="cb71-6"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int tc = threadIdx.x, tr = threadIdx.y;</span></span>
<span id="cb71-7"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int r = blockIdx.y * blockDim.y + tr, c = blockIdx.x * blockDim.x + tc;</span></span>
<span id="cb71-8"></span>
<span id="cb71-9"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Shared memory allocation</span></span>
<span id="cb71-10"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    extern __shared__ float ms[];</span></span>
<span id="cb71-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    float *ns = &amp;ms[tw*tw];</span></span>
<span id="cb71-12"></span>
<span id="cb71-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    float p = 0.0f;  // Accumulator for dot product</span></span>
<span id="cb71-14"></span>
<span id="cb71-15"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Iterate over blocks of the input matrices</span></span>
<span id="cb71-16"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    for (int ph = 0; ph &lt; cdiv(k,tw); ++ph) {</span></span>
<span id="cb71-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        int idx = ph * tw;</span></span>
<span id="cb71-18"></span>
<span id="cb71-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Load data into shared memory</span></span>
<span id="cb71-20"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        ms[tr*tw + tc] = r &lt; h &amp;&amp; idx+tc &lt; k ? m[tc+idx + r*k] : 0.0f;</span></span>
<span id="cb71-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        ns[tr*tw + tc] = c &lt; w &amp;&amp; idx+tr &lt; k ? n[(tr+idx)*w + c] : 0.0f;</span></span>
<span id="cb71-22"></span>
<span id="cb71-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        __syncthreads();  // Ensure all threads have loaded data</span></span>
<span id="cb71-24"></span>
<span id="cb71-25"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Compute partial dot product</span></span>
<span id="cb71-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        for (int i = 0; i &lt; tw; ++i) {</span></span>
<span id="cb71-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">            p += ms[tr*tw + i] * ns[tw*i + tc];</span></span>
<span id="cb71-28"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        }</span></span>
<span id="cb71-29"></span>
<span id="cb71-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        __syncthreads();  // Ensure all threads have used the data</span></span>
<span id="cb71-31"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb71-32"></span>
<span id="cb71-33"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Write result to global memory</span></span>
<span id="cb71-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    if (r &lt; h &amp;&amp; c &lt; w) {</span></span>
<span id="cb71-35"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        out[r*w + c] = p;</span></span>
<span id="cb71-36"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb71-37"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb71-38"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span></code></pre></div>
<div class="sourceCode" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># C++ wrapper function for the CUDA kernel</span></span>
<span id="cb72-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb72-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor matmul_dyn1(torch::Tensor m, torch::Tensor n) {</span></span>
<span id="cb72-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(m);</span></span>
<span id="cb72-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(n);</span></span>
<span id="cb72-6"></span>
<span id="cb72-7"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Get dimensions of input matrices</span></span>
<span id="cb72-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int h = m.size(0), w = n.size(1), k = m.size(1);</span></span>
<span id="cb72-9"></span>
<span id="cb72-10"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Check if matrices can be multiplied</span></span>
<span id="cb72-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    TORCH_CHECK(k == n.size(0), "Size mismatch!");</span></span>
<span id="cb72-12"></span>
<span id="cb72-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Create output tensor</span></span>
<span id="cb72-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    auto output = torch::zeros({h, w}, m.options());</span></span>
<span id="cb72-15"></span>
<span id="cb72-16"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int TW = 16;  // Thread block width (TODO: Calculate this dynamically)</span></span>
<span id="cb72-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    size_t size = TW*TW*2 * sizeof(float) + 1;  // Shared memory size</span></span>
<span id="cb72-18"></span>
<span id="cb72-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Define thread block and grid dimensions</span></span>
<span id="cb72-20"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 tpb(TW, TW);</span></span>
<span id="cb72-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));</span></span>
<span id="cb72-22"></span>
<span id="cb72-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Lambda function to launch kernel</span></span>
<span id="cb72-24"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    auto f = [&amp;](auto kf) {</span></span>
<span id="cb72-25"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        kf&lt;&lt;&lt;blocks, tpb, size&gt;&gt;&gt;(</span></span>
<span id="cb72-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">            m.data_ptr&lt;float&gt;(), n.data_ptr&lt;float&gt;(), output.data_ptr&lt;float&gt;(), h, w, k</span></span>
<span id="cb72-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        );</span></span>
<span id="cb72-28"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    };</span></span>
<span id="cb72-29"></span>
<span id="cb72-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Launch kernel based on thread block size</span></span>
<span id="cb72-31"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    switch(TW) {</span></span>
<span id="cb72-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        case 8: f(matmul_k&lt;8&gt;); break;</span></span>
<span id="cb72-33"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        case 16: f(matmul_k&lt;16&gt;); break;</span></span>
<span id="cb72-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        case 32: f(matmul_k&lt;32&gt;); break;</span></span>
<span id="cb72-35"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        default: break;</span></span>
<span id="cb72-36"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb72-37"></span>
<span id="cb72-38"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Check for CUDA errors</span></span>
<span id="cb72-39"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    C10_CUDA_KERNEL_LAUNCH_CHECK();</span></span>
<span id="cb72-40"></span>
<span id="cb72-41"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb72-42"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb72-43"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span></code></pre></div>
<ul>
<li>Define a C++ template function with tile width as a template parameter.</li>
<li>Support a fixed set of tile widths and compile a separate kernel version for each.</li>
<li>Use a lambda function to call the appropriate kernel version based on the chosen tile width.</li>
</ul></li>
<li><p><strong>Benefits:</strong> Enables optimized performance while allowing for some flexibility in tile width selection.</p>
<div class="sourceCode" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>time</span>
<span id="cb73-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Measure execution time of the following code</span></span>
<span id="cb73-3"></span>
<span id="cb73-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define function name</span></span>
<span id="cb73-5">fname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'matmul_dyn1'</span></span>
<span id="cb73-6"></span>
<span id="cb73-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate C++ function signature</span></span>
<span id="cb73-8">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_sig(fname, cuda_src)</span>
<span id="cb73-9"></span>
<span id="cb73-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load CUDA module with optimization</span></span>
<span id="cb73-11">module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_cuda(cuda_src, cpp_src, [fname], opt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb73-12"></span>
<span id="cb73-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the function from the loaded module</span></span>
<span id="cb73-14">func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(module, fname)</span></code></pre></div>
<pre class="text"><code>CPU times: user 49.5 ms, sys: 63.7 ms, total: 113 ms
Wall time: 41.1 s</code></pre>
<div class="sourceCode" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify correctness of the custom matrix multiplication</span></span>
<span id="cb75-2">torch.isclose(func(m1c, m2c), m1c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> m2c).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True, device='cuda:0')</code></pre>
<div class="sourceCode" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb77-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Measure execution time of the custom matrix multiplication</span></span>
<span id="cb77-3">func(m1c, m2c)</span>
<span id="cb77-4"></span>
<span id="cb77-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure all CUDA operations are completed</span></span>
<span id="cb77-6">torch.cuda.synchronize()</span></code></pre></div>
<pre class="text"><code>2.06 ms ± 51.2 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre></li>
</ul>
</section>
</section>
<section id="implementing-tiling-with-numba" class="level2">
<h2 class="anchored" data-anchor-id="implementing-tiling-with-numba">Implementing Tiling with Numba</h2>
<ul>
<li><p><strong><a href="https://numba.readthedocs.io/en/stable/index.html">Numba</a>:</strong> An alternative library for writing CUDA code directly in Python.</p>
<div class="sourceCode" id="cb79" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb79-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install numba</span>
<span id="cb79-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-U</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"numpy&lt;2.1"</span></span></code></pre></div>
<div class="sourceCode" id="cb80" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> numba <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cuda</span>
<span id="cb80-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> numba.cuda <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> as_cuda_array <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> ca</span></code></pre></div></li>
<li><p><strong>CUDA Kernel (Numba):</strong> Python code decorated with <code>@cuda.jit</code> to indicate it’s a CUDA kernel.</p>
<div class="sourceCode" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@cuda.jit</span></span>
<span id="cb81-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_k_numba(m, n, out, tw):</span>
<span id="cb81-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb81-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform matrix multiplication on GPU using CUDA.</span></span>
<span id="cb81-5"></span>
<span id="cb81-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This kernel function multiplies matrices 'm' and 'n', storing the result in 'out'.</span></span>
<span id="cb81-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    It uses shared memory and tiling for improved performance.</span></span>
<span id="cb81-8"></span>
<span id="cb81-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb81-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    m (ndarray): First input matrix</span></span>
<span id="cb81-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    n (ndarray): Second input matrix</span></span>
<span id="cb81-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    out (ndarray): Output matrix to store the result</span></span>
<span id="cb81-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    tw (int): Tile width for shared memory optimization</span></span>
<span id="cb81-14"></span>
<span id="cb81-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Note: This function is designed to be called from a host function, not directly.</span></span>
<span id="cb81-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb81-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get CUDA thread and block information</span></span>
<span id="cb81-18">    cbi, cbd, tid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda.blockIdx, cuda.blockDim, cuda.threadIdx</span>
<span id="cb81-19">    tc, tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tid.x, tid.y</span>
<span id="cb81-20"></span>
<span id="cb81-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate global row and column indices</span></span>
<span id="cb81-22">    r, c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cbi.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> cbd.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tr, cbi.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> cbd.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tc</span>
<span id="cb81-23"></span>
<span id="cb81-24">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get input matrix dimensions</span></span>
<span id="cb81-25">    h, k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m.shape</span>
<span id="cb81-26">    k2, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n.shape</span>
<span id="cb81-27"></span>
<span id="cb81-28">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Allocate shared memory for tile-based computation</span></span>
<span id="cb81-29">    shar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda.shared.array(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float32)</span>
<span id="cb81-30">    ms, ns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> shar[:tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw], shar[tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split shared memory for both input matrices</span></span>
<span id="cb81-31"></span>
<span id="cb81-32">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize partial sum</span></span>
<span id="cb81-33">    p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.float32(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)</span>
<span id="cb81-34"></span>
<span id="cb81-35">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate over tiles</span></span>
<span id="cb81-36">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> ph <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(math.ceil(k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>tw)):</span>
<span id="cb81-37">        idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ph <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> tw</span>
<span id="cb81-38"></span>
<span id="cb81-39">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load data into shared memory, with boundary checks</span></span>
<span id="cb81-40">        ms[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m[r, tc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>idx] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> k <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb81-41">        ns[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>idx, c] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> w <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> k <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb81-42"></span>
<span id="cb81-43">        cuda.syncthreads()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure all threads have loaded data</span></span>
<span id="cb81-44"></span>
<span id="cb81-45">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute partial dot product for this tile</span></span>
<span id="cb81-46">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(tw):</span>
<span id="cb81-47">            p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> ms[tr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> ns[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tc]</span>
<span id="cb81-48"></span>
<span id="cb81-49">        cuda.syncthreads()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure all threads have used the data before next iteration</span></span>
<span id="cb81-50"></span>
<span id="cb81-51">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Store the result if within output matrix bounds</span></span>
<span id="cb81-52">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">and</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> w:</span>
<span id="cb81-53">        out[r, c] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> p</span></code></pre></div>
<ul>
<li><strong>Shared Memory:</strong> <code>cuda.shared.array</code> creates dynamic shared memory arrays.</li>
<li><strong>Synchronization:</strong> <code>cuda.syncthreads()</code> for thread synchronization.</li>
</ul></li>
<li><p><strong>Kernel Launching:</strong> Uses square brackets instead of triple angle brackets (e.g., <code>kernel[blocks, threadsperblock, stream, shared_mem_size](...)</code>).</p>
<div class="sourceCode" id="cb82" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_2d_numba(m, n, tw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>):</span>
<span id="cb82-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb82-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform matrix multiplication using CUDA.</span></span>
<span id="cb82-4"></span>
<span id="cb82-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function prepares the CUDA kernel call for matrix multiplication.</span></span>
<span id="cb82-6"></span>
<span id="cb82-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb82-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    m (Tensor): First input matrix (PyTorch tensor on CUDA)</span></span>
<span id="cb82-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    n (Tensor): Second input matrix (PyTorch tensor on CUDA)</span></span>
<span id="cb82-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    tw (int): Tile width for shared memory optimization (default: 16)</span></span>
<span id="cb82-11"></span>
<span id="cb82-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb82-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Tensor: Result of matrix multiplication</span></span>
<span id="cb82-14"></span>
<span id="cb82-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Raises:</span></span>
<span id="cb82-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    AssertionError: If input matrices have mismatched inner dimensions</span></span>
<span id="cb82-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb82-18">    h, k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m.shape</span>
<span id="cb82-19">    k2, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n.shape</span>
<span id="cb82-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> k2, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Size mismatch!"</span></span>
<span id="cb82-21"></span>
<span id="cb82-22">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize output matrix</span></span>
<span id="cb82-23">    out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(h, w, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m.dtype, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m.device)</span>
<span id="cb82-24"></span>
<span id="cb82-25">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up CUDA kernel parameters</span></span>
<span id="cb82-26">    dyn_shared_mem_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> tw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> tw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Size of shared memory in bytes</span></span>
<span id="cb82-27">    tpb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tw, tw  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Threads per block</span></span>
<span id="cb82-28">    blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cdiv(w, tpb[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]), cdiv(h, tpb[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate grid dimensions</span></span>
<span id="cb82-29"></span>
<span id="cb82-30">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Launch CUDA kernel</span></span>
<span id="cb82-31">    matmul_k_numba[blocks, tpb, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, dyn_shared_mem_size](ca(m), ca(n), ca(out), tw)</span>
<span id="cb82-32"></span>
<span id="cb82-33">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> out</span></code></pre></div>
<div class="sourceCode" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify correctness of the implementation</span></span>
<span id="cb83-2">torch.isclose(matmul_2d_numba(m1c, m2c), m1c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2c).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True, device='cuda:0')</code></pre></li>
<li><p><strong>Performance:</strong> The Numba version with dynamic shared memory is slower than the optimized CUDA C version but still provides CUDA-level speed.</p>
<div class="sourceCode" id="cb85" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb85-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Benchmark the implementation</span></span>
<span id="cb85-3">matmul_2d_numba(m1c, m2c)</span>
<span id="cb85-4">torch.cuda.synchronize()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure all CUDA operations are completed before timing</span></span></code></pre></div>
<pre class="text"><code>7.8 ms ± 80.7 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre></li>
<li><p><strong>Benefits:</strong></p>
<ul>
<li>Faster compilation times compared to PyTorch’s CUDA C/C++ approach.
<ul>
<li>Allows for faster iteration during development.</li>
</ul></li>
<li>No need to flatten tensors (supports multidimensional indexing).</li>
<li>Access to tensor shape information within the kernel.</li>
</ul></li>
<li><p><strong><a href="https://numba.readthedocs.io/en/stable/cuda/simulator.html">CUDA Simulator</a>:</strong> Numba provides a built-in CUDA simulator by setting the environment variable <code>NUMBA_ENABLE_CUDASIM=1</code>.</p>
<ul>
<li>Executes CUDA code as pure Python on the CPU, allowing for debugging and experimentation with small datasets.</li>
</ul></li>
<li><p><strong>Development Workflow:</strong></p>
<ol type="1">
<li>Develop and debug CUDA kernels in Numba with the simulator enabled.</li>
<li>Disable the simulator to run the code on the GPU.</li>
<li>Optionally, convert the Numba code to CUDA C/C++ using ChatGPT for deployment.</li>
</ol></li>
</ul>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<ul>
<li><strong>Shipping Numba Kernels and AOT Compilation:</strong>
<ul>
<li><strong>AOT Compilation:</strong> Numba’s AOT was discussed as a potential deployment simplification solution.</li>
<li><strong>AOT Deprecation:</strong> Numba’s AOT is deprecated (February 2024), with a replacement planned but unspecified.</li>
</ul></li>
<li><strong>Performance Comparisons and Optimization Opportunities:</strong>
<ul>
<li><strong>Optimization Tools:</strong> TVM and Mojo GPU’s auto-tune (expected late February/March 2024) were mentioned as potential optimization aids.</li>
</ul></li>
<li><strong>PyTorch’s Matrix Multiplication Implementation:</strong>
<ul>
<li>PyTorch primarily uses cuBLAS.</li>
<li><strong>Torch Compile and Inductor:</strong> Torch Compile’s experimental mode (torch.inductor.config) was mentioned as a potential alternative backend.</li>
<li><strong>Profiling for Backend Identification:</strong> PyTorch’s profiler can reveal the backend used through function signatures.</li>
</ul></li>
<li><strong>Compilation Speed and Iterative Development:</strong>
<ul>
<li><strong>Compilation Speed Importance:</strong> Fast compilation was emphasized as crucial for iterative development.</li>
<li><strong>Fast Compilation Benefits:</strong> Fast compilation, aided by tools like the CUDA simulator and Numba’s CUDA JIT, enhances productivity and reduces debugging time.</li>
</ul></li>
<li><strong>ChatGPT’s Role in CUDA Development:</strong>
<ul>
<li><strong>ChatGPT’s Code Generation Capabilities:</strong> ChatGPT is useful for code conversion and API usage but less effective for novel algorithms.</li>
</ul></li>
<li><strong>Numba vs.&nbsp;Triton:</strong>
<ul>
<li><strong>Different Purposes:</strong> Numba and Triton were recognized as valuable tools with distinct strengths, suitable for different use cases. Triton’s limitations in expressing certain CUDA constructs (e.g., 4-bit discretization) were noted.</li>
<li><strong>Complementary Tools:</strong> Numba and Triton were seen as complementary, each offering unique advantages.</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>cuda</category>
  <guid>https://christianjmills.com/posts/cuda-mode-notes/lecture-005/</guid>
  <pubDate>Sun, 01 Sep 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>CUDA MODE Lecture 4: Compute and Memory Basics</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/cuda-mode-notes/lecture-004/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/cuda-mode-notes.html"><strong>CUDA Mode Lecture Notes</strong></a>: My notes from the <strong>CUDA MODE</strong> reading group lectures run by <strong>Andreas Kopf</strong> and <strong>Mark Saroufim</strong>.</li>
</ul>
</div>
</div>
<ul>
<li><strong>Compute Architecture and Scheduling</strong></li>
<li><strong>Memory Architecture and Data Locality</strong><br>
</li>
<li><strong>Conclusions and Key Takeaways</strong></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Resource Links:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resource Links:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>YouTube Recording:</strong> <a href="https://www.youtube.com/watch?v=lTmYrKwjSOU">Lecture 4 Compute and Memory Basics</a></li>
<li><strong>Jupyter Notebook:</strong> <a href="https://github.com/cuda-mode/lectures/blob/main/lecture_004/cuda-mode-session-4.ipynb">lecture_004/cuda-mode-session-4.ipynb</a></li>
<li><strong>Paper:</strong> <a href="https://www.nvidia.com/content/PDF/nvidia-ampere-ga-102-gpu-architecture-whitepaper-v2.pdf">GA102 Whitepaper</a></li>
</ul>
</div>
</div>
<section id="compute-architecture-and-scheduling" class="level2">
<h2 class="anchored" data-anchor-id="compute-architecture-and-scheduling"><strong>Compute Architecture and Scheduling</strong></h2>
<section id="gpu-architecture-vs.-cpu" class="level3">
<h3 class="anchored" data-anchor-id="gpu-architecture-vs.-cpu"><strong>GPU Architecture vs.&nbsp;CPU</strong></h3>
<ul>
<li><strong>CPUs:</strong>
<ul>
<li>Complex cores with multiple specialized units (fetch, decode, ALU).</li>
<li>Typically, one or few Arithmetic Logic Units (ALUs) per core. <img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-004/images/cpu-core.png" class="img-fluid quarto-figure quarto-figure-center"></li>
</ul></li>
<li><strong>GPUs:</strong>
<ul>
<li>Streaming Multiprocessors (SMs) with many ALUs.</li>
<li><strong>Threads</strong> share context and resources within an SM.</li>
<li>Each thread has its own program counter in newer GPUs (e.g., Volta and later).</li>
<li>Older GPUs shared program counters among threads in a warp. <img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-004/images/gpu-sm.png" class="img-fluid quarto-figure quarto-figure-center"></li>
</ul></li>
</ul>
</section>
<section id="gpu-architecture-details-rtx-3090-example" class="level3">
<h3 class="anchored" data-anchor-id="gpu-architecture-details-rtx-3090-example">GPU Architecture Details (RTX 3090 Example)</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-004/images/rtx-3090.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2. GA102 Full GPU with 84 SMs</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Note:</strong> The GA102 GPU also features 168 FP64 units (two per SM), which are not depicted in this diagram. The FP64 TFLOP rate is 1/64th the TFLOP rate of FP32 operations. The small number of FP64 hardware units are included to ensure any programs with FP64 code operate correctly, including FP64 Tensor Core code.</p>
</div>
</div>
<ul>
<li><strong>Streaming Multiprocessors (SMs):</strong>
<ul>
<li>RTX 3090 has 82 SMs.</li>
<li>SMs are largely independent.</li>
<li>Share a common L2 cache.</li>
</ul></li>
<li><strong>Floating-Point Cores:</strong>
<ul>
<li>Consumer GPUs lack dedicated FP64 cores.</li>
<li>RTX 3090 has a limited FP64 rate (1/64th of FP32).</li>
<li>Accidental use of FP64 constants can significantly slow down computation.</li>
</ul></li>
<li><strong>Streaming Multiprocessor Structure:</strong>
<ul>
<li>Each SM has four units, each with:
<ul>
<li>Register file.</li>
<li>Scheduling and dispatch unit (32 threads/clock).</li>
<li>Compute units: 32 FP32 units (half can do INT32).</li>
<li>Tensor cores.</li>
</ul></li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-004/images/figure-3-ga10x-streaming-multiprocessor-sm.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3. GA10x Streaming Multiprocessor (SM)</figcaption>
</figure>
</div>
<ul>
<li><strong>Kernel Execution:</strong>
<ul>
<li><strong>Thread blocks</strong> are assigned to SMs (no user control over assignment).</li>
<li>Multiple blocks can be assigned to one SM if resource limits allow.</li>
<li>RTX 3090 can handle up to 1536 threads per SM.</li>
<li>Ideal block size divides 1536 (e.g., 256 or 512).</li>
</ul></li>
<li><strong>Warp Execution:</strong>
<ul>
<li>Each SM processes one <strong>warp</strong> (32 threads) at a time.</li>
<li><strong>Warp divergence</strong> occurs when threads within a warp are not in sync, leading to partial execution.</li>
</ul></li>
<li><strong>Registers:</strong>
<ul>
<li>Shared register file (64K 32-bit registers per SM).</li>
<li>Registers are not cleared when switching between warps, requiring careful management of register usage.</li>
</ul></li>
<li><strong>L1 Cache and Shared Memory:</strong>
<ul>
<li>128KB of on-chip memory per SM, split between L1 cache and shared memory.</li>
</ul></li>
</ul>
</section>
<section id="threads-warps-and-blocks" class="level3">
<h3 class="anchored" data-anchor-id="threads-warps-and-blocks"><strong>Threads, Warps, and Blocks</strong></h3>
<ul>
<li><strong>Kernel Launch:</strong> Defined by block layout (threads per block) and grid layout (number of blocks).</li>
<li><strong>Thread Block:</strong>
<ul>
<li>Assigned to a single SM.</li>
<li>Threads within a block execute in parallel on the same SM.</li>
<li>Threads within a block can access <strong>shared memory</strong>.</li>
</ul></li>
<li><strong>Blocks:</strong>
<ul>
<li>Independent of each other.</li>
<li>CUDA assigns blocks to SMs arbitrarily (no programmer control).</li>
<li>Execution order of blocks is not guaranteed.</li>
</ul></li>
<li><strong>SM Thread Capacity:</strong>
<ul>
<li>SMs can process more threads than the maximum threads in a block.</li>
<li>Multiple blocks can be assigned to a single SM, if resource limits allow.</li>
<li><strong>Example (RTX 3090):</strong> Maximum 1536 threads per SM.</li>
<li><strong>Recommendation:</strong> Choose block sizes (e.g., 256, 512) that divide the maximum thread capacity for optimal SM utilization.</li>
</ul></li>
<li><strong>Warp:</strong>
<ul>
<li>A group of 32 threads.</li>
<li>SMs process one warp at a time.</li>
<li><strong>Warp Divergence:</strong> Occurs when threads within a warp follow different execution paths (e.g., due to conditional statements).
<ul>
<li>Leads to reduced performance as only a subset of threads in a warp execute at a time.</li>
</ul></li>
</ul></li>
<li><strong>AMD Terminology:</strong>
<ul>
<li><strong>Wavefronts:</strong> AMD’s term for warps.</li>
<li>Typically 64 threads, but can be reduced to 32 via compiler options.</li>
</ul></li>
</ul>
</section>
<section id="multi-dimensional-thread-grids" class="level3">
<h3 class="anchored" data-anchor-id="multi-dimensional-thread-grids"><strong>Multi-Dimensional Thread Grids</strong></h3>
<ul>
<li><p><strong>Linearization:</strong> Multi-dimensional thread grids are linearized for execution.</p></li>
<li><p><strong>Thread Index Order:</strong> <code>threadIdx.x</code> is the fastest moving dimension, followed by <code>threadIdx.y</code>, and then <code>threadIdx.z</code>.</p></li>
<li><p><strong>Example:</strong> An <code>8x8x8</code> thread block:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA kernel and C++ function declaration</span></span>
<span id="cb1-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">#include &lt;c10/cuda/CUDAException.h&gt;</span></span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb1-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> * CUDA kernel to compute thread indices of neighbors in a 3D grid.</span></span>
<span id="cb1-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> * </span></span>
<span id="cb1-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param out Pointer to output array where neighbor indices will be stored.</span></span>
<span id="cb1-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb1-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">__global__ void thread_idx_of_neighbors_kernel(int32_t* out) {</span></span>
<span id="cb1-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Grid dimensions: 8x8x8 threads per block, 32 neighbors per thread, 3 coordinates per neighbor</span></span>
<span id="cb1-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    int x = threadIdx.x;</span></span>
<span id="cb1-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    int y = threadIdx.y;</span></span>
<span id="cb1-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    int z = threadIdx.z;</span></span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Iterate over all 32 threads in the warp</span></span>
<span id="cb1-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    for (int i = 0; i &lt; 32; i++) {</span></span>
<span id="cb1-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Use warp shuffle to get coordinates of other threads</span></span>
<span id="cb1-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        int other_x = __shfl_sync(0xffffffff, x, i);</span></span>
<span id="cb1-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        int other_y = __shfl_sync(0xffffffff, y, i);</span></span>
<span id="cb1-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        int other_z = __shfl_sync(0xffffffff, z, i);</span></span>
<span id="cb1-22"></span>
<span id="cb1-23"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Calculate offset in output array and store neighbor coordinates</span></span>
<span id="cb1-24"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        int offset = z * 8*8*32*3 + y * 8*32*3 + x * 32*3 + i*3;</span></span>
<span id="cb1-25"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        out[offset] = other_x;</span></span>
<span id="cb1-26"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        out[offset + 1] = other_y;</span></span>
<span id="cb1-27"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        out[offset + 2] = other_z;</span></span>
<span id="cb1-28"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb1-29"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-30"></span>
<span id="cb1-31"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb1-32"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> * C++ wrapper function to launch the CUDA kernel and return results as a Torch tensor.</span></span>
<span id="cb1-33"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> * </span></span>
<span id="cb1-34"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @return torch::Tensor A 5D tensor containing thread indices of neighbors.</span></span>
<span id="cb1-35"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb1-36"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor thread_idx_of_neighbors() {</span></span>
<span id="cb1-37"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Create output tensor: 8x8x8 threads, 32 neighbors, 3 coordinates</span></span>
<span id="cb1-38"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    auto output = torch::empty({8, 8, 8, 32, 3}, torch::TensorOptions().device(torch::kCUDA).dtype(torch::kInt));</span></span>
<span id="cb1-39"></span>
<span id="cb1-40"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Set up kernel launch parameters</span></span>
<span id="cb1-41"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 block(8, 8, 8);</span></span>
<span id="cb1-42"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 grid(1);</span></span>
<span id="cb1-43"></span>
<span id="cb1-44"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Launch kernel</span></span>
<span id="cb1-45"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    thread_idx_of_neighbors_kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(output.data_ptr&lt;int32_t&gt;());</span></span>
<span id="cb1-46"></span>
<span id="cb1-47"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Check for CUDA errors</span></span>
<span id="cb1-48"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    C10_CUDA_KERNEL_LAUNCH_CHECK();</span></span>
<span id="cb1-49"></span>
<span id="cb1-50"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb1-51"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-52"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># C++ function declaration</span></span>
<span id="cb2-2">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor thread_idx_of_neighbors();</span></span>
<span id="cb2-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the CUDA kernel and C++ function as a PyTorch extension</span></span>
<span id="cb3-2">thread_idx_of_neighbors_module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.utils.cpp_extension.load_inline(</span>
<span id="cb3-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test_thread_idx"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Name of the extension</span></span>
<span id="cb3-4">    cpp_src,            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># C++ source code</span></span>
<span id="cb3-5">    cuda_src,           <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA source code</span></span>
<span id="cb3-6">    functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'thread_idx_of_neighbors'</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># List of functions to expose</span></span>
<span id="cb3-7">    extra_cuda_cflags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--ptxas-options=-v'</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Additional CUDA compiler flags</span></span>
<span id="cb3-8">    verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Enable verbose output during compilation</span></span>
<span id="cb3-9">)</span></code></pre></div>
<ul>
<li>Threads within a warp have consecutive <code>threadIdx.x</code> values.</li>
<li><code>threadIdx.y</code> changes less frequently than <code>threadIdx.x</code>.</li>
<li><code>threadIdx.z</code> changes least frequently.</li>
</ul></li>
<li><p><strong>Verification:</strong> Kernel code demonstrates thread indexing using shuffle instructions.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Call the CUDA kernel through the PyTorch extension</span></span>
<span id="cb4-2">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> thread_idx_of_neighbors_module.thread_idx_of_neighbors()</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Access the first element of the result tensor</span></span>
<span id="cb4-5">t[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<pre class="text"><code>tensor([[0, 0, 0],
        [1, 0, 0],
        [2, 0, 0],
        [3, 0, 0],
        [4, 0, 0],
        [5, 0, 0],
        [6, 0, 0],
        [7, 0, 0],
        [0, 1, 0],
        [1, 1, 0],
        [2, 1, 0],
        [3, 1, 0],
        [4, 1, 0],
        [5, 1, 0],
        [6, 1, 0],
        [7, 1, 0],
        [0, 2, 0],
        [1, 2, 0],
        [2, 2, 0],
        [3, 2, 0],
        [4, 2, 0],
        [5, 2, 0],
        [6, 2, 0],
        [7, 2, 0],
        [0, 3, 0],
        [1, 3, 0],
        [2, 3, 0],
        [3, 3, 0],
        [4, 3, 0],
        [5, 3, 0],
        [6, 3, 0],
        [7, 3, 0]], device='cuda:0', dtype=torch.int32)</code></pre></li>
</ul>
</section>
<section id="warp-divergence-and-control-flow" class="level3">
<h3 class="anchored" data-anchor-id="warp-divergence-and-control-flow"><strong>Warp Divergence and Control Flow</strong></h3>
<ul>
<li><strong>Traditional GPUs (Single Program Counter per Warp):</strong>
<ul>
<li><strong>Conditional Statements (if-else):</strong> Threads not satisfying the condition are disabled, leading to warp divergence.</li>
<li>Only the active threads execute the corresponding branch.</li>
<li>Threads are re-enabled/disabled as needed at each branch point.</li>
<li><strong>Limitations:</strong>
<ul>
<li>Inter-thread communication within a warp is not possible during divergence (waiting threads would stall the warp).</li>
<li>Performance is reduced due to idle threads and sequential execution of branches.</li>
</ul></li>
</ul></li>
<li><strong>Newer GPUs (&gt;= Volta) (Independent Program Counters):</strong>
<ul>
<li>Each thread has its own program counter.</li>
<li>GPU can interleave execution of different branches, improving utilization.</li>
<li><strong>Advantages:</strong>
<ul>
<li>Can hide memory latency by switching to other warps while one warp waits for memory access.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>Reconvergence of threads after divergence is not automatic.</li>
<li>Requires explicit synchronization using <code>__syncwarp()</code> to ensure all threads are at the same point before continuing.</li>
</ul></li>
</ul></li>
<li><strong>Loop Divergence:</strong> Similar divergence occurs in loops with variable iteration counts across threads in a warp.</li>
</ul>
</section>
<section id="achieving-good-occupancy" class="level3">
<h3 class="anchored" data-anchor-id="achieving-good-occupancy"><strong>Achieving Good Occupancy</strong></h3>
<ul>
<li><strong>Occupancy:</strong> A measure of how well the GPU’s resources are utilized.</li>
<li><strong>Goals:</strong>
<ul>
<li>Keep all SMs busy.</li>
<li>Maximize the number of active threads per SM.</li>
<li>Minimize warp divergence.</li>
<li>Avoid slow FP64 and INT64 operations (especially on consumer GPUs).</li>
</ul></li>
<li><strong>Strategies:</strong>
<ul>
<li><strong>Many Blocks:</strong> Utilize all available SMs.</li>
<li><strong>Optimal Block Size:</strong> Choose a power of two smaller than 512 (or a divisor of the maximum threads per SM) to maximize concurrent threads.</li>
<li><strong>Minimize Divergence:</strong>
<ul>
<li>Use conditional load/store instructions to avoid control flow divergence.</li>
<li>Structure code to minimize branching within warps.</li>
</ul></li>
<li><strong>Avoid FP64/INT64:</strong> Use FP32/INT32 whenever possible for better performance.</li>
</ul></li>
<li><strong>Shared Memory and Registers:</strong>
<ul>
<li>Excessive use of shared memory or registers can limit the number of threads scheduled per SM.</li>
<li><strong>Launch Bounds:</strong> Use <code>__launch_bounds__</code> to advise the compiler about expected thread counts, allowing for better register allocation.</li>
<li><strong>Register Spills:</strong> If register usage exceeds the limit, variables are spilled to slower local memory, impacting performance.</li>
</ul></li>
<li><strong>Occupancy Calculation Tools:</strong>
<ul>
<li><strong>Previously:</strong> Excel sheets.</li>
<li><strong>Currently:</strong> NVIDIA Nsight Compute provides occupancy analysis.</li>
</ul></li>
</ul>
</section>
<section id="querying-gpu-properties" class="level3">
<h3 class="anchored" data-anchor-id="querying-gpu-properties"><strong>Querying GPU Properties</strong></h3>
<ul>
<li><strong>PyTorch:</strong> <code>torch.cuda.get_device_properties(device)</code> provides basic properties (name, compute architecture, memory, processor count, registers per SM, max threads per SM).</li>
<li><strong>CUDA C API:</strong> More detailed properties are available through the CUDA Runtime API.</li>
</ul>
</section>
</section>
<section id="memory-architecture-and-data-locality" class="level2">
<h2 class="anchored" data-anchor-id="memory-architecture-and-data-locality"><strong>Memory Architecture and Data Locality</strong></h2>
<section id="performance-bottlenecks" class="level3">
<h3 class="anchored" data-anchor-id="performance-bottlenecks"><strong>Performance Bottlenecks</strong></h3>
<ul>
<li><strong>Memory Accesses:</strong> Often a major bottleneck in kernel performance.</li>
<li><strong>Kernel Fusion:</strong> Combining multiple kernels into one can reduce memory transfers by avoiding intermediate reads and writes.</li>
</ul>
</section>
<section id="pytorch-performance-breakdown" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-performance-breakdown"><strong>PyTorch Performance Breakdown</strong></h3>
<ul>
<li><p><strong>High-Level:</strong></p>
<ul>
<li>Python processing.</li>
<li>Data administrative overhead (tensor allocation, etc.).</li>
<li>Data acquisition.</li>
<li>GPU computation.</li>
</ul></li>
<li><p><strong>Data Acquisition:</strong> Often a significant bottleneck if not optimized.</p></li>
<li><p><strong>GPU Computation:</strong></p>
<ul>
<li>Fixed costs (kernel launches).</li>
<li>Memory accesses (reading inputs, writing outputs).</li>
<li>Actual computation (influenced by occupancy).</li>
</ul></li>
<li><p><strong>Rules of Thumb:</strong></p>
<ul>
<li><p>As long as you don’t have close to 100% GPU utilization in nvidia-smi, work on data acquisition etc.</p></li>
<li><p>As long as you have Tensors with a few 100s of elements, “Python is slow” and data administrative over head is single digit percentages.</p></li>
<li><p>Algorithms also matter (parallel algorithms in the following chapters)</p></li>
</ul></li>
</ul>
</section>
<section id="memory-access-as-a-bottleneck" class="level3">
<h3 class="anchored" data-anchor-id="memory-access-as-a-bottleneck"><strong>Memory Access as a Bottleneck</strong></h3>
<ul>
<li><strong>Eager PyTorch:</strong> Typically loads inputs, computes, and stores outputs for each operation.</li>
<li><strong>Fusion Benefits:</strong> Reduces memory transfers by combining multiple operations into a single kernel.</li>
<li><strong>PyTorch JIT:</strong>
<ul>
<li>First generation: Fused point-wise operations.</li>
<li>Second generation (NVFuser): Added support for contractions.</li>
</ul></li>
<li><strong>NVFuser:</strong>
<ul>
<li>Evolved beyond PyTorch.</li>
<li>Active git repository with ongoing development.
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/NVIDIA/Fuser">https://github.com/NVIDIA/Fuser</a></li>
</ul></li>
</ul></li>
<li><strong>Inductor and Triton:</strong> Support more complex operations through a specialized language and templates.</li>
<li><strong>Flash Attention:</strong> Minimizes global memory accesses by leveraging shared memory effectively.</li>
</ul>
</section>
<section id="flash-attention-example" class="level3">
<h3 class="anchored" data-anchor-id="flash-attention-example"><strong>Flash Attention Example</strong></h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-004/images/flash-attention-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2205.14135">FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a></li>
<li><strong>Figure:</strong> (from the Flash Attention paper) Shows the relative speeds of different memory types.
<ul>
<li><strong>High Bandwidth Memory (HBM):</strong> 1.5 TB/s (900 GB/s on the RTX 3090).</li>
<li><strong>Shared Memory:</strong> More than 10x faster than HBM.</li>
<li><strong>Shared Memory Limitation:</strong> Significantly smaller capacity (0.2% of global memory).</li>
</ul></li>
<li><strong>Goal:</strong> Minimize global memory accesses and maximize shared memory usage.</li>
</ul>
</section>
<section id="kernel-fusion-example-approximated-gelu" class="level3">
<h3 class="anchored" data-anchor-id="kernel-fusion-example-approximated-gelu"><strong>Kernel Fusion Example: Approximated Gelu</strong></h3>
<ul>
<li><p><strong>Approximated Gelu Formula:</strong> (from <a href="https://pytorch.org/docs/stable/generated/torch.nn.GELU.html">PyTorch documentation</a>) Uses <code>tanh</code> for an approximation of the Gaussian error linear unit (GELU) activation function. <img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BGELU%7D(x)%20=%200.5%20*%20x%20*%20(1%20+%20%5Ctext%7BTanh%7D(%5Csqrt%7B2%20/%20%5Cpi%7D%20*%20(x%20+%200.044715%20*%20x%5E3)))%0A"></p></li>
<li><p><strong>PyTorch Implementation:</strong> Highly optimized, around 13.3 microseconds.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit torch.nn.functional.gelu(x, approximate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tanh'</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> torch.cuda.synchronize()</span></code></pre></div>
<pre class="text"><code>13.3 μs ± 331 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)</code></pre></li>
<li><p><strong>Naive Implementation:</strong></p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> gelu(x):</span>
<span id="cb8-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb8-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Compute the Gaussian Error Linear Unit (GELU) activation function.</span></span>
<span id="cb8-4"></span>
<span id="cb8-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    GELU is defined as: GELU(x) = 0.5 * x * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3)))</span></span>
<span id="cb8-6"></span>
<span id="cb8-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb8-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        x (torch.Tensor): Input tensor</span></span>
<span id="cb8-9"></span>
<span id="cb8-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb8-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        torch.Tensor: Output tensor after applying GELU activation</span></span>
<span id="cb8-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb8-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the constant term (2/pi)^0.5</span></span>
<span id="cb8-14">    const <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> torch.pi) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb8-15"></span>
<span id="cb8-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the inner term: x + 0.044715 * x^3</span></span>
<span id="cb8-17">    inner_term <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.044715</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb8-18"></span>
<span id="cb8-19">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the GELU formula</span></span>
<span id="cb8-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> torch.tanh(const <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> inner_term))</span></code></pre></div>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a random tensor of size 1024x1024 on the GPU</span></span>
<span id="cb9-2">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span></code></pre></div>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Measure the execution time of the GELU function</span></span>
<span id="cb10-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Synchronize CUDA operations to ensure accurate timing</span></span>
<span id="cb10-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit gelu(x)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> torch.cuda.synchronize()</span></code></pre></div>
<pre class="text"><code>67.2 μs ± 1.41 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)</code></pre>
<ul>
<li>Separate kernels for each operation.</li>
<li>Significantly slower due to numerous memory accesses.</li>
</ul></li>
<li><p><strong>PyTorch Profiler:</strong> Can be used to identify individual kernel calls and their execution times.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use torch.profiler to analyze the performance of the GELU function</span></span>
<span id="cb12-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.profiler.profile() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> prof:</span>
<span id="cb12-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Measure the execution time of the GELU function</span></span>
<span id="cb12-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run the function 1000 times for more accurate timing</span></span>
<span id="cb12-5">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span> gelu(x)</span>
<span id="cb12-6"></span>
<span id="cb12-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print a table of key performance metrics</span></span>
<span id="cb12-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(prof.key_averages().table())</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
Name
</th>
<th>
Self CPU %
</th>
<th>
Self CPU
</th>
<th>
CPU total %
</th>
<th>
CPU total
</th>
<th>
CPU time avg
</th>
<th>
Self CUDA
</th>
<th>
Self CUDA %
</th>
<th>
CUDA total
</th>
<th>
CUDA time avg
</th>
<th>
# of Calls
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
aten::mul
</td>
<td>
30.34%
</td>
<td>
130.980ms
</td>
<td>
50.70%
</td>
<td>
218.874ms
</td>
<td>
7.817us
</td>
<td>
88.571ms
</td>
<td>
49.36%
</td>
<td>
88.571ms
</td>
<td>
3.163us
</td>
<td>
28000
</td>
</tr>
<tr>
<td>
cudaLaunchKernel
</td>
<td>
37.49%
</td>
<td>
161.833ms
</td>
<td>
37.49%
</td>
<td>
161.833ms
</td>
<td>
2.890us
</td>
<td>
0.000us
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.000us
</td>
<td>
56000
</td>
</tr>
<tr>
<td>
aten::pow
</td>
<td>
9.45%
</td>
<td>
40.780ms
</td>
<td>
14.16%
</td>
<td>
61.140ms
</td>
<td>
8.734us
</td>
<td>
20.920ms
</td>
<td>
11.66%
</td>
<td>
20.920ms
</td>
<td>
2.989us
</td>
<td>
7000
</td>
</tr>
<tr>
<td>
aten::result_type
</td>
<td>
0.18%
</td>
<td>
785.257us
</td>
<td>
0.18%
</td>
<td>
785.257us
</td>
<td>
0.112us
</td>
<td>
0.000us
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.000us
</td>
<td>
7000
</td>
</tr>
<tr>
<td>
aten::to
</td>
<td>
0.14%
</td>
<td>
603.008us
</td>
<td>
0.14%
</td>
<td>
603.008us
</td>
<td>
0.086us
</td>
<td>
0.000us
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.000us
</td>
<td>
7000
</td>
</tr>
<tr>
<td>
aten::add
</td>
<td>
15.28%
</td>
<td>
65.959ms
</td>
<td>
23.82%
</td>
<td>
102.833ms
</td>
<td>
7.345us
</td>
<td>
46.930ms
</td>
<td>
26.16%
</td>
<td>
46.930ms
</td>
<td>
3.352us
</td>
<td>
14000
</td>
</tr>
<tr>
<td>
aten::tanh
</td>
<td>
7.13%
</td>
<td>
30.763ms
</td>
<td>
11.32%
</td>
<td>
48.857ms
</td>
<td>
6.980us
</td>
<td>
23.008ms
</td>
<td>
12.82%
</td>
<td>
23.008ms
</td>
<td>
3.287us
</td>
<td>
7000
</td>
</tr>
<tr>
<td>
void at::native::vectorized_elementwise_kernel&lt;4, at…
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.000us
</td>
<td>
62.472ms
</td>
<td>
34.82%
</td>
<td>
62.472ms
</td>
<td>
2.975us
</td>
<td>
21000
</td>
</tr>
<tr>
<td>
void at::native::vectorized_elementwise_kernel&lt;4, at…
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.000us
</td>
<td>
20.920ms
</td>
<td>
11.66%
</td>
<td>
20.920ms
</td>
<td>
2.989us
</td>
<td>
7000
</td>
</tr>
<tr>
<td>
void at::native::vectorized_elementwise_kernel&lt;4, at…
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.000us
</td>
<td>
26.045ms
</td>
<td>
14.52%
</td>
<td>
26.045ms
</td>
<td>
3.721us
</td>
<td>
7000
</td>
</tr>
<tr>
<td>
void at::native::vectorized_elementwise_kernel&lt;4, at…
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.000us
</td>
<td>
23.008ms
</td>
<td>
12.82%
</td>
<td>
23.008ms
</td>
<td>
3.287us
</td>
<td>
7000
</td>
</tr>
<tr>
<td>
void at::native::vectorized_elementwise_kernel&lt;4, at…
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.000us
</td>
<td>
20.886ms
</td>
<td>
11.64%
</td>
<td>
20.886ms
</td>
<td>
2.984us
</td>
<td>
7000
</td>
</tr>
<tr>
<td>
void at::native::vectorized_elementwise_kernel&lt;4, at…
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.000us
</td>
<td>
26.099ms
</td>
<td>
14.55%
</td>
<td>
26.099ms
</td>
<td>
3.728us
</td>
<td>
7000
</td>
</tr>
<tr>
<td>
cudaDeviceSynchronize
</td>
<td>
0.00%
</td>
<td>
5.062us
</td>
<td>
0.00%
</td>
<td>
5.062us
</td>
<td>
5.062us
</td>
<td>
0.000us
</td>
<td>
0.00%
</td>
<td>
0.000us
</td>
<td>
0.000us
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
<p>
Self CPU time total: 431.709ms
</p>
<p>
Self CUDA time total: 179.430ms
</p>
</div>
<ul>
<li>Shows a large number of separate kernels for point-wise operations in the naive implementation.</li>
</ul></li>
<li><p><strong>Fused Kernel:</strong></p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define CUDA source code as a string</span></span>
<span id="cb13-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb13-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">__global__ void my_gelu_kernel(float* out, float* inp, int n) {</span></span>
<span id="cb13-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Calculate global thread index</span></span>
<span id="cb13-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span></span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Return if thread index is out of bounds</span></span>
<span id="cb13-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    if (i &gt;= n) return;</span></span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Load input value</span></span>
<span id="cb13-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    float x = inp[i];</span></span>
<span id="cb13-12"></span>
<span id="cb13-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Compute GELU (Gaussian Error Linear Unit) activation</span></span>
<span id="cb13-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // GELU(x) = 0.5 * x * (1 + tanh(sqrt(2/π) * (x + 0.044715 * x^3)))</span></span>
<span id="cb13-15"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    out[i] = 0.5f * x * (1.0f + tanhf(sqrtf(2.0f/3.141592653589793f) * (x + 0.044715f * (x*x*x))));</span></span>
<span id="cb13-16"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb13-17"></span>
<span id="cb13-18"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor my_gelu_out(torch::Tensor output, const torch::Tensor&amp; inp) {</span></span>
<span id="cb13-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(inp);  // Validate input tensor</span></span>
<span id="cb13-20"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int n = inp.numel();  // Get total number of elements in input tensor</span></span>
<span id="cb13-21"></span>
<span id="cb13-22"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Ensure output tensor has same properties as input tensor</span></span>
<span id="cb13-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    TORCH_CHECK((output.sizes() == inp.sizes()) || (output.device() == inp.device())</span></span>
<span id="cb13-24"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">                || (output.scalar_type() == inp.scalar_type()));</span></span>
<span id="cb13-25"></span>
<span id="cb13-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int threads = 256;  // Set number of threads per block</span></span>
<span id="cb13-27"></span>
<span id="cb13-28"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Launch CUDA kernel</span></span>
<span id="cb13-29"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    my_gelu_kernel&lt;&lt;&lt;cdiv(n, threads), threads&gt;&gt;&gt;(</span></span>
<span id="cb13-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        output.data_ptr&lt;float&gt;(), inp.data_ptr&lt;float&gt;(), n);</span></span>
<span id="cb13-31"></span>
<span id="cb13-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    C10_CUDA_KERNEL_LAUNCH_CHECK();  // Check for CUDA errors</span></span>
<span id="cb13-33"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb13-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb13-35"></span>
<span id="cb13-36"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor my_gelu(const torch::Tensor&amp; inp) {</span></span>
<span id="cb13-37"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(inp);  // Validate input tensor</span></span>
<span id="cb13-38"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    auto output = torch::empty_like(inp);  // Create output tensor with same properties as input</span></span>
<span id="cb13-39"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    my_gelu_out(output, inp);  // Compute GELU activation</span></span>
<span id="cb13-40"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb13-41"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb13-42"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span>
<span id="cb13-43"></span>
<span id="cb13-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define C++ source code as a string</span></span>
<span id="cb13-45">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb13-46"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor my_gelu(const torch::Tensor&amp; inp);</span></span>
<span id="cb13-47"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor my_gelu_out(torch::Tensor output, const torch::Tensor&amp; inp);</span></span>
<span id="cb13-48"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb13-49"></span>
<span id="cb13-50"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set environment variables for compiler paths</span></span>
<span id="cb13-51"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb13-52">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'CXX'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'/usr/lib/ccache/g++-11'</span></span>
<span id="cb13-53">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'CC'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'/usr/lib/ccache/gcc-11'</span></span>
<span id="cb13-54"></span>
<span id="cb13-55"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load and compile the CUDA extension</span></span>
<span id="cb13-56">gelu_module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.utils.cpp_extension.load_inline(</span>
<span id="cb13-57">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test_ext_gelu"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Name of the extension</span></span>
<span id="cb13-58">    cpp_src,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># C++ source code</span></span>
<span id="cb13-59">    cuda_src,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA source code</span></span>
<span id="cb13-60">    functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'my_gelu'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'my_gelu_out'</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Functions to expose</span></span>
<span id="cb13-61">    extra_cuda_cflags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--ptxas-options=-v'</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Additional CUDA compiler flags</span></span>
<span id="cb13-62">    verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Enable verbose output during compilation</span></span>
<span id="cb13-63">)</span></code></pre></div>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit gelu_module.my_gelu(x)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> torch.cuda.synchronize()</span></code></pre></div>
<pre class="text"><code>17 μs ± 246 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)</code></pre>
<ul>
<li>Combines all operations into a single C++ kernel.</li>
<li>Slightly slower than PyTorch’s implementation (tested on an RTX 4090 with PyTorch 2.4.0).</li>
</ul></li>
<li><p><strong>Numerical Accuracy:</strong> Results are the same as PyTorch’s implementation, “up to numerical accuracy.”</p></li>
</ul>
</section>
<section id="numerical-accuracy-and-floating-point-operations" class="level3">
<h3 class="anchored" data-anchor-id="numerical-accuracy-and-floating-point-operations"><strong>Numerical Accuracy and Floating Point Operations</strong></h3>
<ul>
<li><strong>Floating Point Addition:</strong> Not strictly associative due to limited precision.
<ul>
<li>The order of operations can affect the result, especially when adding numbers with vastly different magnitudes.</li>
<li><strong>Example:</strong> Adding a very small number to a large number might result in no change if the small number is below the precision threshold.</li>
</ul></li>
<li><strong>Relative Accuracy:</strong>
<ul>
<li>FP32: Typically around 10⁻⁷ or 10⁻⁸.</li>
<li>FP64: Higher precision.</li>
</ul></li>
</ul>
</section>
<section id="theoretical-maximum-speed-level-rgb-to-gray-kernel" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-maximum-speed-level-rgb-to-gray-kernel"><strong>Theoretical Maximum Speed: Level RGB to Gray Kernel</strong></h3>
<ul>
<li><strong>Kernel Operations:</strong>
<ul>
<li>Load 3 bytes (R, G, B).</li>
<li>Compute index (1 multiplication, 1 addition - INT32).</li>
<li>Compute grayscale value (3 multiplications, 2 additions - FP32).</li>
<li>Data conversion.</li>
<li>Store 1 byte.</li>
</ul></li>
<li><strong>Memory Bandwidth (RTX 3090):</strong> 900 GB/s.</li>
<li><strong>Image Size:</strong> 2048 x 2048.</li>
<li><strong>Theoretical Memory Transfer Time (“Speed of Light”):</strong> ~18 microseconds (assuming ideal access patterns).</li>
<li><strong>Compute Performance (RTX 3090):</strong>
<ul>
<li>FP32: 35.6 TFLOPs.</li>
<li>INT32: 16.8 TFLOPs.</li>
</ul></li>
<li><strong>Theoretical Compute Time:</strong> ~2 microseconds (excluding parallelism and memory latency).</li>
<li><strong>Kernel Launch Overhead:</strong> ~3 microseconds (measured using an empty kernel).</li>
<li><strong>Measured Kernel Time:</strong> ~26-27 microseconds.</li>
<li><strong>Efficiency:</strong> Achieves about 75% of the theoretical maximum speed.</li>
</ul>
</section>
<section id="roofline-model" class="level3">
<h3 class="anchored" data-anchor-id="roofline-model"><strong>Roofline Model</strong></h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-004/images/roofline-model.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<ul>
<li><strong>Purpose:</strong> Helps analyze the performance limitations of a kernel.</li>
<li><strong>Computational Intensity:</strong> Key metric, defined as the number of floating-point operations (FLOPs) per byte of memory transfer.</li>
<li><strong>Memory-Bound Kernels:</strong>
<ul>
<li>Low computational intensity.</li>
<li>Performance limited by memory bandwidth.</li>
<li>Throughput limited by the diagonal line in the roofline model representing memory bandwidth.</li>
</ul></li>
<li><strong>Compute-Bound Kernels:</strong>
<ul>
<li>High computational intensity.</li>
<li>Performance limited by the GPU’s compute capabilities.</li>
<li>Throughput limited by the horizontal line in the roofline model representing peak compute performance.</li>
</ul></li>
<li><strong>Roofline Shape:</strong> The characteristic “roof” shape arises from the fact that memory latency can be hidden if other warps can compute while one warp waits for memory.
<ul>
<li>The performance becomes the maximum of the memory bandwidth and compute throughput, leading to the minimum of the two limiting factors.</li>
</ul></li>
</ul>
</section>
<section id="gpu-memory-hierarchy" class="level3">
<h3 class="anchored" data-anchor-id="gpu-memory-hierarchy"><strong>GPU Memory Hierarchy</strong></h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-004/images/cuda-device-memory-model.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5.2</figcaption>
</figure>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 60%">
<col style="width: 12%">
<col style="width: 9%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th>Variable declaration</th>
<th>Memory</th>
<th>Scope</th>
<th>Lifetime</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Automatic variables other than arrays</td>
<td>Register</td>
<td>Thread</td>
<td>Grid</td>
</tr>
<tr class="even">
<td>Automatic array variables</td>
<td>Local</td>
<td>Thread</td>
<td>Grid</td>
</tr>
<tr class="odd">
<td><code>__device__ __shared__ int SharedVar;</code></td>
<td>Shared</td>
<td>Block</td>
<td>Grid</td>
</tr>
<tr class="even">
<td><code>__device__ int GlobalVar;</code></td>
<td>Global</td>
<td>Grid</td>
<td>Application</td>
</tr>
<tr class="odd">
<td><code>__device__ __constant__ int ConstVar;</code></td>
<td>Constant</td>
<td>Grid</td>
<td>Application</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Registers:</strong> Fastest, used for local variables within a thread.</li>
<li><strong>Local Memory:</strong> Slower than registers, used for arrays declared within a thread or for register spills.</li>
<li><strong>Shared Memory:</strong> Per-block memory, faster than global memory, accessible by all threads in a block, declared using <code>__shared__</code>.</li>
<li><strong>Global Memory:</strong> Main GPU memory, accessible by all threads, typically accessed through pointers.</li>
<li><strong>Constant Memory:</strong> Read-only memory, cached, used for kernel launch parameters and can be explicitly declared.</li>
</ul>
</section>
<section id="shared-memory-and-tiling" class="level3">
<h3 class="anchored" data-anchor-id="shared-memory-and-tiling"><strong>Shared Memory and Tiling</strong></h3>
<ul>
<li><p><strong>Tiling:</strong> A technique to improve data locality by loading data from global memory into shared memory and reusing it multiple times within a block.</p></li>
<li><p><strong>Matrix Multiplication Example:</strong></p>
<ul>
<li><p><strong>Naive Approach:</strong> Each output element reads 2n inputs from global memory n times.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA kernel for matrix multiplication</span></span>
<span id="cb16-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb16-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">__global__ void simple_matmul_k(float* m, float* n, float* out, int h, int w, int k) {</span></span>
<span id="cb16-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Calculate global thread indices</span></span>
<span id="cb16-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int r = blockIdx.y*blockDim.y + threadIdx.y;</span></span>
<span id="cb16-6"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int c = blockIdx.x*blockDim.x + threadIdx.x;</span></span>
<span id="cb16-7"></span>
<span id="cb16-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Boundary check</span></span>
<span id="cb16-9"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    if (r&gt;=h || c&gt;=w) return;</span></span>
<span id="cb16-10"></span>
<span id="cb16-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    float o = 0;</span></span>
<span id="cb16-12"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Perform dot product for this element</span></span>
<span id="cb16-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    for (int i = 0; i&lt;k; ++i) o += m[r*k+i] * n[i*w+c];</span></span>
<span id="cb16-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    out[r*w+c] = o;</span></span>
<span id="cb16-15"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb16-16"></span>
<span id="cb16-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor simple_matmul(const torch::Tensor&amp; m, const torch::Tensor&amp; n) {</span></span>
<span id="cb16-18"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(m); CHECK_INPUT(n);</span></span>
<span id="cb16-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int h = m.size(0);</span></span>
<span id="cb16-20"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int w = n.size(1);</span></span>
<span id="cb16-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int k = m.size(1);</span></span>
<span id="cb16-22"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    TORCH_CHECK(k==n.size(0), "Size mismatch!");</span></span>
<span id="cb16-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    auto output = torch::zeros({h, w}, m.options());</span></span>
<span id="cb16-24"></span>
<span id="cb16-25"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Define thread block and grid dimensions</span></span>
<span id="cb16-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 tpb(16,16);</span></span>
<span id="cb16-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));</span></span>
<span id="cb16-28"></span>
<span id="cb16-29"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Launch CUDA kernel</span></span>
<span id="cb16-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    simple_matmul_k&lt;&lt;&lt;blocks, tpb&gt;&gt;&gt;(</span></span>
<span id="cb16-31"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        m.data_ptr&lt;float&gt;(), n.data_ptr&lt;float&gt;(), output.data_ptr&lt;float&gt;(), h, w, k);</span></span>
<span id="cb16-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    C10_CUDA_KERNEL_LAUNCH_CHECK();</span></span>
<span id="cb16-33"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb16-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb16-35"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span>
<span id="cb16-36"></span>
<span id="cb16-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># C++ function declaration</span></span>
<span id="cb16-38">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb16-39"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor simple_matmul(const torch::Tensor&amp; m, const torch::Tensor&amp; n);</span></span>
<span id="cb16-40"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb16-41"></span>
<span id="cb16-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the custom CUDA extension</span></span>
<span id="cb16-43">simple_matmul_module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.utils.cpp_extension.load_inline(</span>
<span id="cb16-44">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test_ext_simple_matmul"</span>,</span>
<span id="cb16-45">    cpp_sources<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cpp_src,</span>
<span id="cb16-46">    cuda_sources<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cuda_src,</span>
<span id="cb16-47">    functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'simple_matmul'</span>],</span>
<span id="cb16-48">    extra_cuda_cflags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--ptxas-options=-v'</span>],</span>
<span id="cb16-49">    verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb16-50">)</span></code></pre></div>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create two random 1024x1024 matrices on the GPU</span></span>
<span id="cb17-2">a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span>
<span id="cb17-3">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span>
<span id="cb17-4"></span>
<span id="cb17-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Benchmark the custom matrix multiplication function</span></span>
<span id="cb17-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit simple_matmul_module.simple_matmul(a, b)</span>
<span id="cb17-7"></span>
<span id="cb17-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the maximum absolute difference between custom and built-in matrix multiplication</span></span>
<span id="cb17-9">max_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (simple_matmul_module.simple_matmul(a, b) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> a<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>b).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()</span></code></pre></div>
<pre class="text"><code>426 μs ± 9.98 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</code></pre></li>
<li><p><strong>Tiling:</strong> Reduces the number of global memory accesses by reading input tiles into shared memory and reusing them for multiple output tiles.</p>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Constants and CUDA kernel definition</span></span>
<span id="cb19-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r"""</span></span>
<span id="cb19-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">constexpr int TILE_SIZE = 16;  // Size of each tile for matrix multiplication</span></span>
<span id="cb19-4"></span>
<span id="cb19-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb19-6"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @brief Tiled matrix multiplication kernel.</span></span>
<span id="cb19-7"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * </span></span>
<span id="cb19-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * This kernel performs matrix multiplication using shared memory tiles to improve performance.</span></span>
<span id="cb19-9"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> *</span></span>
<span id="cb19-10"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param out Pointer to the output matrix</span></span>
<span id="cb19-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param M Pointer to the first input matrix</span></span>
<span id="cb19-12"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param N Pointer to the second input matrix</span></span>
<span id="cb19-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param h Height of matrix M</span></span>
<span id="cb19-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param w Width of matrix N</span></span>
<span id="cb19-15"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param k Width of matrix M / Height of matrix N</span></span>
<span id="cb19-16"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb19-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">__global__ void tiled_matmul_kernel(float* out, float* M, float* N, int h, int w, int k) {</span></span>
<span id="cb19-18"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    __shared__ float M_tile[TILE_SIZE][TILE_SIZE];  // Shared memory for M matrix tile</span></span>
<span id="cb19-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    __shared__ float N_tile[TILE_SIZE][TILE_SIZE];  // Shared memory for N matrix tile</span></span>
<span id="cb19-20"></span>
<span id="cb19-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Thread indices within a tile</span></span>
<span id="cb19-22"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int ir = threadIdx.y;</span></span>
<span id="cb19-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int ic = threadIdx.x;</span></span>
<span id="cb19-24"></span>
<span id="cb19-25"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Global thread indices</span></span>
<span id="cb19-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int r = blockIdx.y * blockDim.y + threadIdx.y;</span></span>
<span id="cb19-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int c = blockIdx.x * blockDim.x + threadIdx.x;</span></span>
<span id="cb19-28"></span>
<span id="cb19-29"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    float res = 0.0f;  // Accumulator for dot product result</span></span>
<span id="cb19-30"></span>
<span id="cb19-31"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Iterate over tiles</span></span>
<span id="cb19-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    for (int K_tileidx = 0; K_tileidx &lt; (k + TILE_SIZE -1) / TILE_SIZE; K_tileidx++) {</span></span>
<span id="cb19-33"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Load data into shared memory tiles, with bounds checking</span></span>
<span id="cb19-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        M_tile[ir][ic] = (((r &lt; h) &amp;&amp; (K_tileidx * TILE_SIZE + ic &lt; k)) ? M[r * k + K_tileidx * TILE_SIZE + ic] : 0.f);</span></span>
<span id="cb19-35"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        N_tile[ir][ic] = ((((K_tileidx * TILE_SIZE + ir) &lt; k) &amp;&amp; (c &lt; w)) ? N[(K_tileidx * TILE_SIZE + ir) * w + c] : 0.f);</span></span>
<span id="cb19-36"></span>
<span id="cb19-37"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        __syncthreads();  // Ensure all threads have loaded data before computation</span></span>
<span id="cb19-38"></span>
<span id="cb19-39"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Compute dot product for this tile</span></span>
<span id="cb19-40"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        for (int idx = 0; idx &lt; TILE_SIZE; idx++) {</span></span>
<span id="cb19-41"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">           res += M_tile[ir][idx] * N_tile[idx][ic];</span></span>
<span id="cb19-42"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        }</span></span>
<span id="cb19-43"></span>
<span id="cb19-44"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        __syncthreads();  // Ensure all computations are done before loading next tile</span></span>
<span id="cb19-45"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb19-46"></span>
<span id="cb19-47"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Write result to global memory if within bounds</span></span>
<span id="cb19-48"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    if ((r &lt; h) &amp;&amp; (c &lt; w)) {</span></span>
<span id="cb19-49"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        out[r * w + c] = res;</span></span>
<span id="cb19-50"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb19-51"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb19-52"></span>
<span id="cb19-53"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb19-54"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @brief Wrapper function for tiled matrix multiplication kernel.</span></span>
<span id="cb19-55"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * </span></span>
<span id="cb19-56"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * This function checks input tensors, sets up kernel parameters, and launches the CUDA kernel.</span></span>
<span id="cb19-57"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> *</span></span>
<span id="cb19-58"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param m First input matrix</span></span>
<span id="cb19-59"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param n Second input matrix</span></span>
<span id="cb19-60"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @return torch::Tensor Result of matrix multiplication</span></span>
<span id="cb19-61"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb19-62"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor tiled_matmul(const torch::Tensor&amp; m, const torch::Tensor&amp; n) {</span></span>
<span id="cb19-63"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(m); CHECK_INPUT(n);</span></span>
<span id="cb19-64"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int h = m.size(0);</span></span>
<span id="cb19-65"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int w = n.size(1);</span></span>
<span id="cb19-66"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int k = m.size(1);</span></span>
<span id="cb19-67"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    TORCH_CHECK(k==n.size(0), "Size mismatch");</span></span>
<span id="cb19-68"></span>
<span id="cb19-69"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    auto output = torch::empty({h, w}, m.options());</span></span>
<span id="cb19-70"></span>
<span id="cb19-71"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Define thread block and grid dimensions</span></span>
<span id="cb19-72"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 tpb(TILE_SIZE, TILE_SIZE);</span></span>
<span id="cb19-73"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));</span></span>
<span id="cb19-74"></span>
<span id="cb19-75"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Launch kernel</span></span>
<span id="cb19-76"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    tiled_matmul_kernel&lt;&lt;&lt;blocks, tpb&gt;&gt;&gt;(</span></span>
<span id="cb19-77"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        output.data_ptr&lt;float&gt;(), m.data_ptr&lt;float&gt;(), n.data_ptr&lt;float&gt;(), h, w, k);</span></span>
<span id="cb19-78"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    C10_CUDA_KERNEL_LAUNCH_CHECK();</span></span>
<span id="cb19-79"></span>
<span id="cb19-80"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb19-81"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb19-82"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb19-83"></span>
<span id="cb19-84"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># C++ interface definition</span></span>
<span id="cb19-85">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb19-86"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor tiled_matmul(const torch::Tensor&amp; m, const torch::Tensor&amp; n);</span></span>
<span id="cb19-87"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb19-88"></span>
<span id="cb19-89"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the CUDA kernel as a PyTorch C++ extension</span></span>
<span id="cb19-90">tiled_matmul_module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.utils.cpp_extension.load_inline(</span>
<span id="cb19-91">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test_ext_tiled_matmul"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Name of the extension</span></span>
<span id="cb19-92">    cpp_src,                  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># C++ interface</span></span>
<span id="cb19-93">    cuda_src,                 <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA source code</span></span>
<span id="cb19-94">    functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tiled_matmul'</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Exported functions</span></span>
<span id="cb19-95">    extra_cuda_cflags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--ptxas-options=-v'</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Additional CUDA compilation flags</span></span>
<span id="cb19-96">    verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>              <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Enable verbose output during compilation</span></span>
<span id="cb19-97">)</span></code></pre></div>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit tiled_matmul_module.tiled_matmul(a, b)</span></code></pre></div>
<pre class="text"><code>323 μs ± 2.73 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)</code></pre></li>
</ul></li>
<li><p><strong>Tiled Matrix Multiplication (Square Matrices):</strong></p>
<ul>
<li><strong>Tile Size:</strong> A parameter that determines the size of the tiles.</li>
<li><strong>Thread Block:</strong> Typically, the tile size squared (e.g., <code>16x16</code> threads for a tile size of <code>16</code>).</li>
<li><strong>Shared Memory:</strong> Two shared memory arrays to store tiles from matrices A and B.</li>
<li><strong>Algorithm:</strong>
<ol type="1">
<li>Load tiles from global memory into shared memory.</li>
<li>Perform matrix multiplication within the tiles using shared memory.</li>
<li>Loop over all tiles to compute the complete result.</li>
<li>Store the result back to global memory.</li>
</ol></li>
</ul></li>
<li><p><strong>Synchronization:</strong> <code>__syncthreads()</code> is crucial to ensure that all threads have finished reading/writing to shared memory before proceeding.</p></li>
<li><p><strong>Padding:</strong> For matrices where the size is not a multiple of the tile size, padding with zeros is used to complete the tiles.</p></li>
<li><p><strong>Performance Improvement:</strong> Reduces memory accesses and improves performance (e.g., from 426 microseconds to 323 microseconds in the example).</p></li>
</ul>
</section>
<section id="future-considerations" class="level3">
<h3 class="anchored" data-anchor-id="future-considerations"><strong>Future Considerations</strong></h3>
<ul>
<li><strong>Thread Coarsening:</strong>
<ul>
<li><strong>Concept:</strong> Increasing the amount of work done by each thread to improve performance.</li>
<li><strong>Application to Tiling:</strong> Allows for larger tile sizes.</li>
<li><strong>Details:</strong> Covered in the next session.</li>
</ul></li>
<li><strong>Flash Attention Implementation:</strong>
<ul>
<li><strong>Exercise:</strong> Implement the original Flash Attention algorithm from scratch based on the pseudocode.</li>
<li><strong>Key Aspect:</strong> Blocking of inputs and output for efficient kernel fusion.</li>
</ul></li>
</ul>
</section>
</section>
<section id="conclusions-and-key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="conclusions-and-key-takeaways"><strong>Conclusions and Key Takeaways</strong></h2>
<section id="gpu-computation" class="level3">
<h3 class="anchored" data-anchor-id="gpu-computation"><strong>GPU Computation:</strong></h3>
<ul>
<li>GPUs use a hierarchy of threads, warps, and blocks to organize computation.</li>
<li>Understanding the hardware architecture and scheduling is crucial for performance optimization.</li>
<li>Occupancy, a measure of resource utilization, should be maximized.</li>
<li>Thread divergence should be minimized.</li>
</ul>
</section>
<section id="memory-management" class="level3">
<h3 class="anchored" data-anchor-id="memory-management"><strong>Memory Management:</strong></h3>
<ul>
<li>Memory accesses are often a major bottleneck.</li>
<li>Kernel fusion can reduce memory transfers.</li>
<li>The roofline model provides insights into the performance limitations of a kernel.</li>
<li>Tiling is a powerful technique to improve data locality by leveraging shared memory.</li>
</ul>
</section>
<section id="next-steps" class="level3">
<h3 class="anchored" data-anchor-id="next-steps"><strong>Next Steps:</strong></h3>
<ul>
<li>The next chapter will focus on <strong>coalesced memory access</strong>, a technique to optimize global memory reads and writes for maximum efficiency.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>cuda</category>
  <guid>https://christianjmills.com/posts/cuda-mode-notes/lecture-004/</guid>
  <pubDate>Sat, 31 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>CUDA MODE Lecture 3: Getting Started With CUDA for Python Programmers</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/cuda-mode-notes/lecture-003/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/cuda-mode-notes.html"><strong>CUDA Mode Lecture Notes</strong></a>: My notes from the <strong>CUDA MODE</strong> reading group lectures run by <strong>Andreas Kopf</strong> and <strong>Mark Saroufim</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Setup</li>
<li>Exercise 1: RGB to Grayscale Conversion<br>
</li>
<li>Exercise 2: Matrix Multiplication<br>
</li>
<li>Conclusion and Next Steps</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Resource Links">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resource Links
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>YouTube Recording:</strong> <a href="https://www.youtube.com/watch?v=4sgKnKbR-WE&amp;t=2715s">Lecture 3: Getting Started With CUDA for Python Programmers</a></li>
<li><strong>Jupyter Notebook:</strong> <a href="https://github.com/cuda-mode/lectures/blob/main/lecture_003/pmpp.ipynb">lecture_003/pmpp.ipynb</a></li>
<li><strong>Google Colab:</strong> <a href="https://colab.research.google.com/drive/180uk6frvMBeT4tywhhYXmz3PJaCIA_uk?usp=sharing">lecture_003/pmpp.ipynb</a>
<ul>
<li>Select the T4 GPU runtime in Colab.</li>
</ul></li>
<li><strong>Textbook:</strong> <a href="https://www.amazon.com/Programming-Massively-Parallel-Processors-Hands/dp/0323912311/">Programming Massively Parallel Processors</a></li>
</ul>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li><strong>CUDA (Compute Unified Device Architecture):</strong> A parallel computing platform and programming model developed by NVIDIA for programming NVIDIA GPUs.</li>
<li>Enables high-performance computing and maximum flexibility.</li>
<li>Has a reputation for being difficult to learn, but can be approachable with the right techniques.</li>
<li><strong>Prerequisites:</strong>
<ul>
<li><strong>Basic PyTorch Knowledge</strong>:
<ul>
<li>Familiarity with tensors, indexing, and basic operations.</li>
<li><strong>Recommended:</strong> <a href="https://course.fast.ai/">Practical Deep Learning for Coders</a> (especially Part 1).</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<ul>
<li><p><strong>Import Dependencies:</strong></p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Core libraries for various functionalities</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># PyTorch library for deep learning</span></span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Operating system interfaces</span></span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Mathematical functions</span></span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> gzip   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compression/decompression using gzip</span></span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pickle <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Object serialization</span></span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plotting library</span></span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># For downloading files from URLs</span></span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> urllib.request <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> urlretrieve</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># File and directory handling</span></span>
<span id="cb1-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb1-16"></span>
<span id="cb1-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Specific PyTorch imports</span></span>
<span id="cb1-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Tensor data structure</span></span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Computer vision libraries</span></span>
<span id="cb1-21"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> tv  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># PyTorch's computer vision library</span></span>
<span id="cb1-22"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms.functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> tvf  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Functional image transformations</span></span>
<span id="cb1-23"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> io  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># I/O operations for images and videos</span></span>
<span id="cb1-24"></span>
<span id="cb1-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># For loading custom CUDA extensions</span></span>
<span id="cb1-26"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.cpp_extension <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_inline, CUDA_HOME</span>
<span id="cb1-27"></span>
<span id="cb1-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify the CUDA install path </span></span>
<span id="cb1-29"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(CUDA_HOME)</span></code></pre></div>
<pre class="text"><code>/home/innom-dt/mambaforge/envs/cuda-mode</code></pre></li>
</ul>
</section>
<section id="exercise-1-rgb-to-grayscale-conversion" class="level2">
<h2 class="anchored" data-anchor-id="exercise-1-rgb-to-grayscale-conversion">Exercise 1: RGB to Grayscale Conversion</h2>
<section id="understanding-the-problem" class="level3">
<h3 class="anchored" data-anchor-id="understanding-the-problem">1. Understanding the Problem</h3>
<ul>
<li><strong>Goal:</strong> Convert an RGB color image to a grayscale image.</li>
<li><strong>Formula:</strong> Grayscale (luminance) = 0.2989 * Red + 0.5870 * Green +0.1140 * Blue</li>
<li>This formula is a standard way to calculate luminance from RGB values.</li>
</ul>
</section>
<section id="loading-and-displaying-the-image" class="level3">
<h3 class="anchored" data-anchor-id="loading-and-displaying-the-image">2. Loading and Displaying the Image</h3>
<ul>
<li><p><strong>Image Source:</strong> A puppy image downloaded from a URL.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> download_image(url: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, path: Path) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Download an image from a given URL and save it to the specified path.</span></span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb3-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        url (str): The URL of the image to download.</span></span>
<span id="cb3-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        path (Path): The local path where the image will be saved.</span></span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        None</span></span>
<span id="cb3-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb3-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> path.exists():</span>
<span id="cb3-13">        urlretrieve(url, path)</span></code></pre></div>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># URL of the image to be downloaded</span></span>
<span id="cb4-2">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Cute_dog.jpg/1600px-Cute_dog.jpg?20140729055059'</span></span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the local path where the image will be saved</span></span>
<span id="cb4-5">path_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'puppy.jpg'</span>)</span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the image if it doesn't exist locally</span></span>
<span id="cb4-8">download_image(url, path_img)</span></code></pre></div></li>
<li><p><strong>Loading:</strong> Use <code>torchvision.io.read_image</code> to load the image.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Read the downloaded image</span></span>
<span id="cb5-2">img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> io.read_image(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'puppy.jpg'</span>)</span></code></pre></div></li>
<li><p><strong>Image Shape:</strong> The image is a 3D tensor with dimensions (channels, height, width).</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the shape of the image (channels, height, width)</span></span>
<span id="cb6-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(img.shape)</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display a small portion of the image data (top-left corner)</span></span>
<span id="cb6-5">img[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span></code></pre></div>
<pre class="text"><code>torch.Size([3, 1066, 1600])

tensor([[[117, 119, 117, 113],
         [119, 129, 129, 113],
         [130, 126, 122, 115]],

        [[ 83,  85,  85,  80],
         [ 85,  97,  97,  82],
         [ 98,  93,  89,  83]]], dtype=torch.uint8)</code></pre>
<ul>
<li><strong>Shape:</strong> (3, 1066, 1600) means 3 channels (RGB), 1066 rows (height), 1600 columns (width).</li>
</ul></li>
<li><p><strong>Data Type:</strong> The image pixels are stored as unsigned 8-bit integers (bytes).</p></li>
<li><p><strong>Displaying:</strong> Use a custom <code>showImage</code> function that uses <code>matplotlib</code> to display the image.</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> show_img(x, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>), <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb8-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb8-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Display an image using matplotlib.</span></span>
<span id="cb8-4"></span>
<span id="cb8-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb8-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        x (Tensor): The image tensor to display.</span></span>
<span id="cb8-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        figsize (tuple): The size of the figure (width, height).</span></span>
<span id="cb8-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        **kwargs: Additional keyword arguments to pass to plt.imshow().</span></span>
<span id="cb8-9"></span>
<span id="cb8-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb8-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        None</span></span>
<span id="cb8-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb8-13">    plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>figsize)</span>
<span id="cb8-14">    plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'off'</span>)</span>
<span id="cb8-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(x.shape) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>:</span>
<span id="cb8-16">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.permute(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert from CHW to HWC format</span></span>
<span id="cb8-17">    plt.imshow(x.cpu(), <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span></code></pre></div>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Resize the image to a height of 150 pixels while maintaining aspect ratio</span></span>
<span id="cb9-2">img2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tvf.resize(img, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span>, antialias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb9-3"></span>
<span id="cb9-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the dimensions of the resized image</span></span>
<span id="cb9-5">ch, h, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img2.shape</span>
<span id="cb9-6"></span>
<span id="cb9-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the channel count, height, width, and total number of pixels</span></span>
<span id="cb9-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(ch, h, w, h<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w)</span>
<span id="cb9-9"></span>
<span id="cb9-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the resized image</span></span>
<span id="cb9-11">show_img(img2)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-003/images/output_8_1.png" class="img-fluid figure-img"></p>
<figcaption>resized image</figcaption>
</figure>
</div>
<ul>
<li>Resizes the image to a smaller size (smallest dimension = 150) for faster processing in the initial Python example.</li>
</ul></li>
</ul>
</section>
<section id="grayscale-conversion-in-python" class="level3">
<h3 class="anchored" data-anchor-id="grayscale-conversion-in-python">3. Grayscale Conversion in Python</h3>
<ul>
<li><p><strong>Approach:</strong> Iterate through every pixel and apply the gray scale formula.</p></li>
<li><p><strong>Implementation:</strong></p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> rgb2grey_py(x):</span>
<span id="cb10-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Convert an RGB image to grayscale.</span></span>
<span id="cb10-4"></span>
<span id="cb10-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        x (torch.Tensor): Input RGB image tensor of shape (C, H, W).</span></span>
<span id="cb10-7"></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb10-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        torch.Tensor: Grayscale image tensor of shape (H, W).</span></span>
<span id="cb10-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb10-11">    c, h, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.shape</span>
<span id="cb10-12">    n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> w</span>
<span id="cb10-13">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.flatten()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Flatten the input tensor</span></span>
<span id="cb10-14">    res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.empty(n, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>x.dtype, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>x.device)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize result tensor</span></span>
<span id="cb10-15"></span>
<span id="cb10-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert RGB to grayscale using weighted sum</span></span>
<span id="cb10-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n):</span>
<span id="cb10-18">        res[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2989</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5870</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x[i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> n] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1140</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x[i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> n]</span>
<span id="cb10-19"></span>
<span id="cb10-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> res.view(h, w)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reshape result to original dimensions</span></span></code></pre></div>
<ul>
<li>Flatten the image into a 1D vector to simplify indexing.
<ul>
<li>Flattening arranges the pixels in memory linearly
<ul>
<li>(channel 1, row 1, col 1, channel 1, row 1, col 2, etc.).</li>
</ul></li>
</ul></li>
<li>Calculate the luminance for each pixel using the formula and store it in an output vector.</li>
<li>Reshape the output vector back into a 2D matrix (height, width).</li>
</ul></li>
<li><p><strong>Performance:</strong> This Python implementation is very slow (726 ms for a small image).</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>time</span>
<span id="cb11-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert image to grayscale and display</span></span>
<span id="cb11-3">img_g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rgb2grey_py(img2)</span>
<span id="cb11-4">show_img(img_g, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray'</span>)</span></code></pre></div>
<pre class="text"><code>CPU times: user 724 ms, sys: 51 μs, total: 724 ms
Wall time: 726 ms</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-003/images/output_13_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div></li>
</ul>
</section>
<section id="understanding-cuda-and-gpus" class="level3">
<h3 class="anchored" data-anchor-id="understanding-cuda-and-gpus">4. Understanding CUDA and GPUs</h3>
<ul>
<li><strong>CUDA Speedup:</strong> CUDA enables significant speedup by utilizing the parallel processing capabilities of GPUs.</li>
<li><strong>GPU Architecture:</strong>
<ul>
<li><strong>Streaming Multiprocessors (SMs):</strong> Independent processing units within a GPU (e.g., 82 in an RTX 3090).</li>
<li><strong>CUDA Cores:</strong> Parallel processing units within each SM (e.g., 128 per SM in an RTX 3090).</li>
<li>An RTX 3090 has 10,496 CUDA cores that can operate simultaneously.</li>
</ul></li>
<li><strong>CUDA Programming Model:</strong>
<ul>
<li><strong>Kernels:</strong> Functions designed to be executed in parallel on many CUDA cores.</li>
<li><strong>Parallel Execution:</strong> CUDA automatically distributes the kernel execution across multiple CUDA cores.</li>
<li><strong>Memory Modification:</strong> Kernels primarily modify memory; they do not return values directly.</li>
</ul></li>
</ul>
</section>
<section id="simulating-a-cuda-kernel-in-python" class="level3">
<h3 class="anchored" data-anchor-id="simulating-a-cuda-kernel-in-python">5. Simulating a CUDA Kernel in Python</h3>
<ul>
<li><p><strong>Limitations:</strong> This simulation does not run in parallel and is not faster than the original Python loop.</p></li>
<li><p><strong>Purpose:</strong> To demonstrate the conceptual behavior of a CUDA kernel.</p></li>
<li><p><strong><code>runKernel</code> Function:</strong> Simulates a CUDA kernel execution in Python using a single for loop.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> run_kernel(f, times, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args):</span>
<span id="cb13-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb13-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Run a kernel function multiple times.</span></span>
<span id="cb13-4"></span>
<span id="cb13-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb13-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        f (function): Kernel function to run.</span></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        times (int): Number of times to run the kernel.</span></span>
<span id="cb13-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        *args: Additional arguments to pass to the kernel function.</span></span>
<span id="cb13-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb13-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(times):</span>
<span id="cb13-11">        f(i, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args)</span></code></pre></div>
<ul>
<li>Takes a function, the number of times to run it, and arguments as input.</li>
<li>Calls the function repeatedly with an index and the provided arguments.</li>
</ul></li>
<li><p><strong>Grayscale Conversion (Simulated Kernel)</strong>:</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> rgb2grey_k(i, x, out, n):</span>
<span id="cb14-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb14-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Kernel function for RGB to grayscale conversion.</span></span>
<span id="cb14-4"></span>
<span id="cb14-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb14-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        i (int): Current index.</span></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        x (torch.Tensor): Flattened input RGB tensor.</span></span>
<span id="cb14-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        out (torch.Tensor): Output grayscale tensor.</span></span>
<span id="cb14-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (int): Number of pixels in a single channel.</span></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb14-11">    out[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2989</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5870</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x[i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> n] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1140</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x[i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> n]</span></code></pre></div>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> rgb2grey_pyk(x):</span>
<span id="cb15-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb15-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Convert an RGB image to grayscale using a kernel approach.</span></span>
<span id="cb15-4"></span>
<span id="cb15-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb15-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        x (torch.Tensor): Input RGB image tensor of shape (C, H, W).</span></span>
<span id="cb15-7"></span>
<span id="cb15-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb15-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        torch.Tensor: Grayscale image tensor of shape (H, W).</span></span>
<span id="cb15-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb15-11">    c, h, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.shape</span>
<span id="cb15-12">    n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> w</span>
<span id="cb15-13">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.flatten()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Flatten the input tensor</span></span>
<span id="cb15-14">    res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.empty(n, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>x.dtype, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>x.device)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize result tensor</span></span>
<span id="cb15-15"></span>
<span id="cb15-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the kernel function to convert RGB to grayscale</span></span>
<span id="cb15-17">    run_kernel(rgb2grey_k, h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> w, x, res, n)</span>
<span id="cb15-18"></span>
<span id="cb15-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> res.view(h, w)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reshape result to original dimensions</span></span></code></pre></div>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert image to grayscale using kernel approach and display</span></span>
<span id="cb16-2">img_g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rgb2grey_pyk(img2)</span>
<span id="cb16-3">show_img(img_g, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-003/images/output_19_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<ul>
<li><strong>Call <code>runKernel</code></strong>: Pass the grayscale conversion logic as the kernel function.</li>
<li><strong>No Parallelism</strong>: This simulation does not achieve true parallelism, but demonstrates the concept.</li>
</ul></li>
</ul>
</section>
<section id="cuda-blocks-and-threads" class="level3">
<h3 class="anchored" data-anchor-id="cuda-blocks-and-threads">6. CUDA Blocks and Threads</h3>
<ul>
<li><p><strong>Blocks and Threads:</strong> CUDA organizes kernel execution into blocks and threads.</p>
<ul>
<li><strong>Blocks:</strong> Groups of threads.</li>
<li><strong>Threads:</strong> Individual execution units within a block.</li>
</ul></li>
<li><p><strong>Kernel Runner with Blocks and Threads:</strong></p>
<ul>
<li>CUDA kernel execution is simulated using nested for loops (one for blocks, one for threads).</li>
<li>Each thread gets a unique index calculated from its block index and thread index.</li>
</ul></li>
<li><p><strong>Reason for Blocks and Threads:</strong></p>
<ul>
<li><strong>Shared Memory:</strong> Threads within a block share a small, fast memory space (shared memory).
<ul>
<li>256 KB Register File &amp; 128 KB of L1/Shared Memory in an RTX 3090</li>
</ul></li>
<li><strong>Synchronization:</strong> Threads within a block can synchronize their execution.</li>
<li><strong>Streaming Multiprocessor (SM) Execution:</strong> All threads within a block are executed on the same SM.</li>
</ul></li>
<li><p><strong>Choosing Block and Thread Dimensions:</strong></p>
<ul>
<li><strong>Threads per Block:</strong> Often set to 256 as a default.</li>
<li><strong>Number of Blocks:</strong> Calculated based on the total number of iterations needed and the threads per block.</li>
</ul></li>
<li><p><strong>Guard Block:</strong> An <code>if</code> statement within the kernel to prevent out-of-bounds memory access due to potential block size mismatches.</p></li>
<li><p><strong>Python Block Kernel:</strong></p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> blk_kernel(f, blocks, threads, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args):</span>
<span id="cb17-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb17-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Simulate a GPU-like block and thread execution model.</span></span>
<span id="cb17-4"></span>
<span id="cb17-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function emulates the behavior of GPU kernels by executing a given function</span></span>
<span id="cb17-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    across a specified number of blocks and threads.</span></span>
<span id="cb17-7"></span>
<span id="cb17-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb17-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        f (function): The function to be executed in a block-thread manner.</span></span>
<span id="cb17-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blocks (int): The number of blocks to simulate.</span></span>
<span id="cb17-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        threads (int): The number of threads per block to simulate.</span></span>
<span id="cb17-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        *args: Additional arguments to be passed to the function f.</span></span>
<span id="cb17-13"></span>
<span id="cb17-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb17-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        None</span></span>
<span id="cb17-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb17-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blocks):</span>
<span id="cb17-18">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(threads):</span>
<span id="cb17-19">            f(i, j, threads, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args)</span></code></pre></div>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> rgb2grey_bk(blockidx, threadidx, blockdim, x, out, n):</span>
<span id="cb18-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb18-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Convert RGB to greyscale for a single pixel in a block-thread execution model.</span></span>
<span id="cb18-4"></span>
<span id="cb18-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function calculates the greyscale value for a single pixel using the formula:</span></span>
<span id="cb18-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    grey = 0.2989*R + 0.5870*G + 0.1140*B</span></span>
<span id="cb18-7"></span>
<span id="cb18-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb18-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockidx (int): The current block index.</span></span>
<span id="cb18-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        threadidx (int): The current thread index within the block.</span></span>
<span id="cb18-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockdim (int): The number of threads per block.</span></span>
<span id="cb18-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        x (torch.Tensor): The flattened input RGB image tensor.</span></span>
<span id="cb18-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        out (torch.Tensor): The output tensor to store the greyscale result.</span></span>
<span id="cb18-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (int): The total number of pixels in the image.</span></span>
<span id="cb18-15"></span>
<span id="cb18-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb18-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        None</span></span>
<span id="cb18-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb18-19">    i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> blockidx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockdim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> threadidx  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate global index</span></span>
<span id="cb18-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> n:  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure we're within the image bounds</span></span>
<span id="cb18-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate greyscale value using standard coefficients</span></span>
<span id="cb18-22">        out[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2989</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>x[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5870</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>x[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>n] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1140</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>x[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n]</span></code></pre></div>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> rgb2grey_pybk(x):</span>
<span id="cb19-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb19-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Convert an RGB image to greyscale using a block-thread execution model.</span></span>
<span id="cb19-4"></span>
<span id="cb19-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function simulates GPU-like parallel processing to convert an RGB image</span></span>
<span id="cb19-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    to greyscale efficiently.</span></span>
<span id="cb19-7"></span>
<span id="cb19-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb19-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        x (torch.Tensor): The input RGB image tensor with shape (3, height, width).</span></span>
<span id="cb19-10"></span>
<span id="cb19-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb19-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        torch.Tensor: The resulting greyscale image tensor with shape (height, width).</span></span>
<span id="cb19-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb19-14">    c, h, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.shape</span>
<span id="cb19-15">    n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> w</span>
<span id="cb19-16">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.flatten()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Flatten the input tensor</span></span>
<span id="cb19-17"></span>
<span id="cb19-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare output tensor</span></span>
<span id="cb19-19">    res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.empty(n, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>x.dtype, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>x.device)</span>
<span id="cb19-20"></span>
<span id="cb19-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up block and thread dimensions</span></span>
<span id="cb19-22">    threads <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span></span>
<span id="cb19-23">    blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(math.ceil(h<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>threads))</span>
<span id="cb19-24"></span>
<span id="cb19-25">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Execute the conversion using our simulated block-thread model</span></span>
<span id="cb19-26">    blk_kernel(rgb2grey_bk, blocks, threads, x, res, n)</span>
<span id="cb19-27"></span>
<span id="cb19-28">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> res.view(h, w)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reshape the result back to 2D</span></span></code></pre></div>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the image to greyscale</span></span>
<span id="cb20-2">img_g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rgb2grey_pybk(img2)</span>
<span id="cb20-3"></span>
<span id="cb20-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the greyscale image</span></span>
<span id="cb20-5">show_img(img_g, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-003/images/output_26_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div></li>
</ul>
</section>
<section id="cuda-setup-in-a-notebook" class="level3">
<h3 class="anchored" data-anchor-id="cuda-setup-in-a-notebook">7. CUDA Setup in a Notebook</h3>
<ul>
<li><p><strong>Setup:</strong></p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set CUDA launch blocking to '1' for synchronous kernel launches</span></span>
<span id="cb21-2">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'CUDA_LAUNCH_BLOCKING'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'1'</span></span></code></pre></div>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>pip install <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>q wurlitzer ninja</span></code></pre></div>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the wurlitzer extension for capturing and redirecting output</span></span>
<span id="cb23-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>load_ext wurlitzer</span></code></pre></div>
<ul>
<li>Set environment variable <code>CUDA_LAUNCH_BLOCKING=1</code> for debugging (slows down execution).</li>
<li>Install <code>ninja</code> (build tool) and <code>wurlitzer</code> (to enable printing from CUDA code in notebooks).</li>
</ul></li>
<li><p><strong><code>load_cuda</code> Function:</strong> A wrapper around <a href="https://pytorch.org/docs/stable/cpp_extension.html#torch.utils.cpp_extension.load_inline"><code>torch.utils.cpp_extension.load_inline</code></a> to simplify loading CUDA code.</p>
<ul>
<li><code>load_inline</code>: A powerful function for compiling and loading CUDA code directly from Python strings.</li>
</ul>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> load_cuda(cuda_src, cpp_src, funcs, opt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb24-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb24-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Load CUDA and C++ source code as a Python extension.</span></span>
<span id="cb24-4"></span>
<span id="cb24-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function compiles and loads CUDA and C++ source code as a Python extension,</span></span>
<span id="cb24-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    allowing for the use of custom CUDA kernels in Python.</span></span>
<span id="cb24-7"></span>
<span id="cb24-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb24-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        cuda_src (str): CUDA source code as a string.</span></span>
<span id="cb24-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        cpp_src (str): C++ source code as a string.</span></span>
<span id="cb24-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        funcs (list): List of function names to be exposed from the extension.</span></span>
<span id="cb24-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        opt (bool, optional): Whether to enable optimization flags. Defaults to False.</span></span>
<span id="cb24-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        verbose (bool, optional): Whether to print verbose output during compilation. Defaults to False.</span></span>
<span id="cb24-14"></span>
<span id="cb24-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb24-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        module: Loaded Python extension module containing the compiled functions.</span></span>
<span id="cb24-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb24-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use load_inline to compile and load the CUDA and C++ source code</span></span>
<span id="cb24-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> load_inline(cuda_sources<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[cuda_src], cpp_sources<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[cpp_src], functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>funcs,</span>
<span id="cb24-20">                       extra_cuda_cflags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-O2"</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> opt <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> [], verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>verbose, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"inline_ext"</span>)</span></code></pre></div></li>
<li><p><strong>Common C++ Code:</strong> Define common C++ code, including header files, macros for checking tensor properties (CUDA, contiguous), and a macro for ceiling division.</p>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define CUDA boilerplate code and utility macros</span></span>
<span id="cb25-2">cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb25-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">#include &lt;torch/extension.h&gt;</span></span>
<span id="cb25-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">#include &lt;stdio.h&gt;</span></span>
<span id="cb25-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">#include &lt;c10/cuda/CUDAException.h&gt;</span></span>
<span id="cb25-6"></span>
<span id="cb25-7"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">// Macro to check if a tensor is a CUDA tensor</span></span>
<span id="cb25-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x " must be a CUDA tensor")</span></span>
<span id="cb25-9"></span>
<span id="cb25-10"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">// Macro to check if a tensor is contiguous in memory</span></span>
<span id="cb25-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x " must be contiguous")</span></span>
<span id="cb25-12"></span>
<span id="cb25-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">// Macro to check both CUDA and contiguity requirements</span></span>
<span id="cb25-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)</span></span>
<span id="cb25-15"></span>
<span id="cb25-16"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">// Utility function for ceiling division</span></span>
<span id="cb25-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}</span></span>
<span id="cb25-18"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span></code></pre></div></li>
</ul>
</section>
<section id="writing-and-compiling-cuda-kernels" class="level3">
<h3 class="anchored" data-anchor-id="writing-and-compiling-cuda-kernels">8. Writing and Compiling CUDA Kernels</h3>
<ul>
<li><p><strong>Writing CUDA Kernels:</strong></p>
<ul>
<li>Use ChatGPT to convert Python kernel code to C++ CUDA code (or write it manually if comfortable with C++).</li>
<li>Adapt the code to CUDA syntax (e.g., <code>blockidx.x</code>, <code>blockdim.x</code>, <code>threadidx.x</code>, data types, semicolons).</li>
<li>Use <code>unsigned char*</code> for <code>uint8</code> (byte) data type in C++.</li>
<li><strong><code>__global__</code>:</strong> A CUDA keyword that indicates a kernel function callable from the CPU and executed on the GPU.</li>
</ul></li>
<li><p><strong>Calling CUDA Kernels:</strong></p>
<ul>
<li>Use triple angle brackets (<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>) to launch a CUDA kernel.</li>
<li>Specify the number of blocks and threads per block within the brackets.</li>
<li>Pass tensor arguments using <code>.data_ptr&lt;data_type&gt;()</code> to get C++ pointers.</li>
<li>Use <code>input.options()</code> to create output tensors with the same data type and device as the input tensor.</li>
<li>Use <code>TORCH_CHECK</code> to check for CUDA errors after kernel execution.</li>
</ul></li>
<li><p><strong>CUDA Source Code:</strong></p>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA kernel definition for RGB to grayscale conversion</span></span>
<span id="cb26-2">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb26-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb26-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @brief CUDA kernel for converting RGB image to grayscale.</span></span>
<span id="cb26-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * </span></span>
<span id="cb26-6"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * This kernel applies the luminance formula to convert RGB values to grayscale:</span></span>
<span id="cb26-7"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * Gray = 0.2989 * R + 0.5870 * G + 0.1140 * B</span></span>
<span id="cb26-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> *</span></span>
<span id="cb26-9"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param x Pointer to the input RGB image data (interleaved R, G, B channels)</span></span>
<span id="cb26-10"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param out Pointer to the output grayscale image data</span></span>
<span id="cb26-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param n Total number of pixels in the image</span></span>
<span id="cb26-12"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb26-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">__global__ void rgb_to_grayscale_kernel(unsigned char* x, unsigned char* out, int n) {</span></span>
<span id="cb26-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Calculate global thread ID</span></span>
<span id="cb26-15"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span></span>
<span id="cb26-16"></span>
<span id="cb26-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Ensure we don't process beyond the image bounds</span></span>
<span id="cb26-18"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    if (i &lt; n) {</span></span>
<span id="cb26-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Apply luminance formula. Note: x[i], x[i+n], and x[i+2*n] correspond to R, G, and B channels respectively</span></span>
<span id="cb26-20"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        out[i] = 0.2989 * x[i] + 0.5870 * x[i+n] + 0.1140 * x[i+2*n];</span></span>
<span id="cb26-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb26-22"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb26-23"></span>
<span id="cb26-24"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb26-25"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @brief C++ wrapper function to call the CUDA kernel for RGB to grayscale conversion.</span></span>
<span id="cb26-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * </span></span>
<span id="cb26-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * This function prepares the data and launches the CUDA kernel to perform the conversion.</span></span>
<span id="cb26-28"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> *</span></span>
<span id="cb26-29"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param input Input RGB image tensor (expected shape: [3, height, width])</span></span>
<span id="cb26-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @return torch::Tensor Grayscale image tensor (shape: [height, width])</span></span>
<span id="cb26-31"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb26-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor rgb_to_grayscale(torch::Tensor input) {</span></span>
<span id="cb26-33"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Verify input tensor properties (shape, type, etc.)</span></span>
<span id="cb26-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(input);</span></span>
<span id="cb26-35"></span>
<span id="cb26-36"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Extract image dimensions</span></span>
<span id="cb26-37"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int h = input.size(1);</span></span>
<span id="cb26-38"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int w = input.size(2);</span></span>
<span id="cb26-39"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    printf("h*w: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%d</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">*</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%d</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">\n", h, w);</span></span>
<span id="cb26-40"></span>
<span id="cb26-41"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Create output tensor for grayscale image</span></span>
<span id="cb26-42"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    auto output = torch::empty({h,w}, input.options());</span></span>
<span id="cb26-43"></span>
<span id="cb26-44"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Set number of threads per block</span></span>
<span id="cb26-45"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int threads = 256;</span></span>
<span id="cb26-46"></span>
<span id="cb26-47"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Launch kernel with calculated grid size</span></span>
<span id="cb26-48"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    rgb_to_grayscale_kernel&lt;&lt;&lt;cdiv(w*h,threads), threads&gt;&gt;&gt;(</span></span>
<span id="cb26-49"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        input.data_ptr&lt;unsigned char&gt;(), output.data_ptr&lt;unsigned char&gt;(), w*h);</span></span>
<span id="cb26-50"></span>
<span id="cb26-51"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Check for any errors in kernel launch or execution</span></span>
<span id="cb26-52"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    C10_CUDA_KERNEL_LAUNCH_CHECK();</span></span>
<span id="cb26-53"></span>
<span id="cb26-54"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb26-55"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb26-56"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span></code></pre></div></li>
<li><p><strong>C++ Source Code:</strong> Define a C++ header that lists the CUDA functions to be made available to Python.</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># C++ function declaration for the RGB to grayscale conversion</span></span>
<span id="cb27-2">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"torch::Tensor rgb_to_grayscale(torch::Tensor input);"</span></span></code></pre></div></li>
<li><p><strong>Compiling with <code>load_cuda</code>:</strong> Use the <code>load_cuda</code> function to compile the CUDA and C++ code into a Python module.</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the CUDA module with the defined kernel and C++ function</span></span>
<span id="cb28-2">module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_cuda(cuda_src, cpp_src, [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rgb_to_grayscale'</span>], verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
<pre class="text"><code>Using /home/innom-dt/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
Creating extension directory /home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext/build.ninja...
/home/innom-dt/mambaforge/envs/cuda-mode/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1961: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module inline_ext...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module inline_ext...</code></pre>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the path to the extension module</span></span>
<span id="cb30-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Module Path: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__file__</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<pre class="text"><code>Module Path: /home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext/inline_ext.so</code></pre>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import the pandas package</span></span>
<span id="cb32-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb32-3"></span>
<span id="cb32-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do not truncate the contents of cells and display all rows and columns</span></span>
<span id="cb32-5">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_colwidth'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_columns'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb32-6"></span>
<span id="cb32-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the content of the module folder as a Pandas DataFrame</span></span>
<span id="cb32-8">pd.DataFrame(Path(module.<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__file__</span>).parent.iterdir())</span></code></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Files
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
/home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext/main.o
</td>
</tr>
<tr>
<th>
1
</th>
<td>
/home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext/.ninja_deps
</td>
</tr>
<tr>
<th>
2
</th>
<td>
/home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext/build.ninja
</td>
</tr>
<tr>
<th>
3
</th>
<td>
/home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext/cuda.cuda.o
</td>
</tr>
<tr>
<th>
4
</th>
<td>
/home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext/cuda.cu
</td>
</tr>
<tr>
<th>
5
</th>
<td>
/home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext/.ninja_log
</td>
</tr>
<tr>
<th>
6
</th>
<td>
/home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext/inline_ext.so
</td>
</tr>
<tr>
<th>
7
</th>
<td>
/home/innom-dt/.cache/torch_extensions/py311_cu124/inline_ext/main.cpp
</td>
</tr>
</tbody>
</table>
</div>
<div class="sourceCode" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># List all non-private attributes of the loaded module</span></span>
<span id="cb33-2">[o <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> o <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dir</span>(module) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> o[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_'</span>]</span></code></pre></div>
<pre class="text"><code>['rgb_to_grayscale']</code></pre></li>
</ul>
</section>
<section id="running-the-cuda-kernel" class="level3">
<h3 class="anchored" data-anchor-id="running-the-cuda-kernel">9. Running the CUDA Kernel</h3>
<ul>
<li><p><strong>Ensure Contiguity and CUDA Device:</strong> Put the input tensor on the CUDA device and make it contiguous.</p>
<div class="sourceCode" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure the input image is contiguous and move it to CUDA device</span></span>
<span id="cb35-2">imgc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> img.contiguous().cuda()</span></code></pre></div></li>
<li><p><strong>Kernel Execution:</strong> Call the compiled CUDA function from Python, passing the input tensor and other required arguments.</p>
<div class="sourceCode" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>time</span>
<span id="cb36-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Time the execution of the RGB to grayscale conversion</span></span>
<span id="cb36-3">res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> module.rgb_to_grayscale(imgc).cpu()</span>
<span id="cb36-4"></span>
<span id="cb36-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract height and width of the resulting grayscale image</span></span>
<span id="cb36-6">h, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> res.shape</span>
<span id="cb36-7">h, w, h<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display height, width, and total number of pixels</span></span></code></pre></div>
<pre class="text"><code>CPU times: user 740 μs, sys: 0 ns, total: 740 μs
Wall time: 636 μs

(1066, 1600, 1705600)</code></pre>
<div class="sourceCode" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the resulting grayscale image</span></span>
<span id="cb38-2">show_img(res, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-003/images/output_43_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<ul>
<li><strong>Performance:</strong> The CUDA kernel execution is significantly faster on the full size image than the Python implementation on the smaller image (636 μs vs.&nbsp;726 ms).</li>
</ul></li>
</ul>
</section>
</section>
<section id="exercise-2-matrix-multiplication" class="level2">
<h2 class="anchored" data-anchor-id="exercise-2-matrix-multiplication">Exercise 2: Matrix Multiplication</h2>
<section id="understanding-matrix-multiplication" class="level3">
<h3 class="anchored" data-anchor-id="understanding-matrix-multiplication">1. Understanding Matrix Multiplication</h3>
<ul>
<li><p><strong>Definition:</strong> A fundamental linear algebra operation used extensively in deep learning.</p></li>
<li><p><strong>Process:</strong> Involves calculating the dot product of rows of one matrix with columns of another matrix.</p></li>
<li><p><strong>Example:</strong> Multiplying a 5x784 matrix with a 784x10 matrix results in a 5x10 matrix.</p></li>
</ul>
</section>
<section id="matrix-multiplication-in-python" class="level3">
<h3 class="anchored" data-anchor-id="matrix-multiplication-in-python">2. Matrix Multiplication in Python</h3>
<ul>
<li><p><strong>MNIST Dataset:</strong> Uses the MNIST dataset of handwritten digits (28x28 images) for the example.</p>
<div class="sourceCode" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> gzip,pickle</span>
<span id="cb39-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> urllib.request <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> urlretrieve</span>
<span id="cb39-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb39-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor</span></code></pre></div>
<div class="sourceCode" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># URL for downloading the MNIST dataset</span></span>
<span id="cb40-2">MNIST_URL <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'</span></span>
<span id="cb40-3"></span>
<span id="cb40-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a directory to store the data</span></span>
<span id="cb40-5">path_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'data'</span>)</span>
<span id="cb40-6">path_data.mkdir(exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb40-7"></span>
<span id="cb40-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the path for the gzipped MNIST file</span></span>
<span id="cb40-9">path_gz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> path_data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mnist.pkl.gz'</span></span>
<span id="cb40-10"></span>
<span id="cb40-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Download the MNIST dataset if it doesn't exist</span></span>
<span id="cb40-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> path_gz.exists():</span>
<span id="cb40-13">    urlretrieve(MNIST_URL, path_gz)</span></code></pre></div>
<div class="sourceCode" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load and extract the MNIST data</span></span>
<span id="cb41-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> gzip.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(path_gz, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rb'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb41-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load training, validation, and test sets (ignoring test set)</span></span>
<span id="cb41-4">    ((x_train, y_train), (x_valid, y_valid), _) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pickle.load(f, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'latin-1'</span>)</span>
<span id="cb41-5"></span>
<span id="cb41-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert data to PyTorch tensors</span></span>
<span id="cb41-7">x_train, y_train, x_valid, y_valid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(tensor, (x_train, y_train, x_valid, y_valid))</span>
<span id="cb41-8"></span>
<span id="cb41-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print shape and data type of training data</span></span>
<span id="cb41-10">x_train.shape, x_train.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>()</span></code></pre></div>
<pre class="text"><code>(torch.Size([50000, 784]), 'torch.FloatTensor')</code></pre>
<div class="sourceCode" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reshape training images to 2D format (28x28 pixels)</span></span>
<span id="cb43-2">imgs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_train.reshape((<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>))</span>
<span id="cb43-3">imgs.shape</span></code></pre></div>
<pre class="text"><code>torch.Size([50000, 28, 28])</code></pre>
<div class="sourceCode" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the first image in the dataset</span></span>
<span id="cb45-2">show_img(imgs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray_r'</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-003/images/output_50_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div></li>
<li><p><strong>Weight Matrix:</strong> A randomly initialized weight matrix (784x10) is used.</p>
<div class="sourceCode" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set random seed for reproducibility</span></span>
<span id="cb46-2">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb46-3"></span>
<span id="cb46-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize random weights for a neural network (784 input features, 10 output classes)</span></span>
<span id="cb46-5">weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">784</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb46-6">weights</span></code></pre></div>
<pre class="text"><code>tensor([[-1.5256, -0.7502, -0.6540,  ..., -1.6091, -0.7121,  0.3037],
        [-0.7773, -0.2515, -0.2223,  ..., -1.1608,  0.6995,  0.1991],
        [ 0.8657,  0.2444, -0.6629,  ..., -1.4465,  0.0612, -0.6177],
        ...,
        [ 0.5063,  0.4656, -0.2634,  ...,  0.6452,  0.4298, -1.2936],
        [ 0.5171,  1.0315,  0.8120,  ..., -0.1046,  2.2588, -0.2793],
        [-1.4899,  0.3898, -0.5454,  ..., -0.1923, -0.5076,  0.5439]])</code></pre></li>
<li><p><strong>Base Implementation:</strong></p>
<div class="sourceCode" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Example usage and performance measurement</span></span>
<span id="cb48-2">m1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_valid[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Select first 5 rows from x_valid</span></span>
<span id="cb48-3">m2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> weights  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assign weights to m2</span></span>
<span id="cb48-4"></span>
<span id="cb48-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print shapes of input matrices</span></span>
<span id="cb48-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Shape of m1: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>m1<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, Shape of m2: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>m2<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<pre class="text"><code>Shape of m1: torch.Size([5, 784]), Shape of m2: torch.Size([784, 10])</code></pre>
<div class="sourceCode" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Unpack dimensions of input matrices</span></span>
<span id="cb50-2">ar, ac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m1.shape  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of rows and columns in m1</span></span>
<span id="cb50-3">br, bc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m2.shape  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of rows and columns in m2</span></span>
<span id="cb50-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Dimensions: (ar=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ar<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, ac=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ac<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">), (br=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>br<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, bc=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>bc<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)"</span>)</span></code></pre></div>
<pre class="text"><code>Dimensions: (ar=5, ac=784), (br=784, bc=10)</code></pre>
<div class="sourceCode" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize result tensor</span></span>
<span id="cb52-2">t1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)</span>
<span id="cb52-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Shape of result tensor: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>t1<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<pre class="text"><code>Shape of result tensor: torch.Size([5, 10])</code></pre>
<div class="sourceCode" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Perform matrix multiplication using nested loops</span></span>
<span id="cb54-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar):         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 5 iterations (rows of m1)</span></span>
<span id="cb54-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(bc):     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 10 iterations (columns of m2)</span></span>
<span id="cb54-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ac): <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 784 iterations (columns of m1 / rows of m2)</span></span>
<span id="cb54-5">            t1[i, j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> m1[i, k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> m2[k, j]</span>
<span id="cb54-6"></span>
<span id="cb54-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Shape of result after multiplication: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>t1<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<pre class="text"><code>Shape of result after multiplication: torch.Size([5, 10])</code></pre>
<div class="sourceCode" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Configure numpy and torch print options for better readability</span></span>
<span id="cb56-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb56-3">np.set_printoptions(precision<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>)</span>
<span id="cb56-4">torch.set_printoptions(precision<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>, sci_mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
<div class="sourceCode" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the result</span></span>
<span id="cb57-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Result of matrix multiplication:"</span>)</span>
<span id="cb57-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(t1)</span></code></pre></div>
<pre class="text"><code>Result of matrix multiplication:
tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],
        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],
        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],
        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],
        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])</code></pre>
<div class="sourceCode" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Matrix multiplication implementation</span></span>
<span id="cb59-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul(a, b):</span>
<span id="cb59-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb59-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform matrix multiplication of two 2D tensors.</span></span>
<span id="cb59-5"></span>
<span id="cb59-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb59-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    a (torch.Tensor): First input tensor with shape (ar, ac)</span></span>
<span id="cb59-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    b (torch.Tensor): Second input tensor with shape (br, bc)</span></span>
<span id="cb59-9"></span>
<span id="cb59-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb59-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    torch.Tensor: Resulting tensor after matrix multiplication with shape (ar, bc)</span></span>
<span id="cb59-12"></span>
<span id="cb59-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Note: This function assumes that the number of columns in 'a' equals the number of rows in 'b'.</span></span>
<span id="cb59-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb59-15">    (ar, ac), (br, bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape, b.shape</span>
<span id="cb59-16">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize result tensor with zeros</span></span>
<span id="cb59-17"></span>
<span id="cb59-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Perform matrix multiplication using nested loops</span></span>
<span id="cb59-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar):</span>
<span id="cb59-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(bc):</span>
<span id="cb59-21">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ac):</span>
<span id="cb59-22">                c[i, j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> a[i, k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[k, j]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Accumulate the product of corresponding elements</span></span>
<span id="cb59-23"></span>
<span id="cb59-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> c</span></code></pre></div>
<div class="sourceCode" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Measure execution time of matmul function</span></span>
<span id="cb60-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>time _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> matmul(m1, m2)</span></code></pre></div>
<pre class="text"><code>CPU times: user 443 ms, sys: 0 ns, total: 443 ms
Wall time: 443 ms</code></pre>
<div class="sourceCode" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate total number of operations</span></span>
<span id="cb62-2">total_ops <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> bc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> ac</span>
<span id="cb62-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Total number of operations: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>total_ops<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<pre class="text"><code>Total number of operations: 39200</code></pre>
<ul>
<li>Uses nested loops to iterate through rows of the first matrix and columns of the second matrix.</li>
<li>Calculates the dot product for each element in the output matrix.</li>
<li><strong>Performance:</strong> Slow for large matrices (around 1 second for 39,200 innermost operations).</li>
</ul></li>
</ul>
</section>
<section id="matrix-multiplication-with-a-cuda-kernel" class="level3">
<h3 class="anchored" data-anchor-id="matrix-multiplication-with-a-cuda-kernel">3. Matrix Multiplication with a CUDA Kernel</h3>
<ul>
<li><p><strong>Kernel Design:</strong></p>
<ul>
<li>The innermost loop (dot product calculation) is implemented as a CUDA kernel.</li>
<li>Each CUDA thread will calculate the dot product for one element in the output matrix.</li>
</ul></li>
<li><p><strong>2D Blocks and Threads:</strong></p>
<ul>
<li>CUDA allows for 2D (or even 3D) blocks and threads.</li>
<li>Blocks and threads are indexed using x and y coordinates (e.g., block(3, 4), thread(6, 12)).</li>
</ul></li>
<li><p><strong>Kernel Runner with 2D Blocks and Threads:</strong></p>
<ul>
<li>Uses four nested for loops to iterate through blocks and threads in both x and y dimensions.</li>
<li>Passes block and thread index information to the kernel.</li>
</ul></li>
<li><p><strong>CUDA Kernel Implementation:</strong></p>
<ul>
<li>Uses a guard block to prevent out-of-bounds memory access.</li>
<li>Calculates row and column indices from block and thread indices.</li>
<li>Performs the dot product calculation and stores the result in the output matrix.</li>
</ul></li>
<li><p><strong>2D Python Kernel:</strong></p>
<div class="sourceCode" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> types <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SimpleNamespace <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> ns</span></code></pre></div>
<div class="sourceCode" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> blk_kernel2d(f, blocks, threads, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args):</span>
<span id="cb65-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb65-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Simulate a 2D block-based kernel execution.</span></span>
<span id="cb65-4"></span>
<span id="cb65-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function emulates the behavior of a GPU kernel by iterating over blocks and threads</span></span>
<span id="cb65-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    in a 2D grid, calling the provided function 'f' for each thread.</span></span>
<span id="cb65-7"></span>
<span id="cb65-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb65-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        f (callable): The function to be executed for each thread.</span></span>
<span id="cb65-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blocks (ns): Namespace object representing the number of blocks in x and y dimensions.</span></span>
<span id="cb65-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        threads (ns): Namespace object representing the number of threads per block in x and y dimensions.</span></span>
<span id="cb65-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        *args: Additional arguments to be passed to the function 'f'.</span></span>
<span id="cb65-13"></span>
<span id="cb65-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb65-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        None</span></span>
<span id="cb65-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb65-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i0 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blocks.y):</span>
<span id="cb65-18">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i1 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(blocks.x):</span>
<span id="cb65-19">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j0 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(threads.y):</span>
<span id="cb65-20">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j1 <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(threads.x):</span>
<span id="cb65-21">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Call the function 'f' for each thread, passing block and thread indices</span></span>
<span id="cb65-22">                    f(ns(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>i1, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>i0), ns(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>j1, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>j0), threads, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args)</span></code></pre></div>
<div class="sourceCode" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_bk(blockidx, threadidx, blockdim, m, n, out, h, w, k):</span>
<span id="cb66-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb66-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform matrix multiplication for a single thread in a block.</span></span>
<span id="cb66-4"></span>
<span id="cb66-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function calculates the dot product for a specific element in the output matrix.</span></span>
<span id="cb66-6"></span>
<span id="cb66-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb66-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockidx (ns): Namespace object representing the block index.</span></span>
<span id="cb66-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        threadidx (ns): Namespace object representing the thread index within the block.</span></span>
<span id="cb66-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        blockdim (ns): Namespace object representing the block dimensions.</span></span>
<span id="cb66-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        m (array): Flattened input matrix 1.</span></span>
<span id="cb66-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (array): Flattened input matrix 2.</span></span>
<span id="cb66-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        out (array): Flattened output matrix.</span></span>
<span id="cb66-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        h (int): Height of the output matrix.</span></span>
<span id="cb66-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        w (int): Width of the output matrix.</span></span>
<span id="cb66-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        k (int): Shared dimension of input matrices.</span></span>
<span id="cb66-17"></span>
<span id="cb66-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb66-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        None</span></span>
<span id="cb66-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb66-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate global row and column indices</span></span>
<span id="cb66-22">    r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> blockidx.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockdim.y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> threadidx.y</span>
<span id="cb66-23">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> blockidx.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> blockdim.x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> threadidx.x</span>
<span id="cb66-24"></span>
<span id="cb66-25">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check if the current thread is within the output matrix dimensions</span></span>
<span id="cb66-26">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">or</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> w):</span>
<span id="cb66-27">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span></span>
<span id="cb66-28"></span>
<span id="cb66-29">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Perform dot product calculation</span></span>
<span id="cb66-30">    o <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb66-31">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(k):</span>
<span id="cb66-32">        o <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> m[r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> n[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>c]</span>
<span id="cb66-33"></span>
<span id="cb66-34">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Store the result in the output matrix</span></span>
<span id="cb66-35">    out[r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>w<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>c] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> o</span></code></pre></div>
<div class="sourceCode" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul_2d(m, n):</span>
<span id="cb67-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb67-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform 2D matrix multiplication using a block-based approach.</span></span>
<span id="cb67-4"></span>
<span id="cb67-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    This function implements matrix multiplication by simulating a GPU-like</span></span>
<span id="cb67-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    block and thread structure.</span></span>
<span id="cb67-7"></span>
<span id="cb67-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb67-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        m (torch.Tensor): Input matrix 1.</span></span>
<span id="cb67-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n (torch.Tensor): Input matrix 2.</span></span>
<span id="cb67-11"></span>
<span id="cb67-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb67-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        torch.Tensor: Result of the matrix multiplication.</span></span>
<span id="cb67-14"></span>
<span id="cb67-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Raises:</span></span>
<span id="cb67-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        AssertionError: If the inner dimensions of the input matrices don't match.</span></span>
<span id="cb67-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb67-18">    h, k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m.shape</span>
<span id="cb67-19">    k2, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n.shape</span>
<span id="cb67-20"></span>
<span id="cb67-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure that the inner dimensions of the matrices match</span></span>
<span id="cb67-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> k2, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Size mismatch!"</span></span>
<span id="cb67-23"></span>
<span id="cb67-24">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the output matrix</span></span>
<span id="cb67-25">    output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(h, w, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m.dtype)</span>
<span id="cb67-26"></span>
<span id="cb67-27">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define thread-per-block dimensions</span></span>
<span id="cb67-28">    tpb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ns(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>)</span>
<span id="cb67-29"></span>
<span id="cb67-30">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the number of blocks needed</span></span>
<span id="cb67-31">    blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ns(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>math.ceil(w<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>tpb.x), y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>math.ceil(h<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>tpb.y))</span>
<span id="cb67-32"></span>
<span id="cb67-33">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Execute the block kernel</span></span>
<span id="cb67-34">    blk_kernel2d(matmul_bk, blocks, tpb,</span>
<span id="cb67-35">                 m.flatten(), n.flatten(), output.flatten(), h, w, k)</span>
<span id="cb67-36"></span>
<span id="cb67-37">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> output</span></code></pre></div>
<div class="sourceCode" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Perform matrix multiplication</span></span>
<span id="cb68-2">res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> matmul_2d(m1, m2)</span>
<span id="cb68-3"></span>
<span id="cb68-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify the result (assuming 't1' is the expected output)</span></span>
<span id="cb68-5">torch.isclose(t1, res).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True)</code></pre></li>
</ul>
</section>
<section id="matrix-multiplication-in-cuda" class="level3">
<h3 class="anchored" data-anchor-id="matrix-multiplication-in-cuda">4. Matrix Multiplication in CUDA</h3>
<ul>
<li><p><strong>Optimized CPU Approach:</strong> Uses a broadcasting approach in Python for a faster CPU-based matrix multiplication to compare against the CUDA version.</p>
<div class="sourceCode" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul(a, b):</span>
<span id="cb70-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb70-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Perform matrix multiplication of two 2D tensors.</span></span>
<span id="cb70-4"></span>
<span id="cb70-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb70-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        a (torch.Tensor): First input tensor with shape (ar, ac)</span></span>
<span id="cb70-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        b (torch.Tensor): Second input tensor with shape (br, bc)</span></span>
<span id="cb70-8"></span>
<span id="cb70-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb70-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        torch.Tensor: Result of matrix multiplication with shape (ar, bc)</span></span>
<span id="cb70-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb70-12">    (ar, ac), (br, bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape, b.shape</span>
<span id="cb70-13">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize result tensor with zeros</span></span>
<span id="cb70-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar):</span>
<span id="cb70-15">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Multiply each row of 'a' with all columns of 'b' and sum the results</span></span>
<span id="cb70-16">        c[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[i, :, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb70-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> c</span></code></pre></div>
<div class="sourceCode" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check if the custom matmul function produces the same result as torch.matmul</span></span>
<span id="cb71-2">torch.isclose(t1, matmul(m1, m2)).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True)</code></pre>
<div class="sourceCode" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Measure the execution time of the custom matmul function</span></span>
<span id="cb73-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>time _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> matmul(m1, m2)</span></code></pre></div>
<pre class="text"><code>CPU times: user 634 μs, sys: 266 μs, total: 900 μs
Wall time: 568 μs</code></pre>
<div class="sourceCode" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use x_train as m1 and perform matrix multiplication</span></span>
<span id="cb75-2">m1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_train</span>
<span id="cb75-3">tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> matmul(m1, m2)</span>
<span id="cb75-4">tr.shape  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the shape of the resulting tensor</span></span></code></pre></div>
<pre class="text"><code>torch.Size([50000, 10])</code></pre>
<div class="sourceCode" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Measure the execution time with whole input matrices</span></span>
<span id="cb77-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>time _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> matmul(m1, m2)</span></code></pre></div>
<pre class="text"><code>CPU times: user 712 ms, sys: 0 ns, total: 712 ms
Wall time: 641 ms</code></pre>
<div class="sourceCode" id="cb79" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the total number of scalar multiplications in the matrix multiplication</span></span>
<span id="cb79-2">ar, ac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m1.shape</span>
<span id="cb79-3">br, bc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m2.shape</span>
<span id="cb79-4">ar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> bc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> ac  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of multiplications: (rows of m1) * (cols of m2) * (cols of m1)</span></span></code></pre></div>
<pre class="text"><code>392000000</code></pre></li>
<li><p><strong>CUDA Kernel Conversion:</strong> Convert the Python kernel to C++ CUDA code using ChatGPT (or manually).</p></li>
<li><p><strong>Implementing the CUDA Kernel:</strong></p>
<div class="sourceCode" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA kernel for matrix multiplication</span></span>
<span id="cb81-2">  cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb81-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  __global__ void matmul_k(float* m, float* n, float* out, int h, int w, int k) {</span></span>
<span id="cb81-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      // Calculate global thread indices</span></span>
<span id="cb81-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      int r = blockIdx.y * blockDim.y + threadIdx.y;</span></span>
<span id="cb81-6"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      int c = blockIdx.x * blockDim.x + threadIdx.x;</span></span>
<span id="cb81-7"></span>
<span id="cb81-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      // Boundary check</span></span>
<span id="cb81-9"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      if (r &gt;= h || c &gt;= w) return;</span></span>
<span id="cb81-10"></span>
<span id="cb81-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      // Perform dot product for this element</span></span>
<span id="cb81-12"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      float o = 0;</span></span>
<span id="cb81-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      for (int i = 0; i &lt; k; ++i) {</span></span>
<span id="cb81-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">          o += m[r*k + i] * n[i*w + c];</span></span>
<span id="cb81-15"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      }</span></span>
<span id="cb81-16"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      out[r*w + c] = o;</span></span>
<span id="cb81-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  }</span></span>
<span id="cb81-18"></span>
<span id="cb81-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  /**</span></span>
<span id="cb81-20"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">   * Perform matrix multiplication using CUDA.</span></span>
<span id="cb81-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">   *</span></span>
<span id="cb81-22"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">   * @param m First input tensor</span></span>
<span id="cb81-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">   * @param n Second input tensor</span></span>
<span id="cb81-24"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">   * @return Result of matrix multiplication</span></span>
<span id="cb81-25"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">   */</span></span>
<span id="cb81-26"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  torch::Tensor matmul(torch::Tensor m, torch::Tensor n) {</span></span>
<span id="cb81-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      CHECK_INPUT(m); CHECK_INPUT(n);</span></span>
<span id="cb81-28"></span>
<span id="cb81-29"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      // Extract dimensions</span></span>
<span id="cb81-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      int h = m.size(0);</span></span>
<span id="cb81-31"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      int w = n.size(1);</span></span>
<span id="cb81-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      int k = m.size(1);</span></span>
<span id="cb81-33"></span>
<span id="cb81-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      // Ensure matrices are compatible for multiplication</span></span>
<span id="cb81-35"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      TORCH_CHECK(k == n.size(0), "Size mismatch!");</span></span>
<span id="cb81-36"></span>
<span id="cb81-37"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      // Initialize output tensor</span></span>
<span id="cb81-38"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      auto output = torch::zeros({h, w}, m.options());</span></span>
<span id="cb81-39"></span>
<span id="cb81-40"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      // Define thread block and grid dimensions</span></span>
<span id="cb81-41"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      dim3 tpb(16, 16);</span></span>
<span id="cb81-42"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));</span></span>
<span id="cb81-43"></span>
<span id="cb81-44"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      // Launch CUDA kernel</span></span>
<span id="cb81-45"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      matmul_k&lt;&lt;&lt;blocks, tpb&gt;&gt;&gt;(</span></span>
<span id="cb81-46"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">          m.data_ptr&lt;float&gt;(), n.data_ptr&lt;float&gt;(), output.data_ptr&lt;float&gt;(), h, w, k);</span></span>
<span id="cb81-47"></span>
<span id="cb81-48"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      // Check for CUDA errors</span></span>
<span id="cb81-49"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      C10_CUDA_KERNEL_LAUNCH_CHECK();</span></span>
<span id="cb81-50"></span>
<span id="cb81-51"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      return output;</span></span>
<span id="cb81-52"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  }</span></span>
<span id="cb81-53"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  '''</span></span></code></pre></div>
<div class="sourceCode" id="cb82" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># C++ function declaration for the CUDA kernel</span></span>
<span id="cb82-2">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"torch::Tensor matmul(torch::Tensor m, torch::Tensor n);"</span></span></code></pre></div>
<ul>
<li>Uses <code>DIM3</code> structures to specify the number of threads per block in x and y dimensions.</li>
<li>Calculates the number of blocks in x and y dimensions using ceiling division.</li>
<li>Launches the CUDA kernel with the calculated block and thread dimensions.</li>
</ul></li>
<li><p><strong>Performance:</strong> The CUDA kernel is significantly faster than both the Python implementation and the optimized CPU approach (1.21 ms vs.&nbsp;641 ms).</p>
<div class="sourceCode" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the CUDA module</span></span>
<span id="cb83-2">module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_cuda(cuda_src, cpp_src, [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'matmul'</span>])</span></code></pre></div>
<pre class="text"><code>/home/innom-dt/mambaforge/envs/cuda-mode/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1961: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(</code></pre>
<div class="sourceCode" id="cb85" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare input tensors for CUDA</span></span>
<span id="cb85-2">m1c, m2c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m1.contiguous().cuda(), m2.contiguous().cuda()</span></code></pre></div>
<div class="sourceCode" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify the result against a reference implementation</span></span>
<span id="cb86-2">torch.isclose(tr, module.matmul(m1c, m2c).cpu(), atol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-5</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True)</code></pre>
<div class="sourceCode" id="cb88" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>time</span>
<span id="cb88-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Measure execution time of the CUDA matrix multiplication</span></span>
<span id="cb88-3">res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> module.matmul(m1c, m2c).cpu()</span>
<span id="cb88-4">res.shape</span></code></pre></div>
<pre class="text"><code>CPU times: user 1.45 ms, sys: 138 μs, total: 1.59 ms
Wall time: 1.21 ms

torch.Size([50000, 10])</code></pre></li>
</ul>
</section>
<section id="comparison-with-pytorchs-operator" class="level3">
<h3 class="anchored" data-anchor-id="comparison-with-pytorchs-operator">5. Comparison with PyTorch’s <code>@</code> Operator</h3>
<ul>
<li><p><strong>PyTorch’s Matrix Multiplication:</strong> PyTorch provides the <code>@</code> operator for efficient matrix multiplication.</p></li>
<li><p><strong>Performance:</strong> PyTorch’s <code>@</code> operator is even faster than the custom CUDA kernel (636 μs vs.&nbsp;1.21 ms).</p>
<div class="sourceCode" id="cb90" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compare CUDA matrix multiplication with PyTorch's built-in operation</span></span>
<span id="cb90-2">torch.isclose(tr, (m1c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> m2c).cpu(), atol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-5</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()</span></code></pre></div>
<pre class="text"><code>tensor(True)</code></pre>
<div class="sourceCode" id="cb92" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Measure the execution time of PyTorch's built-in matrix multiplication</span></span>
<span id="cb92-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span> _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (m1c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> m2c).cpu()</span></code></pre></div>
<pre class="text"><code>636 μs ± 62.7 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre></li>
</ul>
</section>
<section id="optimizing-cuda-kernels-with-shared-memory" class="level3">
<h3 class="anchored" data-anchor-id="optimizing-cuda-kernels-with-shared-memory">6. Optimizing CUDA Kernels with Shared Memory</h3>
<ul>
<li><strong>Shared Memory:</strong> A small, fast memory space shared by threads within a block.</li>
<li><strong>Optimization Potential:</strong> PyTorch’s matrix multiplication likely uses shared memory effectively to achieve higher performance.</li>
<li><strong>Caching:</strong> Shared memory can be used to cache frequently accessed data, reducing reliance on slower global memory.</li>
</ul>
</section>
<section id="d-vs.-2d-blocks-and-threads" class="level3">
<h3 class="anchored" data-anchor-id="d-vs.-2d-blocks-and-threads">7. 1D vs.&nbsp;2D Blocks and Threads</h3>
<ul>
<li><p><strong>Flexibility:</strong> CUDA allows for 1D, 2D, or 3D blocks and threads.</p></li>
<li><p><strong>Simplicity:</strong> In some cases, 1D blocks and threads can lead to simpler code compared to 2D or 3D.</p></li>
<li><p><strong>Choice:</strong> The choice between 1D, 2D, or 3D blocks and threads depends on the specific problem and coding preferences.</p></li>
<li><p><strong>2D Block Implementation:</strong></p>
<div class="sourceCode" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1">cuda_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda_begin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'''</span></span>
<span id="cb94-2"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb94-3"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * CUDA kernel function to convert RGB image to grayscale.</span></span>
<span id="cb94-4"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> *</span></span>
<span id="cb94-5"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param x Input RGB image data</span></span>
<span id="cb94-6"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param out Output grayscale image data</span></span>
<span id="cb94-7"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param w Image width</span></span>
<span id="cb94-8"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param h Image height</span></span>
<span id="cb94-9"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> *</span></span>
<span id="cb94-10"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * Note: This function is executed on the GPU for each pixel in parallel.</span></span>
<span id="cb94-11"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb94-12"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">__global__ void rgb_to_grayscale_kernel(unsigned char* x, unsigned char* out, int w, int h) {</span></span>
<span id="cb94-13"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Calculate the current pixel coordinates</span></span>
<span id="cb94-14"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int c = blockIdx.x * blockDim.x + threadIdx.x;  // Column index</span></span>
<span id="cb94-15"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int r = blockIdx.y * blockDim.y + threadIdx.y;  // Row index</span></span>
<span id="cb94-16"></span>
<span id="cb94-17"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    if (c &lt; w &amp;&amp; r &lt; h) {</span></span>
<span id="cb94-18"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        int i = r * w + c;  // Linear index for the current pixel</span></span>
<span id="cb94-19"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        int n = h * w;      // Total number of pixels in the image</span></span>
<span id="cb94-20"></span>
<span id="cb94-21"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Convert RGB to grayscale using the luminosity method</span></span>
<span id="cb94-22"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        // Weights: 0.2989 (Red), 0.5870 (Green), 0.1140 (Blue)</span></span>
<span id="cb94-23"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        out[i] = 0.2989 * x[i] + 0.5870 * x[i + n] + 0.1140 * x[i + 2 * n];</span></span>
<span id="cb94-24"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb94-25"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb94-26"></span>
<span id="cb94-27"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">/**</span></span>
<span id="cb94-28"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * Convert an RGB image to grayscale using CUDA.</span></span>
<span id="cb94-29"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> *</span></span>
<span id="cb94-30"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @param input Input RGB image tensor of shape (3, H, W)</span></span>
<span id="cb94-31"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * @return Grayscale image tensor of shape (H, W)</span></span>
<span id="cb94-32"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> *</span></span>
<span id="cb94-33"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> * Note: This function launches the CUDA kernel to perform the conversion.</span></span>
<span id="cb94-34"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> */</span></span>
<span id="cb94-35"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">torch::Tensor rgb_to_grayscale(torch::Tensor input) {</span></span>
<span id="cb94-36"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    CHECK_INPUT(input);  // Verify input tensor properties</span></span>
<span id="cb94-37"></span>
<span id="cb94-38"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int h = input.size(1);  // Image height</span></span>
<span id="cb94-39"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    int w = input.size(2);  // Image width</span></span>
<span id="cb94-40"></span>
<span id="cb94-41"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Create an empty tensor for the output grayscale image</span></span>
<span id="cb94-42"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    torch::Tensor output = torch::empty({h, w}, input.options());</span></span>
<span id="cb94-43"></span>
<span id="cb94-44"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Define the thread block dimensions</span></span>
<span id="cb94-45"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 tpb(16, 16);</span></span>
<span id="cb94-46"></span>
<span id="cb94-47"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Calculate the number of blocks needed to cover the entire image</span></span>
<span id="cb94-48"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));</span></span>
<span id="cb94-49"></span>
<span id="cb94-50"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Launch the CUDA kernel</span></span>
<span id="cb94-51"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    rgb_to_grayscale_kernel&lt;&lt;&lt;blocks, tpb&gt;&gt;&gt;(</span></span>
<span id="cb94-52"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        input.data_ptr&lt;unsigned char&gt;(),</span></span>
<span id="cb94-53"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        output.data_ptr&lt;unsigned char&gt;(),</span></span>
<span id="cb94-54"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">        w, h</span></span>
<span id="cb94-55"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    );</span></span>
<span id="cb94-56"></span>
<span id="cb94-57"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    // Check for any CUDA errors during kernel launch</span></span>
<span id="cb94-58"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    C10_CUDA_KERNEL_LAUNCH_CHECK();</span></span>
<span id="cb94-59"></span>
<span id="cb94-60"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    return output;</span></span>
<span id="cb94-61"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb94-62"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'''</span></span></code></pre></div>
<div class="sourceCode" id="cb95" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># C++ function declaration for the RGB to grayscale conversion</span></span>
<span id="cb95-2">cpp_src <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"torch::Tensor rgb_to_grayscale(torch::Tensor input);"</span></span></code></pre></div>
<div class="sourceCode" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the CUDA module</span></span>
<span id="cb96-2">module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_cuda(cuda_src, cpp_src, [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rgb_to_grayscale'</span>])</span></code></pre></div>
<div class="sourceCode" id="cb97" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the input image to grayscale and move it to CPU</span></span>
<span id="cb97-2">res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> module.rgb_to_grayscale(imgc).cpu()</span>
<span id="cb97-3"></span>
<span id="cb97-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display the resulting grayscale image</span></span>
<span id="cb97-5">show_img(res, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray'</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/cuda-mode-notes/lecture-003/images/output_89_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div></li>
</ul>
</section>
</section>
<section id="conclusion-and-next-steps" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-and-next-steps">Conclusion and Next Steps</h2>
<ul>
<li><strong>CUDA Accessibility:</strong> CUDA programming is becoming increasingly important for implementing advanced deep learning techniques.</li>
<li><strong>Python-based Development:</strong> Writing CUDA kernels can be made easier by starting with Python code and converting it to C++.</li>
<li><strong>Notebook Environment:</strong> CUDA development can be done effectively in Jupyter Notebooks.</li>
<li><strong>Local and Cloud Development:</strong> CUDA code can be run on local machines with GPUs or on cloud instances.</li>
<li><strong>Conda for CUDA Setup:</strong> Conda is a recommended tool for managing CUDA environments.
<ul>
<li><strong>Tutorial:</strong> <a href="../../../posts/cuda-python-setup-tutorial/ubuntu/">Setting Up CUDA for Python on Ubuntu</a></li>
</ul></li>
<li><strong>Further Learning:</strong>
<ul>
<li>Explore other CUDA mode lectures.</li>
<li>Try implementing projects like 4-bit quantization, flash attention, etc.</li>
<li>Read and understand other people’s CUDA code (e.g., flash attention, bits and bytes, GPTQ).</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>cuda</category>
  <category>pytorch</category>
  <guid>https://christianjmills.com/posts/cuda-mode-notes/lecture-003/</guid>
  <pubDate>Sat, 31 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Livestream: Lessons from a Year of Building with LLMs</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/lessons-from-a-year-of-building-with-llms/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="introduction-and-background" class="level3">
<h3 class="anchored" data-anchor-id="introduction-and-background">Introduction and Background</h3>
<ul>
<li><strong><a href="https://hugobowne.github.io/">Hugo Bowne-Anderson</a></strong>: Host of the <em>Vanishing Gradients</em> podcast and live stream. Has a background in data science, machine learning, and education.</li>
<li><strong>Live Stream Focus</strong>: Discussion of a report co-authored by six AI professionals (Eugene Yan, Shreya Shankar, Hamel Husain, Brian Bischof, Charles Frye, and Jason Liu), focusing on practical lessons learned from building real-world applications with Large Language Models (LLMs) over the past year.</li>
<li><strong>Report Link</strong>: <a href="https://applied-llms.org/">https://applied-llms.org/</a></li>
<li><strong>Recording Link</strong>: <a href="https://www.youtube.com/live/c0gcsprsFig">https://www.youtube.com/live/c0gcsprsFig</a></li>
<li><strong>Key Themes</strong>: The report covers tactical, operational, and strategic aspects of building LLM systems, including:
<ul>
<li><strong>Tactical</strong>: Prompt engineering, data management, evaluation strategies.</li>
<li><strong>Operational</strong>: Building development pipelines, integrating LLMs into existing workflows.</li>
<li><strong>Strategic</strong>: Understanding business use cases, defining success metrics, and building trust with stakeholders.</li>
</ul></li>
</ul>
</section>
<section id="panelist-introductions-and-motivations" class="level3">
<h3 class="anchored" data-anchor-id="panelist-introductions-and-motivations">Panelist Introductions and Motivations</h3>
<ul>
<li><strong>Eugene Yan</strong>:
<ul>
<li>Works at Amazon Books, focusing on recommendation systems and search.</li>
<li>Interested in using LLMs to enhance recommendations and search by improving customer understanding.</li>
<li>Co-authored several key resources on prompt engineering and LLM evaluation.</li>
<li>Blog: <a href="https://eugeneyan.com">https://eugeneyan.com</a></li>
</ul></li>
<li><strong>Shreya Shankar</strong>:
<ul>
<li>Researcher and ML engineer pursuing a PhD focused on data management, UX, and HCI for machine learning.</li>
<li>Interested in building intelligent software with LLMs, particularly for small teams and early-stage products.</li>
<li>Emphasis on developing evaluation methods that are simple and accessible.</li>
<li>Conducts research on evaluating LLM output quality and validating evaluation methods.</li>
</ul></li>
<li><strong>Hamel Husain</strong>:
<ul>
<li>25 years of experience in machine learning, including work on developer tools and ML infrastructure at GitHub.</li>
<li>Led research at GitHub that contributed to Copilot.</li>
<li>Passionate about using LLMs to accelerate software development and launch applications faster.</li>
<li>Strong advocate for prioritizing evaluation (<strong>evals</strong>) as a core part of the AI development process.</li>
<li>Blog post: <a href="https://hamel.dev/blog/posts/evals/">https://hamel.dev/blog/posts/evals/</a></li>
</ul></li>
<li><strong>Brian Bischof</strong>:
<ul>
<li>Head of AI at Hex, leads the team developing Magic (an AI-powered data science tool).</li>
<li>Extensive experience building data teams at Blue Bottle Coffee, Stitch Fix, and Weights &amp; Biases.</li>
<li>Passionate about applying LLMs to answer questions with data, particularly in the context of data science workflows.</li>
<li>Strong advocate for using notebooks for exploring and understanding data.</li>
</ul></li>
<li><strong>Charles Frye</strong>:
<ul>
<li>Works at Modal, focused on teaching people to build AI applications.</li>
<li>Background in psychopharmacology, neurobiology, and neural networks.</li>
<li>Interested in developing intelligent software and using LLMs to democratize cognition.</li>
<li>Key contributor to Modal’s infrastructure and developer tools, including the TensorRT-LLM library.</li>
</ul></li>
</ul>
</section>
<section id="the-genesis-of-the-report" class="level3">
<h3 class="anchored" data-anchor-id="the-genesis-of-the-report">The Genesis of the Report</h3>
<ul>
<li><strong>Origin</strong>: The report originated from discussions within a group chat among the co-authors.</li>
<li><strong>Initial Motivation</strong>:
<ul>
<li><strong>Brian Bischof</strong>: Was considering writing about a year of LLMs.</li>
<li><strong>Eugene Yan</strong>: Had already started drafting similar content.</li>
<li><strong>Charles Frye</strong>: Suggested a collaborative effort.</li>
<li><strong>Hamel Husain and Jason Liu</strong>: Enthusiastically joined the project.</li>
<li><strong>Shreya Shankar</strong>: Was invited for her expertise in evaluation and editing.</li>
</ul></li>
<li><strong>Organization</strong>:
<ul>
<li><strong>Brian Bischof</strong>: Proposed structuring the report into tactical, operational, and strategic levels.</li>
</ul></li>
<li><strong>Collaborative Workflow</strong>:
<ul>
<li>Authors contributed their ideas and experiences.</li>
<li>Content was synthesized and organized collaboratively.</li>
<li>Charles Frye played a key role in editing and consolidating the material.</li>
</ul></li>
</ul>
</section>
<section id="the-importance-of-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="the-importance-of-evaluation">The Importance of Evaluation</h3>
<ul>
<li><strong>Traditional Evals vs.&nbsp;LLM Evals</strong>:
<ul>
<li><strong>Shreya Shankar</strong>:
<ul>
<li>Traditional evaluation methods often fail to uncover issues arising from real-world data idiosyncrasies (e.g., typos, inconsistent casing).</li>
<li>Canonical benchmarks and datasets often rely on clean, pre-processed data, which does not reflect real-world data challenges.</li>
<li><strong>Example</strong>: Mistral struggles to retrieve names from documents if the name is in lowercase.</li>
<li>Traditional evals often lack methods for validating the evaluation methods themselves.</li>
<li>LLM-based evals can make evaluation more accessible to smaller teams who lack resources for traditional methods.</li>
<li><strong><a href="https://arxiv.org/abs/2404.12272">EvalGen Paper</a></strong>: Discusses a flow-based approach to validating evaluation methods and constructing appropriate evals for deployment.</li>
</ul></li>
</ul></li>
<li><strong>Overcoming Barriers to Evaluation</strong>:
<ul>
<li>Developers often struggle with the concept of evals and how to get started.</li>
<li>Shreya Shankar’s research tools provide a visual, intuitive approach to building and understanding evals, similar to Scratch for programming.</li>
<li>This “Scratch for evals” approach makes evals more accessible and understandable.</li>
</ul></li>
<li><strong>Evaluation as an Integral Part of AI Development</strong>:
<ul>
<li>Evaluation is not optional, it’s an essential part of the AI development process.</li>
<li>Evals are not separate from building AI, they are how you build AI.</li>
<li>Measuring progress and having a systematic approach to improvement are critical.</li>
<li>Focus on making evals frictionless and integrated into the workflow to enable continuous improvement.</li>
</ul></li>
<li><strong>Shifting the Focus from Tools to Process</strong>:
<ul>
<li>Developers often focus on tools (e.g., vector databases, embeddings) rather than understanding the underlying process of building and improving AI applications.</li>
<li>It’s essential to shift the focus from tools to the process of evaluation and data understanding.</li>
</ul></li>
<li><strong>Evaluation as a Proxy for Loss Functions</strong>:
<ul>
<li>Traditional machine learning relies on explicit loss functions for optimization.</li>
<li>In generative AI, the loss functions are less defined, and evals act as a proxy for measuring progress and alignment with desired outcomes.</li>
</ul></li>
</ul>
</section>
<section id="underappreciated-aspects-of-llm-development" class="level3">
<h3 class="anchored" data-anchor-id="underappreciated-aspects-of-llm-development">Underappreciated Aspects of LLM Development</h3>
<ul>
<li><strong>Equipping Engineers with LLM Skills</strong>:
<ul>
<li>Organizations need to focus on training existing software engineers to understand and effectively use LLMs.</li>
<li>Key areas for training:
<ul>
<li>Basic evaluation methods (e.g., using synthetic data, Kaggle datasets).</li>
<li>Understanding the autoregressive nature of LLM generation and its impact on latency.</li>
<li>Understanding context as conditioning.</li>
</ul></li>
</ul></li>
<li><strong>Moving from Prototype to Production</strong>:
<ul>
<li>The industry has focused heavily on demos and prototypes, and the bar for “production” has been lowered with generative AI.</li>
<li><strong>Prototype++</strong>: Products are being launched without rigorous evaluation or clear methods for quantifying improvements.</li>
<li>The definition of “production” should include systematic improvement processes and clear evidence of progress for stakeholders.</li>
<li><strong>Challenge</strong>: Moving from prototype++ to true production-ready LLM applications with robust evals and improvement processes.</li>
</ul></li>
<li><strong>The Importance of Data Literacy</strong>:
<ul>
<li>Data literacy is essential for working with LLMs, even if you are not training models from scratch.</li>
<li>Data literacy enables developers to:
<ul>
<li><strong>Analyze and debug systems</strong>: By examining data, developers can identify issues and understand system behavior.</li>
<li><strong>Develop domain-specific evals</strong>: Understanding the data is crucial for creating meaningful and effective evaluation methods.</li>
</ul></li>
<li><strong>Challenge</strong>: Overcoming the misconception that AI automates everything and realizing the ongoing need to look at and understand data.</li>
</ul></li>
<li><strong>Specific Data Literacy Skills</strong>:
<ul>
<li><strong>Assessing Output Quality</strong>:
<ul>
<li>Develop methods for determining whether an output is good or bad.</li>
<li>Use a combination of binary indicators (e.g., conciseness, tone, presence of specific phrases) to simplify evaluation.</li>
</ul></li>
<li><strong>Pairwise Comparisons</strong>: Compare two models or pipelines directly instead of relying on individual ratings.</li>
<li><strong>Understanding Implicit Constraints</strong>: Define criteria for “good” that align with user expectations.</li>
<li><strong>Simplifying Evaluation</strong>: Break down complex evaluation tasks into smaller, more manageable binary assessments.</li>
</ul></li>
<li><strong>The Role of Human-in-the-Loop Evaluation</strong>:
<ul>
<li>Importance of manual data labeling and review, especially in the early stages of development.</li>
<li>“Homework” approach at Hex: Team members use interactive Hex applications to provide feedback on model outputs and assist with data labeling.</li>
<li>This process helps to bootstrap data sets and align LLM evaluations with human judgment.</li>
</ul></li>
</ul>
</section>
<section id="misconceptions-and-knowledge-gaps-in-organizations" class="level3">
<h3 class="anchored" data-anchor-id="misconceptions-and-knowledge-gaps-in-organizations">Misconceptions and Knowledge Gaps in Organizations</h3>
<ul>
<li><strong>The “AI Engineer” Narrative and Its Limitations</strong>:
<ul>
<li><strong>Popular Characterization</strong>:
<ul>
<li>AI engineers are portrayed as primarily focused on tools, infrastructure, chains, and agents, with limited involvement in training, evals, inference, and data.</li>
</ul></li>
<li><strong>Skills Gaps</strong>:
<ul>
<li>Neglecting data literacy and evaluation skills creates significant challenges beyond the MVP stage.</li>
<li>AI engineers may find themselves unable to systematically improve their applications due to a lack of understanding of data and evaluation.</li>
</ul></li>
<li><strong>Title Issues</strong>:
<ul>
<li>The “AI engineer” title sets unrealistic expectations and places undue pressure on individuals when projects face challenges.</li>
</ul></li>
</ul></li>
<li><strong>Addressing the Talent Gap</strong>:
<ul>
<li>The most significant impact on AI product development is the talent and skills of the team.</li>
<li>Organizations need to hire for data literacy and evaluation expertise, not just tooling and infrastructure skills.</li>
<li><strong>Consulting Work</strong>: A significant portion of Hamel’s consulting work arises from addressing this talent gap and helping organizations build effective AI teams.</li>
</ul></li>
<li><strong>Real-World Example of Successful “AI Engineer” Hiring</strong>:
<ul>
<li>Successfully hired “AI engineers” by focusing on core data science skills.</li>
<li>Take-home exam focused on data cleaning, demonstrating the importance of data literacy in his definition of the role.</li>
</ul></li>
<li><strong>The Importance of Data Literacy in AI Engineering</strong>:
<ul>
<li>Data literacy is essential for AI engineers to analyze outputs, understand failure modes, and develop effective evaluation strategies.</li>
<li>It’s crucial for AI engineers to be able to examine data and draw conclusions about system performance without relying solely on AI tools.</li>
</ul></li>
</ul>
</section>
<section id="promising-opportunities-and-future-challenges" class="level3">
<h3 class="anchored" data-anchor-id="promising-opportunities-and-future-challenges">Promising Opportunities and Future Challenges</h3>
<ul>
<li><strong>Focusing on Unsexy, Expensive, and Slow Tasks</strong>:
<ul>
<li>LLMs offer the potential to automate tasks that are currently time-consuming and costly for humans.</li>
<li><strong>Examples</strong>:
<ul>
<li>Classification.</li>
<li>Information Extraction.</li>
<li>Quiz Generation from Textbooks.</li>
</ul></li>
<li><strong>Focus</strong>: Identify tasks that are currently unsexy but can be effectively delegated to LLMs, leading to cost savings and increased efficiency.</li>
</ul></li>
<li><strong>Developing More Thoughtful UX</strong>:
<ul>
<li>LLMs should not be seen as one-shot wonders with perfect UX.</li>
<li>Graceful failure modes and user-friendly interfaces are essential.</li>
<li><strong>Co-pilot Mentality</strong>: Design systems that allow users to edit and interact with LLM outputs, turning failures into learning opportunities.</li>
</ul></li>
<li><strong>Empowering End Users as Programmers</strong>:
<ul>
<li>AI will not be able to read minds, so empowering users to interact and refine LLM outputs is crucial.</li>
<li><strong>ChatGPT Example</strong>: Users act as programmers by refining their prompts and editing previous messages to achieve their desired outcomes.</li>
<li><strong>Notebook Interfaces</strong>: Offer a flexible workspace for both technical and non-technical users to interact with and programmatically control LLMs.</li>
</ul></li>
</ul>
</section>
<section id="key-insights-from-collaboration" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-from-collaboration">Key Insights from Collaboration</h3>
<ul>
<li><strong>Value of Community and Alignment</strong>:
<ul>
<li>The most valuable aspect of the collaboration was the opportunity to connect with other experts, discuss ideas, and learn from each other’s experiences.</li>
<li>Having a network of trusted peers to consult with and debate challenging questions is essential.</li>
</ul></li>
<li><strong>Surprising Alignment Despite Diverse Perspectives</strong>:
<ul>
<li>The authors, despite working in different parts of the LLM stack (research, infrastructure, product development, etc.), found a remarkable degree of alignment in their key insights.</li>
<li>They had “grabbed different parts of the elephant” but had all come to similar conclusions about the core principles of building with LLMs.</li>
</ul></li>
<li><strong>The Collaborative Process as a “Raid Boss”</strong>:
<ul>
<li>The collaborative effort was akin to battling a raid boss in an MMORPG, requiring a skilled and coordinated team effort.</li>
<li>Charles Frye played a critical role in editing and consolidating the vast amount of material.</li>
<li>Hamel Husain demonstrated high agency by quickly setting up a website for the report.</li>
<li>The collaborative process was enjoyable, inspiring, and ultimately led to a highly impactful resource for the community.</li>
</ul></li>
<li><strong>Impact Beyond Industry</strong>:
<ul>
<li>The report’s impact has extended beyond industry, reaching academics and researchers who traditionally do not engage with industry blogs.</li>
<li>The report’s timing was critical, capturing the widespread interest in LLMs and their potential to transform computing.</li>
</ul></li>
</ul>
</section>
<section id="the-importance-of-data-centric-ai-development" class="level3">
<h3 class="anchored" data-anchor-id="the-importance-of-data-centric-ai-development">The Importance of Data-Centric AI Development</h3>
<ul>
<li><strong>Data Literacy as a Core Skill</strong>:
<ul>
<li>The ability to understand and work with data is essential for success with LLMs.</li>
<li>Traditional software engineering often focuses on the syntactic correctness of code, while data science emphasizes the semantic meaning of data.</li>
<li><strong>Challenge</strong>: Bridging this gap in perspective and helping software engineers develop data literacy skills.</li>
</ul></li>
<li><strong>Developing Intuition for Data Distributions</strong>:
<ul>
<li>Experience with data analysis and visualization leads to an intuitive understanding of data distributions.</li>
<li>This intuition allows for quickly identifying issues in data or model outputs, even without specific theoretical knowledge.</li>
</ul></li>
</ul>
</section>
<section id="building-trust-with-stakeholders-and-users" class="level3">
<h3 class="anchored" data-anchor-id="building-trust-with-stakeholders-and-users">Building Trust with Stakeholders and Users</h3>
<ul>
<li><strong>Collaborative Design</strong>:
<ul>
<li>Involve designers, UX professionals, and domain experts early in the process to understand user needs and build trust.</li>
<li>Co-designing with stakeholders helps identify potential pitfalls and ensure the application aligns with user expectations.</li>
</ul></li>
<li><strong>Slow Rollout and Iterative Feedback</strong>:
<ul>
<li>Slowly roll out LLM applications to small groups of users to gather feedback and identify issues before wider deployment.</li>
<li>Repeated interactions with small groups provide more valuable insights than initial interactions with larger groups.</li>
</ul></li>
<li><strong>User Feedback as the Antidote to Demoitis</strong>:
<ul>
<li>Gathering user feedback through beta programs and interactions at meetups is crucial for moving beyond the hype of demos.</li>
<li>Directly observing user reactions provides valuable insights into usability and helps identify areas for improvement.</li>
</ul></li>
</ul>
</section>
<section id="systems-thinking-vs.-model-focus" class="level3">
<h3 class="anchored" data-anchor-id="systems-thinking-vs.-model-focus">Systems Thinking vs.&nbsp;Model Focus</h3>
<ul>
<li><strong>The Importance of Systems-Level Design</strong>:
<ul>
<li>Building successful LLM applications requires a systems-level perspective, not just a focus on the model itself.</li>
<li><strong>Example</strong>: At Hex, the team started by designing the overall system architecture, including prompt templating, evaluation frameworks, and context construction (RAG).</li>
<li>These architectural decisions have proven durable and have guided the project’s development.</li>
</ul></li>
<li><strong>Key System Design Considerations</strong>:
<ul>
<li><strong>Evals</strong>: Prioritize building robust evaluation frameworks from the outset.</li>
<li><strong>Composability</strong>: Design systems with composability in mind, especially for context construction and prompt generation.</li>
<li><strong>Meta-Programming</strong>: Think of prompt construction as a form of meta-programming, allowing for flexible and adaptable system behavior.</li>
</ul></li>
<li><strong>Leveraging Prior Experience from ML</strong>:
<ul>
<li>Much of the knowledge and best practices from traditional machine learning apply to building LLM systems.</li>
<li><strong>Example</strong>: The principles outlined in the book <em>Machine Learning Design Patterns</em> are directly relevant to LLM application development.</li>
</ul></li>
</ul>
</section>
<section id="final-advice-and-future-directions" class="level3">
<h3 class="anchored" data-anchor-id="final-advice-and-future-directions">Final Advice and Future Directions</h3>
<ul>
<li><strong>Prioritize Evaluation</strong>:
<ul>
<li>Start by creating sample inputs and ideal outputs, then build evaluation methods to measure progress and identify issues.</li>
<li>Focus on creating a gold standard dataset, even if it’s small, to guide evaluation and refinement.</li>
</ul></li>
<li><strong>Read, Build, and Share</strong>:
<ul>
<li><strong>Read</strong>: Engage with high-quality resources and articles that distill key concepts and best practices.</li>
<li><strong>Build</strong>: Get hands-on experience by building demos and experimenting with LLMs to understand their capabilities and limitations.</li>
<li><strong>Share</strong>: Contribute to the community by sharing your experiences, insights, and code to accelerate learning and adoption.</li>
</ul></li>
<li><strong>Focus on Iterative Improvement</strong>:
<ul>
<li>Embrace a process of validated iterative improvement, similar to gradient descent in optimization.</li>
<li>LLMs introduce complexity and uncertainty, but the fundamental principles of building complex systems remain the same: make small, validated steps toward improvement.</li>
<li><strong>Key Elements</strong>: Data, experimentation, operationalization, and rapid deployment to production.</li>
<li>Focus on iterative experimentation and building evaluation frameworks to guide development toward user-centric solutions.
<ul>
<li><strong>Zero-to-One Mentality</strong>: Break down the problem into smaller, manageable chunks and iteratively improve each component.</li>
</ul></li>
</ul></li>
<li><strong>The Future of Knowledge Access</strong>:
<ul>
<li>LLMs have the potential to make knowledge more accessible, personalized, and useful.</li>
<li><strong>Example</strong>: Memory extenders and personal Memex systems.</li>
<li>LLMs will transform how we interact with information, socialize, and carry out our daily lives.</li>
</ul></li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<ul>
<li>The report and this discussion highlight the essential lessons learned from a year of building with LLMs.</li>
<li><strong>Key Takeaways</strong>:
<ul>
<li><strong>Data Literacy</strong>: Prioritize understanding and working with data as a foundational skill.</li>
<li><strong>Evaluation</strong>: Make evaluation a core part of the development process, focusing on human-in-the-loop methods and iterative refinement.</li>
<li><strong>Systems Thinking</strong>: Build end-to-end systems that go beyond model focus, considering aspects like prompt design, context construction, and evaluation frameworks.</li>
<li><strong>Process over Tools</strong>: Focus on developing robust processes and methodologies rather than relying solely on tools.</li>
<li><strong>User-Centricity</strong>: Design applications with user needs in mind, prioritizing trust, feedback, and iterative improvement.</li>
</ul></li>
<li>The future of LLMs is bright, with the potential to transform how we interact with information and build intelligent software.</li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/lessons-from-a-year-of-building-with-llms/</guid>
  <pubDate>Fri, 30 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 20: Back to Basics for RAG</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-020/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Presentation Resources:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Presentation Resources:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Slides:</strong> <a href="https://docs.google.com/presentation/d/19L2j2-fBC_iPGswwER3Cfsy7N3HSqUrVfxh2xvcBU2Y/edit#slide=id.p">Back to basics?</a></li>
</ul>
</div>
</div>
<section id="about-jo-kristian-bergum" class="level3">
<h3 class="anchored" data-anchor-id="about-jo-kristian-bergum">About Jo Kristian Bergum</h3>
<ul>
<li><strong>Distinguished Engineer</strong> at Vespa.ai</li>
<li>18 years at Vespa.ai, 20 years in search and recommendation.</li>
<li><strong><a href="https://vespa.ai/">Vespa.ai</a>:</strong>
<ul>
<li>Serving platform spun out of Yahoo.</li>
<li>Open source since 2017.</li>
<li><strong>Blog:</strong> <a href="https://blog.vespa.ai/">https://blog.vespa.ai/</a></li>
</ul></li>
<li>Active on Twitter (<a href="https://x.com/jobergum"><span class="citation" data-cites="jobergum">@jobergum</span></a>), enjoys posting memes.</li>
</ul>
</section>
<section id="talk-overview" class="level3">
<h3 class="anchored" data-anchor-id="talk-overview">Talk Overview</h3>
<ul>
<li><strong>Stuffing Text into Language Model Prompts:</strong> Using RAG beyond question answering, e.g., for classification by retrieving relevant training examples.</li>
<li><strong>Information Retrieval (The R in RAG):</strong> Exploring the core concepts of retrieval and its importance in RAG pipelines.</li>
<li><strong>Evaluation of IR Systems:</strong>
<ul>
<li>Building your own evaluation systems to measure and improve search performance.</li>
<li>Demonstrating the impact of changes to your CTO.</li>
</ul></li>
<li><strong>Representational Approaches for IR:</strong>
<ul>
<li>Discussing <strong>sparse</strong> and <strong>dense</strong> representations (BM25, vectors, embeddings).</li>
<li>Examining baselines for comparison.</li>
</ul></li>
</ul>
</section>
<section id="demystifying-rag" class="level3">
<h3 class="anchored" data-anchor-id="demystifying-rag">Demystifying RAG</h3>
<ul>
<li><strong>RAG (Retrieval Augmented Generation):</strong> A technique for enhancing language model outputs by retrieving relevant context from external knowledge sources.</li>
<li><strong>Common Use Cases:</strong> Question answering, chatbots, generating grounded responses.
<ul>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Current date is {date}, Don’t be rude. I’ll tip $5. Think step-by-step.</strong></p>
<p>I want you to classify the text input as positive, negative or neutral. Examples:</p>
<p><strong>Input:</strong> I’m very happy today<br>
<strong>Output:</strong> positive</p>
<p><strong>Input:</strong> I’m sad today<br>
<strong>Output:</strong> negative</p>
<p><strong>Input:</strong> I don’t know what to feel today<br>
<strong>Output:</strong> neutral</p>
<p>✨ <strong>{many_retrieved_context_sensitive_examples}</strong> ✨</p>
<p><strong>Input:</strong> {input}<br>
<strong>Output:</strong></p>
</div>
</div></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Current date is {date}, Don’t be rude. I’ll tip $5. Think step-by-step.</strong></p>
<p>I want you to summarize and answer the question using context retrieved by a search engine.<br>
<strong>Context:</strong> [1] BERT: Pre-training of deep bidirectional transformers for language understanding…<br>
<strong>Question:</strong> What is a bidirectional transformer model?<br>
<strong>Helpful answer:</strong> bidirectional means that tokens attend to all other tokens in the input sequence [1].</p>
<p>✨ <strong>{retrieved_context_sensitive_examples}</strong> ✨</p>
<p><strong>Context:</strong> {retrieved_context_question}<br>
<strong>Question:</strong> {question}<br>
<strong>Helpful answer:</strong></p>
</div>
</div></li>
</ul></li>
<li><strong>Basic Architecture:</strong>
<ul>
<li><strong>Orchestration Component:</strong> Manages the flow of data and interactions between components.</li>
<li><strong>Input:</strong> User queries or prompts.</li>
<li><strong>Output:</strong> Generated responses.</li>
<li><strong>Evaluation:</strong> Measures the quality of the output.</li>
<li><strong>Prompting:</strong> Techniques for interacting with language models.</li>
<li><strong>Language Models:</strong> The core component for generating text.</li>
<li><strong>State:</strong> Data storage, including files, search engines, vector databases, and databases.</li>
</ul></li>
</ul>
</section>
<section id="cutting-through-the-hype" class="level3">
<h3 class="anchored" data-anchor-id="cutting-through-the-hype">Cutting Through the Hype</h3>
<ul>
<li><strong>Challenges in the RAG Landscape:</strong>
<ul>
<li>Constant stream of new models, components, and tricks.</li>
<li>Oversimplification of RAG as just vector embeddings and language models.</li>
<li>Lack of focus on evaluating performance on specific data.</li>
</ul></li>
<li><strong>Importance of Information Retrieval:</strong>
<ul>
<li>Retrieval is a deep and well-studied field, crucial for many applications.</li>
<li>It’s more complex than simply encoding text into a single vector representation.</li>
<li>Building effective RAG solutions requires understanding and leveraging existing retrieval techniques.</li>
</ul></li>
</ul>
</section>
<section id="evaluating-information-retrieval-systems" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-information-retrieval-systems">Evaluating Information Retrieval Systems</h3>
<ul>
<li><strong>Information Retrieval System as a Black Box:</strong>
<ul>
<li>Input: Query</li>
<li>Output: Ranked list of documents</li>
</ul></li>
<li><strong>Evaluation Based on Relevance:</strong>
<ul>
<li>Human annotators judge the relevance of retrieved documents to the query.</li>
<li><strong>Binary Judgment:</strong> Relevant or not relevant.</li>
<li><strong>Graded Judgment:</strong> Levels of relevance (e.g., 0 - irrelevant, 1 - slightly relevant, 2 - highly relevant).</li>
</ul></li>
<li><strong>Established IR Research and Benchmarks:</strong>
<ul>
<li><strong><a href="https://trec.nist.gov/">TREC (Text Retrieval Conference)</a>:</strong> Evaluates various retrieval tasks, including news retrieval.</li>
<li><strong><a href="https://microsoft.github.io/msmarco/">MS MARCO</a>:</strong> Large-scale dataset from Bing with real-world annotated data used for training embedding models.
<ul>
<li><strong>HuggingFace Hub:</strong> <a href="https://huggingface.co/datasets/microsoft/ms_marco">microsoft/ms_marco</a></li>
</ul></li>
<li><strong><a href="https://github.com/beir-cellar/beir">BEIR</a>:</strong> Evaluates models in a zero-shot setting without training data.</li>
</ul></li>
<li><strong>Common IR Metrics:</strong>
<ul>
<li><strong>Recall@K:</strong> Measures the proportion of relevant documents retrieved within the top K positions.</li>
<li><strong>Precision@K:</strong> Measures the proportion of relevant documents among the top K retrieved documents.</li>
<li><strong>nDCG (Normalized Discounted Cumulative Gain):</strong> Rank-aware metric that considers graded relevance judgments.</li>
<li><strong>Reciprocal Rank:</strong> Measures the position of the first relevant hit.</li>
<li><strong>LGTM (Looks Good To Me):</strong> Informal but common metric in industry.</li>
</ul></li>
<li><strong>Production System Metrics:</strong> Engagement (clicks, dwell time), add-to-cart rate, revenue.</li>
<li><strong>Benchmark Limitations:</strong>
<ul>
<li>Often compare flat lists, not personalized results.</li>
<li>Don’t always transfer well to specific domains or use cases.</li>
</ul></li>
</ul>
</section>
<section id="building-your-own-relevancy-dataset" class="level3">
<h3 class="anchored" data-anchor-id="building-your-own-relevancy-dataset">Building Your Own Relevancy Dataset</h3>
<ul>
<li><p><strong>The Importance of Measuring:</strong> To improve RAG performance, measure relevance on your specific data.</p></li>
<li><p><strong>Creating a Relevancy Dataset:</strong></p>
<ul>
<li><strong>Leverage Existing Traffic:</strong> Log user searches and judge the relevance of results.</li>
<li><strong>Bootstrap with Language Models:</strong> Use LLMs to generate questions based on your content and judge the relevance of retrieved passages.</li>
</ul></li>
<li><p><strong>Dataset Format:</strong></p>
<ul>
<li><p>Simple TSV file is sufficient.</p></li>
<li><p><strong>Query ID, Document ID, Relevance Label</strong></p>
<ul>
<li><table class="caption-top table">
<thead>
<tr class="header">
<th>qid</th>
<th>docid</th>
<th>relevance label</th>
<th>comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>3 (how to ..)</td>
<td>4</td>
<td>2</td>
<td></td>
</tr>
<tr class="even">
<td>3 (where ..)</td>
<td>2</td>
<td>0</td>
<td></td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul></li>
<li><p><strong>Static vs.&nbsp;Dynamic Collections:</strong></p>
<ul>
<li>Static collections are preferred for consistent evaluation.</li>
<li>Dynamic collections can introduce noise when evaluating metrics.</li>
</ul></li>
<li><p><strong>Using Language Models for Relevance Judgments:</strong></p>
<ul>
<li><p><strong>Paper:</strong> <a href="https://arxiv.org/abs/2309.10621">Large language models can accurately predict searcher preferences</a></p></li>
<li><p>LLMs can be prompted to assess the relevance of queries and passages.</p></li>
<li><p>Find a prompt that correlates well with your golden dataset.</p></li>
<li><p>Enables cheaper and larger-scale evaluation.</p></li>
<li><p><strong>Example:</strong> Microsoft research demonstrating LLM effectiveness in judging relevance.</p>
<ul>
<li><p><strong>Paper:</strong> <a href="https://arxiv.org/abs/2406.06519">UMBRELA: UMbrela is the (Open-Source Reproduction of the) Bing RELevance Assessor</a></p></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Figure 1: Prompt used for relevance assessment.">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Figure 1: Prompt used for relevance assessment.
</div>
</div>
<div class="callout-body-container callout-body">
<pre class="text"><code>Given a query and a passage, you must provide a score on an
integer scale of 0 to 3 with the following meanings:
0 = represent that the passage has nothing to do with the query,
1 = represents that the passage seems related to the query but
does not answer it,
2 = represents that the passage has some answer for the query,
but the answer may be a bit unclear, or hidden amongst extraneous
information and
3 = represents that the passage is dedicated to the query and
contains the exact answer.

Important Instruction: Assign category 1 if the passage is
somewhat related to the topic but not completely, category 2 if
passage presents something very important related to the entire
topic but also has some extra information and category 3 if the
passage only and entirely refers to the topic. If none of the
above satisfies give it category 0.

Query: {query}
Passage: {passage}

Split this problem into steps:
Consider the underlying intent of the search.
Measure how well the content matches a likely intent of the query
(M).
Measure how trustworthy the passage is (T).
Consider the aspects above and the relative importance of each,
and decide on a final score (O). Final score must be an integer
value only.
Do not provide any code in result. Provide each score in the
format of: ##final score: score without providing any reasoning.</code></pre>
</div>
</div></li>
</ul></li>
</ul></li>
<li><p><strong>Benefits of Custom Relevancy Datasets:</strong></p>
<ul>
<li>Iterate and measure the impact of changes to your retrieval system.</li>
<li>Track improvements in metrics like nDCG.</li>
<li><strong>Example:</strong> Vespa documentation search showing improvement in nDCG with hybrid retrieval methods.</li>
</ul></li>
</ul>
</section>
<section id="representational-approaches-and-scoring-functions" class="level3">
<h3 class="anchored" data-anchor-id="representational-approaches-and-scoring-functions">Representational Approaches and Scoring Functions</h3>
<ul>
<li><strong>Motivation for Efficient Retrieval:</strong> Avoid scoring all documents in the collection for each query.</li>
<li><strong>Sparse Representations:</strong>
<ul>
<li><strong>Term-based:</strong> Documents and queries are represented by the presence and weight of terms.</li>
<li><strong>Efficient Retrieval:</strong> Inverted indexes, algorithms like WAND and MaxScore.</li>
<li><strong>Example:</strong> Keyword search technologies like Elasticsearch and Vespa.</li>
</ul></li>
<li><strong>Dense Representations:</strong>
<ul>
<li><strong>Embedding-based:</strong> Documents and queries are represented by vectors in a latent space.</li>
<li><strong>Neural/Sparse Embedding Models:</strong> Learn term weights using transformer models.</li>
<li><strong>Efficient Retrieval:</strong> Approximate Nearest Neighbor search, vector databases.</li>
<li><strong>Example:</strong> Text embedding models, semantic search.</li>
</ul></li>
<li><strong>Advantages of Dense Representations:</strong>
<ul>
<li>Capture semantic relationships between words and concepts.</li>
<li>Enable search based on meaning rather than exact keyword matches.</li>
</ul></li>
<li><strong>Challenges of Dense Representations:</strong>
<ul>
<li><strong>Transfer Learning:</strong> Off-the-shelf models may not perform well on specific data.</li>
<li><strong>Diluted Representations:</strong> Averaging token embeddings into a single vector can lose information.</li>
<li><strong>Fixed Vocabulary:</strong> Out-of-vocabulary words can be mapped to incorrect concepts.</li>
<li><strong>Chunking:</strong> Long documents need to be chunked to maintain precision.</li>
</ul></li>
<li><strong>Baselines for Comparison:</strong>
<ul>
<li><strong>BM25:</strong>
<ul>
<li><strong>Term-based scoring function.</strong></li>
<li><strong>Unsupervised, based on corpus statistics.</strong></li>
<li><strong>Cheap, small index footprint.</strong></li>
<li><strong>Strong baseline for many tasks.</strong></li>
<li><strong>Limitations:</strong> Requires language-specific tokenization, struggles with long context.</li>
</ul></li>
<li><strong>Example:</strong> BM25 outperforming embedding models on long context documents in ColBERT evaluation.
<ul>
<li><strong>Blog Post:</strong> <a href="https://blog.vespa.ai/announcing-long-context-ColBERT-in-vespa/">Announcing Vespa Long-Context ColBERT</a></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="hybrid-approaches" class="level3">
<h3 class="anchored" data-anchor-id="hybrid-approaches">Hybrid Approaches</h3>
<ul>
<li><strong>Combining Sparse and Dense Representations:</strong>
<ul>
<li>Can overcome limitations of individual approaches.</li>
<li>Example: Combining keyword search with embedding retrieval.</li>
</ul></li>
<li><strong>Challenges of Hybrid Approaches:</strong>
<ul>
<li>Calibration of different scoring functions.</li>
<li>Determining when to ignore embedding results.</li>
<li>Requires careful tuning and evaluation.</li>
</ul></li>
</ul>
</section>
<section id="long-context-and-chunking" class="level3">
<h3 class="anchored" data-anchor-id="long-context-and-chunking">Long Context and Chunking</h3>
<ul>
<li><strong>Desire for Long Context Models:</strong> Eliminate the need for chunking.</li>
<li><strong>Reality of Chunking:</strong>
<ul>
<li>Necessary for meaningful representations in high-precision search.
<ul>
<li>Dense representation beyond 256 tokens are bad for high-precision search.</li>
</ul></li>
<li><strong>Pooling operations dilute representations in long contexts.</strong></li>
<li><strong>Limited training data for long context models.</strong></li>
</ul></li>
<li><strong>Chunking Strategies:</strong>
<ul>
<li>Split long documents into smaller segments.</li>
<li>Index multiple vectors per row in a database.</li>
</ul></li>
</ul>
</section>
<section id="real-world-rag-considerations" class="level3">
<h3 class="anchored" data-anchor-id="real-world-rag-considerations">Real-World RAG Considerations</h3>
<ul>
<li><strong>Google Search Signals:</strong>
<ul>
<li><strong>Text Similarity:</strong> BM25, vector cosine similarity.</li>
<li><strong>Freshness:</strong> Recency of content.</li>
<li><strong>Authority:</strong> Trustworthiness of the source.</li>
<li><strong>Quality:</strong> Overall content quality.</li>
<li><strong>PageRank:</strong> Link analysis algorithm.</li>
<li><strong>Revenue:</strong> In advertising-based search.</li>
</ul></li>
<li><strong>GBDT (Gradient Boosted Decision Trees):</strong>
<ul>
<li>Effective for combining tabular features.</li>
<li>Still relevant for real-world search.</li>
</ul></li>
</ul>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<ul>
<li><strong>Information retrieval is more than just vector representations.</strong></li>
<li><strong>Build your own evaluations to improve retrieval.</strong></li>
<li><strong>Don’t ignore the BM25 baseline.</strong></li>
<li><strong>Choose technologies with hybrid capabilities.</strong></li>
<li><strong>Real-world search involves more than just text similarity.</strong></li>
</ul>
</section>
<section id="qa-session" class="level3">
<h3 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h3>
<section id="q1-metadata-for-vector-db-in-rag" class="level4">
<h4 class="anchored" data-anchor-id="q1-metadata-for-vector-db-in-rag">Q1: Metadata for Vector DB in RAG</h4>
<ul>
<li><strong>Question:</strong> What kind of metadata is most valuable to put into a vector DB for doing RAG?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Context-Dependent:</strong> The most valuable metadata depends on the specific use case and domain.</li>
<li><strong>Text-Only Use Cases:</strong>
<ul>
<li><strong>Authority/Source Filtering:</strong> Important in domains like healthcare where trustworthiness of sources is crucial (e.g., filter out Reddit posts in favor of medical journals).</li>
<li><strong>Title and other basic metadata:</strong> Can provide additional context for retrieval.</li>
</ul></li>
<li><strong>Real-World Use Cases:</strong>
<ul>
<li>Consider factors beyond text, such as freshness, authority, quality, and even revenue.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="q2-calibration-of-different-indices" class="level4">
<h4 class="anchored" data-anchor-id="q2-calibration-of-different-indices">Q2: Calibration of Different Indices</h4>
<ul>
<li><strong>Question:</strong> Do you have any thoughts on calibration of different indices? How can we obtain confidence scores for recommendations?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Challenge:</strong> Different scoring functions (e.g., BM25, cosine similarity) have different distributions and ranges, making calibration difficult. Scores are not probabilities.</li>
<li><strong>Learning Task:</strong> Combining scores effectively is a learning problem.</li>
<li><strong>GBDT’s Strength:</strong> Gradient Boosted Decision Trees (GBDT) can learn non-linear combinations of features, including different scoring functions.</li>
<li><strong>Need for Training Data:</strong> Calibration and learning require training data.</li>
<li><strong>Options for Training Data:</strong>
<ul>
<li><strong>Evaluation Data:</strong> The evaluation datasets described earlier can be used to generate training data.</li>
<li><strong>Real User Interactions:</strong> Gather data from user searches and clicks (like Google).</li>
<li><strong>Synthetic Data:</strong> Use large language models to generate synthetic training data.</li>
</ul></li>
<li><strong>No Easy Tricks:</strong> There’s no universal solution for calibration without training data and evaluation.</li>
</ul></li>
</ul>
</section>
<section id="q3-efficacy-of-re-rankers" class="level4">
<h4 class="anchored" data-anchor-id="q3-efficacy-of-re-rankers">Q3: Efficacy of Re-rankers</h4>
<ul>
<li><strong>Question:</strong> What are your observations on the efficacy of re-rankers? Do you recommend using them?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Phased Retrieval and Ranking:</strong> Re-rankers are valuable in multi-stage pipelines. They allow you to invest more compute into fewer, more promising hits retrieved in earlier stages.</li>
<li><strong>Benefits of Re-rankers:</strong>
<ul>
<li><strong>Token-Level Interaction:</strong> Re-rankers like Cohere or cross-encoders enable deeper interaction between the query and document at the token level, improving accuracy.</li>
<li><strong>Latency Management:</strong> By focusing on a smaller set of candidates, re-rankers can help meet latency requirements.</li>
</ul></li>
<li><strong>Trade-offs:</strong> Re-rankers add computational cost and latency.</li>
<li><strong>Recommendation:</strong> If accuracy is a priority and the cost is acceptable, re-rankers are recommended.</li>
</ul></li>
</ul>
</section>
<section id="q4-combining-usage-data-and-semantic-similarity" class="level4">
<h4 class="anchored" data-anchor-id="q4-combining-usage-data-and-semantic-similarity">Q4: Combining Usage Data and Semantic Similarity</h4>
<ul>
<li><strong>Question:</strong> Do you have advice on combining usage data (e.g., number of views) with semantic similarity?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Learning to Rank Problem:</strong> Integrating usage data turns it into a learning to rank problem.</li>
<li><strong>Label Generation:</strong> Convert interaction data into labeled training data. Different interactions (e.g., views, clicks, add-to-cart) may have different weights in the label generation process.</li>
<li><strong>Model Training:</strong> Train a ranking model (e.g., GBDT) using the labeled data, including semantic similarity scores and usage data as features.</li>
</ul></li>
</ul>
</section>
<section id="q5-jason-lius-post-on-structured-summaries" class="level4">
<h4 class="anchored" data-anchor-id="q5-jason-lius-post-on-structured-summaries">Q5: Jason Liu’s Post on Structured Summaries</h4>
<ul>
<li><strong>Question:</strong> What are your thoughts on Jason Liu’s post about the value of generating structured summaries and reports for decision makers instead of doing RAG as commonly done today?</li>
<li><strong>Answer:</strong> Jo was not familiar with the specific post.</li>
</ul>
</section>
<section id="q6-recent-advancements-in-text-embedding-models" class="level4">
<h4 class="anchored" data-anchor-id="q6-recent-advancements-in-text-embedding-models">Q6: Recent Advancements in Text Embedding Models</h4>
<ul>
<li><strong>Question:</strong> What are some of your favorite advancements recently in text embedding models or other search technologies?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Larger Vocabularies:</strong> Jo hopes for embedding models with larger vocabularies to better handle out-of-vocabulary words, especially in specialized domains. BERT’s vocabulary is outdated.</li>
<li><strong>Improved Pre-trained Models:</strong> Better pre-training techniques and data can lead to more robust and generalizable embedding models.</li>
<li><strong>Caution on Long Context:</strong> Jo is not overly enthusiastic about increasing context length for embedding models. Research suggests diminishing returns for high-precision search with very long contexts.</li>
</ul></li>
</ul>
</section>
<section id="q7-query-expansion-with-bm25" class="level4">
<h4 class="anchored" data-anchor-id="q7-query-expansion-with-bm25">Q7: Query Expansion with BM25</h4>
<ul>
<li><strong>Question:</strong> Does query expansion of out-of-vocabulary words with BM25 work better at search? Are people utilizing classical search techniques like query expansion enough?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>BM25 and Re-ranking:</strong> Combining BM25 with a re-ranker can yield excellent results. While BM25 may struggle with single-word queries that are out-of-vocabulary, it avoids the severe failure modes of relying solely on embedding-based search.</li>
<li><strong>Query Expansion’s Potential:</strong> Query expansion and understanding are powerful techniques. Language models can be used for query expansion, and tools for prompting LLMs for this purpose are improving.</li>
<li><strong>Importance of Evaluation:</strong> Building your own evaluation setup allows you to systematically test different techniques like query expansion on your specific data and determine their effectiveness.</li>
</ul></li>
</ul>
</section>
<section id="q8-handling-jargon-and-tokenization-issues" class="level4">
<h4 class="anchored" data-anchor-id="q8-handling-jargon-and-tokenization-issues">Q8: Handling Jargon and Tokenization Issues</h4>
<ul>
<li><strong>Question:</strong> How do you overcome limitations in fixed vocabulary and poor tokenization in domains with a lot of jargon, when using an out-of-the-box model?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Hybrid Approach:</strong> Combine keyword search with embedding retrieval to mitigate vocabulary limitations.</li>
<li><strong>Challenge of Ignoring Embedding Results:</strong> Embedding retrieval always returns results, even if they are not semantically relevant. It’s crucial to identify and filter out these irrelevant results.</li>
<li><strong>Fine-tuning:</strong> Fine-tuning your own embedding model on domain-specific data can help, but vocabulary limitations may persist.</li>
<li><strong>Pre-training from Scratch:</strong> Training a BERT-like model from scratch with a custom vocabulary tailored to the domain is becoming more feasible.
<ul>
<li>This is a common practice in e-commerce.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="q9-colbert-and-tokenizer-problems" class="level4">
<h4 class="anchored" data-anchor-id="q9-colbert-and-tokenizer-problems">Q9: ColBERT and Tokenizer Problems</h4>
<ul>
<li><strong>Question:</strong> Would ColBERT-based methods improve retrieval when we are concerned with tokenizer problems?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>ColBERT’s Approach:</strong> ColBERT learns token-level vector representations instead of a single vector for the whole passage or query. It offers high accuracy while being computationally less expensive than cross-encoders.</li>
<li><strong>Vocabulary Limitations:</strong> ColBERT still relies on the same vocabulary as other BERT-based models, so it’s not a complete solution to tokenizer problems.</li>
<li><strong>Future Direction:</strong> Better pre-trained models with larger vocabularies would benefit ColBERT and other embedding models.</li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-020/</guid>
  <pubDate>Fri, 30 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 19: Fine Tuning LLMs for Function Calling</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-019/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<ul>
<li><strong>Pawell</strong>, from <strong><a href="https://fireworks.ai/">Fireworks AI</a></strong>, discusses fine-tuning LLMs for function calling, covering key decisions, challenges, and solutions.</li>
<li><strong>Documentation:</strong> <a href="https://docs.fireworks.ai/guides/function-calling">Using function-calling</a></li>
<li><strong>Documentation:</strong> <a href="https://docs.fireworks.ai/fine-tuning/fine-tuning-models">Fine-tuning models</a></li>
<li><strong>Documentation:</strong> <a href="https://docs.fireworks.ai/structured-responses/structured-output-grammar-based">Using grammar mode</a></li>
</ul>
</section>
<section id="understanding-functiontool-calling" class="level3">
<h3 class="anchored" data-anchor-id="understanding-functiontool-calling">Understanding Function/Tool Calling</h3>
<ul>
<li><strong>Definition:</strong> Giving LLMs the ability to interact with the external world.</li>
<li><strong>Use Cases:</strong>
<ul>
<li><strong>Accessing real-time or unavailable information:</strong> E.g., retrieving current stock prices.</li>
<li><strong>Orchestrating multi-agent systems:</strong> LLMs can access and utilize multiple tools to assist users.</li>
</ul></li>
</ul>
</section>
<section id="key-decisions-in-fine-tuning-for-function-calling" class="level3">
<h3 class="anchored" data-anchor-id="key-decisions-in-fine-tuning-for-function-calling">Key Decisions in Fine-Tuning for Function Calling</h3>
<section id="objective-selection" class="level4">
<h4 class="anchored" data-anchor-id="objective-selection">1. Objective Selection:</h4>
<ul>
<li><strong>Impact:</strong> The objective significantly impacts data preparation, training data volume, fine-tuning complexity, and model usage.</li>
<li><strong>Recommendation:</strong> Choose the simplest objective that meets the use case requirements.</li>
<li><strong>Common Objectives:</strong>
<ul>
<li><strong>Single-Turn Forced Call (Routing Use Case):</strong>
<ul>
<li>User provides a single instruction.</li>
<li>Model maps the instruction to one of several pre-defined functions and its parameters.</li>
<li><strong>Forced Call:</strong> The model is constrained to respond with a function call, not natural language.</li>
<li><strong>Example:</strong> User requests the current stock price of Nvidia, the model identifies the appropriate function and its parameters.
<ul>
<li><pre class="text"><code>User: What is the stock price of Nvidia?

Assistant: {
  "name": "get_stock_price",
  "arguments": {"ticker": "NVDA"}
}</code></pre></li>
</ul></li>
</ul></li>
<li><strong>Parallel Function Calling:</strong>
<ul>
<li>Similar to single-turn forced call, but the model can call multiple independent functions in parallel.</li>
<li><strong>Example:</strong> Retrieving stock prices for multiple companies simultaneously.
<ul>
<li><pre class="text"><code>User: What is the stock price of Nvidia and Apple?

Assistant: [
  {
    "name": "get_stock_price",
    "arguments": {"ticker": "NVDA"}
  },
  {
    "name": "get_stock_price",
    "arguments": {"ticker": "AAPL"}
  }
]</code></pre></li>
</ul></li>
</ul></li>
<li><strong>Nested Function Calls:</strong>
<ul>
<li>Model calls functions sequentially, with the output of one function feeding into the next.</li>
<li><strong>Example:</strong> Retrieving stock prices and then using those prices to generate a plot.
<ul>
<li><pre class="text"><code>User: Plot the stock price of Nvidia and Apple over the last two weeks

Assistant: [
  {
    "name": "get_stock_price",
    "arguments": {"ticker": "NVDA", "start_time": "2 weeks ago"}
  },
  {
    "name": "get_stock_price",
    "arguments": {"ticker": "AAPL", "start_time": "2 weeks ago"}
  }
]

Tool: {"NVDA": [120, 121, …],"AAPL": [192, 190, …]}

Assistant: {
  "name": "plot",
  "arguments": {"NVDA": [120, 121, …],"AAPL": [192, 190, …]}
}</code></pre></li>
</ul></li>
<li><strong>Implementation:</strong>
<ul>
<li><strong>User Role:</strong> Client interacting with the model.</li>
<li><strong>Assistant Role:</strong> The LLM generating function calls.</li>
<li><strong>Tool Role:</strong> Client-side component that executes function calls and returns results to the model.</li>
</ul></li>
</ul></li>
<li><strong>Multi-Turn Chat with Optional Function Calling:</strong>
<ul>
<li>Most complex objective, combining natural language conversation with optional function calls.</li>
<li><strong>Example:</strong> User asks for news, model fetches trending news, summarizes them, and engages in further conversation.
<ul>
<li><pre class="text"><code>User: What's in the news today?

Assistant: {"name": "trending_news"}

Tool: {
  "headlines": [
    "Nvidia market cap surpasses Apple", …
  ]
}

Assistant: Nvidia is now more valuable than Apple

User: What is Nvidia stock price?

Assistant: {
  "name": "get_stock_price",
  "arguments": {"ticker": "NVDA"}
}</code></pre></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="function-call-token" class="level4">
<h4 class="anchored" data-anchor-id="function-call-token">2. Function Call Token:</h4>
<ul>
<li><strong>Purpose:</strong>
<ul>
<li>Indicate to the client when the model is switching to function call mode.</li>
<li>Enable efficient parsing of model responses, especially in mixed natural language and function call outputs.</li>
</ul></li>
<li><strong>Implementation:</strong> Introduce a special token to prefix function calls.
<ul>
<li><pre class="text"><code>  Assistant: &lt;function_call_token&gt;{
    "name": "get_stock_price",
    "arguments": {"ticker": "NVDA"}
  }</code></pre></li>
</ul></li>
<li><strong>Benefits:</strong>
<ul>
<li>Easier parsing of model responses.</li>
<li>Improved <strong>streaming generation</strong> by enabling the client to wait for the entire function call signature before processing.</li>
<li>Facilitates <strong>constraint generation</strong>, ensuring the model adheres to predefined function schemas.</li>
</ul></li>
</ul>
</section>
<section id="syntax-for-function-calling" class="level4">
<h4 class="anchored" data-anchor-id="syntax-for-function-calling">3. Syntax for Function Calling:</h4>
<ul>
<li><strong>Options:</strong>
<ul>
<li><strong>Python Syntax:</strong> Generate function calls using Python function call signature syntax.</li>
<li><strong>JSON Schema:</strong> Generate JSON structures describing the function name and parameters.</li>
</ul></li>
<li><strong>Trade-offs:</strong>
<ul>
<li><strong>Python Syntax:</strong>
<ul>
<li><strong>Advantages:</strong> Easier for LLMs to generate due to extensive training on Python code.</li>
<li><strong>Disadvantages:</strong> Less natural for representing complex, nested parameter structures within a single-line invocation.</li>
</ul></li>
<li><strong>JSON Schema:</strong>
<ul>
<li><strong>Advantages:</strong> Better suited for complex, nested parameter types; easier to enforce schema with constraint generation; compatible with OpenAI APIs.</li>
<li><strong>Disadvantages:</strong> Potentially more challenging for LLMs to generate compared to Python syntax.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="preserving-existing-model-capabilities" class="level4">
<h4 class="anchored" data-anchor-id="preserving-existing-model-capabilities">4. Preserving Existing Model Capabilities:</h4>
<ul>
<li><strong>Challenge:</strong> Fine-tuning for function calling can inadvertently degrade pre-existing instruction following and general language capabilities.</li>
<li><strong>Recommendations:</strong>
<ul>
<li><strong>Fine-tune on Instruction-Tuned Models:</strong> Use the “Instruct” version of the base model instead of the “Base” version when mixing general chat with function calling.
<ul>
<li>Using the “Base” version is fine for forced function calling.</li>
</ul></li>
<li><strong>Reduce Training Data:</strong> Minimize the amount of training data to reduce the risk of overwriting existing capabilities.</li>
<li><strong>High-Quality Data:</strong> Use a smaller volume of carefully curated, high-quality training data.</li>
</ul></li>
</ul>
</section>
<section id="full-weight-tuning-vs.-lora-tuning" class="level4">
<h4 class="anchored" data-anchor-id="full-weight-tuning-vs.-lora-tuning">5. Full-Weight Tuning vs.&nbsp;LoRA Tuning:</h4>
<ul>
<li><strong>Recommendation:</strong> LoRA tuning is generally sufficient and preferable for function calling, particularly in low-data regimes.</li>
<li><strong>Advantages of LoRA:</strong>
<ul>
<li>Fewer parameters to converge, leading to faster training and better results with limited data.</li>
<li>Faster iteration cycles, enabling more experimentation.</li>
<li>Lower hosting and experimentation costs, especially with efficient LoRA serving solutions like Fireworks AI’s platform.</li>
</ul></li>
</ul>
</section>
<section id="constraint-generation" class="level4">
<h4 class="anchored" data-anchor-id="constraint-generation">6. Constraint Generation:</h4>
<ul>
<li><strong>Purpose:</strong> Reduce hallucinations in model-generated function calls by leveraging the known schema of available functions.</li>
<li><strong>Implementation:</strong>
<ul>
<li>Provide the model with the schema of the functions (e.g., function name, parameter names and types).</li>
<li>Use a constraint generation mechanism (like a <a href="https://web.stanford.edu/class/archive/cs/cs103/cs103.1164/lectures/18/Small18.pdf">context-free grammar</a>) to guide the model’s output and enforce adherence to the schema.</li>
</ul></li>
<li><strong>Benefits:</strong>
<ul>
<li><strong>Reduced Hallucinations:</strong> Significantly minimizes or even eliminates hallucinations in function call outputs.</li>
<li><strong>Faster Generation:</strong> Enables short-circuiting generation by autocompleting predictable tokens based on the grammar, improving inference speed.</li>
</ul></li>
<li><strong>Fireworks AI:</strong> Offers constraint generation support for function calling, requiring users to provide the function schemas.</li>
</ul>
</section>
</section>
<section id="general-recommendations-and-considerations" class="level3">
<h3 class="anchored" data-anchor-id="general-recommendations-and-considerations">General Recommendations and Considerations</h3>
<ul>
<li><strong>Work Smart:</strong> Utilize existing open-source function-calling models whenever possible, as they are often sufficient for many use cases.</li>
<li><strong>Fine-Tuning Effort:</strong> Be prepared for an iterative and potentially time-consuming process when fine-tuning for complex function-calling objectives.</li>
</ul>
</section>
<section id="fireworks-ais-fire-function-models" class="level3">
<h3 class="anchored" data-anchor-id="fireworks-ais-fire-function-models">Fireworks AI’s Fire Function Models</h3>
<ul>
<li><p><strong>Playground:</strong> <a href="https://fireworks.ai/models/fireworks/firefunction-v2">Firefunction V2</a></p></li>
<li><p><strong>Blog Post:</strong> <a href="https://fireworks.ai/blog/firefunction-v2-launch-post">Firefunction-v2: Function calling capability on par with GPT4o at 2.5x the speed and 10% of the cost</a></p></li>
<li><p><strong>Fire Function V2:</strong></p>
<ul>
<li>Based on LLaMa 3 70B (Instruct variant).</li>
<li>Outperforms GPT-4 on the Gorilla benchmark.</li>
<li>Designed to approximate GPT-4’s conversational capabilities mixed with function calling.</li>
<li>Addresses limitations of existing datasets by leveraging:
<ul>
<li>Naturally occurring function-calling conversations.</li>
<li>Open-source multi-agent system data (e.g., AutoGPT).</li>
<li>Synthetic datasets with complex instructions and system prompts.</li>
</ul></li>
</ul></li>
<li><p><strong>Benchmark Comparison:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>Firefunction v2</th>
<th>Gpt-4o</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gorilla simple</td>
<td><strong>0.94</strong></td>
<td>0.88</td>
</tr>
<tr class="even">
<td>Gorilla multiple_function</td>
<td>0.91</td>
<td>0.91</td>
</tr>
<tr class="odd">
<td>Gorilla parallel_function</td>
<td>0.89</td>
<td>0.89</td>
</tr>
<tr class="even">
<td>Gorilla parallel_multiple_function</td>
<td>0.79</td>
<td>0.72</td>
</tr>
<tr class="odd">
<td>Nexus parallel</td>
<td>0.53</td>
<td>0.47</td>
</tr>
<tr class="even">
<td>Mtbench</td>
<td>0.84</td>
<td><strong>0.93</strong></td>
</tr>
</tbody>
</table></li>
</ul>
</section>
<section id="challenges-in-fine-tuning-for-function-calling" class="level3">
<h3 class="anchored" data-anchor-id="challenges-in-fine-tuning-for-function-calling">Challenges in Fine-tuning for Function Calling</h3>
<ul>
<li><strong>Data Scarcity:</strong> Unlike general language modeling, readily available datasets for function calling are limited.
<ul>
<li>Existing datasets often focus on specific use cases (e.g., GPT-4 conversations or a limited number of functions).</li>
<li><strong>Solution:</strong> Invest in building custom datasets.</li>
</ul></li>
<li><strong>Data Set Design:</strong>
<ul>
<li><strong>Define Data Categories:</strong> Consider types of function calls (parallel, nested), number of turns, and number of functions supported.
<ul>
<li><strong>Parallel function calling:</strong> Multiple functions are called simultaneously.</li>
<li><strong>Nested function calling:</strong> Functions are called within other functions.</li>
<li><strong>Turn-based conversations:</strong> Single-turn or multi-turn interactions (e.g., exceeding 10 turns).</li>
<li><strong>Number of functions supported:</strong> Fine-tuning for a small set of functions (e.g., 5) is different from tuning for a larger set (e.g., 50).</li>
</ul></li>
<li><strong>Objective Alignment:</strong> Ensure the dataset represents the model’s intended use cases and boundary conditions.</li>
<li><strong>Leverage Existing Resources:</strong> Explore open-source datasets (e.g., Glaive) and multi-agent systems (e.g., Autogen) for inspiration and data.
<ul>
<li><a href="https://github.com/microsoft/autogen"><strong>Autogen</strong></a>, a multi-agent system, can be a good data source, especially for scenarios with multiple agents and complex prompts.</li>
</ul></li>
</ul></li>
<li><strong>Complex System Prompts:</strong> Real-world applications often require intricate instructions for function selection, which are difficult to find in existing datasets.
<ul>
<li><strong>Solution:</strong> Invest in generating synthetic datasets with complex instructions.</li>
</ul></li>
<li><strong>Security Concerns:</strong> Allowing arbitrary function calls raises security risks, especially with functions that modify data.
<ul>
<li><strong>Mitigation:</strong>
<ul>
<li>Focus on read-only functions.</li>
<li>Include precise instructions in system prompts.</li>
</ul></li>
<li><strong>Ongoing Research:</strong> This area requires further exploration as function calling and multi-agent systems become more prevalent.</li>
</ul></li>
</ul>
</section>
<section id="prompt-templates-for-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="prompt-templates-for-fine-tuning">Prompt Templates for Fine-tuning</h3>
<ul>
<li><strong>System prompts</strong> provide context and instructions to the model.</li>
<li><strong>General Guidelines:</strong>
<ul>
<li><strong>Preserve Instruct Model Capabilities:</strong> When fine-tuning on top of existing instruct models, maintain the prompt format to retain existing capabilities.</li>
<li><strong>Clear Role Prefixes:</strong> Use distinct prefixes for different roles (e.g., system, user, assistant, tool) in multi-turn conversations.</li>
</ul></li>
<li><strong>Message Format:</strong>
<ul>
<li><strong>Parsability:</strong> Ensure the format allows easy parsing of function calls by the client.</li>
<li><strong>Mixed Output Handling:</strong> Use special tokens to delineate between natural language and function call sections in assistant responses.</li>
</ul></li>
</ul>
</section>
<section id="successful-fine-tuning-examples" class="level3">
<h3 class="anchored" data-anchor-id="successful-fine-tuning-examples">Successful Fine-tuning Examples</h3>
<ul>
<li><strong>GPT-4 Limitations:</strong> Fine-tuning can overcome limitations in existing models, such as character limits in function descriptions.</li>
<li><strong>Complex Instructions:</strong> Fine-tuning is particularly effective for scenarios with complex instructions on when to call specific functions, even with relatively simple functions.</li>
</ul>
</section>
<section id="function-calling-data-sets-and-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="function-calling-data-sets-and-evaluation">Function Calling Data Sets and Evaluation</h3>
<ul>
<li><strong>Datasets:</strong>
<ul>
<li><a href="https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2"><strong>Glaive</strong></a><strong>:</strong> High-quality but limited coverage of use cases.</li>
<li><a href="https://gorilla.cs.berkeley.edu/blogs/7_open_functions_v2.html"><strong>Gorilla</strong></a><strong>:</strong> Simple functions, Python syntax focus.</li>
<li><a href="https://github.com/nexusflowai/NexusRaven-V2"><strong>Nexus Raven</strong></a><strong>:</strong> More complex parameters, Python focus.</li>
</ul></li>
<li><strong>Evaluation:</strong>
<ul>
<li><strong><a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Gorilla Leaderboard</a>:</strong> Useful for initial assessment, but consider its limitations (e.g., focus on Python syntax).</li>
<li><strong><a href="https://huggingface.co/Nexusflow">Nexus Benchmarks</a>:</strong> More challenging than Gorilla.</li>
<li><strong>Empty Bench:</strong> Evaluates general instruction following without function calling.</li>
<li><strong>Evaluation Challenges:</strong>
<ul>
<li><strong>Real-World Use Case Mismatch:</strong> Benchmarks may not fully capture the complexities of real-world scenarios, such as those requiring precise system prompting and multi-turn conversations.</li>
</ul></li>
</ul></li>
<li><strong>Recommendations:</strong>
<ul>
<li><strong>Benchmark Selection:</strong> Start with publicly available benchmarks to get a general idea of the model’s capabilities.</li>
<li><strong>Real-World Testing:</strong> It’s essential to test and evaluate models on the specific use cases they are intended for.</li>
<li><strong>Model Selection:</strong> Don’t rely solely on benchmark scores; try out the top-performing models on your own data and use case to determine the best fit.</li>
</ul></li>
</ul>
</section>
<section id="base-models-for-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="base-models-for-fine-tuning">Base Models for Fine-tuning</h3>
<ul>
<li><strong>Llama 3 &amp; Llama 3.1:</strong> Strong general-purpose models.
<ul>
<li><strong>FireFunction V1:</strong> Based on Mistral.</li>
<li><strong>FireFunction V2:</strong> Based on Llama, showed significant improvement.</li>
</ul></li>
<li><strong>Coding Models:</strong> Consider coding-focused models (e.g., Llama 2 Python code generation model) for single-turn, Python-based function calling.</li>
<li><strong><a href="https://huggingface.co/Qwen">Qwen Models</a>:</strong> Show promise but require further exploration.</li>
<li><strong>Phi (Microsoft):</strong> Smaller models that perform well for their size and can potentially run without a GPU.</li>
<li><strong>Model Selection:</strong> Consider the specific objective (e.g., forced function calling, Python syntax) when choosing a base model.</li>
</ul>
</section>
<section id="memory-retention-in-long-chains-of-calls" class="level3">
<h3 class="anchored" data-anchor-id="memory-retention-in-long-chains-of-calls">Memory Retention in Long Chains of Calls</h3>
<ul>
<li><strong>Longer Context Models:</strong> Opt for models with larger context windows (e.g., beyond Llama 3’s 8K context) for extended conversations.
<ul>
<li><a href="https://llama.meta.com/">Llama 3.1</a> has 128K content window</li>
</ul></li>
<li><strong>Dataset Representation:</strong> Include sufficient long conversation examples in the training data.</li>
<li><strong>Intelligent Conversation Pruning:</strong>
<ul>
<li>Develop algorithms to selectively retain the most relevant messages from previous turns when the conversation exceeds the context window.</li>
<li>Explore semantic matching techniques to identify relevant past messages.</li>
</ul></li>
<li><strong>Whiteboard Approach:</strong>
<ul>
<li>Have the model summarize the key aspects of the conversation at the end of each turn.</li>
<li>Pass only the summary to the model in subsequent turns, effectively resetting the context while retaining essential information.</li>
</ul></li>
</ul>
</section>
<section id="multi-agent-systems-and-function-calling" class="level3">
<h3 class="anchored" data-anchor-id="multi-agent-systems-and-function-calling">Multi-Agent Systems and Function Calling</h3>
<ul>
<li><p><strong>Function as Agent:</strong> A function can be considered an agent within a multi-agent system, interacting with other agents (potentially other functions or models) to complete tasks.</p></li>
<li><p><strong>Orchestration:</strong> Multi-agent frameworks like Autogen provide tools for defining agents, extracting function schemas, routing messages, and executing function calls based on model responses.</p></li>
<li><p><strong>Agent Team Creation:</strong></p>
<ul>
<li><strong>Identify Strengths and Weaknesses:</strong> Analyze individual models to understand their capabilities and limitations.</li>
<li><strong>Define Agent Roles:</strong> Assign roles and responsibilities to each agent based on their strengths.</li>
<li><strong>Routing Layer:</strong> Design a system for efficiently routing messages and tasks to the appropriate agents.</li>
<li><strong>Context Management:</strong> Implement mechanisms for sharing and summarizing context between agents, especially in long conversations.</li>
</ul></li>
<li><p><strong>Merging Models:</strong> Explore techniques like <strong><a href="https://github.com/arcee-ai/mergekit">MergeKit</a></strong> to combine layers from multiple models, potentially creating more capable composite models.</p></li>
<li><p><strong>Cost and Latency Optimization:</strong> Consider using smaller, specialized models for specific tasks to reduce cost and latency.</p></li>
</ul>
</section>
<section id="comparison-with-gorilla-project" class="level3">
<h3 class="anchored" data-anchor-id="comparison-with-gorilla-project">Comparison with Gorilla Project</h3>
<ul>
<li><strong>Gorilla:</strong>
<ul>
<li>Focuses on single-turn, forced function calling with Python signature generation.</li>
<li>Supports various function calling scenarios (single, parallel, nested).</li>
<li>Primarily designed for functions with simple parameters.</li>
</ul></li>
<li><strong>FireFunction:</strong>
<ul>
<li>Addresses real-world use cases involving complex system prompts and mixed conversations with function calling.</li>
<li>Handles functions with more complex parameters and instructions.</li>
</ul></li>
<li><strong>Benchmarks:</strong> Gorilla leaderboard lacks tasks for complex system prompts and mixed conversation scenarios.</li>
</ul>
</section>
<section id="smallest-model-for-local-smart-home-assistant" class="level3">
<h3 class="anchored" data-anchor-id="smallest-model-for-local-smart-home-assistant">Smallest Model for Local Smart Home Assistant</h3>
<ul>
<li><strong>Challenges:</strong> Running a model locally with hundreds of functions on a resource-constrained device.</li>
<li><strong>Potential Solutions:</strong>
<ul>
<li><strong>Pre-populate KV Cache:</strong> Pre-load function definitions into the model’s KV cache to reduce inference time.</li>
<li><strong>Function Retrieval with RAG:</strong> Use retrieval augmented generation (RAG) to dynamically select relevant functions based on user input, reducing the number of functions in the prompt.</li>
<li><strong>Smaller Models:</strong> Explore smaller models like Phi or Qwen2 (2 billion parameters) that can potentially run without a GPU.</li>
</ul></li>
</ul>
</section>
<section id="function-calling-with-graphql" class="level3">
<h3 class="anchored" data-anchor-id="function-calling-with-graphql">Function Calling with GraphQL</h3>
<ul>
<li><strong>GraphQL as Structured Data:</strong> GraphQL can be treated as a structured data format similar to function call schemas.</li>
<li><strong>Leveraging Function Calling Models:</strong> Explore using existing function calling models to generate or complete GraphQL queries by defining GraphQL operations as functions.</li>
<li><strong><a href="https://docs.fireworks.ai/structured-responses/structured-output-grammar-based">Grammar Mode</a>:</strong> Leverage the grammar enforcement capabilities of function calling models to ensure syntactically correct GraphQL queries.</li>
</ul>
</section>
<section id="handling-api-changes" class="level3">
<h3 class="anchored" data-anchor-id="handling-api-changes">Handling API Changes</h3>
<ul>
<li><strong>Canonical Data Format:</strong> Store data in a format that can be easily translated to different API syntaxes.</li>
<li><strong>Client-Side Translation:</strong> Implement a wrapper around the API to handle syntax conversions, allowing the model to remain agnostic to specific API changes.</li>
<li><strong>Prompt-Based Function Definitions:</strong> Consider defining functions within the prompt itself. This approach allows for easier updates when APIs change, eliminating the need for retraining.</li>
</ul>
</section>
<section id="synthetic-data-generation-best-practices" class="level3">
<h3 class="anchored" data-anchor-id="synthetic-data-generation-best-practices">Synthetic Data Generation Best Practices</h3>
<ul>
<li><strong>High-Quality Prompt and Seed Data:</strong> Start with well-crafted prompts and a small, high-quality seed dataset.</li>
<li><strong>Good Generation Model:</strong> Utilize a capable language model for generation, balancing the legal constraints of using closed-source models with the effort required for filtering outputs from open-source models.</li>
<li><strong>Data Variety over Quantity:</strong> Prioritize diverse use cases and scenarios over a large number of examples for a single case.</li>
<li><strong>Few-Shot Examples in Prompts:</strong> Include examples of desired outputs in the prompts to guide the generation process.</li>
<li><strong>Temperature Variation:</strong> Experiment with different temperature settings to encourage creativity and diversity in generated samples.</li>
<li><strong>Post-Filtering:</strong> Implement filtering mechanisms to remove low-quality or incorrect samples.</li>
<li><strong>DPO Alignment (Optional):</strong> Use DPO to refine the model’s behavior, especially for complex system prompts, by providing examples of both desired and undesired outputs.</li>
</ul>
</section>
<section id="importance-of-data-vs.-hyperparameters-vs.-base-model" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-data-vs.-hyperparameters-vs.-base-model">Importance of Data vs.&nbsp;Hyperparameters vs.&nbsp;Base Model</h3>
<ul>
<li><strong>Data Quality:</strong> As models become more intelligent and training data becomes smaller, the quality of the data becomes increasingly crucial.</li>
<li><strong>Hyperparameter Sensitivity:</strong> Smaller datasets often lead to increased sensitivity to hyperparameters, requiring careful tuning.</li>
<li><strong>Base Model:</strong> The choice of base model significantly impacts performance, especially for specialized tasks like Python code generation.</li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-019/</guid>
  <pubDate>Fri, 30 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Office Hours 8: Predibase</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-008/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="lorax-benefits-over-vllm-and-other-libraries" class="level3">
<h3 class="anchored" data-anchor-id="lorax-benefits-over-vllm-and-other-libraries">Lorax Benefits over vLLM and Other Libraries</h3>
<ul>
<li><strong><a href="https://github.com/predibase/lorax">lorax</a>:</strong> Multi-LoRA inference server that scales to 1000s of fine-tuned LLMs</li>
</ul>
<section id="performance-optimization" class="level4">
<h4 class="anchored" data-anchor-id="performance-optimization">Performance Optimization</h4>
<ul>
<li><p>Lorax uses <a href="https://github.com/punica-ai/punica/tree/master/csrc/sgmv"><strong>SGMV (segmented gathered matrix vector multiplication)</strong> kernel</a> for pre-fill (compute-bound) operations, while vLLM uses <a href="https://github.com/punica-ai/punica/tree/master/csrc/bgmv"><strong>BGMV</strong> kernel</a>.</p>
<ul>
<li><p>SGMV is optimized for pre-fill computation profiles.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-008/images/sgmv.png" class="img-fluid figure-img"></p>
<figcaption>Punica: Multi-Tenant LoRA Serving - Figure 3</figcaption>
</figure>
</div></li>
<li><p><strong>Paper:</strong> <a href="https://arxiv.org/abs/2310.18547">Punica: Multi-Tenant LoRA Serving</a></p></li>
</ul></li>
<li><p>Lorax uses both kernels (SGMV for pre-fill, BGMV for decode) depending on the generation process stage, while vLLM uses only BGMV.</p></li>
</ul>
</section>
<section id="dynamic-adapter-loading" class="level4">
<h4 class="anchored" data-anchor-id="dynamic-adapter-loading">Dynamic Adapter Loading</h4>
<ul>
<li>Lorax is currently the only library offering <strong>dynamic adapter loading</strong>, eliminating the need to pre-specify adapters and simplifying memory management.</li>
</ul>
</section>
<section id="scheduler-component" class="level4">
<h4 class="anchored" data-anchor-id="scheduler-component">Scheduler Component</h4>
<ul>
<li>Lorax’s scheduler intelligently manages:
<ul>
<li>Adapter residency on GPU and host memory.</li>
<li>Batching of requests.</li>
<li>Trade-off between latency and throughput for optimal processing.</li>
</ul></li>
</ul>
</section>
<section id="support-for-various-adapters" class="level4">
<h4 class="anchored" data-anchor-id="support-for-various-adapters">Support for Various Adapters</h4>
<ul>
<li>Supports <strong>LoRa switching</strong> (most popular) and other adapter types.
<ul>
<li><strong>Speculative decoding</strong>, allowing combination with LoRa, is unique to Lorax.</li>
<li>Exploration of other adapter types like <a href="https://arxiv.org/abs/2404.03592">ReFT</a> (representation fine-tuning) and <a href="https://arxiv.org/abs/2402.09353">DoRA</a>.</li>
</ul></li>
</ul>
</section>
<section id="additional-features" class="level4">
<h4 class="anchored" data-anchor-id="additional-features">Additional Features</h4>
<ul>
<li>Adding support for:
<ul>
<li>Embedding models.</li>
<li>Training adapters specifically for embedding models.</li>
</ul></li>
</ul>
</section>
</section>
<section id="data-requirements-and-sourcing-for-quality-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="data-requirements-and-sourcing-for-quality-fine-tuning">Data Requirements and Sourcing for Quality Fine-Tuning</h3>
<section id="data-volume-vs.-quality" class="level4">
<h4 class="anchored" data-anchor-id="data-volume-vs.-quality">Data Volume vs.&nbsp;Quality</h4>
<ul>
<li><strong>High-quality data is more important than high volume.</strong>
<ul>
<li>Large datasets often contain irrelevant information, hindering effective learning.</li>
</ul></li>
<li>Start with a <strong>smaller dataset (hundreds of examples) and a larger base model (e.g., Llama 3 70B).</strong>
<ul>
<li>Larger models perform better with smaller datasets but are more expensive to train and use for inference.</li>
</ul></li>
<li>As the dataset grows, transition to smaller models for cost efficiency.</li>
</ul>
</section>
<section id="synthetic-data-generation" class="level4">
<h4 class="anchored" data-anchor-id="synthetic-data-generation">Synthetic Data Generation</h4>
<ul>
<li><strong>Significantly increases performance</strong>, especially for smaller datasets (hundreds to low thousands of examples).</li>
<li>Gains decrease with larger datasets (hundreds of thousands).</li>
</ul>
</section>
<section id="case-study-metas-less-is-more-for-alignment" class="level4">
<h4 class="anchored" data-anchor-id="case-study-metas-less-is-more-for-alignment">Case Study: Meta’s “Less is More for Alignment”</h4>
<ul>
<li>Demonstrated strong performance using only <strong>2,000 samples</strong> for training Llama 2 70B (older generation).</li>
</ul>
</section>
<section id="dataset-creation-challenges" class="level4">
<h4 class="anchored" data-anchor-id="dataset-creation-challenges">Dataset Creation Challenges</h4>
<ul>
<li>Users often expect to directly transfer knowledge from closed-source APIs (e.g., OpenAI) to open-source models, leading to ineffective QA pairs.</li>
<li>Solution: Reformulate tasks as RAG problems or use embedding/generator models with appropriate data corpus indexing and training.</li>
</ul>
</section>
<section id="dataset-preparation-support" class="level4">
<h4 class="anchored" data-anchor-id="dataset-preparation-support">Dataset Preparation Support</h4>
<ul>
<li>Predibase provides guidance on dataset creation but does not offer specific data preparation tools.</li>
<li>Consulting companies can assist with data preparation and synthetic data generation.</li>
<li>Collaboration with companies like <a href="https://gretel.ai/">Gretel</a> for synthetic data as a service is being explored.</li>
</ul>
</section>
<section id="dataset-complexity" class="level4">
<h4 class="anchored" data-anchor-id="dataset-complexity">Dataset Complexity</h4>
<ul>
<li>Simpler for traditional supervised ML tasks (e.g., classification, NER, summarization) due to straightforward input-output relationships.</li>
</ul>
</section>
</section>
<section id="platform-choice-predibase-vs.-self-hosting-lorax" class="level3">
<h3 class="anchored" data-anchor-id="platform-choice-predibase-vs.-self-hosting-lorax">Platform Choice: Predibase vs.&nbsp;Self-Hosting Lorax</h3>
<section id="considerations-for-self-hosting" class="level4">
<h4 class="anchored" data-anchor-id="considerations-for-self-hosting">Considerations for Self-Hosting</h4>
<ul>
<li>Suitable for companies where ML infrastructure is a core competency or differentiator.</li>
<li>Requires a dedicated team for platform development, maintenance, and updates.</li>
</ul>
</section>
<section id="cost-benefit-analysis" class="level4">
<h4 class="anchored" data-anchor-id="cost-benefit-analysis">Cost-Benefit Analysis</h4>
<ul>
<li><strong>Self-hosting:</strong> High upfront and ongoing costs.</li>
<li><strong>Predibase:</strong> Predictable subscription fee, freeing up resources for other priorities.</li>
</ul>
</section>
<section id="recommendation" class="level4">
<h4 class="anchored" data-anchor-id="recommendation">Recommendation</h4>
<ul>
<li>Predibase is generally more cost-effective for companies whose core competencies lie elsewhere, allowing them to focus on product development or model creation.</li>
</ul>
</section>
</section>
<section id="lorax-adoption-and-engagement-expectations" class="level3">
<h3 class="anchored" data-anchor-id="lorax-adoption-and-engagement-expectations">Lorax Adoption and Engagement Expectations</h3>
<section id="comparison-to-previous-open-source-projects" class="level4">
<h4 class="anchored" data-anchor-id="comparison-to-previous-open-source-projects">Comparison to Previous Open-Source Projects</h4>
<ul>
<li><strong><a href="https://github.com/horovod/horovod">Horovod</a> (distributed training framework):</strong> Significant buy-in from large companies building ML platforms.</li>
<li><strong><a href="https://github.com/ludwig-ai/ludwig">Ludwig</a> (low-code ML framework):</strong> High user adoption but limited contributions due to its abstract nature.</li>
</ul>
</section>
<section id="lorax-adoption-pattern" class="level4">
<h4 class="anchored" data-anchor-id="lorax-adoption-pattern">Lorax Adoption Pattern</h4>
<ul>
<li>Similar to Horovod, attracting technical users building internal ML infrastructure.</li>
<li>Active contributions from self-hosting users, indicating strong engagement and “dogfooding.”</li>
</ul>
</section>
</section>
<section id="future-plans-for-the-fine-tuning-index" class="level3">
<h3 class="anchored" data-anchor-id="future-plans-for-the-fine-tuning-index">Future Plans for the Fine-Tuning Index</h3>
<ul>
<li><strong>Homepage:</strong> <a href="https://predibase.com/fine-tuning-index">The Fine-tuning Index</a></li>
</ul>
<section id="current-state" class="level4">
<h4 class="anchored" data-anchor-id="current-state">Current State</h4>
<ul>
<li>Static artifact averaging performance over 31 diverse tasks.</li>
</ul>
</section>
<section id="short-term-goals" class="level4">
<h4 class="anchored" data-anchor-id="short-term-goals">Short-Term Goals</h4>
<ul>
<li>Transition to a <strong>living artifact</strong> with regular updates as new models are released.</li>
<li>Implement tooling for <strong>easier model addition and UI integration with a database.</strong></li>
</ul>
</section>
<section id="long-term-vision" class="level4">
<h4 class="anchored" data-anchor-id="long-term-vision">Long-Term Vision</h4>
<ul>
<li>Achieve the <strong>freshness and openness of platforms like LMSYS Leaderboard and Hugging Face Leaderboards.</strong></li>
</ul>
</section>
<section id="additional-improvements" class="level4">
<h4 class="anchored" data-anchor-id="additional-improvements">Additional Improvements</h4>
<ul>
<li>Introduce <strong>Elo scores</strong> for more accurate model ranking.</li>
</ul>
</section>
</section>
<section id="handling-large-scale-text-classification-with-sensitive-data" class="level3">
<h3 class="anchored" data-anchor-id="handling-large-scale-text-classification-with-sensitive-data">Handling Large-Scale Text Classification with Sensitive Data</h3>
<section id="scenario" class="level4">
<h4 class="anchored" data-anchor-id="scenario">Scenario</h4>
<ul>
<li>1-2 million free-form text snippets per month requiring 5-10 binary (yes/no) questions.</li>
<li>GPT-4 performance is desired but cost-prohibitive.</li>
<li>Data is sensitive and based in the EU.</li>
</ul>
</section>
<section id="solution" class="level4">
<h4 class="anchored" data-anchor-id="solution">Solution</h4>
<ul>
<li><strong>GPT-4 Distillation:</strong>
<ul>
<li>Use GPT-4 to generate label data for a smaller, more cost-effective model.</li>
<li>Consider OpenAI’s terms of service when using GPT-4 for data generation.</li>
</ul></li>
<li><strong>Adapter Structure:</strong>
<ul>
<li><strong>Multiple Adapters:</strong> Suitable if the specific adapter to use for each request is unknown beforehand.</li>
<li><strong>One Adapter with Multiple Label Outputs:</strong> Preferable if the adapter selection can be determined based on request information.</li>
<li><strong>Routing Architectures:</strong> Explore if dynamically determining the appropriate adapter is necessary.</li>
</ul></li>
<li><strong>GDPR Compliance:</strong>
<ul>
<li>Predibase is working with EU-based, GDPR-compliant cloud providers.</li>
<li>Contact Predibase for options and discussions on EU data center deployments.</li>
</ul></li>
</ul>
</section>
</section>
<section id="on-device-lorax-and-lookahead-loras" class="level3">
<h3 class="anchored" data-anchor-id="on-device-lorax-and-lookahead-loras">On-Device Lorax and Lookahead LoRAs</h3>
<section id="on-device-potential" class="level4">
<h4 class="anchored" data-anchor-id="on-device-potential">On-Device Potential</h4>
<ul>
<li>Highly appealing for running smaller language models on edge devices (e.g., phones) with task-specific LoRAs.</li>
<li>Aligned with the trend of sparse activation for efficient model execution.</li>
</ul>
</section>
<section id="challenges" class="level4">
<h4 class="anchored" data-anchor-id="challenges">Challenges</h4>
<ul>
<li><strong>Hardware Compatibility:</strong> Lorax is currently optimized for NVIDIA GPUs, which are not common on edge devices.
<ul>
<li>Optimizations like flash attention, page attention, and SG&amp;B kernels are CUDA-based.</li>
<li>Porting to different hardware architectures (e.g., Qualcomm’s AI chips) would require significant code rewriting.</li>
<li>Optimization techniques might not translate well to specialized ASICs used in edge devices.</li>
</ul></li>
</ul>
</section>
<section id="lookahead-loras-and-speculative-decoding" class="level4">
<h4 class="anchored" data-anchor-id="lookahead-loras-and-speculative-decoding">Lookahead LoRAs and Speculative Decoding</h4>
<ul>
<li><strong>Lookahead LoRAs:</strong> Fine-tuned for both performance and inference speed (low-rank acceleration).</li>
<li><strong>Speculative Decoding:</strong> Works best for narrow tasks (e.g., summarization, structured generation) where predictions can be made based on limited context.
<ul>
<li>Effectiveness increases with narrower task definitions.</li>
<li>Aligns with the trend of using LLMs for specialized tasks with task-specific LoRAs.</li>
</ul></li>
<li><strong>Hardware Trends:</strong> NVIDIA’s newer GPUs (e.g., L40S) prioritize increased FLOPs over memory bandwidth, favoring compute-intensive techniques like speculative decoding.</li>
</ul>
</section>
<section id="speculative-decoding-in-practice" class="level4">
<h4 class="anchored" data-anchor-id="speculative-decoding-in-practice">Speculative Decoding in Practice</h4>
<ul>
<li><strong>Performance:</strong> Expected to work well in practice due to its suitability for narrow tasks.</li>
<li><strong>High QPS:</strong> Ensuring efficient operation at high query per second (QPS) is a current challenge being addressed.</li>
<li><strong>Fine-Tuning:</strong> Speculative decoding components should be fine-tuned alongside the LoRA for seamless integration.</li>
</ul>
</section>
</section>
<section id="synthetic-data-generation-for-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="synthetic-data-generation-for-fine-tuning">Synthetic Data Generation for Fine-Tuning</h3>
<section id="process" class="level4">
<h4 class="anchored" data-anchor-id="process">Process</h4>
<ul>
<li>Use a large language model (e.g., Llama 3 70B) with a small dataset for initial fine-tuning.</li>
<li>Generate synthetic data using the fine-tuned model.</li>
<li>Fine-tune a smaller model using the generated synthetic data.</li>
</ul>
</section>
<section id="effectiveness" class="level4">
<h4 class="anchored" data-anchor-id="effectiveness">Effectiveness</h4>
<ul>
<li>Significant performance improvements observed.</li>
<li>Each 2x increase in data leads to approximately a 5% performance lift.</li>
</ul>
</section>
<section id="model-family-considerations" class="level4">
<h4 class="anchored" data-anchor-id="model-family-considerations">Model Family Considerations</h4>
<ul>
<li>Use the same model family for both the initial large model and the final smaller model (e.g., Llama) for optimal distillation.</li>
<li>Cross-family distillation might not be as effective due to differences in data distributions.</li>
</ul>
</section>
<section id="alternative-approach" class="level4">
<h4 class="anchored" data-anchor-id="alternative-approach">Alternative Approach</h4>
<ul>
<li>Use GPT-3.5 or GPT-4 to generate synthetic data based on the small input dataset.</li>
<li>Fine-tune a smaller model using the GPT-generated synthetic data.</li>
</ul>
</section>
<section id="ensemble-techniques-for-synthetic-data-generation" class="level4">
<h4 class="anchored" data-anchor-id="ensemble-techniques-for-synthetic-data-generation">Ensemble Techniques for Synthetic Data Generation</h4>
<ul>
<li>Explore generating synthetic data using multiple model families to enhance diversity and capture different data aspects.</li>
<li>Fine-tune the final model on the ensemble of predictions from different models, similar to ensembling techniques in traditional ML.</li>
<li>This approach could potentially outperform fine-tuning on synthetic data generated from a single model family.</li>
</ul>
</section>
<section id="data-programming-and-weak-labeling" class="level4">
<h4 class="anchored" data-anchor-id="data-programming-and-weak-labeling">Data Programming and Weak Labeling</h4>
<ul>
<li>Data programming techniques (e.g., <a href="https://www.snorkel.org/">Snorkel</a>) can be used to combine predictions from multiple “weak” experts (models) to generate more accurate labels.</li>
<li>Distilling on the logits or probabilities, rather than the final labels, captures the uncertainty and agreement levels among different models, improving label quality.</li>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/1605.07723">Data Programming: Creating Large Training Sets, Quickly</a></li>
</ul>
</section>
</section>
<section id="fine-tuning-adapters-vs.-gpt-4-for-qa-over-internal-documentation" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-adapters-vs.-gpt-4-for-qa-over-internal-documentation">Fine-Tuning Adapters vs.&nbsp;GPT-4 for Q&amp;A over Internal Documentation</h3>
<section id="long-term-vision-1" class="level4">
<h4 class="anchored" data-anchor-id="long-term-vision-1">Long-Term Vision</h4>
<ul>
<li>Fine-tuning could potentially replace RAG entirely for domain adaptation, allowing models to directly answer questions based on internal data.</li>
</ul>
</section>
<section id="current-state-1" class="level4">
<h4 class="anchored" data-anchor-id="current-state-1">Current State</h4>
<ul>
<li>Fine-tuning is not yet a complete replacement for RAG.</li>
</ul>
</section>
<section id="fine-tuning-applications-within-rag" class="level4">
<h4 class="anchored" data-anchor-id="fine-tuning-applications-within-rag">Fine-Tuning Applications within RAG</h4>
<ul>
<li>Improve individual RAG components:
<ul>
<li><strong>Embedder:</strong> Enhance document retrieval accuracy.</li>
<li><strong>Re-ranker:</strong> Improve relevance ranking of retrieved documents.</li>
<li><strong>Generator:</strong> Enhance answer generation quality.</li>
</ul></li>
<li>Jointly fine-tune multiple components for optimal performance.</li>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2403.18295">Dual Instruction Tuning with Large Language Models for Mathematical Reasoning</a></li>
</ul>
</section>
<section id="benefits-of-fine-tuning-for-rag" class="level4">
<h4 class="anchored" data-anchor-id="benefits-of-fine-tuning-for-rag">Benefits of Fine-Tuning for RAG</h4>
<ul>
<li>Addresses limitations of pre-trained models by tailoring them to specific domains and tasks.</li>
<li>Improves accuracy, relevance, and quality of RAG system outputs.</li>
</ul>
</section>
<section id="considerations" class="level4">
<h4 class="anchored" data-anchor-id="considerations">Considerations</h4>
<ul>
<li><strong>Freshness:</strong> Keeping fine-tuned models up-to-date with changing data can be challenging.</li>
<li><strong>Metadata Filtering:</strong> RAG allows for flexible filtering based on document metadata, which might not be easily replicated with fine-tuning alone.</li>
</ul>
</section>
<section id="recommendations" class="level4">
<h4 class="anchored" data-anchor-id="recommendations">Recommendations</h4>
<ul>
<li>Start with a baseline RAG system using pre-trained models.</li>
<li>Identify performance bottlenecks and target fine-tuning efforts accordingly.</li>
<li>Consider joint fine-tuning of multiple components for optimal results.</li>
</ul>
</section>
</section>
<section id="catastrophic-forgetting-with-lora-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="catastrophic-forgetting-with-lora-fine-tuning">Catastrophic Forgetting with LoRA Fine-Tuning</h3>
<ul>
<li>Still possible, even with LoRA, if the LoRA’s output leads to model collapse (e.g., producing NaNs or zeros).</li>
<li>Less prevalent with LoRA compared to full fine-tuning.
<ul>
<li>Learns less, forgets less</li>
</ul></li>
<li>LoRA is better suited for structuring outputs and narrow tasks, where catastrophic forgetting is less likely.</li>
</ul>
<section id="lora-fine-tuning-benefits" class="level4">
<h4 class="anchored" data-anchor-id="lora-fine-tuning-benefits">LoRA Fine-Tuning Benefits</h4>
<ul>
<li>Consistent performance improvements observed for suitable tasks.</li>
<li>Reduced risk of catastrophic forgetting compared to full fine-tuning.</li>
</ul>
</section>
</section>
<section id="multiple-loras-and-parameter-updates" class="level3">
<h3 class="anchored" data-anchor-id="multiple-loras-and-parameter-updates">Multiple LoRAs and Parameter Updates</h3>
<ul>
<li>Multiple LoRAs can update different subsets of model parameters</li>
<li>Punica project kernels modified to allow sparse segmented matrix multiplication</li>
<li>Heterogeneous setups (LoRAs targeting different layers) can be batched together</li>
</ul>
</section>
<section id="lora-rank-and-parameter-count" class="level3">
<h3 class="anchored" data-anchor-id="lora-rank-and-parameter-count">LoRA Rank and Parameter Count</h3>
<section id="rank-selection" class="level4">
<h4 class="anchored" data-anchor-id="rank-selection">Rank Selection</h4>
<ul>
<li>Experimentation with ranks from 8 to 128.</li>
<li><strong>8:</strong> Good starting point, default in some libraries.</li>
<li><strong>16:</strong> Generally provides strong performance and is widely used in the industry.</li>
<li><strong>64:</strong> Performance tends to plateau or decline beyond this rank.</li>
<li><strong>LoRA Alpha:</strong> Consider adjusting this parameter, which controls the contribution of base model weights, when using higher ranks.</li>
</ul>
</section>
<section id="parameter-scaling" class="level4">
<h4 class="anchored" data-anchor-id="parameter-scaling">Parameter Scaling</h4>
<ul>
<li>Primarily scales with the LoRA rank, not the training data size.</li>
<li>2x increase in rank results in a 2x increase in trainable parameters.</li>
<li>Increasing rank beyond a certain point leads to diminishing returns and increased training costs.</li>
</ul>
</section>
<section id="layer-targeting" class="level4">
<h4 class="anchored" data-anchor-id="layer-targeting">Layer Targeting</h4>
<ul>
<li>Explore targeting specific layers for LoRA application beyond the default QKV or QV layers.</li>
<li><strong>Generative Use Cases:</strong> Targeting all linear layers, embedding, and LM head can be beneficial.</li>
</ul>
</section>
</section>
<section id="fine-tuning-for-question-answering-and-verbatim-quoting" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-for-question-answering-and-verbatim-quoting">Fine-Tuning for Question Answering and Verbatim Quoting</h3>
<section id="scenario-1" class="level4">
<h4 class="anchored" data-anchor-id="scenario-1">Scenario</h4>
<ul>
<li>Fine-tuning a model on a corpus of books for question answering and verbatim quoting.</li>
</ul>
</section>
<section id="recommendations-1" class="level4">
<h4 class="anchored" data-anchor-id="recommendations-1">Recommendations</h4>
<ul>
<li><strong>RAG for Verbatim Quoting:</strong> Use RAG to retrieve and cite specific passages from the books verbatim.</li>
<li><strong>Fine-Tuning for Question Answering:</strong> Fine-tune the model to improve its ability to answer questions based on the corpus.</li>
<li><strong>Hybrid Approach:</strong> Combine RAG and fine-tuning to leverage the strengths of both approaches.</li>
</ul>
</section>
</section>
<section id="fine-tuning-for-function-calling-lora-per-function-type-vs.-multi-skill-lora" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-for-function-calling-lora-per-function-type-vs.-multi-skill-lora">Fine-Tuning for Function Calling: LoRA per Function Type vs.&nbsp;Multi-Skill LoRA</h3>
<section id="recommendation-1" class="level4">
<h4 class="anchored" data-anchor-id="recommendation-1">Recommendation</h4>
<ul>
<li>Use a LoRA per function type if the function type can be determined at request time.
<ul>
<li>Leverages the principle of narrower tasks leading to better fine-tuning performance.</li>
</ul></li>
<li>If function type is unknown beforehand, consider a multi-skill LoRA or explore alternative approaches.</li>
</ul>
</section>
<section id="granularity" class="level4">
<h4 class="anchored" data-anchor-id="granularity">Granularity</h4>
<ul>
<li>Determine the appropriate level of granularity for LoRA specialization based on available request metadata.</li>
</ul>
</section>
<section id="further-exploration" class="level4">
<h4 class="anchored" data-anchor-id="further-exploration">Further Exploration</h4>
<ul>
<li>Attend the upcoming session on fine-tuning for function calling for more in-depth insights and recommendations.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-008/</guid>
  <pubDate>Thu, 29 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 18: Fine-Tuning OpenAI Models - Best Practices</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-018/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="what-is-fine-tuning-when-to-use-it" class="level3">
<h3 class="anchored" data-anchor-id="what-is-fine-tuning-when-to-use-it">What is fine-tuning? When to use it?</h3>
<ul>
<li><strong>What is fine-tuning?</strong>
<ul>
<li>Training a model to follow a set of input-output examples.</li>
<li>Teaching the model to output specific responses for given inputs.</li>
</ul></li>
<li><strong>When to use fine-tuning?</strong>
<ul>
<li><strong>Following a specific format or tone:</strong> e.g., writing in a consistent style.</li>
<li><strong>Processing input in a particular way:</strong> e.g., extracting specific information from text.</li>
<li><strong>Following complex instructions:</strong> When the base model struggles with specific instructions.</li>
<li><strong>Improving latency (speed) and reducing token usage (cost):</strong> Compared to multi-shot prompting, fine-tuning can be faster and cheaper.</li>
</ul></li>
<li><strong>When NOT to use fine-tuning?</strong>
<ul>
<li><strong>Teaching the model new knowledge:</strong> Fine-tuning is not effective for adding new information to the model’s knowledge base. Use RAG (Retrieval Augmented Generation) or custom models for this purpose.</li>
<li><strong>Performing multiple, unrelated tasks:</strong> A single fine-tuned model is best suited for one task. Create separate models for different tasks or use prompt engineering.</li>
<li><strong>Including up-to-date information:</strong> Fine-tuning is not suitable for incorporating real-time or constantly changing data.</li>
</ul></li>
</ul>
</section>
<section id="custom-models-and-real-world-fine-tuning-examples" class="level3">
<h3 class="anchored" data-anchor-id="custom-models-and-real-world-fine-tuning-examples">Custom Models and Real-World Fine-tuning Examples</h3>
<ul>
<li><strong>Question:</strong> What are “custom models”?
<ul>
<li><strong>Answer:</strong>
<ul>
<li><strong>Custom models</strong> involve a deeper level of collaboration with OpenAI.</li>
<li>OpenAI works with select partners to train and refine models using large datasets over several months.</li>
<li><strong>Example:</strong> OpenAI collaborated with Harvey, a legal tech company, to create a model trained on case law. This model excels in legal tasks and significantly reduces hallucinations compared to the base GPT model.
<ul>
<li><strong>Blog Post:</strong> <a href="https://openai.com/index/harvey/">Harvey</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Question:</strong> Are there detailed examples of fine-tuning for real-world use cases, including training data and prompts?
<ul>
<li><strong>Answer:</strong>
<ul>
<li>OpenAI’s cookbook (<a href="https://cookbook.openai.com/">cookbook.openai.com</a>) offers a Q&amp;A model example.
<ul>
<li>The model is trained to respond with “I don’t know” when it lacks relevant knowledge.</li>
<li>This example demonstrates how fine-tuning can improve a model’s ability to recognize its limitations.</li>
<li><strong>GitHub Repository:</strong> <a href="examples/fine-tuned_qa">examples/fine-tuned_qa</a></li>
<li><strong>Notebook 1:</strong> <a href="https://cookbook.openai.com/examples/fine-tuned_qa/olympics-1-collect-data">Fine-Tuned Q&amp;A - collect data</a></li>
<li><strong>Notebook 2:</strong> <a href="https://cookbook.openai.com/examples/fine-tuned_qa/olympics-2-create-qa">Fine-Tuned Q&amp;A - create Q&amp;A</a></li>
<li><strong>Notebook 3:</strong> <a href="https://cookbook.openai.com/examples/fine-tuned_qa/olympics-3-train-qa">Fine-Tuned Q&amp;A - train</a></li>
</ul></li>
<li>The “<a href="https://platform.openai.com/docs/guides/optimizing-llm-accuracy">Optimizing LLMs for Accuracy</a>” guide on the OpenAI developer site provides a helpful framework for deciding when to use fine-tuning, RAG, or both.
<ul>
<li>The guide includes a chart illustrating different approaches based on the need for adding context versus optimizing responses.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="a-combined-approach" class="level3">
<h3 class="anchored" data-anchor-id="a-combined-approach">A Combined Approach</h3>
<ul>
<li><strong>Question:</strong> What does it mean to combine fine-tuning and RAG, as shown in the upper-right quadrant of the “Optimizing LLMs” chart?
<ul>
<li><strong>Answer:</strong>
<ul>
<li>The chart depicts a general progression, but specific applications may not require all steps.</li>
<li>Combining fine-tuning and RAG involves:
<ul>
<li>Using RAG to introduce new knowledge or context.</li>
<li>Using fine-tuning to modify the model’s response style or instruction-following capabilities.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="importance-of-evals-evaluation-metrics" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-evals-evaluation-metrics">Importance of Evals (Evaluation Metrics)</h3>
<ul>
<li><strong>Key Takeaway:</strong> Define your own set of <strong>evals</strong> (evaluation metrics) tailored to your application’s specific needs.</li>
<li><strong>Why not use standard benchmarks?</strong>
<ul>
<li>Standard benchmarks might not accurately reflect your application’s requirements.</li>
</ul></li>
<li><strong>Best Practice:</strong> Create evals based on real prompts and desired responses from your application.</li>
</ul>
</section>
<section id="a-cautionary-tale-when-fine-tuning-goes-wrong" class="level3">
<h3 class="anchored" data-anchor-id="a-cautionary-tale-when-fine-tuning-goes-wrong">A Cautionary Tale: When Fine-tuning Goes Wrong</h3>
<ul>
<li><strong>Example:</strong> A company tried to create a Slack bot using fine-tuning on their entire Slack corpus.
<ul>
<li><strong>Goal:</strong> The bot was intended to answer onboarding questions from new employees.</li>
<li><strong>Problem:</strong> The model learned the format of Slack responses but not the underlying information.
<ul>
<li>It often responded with deferrals like “I’ll do that tomorrow” or “Okay.”</li>
</ul></li>
<li><strong>Reason for Failure:</strong>
<ul>
<li>The model focused on replicating common responses instead of understanding the content.</li>
<li>This approach violated the principle of not using fine-tuning to add new knowledge.</li>
</ul></li>
<li><strong>Better Approach:</strong> Using RAG on the Slack data to provide the model with relevant information.</li>
</ul></li>
</ul>
</section>
<section id="preparing-data-for-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="preparing-data-for-fine-tuning">Preparing Data for Fine-tuning</h3>
<ul>
<li><strong>Data Format:</strong>
<ul>
<li>Similar to the chat completions API, using system, user, and assistant messages.</li>
<li>Include the desired assistant response for each user message.</li>
<li><strong>Documentation:</strong> <a href="https://platform.openai.com/docs/api-reference/fine-tuning/chat-input">Training format for chat models</a></li>
<li><strong>Documentation:</strong> <a href="https://platform.openai.com/docs/api-reference/fine-tuning/completions-input">Training format for completion models</a></li>
</ul></li>
<li><strong>Recommendations:</strong>
<ul>
<li><strong>Number of Examples:</strong> 50-100 examples per task.</li>
<li><strong>Focus on a Single Task:</strong> Use a single fine-tuned model for one specific task.</li>
<li><strong>Consistency in Prompt Structure:</strong> Maintain consistency between the prompt structure used in fine-tuning and in actual application calls.</li>
</ul></li>
</ul>
</section>
<section id="handling-multi-turn-conversations-and-internal-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="handling-multi-turn-conversations-and-internal-thoughts">Handling Multi-Turn Conversations and Internal Thoughts</h3>
<ul>
<li><strong>Question:</strong> How to handle multi-turn conversations with RAG, function calling, and internal thoughts (generated by tools like Langchain) during fine-tuning data preparation? Should all internal thoughts be included, even if they are not always present in production?
<ul>
<li><strong>Answer:</strong>
<ul>
<li>Experiment with the <strong>weight parameter</strong> to control which parts of the conversation the model should focus on learning.</li>
<li>The weight parameter allows you to assign different levels of importance to different messages in the training data.</li>
<li><strong>General Advice:</strong>
<ul>
<li>Avoid excessive complexity in fine-tuning. If multi-turn conversations prove too complex, consider simplifying or using alternative approaches.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Follow-up Question:</strong> Is a weight parameter of 0 equivalent to setting the label of those tokens to -100 (effectively ignoring them)?
<ul>
<li><strong>Answer:</strong>
<ul>
<li>A weight of 0 means the model won’t learn how to generate those specific messages (e.g., user and system messages).</li>
<li>However, it will still use them as context when learning how to generate other messages.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="evolution-of-the-weight-parameter-and-openais-development-process" class="level3">
<h3 class="anchored" data-anchor-id="evolution-of-the-weight-parameter-and-openais-development-process">Evolution of the Weight Parameter and OpenAI’s Development Process</h3>
<ul>
<li><strong>Observation:</strong> The introduction of the weight parameter was a significant development. However, its rollout wasn’t widely publicized.</li>
<li><strong>Question:</strong> How does OpenAI decide on new features and gather feedback? Could this process be more transparent?
<ul>
<li><strong>Answer:</strong>
<ul>
<li>OpenAI gathers feedback from various sources:
<ul>
<li>OpenAI Developer Forum</li>
<li>Direct customer interactions</li>
<li>Account managers</li>
<li>Events, conferences, and talks</li>
</ul></li>
<li>The weight parameter was a direct result of this feedback process.</li>
<li>OpenAI acknowledges the importance of a more prominent announcement for such features.</li>
<li><strong>Future Direction:</strong> OpenAI plans to continue adding models, methods, and customization options to its fine-tuning platform.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="openais-fine-tuning-best-practices-and-hyperparameters" class="level3">
<h3 class="anchored" data-anchor-id="openais-fine-tuning-best-practices-and-hyperparameters">OpenAI’s Fine-tuning Best Practices and Hyperparameters</h3>
<section id="curate-examples-carefully" class="level4">
<h4 class="anchored" data-anchor-id="curate-examples-carefully">Curate examples carefully</h4>
<ul>
<li>Datasets can be difficult to build, start small and invest intentionally. Optimize for fewer high-quality training examples.
<ul>
<li>Consider “prompt baking”, or using a basic prompt to generate your initial examples</li>
<li>If your conversations are multi-turn, ensure your examples are representative</li>
<li>Collect examples to target issues detected in evaluation</li>
<li>Consider the balance &amp; diversity of data</li>
<li>Make sure your examples contain all the information needed in the response</li>
</ul></li>
</ul>
</section>
<section id="iterate-on-hyperparameters" class="level4">
<h4 class="anchored" data-anchor-id="iterate-on-hyperparameters">Iterate on hyperparameters</h4>
<ul>
<li>Start with the defaults and adjust based on performance.
<ul>
<li>If the model does not appear to converge, increase the learning rate multiplier</li>
<li>If the model does not follow the training data as much as expected, increase the number of epochs</li>
<li>If the model becomes less diverse than expected, decrease the number of epochs by 1-2</li>
</ul></li>
</ul>
</section>
<section id="establish-a-baseline" class="level4">
<h4 class="anchored" data-anchor-id="establish-a-baseline">Establish a baseline</h4>
<ul>
<li>Often users start with a zero-shot or few-shot prompt to build a baseline evaluation before graduating to fine-tuning.</li>
</ul>
</section>
<section id="optimize-for-latency-and-token-efficiency" class="level4">
<h4 class="anchored" data-anchor-id="optimize-for-latency-and-token-efficiency">Optimize for latency and token efficiency</h4>
<ul>
<li>When using GPT-4, once you have a baseline evaluation and training examples, consider fine-tuning 3.5 to get similar performance for less cost and latency.
<ul>
<li>Experiment with reducing or removing system instructions with subsequent fine-tuned model versions.</li>
</ul></li>
</ul>
</section>
<section id="automate-your-feedback-pipeline" class="level4">
<h4 class="anchored" data-anchor-id="automate-your-feedback-pipeline">Automate your feedback pipeline</h4>
<ul>
<li>Introduce automated evaluations to highlight potential problem cases to clean up and use as training data.
<ul>
<li>Consider the G-Eval approach of using GPT-4 to perform automated testing using a scorecard.</li>
</ul></li>
</ul>
</section>
<section id="hyperparameters" class="level4">
<h4 class="anchored" data-anchor-id="hyperparameters">Hyperparameters</h4>
<ul>
<li><strong>Epochs:</strong> The number of times the training data is iterated over.
<ul>
<li>Impacts training the most.</li>
<li>Higher epochs risk overfitting, lower epochs might lead to underfitting.</li>
<li>OpenAI automatically chooses a default based on dataset size.</li>
</ul></li>
<li><strong>Batch Size and Learning Rate Multiplier:</strong> Have less impact but can be adjusted for optimization.
<ul>
<li>Larger batch sizes tend to work better for larger datasets.</li>
<li>Experiment with learning rates between <code>0.02-0.2</code>.</li>
<li>Larger learning rates often perform better with larger batch sizes</li>
</ul></li>
<li><strong>Recommendation:</strong> Start with defaults and adjust based on eval results.</li>
</ul>
</section>
</section>
<section id="success-stories-and-performance-improvements" class="level3">
<h3 class="anchored" data-anchor-id="success-stories-and-performance-improvements">Success Stories and Performance Improvements</h3>
<ul>
<li><strong>Case Study 1:</strong> Fine-tuning a larger model (GPT-4) for an Icelandic government project resulted in significant improvements in grammar correction compared to the base model and other approaches.</li>
<li><strong>Case Study 2:</strong> Fine-tuning GPT-3.5 outperformed GPT-4 with few-shot prompting in a specific task, highlighting potential cost and latency benefits.</li>
</ul>
</section>
<section id="function-calling-and-fine-tuning-considerations" class="level3">
<h3 class="anchored" data-anchor-id="function-calling-and-fine-tuning-considerations">Function Calling and Fine-tuning Considerations</h3>
<ul>
<li><strong>Use Case:</strong> Fine-tuning can improve the model’s ability to select and call the correct functions.</li>
<li><strong>Caution:</strong> When working with complex or lengthy function definitions, it might be necessary to include them in the prompt even after fine-tuning.
<ul>
<li>Unlike scenarios where fine-tuning can replace lengthy prompts, function calling might require those definitions to be present during runtime.</li>
</ul></li>
</ul>
</section>
<section id="reducing-hallucinations" class="level3">
<h3 class="anchored" data-anchor-id="reducing-hallucinations">Reducing Hallucinations</h3>
<ul>
<li><strong>Example:</strong> The Q&amp;A model in OpenAI’s cookbook demonstrates how to reduce hallucinations.
<ul>
<li><strong>Approach:</strong> The model is trained on Olympic-related questions. If the question falls outside this domain, it’s designed to respond with “I don’t know.”</li>
<li><strong>Result:</strong> Fine-tuning effectively minimizes false positives (incorrect answers) in this scenario.</li>
</ul></li>
</ul>
</section>
<section id="adoption-rate-of-fine-tuning-and-open-source-alternatives" class="level3">
<h3 class="anchored" data-anchor-id="adoption-rate-of-fine-tuning-and-open-source-alternatives">Adoption Rate of Fine-tuning and Open Source Alternatives</h3>
<ul>
<li><strong>Observation:</strong> Less than 1% of OpenAI API users utilize fine-tuning.
<ul>
<li><strong>Reason:</strong>
<ul>
<li>Fine-tuning is a more advanced technique used for optimization or when other methods are insufficient.</li>
<li>Many users find success with base models and simpler approaches.</li>
</ul></li>
</ul></li>
<li><strong>Question:</strong> What are the advantages of fine-tuning OpenAI models compared to open-source models?
<ul>
<li><strong>Answer:</strong>
<ul>
<li><strong>Advantages of OpenAI models:</strong>
<ul>
<li>Access to state-of-the-art models like GPT-4 (for select partners).</li>
<li>Advanced features like tool calling, function calling, and the assistance API.</li>
<li>Simplified deployment and infrastructure management.</li>
</ul></li>
<li><strong>Consider Open Source When:</strong>
<ul>
<li>OpenAI’s offerings don’t meet specific needs or violate terms of service.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Additional Insights:</strong>
<ul>
<li>OpenAI’s models, even GPT-3.5, often outperform open-source alternatives, especially for complex tasks and at scale.</li>
<li>OpenAI’s platform offers greater ease of use, especially with features like tool calling and handling API rate limits.</li>
</ul></li>
</ul>
</section>
<section id="moving-from-fine-tuning-to-newer-models" class="level3">
<h3 class="anchored" data-anchor-id="moving-from-fine-tuning-to-newer-models">Moving from Fine-tuning to Newer Models</h3>
<ul>
<li><strong>Observation:</strong> The release of more powerful base models sometimes leads users to abandon fine-tuning in favor of the improved base models.</li>
<li><strong>Factors Influencing the Decision:</strong>
<ul>
<li><strong>Performance Difference:</strong> If the new base model offers substantial improvement, switching might be preferable.</li>
<li><strong>Cost and Latency:</strong> If the performance difference is minimal, sticking with a fine-tuned 3.5 model might be more cost-effective and faster.</li>
</ul></li>
</ul>
</section>
<section id="sustainability-and-future-of-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="sustainability-and-future-of-fine-tuning">Sustainability and Future of Fine-tuning</h3>
<ul>
<li><strong>Concern:</strong> Given Google’s history of discontinuing products, is there a risk of OpenAI doing the same with fine-tuning?</li>
<li><strong>Reassurance:</strong>
<ul>
<li>OpenAI is committed to supporting applications that are successful with fine-tuning.</li>
<li>The company recognizes the investment users make in data preparation and training, and aims to avoid disruption.</li>
<li><strong>Key Takeaway:</strong> OpenAI understands the higher switching cost associated with fine-tuning and aims to provide continued support.</li>
</ul></li>
</ul>
</section>
<section id="data-ownership-and-licensing-for-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="data-ownership-and-licensing-for-fine-tuning">Data Ownership and Licensing for Fine-tuning</h3>
<ul>
<li><strong>Question:</strong> What happens to the data used for fine-tuning in terms of IP and licensing?</li>
<li><strong>Answer:</strong>
<ul>
<li><strong>Data Privacy:</strong> OpenAI never uses customer data for training its foundation models. This is explicitly stated in their privacy policy and terms of service.</li>
<li><strong>Data Control:</strong> Users have complete control over their data’s lifecycle. They can delete it after fine-tuning or retain it for future models.</li>
</ul></li>
</ul>
</section>
<section id="language-model-agents-and-function-calling-internals" class="level3">
<h3 class="anchored" data-anchor-id="language-model-agents-and-function-calling-internals">Language Model Agents and Function Calling Internals</h3>
<ul>
<li><strong>Question:</strong> Are there any impressive examples of OpenAI being used to create successful language model agents?</li>
<li><strong>Answer:</strong>
<ul>
<li>Steven defers to another team specializing in agents and tool calling.</li>
<li><strong>Personal Interest:</strong> Steven finds the GitHub AI workspaces and their agent-like capabilities for coding tasks promising.</li>
</ul></li>
<li><strong>Question:</strong> Is there tension between the abstraction provided by higher-level services (like the assistance API) and fine-tuning, especially regarding data access and transparency?
<ul>
<li><strong>Answer:</strong>
<ul>
<li>Fine-tuned models can be used within the assistance API.</li>
<li>The assistance API primarily aids in context management and tool access, not necessarily replacing fine-tuning.</li>
</ul></li>
</ul></li>
<li><strong>Follow-up Question:</strong> If the assistance API modifies or truncates context, wouldn’t that impact fine-tuning?
<ul>
<li><strong>Answer:</strong>
<ul>
<li>Steven acknowledges the potential issue but lacks specific details about the assistance API’s internal context handling.</li>
</ul></li>
</ul></li>
<li><strong>Question:</strong> Regarding function calling, is it true that JSON schema definitions are translated into a Hyperscript-like format before processing? Can users leverage this for simpler function definitions?
<ul>
<li><strong>Answer:</strong>
<ul>
<li>Steven confirms that all inputs, including JSON schemas, are converted into OpenAI’s internal token format.</li>
<li>He can’t share specifics about the internal representation or translation process.</li>
<li><strong>General Direction:</strong> OpenAI aims to make the default function calling experience (using JSON schemas) the most effective, without requiring users to rely on workarounds or internal knowledge.</li>
</ul></li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-018/</guid>
  <pubDate>Thu, 29 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 17: Language Models on the Command-Line</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-017/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Presentation Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Presentation Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Talk Recording:</strong> <a href="https://www.youtube.com/watch?v=QUXQNi6jQ30">Language models on the command-line w/ Simon Willison</a></li>
<li><strong>Handout:</strong> <a href="https://github.com/simonw/language-models-on-the-command-line/blob/main/README.md">Language models on the command-line</a></li>
</ul>
</div>
</div>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<ul>
<li><strong><a href="https://simonwillison.net/">Simon Willison</a></strong>, creator of <a href="https://datasette.io/">Datasette</a>, Django co-creator, and PSF board member, presents a case for using Unix command line with LLMs.</li>
</ul>
</section>
<section id="unix-command-line-a-perfect-llm-playground" class="level3">
<h3 class="anchored" data-anchor-id="unix-command-line-a-perfect-llm-playground">Unix Command Line: A Perfect LLM Playground</h3>
<ul>
<li><strong>Unix Philosophy</strong>: Tools output information that gets piped into other tools as input.</li>
<li>LLMs function similarly: Prompt input generates responses that can be further processed.</li>
<li><strong>LLM Tool</strong>: A Python command line tool for interacting with LLMs.
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/simonw/llm">https://github.com/simonw/llm</a></li>
<li><strong>Documentation:</strong> <a href="https://llm.datasette.io/en/stable/">https://llm.datasette.io/en/stable/</a></li>
</ul></li>
</ul>
</section>
<section id="installing-llm" class="level3">
<h3 class="anchored" data-anchor-id="installing-llm">Installing LLM</h3>
<ul>
<li><strong>Python Users</strong>: <code>pip install llm</code> (recommended: <code>pipx install llm</code>).</li>
<li><strong>Homebrew Users</strong>: <code>brew install llm</code>.</li>
</ul>
</section>
<section id="using-llm-with-openai" class="level3">
<h3 class="anchored" data-anchor-id="using-llm-with-openai">Using LLM with OpenAI</h3>
<ul>
<li><strong>Setting API Key</strong>:
<ul>
<li><code>llm keys set openAI &lt;your_api_key&gt;</code></li>
</ul></li>
<li><strong>Running Prompts</strong>:
<ul>
<li><code>llm "five great names for a pet pelican"</code></li>
</ul></li>
<li><strong>Saving Output</strong>:
<ul>
<li><code>llm "five great names for a pet pelican" &gt; pelicans.txt</code></li>
</ul></li>
<li><strong>Continuing Conversation</strong>:
<ul>
<li><code>llm -c "now do walruses"</code></li>
</ul></li>
<li><strong>Accessing Logs</strong>:
<ul>
<li><code>llm logs -c &lt;conversation_id&gt;</code> (e.g., to retrieve past responses)</li>
</ul></li>
<li><strong>Viewing Logs in <a href="https://datasette.io/">Datasette</a></strong>:
<ul>
<li><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pipx</span> install datasette</span></code></pre></div></li>
<li><code>llm logs path</code> (provides path to SQLite database)</li>
<li><code>datasette "&lt;path_to_database&gt;"</code> (opens a web interface for browsing conversations).</li>
</ul></li>
<li><strong>Changing Default Model</strong>:
<ul>
<li><code>llm models default</code> (shows the current default model)</li>
<li><code>llm models default -m &lt;model_name&gt;</code> (sets a new default model, e.g., <code>chatGPT</code>).</li>
</ul></li>
</ul>
</section>
<section id="llm-plugins" class="level3">
<h3 class="anchored" data-anchor-id="llm-plugins">LLM Plugins</h3>
<ul>
<li><strong>Plugin Directory</strong>: <a href="https://llm.datasette.io/en/stable/plugins/directory.html">https://llm.datasette.io/en/stable/plugins/directory.html</a></li>
<li><strong>Plugin Types</strong>:
<ul>
<li><strong>Remote API Plugins</strong>: Connect to various LLM providers like Claude, Rekha, Perplexity, AnyScale.</li>
<li><strong>Local Model Plugins</strong>: Enable running models locally on your computer.</li>
</ul></li>
<li><strong>Installing Plugins</strong>:
<ul>
<li><code>llm install &lt;plugin_name&gt;</code> (e.g., <code>llm install llm-claude-3</code>)</li>
</ul></li>
<li><strong>Viewing Installed Plugins</strong>:
<ul>
<li><code>llm plugins</code></li>
</ul></li>
<li><strong>Using Plugin Aliases</strong>:
<ul>
<li><code>llm -m &lt;plugin_alias&gt;</code> (e.g., <code>llm -m haiku</code> to use <code>llm-claude-3-haiku</code>).</li>
</ul></li>
</ul>
</section>
<section id="llm-and-local-models" class="level3">
<h3 class="anchored" data-anchor-id="llm-and-local-models">LLM and Local Models</h3>
<ul>
<li><p><strong>Local Models</strong>: Increasingly effective and accessible through LLM plugins.</p></li>
<li><p><strong>LLM-GPT4all Plugin</strong>: Wrapper around nomic’s <a href="https://github.com/nomic-ai/gpt4all">gpt4all library</a>.</p>
<ul>
<li>Install: <code>llm install llm-gpt4all</code>.</li>
<li>List Models: <code>llm models</code> (includes installed local models).</li>
</ul></li>
<li><p><strong>Example</strong>: Running a local Mistral model:</p>
<ul>
<li><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">llm</span> chat <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-m</span> mistral-7b-instruct-v0 <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"five great names for a pet seagull, explanations"</span></span></code></pre></div></li>
</ul></li>
<li><p><strong>LLM Chat</strong>: A command for persistent chat sessions with local models, avoids repeated loading.</p>
<ul>
<li><code>llm chat -m &lt;model_name&gt;</code> (e.g., <code>llm chat -m "mistral-7b"</code>)</li>
</ul></li>
<li><p><strong>Ollama Integration</strong>:</p>
<ul>
<li><strong><a href="https://ollama.com/">Ollama</a></strong>: A desktop app for managing and running local models.</li>
<li><strong>LLM-Olama Plugin</strong>: Allows using Ollama models within LLM.
<ul>
<li>Install: <code>llm install llm-olama</code>.</li>
<li>Access Ollama models: <code>llm models</code>.</li>
</ul></li>
<li>Example: Using Mixtral through Ollama:
<ul>
<li><code>llm chat -m "mixtral-latest" "Hola en español"</code></li>
</ul></li>
</ul></li>
<li><p><strong><a href="https://github.com/Mozilla-Ocho/llamafile">LlamaFile</a></strong>:</p>
<ul>
<li><strong>Functionality</strong>: A single binary containing both the LLM and the software to run it, compatible across multiple operating systems.</li>
<li><strong>Advantages</strong>: Downloadable, self-contained, acts as an offline backup.</li>
<li><strong>Example</strong>: Running Llama-370b:
<ul>
<li>Download the LlamaFile binary.</li>
<li>Make it executable: <code>chmod +x &lt;llamafile_binary&gt;</code>.</li>
<li>Run: <code>./&lt;llamafile_binary&gt;</code> (starts a web server for interaction).</li>
</ul></li>
<li><strong>LLM-LamaFile Plugin</strong>: Allows using LlamaFile models within LLM.
<ul>
<li>Install: <code>llm install llm-llamafile</code>.</li>
<li>Access LlamaFile models: <code>llm models</code>.</li>
</ul></li>
<li><strong>Lava Model</strong>: A notable LlamaFile model, recommended for its multi-modal capabilities.</li>
</ul></li>
</ul>
</section>
<section id="command-line-scripts-with-llm" class="level3">
<h3 class="anchored" data-anchor-id="command-line-scripts-with-llm">Command Line Scripts with LLM</h3>
<ul>
<li><strong><a href="https://til.simonwillison.net/llms/claude-hacker-news-themes">HN-Summary Script</a></strong>: Summarizes Hacker News posts and conversations using a combination of:
<ul>
<li><code>curl</code> to fetch data from the Hacker News API.</li>
<li><code>jq</code> to process the JSON output.</li>
<li><code>llm</code> with a system prompt to summarize the extracted text.</li>
</ul></li>
<li><strong><a href="https://simonwillison.net/2024/Apr/8/files-to-prompt/">Files-to-Prompt Command</a></strong>: Converts multiple files into a single prompt, including filenames and content.
<ul>
<li>Example: Using LLM to suggest tests for a project:
<ul>
<li><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">files-to-prompt</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>project_directory<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">|</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">llm</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-s</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"suggest tests to add to this project"</span></span></code></pre></div></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="llm-and-shotscraper-for-rag" class="level3">
<h3 class="anchored" data-anchor-id="llm-and-shotscraper-for-rag">LLM and ShotScraper for RAG</h3>
<ul>
<li><strong><a href="https://github.com/simonw/shot-scraper">ShotScraper Tool</a></strong>: A browser automation tool for taking screenshots and executing JavaScript from the command line.</li>
<li><strong>Scraping Google Search Results</strong>:
<ul>
<li>Example: Using ShotScraper and LLM to answer a question using Google search results:
<ul>
<li><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">shot-scraper</span> javascript <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'https://www.google.com/search?q=nytimes+slop'</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb4-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  Array.from(</span></span>
<span id="cb4-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    document.querySelectorAll("h3"),</span></span>
<span id="cb4-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    el =&gt; ({href: el.parentNode.href, title: el.innerText})</span></span>
<span id="cb4-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  )'</span></span></code></pre></div></li>
<li><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">shot-scraper</span> javascript <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'https://www.google.com/search?q=nytimes+slop'</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb5-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  () =&gt; {</span></span>
<span id="cb5-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      function findParentWithHveid(element) {</span></span>
<span id="cb5-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          while (element &amp;&amp; !element.hasAttribute("data-hveid")) {</span></span>
<span id="cb5-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              element = element.parentElement;</span></span>
<span id="cb5-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb5-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          return element;</span></span>
<span id="cb5-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      }</span></span>
<span id="cb5-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      return Array.from(</span></span>
<span id="cb5-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          document.querySelectorAll("h3"),</span></span>
<span id="cb5-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          el =&gt; findParentWithHveid(el).innerText</span></span>
<span id="cb5-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      );</span></span>
<span id="cb5-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  }'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">|</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">llm</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-s</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'describe slop'</span></span></code></pre></div></li>
<li>This script scrapes Google search results for “NY Times slop”, extracts relevant information using JavaScript, and pipes the results to LLM to answer the question “describe slop”.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="llm-and-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="llm-and-embeddings">LLM and Embeddings</h3>
<ul>
<li><p><strong>Embeddings</strong>: Supported through plugins, both API-based and local.</p></li>
<li><p><strong>Viewing Available Embedding Models</strong>:</p>
<ul>
<li><code>llm embed models</code>.</li>
</ul></li>
<li><p><strong>Creating Embeddings</strong>:</p>
<ul>
<li><code>llm embed -m &lt;model_name&gt; "&lt;text_to_embed&gt;"</code>.</li>
</ul></li>
<li><p><strong>Storing Embeddings in SQLite</strong>:</p>
<ul>
<li><strong><code>llm embed multi</code> Command</strong>: Creates a collection of embeddings and stores them in a SQLite database.</li>
<li>Example: Creating embeddings for bookmarks in a blog database:
<ul>
<li><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">curl</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-O</span> https://datasette.simonwillison.net/simonwillisonblog.db</span>
<span id="cb6-2">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">llm</span> embed-multi links <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb6-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-d</span> simonwillisonblog.db <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb6-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--sql</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'select id, link_url, link_title, commentary from blog_blogmark'</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb6-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-m</span> 3-small <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--store</span></span></code></pre></div></li>
<li>This command creates a collection called “links”, embeds bookmarks from the specified database, uses the “text-embedding-ada-002” model, and stores both text and embeddings in the database.</li>
</ul></li>
</ul></li>
<li><p><strong>Searching with Embeddings</strong>:</p>
<ul>
<li><strong><code>llm similar</code> Command</strong>: Finds similar items in a collection based on embedding similarity.</li>
<li>Example: Searching for bookmarks related to “things that make me angry”:
<ul>
<li><div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">llm</span> similar links <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb7-2">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-d</span> simonwillisonblog.db <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb7-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'things that make me angry'</span></span></code></pre></div></li>
</ul></li>
</ul></li>
<li><p><strong>Combining Embeddings and RAG</strong>:</p>
<ul>
<li>Example: Searching for data set plugins and summarizing the most interesting ones:
<ul>
<li><div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">llm</span> similar <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> links <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-d</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>database_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"datasette plugins"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">|</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">llm</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-s</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"most interesting plugins"</span></span></code></pre></div></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="building-a-rag-system-with-llm" class="level3">
<h3 class="anchored" data-anchor-id="building-a-rag-system-with-llm">Building a RAG System with LLM</h3>
<ul>
<li><strong><code>blog-answer</code> Script</strong>: A bash script demonstrating a full RAG Q&amp;A workflow using:
<ul>
<li>Embedding search against paragraphs in a blog.</li>
<li>JQ for data processing.</li>
<li>A local LlamaFile model (or other models) for question answering.</li>
</ul></li>
<li><strong>Limitations of SQLite for Large Datasets</strong>:
<ul>
<li>Brute force search becomes inefficient for very large datasets.</li>
<li>Consider specialized vector indexes (SQLite-based or external like Pinecone) for better performance.</li>
</ul></li>
<li><strong>Future Goals</strong>:
<ul>
<li>Integrating support for external vector indexes within LLM.</li>
</ul></li>
<li><strong>Python API</strong>:
<ul>
<li><code>pip install llm</code> provides a Python API for accessing LLM functionalities.</li>
</ul></li>
</ul>
</section>
<section id="qa-highlights" class="level2">
<h2 class="anchored" data-anchor-id="qa-highlights">Q&amp;A Highlights</h2>
<section id="hugging-face-hub-models" class="level3">
<h3 class="anchored" data-anchor-id="hugging-face-hub-models">Hugging Face Hub Models</h3>
<ul>
<li><strong>No plugins currently exist for Hugging Face Hub models</strong> in LLM due to Simon’s lack of an NVIDIA GPU (required for most Hugging Face models).</li>
<li><strong>Opportunity for contribution</strong>: Anyone with an NVIDIA GPU is encouraged to write an LLM plugin for Hugging Face models.</li>
<li>Other serving technologies for Hugging Face models (e.g., vLLM) are also worth exploring.</li>
</ul>
</section>
<section id="serverless-inference" class="level3">
<h3 class="anchored" data-anchor-id="serverless-inference">Serverless Inference</h3>
<ul>
<li>LLM supports various <strong>API-based models</strong> through plugins (e.g., AnyScale, Fireworks, Open Router).</li>
<li><strong>OpenAI compatible models</strong> can be configured directly within LLM without writing plugins.</li>
<li><strong>Hugging Face Inference API</strong>: Potentially exciting opportunity for a new LLM plugin.</li>
</ul>
</section>
<section id="agentic-workflows" class="level3">
<h3 class="anchored" data-anchor-id="agentic-workflows">Agentic Workflows</h3>
<ul>
<li><strong>Not yet supported</strong> in LLM due to the lack of function calling functionality.</li>
<li><strong>Future plans</strong>: Function calling support and potential LLM agents plugin.</li>
<li><strong>Python API</strong>: Offers a way to access LLM functionalities from Python code, but the interface is still under development.</li>
</ul>
</section>
<section id="productivity-tips-from-simon-willison" class="level3">
<h3 class="anchored" data-anchor-id="productivity-tips-from-simon-willison">Productivity Tips from Simon Willison</h3>
<ul>
<li><strong>Blog Post:</strong> <a href="https://simonwillison.net/2022/Nov/26/productivity/">Coping strategies for the serial project hoarder</a></li>
<li><strong>Importance of Unit Tests and Documentation</strong>: Enables revisiting and continuing projects easily.</li>
<li><strong>Focus on Quick Projects</strong>: Leverage existing expertise to build cool things rapidly.</li>
<li><strong>GitHub Issues for Comprehensive Note-Taking</strong>: Use GitHub issues to document every step of a project, facilitating TIL writing and future reference.
<ul>
<li><strong>Example:</strong> <a href="https://github.com/simonw/public-notes/issues/1">Figure out how to serve an AWS Lambda function with a Function URL from a custom subdomain</a></li>
</ul></li>
</ul>
</section>
<section id="hardware-and-local-model-performance" class="level3">
<h3 class="anchored" data-anchor-id="hardware-and-local-model-performance">Hardware and Local Model Performance</h3>
<ul>
<li><strong>Simon’s Hardware</strong>: M2 Max with 64 GB RAM.</li>
<li><strong>Local Model Performance</strong>: Runs Mistral and other small models flawlessly, Llama-370b requires 40 GB RAM.</li>
<li><strong>Apple Silicon’s future</strong>: Potentially a powerful platform for running local models with the development of Apple’s MLX library.</li>
</ul>
</section>
<section id="running-llm-on-iphones" class="level3">
<h3 class="anchored" data-anchor-id="running-llm-on-iphones">Running LLM on iPhones</h3>
<ul>
<li><strong><a href="https://apps.apple.com/us/app/mlc-chat/id6448482937">MLC Chat App</a></strong>: Allows running Mistral directly on iPhones, enabling offline LLM access.</li>
</ul>
</section>
<section id="apples-approach-to-llms" class="level3">
<h3 class="anchored" data-anchor-id="apples-approach-to-llms">Apple’s Approach to LLMs</h3>
<ul>
<li><strong>Focused on specific features</strong>: Emphasizes using LLMs for functionalities like summarization and copy editing, avoiding the complexities of general chatbots.</li>
</ul>
</section>
<section id="value-of-running-local-llms" class="level3">
<h3 class="anchored" data-anchor-id="value-of-running-local-llms">Value of Running Local LLMs</h3>
<ul>
<li><strong>Exploration and Learning</strong>: Provides hands-on experience with different models, including less performant ones, which helps understand their strengths and weaknesses.</li>
<li><strong>Privacy</strong>: Keeps sensitive data on your local machine.</li>
<li><strong>Offline Access</strong>: Essential for situations without internet connectivity (e.g., flights, post-apocalyptic scenarios).</li>
</ul>
</section>
<section id="llm-evaluation-tool-in-development" class="level3">
<h3 class="anchored" data-anchor-id="llm-evaluation-tool-in-development">LLM Evaluation Tool (In Development)</h3>
<ul>
<li><strong>Goals</strong>:
<ul>
<li>Record evaluation results in SQLite.</li>
<li>Build an interface for comparing model responses and collecting human feedback (similar to <a href="https://lmarena.ai/">LM Arena</a>).</li>
</ul></li>
<li><strong>Advantages of SQLite</strong>:
<ul>
<li>Fast, free, universally available.</li>
<li>Works as a portable file format for sharing evaluation data.</li>
</ul></li>
</ul>
</section>
<section id="benchmarking-and-logging" class="level3">
<h3 class="anchored" data-anchor-id="benchmarking-and-logging">Benchmarking and Logging</h3>
<ul>
<li><strong>Planned Feature</strong>: Log latency, token count, and duration of LLM operations in the SQLite database.</li>
<li><strong>Challenges</strong>: Determining token counts for models that don’t provide this information.</li>
</ul>
</section>
<section id="running-llm-on-multiple-machines" class="level3">
<h3 class="anchored" data-anchor-id="running-llm-on-multiple-machines">Running LLM on Multiple Machines</h3>
<ul>
<li><strong>Solution</strong>: Leverage existing tools like <a href="https://www.ansible.com/">Ansible</a> to run LLM commands in parallel on different machines within a LAN.</li>
<li><strong>Unix Flexibility</strong>: Highlights the ability to combine LLM with other Unix tools for customized workflows and automation.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-017/</guid>
  <pubDate>Thu, 29 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 16: A Deep Dive on LLM Evaluation</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-016/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Presentation Slides">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Presentation Slides
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Slides:</strong> <a href="https://docs.google.com/presentation/d/1qTaDYqLCgxkUaTfxQkN1it4tx6_jixwv9ZtsbqQgE4U/">A Deep Dive on LM Evaluation</a></li>
</ul>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li><strong>Speaker:</strong> Hailey Schoelkopf, Research Scientist at Eleuther AI</li>
<li><strong>Topic:</strong> Deep dive into the challenges and best practices of Large Language Model (LLM) evaluation.</li>
</ul>
<section id="about-the-speaker" class="level3">
<h3 class="anchored" data-anchor-id="about-the-speaker">About the Speaker</h3>
<ul>
<li><strong>Hailey Schoelkopf:</strong>
<ul>
<li>Research Scientist at Eleuther AI.</li>
<li>Maintainer of the <strong>LM Evaluation Harness</strong>, a widely used open-source library for evaluating LLMs.</li>
</ul></li>
</ul>
</section>
<section id="about-eleuther-ai" class="level3">
<h3 class="anchored" data-anchor-id="about-eleuther-ai">About Eleuther AI:</h3>
<ul>
<li><strong>Website:</strong> <a href="https://eleuther.ai/">https://eleuther.ai/</a></li>
<li><strong>Project Page:</strong> <a href="https://www.eleuther.ai/projects/large-language-model-evaluation">Evaluating LLMs</a></li>
<li><strong>Non-profit research lab</strong> known for:
<ul>
<li>Releasing open-source LLMs like GPT-J and GPT-NeoX-20B.</li>
<li>Research on:
<ul>
<li>Model Interpretability</li>
<li>Datasets</li>
<li>Distributed Training</li>
<li>LLM Evaluation</li>
</ul></li>
<li>Building and maintaining tools for the open-source AI ecosystem.</li>
</ul></li>
</ul>
</section>
<section id="lm-evaluation-harness" class="level3">
<h3 class="anchored" data-anchor-id="lm-evaluation-harness">LM Evaluation Harness</h3>
<ul>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/EleutherAI/lm-evaluation-harness">https://github.com/EleutherAI/lm-evaluation-harness</a></li>
<li><strong>Purpose:</strong>
<ul>
<li>Originally created to reproduce and track the evaluations from the GPT-3 paper.</li>
<li>Evolved into a comprehensive library for evaluating LLMs.</li>
</ul></li>
<li><strong>Usage:</strong>
<ul>
<li>Widely used by researchers and practitioners.</li>
<li>Powers the backend for the OpenLLM Leaderboard.</li>
</ul></li>
</ul>
</section>
</section>
<section id="challenges-in-llm-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="challenges-in-llm-evaluation">Challenges in LLM Evaluation</h2>
<section id="scoring-difficulties" class="level4">
<h4 class="anchored" data-anchor-id="scoring-difficulties">1. Scoring Difficulties</h4>
<ul>
<li><strong>Core Issue:</strong> Reliably evaluating the correctness of LLM responses in natural language.</li>
<li><strong>Challenges:</strong>
<ul>
<li><strong>Subjectivity of Language:</strong> What constitutes a “correct” response can be subjective and context-dependent.</li>
<li><strong>Hallucination:</strong> LLMs can generate plausible-sounding but incorrect information, making it challenging to determine accuracy based on surface-level analysis.</li>
<li><strong>Lack of Standardized Metrics:</strong> Absence of universally agreed-upon metrics for evaluating LLM performance across different tasks and domains.</li>
</ul></li>
</ul>
</section>
<section id="reproducibility-issues" class="level4">
<h4 class="anchored" data-anchor-id="reproducibility-issues">2. Reproducibility Issues</h4>
<ul>
<li><strong>Importance:</strong> Ensuring that evaluation results are consistent and replicable.</li>
<li><strong>Challenges:</strong>
<ul>
<li><strong>Sensitivity to Implementation Details:</strong> LLM performance can vary significantly based on seemingly minor differences in implementation, such as tokenization, prompt formatting, and hyperparameters.</li>
<li><strong>Lack of Transparency:</strong> Limited sharing of evaluation code and detailed methodologies makes it difficult for others to reproduce results.</li>
<li><strong>Data Set Variability:</strong> Differences in data set composition and quality can lead to inconsistent evaluations.</li>
</ul></li>
</ul>
</section>
</section>
<section id="common-llm-evaluation-methods" class="level2">
<h2 class="anchored" data-anchor-id="common-llm-evaluation-methods">Common LLM Evaluation Methods</h2>
<section id="log-likelihoods-assessing-the-probability-of-expected-outputs" class="level4">
<h4 class="anchored" data-anchor-id="log-likelihoods-assessing-the-probability-of-expected-outputs">1. Log Likelihoods: Assessing the Probability of Expected Outputs</h4>
<ul>
<li><p><strong>Background:</strong></p>
<ul>
<li>LLMs output a probability distribution over vocabulary for each possible next token.</li>
<li>This distribution represents the model’s confidence in different words following the given input.</li>
</ul></li>
<li><p><strong>How It Works:</strong></p>
<ul>
<li><p><strong>Input:</strong> A prompt (X) and a potential output (Y).</p></li>
<li><p><strong>Process:</strong> Calculate the probability of the model generating Y given X. This involves summing the log probabilities of each token in Y, conditioned on the preceding tokens in X and Y.</p>
<ul>
<li><p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20P(y%7Cx)%20=%20%5Csum_%7Bi=0%7D%5E%7Bm-1%7D%20%5Clog%20p(y_i%20%7C%20x,%20y_0,%20%5Cldots,%20y_%7Bi-1%7D)%20=%20%5Csum_%7Bi=0%7D%5E%7Bm-1%7D%20l(n+i,%20y_%7Bi%7D)%0A"></p></li>
<li><p>where <img src="https://latex.codecogs.com/png.latex?%5Clog%20p(y_i%20%7C%20x,%20y_0,%20%5Cldots,%20y_%7Bi-1%7D)"> is the log probability of the <img src="https://latex.codecogs.com/png.latex?i">-th target token conditioned on the full input <img src="https://latex.codecogs.com/png.latex?x"> and the preceding target tokens. (and where <img src="https://latex.codecogs.com/png.latex?x,%20y_0,%20%5Cldots,%20y_%7Bi-1%7D"> denotes conditioning on only <img src="https://latex.codecogs.com/png.latex?x">.).</p></li>
</ul></li>
<li><p><strong>Example:</strong> For the prompt “The cow jumped over the,” calculate the probability of the model generating “moon” versus other words.</p></li>
</ul></li>
<li><p><strong>Use Case: Multiple Choice Question Answering</strong></p>
<ul>
<li><strong>Advantages:</strong>
<ul>
<li>Computationally cheaper than generation-based evaluation.</li>
<li>Avoids issues with parsing errors in generated text.</li>
<li>Suitable for evaluating smaller LLMs or those in early training stages.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>Limited real-world applicability compared to open-ended generation.</li>
<li>Doesn’t assess a model’s ability to formulate its own answers.</li>
<li>Cannot evaluate chain-of-thought reasoning.</li>
</ul></li>
</ul></li>
<li><p><strong>Challenges with Log Likelihoods and Perplexity:</strong></p>
<ul>
<li><strong>Tokenizer Sensitivity:</strong> Metrics are affected by the specific tokenizer used, making comparisons between models with different tokenizers difficult.
<ul>
<li><strong>Solution:</strong> Implement normalization techniques to account for tokenizer variations.</li>
</ul></li>
<li><strong>Limited Information:</strong> Log likelihoods only consider the probability of a given output, not its overall quality, coherence, or factual accuracy.</li>
</ul></li>
</ul>
</section>
<section id="perplexity-measuring-how-well-a-model-fits-a-data-distribution" class="level4">
<h4 class="anchored" data-anchor-id="perplexity-measuring-how-well-a-model-fits-a-data-distribution">2. Perplexity: Measuring How Well a Model Fits a Data Distribution</h4>
<ul>
<li><p><strong>Concept:</strong> Quantifies how well a language model predicts a given text, indicating its familiarity with the data distribution.</p></li>
<li><p><strong>Calculation:</strong> Based on the average per-token log probability of the text, with lower perplexity indicating a better fit to the data.</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BPPL%7D%20=%20%5Cexp%20%5Cleft(%20-%5Cfrac%7B1%7D%7B%5Csum_%7Bj=1%7D%5E%7B%7CD%7C%7D%20N_j%7D%20%5Csum_%7Bj=1%7D%5E%7B%7CD%7C%7D%20%5Csum_%7Bi=1%7D%5E%7BN_j%7D%20%5Clog%20P(y_%7Bji%7D%20%7C%20y_%7Bj1%7D,%20%5Cldots,%20y_%7Bji-1%7D)%20%5Cright)%0A"></li>
</ul></li>
<li><p><strong>Use Case:</strong> Evaluating a model’s understanding of a specific text corpus (e.g., Wikipedia).</p></li>
<li><p><strong>Limitations:</strong></p>
<ul>
<li><strong>Domain Specificity:</strong> Perplexity on one dataset (e.g., Wikipedia) may not generalize to other domains or tasks.</li>
<li><strong>Limited Insight into Downstream Performance:</strong> A low perplexity doesn’t guarantee good performance in real-world applications like chatbots or question answering.</li>
</ul></li>
</ul>
</section>
<section id="text-generation-evaluating-real-world-output-but-facing-scoring-challenges" class="level4">
<h4 class="anchored" data-anchor-id="text-generation-evaluating-real-world-output-but-facing-scoring-challenges">3. Text Generation: Evaluating Real-World Output but Facing Scoring Challenges</h4>
<ul>
<li><strong>Importance:</strong> Crucial for assessing LLMs in tasks involving text generation (e.g., chatbots, story writing).</li>
<li><strong>Challenges:</strong>
<ul>
<li><strong>Scoring Free-Form Text:</strong> Determining the correctness and quality of generated text is difficult.
<ul>
<li>Simple heuristics (e.g., keyword matching) are unreliable and prone to gaming.</li>
<li>Human evaluation is expensive and time-consuming.</li>
<li>LLM-based judges introduce their own biases and limitations.</li>
</ul></li>
<li><strong>Sensitivity to Prompt Details:</strong> Minor variations in prompts (e.g., trailing whitespace) can drastically impact results, hindering reproducibility.
<ul>
<li><strong>Example:</strong> In code generation, a trailing tab in the prompt can create syntax errors for models that generate code with specific formatting, leading to artificially lower performance scores.</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="the-need-for-reproducibility-and-best-practices" class="level2">
<h2 class="anchored" data-anchor-id="the-need-for-reproducibility-and-best-practices">The Need for Reproducibility and Best Practices</h2>
<ul>
<li><strong>Reproducibility is Crucial:</strong> Ensuring that evaluation results can be independently verified is essential for:
<ul>
<li><strong>Fair Model Comparisons:</strong> Accurately assessing the relative performance of different LLMs.</li>
<li><strong>Meaningful Progress Tracking:</strong> Tracking improvements in model development and evaluation methods.</li>
</ul></li>
<li><strong>Challenges to Reproducibility:</strong>
<ul>
<li>Lack of standardized evaluation practices and metrics.</li>
<li>Incomplete reporting of evaluation details (e.g., prompts, code, evaluation settings).</li>
</ul></li>
<li><strong>Best Practices for Reproducible LLM Evaluation:</strong>
<ul>
<li><strong>Share Evaluation Code:</strong> Publicly release code used for evaluation to allow for scrutiny and replication of results.</li>
<li><strong>Detailed Reporting:</strong> Provide comprehensive information about evaluation procedures, including:
<ul>
<li>Specific prompts and instructions given to models.</li>
<li>Data preprocessing steps and evaluation datasets used.</li>
<li>Evaluation metrics and their calculation.</li>
</ul></li>
<li><strong>Use Standardized Evaluation Frameworks:</strong> Leverage libraries like the <code>lm-evaluation-harness</code> or other tools (Helm, OpenCompass) to promote consistency and reduce implementation discrepancies.
<ul>
<li><strong><code>lm-evaluation-harness</code>:</strong> <a href="https://github.com/EleutherAI/lm-evaluation-harness">GitHub Repository</a></li>
<li><strong><code>helm</code>:</strong> <a href="https://github.com/stanford-crfm/helm">GitHub Repository</a></li>
<li><strong><code>opencompass</code>:</strong> <a href="https://github.com/open-compass/opencompass">GitHub Repository</a></li>
</ul></li>
</ul></li>
<li><strong>Distinction Between Model Evals and Downstream Evals:</strong>
<ul>
<li><strong>Model Evals (e.g., MMLU benchmark):</strong> Measure general language understanding and capabilities across diverse tasks.</li>
<li><strong>Downstream Evals:</strong> Focus on performance in a specific application or domain (e.g., chatbot for customer support).</li>
<li>Prioritize Downstream Evals whenever possible for production settings, as they directly reflect real-world performance needs.</li>
<li><strong>OpenLLM Leaderboard:</strong> <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</a></li>
<li><strong>MMLU Benchmark:</strong> <a href="https://paperswithcode.com/dataset/mmlu">https://paperswithcode.com/dataset/mmlu</a></li>
<li><strong>HellaSwag Benchmark:</strong> <a href="https://paperswithcode.com/dataset/hellaswag">https://paperswithcode.com/dataset/hellaswag</a></li>
<li><strong>ARC Benchmark:</strong> <a href="https://paperswithcode.com/dataset/arc">https://paperswithcode.com/dataset/arc</a>
<ul>
<li>ARC focuses on generalization and multi-step reasoning, making it more challenging than benchmarks that rely heavily on memorization.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<ul>
<li><strong>Implementation Details Matter:</strong> LLMs are highly sensitive to minor variations in evaluation procedures.</li>
<li><strong>Transparency and Standardization are Key:</strong> Sharing code, detailed reporting, and using standardized frameworks are crucial for reproducible LLM evaluation.</li>
<li><strong>Prioritize Downstream Evaluations:</strong> Focus on evaluations that directly measure performance in your specific application context.</li>
<li><strong>For Further Exploration:</strong>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2405.14782"><em>Lessons from the Trenches on Reproducible Evaluation of Language Models</em></a> (Eleuther AI)</li>
<li><strong>Library:</strong> <a href="https://github.com/EleutherAI/lm-evaluation-harness"><code>lm-evaluation-harness</code></a> (Eleuther AI)</li>
</ul></li>
</ul>
<section id="qa-highlights" class="level3">
<h3 class="anchored" data-anchor-id="qa-highlights">Q&amp;A Highlights:</h3>
<ul>
<li><strong>Dataset Quality:</strong> Errors or biases in benchmark datasets can significantly affect evaluation results and limit the usefulness of benchmarks.</li>
<li><strong>Overfitting to Evaluations:</strong> Repeatedly optimizing for a specific benchmark can lead to overfitting, where models excel on the benchmark but fail to generalize to other tasks or data.</li>
<li><strong>Measurement Validity:</strong> It’s essential to ensure that evaluation metrics accurately measure the desired aspects of LLM performance (e.g., factual accuracy, reasoning, coherence).</li>
<li><strong>LLMs as Judges:</strong>
<ul>
<li><strong>Benefits:</strong> LLMs can potentially automate the evaluation of tasks requiring nuanced understanding and reasoning, which are difficult to assess with simple heuristics.</li>
<li><strong>Considerations:</strong>
<ul>
<li><strong>Judge Model Selection:</strong> Carefully choose an LLM judge that possesses the necessary capabilities for the task being evaluated.</li>
<li><strong>Judge Model Limitations:</strong> Be aware of the judge model’s own biases and limitations, as these can influence the evaluation outcomes.</li>
</ul></li>
</ul></li>
<li><strong>Reliable Multiple-Choice Answers Without Additional Text:</strong>
<ul>
<li><strong>Structured Generation:</strong> Use techniques that constrain the model’s output to specific formats.</li>
<li><strong>System Prompts:</strong> Provide clear instructions to the model to only output the answer.</li>
<li><strong>Log Likelihoods:</strong> Rely on log likelihood-based multiple-choice evaluations if structured generation isn’t possible.</li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-016/</guid>
  <pubDate>Thu, 29 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Chip War Book Notes</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/chip-war-book-notes/</link>
  <description><![CDATA[ 




<ul>
<li>Cast of Characters</li>
<li>Introduction</li>
<li>Part 1꞉ Cold War Chips</li>
<li>Part 2꞉ The Circuitry of the American World</li>
<li>Part 3꞉ Leadership Lost?</li>
<li>Part 4꞉ America Resurgent</li>
<li>Part 5꞉ Integrated Circuits, Integrated World?</li>
<li>Part 6꞉ Offshoring Innovation?</li>
<li>Part 7꞉ China’s Challenge</li>
<li>Part 8꞉ The Chip Choke</li>
<li>Conclusion</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Book Links">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Book Links
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://www.simonandschuster.com/books/Chip-War/Chris-Miller/9781982172008">Publisher Page</a></li>
<li><a href="https://www.christophermiller.net/">Author’s Website</a></li>
</ul>
</div>
</div>
<section id="cast-of-characters" class="level2">
<h2 class="anchored" data-anchor-id="cast-of-characters">Cast of Characters</h2>
<section id="semiconductor-industry-leaders" class="level3">
<h3 class="anchored" data-anchor-id="semiconductor-industry-leaders">Semiconductor Industry Leaders</h3>
<ul>
<li><strong>Morris Chang:</strong>
<ul>
<li>Founder of Taiwan Semiconductor Manufacturing Company (TSMC), the world’s most important chipmaker.</li>
<li>Former senior executive at Texas Instruments.</li>
</ul></li>
<li><strong>Andy Grove:</strong>
<ul>
<li>Former president and CEO of Intel (1980s-1990s).</li>
<li>Known for aggressive style and success in reviving Intel.</li>
<li>Author of “Only the Paranoid Survive.”</li>
</ul></li>
<li><strong>Pat Haggerty:</strong>
<ul>
<li>Chairman of Texas Instruments.</li>
<li>Led the company’s specialization in microelectronics, including for the U.S. military.</li>
</ul></li>
<li><strong>Jack Kilby:</strong>
<ul>
<li>Co-inventor of the Integrated Circuit (1958).</li>
<li>Long-time Texas Instruments employee.</li>
<li>Nobel Prize winner.</li>
</ul></li>
<li><strong>Jay Lathrop:</strong>
<ul>
<li>Co-inventor of photolithography (the process of patterning transistors using specialized chemicals and light).</li>
<li>Formerly of Texas Instruments.</li>
</ul></li>
<li><strong>Carver Mead:</strong>
<ul>
<li>Professor at the California Institute of Technology (Caltech).</li>
<li>Advisor to Fairchild Semiconductor and Intel.</li>
<li>Visionary thinker about the future of technology.</li>
</ul></li>
<li><strong>Gordon Moore:</strong>
<ul>
<li>Co-founder of Fairchild Semiconductor and Intel.</li>
<li>Creator of <strong>Moore’s Law</strong> (1965), which predicted that computing power on each chip would double every couple of years.</li>
</ul></li>
<li><strong>Robert Noyce:</strong>
<ul>
<li>Co-founder of Fairchild Semiconductor and Intel.</li>
<li>Co-inventor of the integrated circuit (1959).</li>
<li>Known as the “Mayor of Silicon Valley.”</li>
<li>First leader of Sematech.</li>
</ul></li>
<li><strong>Jerry Sanders:</strong>
<ul>
<li>Founder and CEO of AMD.</li>
<li>Known as Silicon Valley’s most flamboyant salesman.</li>
<li>Aggressive critic of unfair Japanese trade practices in the 1980s.</li>
</ul></li>
<li><strong>Charlie Sporck:</strong>
<ul>
<li>Drove the offshoring of chip assembly while leading manufacturing operations at Fairchild Semiconductor.</li>
<li>Later became CEO of National Semiconductor.</li>
</ul></li>
<li><strong>Ren Zhengfei:</strong>
<ul>
<li>Founder of Huawei, China’s telecom and chip design giant.</li>
<li>His daughter, Meng Wanzhou, was arrested in Canada in 2018 on charges of violating U.S. law and trying to evade U.S. sanctions.</li>
</ul></li>
</ul>
</section>
<section id="other-notable-figures" class="level3">
<h3 class="anchored" data-anchor-id="other-notable-figures">Other Notable Figures</h3>
<ul>
<li><strong>Akio Morita:</strong>
<ul>
<li>Co-founder of Sony.</li>
<li>Co-author of “The Japan That Can Say No.”</li>
<li>Represented Japanese business on the world stage during the 1970s and 1980s.</li>
</ul></li>
<li><strong>William Perry:</strong>
<ul>
<li>Pentagon official (1977-1981), and later Secretary of Defense (1994-1997).</li>
<li>Advocated using chips to produce precision strike weapons.</li>
</ul></li>
</ul>
</section>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<section id="a-critical-strait-an-obscure-regulation" class="level3">
<h3 class="anchored" data-anchor-id="a-critical-strait-an-obscure-regulation">A Critical Strait &amp; An Obscure Regulation</h3>
<ul>
<li>On August 18, 2020, the USS Mustin sailed through the Taiwan Strait, a waterway increasingly fraught with geopolitical tension.</li>
<li>This show of force underscored a new reality: <strong>the battle for technological dominance, particularly in semiconductors, has become central to the rivalry between the United States and China.</strong></li>
<li>While the U.S. Navy patrolled the strait, Chinese leaders were more concerned about a U.S. Commerce Department regulation called the <strong>Entity List,</strong> which restricts technology exports.</li>
<li>This regulation targeted <strong>Huawei</strong>, a Chinese tech giant, barring it from buying advanced computer chips made with U.S. technology.
<ul>
<li>This action revealed China’s dependence on foreign-made chips, the essential building blocks of all modern electronics.</li>
<li><strong>China now spends more on importing chips than on oil.</strong></li>
</ul></li>
</ul>
</section>
<section id="the-significance-of-semiconductors" class="level3">
<h3 class="anchored" data-anchor-id="the-significance-of-semiconductors">The Significance of Semiconductors</h3>
<ul>
<li><strong>Semiconductors, also known as integrated circuits or chips, are the foundation of modern technology.</strong>
<ul>
<li>They power everything from smartphones and refrigerators to military systems and artificial intelligence.</li>
</ul></li>
<li><strong>Moore’s Law:</strong> In 1965, Gordon Moore observed that the number of transistors on a chip doubles approximately every two years, leading to exponential growth in computing power.
<ul>
<li>This prediction has held true for over half a century, driving the digital revolution.</li>
</ul></li>
<li><strong>Chips have become ubiquitous and essential:</strong>
<ul>
<li>They are found in nearly every device that requires computing power.</li>
<li>The global economy and our daily lives are deeply reliant on a steady supply of increasingly powerful chips.</li>
</ul></li>
</ul>
</section>
<section id="the-rise-of-silicon-valley-and-the-global-chip-supply-chain" class="level3">
<h3 class="anchored" data-anchor-id="the-rise-of-silicon-valley-and-the-global-chip-supply-chain">The Rise of Silicon Valley and the Global Chip Supply Chain</h3>
<ul>
<li><strong>Silicon Valley became the epicenter of the semiconductor revolution due to a unique confluence of factors:</strong>
<ul>
<li>Scientific Expertise: Proximity to universities like Stanford and Berkeley, and access to defense funding.</li>
<li>Manufacturing Know-How: Availability of engineers experienced in aviation and radio technologies.</li>
<li>Entrepreneurial Spirit: A culture that attracted ambitious individuals from around the world.</li>
</ul></li>
<li><strong>The complexity of chipmaking led to a highly specialized and interconnected global supply chain:</strong>
<ul>
<li>Chip Design: Often involves companies in the US, UK, Japan, and Israel.</li>
<li>Raw Materials: Ultra-pure silicon wafers and gases primarily come from Japan.</li>
<li>Manufacturing Equipment: Highly specialized machines are produced by a handful of companies, primarily in the Netherlands, Japan, and California.</li>
<li>Fabrication: Companies in Taiwan, South Korea, and other Asian countries play a major role.</li>
<li>Assembly and Testing: Often done in Southeast Asia.</li>
</ul></li>
<li><strong>This intricate system has enabled the incredible progress predicted by Moore’s Law but has also created vulnerabilities.</strong></li>
</ul>
</section>
<section id="taiwan-the-geopolitical-linchpin-of-the-chip-industry" class="level3">
<h3 class="anchored" data-anchor-id="taiwan-the-geopolitical-linchpin-of-the-chip-industry">Taiwan: The Geopolitical Linchpin of the Chip Industry</h3>
<ul>
<li><strong>Taiwan’s TSMC (Taiwan Semiconductor Manufacturing Company) plays a critical role in the global chip supply:</strong>
<ul>
<li>Produces the world’s most advanced processor chips, powering devices like iPhones.</li>
<li>Responsible for fabricating a third of the world’s new computing power each year.</li>
</ul></li>
<li><strong>This reliance on Taiwan has become a major geopolitical concern:</strong>
<ul>
<li>The island is claimed by China, which considers it a renegade province.</li>
<li>Any disruption to chip production in Taiwan, whether from natural disasters, accidents, or political conflict, would have severe consequences for the global economy.</li>
</ul></li>
</ul>
</section>
<section id="the-vulnerability-of-the-semiconductor-supply-chain" class="level3">
<h3 class="anchored" data-anchor-id="the-vulnerability-of-the-semiconductor-supply-chain">The Vulnerability of the Semiconductor Supply Chain</h3>
<ul>
<li><strong>The COVID-19 pandemic exposed the fragility of the global chip supply chain:</strong>
<ul>
<li>Factory shutdowns, logistical bottlenecks, and fluctuating demand led to widespread chip shortages.</li>
<li>Industries like automotive manufacturing faced production halts due to the lack of essential chips.</li>
</ul></li>
<li><strong>This vulnerability stems from the high concentration of production and specialized expertise in a few key locations:</strong>
<ul>
<li>Earthquakes, political instability, or even targeted attacks could severely disrupt global chip production.</li>
</ul></li>
</ul>
</section>
<section id="the-semiconductor-race-and-the-future-of-global-power" class="level3">
<h3 class="anchored" data-anchor-id="the-semiconductor-race-and-the-future-of-global-power">The Semiconductor Race and the Future of Global Power</h3>
<ul>
<li><strong>The U.S. and China recognize the strategic importance of semiconductors:</strong>
<ul>
<li>Both countries are investing heavily in domestic chip production and research.</li>
<li>The outcome of this technological competition will have major implications for economic and military power.</li>
</ul></li>
<li><strong>Taiwan’s central role in chipmaking adds a dangerous layer to the US-China rivalry:</strong>
<ul>
<li>China’s ambitions towards Taiwan pose a significant threat to the global chip supply.</li>
<li>The U.S. is committed to defending Taiwan, raising the stakes of a potential conflict.</li>
</ul></li>
<li><strong>The complex history of the semiconductor industry, driven by technological innovation, economic efficiency, and government policies, has created a world deeply reliant on a handful of companies and vulnerable to disruption.</strong></li>
</ul>
</section>
<section id="conclusion-a-world-defined-and-imperiled-by-chips" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-a-world-defined-and-imperiled-by-chips">Conclusion: A World Defined and Imperiled by Chips</h3>
<ul>
<li>Semiconductors have become the foundation of modern life, shaping everything from smartphones to military systems.</li>
<li>The intricate global supply chain that produces these chips is a marvel of efficiency but also a point of vulnerability.</li>
<li>The concentration of advanced chip manufacturing in Taiwan, particularly by TSMC, has turned the island into a critical geopolitical linchpin.</li>
<li>The rivalry between the United States and China, coupled with the strategic importance of semiconductors, has created a situation of unprecedented risk.</li>
<li>Understanding the history and interconnectedness of the global chip industry is essential for navigating the challenges and opportunities of the 21st century.</li>
</ul>
<hr>
</section>
</section>
<section id="chapter-1-from-steel-to-silicon" class="level2">
<h2 class="anchored" data-anchor-id="chapter-1-from-steel-to-silicon">Chapter 1: From Steel to Silicon</h2>
<section id="world-war-ii-a-typhoon-of-steel" class="level3">
<h3 class="anchored" data-anchor-id="world-war-ii-a-typhoon-of-steel">World War II: A “Typhoon of Steel”</h3>
<ul>
<li>Japanese soldiers described World War II as a “typhoon of steel.”</li>
</ul>
<section id="akio-moritas-wartime-experience" class="level4">
<h4 class="anchored" data-anchor-id="akio-moritas-wartime-experience">Akio Morita’s Wartime Experience</h4>
<ul>
<li><strong>Akio Morita</strong>, a young engineer from a family of sake merchants, narrowly avoided front-line service in World War II due to his assignment to a Japanese Navy engineering lab.</li>
<li>Morita witnessed the devastation inflicted on Japan by American B-29 Superfortress bombers, which destroyed much of Tokyo and other urban centers.</li>
<li>The American blockade of Japan created widespread hunger and forced the country into desperate measures, such as training Morita’s brothers as kamikaze pilots.</li>
</ul>
</section>
<section id="morris-changs-wartime-experience" class="level4">
<h4 class="anchored" data-anchor-id="morris-changs-wartime-experience">Morris Chang’s Wartime Experience</h4>
<ul>
<li><strong>Morris Chang’s</strong> childhood was marked by the sounds of gunfire and air raid sirens as Japanese armies swept across China.</li>
<li>Chang and his family became refugees, fleeing to Guangzhou, Hong Kong, Chongqing, and finally back to Shanghai after Japan’s defeat.</li>
<li>The war’s end didn’t bring peace to China, as communist guerrillas resumed their fight against the Chinese government, forcing Chang to flee to Hong Kong for a second time.</li>
</ul>
</section>
<section id="andy-groves-wartime-experience" class="level4">
<h4 class="anchored" data-anchor-id="andy-groves-wartime-experience">Andy Grove’s Wartime Experience</h4>
<ul>
<li><strong>Andy Grove</strong>, then known as András Grof, endured multiple invasions of Budapest during World War II.</li>
<li>Hungary’s far-right government treated Jews like Grove’s family as second-class citizens. Despite this, Grove’s father was drafted into the army and sent to fight alongside the Nazis against the Soviet Union, where he went missing in action at Stalingrad.</li>
<li>In 1944, Nazi Germany invaded Hungary, their supposed ally, with plans to deport Jews like Grove to death camps.</li>
<li>Grove and his mother hid in a bomb shelter as the Red Army liberated Budapest, but the Soviet occupation brought its own share of suffering, including the rape of Grove’s mother.</li>
</ul>
</section>
</section>
<section id="americas-industrial-might-deciding-factor-in-world-war-ii" class="level3">
<h3 class="anchored" data-anchor-id="americas-industrial-might-deciding-factor-in-world-war-ii">America’s Industrial Might: Deciding Factor in World War II</h3>
<ul>
<li>World War II was a conflict of industrial attrition, a struggle that the United States, with its vast manufacturing capacity, was well-positioned to win.</li>
<li>The War Production Board in Washington measured success in terms of raw materials like copper, iron, rubber, oil, aluminum, and tin, as America transformed its industrial base to churn out military hardware.</li>
<li>The United States outproduced the Axis powers in every major category of war material, building more tanks, ships, planes, artillery, and machine guns than its enemies combined.</li>
<li>Convoys of American-made goods flowed across the Atlantic and Pacific, supplying Britain, the Soviet Union, China, and other Allied nations with vital resources.</li>
<li>While the war was fought by soldiers and sailors, the fighting power that ultimately decided the conflict was produced on American assembly lines in places like Kaiser shipyards and the River Rouge plant.</li>
</ul>
</section>
<section id="the-dawn-of-a-new-technological-era" class="level3">
<h3 class="anchored" data-anchor-id="the-dawn-of-a-new-technological-era">The Dawn of a New Technological Era</h3>
<ul>
<li>Despite the dominance of industrial output in determining the outcome of World War II, new technologies, particularly in the realm of electronics, were already transforming military power.</li>
<li>While mass-producing planes and tanks by the thousands, the great powers invested heavily in research labs that yielded innovations like rockets and radar.</li>
<li>The atomic bombs dropped on Hiroshima and Nagasaki dramatically illustrated the potential of emerging technologies to reshape warfare, sparking speculation about a future “atomic age” that would supersede the era of coal and steel.</li>
</ul>
<section id="akio-moritas-vision-of-the-future-of-warfare" class="level4">
<h4 class="anchored" data-anchor-id="akio-moritas-vision-of-the-future-of-warfare">Akio Morita’s Vision of the Future of Warfare</h4>
<ul>
<li>Although too young to have been deeply involved in wartime technological developments, Morris Chang and Andy Grove witnessed the shifting technological landscape. Akio Morita, in his early twenties, had a more direct view.</li>
<li>Morita’s experience developing heat-seeking missiles, although far from practical deployment, provided a glimpse into a future where wars might be won not by sheer industrial output but by sophisticated weaponry capable of autonomous targeting and maneuvering.</li>
<li>This notion, seemingly like science fiction at the time, was underpinned by Morita’s awareness of advances in electronic computation. These advances hinted at the possibility of machines performing complex calculations, essentially “thinking” by solving mathematical problems.</li>
</ul>
</section>
</section>
<section id="the-evolution-of-computing" class="level3">
<h3 class="anchored" data-anchor-id="the-evolution-of-computing">The Evolution of Computing</h3>
<ul>
<li>The concept of using devices to aid computation was not new. Humans had long relied on tools like the abacus to manipulate numbers.</li>
<li>The rise of large organizations in government and business during the late 19th and early 20th centuries created a surge in demand for “human computers” - clerks equipped with pen, paper, and mechanical calculators.</li>
<li>These human computers performed essential tasks such as processing payrolls, tracking sales, compiling census data, and analyzing statistics for insurance purposes.</li>
<li>The Works Progress Administration’s Mathematical Tables Project during the Great Depression illustrated both the potential and limitations of human-powered computation. The project employed hundreds of human computers to generate volumes of tables for complex mathematical functions, a valuable but time-consuming and laborious endeavor.</li>
</ul>
<section id="the-need-for-more-powerful-computing" class="level4">
<h4 class="anchored" data-anchor-id="the-need-for-more-powerful-computing">The Need for More Powerful Computing</h4>
<ul>
<li>The demand for faster and more efficient computation continued to grow, particularly in military applications.</li>
<li>Mechanical bombsights, for instance, were developed to improve bombing accuracy, but their limited input-output capabilities and reliance on precise conditions restricted their effectiveness.</li>
<li>Achieving greater accuracy in targeting and other military applications necessitated more sophisticated calculations, pushing the development of more powerful computing devices.</li>
</ul>
</section>
</section>
<section id="from-mechanical-gears-to-vacuum-tubes-a-new-era-of-computing" class="level3">
<h3 class="anchored" data-anchor-id="from-mechanical-gears-to-vacuum-tubes-a-new-era-of-computing">From Mechanical Gears to Vacuum Tubes: A New Era of Computing</h3>
<ul>
<li>The limitations of mechanical computers led to the exploration of electronic alternatives.</li>
<li>Early electronic computers employed <strong>vacuum tubes</strong>, glass-enclosed filaments that could be switched on and off to represent the 1s and 0s of binary code.</li>
<li><strong>Binary counting</strong>, using only 1s and 0s, could theoretically represent any number, enabling a wide range of computations.</li>
<li>Unlike the fixed functionality of mechanical computers, vacuum tube-based computers were <strong>reprogrammable</strong>, allowing for greater versatility.</li>
<li>Despite the advantages of vacuum tubes, they came with significant drawbacks:
<ul>
<li><strong>Attracted insects:</strong> The heat generated by the tubes made them attractive to moths and other insects, often leading to malfunctions.</li>
<li><strong>Burned out frequently:</strong> Vacuum tubes were prone to burning out, just like lightbulbs, requiring constant replacement.</li>
</ul></li>
</ul>
<section id="eniac-a-powerful-but-cumbersome-computer" class="level4">
<h4 class="anchored" data-anchor-id="eniac-a-powerful-but-cumbersome-computer">ENIAC: A Powerful but Cumbersome Computer</h4>
<ul>
<li><strong>ENIAC</strong>, built for the U.S. Army in 1945, exemplified the capabilities and limitations of early vacuum tube computers.</li>
<li>ENIAC could perform hundreds of multiplications per second but occupied an entire room due to its 18,000 fist-sized vacuum tubes.</li>
<li>The high failure rate of the tubes meant frequent breakdowns, halting operations and requiring technicians to locate and replace faulty components.</li>
</ul>
</section>
<section id="the-search-for-a-better-alternative" class="level4">
<h4 class="anchored" data-anchor-id="the-search-for-a-better-alternative">The Search for a Better Alternative</h4>
<ul>
<li>ENIAC demonstrated the potential computing power of vacuum tubes but also highlighted their impracticality for widespread use.</li>
<li>The search for a smaller, faster, more reliable, and less cumbersome alternative to the vacuum tube became paramount in advancing the field of computing.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-2-the-switch" class="level2">
<h2 class="anchored" data-anchor-id="chapter-2-the-switch">Chapter 2: The Switch</h2>
<section id="the-quest-for-a-better-switch" class="level3">
<h3 class="anchored" data-anchor-id="the-quest-for-a-better-switch">The Quest for a Better Switch</h3>
<ul>
<li><p><strong>William Shockley</strong>, a brilliant but obnoxious physicist at Bell Labs, believed <strong>semiconductors</strong> held the key to a better switch.</p>
<ul>
<li><strong>Semiconductors:</strong> Unique materials like silicon and germanium that can conduct electricity under specific conditions, unlike conductors (e.g., copper) or insulators (e.g., glass).</li>
</ul></li>
</ul>
</section>
<section id="shockleys-solid-state-valve-theory" class="level3">
<h3 class="anchored" data-anchor-id="shockleys-solid-state-valve-theory">Shockley’s Solid-State Valve Theory</h3>
<ul>
<li>In 1945, Shockley theorized a <strong>solid-state valve</strong> using a piece of silicon and a 90-volt battery.
<ul>
<li>He hypothesized that an electric field could attract free electrons in the silicon, making its edge conductive and allowing current to flow.</li>
<li>His initial experiment failed to produce measurable results due to the limitations of instruments at the time.</li>
</ul></li>
</ul>
</section>
<section id="brattain-and-bardeens-breakthrough" class="level3">
<h3 class="anchored" data-anchor-id="brattain-and-bardeens-breakthrough">Brattain and Bardeen’s Breakthrough</h3>
<ul>
<li>Two of Shockley’s colleagues at Bell Labs, <strong>Walter Brattain</strong> and <strong>John Bardeen</strong>, built a device with two gold filaments touching a germanium block.
<ul>
<li>On December 16, 1947, they successfully controlled the current flow across the germanium, proving Shockley’s theories.</li>
<li>This device was later named the <strong>transistor</strong>.</li>
</ul></li>
</ul>
</section>
<section id="transistors-initial-applications-and-shockleys-response" class="level3">
<h3 class="anchored" data-anchor-id="transistors-initial-applications-and-shockleys-response">Transistor’s Initial Applications and Shockley’s Response</h3>
<ul>
<li><strong>AT&amp;T</strong>, Bell Labs’ parent company, saw the transistor’s potential for amplifying signals in telephones.</li>
<li>Transistors were also recognized as replacements for vacuum tubes in hearing aids and radios.</li>
<li>Shockley, furious at being outdone, locked himself in a Chicago hotel room and conceived of a new <strong>three-layer transistor</strong> design.
<ul>
<li>This design amplified current and functioned as a switch by manipulating a small current to control a larger one.</li>
</ul></li>
</ul>
</section>
<section id="public-announcement-and-significance" class="level3">
<h3 class="anchored" data-anchor-id="public-announcement-and-significance">Public Announcement and Significance</h3>
<ul>
<li>Bell Labs announced the transistor in June 1948, but the news was met with little fanfare.
<ul>
<li><em>“Little brain cell”</em>, Time magazine, 1948.</li>
</ul></li>
<li>The significance of these “wired blocks of germanium” as replacements for human brains in computing was unimaginable at the time.</li>
</ul>
</section>
</section>
<section id="chapter-3-noyce-kilby-and-the-integrated-circuit" class="level2">
<h2 class="anchored" data-anchor-id="chapter-3-noyce-kilby-and-the-integrated-circuit">Chapter 3: Noyce, Kilby, and the Integrated Circuit</h2>
<section id="the-need-for-mass-production" class="level3">
<h3 class="anchored" data-anchor-id="the-need-for-mass-production">The Need for Mass Production</h3>
<ul>
<li>While <strong>transistors</strong> had been invented and showed promise in replacing <strong>vacuum tubes</strong>, the challenge of mass production and commercial viability remained.</li>
<li>John Bardeen and Walter Brattain, inventors of the transistor, were primarily researchers and less interested in the business aspects of their invention.</li>
<li>William Shockley, their colleague, was ambitious and sought both fame and fortune.
<ul>
<li>In 1955, he founded <strong>Shockley Semiconductor</strong> in Mountain View, California, aiming to capitalize on the potential of transistors.</li>
</ul></li>
</ul>
</section>
<section id="shockley-semiconductor-and-the-transistor-market" class="level3">
<h3 class="anchored" data-anchor-id="shockley-semiconductor-and-the-transistor-market">Shockley Semiconductor and the Transistor Market</h3>
<ul>
<li>AT&amp;T, holding the transistor patent, offered licenses for $25,000, enabling companies like Shockley’s to enter the market.</li>
<li>The potential of the transistor market was uncertain, as it was unclear whether transistors could surpass vacuum tubes in performance or cost.</li>
<li>Shockley, despite winning a Nobel Prize for semiconductor theory, faced the engineering challenge of making transistors practical.</li>
<li>Transistors began replacing vacuum tubes in computers, but the complex wiring between thousands of transistors posed a significant hurdle.</li>
</ul>
</section>
<section id="jack-kilbys-integrated-circuit" class="level3">
<h3 class="anchored" data-anchor-id="jack-kilbys-integrated-circuit">Jack Kilby’s Integrated Circuit</h3>
<ul>
<li><strong>Jack Kilby</strong>, an engineer at Texas Instruments (TI), dedicated himself to simplifying the complex wiring required for transistors.</li>
<li>Kilby’s Background:
<ul>
<li>Known for his quiet brilliance, collaborative spirit, and problem-solving approach.</li>
<li>One of the first engineers outside Bell Labs to work with transistors at Central Lab in Milwaukee.</li>
<li>Joined TI’s transistor unit in 1958.</li>
</ul></li>
<li>TI’s Background:
<ul>
<li>Originally focused on seismic equipment for oil exploration.</li>
<li>Gained electronics expertise during World War II producing sonar devices for the Navy.</li>
<li>Hired engineers like Kilby to develop military electronics after the war.</li>
</ul></li>
<li><strong>Kilby’s Breakthrough (Summer 1958):</strong>
<ul>
<li>While working alone at TI during a holiday period, Kilby focused on reducing the number of wires connecting transistors.</li>
<li>His idea was to build multiple components on a single piece of semiconductor material instead of using separate pieces for each transistor.</li>
</ul></li>
<li><strong>Kilby’s invention, the “integrated circuit,” later became known as a “chip”</strong> because it was made from a piece of silicon chipped off a circular wafer.</li>
</ul>
</section>
<section id="the-rise-of-fairchild-semiconductor" class="level3">
<h3 class="anchored" data-anchor-id="the-rise-of-fairchild-semiconductor">The Rise of Fairchild Semiconductor</h3>
<ul>
<li>In Palo Alto, eight engineers, including <strong>Robert Noyce</strong>, left Shockley Semiconductor due to Shockley’s management style.</li>
<li><strong>The “Traitorous Eight”</strong>
<ul>
<li>This group, seeking a better working environment, founded <strong>Fairchild Semiconductor</strong> with funding from an East Coast investor.</li>
<li>Their departure is considered a pivotal moment in the formation of Silicon Valley.</li>
<li><strong>Eugene Kleiner</strong>, one of the eight, later founded the venture capital firm Kleiner Perkins.</li>
<li><strong>Gordon Moore</strong>, who led Fairchild’s R&amp;D, later formulated “Moore’s Law,” predicting the exponential growth of computing power.</li>
</ul></li>
<li><strong>Robert Noyce</strong>, the group’s leader, possessed a strong vision for microelectronics and a keen understanding of the technical advancements needed to make transistors smaller, cheaper, and more reliable.</li>
</ul>
</section>
<section id="noyces-planar-process-and-the-advancement-of-the-integrated-circuit" class="level3">
<h3 class="anchored" data-anchor-id="noyces-planar-process-and-the-advancement-of-the-integrated-circuit">Noyce’s Planar Process and the Advancement of the Integrated Circuit</h3>
<ul>
<li>While the science of transistors was established, reliable manufacturing was a challenge.</li>
<li>Early transistors, using a <strong>mesa</strong> structure, were prone to impurities affecting their performance.</li>
<li><strong>Jean Ernie</strong>, Noyce’s colleague at Fairchild, developed a <strong>planar process</strong>:
<ul>
<li>This method involved building transistors into, rather than on top of, the germanium, and depositing a protective layer of silicon dioxide to prevent impurities.</li>
<li>Ernie’s innovation significantly improved transistor reliability.</li>
</ul></li>
<li><strong>Noyce’s Refinement:</strong>
<ul>
<li>Noyce realized Ernie’s planar process could be used to create multiple transistors on a single piece of silicon.</li>
<li>Unlike Kilby’s integrated circuit, which used wires, Noyce’s design embedded the transistors and wires within the silicon, further reducing size and complexity.</li>
</ul></li>
<li>Both Kilby and Noyce independently invented the integrated circuit, but Noyce’s planar process proved to be a significant leap forward in miniaturization and reliability.</li>
</ul>
</section>
<section id="fairchilds-vision-for-the-future" class="level3">
<h3 class="anchored" data-anchor-id="fairchilds-vision-for-the-future">Fairchild’s Vision for the Future</h3>
<ul>
<li>Noyce, Moore, and the Fairchild team recognized the advantages of their integrated circuits:
<ul>
<li><strong>Reliability:</strong> Superior to the complex wiring of other electronic devices.</li>
<li><strong>Miniaturization:</strong> Planar design facilitated smaller transistors.</li>
<li><strong>Electric Efficiency:</strong> Smaller circuits consumed less power.</li>
</ul></li>
<li>They envisioned new applications for their invention, driven by miniaturization and reduced power consumption.</li>
<li>The initial cost of Noyce’s integrated circuit was 50 times higher than simpler devices, posing a challenge to market adoption.
<ul>
<li>Despite its ingenuity, the invention needed a market to thrive.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-4-liftoff" class="level2">
<h2 class="anchored" data-anchor-id="chapter-4-liftoff">Chapter 4: Liftoff</h2>
<section id="sputnik-and-the-space-race" class="level3">
<h3 class="anchored" data-anchor-id="sputnik-and-the-space-race">Sputnik and the Space Race</h3>
<ul>
<li>Three days after Fairchild Semiconductor’s founding, the Soviet Union launched <strong>Sputnik</strong>, the world’s first satellite, on October 4, 1957.
<ul>
<li>This event sparked fear in the United States about falling behind in the space race and the military implications of Soviet technological superiority.</li>
<li>Four years later, the Soviet Union also sent the first human, Yuri Gagarin, into space.</li>
</ul></li>
</ul>
<section id="the-impact-of-the-space-race-on-the-u.s.-semiconductor-industry" class="level4">
<h4 class="anchored" data-anchor-id="the-impact-of-the-space-race-on-the-u.s.-semiconductor-industry">The Impact of the Space Race on the U.S. Semiconductor Industry</h4>
<ul>
<li>The U.S. government launched a crash program to catch up in the space race, leading to increased funding for rocket and missile programs.</li>
<li>President John F. Kennedy declared the goal of sending a man to the moon, further fueling investment in aerospace technology.</li>
<li>This created a new market for integrated circuits, with <strong>NASA</strong> emerging as a major customer.</li>
</ul>
</section>
</section>
<section id="the-apollo-guidance-computer" class="level3">
<h3 class="anchored" data-anchor-id="the-apollo-guidance-computer">The Apollo Guidance Computer</h3>
<section id="the-challenge" class="level4">
<h4 class="anchored" data-anchor-id="the-challenge">The Challenge</h4>
<ul>
<li>NASA tasked the MIT Instrumentation Lab with designing the guidance computer for the <strong>Apollo spacecraft</strong>.
<ul>
<li>This computer would need to be extremely complex, reliable, and lightweight.</li>
<li>Initial estimates suggested that a computer powerful enough to guide a spacecraft to the moon would be prohibitively large and power-hungry.</li>
</ul></li>
</ul>
</section>
<section id="the-solution-integrated-circuits" class="level4">
<h4 class="anchored" data-anchor-id="the-solution-integrated-circuits">The Solution: Integrated Circuits</h4>
<ul>
<li><strong>Transistor-based computers</strong> were significantly more advanced than the older <strong>vacuum tube computers</strong>, but their size and power consumption remained a challenge.</li>
<li>MIT engineers had experimented with early integrated circuits from Texas Instruments, purchased in 1959 for $1,000 for 64 chips, for a U.S. Navy missile program.</li>
<li>By 1962, Fairchild began marketing its own <strong>micrologic chips</strong>, attracting the attention of MIT engineers working on the Apollo guidance computer.</li>
</ul>
</section>
<section id="fairchilds-success" class="level4">
<h4 class="anchored" data-anchor-id="fairchilds-success">Fairchild’s Success</h4>
<ul>
<li>Despite being a new company, Fairchild gained the trust of MIT engineers due to the reliability and timely delivery of its chips.</li>
<li>Charles Stark Draper, head of the MIT lab, decided to use Fairchild chips for the Apollo guidance computer.
<ul>
<li>Draper calculated that a computer using Fairchild’s <strong>integrated circuits</strong> would be significantly smaller, lighter, and more energy-efficient than one based on discrete transistors.</li>
</ul></li>
<li>The final Apollo guidance computer weighed 70 pounds and occupied about one cubic foot of space, a dramatic reduction in size compared to earlier computers.</li>
<li>By 1964, Noyce boasted that the integrated circuits in Apollo computers had operated for 19 million hours with only two failures.</li>
</ul>
</section>
<section id="the-impact-of-the-apollo-program-on-fairchild" class="level4">
<h4 class="anchored" data-anchor-id="the-impact-of-the-apollo-program-on-fairchild">The Impact of the Apollo Program on Fairchild</h4>
<ul>
<li>The Apollo program transformed Fairchild Semiconductor from a small startup to a company with 1,000 employees.</li>
<li>Sales skyrocketed from $500,000 in 1958 to $21 million in 1960.</li>
<li>Noyce leveraged increased production for NASA to lower prices for other customers, further expanding the market for integrated circuits.</li>
</ul>
</section>
<section id="nasas-endorsement" class="level4">
<h4 class="anchored" data-anchor-id="nasas-endorsement">NASA’s Endorsement</h4>
<ul>
<li>NASA’s successful use of integrated circuits in the Apollo program provided a critical stamp of approval for the technology.</li>
<li>This demonstrated the reliability and capabilities of integrated circuits in the most demanding environments.</li>
</ul>
</section>
</section>
<section id="texas-instruments-and-the-minuteman-ii-missile" class="level3">
<h3 class="anchored" data-anchor-id="texas-instruments-and-the-minuteman-ii-missile">Texas Instruments and the Minuteman II Missile</h3>
<section id="pat-haggertys-vision" class="level4">
<h4 class="anchored" data-anchor-id="pat-haggertys-vision">Pat Haggerty’s Vision</h4>
<ul>
<li><strong>Pat Haggerty</strong>, president of Texas Instruments, recognized the potential of Jack Kilby’s integrated circuit for military applications.</li>
<li>Haggerty, a skilled salesman and visionary leader, believed integrated circuits could be used in all types of military electronics.</li>
<li>He actively promoted integrated circuits to the <strong>Defense Department</strong> and secured funding for research and development.</li>
</ul>
</section>
<section id="the-minuteman-ii-missile-contract" class="level4">
<h4 class="anchored" data-anchor-id="the-minuteman-ii-missile-contract">The Minuteman II Missile Contract</h4>
<ul>
<li>In 1962, the <strong>Air Force</strong> sought a new computer for its <strong>Minuteman II missile</strong>, aiming to improve its range and accuracy.</li>
<li>Haggerty proposed using integrated circuits to create a smaller, lighter, and more powerful guidance computer.
<ul>
<li>His design relied on 22 different types of integrated circuits to handle 95% of the computer’s functions, resulting in significant weight reduction.</li>
</ul></li>
<li>TI won the contract, marking a turning point for the company’s integrated circuit business.</li>
</ul>
</section>
<section id="the-impact-of-the-minuteman-ii-program-on-texas-instruments" class="level4">
<h4 class="anchored" data-anchor-id="the-impact-of-the-minuteman-ii-program-on-texas-instruments">The Impact of the Minuteman II Program on Texas Instruments</h4>
<ul>
<li>The Minuteman II contract led to a surge in demand for TI’s integrated circuits, driving sales from dozens to thousands.</li>
<li>By the end of 1964, TI had supplied 100,000 integrated circuits for the Minuteman program.</li>
</ul>
</section>
<section id="the-challenge-of-mass-production" class="level4">
<h4 class="anchored" data-anchor-id="the-challenge-of-mass-production">The Challenge of Mass Production</h4>
<ul>
<li>Both Fairchild and TI faced the challenge of mass-producing integrated circuits to meet the growing demand from military and civilian customers.</li>
<li>This required developing new manufacturing techniques, improving reliability, and reducing costs.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-5-mortars-and-mass-production" class="level2">
<h2 class="anchored" data-anchor-id="chapter-5-mortars-and-mass-production">Chapter 5: Mortars and Mass Production</h2>
<section id="jay-lathrop-and-photolithography" class="level3">
<h3 class="anchored" data-anchor-id="jay-lathrop-and-photolithography">Jay Lathrop and Photolithography</h3>
<section id="the-need-for-miniaturization" class="level4">
<h4 class="anchored" data-anchor-id="the-need-for-miniaturization">The Need for Miniaturization</h4>
<ul>
<li><strong>Jay Lathrop</strong>, an MIT graduate working at a U.S. government lab, was tasked with developing a smaller and more efficient <strong>proximity fuse</strong> for 81-millimeter mortar shells.</li>
<li>Like Fairchild’s engineers, Lathrop struggled with the limitations of <strong>mesa-shaped transistors</strong>, which were difficult to miniaturize.</li>
</ul>
</section>
<section id="a-breakthrough-printing-with-light" class="level4">
<h4 class="anchored" data-anchor-id="a-breakthrough-printing-with-light">A Breakthrough: Printing with Light</h4>
<ul>
<li>While examining transistors under a microscope, Lathrop and chemist James Knoll devised a revolutionary technique called <strong>photolithography</strong>.
<ul>
<li>This process used light to create microscopic patterns on semiconductor material, enabling the production of much smaller transistors with greater precision.</li>
</ul></li>
</ul>
</section>
<section id="photolithography-process" class="level4">
<h4 class="anchored" data-anchor-id="photolithography-process">Photolithography Process</h4>
<ol type="1">
<li><strong>Coat:</strong> Cover a block of germanium with a <strong>photoresist</strong> chemical that reacts to light.</li>
<li><strong>Expose:</strong> Shine light through a mask containing the desired pattern onto the photoresist-coated germanium.
<ul>
<li>The light passes through the mask’s open areas and shrinks as it passes through an upside-down microscope lens.</li>
</ul></li>
<li><strong>Develop:</strong> Wash away the exposed photoresist, leaving behind the patterned germanium.</li>
<li><strong>Connect:</strong> Add a thin layer of aluminum to create electrical connections.</li>
</ol>
</section>
<section id="advantages-of-photolithography" class="level4">
<h4 class="anchored" data-anchor-id="advantages-of-photolithography">Advantages of Photolithography</h4>
<ul>
<li>Enabled the production of transistors significantly smaller than previously possible.</li>
<li>Allowed for greater precision and accuracy in creating transistor features.</li>
<li>Opened the door to mass production of transistors and integrated circuits.</li>
</ul>
</section>
</section>
<section id="texas-instruments-adopts-photolithography" class="level3">
<h3 class="anchored" data-anchor-id="texas-instruments-adopts-photolithography">Texas Instruments Adopts Photolithography</h3>
<section id="recognizing-the-potential" class="level4">
<h4 class="anchored" data-anchor-id="recognizing-the-potential">Recognizing the Potential</h4>
<ul>
<li>Pat Haggerty and Jack Kilby recognized the importance of photolithography for mass-producing integrated circuits.</li>
<li>They understood that this technique could mechanize and miniaturize chipmaking, making it possible to meet the growing demand from the military and other customers.</li>
</ul>
</section>
<section id="implementing-photolithography-at-ti" class="level4">
<h4 class="anchored" data-anchor-id="implementing-photolithography-at-ti">Implementing Photolithography at TI</h4>
<ul>
<li>Implementing photolithography at TI required significant investment in new materials and processes:
<ul>
<li><strong>Chemicals:</strong> TI developed its own high-purity photoresist chemicals.</li>
<li><strong>Masks:</strong> TI created its own masks for projecting precise patterns of light.</li>
<li><strong>Silicon Wafers:</strong> TI began producing its own ultra-pure silicon wafers.</li>
</ul></li>
</ul>
</section>
<section id="overcoming-production-challenges" class="level4">
<h4 class="anchored" data-anchor-id="overcoming-production-challenges">Overcoming Production Challenges</h4>
<ul>
<li>Mass production of integrated circuits presented numerous challenges due to the microscopic scale and sensitivity of the process:
<ul>
<li><strong>Impurities:</strong> Even tiny impurities in chemicals or dust particles could ruin an entire production run.</li>
<li><strong>Process Variations:</strong> Fluctuations in temperature, pressure, and other factors could affect the quality and reliability of chips.</li>
</ul></li>
</ul>
</section>
<section id="trial-and-error-and-human-computers" class="level4">
<h4 class="anchored" data-anchor-id="trial-and-error-and-human-computers">Trial and Error and Human Computers</h4>
<ul>
<li>TI relied heavily on trial and error to optimize its production processes.
<ul>
<li>Engineers conducted thousands of experiments to test different combinations of materials, temperatures, and process parameters.</li>
<li><strong>Mary Ann Potter</strong>, a TI production engineer, played a crucial role in scaling up chip production for the Minuteman missile.
<ul>
<li>She spent countless hours running experiments, analyzing data, and refining production processes.</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="morris-chang-and-yield-improvement" class="level3">
<h3 class="anchored" data-anchor-id="morris-chang-and-yield-improvement">Morris Chang and Yield Improvement</h3>
<section id="from-refugee-to-semiconductor-engineer" class="level4">
<h4 class="anchored" data-anchor-id="from-refugee-to-semiconductor-engineer">From Refugee to Semiconductor Engineer</h4>
<ul>
<li><strong>Morris Chang</strong>, a Chinese refugee who fled to the U.S., joined TI in 1958.</li>
<li>Chang, a brilliant engineer and strategist, was tasked with improving <strong>manufacturing yield</strong>—the percentage of usable transistors produced.</li>
</ul>
</section>
<section id="systematic-approach-to-manufacturing" class="level4">
<h4 class="anchored" data-anchor-id="systematic-approach-to-manufacturing">Systematic Approach to Manufacturing</h4>
<ul>
<li>Chang took a methodical approach to improving yield, systematically testing and adjusting production processes:
<ul>
<li>He meticulously tweaked temperatures, pressures, and chemical combinations to find the optimal parameters.</li>
<li>He applied his deep understanding of semiconductor physics to solve production problems.</li>
</ul></li>
</ul>
</section>
<section id="results-and-recognition" class="level4">
<h4 class="anchored" data-anchor-id="results-and-recognition">Results and Recognition</h4>
<ul>
<li>Chang’s efforts dramatically increased yield on his production line, attracting the attention of IBM and establishing him as a leading figure in semiconductor manufacturing.</li>
</ul>
</section>
</section>
<section id="fairchilds-pursuit-of-mass-production" class="level3">
<h3 class="anchored" data-anchor-id="fairchilds-pursuit-of-mass-production">Fairchild’s Pursuit of Mass Production</h3>
<section id="recognizing-photolithographys-potential" class="level4">
<h4 class="anchored" data-anchor-id="recognizing-photolithographys-potential">Recognizing Photolithography’s Potential</h4>
<ul>
<li>Bob Noyce recognized the transformative potential of photolithography for Fairchild’s future.</li>
</ul>
</section>
<section id="hiring-key-talent" class="level4">
<h4 class="anchored" data-anchor-id="hiring-key-talent">Hiring Key Talent</h4>
<ul>
<li>Fairchild hired James Knoll, co-inventor of photolithography, to develop and implement the process at the company.</li>
</ul>
</section>
<section id="andy-grove-and-process-improvement" class="level4">
<h4 class="anchored" data-anchor-id="andy-grove-and-process-improvement">Andy Grove and Process Improvement</h4>
<ul>
<li><strong>Andy Grove</strong>, a Hungarian refugee with a Ph.D.&nbsp;in chemical engineering, joined Fairchild in 1963 and played a pivotal role in improving manufacturing processes.</li>
</ul>
</section>
<section id="the-importance-of-engineering-and-production" class="level4">
<h4 class="anchored" data-anchor-id="the-importance-of-engineering-and-production">The Importance of Engineering and Production</h4>
<ul>
<li>The development of the chip industry highlights the crucial role of engineering and production expertise, alongside scientific breakthroughs.</li>
<li>While academic research provided the foundation, it was the ingenuity and persistence of engineers like Lathrop, Chang, Grove, and countless others that made mass production possible.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-6-i-want-to-get-rich" class="level2">
<h2 class="anchored" data-anchor-id="chapter-6-i-want-to-get-rich">Chapter 6: I Want to Get Rich</h2>
<section id="beyond-military-and-space-targeting-the-civilian-market" class="level3">
<h3 class="anchored" data-anchor-id="beyond-military-and-space-targeting-the-civilian-market">Beyond Military and Space: Targeting the Civilian Market</h3>
<section id="early-dependence-on-military-and-space-programs" class="level4">
<h4 class="anchored" data-anchor-id="early-dependence-on-military-and-space-programs">Early Dependence on Military and Space Programs</h4>
<ul>
<li>In the early 1960s, the majority of Fairchild’s revenue came from military and space programs.
<ul>
<li>In 1965, these sectors accounted for 72% of all integrated circuit sales.</li>
</ul></li>
</ul>
</section>
<section id="noyces-vision-for-a-civilian-market" class="level4">
<h4 class="anchored" data-anchor-id="noyces-vision-for-a-civilian-market">Noyce’s Vision for a Civilian Market</h4>
<ul>
<li>Bob Noyce recognized the potential of integrated circuits to revolutionize civilian products and create a much larger market.</li>
<li>He believed that many of the features demanded by the military, such as miniaturization and ruggedness, would also be valuable in consumer products.</li>
</ul>
</section>
<section id="maintaining-rd-independence" class="level4">
<h4 class="anchored" data-anchor-id="maintaining-rd-independence">Maintaining R&amp;D Independence</h4>
<ul>
<li>Noyce deliberately limited Fairchild’s reliance on military research contracts to maintain control over the company’s R&amp;D priorities.</li>
<li>He wanted Fairchild to focus on developing innovative products for the civilian market, rather than being bound to the specific requirements of military contracts.</li>
</ul>
</section>
</section>
<section id="moores-law-and-the-exponential-growth-of-computing-power" class="level3">
<h3 class="anchored" data-anchor-id="moores-law-and-the-exponential-growth-of-computing-power">Moore’s Law and the Exponential Growth of Computing Power</h3>
<section id="gordon-moores-prediction" class="level4">
<h4 class="anchored" data-anchor-id="gordon-moores-prediction">Gordon Moore’s Prediction</h4>
<ul>
<li>In 1965, <strong>Gordon Moore</strong>, co-founder of Fairchild, published an article predicting that the number of components on an integrated circuit would double every year for the next decade.
<ul>
<li>This prediction, which came to be known as <strong>Moore’s Law</strong>, proved remarkably accurate and had profound implications for the future of computing.</li>
</ul></li>
</ul>
</section>
<section id="implications-of-moores-law" class="level4">
<h4 class="anchored" data-anchor-id="implications-of-moores-law">Implications of Moore’s Law</h4>
<ul>
<li><strong>Exponential Growth in Computing Power:</strong> Moore’s Law implied that computing power would increase exponentially over time.</li>
<li><strong>Decreasing Costs:</strong> As transistors became smaller and more densely packed, the cost per transistor would decrease, making computers more affordable and accessible.</li>
<li><strong>Expanding Applications:</strong> As computing power became cheaper and more readily available, it would find its way into a wider range of products and applications.</li>
</ul>
</section>
</section>
<section id="fairchilds-strategic-shift" class="level3">
<h3 class="anchored" data-anchor-id="fairchilds-strategic-shift">Fairchild’s Strategic Shift</h3>
<section id="the-mcnamara-depression-and-its-impact" class="level4">
<h4 class="anchored" data-anchor-id="the-mcnamara-depression-and-its-impact">The “McNamara Depression” and Its Impact</h4>
<ul>
<li>In the early 1960s, U.S. Defense Secretary Robert McNamara implemented cost-cutting measures that reduced military spending on electronics, impacting companies like Fairchild.</li>
<li>This “McNamara Depression” reinforced Noyce’s belief in the importance of developing civilian markets for integrated circuits.</li>
</ul>
</section>
<section id="focus-on-civilian-products" class="level4">
<h4 class="anchored" data-anchor-id="focus-on-civilian-products">Focus on Civilian Products</h4>
<ul>
<li>Fairchild became the first company to offer a full line of off-the-shelf integrated circuits designed specifically for civilian applications.</li>
</ul>
</section>
<section id="price-cuts-to-drive-adoption" class="level4">
<h4 class="anchored" data-anchor-id="price-cuts-to-drive-adoption">Price Cuts to Drive Adoption</h4>
<ul>
<li>Noyce aggressively cut prices for Fairchild’s integrated circuits, even selling some products below cost, to encourage wider adoption and stimulate demand.</li>
</ul>
</section>
</section>
<section id="the-rise-of-the-civilian-computer-market" class="level3">
<h3 class="anchored" data-anchor-id="the-rise-of-the-civilian-computer-market">The Rise of the Civilian Computer Market</h3>
<section id="rapid-growth-of-the-computer-industry" class="level4">
<h4 class="anchored" data-anchor-id="rapid-growth-of-the-computer-industry">Rapid Growth of the Computer Industry</h4>
<ul>
<li>The computer industry experienced explosive growth in the 1960s, with annual sales increasing from 1,000 units in 1957 to 18,700 units in 1967.</li>
</ul>
</section>
<section id="fairchilds-dominance" class="level4">
<h4 class="anchored" data-anchor-id="fairchilds-dominance">Fairchild’s Dominance</h4>
<ul>
<li>By the mid-1960s, nearly all new computers used integrated circuits, and Fairchild captured a dominant share of this rapidly expanding market.</li>
</ul>
</section>
<section id="the-burroughs-contract" class="level4">
<h4 class="anchored" data-anchor-id="the-burroughs-contract">The Burroughs Contract</h4>
<ul>
<li>In 1966, Fairchild secured a major contract with <strong>Burroughs</strong>, a leading computer manufacturer, for 20 million integrated circuits.</li>
<li>This contract, far larger than any previous order from NASA or the military, signaled the shift in demand towards the civilian market.</li>
</ul>
</section>
</section>
<section id="the-allure-of-wealth-and-the-exodus-from-fairchild" class="level3">
<h3 class="anchored" data-anchor-id="the-allure-of-wealth-and-the-exodus-from-fairchild">The Allure of Wealth and the Exodus from Fairchild</h3>
<section id="financial-incentives-drive-innovation" class="level4">
<h4 class="anchored" data-anchor-id="financial-incentives-drive-innovation">Financial Incentives Drive Innovation</h4>
<ul>
<li>The potential for financial gain became a powerful motivator for engineers and entrepreneurs in Silicon Valley.</li>
</ul>
</section>
<section id="fairchilds-restrictive-stock-option-policy" class="level4">
<h4 class="anchored" data-anchor-id="fairchilds-restrictive-stock-option-policy">Fairchild’s Restrictive Stock Option Policy</h4>
<ul>
<li>Fairchild’s owner, Sherman Fairchild, refused to grant stock options to employees, limiting their ability to share in the company’s success.</li>
</ul>
</section>
<section id="the-search-for-riches" class="level4">
<h4 class="anchored" data-anchor-id="the-search-for-riches">The Search for Riches</h4>
<ul>
<li>As Fairchild’s success attracted competition, many talented engineers and executives left to start their own companies or join rivals, enticed by the promise of greater financial rewards.</li>
<li>This exodus of talent led to the formation of numerous new semiconductor companies, further accelerating innovation and competition in the industry.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="chapter-7-soviet-silicon-valley" class="level2">
<h2 class="anchored" data-anchor-id="chapter-7-soviet-silicon-valley">Chapter 7: Soviet Silicon Valley</h2>
<section id="the-arrival-of-soviet-engineers-in-silicon-valley" class="level3">
<h3 class="anchored" data-anchor-id="the-arrival-of-soviet-engineers-in-silicon-valley">The Arrival of Soviet Engineers in Silicon Valley</h3>
<ul>
<li><strong>Anatoly Trutko</strong>, a Soviet semiconductor engineer, arrived at Stanford University in 1959 as part of a student exchange program.
<ul>
<li>This was surprising given US fears of the USSR catching up in science and technology.</li>
<li>Trutko studied advanced technology, even attending lectures by <strong>William Shockley</strong>.
<ul>
<li>After one class, Trutko asked Shockley to sign his book, <em>Electrons and Holes in Semiconductors</em>.</li>
<li>Shockley complained to Trutko that the USSR refused to pay royalties for the book’s Russian translation.</li>
</ul></li>
</ul></li>
<li>The USSR understood the value of semiconductors.
<ul>
<li>They translated Shockley’s textbook into Russian just two years after it was published.</li>
<li>US spies were ordered to acquire Soviet semiconductor devices as early as 1956 to assess their quality.
<ul>
<li>A 1959 CIA report found that America was only two to four years ahead of the Soviets in transistor quality and quantity.</li>
</ul></li>
</ul></li>
<li>At least several early Soviet exchange students were later revealed to be KGB agents.
<ul>
<li>This highlights the link between student exchanges and Soviet defense industry goals.</li>
</ul></li>
<li>Both the Pentagon and the Kremlin understood that <strong>transistors</strong> and <strong>integrated circuits</strong> would revolutionize manufacturing, computing, and military power.
<ul>
<li>Starting in the late 1950s, the USSR established new semiconductor facilities and assigned top scientists to this industry.</li>
</ul></li>
</ul>
</section>
<section id="yuri-osokyan-and-the-rise-of-soviet-semiconductor-research" class="level3">
<h3 class="anchored" data-anchor-id="yuri-osokyan-and-the-rise-of-soviet-semiconductor-research">Yuri Osokyan and the Rise of Soviet Semiconductor Research</h3>
<ul>
<li><strong>Yuri Osokyan</strong> was a talented young Soviet engineer tasked with advancing Soviet semiconductor technology.
<ul>
<li>He spent his childhood in China, where his father worked in a Soviet military hospital.</li>
<li>He was known for his exceptional memory and expertise in semiconductors.</li>
</ul></li>
<li>Osokyan was assigned to a semiconductor plant in Riga, Latvia.
<ul>
<li>The plant was staffed by top graduates and tasked with building devices for the Soviet space program and military.</li>
</ul></li>
<li>Osokyan was tasked with building a circuit with multiple components on a single piece of germanium, something never done before in the Soviet Union.
<ul>
<li>He created his prototype <strong>integrated circuit</strong> in 1962.</li>
<li>Osokyan and his colleagues were aware they were at the forefront of Soviet science.</li>
<li>They were dedicated to their work, spending evenings discussing solid-state physics.</li>
</ul></li>
</ul>
</section>
<section id="khrushchevs-vision-for-soviet-semiconductor-dominance" class="level3">
<h3 class="anchored" data-anchor-id="khrushchevs-vision-for-soviet-semiconductor-dominance">Khrushchev’s Vision for Soviet Semiconductor Dominance</h3>
<ul>
<li>Soviet leader <strong>Nikita Khrushchev</strong> aimed to surpass the United States in all areas, including technology.</li>
<li><strong>Alexander Shokhin</strong>, First Deputy Chairman of the Soviet State Committee on Radio-Electronics, saw an opportunity to leverage Khrushchev’s ambition.
<ul>
<li>He told Khrushchev, “Imagine, Nikita Sergeyevich, that a TV can be made the size of a cigarette box,” highlighting the potential of Soviet silicon.</li>
</ul></li>
<li>Shokhin believed catching up to and surpassing the United States was possible.</li>
<li>Similar to their approach with nuclear weapons, the USSR had a secret weapon: <strong>espionage</strong>.</li>
</ul>
</section>
<section id="joel-barr-and-alfred-sarant-from-american-spies-to-soviet-computer-pioneers" class="level3">
<h3 class="anchored" data-anchor-id="joel-barr-and-alfred-sarant-from-american-spies-to-soviet-computer-pioneers">Joel Barr and Alfred Sarant: From American Spies to Soviet Computer Pioneers</h3>
<ul>
<li><strong>Joel Barr</strong> and <strong>Alfred Sarant</strong> were American electrical engineers who became Soviet spies.
<ul>
<li>They were childhood friends, both sons of Russian Jewish immigrants, and active in the Young Communist League.</li>
<li>They were recruited into a KGB espionage ring led by <strong>Julius Rosenberg</strong>.</li>
</ul></li>
<li>During the 1940s, Barr and Sarant worked on classified radar and military systems at leading American tech firms.
<ul>
<li>They gained knowledge about electronics in new weapon systems.</li>
</ul></li>
<li>As the FBI closed in on the Rosenberg ring, Barr and Sarant fled to the Soviet Union.
<ul>
<li>They told the KGB they wanted to build advanced computers.</li>
<li>Though not computer experts, their spy status gave them access to resources.</li>
</ul></li>
<li>In the late 1950s, Barr and Sarant began building the UMM computer (“mind” in Russian).
<ul>
<li>Their work got the attention of Shokhin.</li>
</ul></li>
</ul>
</section>
<section id="zelenograd-the-dream-of-a-soviet-silicon-valley" class="level3">
<h3 class="anchored" data-anchor-id="zelenograd-the-dream-of-a-soviet-silicon-valley">Zelenograd: The Dream of a Soviet Silicon Valley</h3>
<ul>
<li>Barr, Sarant, and Shokhin partnered to convince Khrushchev to create a city dedicated to semiconductor production.
<ul>
<li>They envisioned a city with its own researchers, engineers, labs, and production facilities.</li>
</ul></li>
<li>To persuade Khrushchev, Shokhin arranged for him to visit Leningrad’s Special Design Bureau of the Electronics Industry No.&nbsp;2.
<ul>
<li>During the visit, Sarant and Barr showcased Soviet microelectronics achievements, including a miniature radio and a basic computer.</li>
<li>They argued that semiconductors would be crucial for spacecraft, industry, government, aircraft, and even the nuclear missile shield.</li>
</ul></li>
<li>They presented Khrushchev with plans for a futuristic semiconductor city centered around a 52-story skyscraper.
<ul>
<li>Khrushchev loved grand projects and approved the idea.</li>
</ul></li>
<li>The Soviet government soon greenlit the construction of <strong>Zelenograd</strong> (“green city” in Russian) on Moscow’s outskirts.
<ul>
<li>Shokhin envisioned a self-sufficient scientific paradise with research labs, production facilities, schools, daycare, entertainment, libraries, and a hospital.</li>
<li>The <strong>Moscow Institute of Electronic Technology</strong> was built in Zelenograd, modeled after English and American universities.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-8-copy-it" class="level2">
<h2 class="anchored" data-anchor-id="chapter-8-copy-it">Chapter 8: Copy It</h2>
<section id="the-copy-it-strategy-and-its-limitations" class="level3">
<h3 class="anchored" data-anchor-id="the-copy-it-strategy-and-its-limitations">The “Copy It” Strategy and Its Limitations</h3>
<ul>
<li>Around the same time Zelenograd was approved, Soviet student <strong>Boris Malin</strong> returned from Pennsylvania with a <strong>Texas Instruments SN-51</strong>, one of the first commercially available integrated circuits.
<ul>
<li><strong>Alexander Shokhin</strong>, head of Soviet microelectronics, saw it as vital to acquire.</li>
</ul></li>
<li>Shokhin ordered a group of engineers, including Malin, to “Copy it, one for one, without any deviations” within three months.
<ul>
<li>Soviet scientists were angered, believing they were capable of independent innovation.</li>
</ul></li>
<li>While the USSR had leading theoretical physicists, they lagged in practical application and manufacturing, especially in high-volume chipmaking.
<ul>
<li>They excelled in quantity, but not quality or purity, crucial for chipmaking.</li>
</ul></li>
<li><strong>COCOM</strong> restrictions also hindered the USSR’s access to advanced technologies, including semiconductor components.
<ul>
<li>The Soviets used shell companies to bypass COCOM, but this was difficult to do on a large scale.</li>
</ul></li>
</ul>
</section>
<section id="the-limitations-of-espionage-in-semiconductor-production" class="level3">
<h3 class="anchored" data-anchor-id="the-limitations-of-espionage-in-semiconductor-production">The Limitations of Espionage in Semiconductor Production</h3>
<ul>
<li>Simply stealing a chip didn’t reveal how it was made.
<ul>
<li>The chipmaking process required specialized knowledge, often unwritten, about temperatures, chemicals, and exposure times.</li>
<li>Soviet spies couldn’t easily steal this type of knowledge.</li>
</ul></li>
<li>Additionally, the rapid pace of innovation, driven by <strong>Moore’s Law</strong>, meant stolen designs quickly became obsolete.
<ul>
<li>American companies introduced new, more powerful chips annually.</li>
</ul></li>
</ul>
</section>
<section id="the-structural-flaws-of-the-soviet-semiconductor-industry" class="level3">
<h3 class="anchored" data-anchor-id="the-structural-flaws-of-the-soviet-semiconductor-industry">The Structural Flaws of the Soviet Semiconductor Industry</h3>
<ul>
<li>The Soviet leadership didn’t grasp how the “copy it” strategy ensured their technological backwardness.</li>
<li>The entire Soviet semiconductor industry operated like a secretive, top-down defense contractor.
<ul>
<li>There was little room for creativity or market-driven innovation.</li>
<li>Civilian products were a low priority.</li>
</ul></li>
<li>This system stifled innovation and condemned them to follow the US lead, even in such a sensitive industry.</li>
<li>Zelenograd, despite its resources and stolen secrets, could not replicate Silicon Valley’s success.
<ul>
<li>Soviet engineers lacked the practical, on-the-factory-floor experience of their American counterparts.</li>
<li>Career advancement in the USSR favored bureaucracy over innovation.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-9-the-transistor-salesman" class="level2">
<h2 class="anchored" data-anchor-id="chapter-9-the-transistor-salesman">Chapter 9: The Transistor Salesman</h2>
<section id="japans-post-war-economic-transformation" class="level3">
<h3 class="anchored" data-anchor-id="japans-post-war-economic-transformation">Japan’s Post-War Economic Transformation</h3>
<ul>
<li>In 1962, Japanese Prime Minister <strong>Hayato Ikeda</strong> gifted French President <strong>Charles de Gaulle</strong> a Sony transistor radio.
<ul>
<li>De Gaulle, dismissive of Japan as a mere “economic power,” scoffed that Ikeda behaved like a “transistor salesman.”</li>
</ul></li>
<li>This chapter highlights how Japan’s semiconductor industry would make it wealthy and powerful.</li>
<li>Integrated circuits not only revolutionized electronics, but also connected nations, with the US at the center.</li>
<li>Unlike the USSR, Japan deliberately integrated itself into the US semiconductor industry, supported by Japanese business leaders and the US government.</li>
</ul>
</section>
<section id="the-us-role-in-japans-technological-rebirth" class="level3">
<h3 class="anchored" data-anchor-id="the-us-role-in-japans-technological-rebirth">The US Role in Japan’s Technological Rebirth</h3>
<ul>
<li>After World War II, some in the US favored dismantling Japan’s high-tech industries as punishment.</li>
<li>However, US defense officials soon adopted a policy of supporting a strong Japan as a Cold War strategy.
<ul>
<li>The aim was to rebuild Japan’s economy while tying it to the US-led system.</li>
<li>Making Japan a “transistor salesman” became central to this strategy.</li>
</ul></li>
</ul>
</section>
<section id="makoto-kikuchi-and-the-introduction-of-the-transistor-to-japan" class="level3">
<h3 class="anchored" data-anchor-id="makoto-kikuchi-and-the-introduction-of-the-transistor-to-japan">Makoto Kikuchi and the Introduction of the Transistor to Japan</h3>
<ul>
<li><strong>Makoto Kikuchi</strong>, a young physicist at the Electrotechnical Laboratory in Tokyo, was among the first in Japan to learn about the transistor.</li>
<li>He stayed informed through US scientific journals, which were otherwise unavailable in postwar Japan.</li>
<li>In 1953, Kikuchi met <strong>John Bardeen</strong>, co-inventor of the transistor, during Bardeen’s visit to Tokyo for a physics conference.</li>
</ul>
</section>
<section id="akio-morita-and-sonys-embrace-of-the-transistor" class="level3">
<h3 class="anchored" data-anchor-id="akio-morita-and-sonys-embrace-of-the-transistor">Akio Morita and Sony’s Embrace of the Transistor</h3>
<ul>
<li>In 1953, <strong>Akio Morita</strong>, co-founder of Sony, traveled to New York and secured a license from AT&amp;T to produce transistors.
<ul>
<li>AT&amp;T believed the transistor’s use was limited to hearing aids.</li>
</ul></li>
<li>Morita, however, recognized the transistor’s potential to transform consumer electronics.
<ul>
<li>He aimed to sell these devices not just in Japan, but also in the US, the world’s biggest consumer market.</li>
</ul></li>
<li>Japan’s government, through MITI (Ministry of International Trade and Industry), supported the growth of its electronics firms.
<ul>
<li>However, their bureaucracy sometimes clashed with the private sector.</li>
</ul></li>
</ul>
</section>
<section id="sonys-innovation-and-the-rise-of-japanese-electronics" class="level3">
<h3 class="anchored" data-anchor-id="sonys-innovation-and-the-rise-of-japanese-electronics">Sony’s Innovation and the Rise of Japanese Electronics</h3>
<ul>
<li>Unlike the USSR’s “copy it” approach, Sony focused on <strong>innovation</strong>, <strong>product design</strong>, and <strong>marketing</strong>.</li>
<li>They licensed transistor technology but excelled at identifying and targeting new markets with desirable products.
<ul>
<li>“Our plan is to lead the public with new products rather than ask them what kind of products they want,” Morita declared. “The public does not know what is possible, but we do.”</li>
</ul></li>
<li>Sony’s transistor radios were a major success.</li>
<li>Japanese firms, leveraging lower wages and US technology, became major players in consumer electronics.</li>
</ul>
</section>
<section id="a-symbiotic-relationship" class="level3">
<h3 class="anchored" data-anchor-id="a-symbiotic-relationship">A Symbiotic Relationship</h3>
<ul>
<li>The semiconductor industry fostered a complex interdependence between the US and Japan.</li>
<li>By 1964, Japan led in <strong>discrete transistor</strong> production, while US firms made the most advanced chips.</li>
<li>The US built the best computers, while Japan excelled in consumer electronics, driving semiconductor demand.</li>
<li>Despite some US industry concerns about Japanese competition, the US government understood the strategic importance of a strong Japanese electronics sector.</li>
<li>This semiconductor symbiosis benefited both countries:
<ul>
<li>Japan gained access to technology and economic growth.</li>
<li>The US strengthened a key Cold War ally and expanded its economic influence in Asia.</li>
</ul></li>
<li>By the end of the 1970s:
<ul>
<li>Japan’s electronics exports boomed.</li>
<li>US-Japan interdependence deepened.</li>
<li>Japan emerged as a global economic power.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-10-transistor-girls" class="level2">
<h2 class="anchored" data-anchor-id="chapter-10-transistor-girls">Chapter 10: Transistor Girls</h2>
<section id="the-gendered-division-of-labor-in-the-semiconductor-industry" class="level3">
<h3 class="anchored" data-anchor-id="the-gendered-division-of-labor-in-the-semiconductor-industry">The Gendered Division of Labor in the Semiconductor Industry</h3>
<ul>
<li>This chapter explores the role of women in the semiconductor industry, particularly in assembly line work.</li>
<li>The title, “Transistor Girls,” is a play on the 1964 Australian novel of the same name, which depicted Asian women factory workers in a stereotypical and sexualized manner.</li>
<li>The chapter highlights the industry’s reliance on women’s labor, often exploited for lower wages and perceived dexterity.</li>
</ul>
</section>
<section id="charlie-sporck-and-the-drive-for-efficiency" class="level3">
<h3 class="anchored" data-anchor-id="charlie-sporck-and-the-drive-for-efficiency">Charlie Sporck and the Drive for Efficiency</h3>
<ul>
<li><strong>Charlie Sporck</strong> was a production manager at Fairchild Semiconductor known for his focus on efficiency and opposition to unions.</li>
<li>Spork’s background:
<ul>
<li>He had an engineering degree from Cornell.</li>
<li>He previously worked at GE, where he clashed with unions over his proposed changes to the assembly line.</li>
<li>He joined Fairchild in 1959.</li>
</ul></li>
<li>At Fairchild, Spork was determined to prevent unionization and maximize worker productivity.</li>
</ul>
</section>
<section id="women-in-semiconductor-assembly" class="level3">
<h3 class="anchored" data-anchor-id="women-in-semiconductor-assembly">Women in Semiconductor Assembly</h3>
<ul>
<li>The semiconductor industry in Silicon Valley relied heavily on female labor for assembly line work.</li>
<li>Reasons for hiring women:
<ul>
<li><strong>Lower wages:</strong> Women were paid less than men for similar work.</li>
<li><strong>Perceived dexterity:</strong> Managers believed women’s smaller hands were better suited for the intricate tasks of assembling and testing chips.</li>
<li><strong>Less likely to unionize:</strong> Women were seen as less likely to join unions or demand better working conditions.</li>
</ul></li>
<li>Women’s history in the Santa Clara Valley:
<ul>
<li>Many had worked in canneries and the aerospace industry, so they were familiar with factory work.</li>
</ul></li>
<li>The 1965 Immigration Act increased the pool of foreign-born women available for these jobs.</li>
</ul>
</section>
<section id="offshoring-to-asia-hong-kong" class="level3">
<h3 class="anchored" data-anchor-id="offshoring-to-asia-hong-kong">Offshoring to Asia: Hong Kong</h3>
<ul>
<li>Faced with labor shortages in the US, Fairchild Semiconductor looked to Asia for cheaper labor.</li>
<li><strong>Bob Noyce</strong> suggested exploring Hong Kong, where he had invested in a radio factory.</li>
<li><strong>Charlie Sporck</strong> visited Hong Kong and was impressed by the low wages and high productivity of the (mostly female) workforce.
<ul>
<li>Wages in Hong Kong were around 25 cents an hour, one-tenth of the US average.</li>
</ul></li>
<li>Fairchild set up an assembly facility in Hong Kong in 1963.
<ul>
<li>This was the beginning of the semiconductor industry’s shift to Asia.</li>
</ul></li>
</ul>
</section>
<section id="expanding-to-other-asian-countries" class="level3">
<h3 class="anchored" data-anchor-id="expanding-to-other-asian-countries">Expanding to Other Asian Countries</h3>
<ul>
<li>Fairchild’s success in Hong Kong led them to expand to other Asian countries with even lower wages.</li>
<li>Spork targeted countries with:
<ul>
<li>Low wages.</li>
<li>A lack of strong labor unions.</li>
</ul></li>
<li>Fairchild opened facilities in:
<ul>
<li><strong>Singapore</strong></li>
<li><strong>Malaysia</strong> (Penang).</li>
</ul></li>
<li>Other US chipmakers followed suit.</li>
</ul>
</section>
<section id="the-geopolitical-impact-of-offshoring" class="level3">
<h3 class="anchored" data-anchor-id="the-geopolitical-impact-of-offshoring">The Geopolitical Impact of Offshoring</h3>
<ul>
<li>The offshoring of semiconductor assembly had significant geopolitical implications:
<ul>
<li>It strengthened economic ties between the US and Asian countries during the Cold War.</li>
<li>It provided jobs and economic development in these countries, potentially mitigating the appeal of communism.</li>
<li>It created a globalized supply chain that would shape the future of the electronics industry.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-11-precision-strike" class="level2">
<h2 class="anchored" data-anchor-id="chapter-11-precision-strike">Chapter 11: Precision Strike</h2>
<section id="the-need-for-precision-in-warfare" class="level3">
<h3 class="anchored" data-anchor-id="the-need-for-precision-in-warfare">The Need for Precision in Warfare</h3>
<ul>
<li>This chapter examines how the semiconductor revolution transformed military technology, particularly the development of <strong>precision-guided munitions</strong>.</li>
<li>During the Vietnam War, the US military relied heavily on unguided bombs, which were largely ineffective.
<ul>
<li>Operation Rolling Thunder (1965-1968) dropped a massive amount of bombs but had limited impact.</li>
</ul></li>
<li>The <strong>Shrike missile</strong>, which homed in on enemy radar, was somewhat successful, but many other guidance systems were unreliable.
<ul>
<li>A 1985 study revealed the low success rate of air-to-air missiles beyond visual range.</li>
</ul></li>
<li>The military realized it needed to improve the accuracy of its weapons.</li>
</ul>
</section>
<section id="weldon-word-and-the-development-of-laser-guided-bombs" class="level3">
<h3 class="anchored" data-anchor-id="weldon-word-and-the-development-of-laser-guided-bombs">Weldon Word and the Development of Laser-Guided Bombs</h3>
<ul>
<li><strong>Weldon Word</strong>, a project engineer at Texas Instruments (TI), recognized the potential of microelectronics to improve weapons guidance.
<ul>
<li>He envisioned a system where sensors, missiles, and computers worked together to ensure accurate strikes.</li>
</ul></li>
<li>Word believed the key to successful military technology was simplicity and affordability.</li>
<li>In 1965, Word met with <strong>Colonel Joe Davis</strong> at Eglin Air Force Base.
<ul>
<li>Davis showed Word a photo of the <strong>Thang Hoa Bridge</strong> in North Vietnam, which had withstood numerous bombing attempts.</li>
<li>This highlighted the need for more accurate weapons.</li>
</ul></li>
</ul>
</section>
<section id="the-paveway-laser-guided-bomb" class="level3">
<h3 class="anchored" data-anchor-id="the-paveway-laser-guided-bomb">The Paveway Laser-Guided Bomb</h3>
<ul>
<li>Word, inspired by the Thang Hoa Bridge challenge, developed the <strong>Paveway laser-guided bomb</strong>.</li>
<li>How it worked:
<ol type="1">
<li>A laser designator illuminated the target.</li>
<li>The bomb, equipped with a laser seeker and control surfaces (wings), followed the reflected laser light.</li>
<li>A simple silicon chip with four quadrants detected the laser light and adjusted the wings to keep the bomb on target.</li>
</ol></li>
<li>The Paveway was:
<ul>
<li>Simple in design.</li>
<li>Affordable to produce.</li>
<li>Highly accurate.</li>
</ul></li>
</ul>
</section>
<section id="impact-and-legacy-of-precision-guided-munitions" class="level3">
<h3 class="anchored" data-anchor-id="impact-and-legacy-of-precision-guided-munitions">Impact and Legacy of Precision-Guided Munitions</h3>
<ul>
<li>The Paveway was first used in combat in 1972 and proved highly effective in destroying bridges and other targets.</li>
<li>The Vietnam War demonstrated the potential of microelectronics to revolutionize warfare.</li>
<li>The development of the Paveway marked a turning point in military technology, paving the way for more advanced precision-guided weapons.</li>
</ul>
</section>
</section>
<section id="chapter-12-supply-chain-statecraft" class="level2">
<h2 class="anchored" data-anchor-id="chapter-12-supply-chain-statecraft">Chapter 12: Supply Chain Statecraft</h2>
<section id="texas-instruments-expands-to-taiwan" class="level3">
<h3 class="anchored" data-anchor-id="texas-instruments-expands-to-taiwan">Texas Instruments Expands to Taiwan</h3>
<ul>
<li>This chapter explores how semiconductor production became a tool of US foreign policy, particularly in strengthening ties with Taiwan.</li>
<li>In 1968, Texas Instruments (TI) executives <strong>Mark Shepard</strong> and <strong>Morris Chang</strong> traveled to Asia to scout locations for a new chip assembly facility.</li>
<li>Their initial visit to Taiwan was fraught with cultural misunderstandings and disagreements with <strong>K.T. Lee</strong>, Taiwan’s economy minister.</li>
</ul>
</section>
<section id="taiwans-strategic-vulnerabilities-and-opportunities" class="level3">
<h3 class="anchored" data-anchor-id="taiwans-strategic-vulnerabilities-and-opportunities">Taiwan’s Strategic Vulnerabilities and Opportunities</h3>
<ul>
<li>Taiwan in the late 1960s:
<ul>
<li>Economically successful, but politically isolated.</li>
<li>Faced a growing threat from mainland China, which had developed nuclear weapons.</li>
<li>The US, Taiwan’s main ally, was reducing its global commitments after the Vietnam War.</li>
</ul></li>
<li><strong>K.T. Lee</strong> recognized the strategic opportunity presented by TI:
<ul>
<li>Attracting foreign investment could boost Taiwan’s economy and technological development.</li>
<li>Deepening economic ties with the US could enhance Taiwan’s security.</li>
</ul></li>
</ul>
</section>
<section id="a-mutually-beneficial-partnership" class="level3">
<h3 class="anchored" data-anchor-id="a-mutually-beneficial-partnership">A Mutually Beneficial Partnership</h3>
<ul>
<li>TI also saw advantages in Taiwan:
<ul>
<li>Low wages.</li>
<li>A government eager to attract foreign investment.</li>
</ul></li>
<li>Chang, a native of mainland China, was initially hesitant about Taiwan but became convinced by former classmates.</li>
<li>Despite their initial clashes, Shepard and Lee smoothed over relations.</li>
<li>TI’s board approved the Taiwan facility in July 1968, and it began production in 1969.</li>
</ul>
</section>
<section id="semiconductors-as-a-tool-of-us-foreign-policy" class="level3">
<h3 class="anchored" data-anchor-id="semiconductors-as-a-tool-of-us-foreign-policy">Semiconductors as a Tool of US Foreign Policy</h3>
<ul>
<li>TI’s investment was part of a broader trend of US semiconductor firms setting up assembly plants in Asia.</li>
<li>This strategy:
<ul>
<li>Provided low-cost labor for US companies.</li>
<li>Boosted economic growth in Asian countries.</li>
<li>Strengthened US ties with these countries during the Cold War.</li>
</ul></li>
<li>Leaders like Singapore’s <strong>Lee Kuan Yew</strong> saw electronics exports as key to economic growth and political stability.</li>
</ul>
</section>
<section id="the-enduring-impact-of-semiconductor-supply-chains" class="level3">
<h3 class="anchored" data-anchor-id="the-enduring-impact-of-semiconductor-supply-chains">The Enduring Impact of Semiconductor Supply Chains</h3>
<ul>
<li>By the early 1980s, US semiconductor firms employed tens of thousands of workers in Asia, mainly in Korea, Taiwan, and Southeast Asia.</li>
<li>This created a complex web of interdependence, with:
<ul>
<li>US firms relying on Asian labor and markets.</li>
<li>Asian countries benefiting from investment, technology transfer, and jobs.</li>
<li>The US strengthening its economic and strategic position in Asia.</li>
</ul></li>
<li>This interdependence endured even as the US reduced its military presence in the region after Vietnam.</li>
</ul>
</section>
</section>
<section id="chapter-13-intels-revolutionaries" class="level2">
<h2 class="anchored" data-anchor-id="chapter-13-intels-revolutionaries">Chapter 13: Intel’s Revolutionaries</h2>
<section id="the-birth-of-intel" class="level3">
<h3 class="anchored" data-anchor-id="the-birth-of-intel">The Birth of Intel</h3>
<ul>
<li>The year 1968 was marked by global upheaval, but a seemingly minor event in Silicon Valley would have a revolutionary impact: the founding of <strong>Intel</strong>.</li>
<li><strong>Bob Noyce</strong> and <strong>Gordon Moore</strong>, frustrated with their limited control at Fairchild Semiconductor, decided to start their own company.</li>
<li>Their goal:
<ul>
<li>To make <strong>transistors</strong> ubiquitous and affordable, driving a revolution in computing.</li>
</ul></li>
</ul>
</section>
<section id="the-invention-of-dram" class="level3">
<h3 class="anchored" data-anchor-id="the-invention-of-dram">The Invention of DRAM</h3>
<ul>
<li>One of Intel’s first major products was the <strong>Dynamic Random Access Memory (DRAM)</strong> chip.</li>
<li>Before DRAM, computers stored data using <strong>magnetic cores</strong>, which were bulky and difficult to scale down.</li>
<li><strong>Robert Dennard</strong> at IBM developed the concept of DRAM:
<ul>
<li>Using a <strong>transistor</strong> and a <strong>capacitor</strong> to store a single bit of information.</li>
<li>Repeatedly charging the capacitor to maintain data storage (“dynamic”).</li>
</ul></li>
<li>Intel’s DRAM chips were:
<ul>
<li>Smaller.</li>
<li>More reliable.</li>
<li>Cheaper to produce than magnetic cores.</li>
</ul></li>
</ul>
</section>
<section id="from-memory-to-microprocessors" class="level3">
<h3 class="anchored" data-anchor-id="from-memory-to-microprocessors">From Memory to Microprocessors</h3>
<ul>
<li>Initially, Intel focused on memory chips, but Bob Noyce, always seeking new challenges, agreed to develop a custom chip for a Japanese calculator company, <strong>Busicom</strong>.</li>
<li><strong>Ted Hoff</strong>, an Intel engineer with a background in computer architecture, was assigned to the project.</li>
<li>Hoff realized that:
<ul>
<li>Designing custom chips for each device was expensive and time-consuming.</li>
<li>Intel’s increasingly powerful memory chips enabled computers to handle more complex software.</li>
</ul></li>
</ul>
</section>
<section id="the-intel-4004-the-worlds-first-microprocessor" class="level3">
<h3 class="anchored" data-anchor-id="the-intel-4004-the-worlds-first-microprocessor">The Intel 4004: The World’s First Microprocessor</h3>
<ul>
<li>Hoff proposed developing a <strong>general-purpose logic chip</strong> that could be programmed with software for various tasks.
<ul>
<li>This would be more efficient and cost-effective than custom designs.</li>
</ul></li>
<li>The result was the <strong>Intel 4004</strong>, marketed as the world’s first <strong>microprocessor</strong>.
<ul>
<li>It could be used in a wide range of devices, leading to a revolution in computing.</li>
</ul></li>
</ul>
</section>
<section id="carver-mead-and-the-vision-of-ubiquitous-computing" class="level3">
<h3 class="anchored" data-anchor-id="carver-mead-and-the-vision-of-ubiquitous-computing">Carver Mead and the Vision of Ubiquitous Computing</h3>
<ul>
<li><strong>Carver Mead</strong>, a Caltech professor and Intel consultant, understood the profound implications of Intel’s work.
<ul>
<li>He popularized the term “Moore’s Law.”</li>
</ul></li>
<li>Mead predicted that microelectronics would lead to the automation of many aspects of society.
<ul>
<li>He envisioned tiny, inexpensive computers embedded in everyday devices.</li>
</ul></li>
</ul>
</section>
<section id="the-revolutionaries" class="level3">
<h3 class="anchored" data-anchor-id="the-revolutionaries">The Revolutionaries</h3>
<ul>
<li>Intel’s founders and engineers saw themselves as revolutionaries.
<ul>
<li>They were not tearing down the existing order through violence but reshaping it through technological innovation.</li>
</ul></li>
<li>Gordon Moore, reflecting on the societal changes driven by microelectronics, stated in 1973: “We are really the revolutionaries in the world today, not the kids with the long hair and beards who were wrecking the schools a few years ago.”</li>
</ul>
</section>
</section>
<section id="chapter-14-the-pentagons-offset-strategy" class="level2">
<h2 class="anchored" data-anchor-id="chapter-14-the-pentagons-offset-strategy">Chapter 14: The Pentagon’s Offset Strategy</h2>
<section id="william-perry-and-the-pentagons-technological-turn" class="level3">
<h3 class="anchored" data-anchor-id="william-perry-and-the-pentagons-technological-turn">William Perry and the Pentagon’s Technological Turn</h3>
<ul>
<li>This chapter explores how the Pentagon, facing a resurgent Soviet Union, turned to microelectronics to regain its technological edge.</li>
<li><strong>William Perry</strong> became Undersecretary of Defense for Research and Engineering in 1977.
<ul>
<li>He was a Silicon Valley entrepreneur with deep knowledge of semiconductor technology.</li>
<li>He previously worked at Sylvania Electronic Defense Laboratories and founded his own defense electronics company.</li>
</ul></li>
</ul>
</section>
<section id="the-soviet-challenge-and-the-need-for-a-new-strategy" class="level3">
<h3 class="anchored" data-anchor-id="the-soviet-challenge-and-the-need-for-a-new-strategy">The Soviet Challenge and the Need for a New Strategy</h3>
<ul>
<li>Perry arrived in Washington at a time when the US military faced significant challenges:
<ul>
<li>Defeat in Vietnam.</li>
<li>The Soviet Union’s growing military might, particularly its nuclear arsenal and conventional forces.</li>
</ul></li>
<li><strong>Andrew Marshall</strong>, director of the Pentagon’s Office of Net Assessment, argued that the US needed to exploit its technological advantage in computers to offset the USSR’s numerical superiority.</li>
</ul>
</section>
<section id="precision-guided-munitions-and-the-offset-strategy" class="level3">
<h3 class="anchored" data-anchor-id="precision-guided-munitions-and-the-offset-strategy">Precision-Guided Munitions and the “Offset Strategy”</h3>
<ul>
<li>Perry embraced Marshall’s vision and believed that microelectronics was the key to a new “offset strategy.”</li>
<li>He pushed for investments in:
<ul>
<li><strong>Precision-guided munitions (PGMs):</strong> Using microchips to dramatically improve the accuracy of weapons.</li>
<li><strong>Satellites:</strong> For surveillance, communication, and targeting.</li>
<li><strong>Next-generation chips:</strong> To maintain US technological leadership.</li>
</ul></li>
</ul>
</section>
<section id="perrys-vision-for-a-high-tech-military" class="level3">
<h3 class="anchored" data-anchor-id="perrys-vision-for-a-high-tech-military">Perry’s Vision for a High-Tech Military</h3>
<ul>
<li>Perry believed that miniaturized computing power would revolutionize warfare:
<ul>
<li>“We will be able to put computers, which only 10 years ago would have filled up this entire room, on a chip and field smart weapons at all levels,” he said in 1981.</li>
</ul></li>
<li>He championed programs like the <strong>Tomahawk cruise missile</strong>, which relied on sophisticated onboard computers for navigation and guidance.</li>
<li>He envisioned a future of <strong>networked warfare</strong>, with sensors, weapons, and command centers sharing information in real time.</li>
</ul>
</section>
<section id="criticism-and-skepticism" class="level3">
<h3 class="anchored" data-anchor-id="criticism-and-skepticism">Criticism and Skepticism</h3>
<ul>
<li>Perry’s focus on high technology faced criticism from some quarters:
<ul>
<li>Some questioned the reliability and cost-effectiveness of PGMs.</li>
<li>Others doubted the Pentagon’s ability to adapt to rapidly changing technologies.</li>
</ul></li>
<li>Perry dismissed these criticisms, arguing that his opponents underestimated the pace of innovation in microelectronics.</li>
</ul>
</section>
<section id="the-enduring-legacy-of-the-offset-strategy" class="level3">
<h3 class="anchored" data-anchor-id="the-enduring-legacy-of-the-offset-strategy">The Enduring Legacy of the Offset Strategy</h3>
<ul>
<li>Despite skepticism, Perry’s vision largely prevailed.</li>
<li>The Pentagon continued to invest heavily in microelectronics and PGMs, leading to:
<ul>
<li>The development of increasingly sophisticated weapons systems.</li>
<li>The transformation of US military doctrine toward precision strike and information warfare.</li>
</ul></li>
<li>The “offset strategy” helped to maintain US military superiority even as the Soviet Union collapsed.</li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<ul>
<li>The semiconductor revolution had profound geopolitical implications:
<ul>
<li>It transformed the nature of warfare.</li>
<li>It strengthened US military power.</li>
<li>It deepened US economic and strategic ties with key Asian countries.</li>
</ul></li>
<li>By the end of the Cold War, the US, thanks in large part to its dominance in semiconductors, had emerged as the world’s sole superpower.</li>
</ul>
<hr>
</section>
</section>
<section id="chapter-15-that-competition-is-tough" class="level2">
<h2 class="anchored" data-anchor-id="chapter-15-that-competition-is-tough">Chapter 15: That Competition is Tough</h2>
<section id="the-semiconductor-industry-crisis" class="level3">
<h3 class="anchored" data-anchor-id="the-semiconductor-industry-crisis">The Semiconductor Industry Crisis</h3>
<ul>
<li><strong>Richard Anderson</strong>, a Hewlett-Packard executive, found himself at the center of the semiconductor industry crisis in the 1980s.</li>
<li>Silicon Valley, once dominant, faced fierce competition from <strong>Japan</strong>.</li>
<li><strong>Hewlett-Packard (HP)</strong>
<ul>
<li>One of America’s largest tech companies and a major semiconductor buyer.</li>
<li>Founded in the 1930s by Stanford graduates Dave Packard and Bill Hewlett.</li>
<li>Anderson’s chip assessments held significant weight, influencing purchasing decisions.</li>
</ul></li>
</ul>
</section>
<section id="japanese-semiconductor-companies" class="level3">
<h3 class="anchored" data-anchor-id="japanese-semiconductor-companies">Japanese Semiconductor Companies</h3>
<ul>
<li><strong>Toshiba</strong> and <strong>NEC</strong>, Japanese companies, entered the DRAM memory chip market.</li>
<li>Initially underestimated by Silicon Valley, who believed in Japan’s reputation for imitation (“click-click” of cameras).</li>
<li><strong>Anderson’s Findings:</strong>
<ul>
<li>Japanese chips demonstrated superior quality compared to American counterparts.
<ul>
<li>Japanese firms reported failure rates below <strong>0.02%</strong> in the first 1,000 hours.</li>
<li>American firms ranged from <strong>0.09%</strong> to <strong>0.26%</strong> failure rates.</li>
</ul></li>
<li>Despite similar functionality and cost, American DRAM chips malfunctioned more frequently.</li>
</ul></li>
</ul>
</section>
<section id="japans-rise-in-consumer-electronics" class="level3">
<h3 class="anchored" data-anchor-id="japans-rise-in-consumer-electronics">Japan’s Rise in Consumer Electronics</h3>
<ul>
<li>Japan shed its “cheap” image and became synonymous with high-quality products.</li>
<li><strong>Akio Morita</strong>, Sony’s entrepreneur, spearheaded this transformation.
<ul>
<li>Sony’s transistor radios challenged American dominance.</li>
<li>Japanese companies, emboldened by Sony’s success, targeted higher-end markets.</li>
</ul></li>
<li><strong>Shift in Strategy:</strong>
<ul>
<li>Initial success stemmed from replicating and improving upon U.S. products at lower costs.</li>
<li>Gradual transition to innovation, exemplified by Sony’s Walkman.</li>
</ul></li>
</ul>
</section>
<section id="the-walkman-a-japanese-innovation" class="level3">
<h3 class="anchored" data-anchor-id="the-walkman-a-japanese-innovation">The Walkman: A Japanese Innovation</h3>
<ul>
<li>Introduced in <strong>1979</strong>, the Walkman revolutionized portable music.
<ul>
<li>Featured five of Sony’s advanced integrated circuits.</li>
</ul></li>
<li>Global sales reached <strong>385 million units</strong>, making it one of history’s most popular consumer devices.</li>
<li>The Walkman demonstrated Japan’s capacity for innovation.</li>
</ul>
</section>
<section id="u.s.-support-for-japans-transformation" class="level3">
<h3 class="anchored" data-anchor-id="u.s.-support-for-japans-transformation">U.S. Support for Japan’s Transformation</h3>
<ul>
<li>The U.S. played a key role in Japan’s post-war rise as a tech power:
<ul>
<li>Transfer of transistor technology to Japanese physicists during the occupation.</li>
<li>U.S. policies facilitated Japanese firms’ access to American markets.</li>
</ul></li>
</ul>
</section>
<section id="concerns-about-u.s.-competitiveness" class="level3">
<h3 class="anchored" data-anchor-id="concerns-about-u.s.-competitiveness">Concerns About U.S. Competitiveness</h3>
<ul>
<li>Some Americans questioned if supporting Japan had inadvertently undermined U.S. economic and technological dominance.</li>
<li><strong>Charlie Sporck</strong>, a semiconductor industry veteran, observed Japan’s productivity with a mix of fascination and fear.
<ul>
<li>Japan’s efficiency surpassed anything his American workforce could achieve.</li>
<li>Spork’s Findings from Sending Workers to Japan:
<ul>
<li>Japanese workers displayed exceptional company loyalty.</li>
<li>Japanese foremen prioritized the company over their families.</li>
<li>Japanese productivity levels were significantly higher.</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-16-at-war-with-japan" class="level2">
<h2 class="anchored" data-anchor-id="chapter-16-at-war-with-japan">Chapter 16: At War with Japan</h2>
<section id="jerry-sanders-and-the-competitive-chip-industry" class="level3">
<h3 class="anchored" data-anchor-id="jerry-sanders-and-the-competitive-chip-industry">Jerry Sanders and the Competitive Chip Industry</h3>
<ul>
<li><strong>Jerry Sanders</strong>, CEO of Advanced Micro Devices (AMD), recognized the fierce competition within the chip industry.
<ul>
<li>Known for his aggressive business style (“I can’t walk away from a fight”).</li>
<li>AMD frequently engaged in legal battles with Intel over intellectual property.</li>
</ul></li>
<li><strong>Charlie Sporck</strong> described the industry as a battle for survival: “Knock ’em down, fight ’em, kill ’em.”</li>
<li>Intense competition, driven by high stakes and personal pride, was characteristic of the U.S. chip industry.</li>
</ul>
</section>
<section id="japanese-competition-a-different-threat" class="level3">
<h3 class="anchored" data-anchor-id="japanese-competition-a-different-threat">Japanese Competition: A Different Threat</h3>
<ul>
<li>Japanese competition, embodied by companies like <strong>Hitachi, Fujitsu, Toshiba, and NEC</strong>, posed an existential threat.</li>
<li><strong>Spork’s Concerns:</strong>
<ul>
<li>Japanese success could shift the entire industry to the Pacific Rim.</li>
<li>He drew parallels to the decline of the U.S. television industry, warning of similar consequences for semiconductors.</li>
</ul></li>
<li><strong>“We’re at war with Japan,”</strong> Spork declared, emphasizing an economic battle fought with technology, productivity, and quality.</li>
</ul>
</section>
<section id="accusations-of-japanese-espionage-and-unfair-practices" class="level3">
<h3 class="anchored" data-anchor-id="accusations-of-japanese-espionage-and-unfair-practices">Accusations of Japanese Espionage and Unfair Practices</h3>
<ul>
<li>Spork believed Japanese firms benefited unfairly from:
<ul>
<li>Intellectual property theft</li>
<li>Protected markets</li>
<li>Government subsidies</li>
<li>Cheap capital</li>
</ul></li>
</ul>
</section>
<section id="the-hitachi-espionage-case-1981" class="level3">
<h3 class="anchored" data-anchor-id="the-hitachi-espionage-case-1981">The Hitachi Espionage Case (1981)</h3>
<ul>
<li><strong>Jun Naruse</strong>, a Hitachi employee, was caught attempting to steal trade secrets from <strong>Pratt &amp; Whitney</strong>, an aircraft manufacturer.
<ul>
<li>Naruse obtained a fake badge to access a secure facility and photograph a computer.</li>
<li>Hitachi’s involvement in the scheme was revealed, leading to arrests and a public scandal.</li>
</ul></li>
<li>Similar accusations of espionage were leveled against <strong>Mitsubishi Electric</strong>.</li>
</ul>
</section>
<section id="toshiba-and-the-soviet-submarine-scandal" class="level3">
<h3 class="anchored" data-anchor-id="toshiba-and-the-soviet-submarine-scandal">Toshiba and the Soviet Submarine Scandal</h3>
<ul>
<li><strong>Toshiba</strong>, a leading DRAM producer, was implicated in selling machinery to the Soviet Union that helped them build quieter submarines.</li>
<li>While unrelated to Toshiba’s semiconductor business, the scandal further fueled perceptions of Japanese companies engaging in unethical practices.</li>
</ul>
</section>
<section id="silicon-valleys-practices-a-double-standard" class="level3">
<h3 class="anchored" data-anchor-id="silicon-valleys-practices-a-double-standard">Silicon Valley’s Practices: A Double Standard?</h3>
<ul>
<li>The chip industry, including American companies, commonly engaged in:
<ul>
<li>Competitor monitoring</li>
<li>Employee poaching</li>
<li>Accusations of intellectual property infringement</li>
</ul></li>
<li>Legal battles and talent acquisition were integral to Silicon Valley’s competitive landscape.</li>
</ul>
</section>
<section id="japans-protected-market-and-government-support" class="level3">
<h3 class="anchored" data-anchor-id="japans-protected-market-and-government-support">Japan’s Protected Market and Government Support</h3>
<ul>
<li><strong>Protected Domestic Market:</strong>
<ul>
<li>Japan imposed quotas on U.S. chip imports until <strong>1974</strong>.</li>
<li>Even after quotas were lifted, Japanese companies favored domestic suppliers.</li>
<li>NTT, Japan’s state-owned telecom giant, primarily purchased from Japanese companies.</li>
</ul></li>
<li><strong>Government Subsidies:</strong>
<ul>
<li>Japan’s <strong>VLSI program (1976)</strong> promoted collaboration among chipmakers and provided government funding for R&amp;D.</li>
<li>American companies viewed this as an unfair advantage, despite the U.S. government’s own support for the semiconductor industry through DARPA grants.</li>
</ul></li>
</ul>
</section>
<section id="the-cost-of-capital-disadvantage" class="level3">
<h3 class="anchored" data-anchor-id="the-cost-of-capital-disadvantage">The Cost of Capital Disadvantage</h3>
<ul>
<li><strong>High U.S. Interest Rates:</strong>
<ul>
<li><strong>Jerry Sanders</strong>: “The Japanese pay 6%, maybe 7% for capital. I pay 18% on a good day.”</li>
<li>Building chip fabrication facilities was capital-intensive, making interest rates a crucial factor.</li>
<li>U.S. interest rates soared to <strong>21.5%</strong> in the 1980s to combat inflation.</li>
</ul></li>
<li><strong>Japan’s Low Cost of Capital:</strong>
<ul>
<li>Japanese chipmakers, often part of large conglomerates, secured low-interest loans from affiliated banks.</li>
<li>Japanese banks provided long-term support, even during periods of unprofitability.</li>
</ul></li>
<li><strong>Factors Contributing to Japan’s Low Rates:</strong>
<ul>
<li>High savings rates due to demographic trends and a weak social safety net.</li>
<li>Limited investment options channeled savings into banks.</li>
</ul></li>
</ul>
</section>
<section id="japans-investment-and-market-dominance" class="level3">
<h3 class="anchored" data-anchor-id="japans-investment-and-market-dominance">Japan’s Investment and Market Dominance</h3>
<ul>
<li>Armed with cheap capital, Japanese firms aggressively pursued market share in the DRAM market.</li>
<li>Japanese companies invested heavily in production equipment, outspending U.S. rivals by <strong>60%</strong> in the early 1980s.</li>
<li><strong>Sustained Losses:</strong>
<ul>
<li>Japanese companies endured losses to gain market share, relying on bank loans to stay afloat.</li>
</ul></li>
<li><strong>Outcome:</strong>
<ul>
<li>Five years after the 64K DRAM introduction, Intel’s market share plummeted to <strong>1.7%</strong>, while Japanese competitors thrived.</li>
<li>Japan’s capital expenditure in semiconductor manufacturing grew exponentially:
<ul>
<li>Hitachi: From <strong>¥80 billion</strong> to <strong>¥1.5 billion</strong></li>
<li>Toshiba: From <strong>¥3 billion</strong> to <strong>¥75 billion</strong></li>
<li>NEC: From <strong>¥3.5 billion</strong> to <strong>¥110 billion</strong></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="conflicting-narratives-and-the-perception-of-unfairness" class="level3">
<h3 class="anchored" data-anchor-id="conflicting-narratives-and-the-perception-of-unfairness">Conflicting Narratives and the Perception of Unfairness</h3>
<ul>
<li>Japanese chipmakers argued that their success was a result of superior quality and efficiency, not unfair practices.</li>
<li>American consumers, like HP, favored Japanese chips due to their higher quality.</li>
<li>Despite conflicting narratives, Japan’s DRAM market share continued to grow at the expense of American companies.</li>
</ul>
</section>
</section>
<section id="chapter-17-shipping-junk" class="level2">
<h2 class="anchored" data-anchor-id="chapter-17-shipping-junk">Chapter 17: Shipping Junk</h2>
<section id="gca-corporation-from-dominance-to-decline" class="level3">
<h3 class="anchored" data-anchor-id="gca-corporation-from-dominance-to-decline">GCA Corporation: From Dominance to Decline</h3>
<ul>
<li>In the early 1980s, <strong>GCA Corporation</strong> was a leading American manufacturer of photolithography equipment, crucial for chip production.</li>
<li>The Evolution of Photolithography:
<ul>
<li>Advanced from rudimentary setups to sophisticated processes involving:
<ul>
<li>Specialized chemicals</li>
<li>Precision lenses</li>
<li>Laser alignment systems</li>
</ul></li>
</ul></li>
<li><strong>GCA’s Rise:</strong>
<ul>
<li>Initially, <strong>Perkin-Elmer’s</strong> scanner dominated the market.</li>
<li>GCA, led by <strong>Milt Greenberg</strong>, developed the <strong>wafer stepper</strong> based on input from Texas Instruments.</li>
<li>The stepper’s higher resolution enabled smaller transistors.</li>
</ul></li>
</ul>
</section>
<section id="gcas-monopoly-and-subsequent-missteps" class="level3">
<h3 class="anchored" data-anchor-id="gcas-monopoly-and-subsequent-missteps">GCA’s Monopoly and Subsequent Missteps</h3>
<ul>
<li>GCA’s stepper gave it a monopoly, leading to:
<ul>
<li>Revenue surge to <strong>$300 million</strong>.</li>
<li>Soaring stock prices.</li>
</ul></li>
<li><strong>Internal Issues and Mismanagement:</strong>
<ul>
<li>Greenberg, despite his technical brilliance, lacked focus on operational efficiency.</li>
<li>The company became bloated, with uncontrolled costs and inventory mismanagement.</li>
<li>Greenberg ignored warnings of an impending industry downturn.</li>
</ul></li>
</ul>
</section>
<section id="the-semiconductor-industry-downturn-and-loss-of-market-share" class="level3">
<h3 class="anchored" data-anchor-id="the-semiconductor-industry-downturn-and-loss-of-market-share">The Semiconductor Industry Downturn and Loss of Market Share</h3>
<ul>
<li><strong>Industry Downturn (Mid-1980s):</strong>
<ul>
<li>The semiconductor industry experienced a cyclical downturn.</li>
<li>Lithography equipment sales plummeted by <strong>40%</strong> between <strong>1984</strong> and <strong>1986</strong>.</li>
<li>GCA’s revenue dropped by over two-thirds.</li>
</ul></li>
<li><strong>Rise of Nikon:</strong>
<ul>
<li>GCA’s decision to stop using Nikon lenses backfired when Nikon developed its own stepper, eventually surpassing GCA in market share.</li>
</ul></li>
<li><strong>GCA’s Downfall:</strong>
<ul>
<li>Arrogance toward customers.</li>
<li>Unreliable equipment.</li>
<li>Poor customer service.</li>
</ul></li>
</ul>
</section>
<section id="explanations-for-gcas-decline" class="level3">
<h3 class="anchored" data-anchor-id="explanations-for-gcas-decline">Explanations for GCA’s Decline</h3>
<ul>
<li><strong>Impact of Japanese Industrial Subsidies:</strong>
<ul>
<li>Some argued Japan’s VLSI program, which benefited DRAM producers, also aided equipment suppliers like Nikon.</li>
</ul></li>
<li><strong>GCA’s Internal Issues:</strong>
<ul>
<li>GCA employees acknowledged difficulties with mass production and quality control.</li>
<li>Poor customer service and an arrogant attitude towards clients contributed to their decline.</li>
</ul></li>
</ul>
</section>
<section id="nikons-superiority-and-gcas-continued-struggles" class="level3">
<h3 class="anchored" data-anchor-id="nikons-superiority-and-gcas-continued-struggles">Nikon’s Superiority and GCA’s Continued Struggles</h3>
<ul>
<li><strong>Nikon’s Advantages:</strong>
<ul>
<li>Nikon’s systems became more reliable and efficient, outperforming GCA’s even in ideal conditions.</li>
<li>Nikon steppers offered significantly longer periods of continuous operation (10 times that of IBM’s expectations).</li>
</ul></li>
<li><strong>GCA’s Leadership Failure:</strong>
<ul>
<li>Greenberg failed to address the company’s internal issues, blaming employees instead.</li>
<li>The company resorted to accounting gimmicks to meet Wall Street expectations.</li>
</ul></li>
<li><strong>Decline in Market Share:</strong>
<ul>
<li>U.S. firms’ control over the global semiconductor lithography equipment market plummeted from <strong>85%</strong> in <strong>1978</strong> to <strong>50%</strong> a decade later.</li>
<li>GCA’s share dwindled significantly.</li>
</ul></li>
</ul>
</section>
<section id="the-end-of-gca-corporation" class="level3">
<h3 class="anchored" data-anchor-id="the-end-of-gca-corporation">The End of GCA Corporation</h3>
<ul>
<li><strong>Sale and Closure:</strong>
<ul>
<li>GCA’s parent company, General Signal, decided to sell or close GCA in <strong>1993</strong>.</li>
</ul></li>
<li><strong>Sematech’s Withdrawal of Support:</strong>
<ul>
<li>Despite providing millions in funding, Sematech withdrew support.</li>
</ul></li>
<li><strong>Government Inaction:</strong>
<ul>
<li>Despite appeals for help, the government ultimately decided against intervening to save GCA.</li>
</ul></li>
<li><strong>Final Outcome:</strong>
<ul>
<li>GCA closed its doors, sold off its assets, and became another casualty of Japanese competition in the semiconductor industry.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-18-the-crude-oil-of-the-1980s" class="level2">
<h2 class="anchored" data-anchor-id="chapter-18-the-crude-oil-of-the-1980s">Chapter 18: The Crude Oil of the 1980s</h2>
<section id="a-gathering-at-mings-silicon-valley-turns-to-washington" class="level3">
<h3 class="anchored" data-anchor-id="a-gathering-at-mings-silicon-valley-turns-to-washington">A Gathering at Ming’s: Silicon Valley Turns to Washington</h3>
<ul>
<li><strong>Setting:</strong>
<ul>
<li>A private dining room at Ming’s Chinese restaurant in Palo Alto.</li>
</ul></li>
<li><strong>Key Players:</strong>
<ul>
<li><strong>Bob Noyce</strong> (Intel)</li>
<li><strong>Jerry Sanders</strong> (AMD)</li>
<li><strong>Charlie Sporck</strong> (Industry Veteran)</li>
</ul></li>
<li><strong>Purpose:</strong>
<ul>
<li>To address the crisis facing America’s semiconductor industry due to Japanese competition.</li>
</ul></li>
<li><strong>Decision:</strong>
<ul>
<li>To seek government assistance, a departure from Silicon Valley’s previous hands-off approach.</li>
</ul></li>
</ul>
</section>
<section id="semiconductors-the-crude-oil-of-the-1980s" class="level3">
<h3 class="anchored" data-anchor-id="semiconductors-the-crude-oil-of-the-1980s">Semiconductors: “The Crude Oil of the 1980s”</h3>
<ul>
<li><strong>Jerry Sanders’s Argument:</strong>
<ul>
<li>“Semiconductors are the crude oil of the 1980s, and the people who control the crude oil will control the electronics industry.”</li>
</ul></li>
<li><strong>Rationale:</strong>
<ul>
<li>Semiconductors were essential components in a vast array of products, from computers and consumer electronics to military equipment.</li>
<li>Their importance was analogous to oil’s role as a critical resource.</li>
</ul></li>
</ul>
</section>
<section id="strategic-importance-of-semiconductors" class="level3">
<h3 class="anchored" data-anchor-id="strategic-importance-of-semiconductors">Strategic Importance of Semiconductors</h3>
<ul>
<li><strong>The Computer Revolution:</strong>
<ul>
<li>The rapid expansion of the computer industry in the 1980s increased the demand for semiconductors.</li>
</ul></li>
<li><strong>Ubiquity of Chips:</strong>
<ul>
<li>Semiconductors became essential in a wide range of everyday products, making them indispensable.</li>
</ul></li>
<li><strong>National Security Implications:</strong>
<ul>
<li>The reliance on foreign-made semiconductors raised concerns about national security, especially given America’s dependence on technology for military superiority.</li>
</ul></li>
</ul>
</section>
<section id="lessons-from-the-oil-embargoes" class="level3">
<h3 class="anchored" data-anchor-id="lessons-from-the-oil-embargoes">Lessons from the Oil Embargoes</h3>
<ul>
<li><strong>The 1973 and 1979 Oil Embargoes:</strong>
<ul>
<li>Highlighted the vulnerability of relying on foreign suppliers for critical resources.</li>
<li>Led to economic recession and political instability in the U.S.</li>
</ul></li>
<li><strong>Military Intervention:</strong>
<ul>
<li>The U.S. responded to the oil crisis with military actions, demonstrating its commitment to securing oil supplies.</li>
</ul></li>
</ul>
</section>
<section id="silicon-valleys-change-of-heart" class="level3">
<h3 class="anchored" data-anchor-id="silicon-valleys-change-of-heart">Silicon Valley’s Change of Heart</h3>
<ul>
<li><strong>Shift from Defense to Commercial Markets:</strong>
<ul>
<li>In the 1970s, Silicon Valley had shifted its focus from defense contracts to civilian markets.</li>
</ul></li>
<li><strong>Return to Washington:</strong>
<ul>
<li>The semiconductor crisis forced companies to seek help from the government they had previously ignored.</li>
</ul></li>
<li><strong>Formation of the Semiconductor Industry Association (SIA):</strong>
<ul>
<li>CEOs, including Sanders, Noyce, and Spork, formed the SIA to lobby for government support.</li>
</ul></li>
</ul>
</section>
<section id="the-pentagons-perspective" class="level3">
<h3 class="anchored" data-anchor-id="the-pentagons-perspective">The Pentagon’s Perspective</h3>
<ul>
<li><strong>Semiconductors and Military Superiority:</strong>
<ul>
<li>Pentagon officials recognized the crucial role of semiconductors in maintaining America’s military edge, particularly in offsetting the Soviet Union’s conventional forces.</li>
</ul></li>
<li><strong>Defense Strategy Reliance on Semiconductors:</strong>
<ul>
<li>Since the mid-1970s, the U.S. had incorporated semiconductors into advanced weapons systems to enhance guidance, communication, and command and control.</li>
</ul></li>
</ul>
</section>
<section id="concerns-about-japans-semiconductor-dominance" class="level3">
<h3 class="anchored" data-anchor-id="concerns-about-japans-semiconductor-dominance">Concerns About Japan’s Semiconductor Dominance</h3>
<ul>
<li><strong>Growing Japanese Market Share:</strong>
<ul>
<li>By <strong>1986</strong>, Japan surpassed the U.S. in chip production.</li>
<li>Japan’s share of the global lithography equipment market reached <strong>70%</strong> by the end of the 1980s.</li>
</ul></li>
<li><strong>Dependence on Foreign Suppliers:</strong>
<ul>
<li>The trend towards Japanese dominance raised concerns about U.S. dependence on foreign suppliers for critical military technology.</li>
</ul></li>
</ul>
</section>
<section id="the-dilemma-of-japan-as-an-ally-and-competitor" class="level3">
<h3 class="anchored" data-anchor-id="the-dilemma-of-japan-as-an-ally-and-competitor">The Dilemma of Japan as an Ally and Competitor</h3>
<ul>
<li><strong>Cold War Alliance:</strong>
<ul>
<li>Japan was a key U.S. ally during the Cold War.</li>
<li>The U.S. encouraged limited Japanese rearmament for support against the Soviet Union.</li>
</ul></li>
<li><strong>Economic Rivalry:</strong>
<ul>
<li>Japan’s economic success and technological advancements in areas crucial for U.S. military power created a strategic dilemma.</li>
</ul></li>
</ul>
</section>
<section id="the-strategic-importance-of-semiconductors" class="level3">
<h3 class="anchored" data-anchor-id="the-strategic-importance-of-semiconductors">The Strategic Importance of Semiconductors</h3>
<ul>
<li><strong>Charlie Sporck’s Warning:</strong>
<ul>
<li>“You don’t want the same thing to happen to semiconductors as happened to the TV industry, to the camera industry…Without semiconductors, you’re in nowheresville.”</li>
</ul></li>
<li><strong>Semiconductors as a Foundation of Technology:</strong>
<ul>
<li>Spork emphasized that semiconductors were fundamental to a wide range of industries, and losing dominance would have severe consequences for the U.S. economy and national security.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-19-death-spiral" class="level2">
<h2 class="anchored" data-anchor-id="chapter-19-death-spiral">Chapter 19: Death Spiral</h2>
<section id="bob-noyces-concerns-about-u.s.-competitiveness" class="level3">
<h3 class="anchored" data-anchor-id="bob-noyces-concerns-about-u.s.-competitiveness">Bob Noyce’s Concerns about U.S. Competitiveness</h3>
<ul>
<li><strong>“We’re in a death spiral,”</strong> Noyce stated in <strong>1986</strong>, expressing deep concern about the decline of U.S. industries across multiple sectors.</li>
<li><strong>Comparison to Detroit:</strong>
<ul>
<li>Noyce drew a parallel between Silicon Valley and Detroit, fearing that the semiconductor industry might suffer a similar fate due to foreign competition.</li>
</ul></li>
</ul>
</section>
<section id="silicon-valleys-ambivalent-relationship-with-the-government" class="level3">
<h3 class="anchored" data-anchor-id="silicon-valleys-ambivalent-relationship-with-the-government">Silicon Valley’s Ambivalent Relationship with the Government</h3>
<ul>
<li><strong>Desire for Autonomy vs.&nbsp;Need for Support:</strong>
<ul>
<li>Silicon Valley maintained a complex relationship with the government, seeking both independence and assistance.</li>
</ul></li>
<li><strong>Noyce’s Perspective:</strong>
<ul>
<li>As a leading figure, Noyce recognized the need for government help while remaining wary of potential bureaucratic hurdles.</li>
</ul></li>
<li><strong>Shift in Market Dynamics:</strong>
<ul>
<li>By the 1980s, the government was no longer the primary consumer of semiconductors, limiting its influence over the industry.</li>
</ul></li>
</ul>
</section>
<section id="debate-over-government-intervention" class="level3">
<h3 class="anchored" data-anchor-id="debate-over-government-intervention">Debate over Government Intervention</h3>
<ul>
<li><strong>Strategic Importance vs.&nbsp;Free Market Principles:</strong>
<ul>
<li>The debate centered on whether the government should support a specific industry or allow market forces to determine winners and losers.</li>
</ul></li>
<li><strong>Defining “Strategic”:</strong>
<ul>
<li>There was no consensus on what constituted a “strategic” industry deserving of government intervention.</li>
</ul></li>
<li><strong>The Potato Chip Analogy:</strong>
<ul>
<li>A Reagan administration economist famously (though disputedly) argued, “They’re all chips. A hundred dollars of one or a hundred dollars of the other is still a hundred.”</li>
<li>This highlighted the challenge of justifying government support for one industry over another.</li>
</ul></li>
</ul>
</section>
<section id="silicon-valleys-lobbying-efforts" class="level3">
<h3 class="anchored" data-anchor-id="silicon-valleys-lobbying-efforts">Silicon Valley’s Lobbying Efforts</h3>
<ul>
<li><strong>Tax Cuts and Intellectual Property Protection:</strong>
<ul>
<li>Noyce advocated for:
<ul>
<li>Reducing the capital gains tax.</li>
<li>Loosening regulations on venture capital investments.</li>
<li>Strengthening intellectual property protections through the Semiconductor Chip Protection Act.</li>
</ul></li>
</ul></li>
<li><strong>Increased Venture Capital Funding:</strong>
<ul>
<li>These policy changes led to a surge in venture capital flowing into Silicon Valley.</li>
</ul></li>
</ul>
</section>
<section id="trade-tensions-and-market-access" class="level3">
<h3 class="anchored" data-anchor-id="trade-tensions-and-market-access">Trade Tensions and Market Access</h3>
<ul>
<li><strong>Japanese Trade Barriers:</strong>
<ul>
<li>Despite agreements to eliminate tariffs, Silicon Valley companies faced challenges selling chips in Japan.</li>
<li>Japanese companies and government entities often favored domestic suppliers.</li>
</ul></li>
<li><strong>Dumping Allegations:</strong>
<ul>
<li>U.S. companies accused Japanese firms of dumping cheap chips in the American market.</li>
</ul></li>
</ul>
</section>
<section id="the-u.s.-japan-semiconductor-trade-agreement-1986" class="level3">
<h3 class="anchored" data-anchor-id="the-u.s.-japan-semiconductor-trade-agreement-1986">The U.S.-Japan Semiconductor Trade Agreement (1986)</h3>
<ul>
<li><strong>Export Quotas:</strong>
<ul>
<li>Under pressure from the U.S., Japan agreed to limit DRAM chip exports.</li>
</ul></li>
<li><strong>Unintended Consequences:</strong>
<ul>
<li>The agreement reduced supply and raised DRAM prices globally, benefiting Japanese producers and hurting American computer manufacturers.</li>
</ul></li>
<li><strong>Limited Impact on U.S. Companies:</strong>
<ul>
<li>Most American DRAM manufacturers were already exiting the market, so the agreement provided minimal relief.</li>
</ul></li>
</ul>
</section>
<section id="sematech-a-collaborative-effort" class="level3">
<h3 class="anchored" data-anchor-id="sematech-a-collaborative-effort">Sematech: A Collaborative Effort</h3>
<ul>
<li><strong>Formation (1987):</strong>
<ul>
<li>Leading chipmakers, with Defense Department support, formed <strong>Sematech</strong> to revitalize the U.S. semiconductor industry.</li>
</ul></li>
<li><strong>Structure and Funding:</strong>
<ul>
<li>A consortium funded equally by the industry and the Pentagon.</li>
</ul></li>
<li><strong>Goal:</strong>
<ul>
<li>To foster collaboration and innovation in semiconductor manufacturing.</li>
</ul></li>
<li><strong>Bob Noyce’s Leadership:</strong>
<ul>
<li>Noyce came out of semi-retirement to lead Sematech.</li>
</ul></li>
</ul>
</section>
<section id="sematechs-initiatives" class="level3">
<h3 class="anchored" data-anchor-id="sematechs-initiatives">Sematech’s Initiatives</h3>
<ul>
<li><strong>Focus on Manufacturing Equipment:</strong>
<ul>
<li>Assisted equipment manufacturers like GCA in improving reliability and management practices.</li>
</ul></li>
<li><strong>Production Coordination:</strong>
<ul>
<li>Aligned production schedules between chipmakers and equipment manufacturers.</li>
</ul></li>
</ul>
</section>
<section id="saving-the-u.s.-lithography-industry" class="level3">
<h3 class="anchored" data-anchor-id="saving-the-u.s.-lithography-industry">Saving the U.S. Lithography Industry</h3>
<ul>
<li><strong>Lithography as a Priority:</strong>
<ul>
<li>Noyce allocated <strong>51%</strong> of Sematech’s funding to American lithography companies.</li>
</ul></li>
<li><strong>Rationale:</strong>
<ul>
<li>Lithography was essential for chipmaking, and the U.S. industry was struggling to compete with Japanese rivals.</li>
</ul></li>
</ul>
</section>
<section id="gcas-last-chance" class="level3">
<h3 class="anchored" data-anchor-id="gcas-last-chance">GCA’s Last Chance</h3>
<ul>
<li><strong>Noyce’s Initial Skepticism:</strong>
<ul>
<li>Noyce initially believed GCA was beyond saving.</li>
</ul></li>
<li><strong>Change of Heart:</strong>
<ul>
<li>After visiting GCA, Noyce agreed to purchase <strong>$13 million</strong> worth of their equipment to support the company.</li>
</ul></li>
</ul>
</section>
<section id="sematechs-support-for-gca" class="level3">
<h3 class="anchored" data-anchor-id="sematechs-support-for-gca">Sematech’s Support for GCA</h3>
<ul>
<li><strong>Funding for Advanced Equipment:</strong>
<ul>
<li>Sematech provided contracts for GCA to develop cutting-edge <strong>deep ultraviolet lithography</strong> equipment.</li>
</ul></li>
<li><strong>GCA’s Technological Success:</strong>
<ul>
<li>GCA exceeded expectations, producing world-class steppers.</li>
</ul></li>
<li><strong>Business Model Challenges:</strong>
<ul>
<li>Despite technological achievements, GCA still struggled to secure major customers due to its past reputation and financial instability.</li>
</ul></li>
</ul>
</section>
<section id="gcas-demise" class="level3">
<h3 class="anchored" data-anchor-id="gcas-demise">GCA’s Demise</h3>
<ul>
<li><strong>Financial Losses:</strong>
<ul>
<li>GCA continued to incur losses (<strong>$30 million</strong> between <strong>1988</strong> and <strong>1992</strong>) despite Sematech’s support.</li>
</ul></li>
<li><strong>Loss of Key Supporter:</strong>
<ul>
<li>Noyce’s death in <strong>1990</strong> was a significant blow to GCA.</li>
</ul></li>
<li><strong>Sale and Closure:</strong>
<ul>
<li>GCA was put up for sale but failed to find a buyer.</li>
<li>Sematech withdrew funding.</li>
<li>The U.S. government decided against intervention.</li>
</ul></li>
<li><strong>GCA ceased operations in 1993.</strong></li>
</ul>
</section>
</section>
<section id="chapter-20-the-japan-that-can-say-no" class="level2">
<h2 class="anchored" data-anchor-id="chapter-20-the-japan-that-can-say-no">Chapter 20: The Japan That Can Say No</h2>
<section id="akio-moritas-changing-perspective-on-america" class="level3">
<h3 class="anchored" data-anchor-id="akio-moritas-changing-perspective-on-america">Akio Morita’s Changing Perspective on America</h3>
<ul>
<li><strong>Early Admiration:</strong>
<ul>
<li>Morita initially viewed the U.S. with admiration for its technological prowess and economic prosperity.</li>
</ul></li>
<li><strong>Growing Disillusionment:</strong>
<ul>
<li>America’s struggles in the 1970s and 1980s, including economic crises and social unrest, diminished Morita’s perception of U.S. dominance.</li>
</ul></li>
<li><strong>Shift in Balance of Power:</strong>
<ul>
<li>As Sony thrived and Japan’s technological capabilities grew, Morita sensed a shift in the balance of power.</li>
</ul></li>
</ul>
</section>
<section id="moritas-critique-of-american-business-practices" class="level3">
<h3 class="anchored" data-anchor-id="moritas-critique-of-american-business-practices">Morita’s Critique of American Business Practices</h3>
<ul>
<li><strong>Short-Term Focus vs.&nbsp;Long-Term Vision:</strong>
<ul>
<li>Morita criticized American companies for prioritizing short-term profits over long-term investments and strategic planning.</li>
</ul></li>
<li><strong>Emphasis on Lawyers Over Engineers:</strong>
<ul>
<li>He believed the U.S. overemphasized legal professions while neglecting engineering and manufacturing expertise.</li>
</ul></li>
<li><strong>Inadequate Labor Relations:</strong>
<ul>
<li>Morita criticized American management for failing to adequately train and motivate its workforce.</li>
</ul></li>
</ul>
</section>
<section id="the-japan-that-can-say-no" class="level3">
<h3 class="anchored" data-anchor-id="the-japan-that-can-say-no">“The Japan That Can Say No”</h3>
<ul>
<li><strong>Publication (1989):</strong>
<ul>
<li>Morita co-authored “The Japan That Can Say No” with Shintaro Ishihara, a controversial Japanese politician.</li>
</ul></li>
<li><strong>Central Argument:</strong>
<ul>
<li>The book asserted Japan’s growing economic and technological power and urged the country to adopt a more assertive stance in its relationship with the U.S.</li>
</ul></li>
<li><strong>Ishihara’s Nationalist Rhetoric:</strong>
<ul>
<li>Ishihara, known for his nationalist views, called for Japan to shed its subservient role to the U.S.</li>
</ul></li>
<li><strong>Semiconductors as a Strategic Lever:</strong>
<ul>
<li>Ishihara argued that Japan’s dominance in semiconductors, particularly <strong>1-megabit DRAM chips</strong>, gave it leverage over the U.S., including in military affairs.</li>
</ul></li>
</ul>
</section>
<section id="reactions-to-the-book" class="level3">
<h3 class="anchored" data-anchor-id="reactions-to-the-book">Reactions to the Book</h3>
<ul>
<li><strong>Controversy in the U.S.:</strong>
<ul>
<li>The book sparked outrage and fueled anxieties about Japan’s economic and technological rise.</li>
</ul></li>
<li><strong>Morita’s Attempts to Distance Himself:</strong>
<ul>
<li>Morita later downplayed his association with Ishihara, claiming their views differed.</li>
</ul></li>
</ul>
</section>
<section id="the-reality-of-japans-semiconductor-dominance" class="level3">
<h3 class="anchored" data-anchor-id="the-reality-of-japans-semiconductor-dominance">The Reality of Japan’s Semiconductor Dominance</h3>
<ul>
<li><strong>Facts Supported Ishihara’s Assertions:</strong>
<ul>
<li>Japan had undeniably become the leading producer of DRAM chips, essential for computers and military technology.</li>
</ul></li>
<li><strong>Geopolitical Implications:</strong>
<ul>
<li>This shift in technological power had significant potential to reshape the geopolitical landscape.</li>
</ul></li>
</ul>
</section>
<section id="high-tech-as-foreign-policy" class="level3">
<h3 class="anchored" data-anchor-id="high-tech-as-foreign-policy">High-Tech as Foreign Policy</h3>
<ul>
<li><strong>Harold Brown’s Analysis:</strong>
<ul>
<li>Former U.S. Defense Secretary Harold Brown, in a <strong>1989</strong> article titled <strong>“High-Tech is Foreign Policy,”</strong> acknowledged the link between technological leadership and geopolitical power.</li>
</ul></li>
<li><strong>Concerns about U.S. Dependence:</strong>
<ul>
<li>Brown admitted that Japan’s dominance in memory chips and advancements in other semiconductor technologies posed a risk to U.S. military superiority.</li>
</ul></li>
</ul>
</section>
<section id="the-specter-of-a-pax-nipponica" class="level3">
<h3 class="anchored" data-anchor-id="the-specter-of-a-pax-nipponica">The Specter of a “Pax Nipponica”</h3>
<ul>
<li><strong>CIA’s Assessment (1989):</strong>
<ul>
<li>A CIA report predicted the emergence of a <strong>“Pax Nipponica,”</strong> an East Asian economic and political bloc dominated by Japan.</li>
</ul></li>
<li><strong>Shift in Regional Dynamics:</strong>
<ul>
<li>Japan’s growing economic and technological influence threatened to undermine America’s longstanding dominance in Asia.</li>
</ul></li>
<li><strong>Unintended Consequences of U.S. Policy:</strong>
<ul>
<li>The U.S. strategy of fostering Japan’s post-war economic growth had inadvertently created a formidable competitor.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="chapter-21-the-potato-chip-king" class="level2">
<h2 class="anchored" data-anchor-id="chapter-21-the-potato-chip-king">Chapter 21: The Potato Chip King</h2>
<ul>
<li><strong>Jack Simplot</strong>, an Idaho billionaire known for his potato empire, invested in <strong>Micron Technology</strong>, a struggling DRAM chip manufacturer.
<ul>
<li>Simplot’s expertise was in potatoes, evident from his “Mr.&nbsp;Spud” license plate, but he understood business in a way that Silicon Valley often didn’t.</li>
<li>Simplot made his fortune by pioneering potato processing techniques that led to a massive contract with McDonald’s.</li>
</ul></li>
<li><strong>Micron</strong>, founded in 1978 by brothers <strong>Joe and Ward Parkinson</strong>, entered the DRAM market during a time of intense Japanese dominance.
<ul>
<li>Existing American DRAM producers, including <strong>AMD, National Semiconductor</strong>, and <strong>Intel</strong>, were abandoning the market due to billion-dollar losses from Japanese competition.</li>
<li>Micron, initially focused on chip design, was forced to pivot to manufacturing their own chips after losing their only client, <strong>Mostek</strong>, to Japanese competitor <strong>Fujitsu</strong>.</li>
</ul></li>
<li>Silicon Valley lobbied the government for protection against Japanese competition, claiming that computer chips were strategic assets unlike commodities like potatoes.</li>
<li>Micron, however, initially opposed government intervention, believing they could compete with the Japanese through aggressive cost-cutting.</li>
<li>Micron secured funding from <strong>Alan Noble</strong> and other Boise investors. Facing continued struggles, they approached <strong>Simplot</strong>, who saw an opportunity in the depressed DRAM market and invested $1 million, later increasing his stake to over a billion dollars.
<ul>
<li>Simplot believed that Japanese competition had turned DRAM into a commodity, and the best time to buy a commodity business was during a downturn.</li>
</ul></li>
<li>Micron’s competitive edge stemmed from their relentless focus on cost reduction and innovative manufacturing processes.
<ul>
<li><strong>Ward Parkinson</strong>, Micron’s engineering lead, focused on shrinking the chip size to fit more chips onto each silicon wafer, increasing manufacturing efficiency.</li>
<li>Micron simplified manufacturing processes, using fewer steps and less equipment than competitors.</li>
<li>They modified existing lithography machines to exceed manufacturer specifications and adapted furnaces to process more wafers simultaneously.</li>
<li>Micron’s location in Boise offered lower land and electricity costs compared to California or Japan.</li>
</ul></li>
<li>Joe Parkinson instilled a culture of cost-consciousness, dimming lights and emphasizing efficiency to employees. This “sweatshop mentality” was driven by the understanding that Micron’s survival was paramount in a place with limited alternative job opportunities.</li>
<li>Micron’s strategy ultimately succeeded.
<ul>
<li>They survived the Japanese onslaught, while most American DRAM producers were driven out of the market.</li>
<li>Micron acquired <strong>Texas Instruments’</strong> DRAM business and became a major player in the memory chip market.</li>
<li>Their success was attributed to their engineering ingenuity, relentless cost-cutting, and Simplot’s unwavering support.</li>
</ul></li>
</ul>
</section>
<section id="chapter-22-disrupting-intel" class="level2">
<h2 class="anchored" data-anchor-id="chapter-22-disrupting-intel">Chapter 22: Disrupting Intel</h2>
<ul>
<li><strong>Andy Grove</strong>, Intel’s President, recognized that the company’s DRAM business was being disrupted by Japanese competition and needed a drastic change.
<ul>
<li>Grove was known for his “paranoid” management style, driven by a fear of competition and failure, which he outlined in his book, <strong>Only the Paranoid Survive</strong>.</li>
<li>Grove’s experiences as a Hungarian refugee escaping Soviet oppression shaped his leadership, emphasizing constant vigilance and a drive to overcome challenges.</li>
</ul></li>
<li>Despite Intel’s history and identity being rooted in memory chips, Grove acknowledged that the DRAM market was no longer viable and a shift was necessary for survival.
<ul>
<li>The decision to abandon DRAM was difficult and emotionally charged for Intel, but Grove recognized the need to disrupt themselves before being overtaken by competitors.</li>
</ul></li>
<li>Grove initiated a painful restructuring process.
<ul>
<li><strong>Step One</strong>: Laying off over 25% of Intel’s workforce and closing facilities in Silicon Valley, Oregon, Puerto Rico, and Barbados.</li>
<li><strong>Step Two</strong>: Implementing a ruthless approach to improve manufacturing, inspired by Japanese methods.
<ul>
<li><strong>Craig Barrett</strong>, Grove’s deputy, led this effort, pushing for the adoption of rigorous processes.</li>
<li>Intel adopted a “<strong>copy exactly</strong>” manufacturing methodology, replicating the most efficient processes across all facilities to ensure consistency and high yields.</li>
<li>This shift from Silicon Valley’s freewheeling engineering culture to a more disciplined and standardized approach was met with internal resistance but ultimately proved successful in increasing efficiency and reducing costs.</li>
</ul></li>
</ul></li>
<li>Several external factors contributed to Intel’s resurgence:
<ul>
<li>The rising value of the Japanese yen against the dollar made American exports cheaper.</li>
<li>Falling interest rates in the US lowered Intel’s capital costs.</li>
<li>The emergence of <strong>Compaq</strong> and other <strong>IBM PC clones</strong> created a new market for Intel’s microprocessors.</li>
<li>These “clone” manufacturers utilized Intel’s chips and Microsoft’s software, driving down PC prices and fueling mass adoption.</li>
</ul></li>
<li>By transitioning from DRAM to microprocessors, Intel secured a near-monopoly in the burgeoning PC market, solidifying their position as a leading chip manufacturer.</li>
</ul>
</section>
<section id="chapter-23-my-enemys-enemy-the-rise-of-korea" class="level2">
<h2 class="anchored" data-anchor-id="chapter-23-my-enemys-enemy-the-rise-of-korea">Chapter 23: My Enemy’s Enemy, The Rise of Korea</h2>
<ul>
<li><strong>Lee Byung-chul</strong>, founder of <strong>Samsung</strong>, saw an opportunity in the semiconductor industry amidst the US-Japan DRAM wars.
<ul>
<li>Lee, a shrewd businessman who started by trading dried fish and vegetables, believed in building businesses that were “big, strong, and eternal”.</li>
<li>He recognized the potential of semiconductors after witnessing the success of Japanese companies like <strong>Toshiba</strong> and <strong>Fujitsu</strong>.</li>
</ul></li>
<li>Lee was inspired by <strong>Hewlett-Packard’s</strong> journey from a garage startup to a tech giant during a visit to California in 1982.
<ul>
<li>He was determined to replicate their success with Samsung.</li>
</ul></li>
<li>Despite the high capital expenditure and risk involved, Lee decided to invest at least $100 million in semiconductor manufacturing, a move that could have jeopardized his entire business empire.</li>
<li><strong>Support from the South Korean government was crucial</strong>:
<ul>
<li>The government pledged $400 million to develop the country’s semiconductor industry and pressured banks to provide additional loans to companies like Samsung.</li>
<li>This mirrored the Japanese model of government-backed industrial policy.</li>
</ul></li>
<li>Silicon Valley, eager to undercut Japanese dominance, saw Korean companies as potential allies.
<ul>
<li><strong>Bob Noyce</strong> believed that Korean competition would prevent Japan from monopolizing DRAM production.</li>
<li>Intel and other Silicon Valley companies formed joint ventures with Samsung, providing them with manufacturing contracts and technology.</li>
<li>The logic was “my enemy’s enemy is my friend,” as <strong>Jerry Sanders</strong> stated.</li>
</ul></li>
<li>Factors that aided Samsung’s rise:
<ul>
<li>US-imposed tariffs on Japanese DRAM chips created an opening for Korean companies.</li>
<li>Lower wages and production costs in South Korea compared to Japan.</li>
<li>Access to US technology through licensing agreements, such as the deal for a 64K DRAM design from <strong>Micron</strong>.</li>
</ul></li>
<li>The collaboration between Silicon Valley and South Korea, driven by a shared goal of challenging Japan, inadvertently helped establish Korea as a major player in the global memory chip market.</li>
</ul>
</section>
<section id="chapter-24-this-is-the-future" class="level2">
<h2 class="anchored" data-anchor-id="chapter-24-this-is-the-future">Chapter 24: This is the Future</h2>
<ul>
<li>By the 1980s, the limitations of manual chip design were becoming apparent as transistor counts increased.
<ul>
<li>Early microprocessors, like Intel’s 4004, were designed by hand, a time-consuming and error-prone process.</li>
<li><strong>Federico Fagan’s</strong> experience designing Intel’s first microprocessor in 1971 highlighted the challenges: he spent six months meticulously drawing the design, which was then transferred to rubylith film and used to create masks for photolithography.</li>
</ul></li>
<li><strong>Carver Mead</strong> and <strong>Lynn Conway</strong> revolutionized chip design by introducing a standardized, algorithmic approach.
<ul>
<li><strong>Carver Mead</strong>, a physicist, and <strong>Lynn Conway</strong>, a computer architect at <strong>Xerox PARC</strong>, collaborated to create a set of mathematical design rules that enabled software to automate the chip design process.</li>
<li>Their methodology allowed designers to use a library of pre-designed components instead of drawing every transistor individually. This “<strong>Mead-Conway revolution</strong>” mirrored <strong>Gutenberg’s</strong> invention of the printing press, simplifying chip design and making it more accessible.</li>
</ul></li>
<li><strong>DARPA (Defense Advanced Research Projects Agency)</strong> recognized the strategic importance of the Mead-Conway approach and funded initiatives to promote its adoption.
<ul>
<li>They financed programs for university researchers to design and fabricate chips at advanced facilities, fostering a new generation of chip designers.</li>
<li>DARPA’s focus was on building educational infrastructure and supporting research that would maintain America’s lead in microelectronics, recognizing the crucial role of innovation in national security.</li>
</ul></li>
<li>The <strong>Semiconductor Research Corporation (SRC)</strong>, funded by the chip industry, also played a critical role by distributing research grants to universities.
<ul>
<li>Universities like <strong>Carnegie Mellon</strong> and the <strong>University of California, Berkeley</strong> became hubs for semiconductor research, producing graduates who went on to found companies that developed essential software tools for chip design.</li>
<li>These DARPA and SRC-funded programs nurtured an ecosystem of innovation that led to the creation of companies like <strong>Synopsys, Cadence</strong>, and <strong>Mentor Graphics</strong>, which continue to dominate the chip design software industry today.</li>
</ul></li>
<li><strong>Erwin Jacobs</strong>, a pioneer in wireless communication, envisioned using increasingly powerful chips to revolutionize data transmission.
<ul>
<li>Jacobs, who co-founded <strong>Qualcomm</strong>, realized that as transistor density increased, chips would be able to encode and decode significantly more data within the limited bandwidth of radio waves.</li>
<li>He predicted that this would lead to a future where large amounts of data could be transmitted wirelessly.</li>
</ul></li>
<li>DARPA funding was instrumental in Qualcomm’s early success, supporting the development of space communication systems before the company shifted focus to the civilian market.</li>
<li>Jacobs’ story highlights the importance of government funding in supporting early-stage research and development, particularly in capital-intensive fields like semiconductors.</li>
<li>By the end of the 1980s, thanks to these advancements in chip design, manufacturing, and applications, the unthinkable had become reality: Intel released its 486 microprocessor, containing 1.2 million transistors, a testament to the relentless pace of innovation driven by Silicon Valley and its government and academic partners.</li>
</ul>
</section>
<section id="chapter-25-the-kgbs-directorate-t" class="level2">
<h2 class="anchored" data-anchor-id="chapter-25-the-kgbs-directorate-t">Chapter 25: The KGB’s Directorate T</h2>
<ul>
<li>The Soviet Union, lagging behind the West in semiconductor technology, relied heavily on espionage to acquire Western chips and manufacturing equipment.
<ul>
<li><strong>Directorate T</strong>, a specialized KGB division established in 1963, was tasked with stealing foreign technology to bolster the Soviet semiconductor industry.</li>
<li>The KGB employed various tactics, including:
<ul>
<li><strong>Direct theft:</strong> Stealing physical chips from companies.</li>
<li><strong>Black market purchases:</strong> Acquiring chips through intermediaries and smugglers.</li>
<li><strong>Blackmail:</strong> Targeting Westerners with access to sensitive technology.</li>
</ul></li>
</ul></li>
<li>Soviet espionage efforts were extensive:
<ul>
<li>The KGB reportedly had a team of 60 agents in San Francisco focused on infiltrating Silicon Valley companies.</li>
<li>The discovery of a sophisticated Soviet listening device using <strong>Texas Instruments</strong> chips disguised as a buoy in 1982 highlighted the reach and sophistication of their operations.</li>
</ul></li>
<li>The limitations of the “<strong>copy-it</strong>” strategy:
<ul>
<li>While stealing samples or even shipments of chips was relatively straightforward, replicating the complex manufacturing processes was a significant challenge.</li>
<li>As chip complexity increased, the Soviets struggled to produce high-quality copies, rendering their stolen technology less valuable.</li>
<li>This over-reliance on theft hindered the development of indigenous Soviet semiconductor expertise.</li>
</ul></li>
<li><strong>Vladimir Vetrov (codename: Farewell):</strong> A disillusioned KGB agent who became a double agent for France.
<ul>
<li>Vetrov, dissatisfied with his career and personal life, leaked thousands of pages of classified documents about Directorate T’s operations to French intelligence, revealing the vast scale of Soviet technology theft.</li>
<li>He was motivated by a desire for a more exciting life and hoped to rekindle a romantic relationship.</li>
</ul></li>
<li><strong>Operation Exodus</strong>: A US-led initiative to counter Soviet technology theft, launched in response to Vetrov’s revelations.
<ul>
<li>The program implemented stricter export controls, increased customs inspections, and targeted Soviet acquisition networks.</li>
<li>By 1985, Operation Exodus had seized $600 million worth of goods and led to numerous arrests.</li>
</ul></li>
<li>Despite the KGB’s efforts, the Soviet Union remained technologically inferior to the West in microelectronics.
<ul>
<li>By the mid-1980s, Soviet microprocessors were estimated to be half a decade behind their American counterparts.</li>
<li>The reliance on the copy-it strategy ultimately proved detrimental, hindering innovation and perpetuating dependence on foreign technology.</li>
</ul></li>
</ul>
</section>
<section id="chapter-26-weapons-of-mass-destruction-the-impact-of-the-offset" class="level2">
<h2 class="anchored" data-anchor-id="chapter-26-weapons-of-mass-destruction-the-impact-of-the-offset">Chapter 26: Weapons of Mass Destruction, the Impact of the Offset</h2>
<ul>
<li><strong>Marshal Nikolai Ogarkov</strong>, chief of the Soviet military, recognized the transformative impact of microelectronics on warfare, predicting that precision-guided weapons would turn conventional explosives into “<strong>weapons of mass destruction</strong>.”</li>
<li>Ogarkov argued that the Soviet Union’s numerical superiority in tanks and troops was becoming increasingly irrelevant in the face of America’s superior precision-guided weapons and surveillance technology.
<ul>
<li>He recognized that <strong>Bill Perry’s offset strategy</strong> of leveraging technology to counter Soviet numerical superiority was succeeding.</li>
</ul></li>
<li><strong>Impact of the semiconductor gap on Soviet military capabilities</strong>:
<ul>
<li><strong>Missile technology</strong>:
<ul>
<li>Soviet ballistic missiles were less accurate than their American counterparts due to the limitations of their onboard computers and guidance systems.</li>
<li>The US <strong>MX missile</strong> was estimated to be significantly more accurate than the Soviet <strong>SS-25</strong>, giving the US a strategic advantage in a potential nuclear conflict.</li>
</ul></li>
<li><strong>Anti-submarine warfare</strong>:
<ul>
<li>The US Navy’s use of advanced computers, like the <strong>ILLIAC-4</strong>, for analyzing sonar data significantly enhanced their ability to detect and track Soviet submarines.</li>
</ul></li>
<li><strong>Conventional warfare</strong>:
<ul>
<li>The effectiveness of US precision-guided munitions, such as the <strong>Paveway</strong> laser-guided bombs and <strong>Tomahawk</strong> cruise missiles, significantly increased the vulnerability of Soviet forces in a conventional conflict.</li>
</ul></li>
</ul></li>
<li><strong>Challenges faced by the Soviet semiconductor industry</strong>:
<ul>
<li><strong>Political interference</strong>:
<ul>
<li>The KGB’s influence within the industry hindered efficiency and innovation.</li>
<li><strong>Yuri OShokhin’s</strong> removal from the <strong>Riga semiconductor plant</strong> for refusing to dismiss employees targeted by the KGB exemplified this problem.</li>
</ul></li>
<li><strong>Lack of a robust consumer market</strong>:
<ul>
<li>The absence of a large civilian market for electronics limited the growth and innovation of the Soviet semiconductor industry.</li>
<li>This contrasted with the US, Europe, and Japan, where booming consumer markets drove demand for advanced chips.</li>
</ul></li>
<li><strong>Limited international collaboration</strong>:
<ul>
<li>The Soviet Union’s isolation during the Cold War prevented it from accessing the global semiconductor supply chain and benefiting from specialization and economies of scale.</li>
<li>In contrast, the US and its allies had established an efficient international division of labor in chip production and innovation.</li>
</ul></li>
</ul></li>
<li>The Soviet Union’s efforts to revitalize its microelectronics industry ultimately failed.
<ul>
<li>Despite attempts to modernize <strong>Zelenograd</strong>, the USSR couldn’t match the technological advancements or the economic dynamism of Silicon Valley.</li>
</ul></li>
</ul>
</section>
<section id="chapter-27-war-hero" class="level2">
<h2 class="anchored" data-anchor-id="chapter-27-war-hero">Chapter 27: War Hero</h2>
<ul>
<li>The 1991 Persian Gulf War served as the first major test of US military technology developed after the Vietnam War.
<ul>
<li>The US military’s overwhelming victory against Iraq demonstrated the effectiveness of precision-guided munitions and advanced electronics in warfare.</li>
</ul></li>
<li><strong>The Paveway laser-guided bomb</strong>:
<ul>
<li>Originally developed during the Vietnam War, the Paveway underwent continuous improvement, with each iteration incorporating more advanced microelectronics.</li>
<li><strong>Weldon Word</strong>, the key figure behind the Paveway’s development, focused on improving its accuracy, reliability, and affordability.</li>
</ul></li>
<li><strong>Key advantages of the Paveway</strong>:
<ul>
<li><strong>High accuracy</strong>: Paveway bombs significantly increased hit rates compared to unguided munitions.</li>
<li><strong>Versatility</strong>: Targets could be chosen in real-time, allowing for flexibility on the battlefield.</li>
<li><strong>Cost-effectiveness</strong>: Advancements in microelectronics made the Paveway increasingly affordable, enabling widespread adoption.</li>
</ul></li>
<li><strong>The impact of microelectronics on other military technologies</strong>:
<ul>
<li><strong>Improved guidance systems</strong> for missiles, like the Sidewinder air-to-air missile, significantly increased their accuracy.</li>
<li><strong>Enhanced surveillance and communication systems</strong> provided the US military with a decisive information advantage.</li>
</ul></li>
<li><strong>Validation of the offset strategy</strong>:
<ul>
<li>The Persian Gulf War proved the effectiveness of Bill Perry’s offset strategy of investing in technology to counter Soviet numerical superiority.</li>
</ul></li>
<li><strong>“Silicon over steel”</strong>:
<ul>
<li>The war highlighted the shifting balance of power in warfare, with technology and information becoming as important as traditional military hardware.</li>
</ul></li>
</ul>
</section>
<section id="chapter-28-the-cold-war-is-over-and-you-have-won" class="level2">
<h2 class="anchored" data-anchor-id="chapter-28-the-cold-war-is-over-and-you-have-won">Chapter 28: The Cold War is Over and You Have Won</h2>
<ul>
<li>The 1990s marked a period of decline for the Japanese semiconductor industry and the rise of American dominance.
<ul>
<li>Japan’s economic bubble burst in 1990, leading to a prolonged recession and exposing the weaknesses of its over-investment in certain industries, including semiconductors.</li>
</ul></li>
<li><strong>Factors contributing to Japan’s semiconductor decline</strong>:
<ul>
<li><strong>Overinvestment and lack of profitability</strong>:
<ul>
<li>Japanese chipmakers, fueled by easy access to capital, continued investing heavily in DRAM production despite declining prices and competition from lower-cost producers like <strong>Micron</strong> and <strong>Samsung</strong>.</li>
<li>This overcapacity led to a DRAM glut and falling profits.</li>
</ul></li>
<li><strong>Missed opportunities in new markets</strong>:
<ul>
<li>Japanese companies, with the notable exception of <strong>Sony</strong>, failed to capitalize on the rising PC market and largely ignored the growing demand for microprocessors.</li>
<li>This contrasted with Intel’s successful pivot from DRAM to microprocessors.</li>
</ul></li>
<li><strong>Slow to adapt to changing market dynamics</strong>:
<ul>
<li>The Japanese model of consensus-driven decision-making, which had been an advantage in the past, hindered their ability to adapt quickly to the rapidly changing semiconductor landscape.</li>
</ul></li>
</ul></li>
<li><strong>Sony</strong>:
<ul>
<li>Sony’s success in developing specialized chips for image sensors highlighted the potential for innovation within the Japanese semiconductor industry.</li>
<li>However, even Sony struggled to maintain profitability in the face of increasing competition and the company’s failure to cut investments in loss-making sectors.</li>
</ul></li>
<li><strong>The decline of Japan’s semiconductor industry undermined its geopolitical ambitions</strong>:
<ul>
<li><strong>Akio Morita’s</strong>, co-author of “The Japan That Can Say No,” witnessed firsthand the decline of Japan’s economic and technological prowess.</li>
<li>The country’s inability to translate its semiconductor dominance into geopolitical power during the Persian Gulf War further highlighted its limitations.</li>
</ul></li>
<li><strong>The Soviet Union’s collapse</strong>:
<ul>
<li>By 1990, <strong>Mikhail Gorbachev</strong>, recognizing the Soviet Union’s dire economic and technological situation, sought closer ties with the West.</li>
<li>During a visit to Silicon Valley, Gorbachev acknowledged the region’s technological leadership and encouraged US investment in the USSR.</li>
</ul></li>
<li><strong>Ogarkov’s prediction</strong>:
<ul>
<li><strong>Marshal Ogarkov’s</strong> earlier prediction that the US had effectively won the Cold War due to its superior technology proved accurate.</li>
<li>The Soviet Union’s inability to compete in microelectronics and other advanced technologies significantly contributed to its collapse.</li>
</ul></li>
<li><strong>The end of the Cold War</strong>:
<ul>
<li>The US emerged victorious, with Silicon Valley’s technological prowess playing a decisive role in securing this victory.</li>
<li>The semiconductor industry had become a critical driver of both economic and military power.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="chapter-29-we-want-a-semiconductor-industry-in-taiwan" class="level2">
<h2 class="anchored" data-anchor-id="chapter-29-we-want-a-semiconductor-industry-in-taiwan">Chapter 29: We Want a Semiconductor Industry in Taiwan</h2>
<section id="taiwans-semiconductor-ambitions-1960s-1980s" class="level3">
<h3 class="anchored" data-anchor-id="taiwans-semiconductor-ambitions-1960s-1980s">Taiwan’s Semiconductor Ambitions (1960s-1980s)</h3>
<ul>
<li>By the 1980s, Taiwan aimed to transition from semiconductor assembly to chip fabrication to capture a larger share of the industry’s profits.
<ul>
<li><strong>Semiconductor assembly</strong>, primarily involving testing and packaging chips made elsewhere, offered lower profits than chip design and production.</li>
</ul></li>
</ul>
<section id="early-efforts-and-challenges" class="level4">
<h4 class="anchored" data-anchor-id="early-efforts-and-challenges">Early Efforts and Challenges</h4>
<ul>
<li>Taiwan had been strategically integrating itself into semiconductor supply chains since the 1960s.
<ul>
<li><strong>Goals:</strong>
<ul>
<li>Job creation</li>
<li>Acquisition of advanced technology</li>
<li>Strengthened security ties with the United States</li>
</ul></li>
</ul></li>
<li>Early successes included attracting Texas Instruments to build the island’s first semiconductor facility in the 1960s.
<ul>
<li>K.T. Lee, a powerful Taiwanese minister, was instrumental in securing TI’s investment and fostering relationships with its leaders, including Pat Haggerty and Morris Chang.</li>
</ul></li>
<li>Taiwan further encouraged electronics firms to establish factories on the island.</li>
<li>Despite these efforts, Taiwan faced challenges in advancing its chipmaking capabilities:
<ul>
<li><strong>UMC</strong>, a Taiwanese chipmaker founded in 1980 using licensed technology from America’s RCA, lagged behind the industry’s cutting edge.</li>
<li><strong>Competition:</strong> Taiwan faced fierce competition from other Asian economies:
<ul>
<li><strong>South Korea:</strong> Samsung and other conglomerates were heavily investing in advanced memory chips.</li>
<li><strong>Singapore and Malaysia:</strong> These countries were attempting to replicate South Korea’s transition from assembly to fabrication, but with limited success.</li>
</ul></li>
<li><strong>China’s Emergence:</strong> The People’s Republic of China’s integration into the global economy posed a significant threat.
<ul>
<li>China’s low wages and vast workforce attracted basic manufacturing and assembly jobs, directly challenging Taiwan’s economic model.</li>
<li>Taiwanese officials perceived this as “economic warfare,” as competing with China on price was deemed impossible.</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="morris-chang-and-the-birth-of-tsmc-1985" class="level3">
<h3 class="anchored" data-anchor-id="morris-chang-and-the-birth-of-tsmc-1985">Morris Chang and the Birth of TSMC (1985)</h3>
<ul>
<li>In 1985, Minister K.T. Lee recruited Morris Chang, a seasoned semiconductor industry veteran, to lead Taiwan’s push into chip fabrication.
<ul>
<li>Chang had extensive experience at Texas Instruments, playing a key role in establishing TI’s efficient manufacturing processes and the company’s presence in Taiwan.</li>
<li>He had left TI in the early 1980s after being passed over for the CEO position.</li>
<li>Chang’s deep understanding of the industry and proven track record made him an ideal candidate for the challenging task.</li>
</ul></li>
</ul>
<section id="the-foundry-model-a-radical-idea" class="level4">
<h4 class="anchored" data-anchor-id="the-foundry-model-a-radical-idea">The Foundry Model: A Radical Idea</h4>
<ul>
<li>Chang proposed a radical business model—a <strong>“foundry”—</strong>to propel Taiwan’s semiconductor industry forward.
<ul>
<li>This model involved manufacturing chips designed by other companies rather than designing and producing chips in-house, which was the prevailing industry model at the time.</li>
</ul></li>
<li>Chang had first pitched this idea while at TI in 1976, predicting the rise of <strong>“fabless”</strong> companies that focused solely on chip design.
<ul>
<li>However, TI executives rejected the proposal, deeming it too risky to invest in markets that didn’t yet exist.</li>
</ul></li>
<li>The concept gained traction due to several factors:
<ul>
<li><strong>Lynn Conway and Carver Mead’s work:</strong> Their revolution in chip design, which simplified the separation of design and manufacturing, made Chang’s foundry model more feasible.</li>
<li><strong>Growing demand:</strong> Chang anticipated that the decreasing cost of computing power would drive demand for semiconductors in a wide range of new applications, creating opportunities for specialized manufacturers.</li>
<li><strong>Rising manufacturing costs:</strong> As transistors shrank and technology advanced, the cost of manufacturing equipment and R&amp;D became increasingly prohibitive for companies producing smaller volumes of chips.</li>
</ul></li>
</ul>
</section>
<section id="tsmcs-founding-and-government-support" class="level4">
<h4 class="anchored" data-anchor-id="tsmcs-founding-and-government-support">TSMC’s Founding and Government Support</h4>
<ul>
<li>Minister Lee secured government funding for Chang’s ambitious plan, with the Taiwanese government providing 48% of TSMC’s startup capital.
<ul>
<li>The government also granted generous tax benefits to support the company’s growth.</li>
</ul></li>
<li>Chang’s former colleagues at TI and Intel declined to provide the necessary advanced production technology.
<ul>
<li>Gordon Moore, of Intel, famously told Chang, “Morris, you’ve had a lot of good ideas in your time. This isn’t one of them.”</li>
</ul></li>
<li>Eventually, Chang secured a deal with Philips, the Dutch semiconductor company:
<ul>
<li>Philips invested $58 million, transferred its production technology, and licensed intellectual property to TSMC in exchange for a 27.5% stake.</li>
</ul></li>
<li>The remaining capital was raised from wealthy Taiwanese families, often through government pressure and appeals to their past successes with government support.</li>
<li>From its inception, TSMC operated as a project of the Taiwanese state, heavily reliant on government support and funding.</li>
</ul>
</section>
</section>
<section id="tsmcs-success-and-the-rise-of-taiwans-chip-dominance" class="level3">
<h3 class="anchored" data-anchor-id="tsmcs-success-and-the-rise-of-taiwans-chip-dominance">TSMC’s Success and the Rise of Taiwan’s Chip Dominance</h3>
<section id="tsmcs-symbiotic-relationship-with-silicon-valley" class="level4">
<h4 class="anchored" data-anchor-id="tsmcs-symbiotic-relationship-with-silicon-valley">TSMC’s Symbiotic Relationship with Silicon Valley</h4>
<ul>
<li>TSMC’s early success was deeply intertwined with the U.S. chip industry.
<ul>
<li>Many of TSMC’s top executives and engineers had experience working at leading Silicon Valley companies like Motorola, Intel, and TI, bringing valuable expertise to the company.</li>
<li>A significant portion of TSMC’s early customers were U.S.-based chip designers.</li>
<li>By the mid-1990s, American companies accounted for half of TSMC’s sales.</li>
</ul></li>
</ul>
</section>
<section id="the-foundry-models-impact-democratization-and-monopolization" class="level4">
<h4 class="anchored" data-anchor-id="the-foundry-models-impact-democratization-and-monopolization">The Foundry Model’s Impact: Democratization and Monopolization</h4>
<ul>
<li>TSMC’s foundry model addressed the challenges faced by early fabless chip design firms, providing them with a reliable manufacturing partner and fostering innovation in the industry.
<ul>
<li>Previously, these smaller firms had to rely on larger chipmakers with spare capacity, often facing second-class status, potential intellectual property theft, and inconsistencies in manufacturing processes.</li>
</ul></li>
<li>TSMC’s commitment to manufacturing chips designed by its customers, without competing in the design space, built trust and attracted a wide range of clients.</li>
<li>This model, mirroring Carver Mead’s “Gutenberg moment” prediction, significantly lowered the barriers to entry in the chip design industry, leading to a surge in new fabless chip design firms.
<ul>
<li>The availability of affordable, high-quality chip manufacturing enabled these companies to focus on innovation and develop specialized chips for a wide range of applications.</li>
</ul></li>
<li>However, unlike Gutenberg’s printing press, which spread rapidly across Europe, TSMC’s foundry model, while democratizing chip design, ultimately led to the monopolization of chip manufacturing.
<ul>
<li>The economics of chip fabrication favored large-scale production, with companies like TSMC gaining a significant advantage through higher yields and lower costs per chip.</li>
<li>This dynamic drove relentless consolidation in the industry, with TSMC emerging as the dominant player in the production of the world’s most advanced chips.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-1" class="level4">
<h4 class="anchored" data-anchor-id="conclusion-1">Conclusion</h4>
<ul>
<li>Morris Chang’s vision, combined with Taiwan’s unwavering government support, transformed the island into a global semiconductor powerhouse.</li>
<li>TSMC’s foundry model revolutionized the chip industry, enabling innovation and driving the widespread adoption of semiconductors in countless devices.</li>
<li>However, this success came at the cost of increased industry consolidation, with TSMC wielding unprecedented influence over the production of the world’s most critical technology.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-30-all-people-must-make-semiconductors" class="level2">
<h2 class="anchored" data-anchor-id="chapter-30-all-people-must-make-semiconductors">Chapter 30: All People Must Make Semiconductors</h2>
<section id="the-rise-of-taiwan-and-huawei" class="level3">
<h3 class="anchored" data-anchor-id="the-rise-of-taiwan-and-huawei">The Rise of Taiwan and Huawei</h3>
<ul>
<li>In 1987:
<ul>
<li><strong>Morris Chang</strong> founded <strong>TSMC</strong> in Taiwan.</li>
<li><strong>Ren Jung-fei</strong> founded <strong>Huawei</strong>, an electronics trading company, in Shenzhen, China.</li>
</ul></li>
<li><strong>Taiwan:</strong>
<ul>
<li>Small island with global ambitions in chipmaking.</li>
<li>Deep connections with:
<ul>
<li>Advanced chip companies.</li>
<li>Highly educated engineers (Stanford, Berkeley).</li>
</ul></li>
</ul></li>
<li><strong>China:</strong>
<ul>
<li>Vast population, but economically and technologically behind.</li>
<li>Economic openness boosted trade, especially through Hong Kong.</li>
<li><strong>Shenzhen:</strong>
<ul>
<li>Located near Hong Kong, became a hub for electronics trade.</li>
<li>Huawei bought cheap equipment in Hong Kong and sold it at higher prices within China.</li>
</ul></li>
</ul></li>
<li><strong>Different Approaches:</strong>
<ul>
<li><strong>TSMC (Taiwan):</strong> Focused on building advanced chips, targeting Silicon Valley giants as customers.</li>
<li><strong>Huawei (China):</strong> Initially focused on trading electronics, with no chip production aspirations.</li>
</ul></li>
</ul>
</section>
<section id="chinas-semiconductor-struggle-under-communist-rule" class="level3">
<h3 class="anchored" data-anchor-id="chinas-semiconductor-struggle-under-communist-rule">China’s Semiconductor Struggle Under Communist Rule</h3>
<ul>
<li><strong>1980s:</strong>
<ul>
<li>Chinese government, led by <strong>Jiang Zemin</strong>, prioritized electronics.</li>
<li>China’s most advanced domestic chip was a DRAM over a decade behind the cutting edge.</li>
</ul></li>
<li><strong>Lost Potential:</strong>
<ul>
<li>China possessed factors that attracted American semiconductor investment in other Asian countries:
<ul>
<li>Vast, low-cost workforce.</li>
<li>Well-educated scientific elite.</li>
</ul></li>
<li>However, the communist regime:
<ul>
<li>Viewed foreign connections with suspicion.</li>
<li>Discouraged talent like Morris Chang from returning from abroad.</li>
<li>Made similar mistakes to the Soviet Union, but more extreme.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="maos-disastrous-impact-on-chinas-chip-industry" class="level3">
<h3 class="anchored" data-anchor-id="maos-disastrous-impact-on-chinas-chip-industry">Mao’s Disastrous Impact on China’s Chip Industry</h3>
<ul>
<li><strong>Early Efforts:</strong>
<ul>
<li>Mid-1950s: Beijing identified semiconductors as a scientific priority.</li>
<li>1960:
<ul>
<li>Established its first semiconductor research institute in Beijing.</li>
<li>Began manufacturing simple transistor radios.</li>
</ul></li>
<li>1965: Chinese engineers created their first integrated circuit, 5 years behind the US.</li>
</ul></li>
<li><strong>The Cultural Revolution (1966-1976):</strong>
<ul>
<li><strong>Mao Zedong’s</strong> radical policies devastated China’s scientific and technological progress.</li>
<li>Intellectuals and experts were persecuted, sent to work as farmers, or killed.</li>
<li>Education system severely disrupted.</li>
<li><strong>Mao’s Directive (July 21, 1968):</strong>
<ul>
<li>Shorten schooling.</li>
<li>Revolutionize education.</li>
<li>Prioritize proletarian politics over expertise.</li>
<li>Students selected from workers and peasants.</li>
<li>Return to production after a few years.</li>
</ul></li>
<li>This approach hindered technological advancement and innovation.</li>
</ul></li>
<li><strong>Self-Reliance and Suspicion of Foreign Technology:</strong>
<ul>
<li><strong>Mao</strong> enforced an embargo on foreign technology, even though China couldn’t produce advanced components.</li>
<li>Propaganda promoted “independent and self-reliant development” of the electronics industry.</li>
</ul></li>
<li><strong>Ideological Opposition to Electronics:</strong>
<ul>
<li>Mao viewed electronics as potentially anti-socialist.</li>
<li>Prioritized heavy industries like iron and steel over electronics.</li>
</ul></li>
</ul>
</section>
<section id="the-contrast-with-hong-kong-and-taiwan" class="level3">
<h3 class="anchored" data-anchor-id="the-contrast-with-hong-kong-and-taiwan">The Contrast with Hong Kong and Taiwan</h3>
<ul>
<li><strong>Hong Kong:</strong>
<ul>
<li>Still under British rule, avoided the Cultural Revolution.</li>
<li>Fairchild Semiconductor operated a plant in Hong Kong, employing workers while mainland China faced turmoil.</li>
</ul></li>
<li><strong>Taiwan:</strong>
<ul>
<li>Hosted multiple US chip firms, providing jobs and fostering technological development.</li>
</ul></li>
</ul>
</section>
<section id="the-aftermath-of-the-cultural-revolution" class="level3">
<h3 class="anchored" data-anchor-id="the-aftermath-of-the-cultural-revolution">The Aftermath of the Cultural Revolution</h3>
<ul>
<li><strong>Early 1970s:</strong>
<ul>
<li>Mao’s health declined, leading to a gradual end to the Cultural Revolution.</li>
<li>Scientists returned from rural areas, but damage was severe.</li>
<li>China’s chip industry lagged far behind its neighbors and the West.</li>
</ul></li>
<li><strong>1975:</strong>
<ul>
<li>China only produced one usable semiconductor per 1,000 manufactured.</li>
</ul></li>
<li><strong>John Bardeen’s Visit (September 2nd, 1975):</strong>
<ul>
<li>Two-time Nobel laureate in Physics.</li>
<li>Visited China as part of a delegation of American physicists.</li>
<li>Visit signaled a thaw in relations after the Cultural Revolution.</li>
<li>Observed the state of China’s semiconductor industry and found it lacking.</li>
</ul></li>
</ul>
</section>
<section id="deng-xiaoping-and-the-four-modernizations" class="level3">
<h3 class="anchored" data-anchor-id="deng-xiaoping-and-the-four-modernizations">Deng Xiaoping and the Four Modernizations</h3>
<ul>
<li><strong>Post-Mao Era:</strong>
<ul>
<li>Mao died in 1976.</li>
<li><strong>Deng Xiaoping</strong> rose to power.</li>
<li>Implemented the <strong>Four Modernizations</strong>, including advancements in science and technology.</li>
</ul></li>
<li><strong>National Science Conference (March 1978):</strong>
<ul>
<li>Semiconductors were central to the agenda.</li>
<li>Aim: Develop weapons systems, consumer electronics, and computers.</li>
</ul></li>
<li><strong>Challenges:</strong>
<ul>
<li>Decades of isolation and ideological opposition had severely hampered China’s technological capabilities.</li>
<li>China remained heavily reliant on foreign chips.</li>
</ul></li>
</ul>
</section>
<section id="the-made-in-china-obsession" class="level3">
<h3 class="anchored" data-anchor-id="the-made-in-china-obsession">The “Made in China” Obsession</h3>
<ul>
<li><strong>1980s:</strong>
<ul>
<li>China pushed for domestic production of semiconductors.</li>
<li>This drive was hindered by:
<ul>
<li>Technological backwardness.</li>
<li>Bureaucracy.</li>
<li>Lack of access to advanced foreign technology.</li>
</ul></li>
</ul></li>
<li><strong>Huawei’s Rise:</strong>
<ul>
<li>Despite the push for domestic production, companies like Huawei remained reliant on foreign chips for their electronics assembly.</li>
</ul></li>
</ul>
</section>
<section id="key-takeaways" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaways">Key Takeaways:</h3>
<ul>
<li>The Cultural Revolution had a devastating and long-lasting impact on China’s semiconductor industry.</li>
<li>Despite efforts to catch up, China remained reliant on foreign technology.</li>
<li>The “Made in China” ambition faced significant challenges due to the legacy of past policies and the global dominance of other chip-producing regions.</li>
</ul>
</section>
</section>
<section id="chapter-31-sharing-gods-love-with-the-chinese" class="level2">
<h2 class="anchored" data-anchor-id="chapter-31-sharing-gods-love-with-the-chinese">Chapter 31: Sharing God’s Love with the Chinese</h2>
<section id="richard-chang-and-semiconductor-manufacturing-in-china" class="level3">
<h3 class="anchored" data-anchor-id="richard-chang-and-semiconductor-manufacturing-in-china">Richard Chang and Semiconductor Manufacturing in China</h3>
<ul>
<li><strong>Richard Chang</strong>, a devout Christian and semiconductor engineer, aimed to bring advanced chip-making to China.
<ul>
<li>Born in Nanjing in 1948, his family fled to Taiwan when he was one year old after the Communist takeover.</li>
<li>Earned a graduate degree in Buffalo, New York, and worked at Texas Instruments, gaining expertise in operating fabs.</li>
</ul></li>
<li>In 2000, Chang founded <strong>Semiconductor Manufacturing International Corporation (SMIC)</strong> in Shanghai.
<ul>
<li>Secured over $1.5 billion from international investors, with an estimated half coming from U.S. investors.</li>
<li>Hired hundreds of foreign experts, including at least 400 from Taiwan, to operate SMIC’s fab.</li>
</ul></li>
<li>Chang’s strategy mirrored TSMC’s successful approach in Taiwan:
<ul>
<li>Recruit the best engineers with experience at advanced chip firms.</li>
<li>Invest in the best equipment.</li>
<li>Prioritize employee training in industry best practices.</li>
<li>Leverage government tax and subsidy benefits.</li>
</ul></li>
<li>SMIC’s aggressive hiring strategy:
<ul>
<li>Focused on recruiting experienced engineers from overseas chipmakers, primarily Taiwan.</li>
<li><strong>“One Old Staffer Brings Along Two New Ones”</strong>: A company slogan emphasizing the need for experienced foreign-trained employees to train local engineers.</li>
<li>Foreign-trained workforce proved crucial for SMIC’s success in domesticating technology.</li>
</ul></li>
<li>Workforce Composition (Doug Fuller’s analysis):
<ul>
<li>In 2001: 650 local engineers and 393 recruited from overseas (mostly Taiwan and the U.S.).</li>
<li>Throughout the 2000s: Approximately one-third of engineering employees were hired from abroad.</li>
</ul></li>
<li>SMIC’s Successes:
<ul>
<li>Benefited from significant government support (five-year corporate tax holiday, reduced sales tax on chips sold in China).</li>
<li>Focused on manufacturing quality and adopting near cutting-edge technology.</li>
<li>Secured contracts to build chips for industry leaders like Texas Instruments.</li>
<li>Listed its shares on the New York Stock Exchange in 2004.</li>
</ul></li>
<li>By the late 2000s, SMIC was only a couple of years behind the world’s technology leaders, on track to potentially rival TSMC.</li>
</ul>
</section>
<section id="the-global-shift-in-semiconductor-fabrication-1990s-2000s" class="level3">
<h3 class="anchored" data-anchor-id="the-global-shift-in-semiconductor-fabrication-1990s-2000s">The Global Shift in Semiconductor Fabrication (1990s-2000s)</h3>
<ul>
<li><strong>Declining U.S. Market Share:</strong>
<ul>
<li>1990: U.S. fabs produced 37% of the world’s chips.</li>
<li>2000: This figure fell to 19%.</li>
<li>2010: Further declined to 13%.</li>
</ul></li>
<li><strong>Japan’s Collapsing Market Share:</strong> Experienced a significant decline (specific figures not provided).</li>
<li><strong>Rise of East Asian Competitors:</strong>
<ul>
<li>South Korea, Singapore, and Taiwan made substantial investments in their chip industries, leading to rapid output increases.</li>
</ul></li>
<li><strong>Singapore:</strong>
<ul>
<li>Government-funded fabrication facilities and chip design centers in partnership with companies like Texas Instruments, Hewlett-Packard, and Hitachi, fostering a thriving semiconductor sector.</li>
<li><strong>Chartered Semiconductor:</strong> A government-backed foundry established to emulate TSMC (though it never achieved the same level of success).</li>
</ul></li>
<li><strong>South Korea:</strong>
<ul>
<li><strong>Samsung’s Rise:</strong> After becoming the world’s leading memory chip maker in 1992 by dethroning Japanese DRAM producers, Samsung experienced rapid growth.
<ul>
<li>Benefited from government support, including pressure on banks to provide credit.</li>
<li>Successfully fended off competition from Taiwan and Singapore in the DRAM market.</li>
</ul></li>
</ul></li>
<li><strong>The DRAM “Chicken Game”:</strong>
<ul>
<li>Characterized by intense competition and heavy investment in new factories, leading to overcapacity and price drops.</li>
<li>Samsung’s financial strength allowed it to outspend rivals during downturns, leading to increased market share.</li>
</ul></li>
</ul>
</section>
<section id="chinas-semiconductor-ambitions" class="level3">
<h3 class="anchored" data-anchor-id="chinas-semiconductor-ambitions">China’s Semiconductor Ambitions</h3>
<ul>
<li><strong>1990s:</strong>
<ul>
<li>China emerged as the “world’s workshop,” with cities like Shanghai and Shenzhen becoming hubs for electronics assembly.</li>
<li>However, chip manufacturing lagged behind Taiwan, South Korea, and the U.S.</li>
<li>Smuggling chips from Hong Kong remained profitable due to limited domestic production.</li>
</ul></li>
<li><strong>Government Efforts to Develop Domestic Chip Industry:</strong>
<ul>
<li>Early attempts were often characterized by:
<ul>
<li>Reliance on foreign investment and technology transfer agreements that offered limited benefits to China.</li>
<li>Examples:
<ul>
<li><strong>Hua Hong and NEC Joint Venture:</strong> Japanese experts retained control, leaving Chinese workers with basic tasks.</li>
<li><strong>Grace Semiconductor:</strong> A venture involving politically connected individuals (Jiang Minhang, son of Chinese President Jiang Zemin, and Winston Wang) and Neil Bush (brother of U.S. President George W. Bush). Despite this, the company struggled with technology and market share.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Shift from Assembly to Components:</strong>
<ul>
<li>Chinese leaders recognized the greater profitability of producing semiconductors compared to assembling electronics.</li>
<li>Richard Chang’s vision of bringing chip manufacturing to China aligned with this ambition.</li>
</ul></li>
</ul>
</section>
<section id="the-rise-of-fabless-semiconductor-designers-and-the-smartphone-revolution" class="level3">
<h3 class="anchored" data-anchor-id="the-rise-of-fabless-semiconductor-designers-and-the-smartphone-revolution">The Rise of Fabless Semiconductor Designers and the Smartphone Revolution</h3>
<ul>
<li>The emergence of <strong>fabless</strong> semiconductor firms that designed chips but outsourced manufacturing.</li>
<li><strong>Benefits of Offshoring:</strong> Lower manufacturing costs and increased competition, resulting in lower prices for consumers.</li>
<li><strong>The Smartphone Revolution:</strong>
<ul>
<li>Fabless firms played a key role in developing smartphones, which required numerous complex chips.</li>
<li>The combination of offshoring, competition, and technological innovation benefited consumers with affordable and advanced devices.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-2" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-2">Conclusion</h3>
<ul>
<li>Richard Chang’s efforts to establish SMIC as a leading chip manufacturer in China exemplified the global shift in semiconductor production.</li>
<li>Government support, foreign investment, and the relentless pursuit of technological advancement characterized this period.</li>
<li>The rise of fabless firms, coupled with the increasing demand for complex chips in devices like smartphones, further fueled the growth of the semiconductor industry.</li>
</ul>
</section>
</section>
<section id="chapter-32-lithography-wars" class="level2">
<h2 class="anchored" data-anchor-id="chapter-32-lithography-wars">Chapter 32: Lithography Wars</h2>
<section id="the-challenge-of-shrinking-transistors" class="level3">
<h3 class="anchored" data-anchor-id="the-challenge-of-shrinking-transistors">The Challenge of Shrinking Transistors</h3>
<ul>
<li><strong>Lithography</strong> - A process using light to carve circuits onto silicon wafers.</li>
<li>As transistors shrunk due to <strong>Moore’s Law</strong>, traditional lithography methods faced limitations.
<ul>
<li><strong>Moore’s Law:</strong> The observation that the number of transistors on a microchip doubles approximately every two years, leading to exponential increases in computing power.</li>
</ul></li>
<li>Existing ultraviolet (UV) light techniques with wavelengths of 248 or 193 nanometers would soon be insufficient.</li>
<li><strong>Extreme ultraviolet (EUV) light</strong>, with a wavelength of 13.5 nanometers, was proposed as the solution for producing smaller circuits.
<ul>
<li>Smaller wavelengths enable carving smaller features onto chips.</li>
</ul></li>
<li><strong>Challenge</strong>: Most experts believed mass-producing EUV light was impossible.</li>
</ul>
</section>
<section id="intels-gamble-on-euv" class="level3">
<h3 class="anchored" data-anchor-id="intels-gamble-on-euv">Intel’s Gamble on EUV</h3>
<ul>
<li><strong>1992</strong>: John Carruthers, Intel’s R&amp;D leader, requested $200 million from CEO Andy Grove to develop EUV lithography.
<ul>
<li>Grove was skeptical, as EUV’s viability was uncertain.</li>
<li>Carruthers argued it was a necessary “research” investment.</li>
<li>Gordon Moore (former CEO and advisor) agreed, highlighting the lack of alternatives if Moore’s Law were to continue.</li>
</ul></li>
<li><strong>Outcome</strong>: Grove approved the funding, ultimately leading to billions invested in EUV R&amp;D and implementation.</li>
<li><strong>Intel’s Strategy</strong>:
<ul>
<li>Focused on ensuring at least one lithography company successfully brought EUV machines to market.</li>
<li>Intel needed these tools to continue shrinking circuits on their chips.</li>
</ul></li>
</ul>
</section>
<section id="three-battles-over-lithographys-future" class="level3">
<h3 class="anchored" data-anchor-id="three-battles-over-lithographys-future">Three Battles over Lithography’s Future</h3>
<section id="the-engineering-battle-finding-the-right-beam" class="level4">
<h4 class="anchored" data-anchor-id="the-engineering-battle-finding-the-right-beam">1. The Engineering Battle: Finding the Right Beam</h4>
<ul>
<li><strong>The Challenge:</strong> Transistors were approaching sizes where the wavelength of light used in lithography significantly impacted precision.</li>
<li><strong>Competing technologies:</strong>
<ul>
<li><strong>Electron beam lithography</strong>: Precise but too slow for mass production.</li>
<li><strong>X-ray lithography</strong>: Used X-rays and specific photoresist chemicals.</li>
<li><strong>EUV lithography</strong>: Utilized extreme ultraviolet light and its corresponding photoresists.</li>
</ul></li>
<li><strong>“Lithography Wars”</strong>: Intense competition between engineering groups advocating for different technologies.</li>
</ul>
</section>
<section id="the-commercial-battle-dominance-in-lithography-equipment" class="level4">
<h4 class="anchored" data-anchor-id="the-commercial-battle-dominance-in-lithography-equipment">2. The Commercial Battle: Dominance in Lithography Equipment</h4>
<ul>
<li><strong>High Stakes:</strong> Developing new lithography equipment was incredibly expensive, leading to industry consolidation.</li>
<li><strong>Key Players:</strong>
<ul>
<li><strong>Canon (Japan)</strong>: Market leader.</li>
<li><strong>Nikon (Japan)</strong>: Market leader.</li>
<li><strong>ASML (Netherlands):</strong> Small but growing competitor.</li>
</ul></li>
<li><strong>Decline of US Companies:</strong>
<ul>
<li><strong>GCA:</strong> Liquidated.</li>
<li><strong>Silicon Valley Group (SVG):</strong> Technologically behind Canon and Nikon.</li>
</ul></li>
<li><strong>ASML’s Rise:</strong>
<ul>
<li><strong>Strategic Sourcing:</strong> Assembled systems from globally sourced components, allowing them to utilize the best available parts.</li>
<li><strong>Neutrality:</strong> Perceived as neutral in US-Japan trade disputes, attracting US customers like Micron.</li>
<li><strong>Partnership with TSMC (Taiwan):</strong>
<ul>
<li>Philips (ASML’s parent company) had a strong relationship with TSMC.</li>
<li>ASML became a key supplier as TSMC’s fabs were compatible with Philips’ technology.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="the-geopolitical-battle-control-and-access" class="level4">
<h4 class="anchored" data-anchor-id="the-geopolitical-battle-control-and-access">3. The Geopolitical Battle: Control and Access</h4>
<ul>
<li><strong>Context:</strong>
<ul>
<li>The US emerged from the Cold War as a global superpower.</li>
<li>Globalization and interconnectedness were seen as inevitable and positive.</li>
<li>Intel dominated the microprocessor market.</li>
</ul></li>
<li><strong>Intel’s Consortium:</strong>
<ul>
<li><strong>1996</strong>: Intel partnered with US Department of Energy labs (e.g., Lawrence Livermore, Sandia) to advance EUV.</li>
<li>Goal: Transition EUV from scientific research to mass production.</li>
</ul></li>
<li><strong>Choosing ASML:</strong>
<ul>
<li>US firms (GCA defunct, SVG lagging) couldn’t commercialize EUV.</li>
<li>Government opposed Japanese involvement (Nikon, Canon) due to past trade tensions.</li>
<li>ASML, despite being foreign, became the only viable option.</li>
</ul></li>
<li><strong>Concerns and Justifications:</strong>
<ul>
<li><strong>US Government Concerns:</strong> Giving a foreign company access to sensitive national lab research raised concerns about future access to critical technology.</li>
<li><strong>Counterarguments:</strong>
<ul>
<li>No immediate military application for EUV.</li>
<li>EUV’s success was not guaranteed.</li>
<li>ASML (and the Netherlands) were seen as reliable partners.</li>
<li>Job creation through an ASML facility in the US was prioritized.</li>
</ul></li>
<li><strong>Industry Perspective:</strong> Focused on efficient semiconductor production; ASML was the only company capable of delivering EUV.</li>
</ul></li>
<li><strong>ASML’s Monopoly:</strong>
<ul>
<li>Nikon and Canon, excluded from US research, abandoned EUV development.</li>
<li><strong>2001</strong>: ASML acquired SVG (US’s last major lithography firm).
<ul>
<li><strong>Concerns:</strong> Further consolidated EUV technology under ASML.</li>
<li><strong>Justifications:</strong>
<ul>
<li>Necessary for EUV progress and the future of computing (argued by Intel CEO Craig Barrett).</li>
<li>Aligned with the Bush administration’s policy of promoting globalization and loosening export controls.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The Outcome:</strong>
<ul>
<li>EUV development continued with ASML as the sole supplier.</li>
<li>Concerns about US reliance on a foreign company for this critical technology were dismissed.</li>
<li>The narrative of globalization masked the reality of a single company monopolizing EUV lithography.</li>
</ul></li>
</ul>
</section>
</section>
</section>
<section id="chapter-33-the-innovators-dilemma" class="level2">
<h2 class="anchored" data-anchor-id="chapter-33-the-innovators-dilemma">Chapter 33: The Innovator’s Dilemma</h2>
<section id="intels-missed-opportunities" class="level3">
<h3 class="anchored" data-anchor-id="intels-missed-opportunities">Intel’s Missed Opportunities</h3>
<section id="intels-dominance-and-the-x86-architecture" class="level4">
<h4 class="anchored" data-anchor-id="intels-dominance-and-the-x86-architecture">Intel’s Dominance and the x86 Architecture</h4>
<ul>
<li>By 2006, <strong>Intel</strong> supplied the processors for most PCs.
<ul>
<li>They achieved this by fending off <strong>AMD</strong>, the only other major company producing chips using the <strong>x86 instruction set architecture</strong>.
<ul>
<li><strong>x86 instruction set architecture</strong>: A foundational set of rules governing how chips compute; the industry standard for PCs.</li>
</ul></li>
<li><strong>Apple</strong> was the only major computer maker not using x86-based chips until 2006 when they announced a switch to Intel chips.</li>
</ul></li>
<li>Intel’s dominance in the PC market stemmed from <strong>IBM</strong>’s decision to use x86 processors in their first personal computers.
<ul>
<li>This positioned Intel as a controller of a crucial building block in the PC ecosystem, much like <strong>Microsoft</strong> with their operating system, Windows.</li>
</ul></li>
<li>While considered complex and bulky compared to the <strong>RISC</strong> architecture, x86 became entrenched due to the cost of change and the threat to Intel’s dominance.</li>
</ul>
</section>
<section id="andy-groves-castle-and-moat-vision" class="level4">
<h4 class="anchored" data-anchor-id="andy-groves-castle-and-moat-vision">Andy Grove’s “Castle and Moat” Vision</h4>
<ul>
<li>In the early 1990s, then-CEO <strong>Andy Grove</strong> envisioned Intel’s future as a “castle and moat.”
<ul>
<li>The castle represented Intel’s profitability.</li>
<li>The moat was the x86 architecture, protecting the castle.</li>
</ul></li>
<li>Grove considered, but ultimately rejected, switching to the more efficient RISC architecture.
<ul>
<li>The cost of abandoning the established x86 infrastructure was deemed too high.</li>
</ul></li>
</ul>
</section>
<section id="intels-server-chip-monopoly" class="level4">
<h4 class="anchored" data-anchor-id="intels-server-chip-monopoly">Intel’s Server Chip Monopoly</h4>
<ul>
<li>Alongside their PC market dominance, Intel leveraged their manufacturing prowess to dominate the server chip market.</li>
<li>This market grew rapidly with the rise of large data centers and cloud computing.</li>
<li>Today, <strong>Intel</strong> and <strong>AMD</strong>, both using x86, control nearly the entire data center chip market.</li>
</ul>
</section>
</section>
<section id="the-rise-of-arm-and-the-mobile-revolution" class="level3">
<h3 class="anchored" data-anchor-id="the-rise-of-arm-and-the-mobile-revolution">The Rise of ARM and the Mobile Revolution</h3>
<section id="arms-alternative-vision" class="level4">
<h4 class="anchored" data-anchor-id="arms-alternative-vision">ARM’s Alternative Vision</h4>
<ul>
<li><strong>ARM</strong> (Advanced RISC Machines), a joint venture founded by Apple and two partners in 1990, aimed to challenge x86 with a RISC-based architecture.</li>
<li><strong>Robin Saxby</strong>, ARM’s first CEO, envisioned ARM as the global standard in chip architecture.</li>
<li><strong>ARM’s Business Model</strong>:
<ul>
<li>Sell licenses for their architecture to <strong>fabless design firms</strong>.</li>
<li>These firms would customize ARM’s architecture, then outsource manufacturing to companies like <strong>TSMC</strong> (Taiwan Semiconductor Manufacturing Company).</li>
</ul></li>
<li>This model directly challenged Intel’s vertically integrated approach.</li>
</ul>
</section>
<section id="arms-early-successes-and-intels-missed-opportunity" class="level4">
<h4 class="anchored" data-anchor-id="arms-early-successes-and-intels-missed-opportunity">ARM’s Early Successes and Intel’s Missed Opportunity</h4>
<ul>
<li>ARM initially struggled to penetrate the PC market due to the strength of the Intel-Microsoft partnership.</li>
<li>However, ARM’s energy-efficient architecture flourished in the mobile device market.
<ul>
<li><strong>Nintendo</strong> adopted ARM-based chips for their handheld consoles.</li>
</ul></li>
<li>Intel, blinded by the profitability of their PC market, failed to recognize the significance of mobile devices.</li>
<li>Despite early warnings from executives about the potential of mobile devices, Intel prioritized their highly profitable PC chip business.</li>
</ul>
</section>
</section>
<section id="the-iphone-and-the-consequences-of-inaction" class="level3">
<h3 class="anchored" data-anchor-id="the-iphone-and-the-consequences-of-inaction">The iPhone and the Consequences of Inaction</h3>
<section id="apples-proposal-and-intels-refusal" class="level4">
<h4 class="anchored" data-anchor-id="apples-proposal-and-intels-refusal">Apple’s Proposal and Intel’s Refusal</h4>
<ul>
<li><strong>Steve Jobs</strong> approached Intel’s CEO, <strong>Paul Ottolini</strong>, to build a powerful, computer-style processor for their new product - the iPhone.</li>
<li>Intel, focused on profit margins and underestimating the iPhone’s potential, declined Apple’s offer.</li>
</ul>
</section>
<section id="the-rise-of-apple-and-the-decline-of-intels-mobile-ambitions" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-apple-and-the-decline-of-intels-mobile-ambitions">The Rise of Apple and the Decline of Intel’s Mobile Ambitions</h4>
<ul>
<li>Apple turned to ARM architecture and <strong>Samsung</strong> (as the chip manufacturer) for the iPhone’s processor.</li>
<li>The iPhone’s success exceeded all expectations, with Apple’s profits from smartphones eventually surpassing Intel’s PC processor profits.</li>
<li>While Intel invested heavily in catching up in the mobile market, they failed to gain a significant foothold against Apple.</li>
</ul>
</section>
</section>
<section id="intels-innovators-dilemma" class="level3">
<h3 class="anchored" data-anchor-id="intels-innovators-dilemma">Intel’s “Innovator’s Dilemma”</h3>
<ul>
<li>Despite being familiar with <strong>Clayton Christensen</strong>’s concept of the <strong>innovator’s dilemma</strong>, Intel fell victim to their own success.</li>
<li><strong>The Innovator’s Dilemma</strong>: The tendency of established, successful companies to focus on sustaining innovation for existing markets (and higher profit margins), thus neglecting potentially disruptive innovations in smaller, emerging markets.</li>
<li>Intel’s focus on short-term profit margins, driven by a management culture that prioritized financial engineering over technological leadership, blinded them to the transformative potential of mobile devices.</li>
</ul>
<section id="key-takeaways-1" class="level4">
<h4 class="anchored" data-anchor-id="key-takeaways-1">Key Takeaways:</h4>
<ul>
<li>Intel’s immense profitability in the PC and server markets became a liability.</li>
<li>Their prioritization of high-profit-margin products stifled innovation in new, potentially disruptive markets.</li>
<li>The company culture shifted from a focus on technological advancement to a focus on financial optimization.</li>
<li>This led to a failure to capitalize on the mobile revolution, costing them a chance to dominate another era of computing.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-34-running-faster" class="level2">
<h2 class="anchored" data-anchor-id="chapter-34-running-faster">Chapter 34: Running Faster?</h2>
<section id="andy-groves-concerns" class="level3">
<h3 class="anchored" data-anchor-id="andy-groves-concerns">Andy Grove’s Concerns</h3>
<ul>
<li>In 2010, Andy Grove, former Intel chairman, expressed concern about the offshoring of advanced manufacturing jobs in Silicon Valley, despite the region’s economic success.</li>
</ul>
<section id="observations-fueling-groves-concerns" class="level4">
<h4 class="anchored" data-anchor-id="observations-fueling-groves-concerns">Observations Fueling Grove’s Concerns</h4>
<ul>
<li><strong>Offshoring Trend:</strong> The iPhone, introduced in 2007, exemplified the offshoring trend, with few components built in the U.S.</li>
<li><strong>Loss of Expertise:</strong> Grove worried that offshoring, which started with low-skilled jobs, would expand to encompass advanced manufacturing and engineering expertise.</li>
<li><strong>Electric Vehicle Battery Industry:</strong> He cited the lithium battery industry for electric vehicles as a prime example, where the U.S. lagged significantly despite inventing core technologies.</li>
</ul>
</section>
<section id="groves-proposed-solution" class="level4">
<h4 class="anchored" data-anchor-id="groves-proposed-solution">Grove’s Proposed Solution</h4>
<ul>
<li>Levy an additional tax on products manufactured using offshored labor.</li>
<li>Be prepared to engage in a “trade war” to protect American manufacturing and expertise.</li>
</ul>
</section>
</section>
<section id="dismissive-response-to-groves-concerns" class="level3">
<h3 class="anchored" data-anchor-id="dismissive-response-to-groves-concerns">Dismissive Response to Grove’s Concerns</h3>
<ul>
<li>Many dismissed Grove’s concerns as outdated, arguing:
<ul>
<li><strong>Bygone Era:</strong> Grove built Intel before the internet, and Intel missed the mobile phone revolution.</li>
<li><strong>Reliance on Legacy Business:</strong> Intel’s success relied on its x86 processor monopoly, not disruptive innovation.</li>
<li><strong>Shrinking Technological Lead:</strong> While Intel retained advanced semiconductor process technology, rivals like TSMC and Samsung were closing the gap.</li>
<li><strong>Rise of New Tech Giants:</strong> Companies like Apple and Facebook, with different business models, surpassed Intel in valuation.</li>
<li><strong>Semiconductor Industry Trends:</strong> The success of foreign semiconductor foundries like TSMC, primarily producing chips designed by American firms, was seen as a sign of a healthy ecosystem.</li>
<li><strong>Historical Precedent:</strong> Offshoring to Southeast Asia had been a core part of the semiconductor industry since Fairchild Semiconductor’s Hong Kong assembly plant.</li>
</ul></li>
</ul>
</section>
<section id="groves-counterarguments" class="level3">
<h3 class="anchored" data-anchor-id="groves-counterarguments">Grove’s Counterarguments</h3>
<ul>
<li><p><strong>Loss of Future Opportunities:</strong> Grove argued that abandoning current commodity manufacturing could hinder entry into emerging industries, using the electric battery industry as an example:</p>
<blockquote class="blockquote">
<p>“Abandoning today’s commodity manufacturing can lock you out of tomorrow’s emerging industry,” he declared, pointing to the electric battery industry. (Source: Chapter 34)</p>
</blockquote></li>
<li><p><strong>U.S. Decline in Battery Technology:</strong></p>
<blockquote class="blockquote">
<p>“The U.S. lost its lead in batteries 30 years ago when it stopped making consumer electronics devices,” Grove wrote. Then it missed PC batteries, and now was far behind on batteries for electric vehicles. “I doubt they will ever catch up,” he predicted in 2010. (Source: Chapter 34)</p>
</blockquote></li>
</ul>
</section>
<section id="strengths-of-the-u.s.-semiconductor-ecosystem" class="level3">
<h3 class="anchored" data-anchor-id="strengths-of-the-u.s.-semiconductor-ecosystem">Strengths of the U.S. Semiconductor Ecosystem</h3>
<ul>
<li><strong>Profitability of U.S. Chip Design Firms:</strong> Numerous American fabless chip design companies were highly profitable.</li>
<li><strong>Dominance in Semiconductor Manufacturing Equipment:</strong>
<ul>
<li><strong>Applied Materials:</strong> Remained the world’s largest semiconductor toolmaking company.</li>
<li><strong>LAM Research:</strong> Held world-leading expertise in etching circuits onto silicon wafers.</li>
<li><strong>KLA:</strong> Possessed the world’s most advanced tools for identifying nanoscale errors on wafers and lithography masks.</li>
</ul></li>
<li><strong>Critical Role of U.S. Equipment:</strong> Manufacturing advanced chips without American equipment was practically impossible.</li>
<li><strong>Monopoly in Chip Design Software:</strong>
<ul>
<li><strong>Cadence, Synopsys, Mentor:</strong> Three American firms controlled roughly 75% of the market for chip design software, making their products essential for chip development.</li>
<li><strong>U.S. Dominance:</strong> Most smaller chip design software providers were also U.S.-based.</li>
</ul></li>
</ul>
</section>
<section id="risks-of-offshore-manufacturing-the-taiwan-earthquake-example" class="level3">
<h3 class="anchored" data-anchor-id="risks-of-offshore-manufacturing-the-taiwan-earthquake-example">Risks of Offshore Manufacturing: The Taiwan Earthquake Example</h3>
<ul>
<li><strong>1999 Taiwan Earthquake:</strong> A 7.3 magnitude earthquake in Taiwan caused widespread power outages, impacting TSMC’s fabs and highlighting the risks of concentrated manufacturing.
<ul>
<li><strong>TSMC’s Response:</strong> Morris Chang, TSMC’s founder, secured prioritized access to electricity, restoring most fabs within a week.</li>
<li><strong>Limited Disruptions:</strong> Market disruptions were short-lived, with consumer electronics returning to normal within a month.</li>
</ul></li>
<li><strong>Seismic Vulnerability:</strong> While TSMC claimed earthquake resistance up to a magnitude of nine, the potential for stronger earthquakes remained a concern.</li>
</ul>
</section>
<section id="the-run-faster-strategy-and-its-flaws" class="level3">
<h3 class="anchored" data-anchor-id="the-run-faster-strategy-and-its-flaws">The “Run Faster” Strategy and Its Flaws</h3>
<section id="changing-relationship-between-silicon-valley-and-the-pentagon" class="level4">
<h4 class="anchored" data-anchor-id="changing-relationship-between-silicon-valley-and-the-pentagon">Changing Relationship Between Silicon Valley and the Pentagon</h4>
<ul>
<li><strong>Reduced Reliance on the Pentagon:</strong> Silicon Valley giants, facing less direct competition from Japanese firms, decreased their engagement with the Pentagon in the 1990s and 2000s.</li>
<li><strong>Shifting Priorities:</strong> The industry’s primary focus shifted to advocating for trade deals and deregulation, rather than government support.</li>
</ul>
</section>
<section id="the-rise-of-the-run-faster-consensus" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-the-run-faster-consensus">The Rise of the “Run Faster” Consensus</h4>
<ul>
<li><strong>Belief in Globalization’s Inevitability:</strong> Many officials in Washington believed that strict export controls were impractical and counterproductive in an increasingly globalized economy.</li>
<li><strong>China’s Integration:</strong> China’s deep integration into the global economy further complicated export control efforts.</li>
<li><strong>Focus on Engagement with China:</strong> U.S. policymakers prioritized building positive relations with China, viewing trade and investment as tools to encourage responsible behavior.</li>
<li><strong>The “Run Faster” Doctrine:</strong> The prevailing strategy became to outpace rivals in technological innovation rather than restrict trade.</li>
</ul>
</section>
<section id="evidence-challenging-the-run-faster-approach" class="level4">
<h4 class="anchored" data-anchor-id="evidence-challenging-the-run-faster-approach">Evidence Challenging the “Run Faster” Approach</h4>
<ul>
<li><strong>Van Atta’s Report (2007):</strong> A Defense Department study led by Richard Van Atta warned that offshoring threatened the military’s access to cutting-edge chips. This warning was largely ignored.</li>
<li><strong>Historical Counterexamples:</strong> Past experiences, such as the rise of the Japanese semiconductor industry in the 1980s, demonstrated that simply “running faster” did not guarantee U.S. leadership.</li>
<li><strong>Shrinking Leads:</strong> While the U.S. maintained advantages in chip design and manufacturing equipment, the gap was narrowing in key areas like advanced lithography and DRAM production.</li>
</ul>
</section>
<section id="conclusion-3" class="level4">
<h4 class="anchored" data-anchor-id="conclusion-3">Conclusion</h4>
<p>Despite the perceived success of the U.S. semiconductor industry, Andy Grove’s concerns about offshoring expertise and the potential for a decline in U.S. technological leadership were supported by emerging evidence. The popular “run faster” strategy, while appealing in theory, lacked sufficient analysis and ignored warning signs.</p>
<hr>
</section>
</section>
</section>
<section id="chapter-35-real-men-have-fabs" class="level2">
<h2 class="anchored" data-anchor-id="chapter-35-real-men-have-fabs">Chapter 35: Real Men Have Fabs</h2>
<section id="the-semiconductor-industry-in-the-2000s" class="level3">
<h3 class="anchored" data-anchor-id="the-semiconductor-industry-in-the-2000s">The Semiconductor Industry in the 2000s</h3>
<ul>
<li>The semiconductor industry can be split into three categories:
<ul>
<li><strong>Logic:</strong> Processors for smartphones, computers, and servers. Driven by Moore’s Law, requiring smaller transistors for better performance.</li>
<li><strong>Memory:</strong> DRAM (short-term memory) and Flash/NAND (long-term memory). Also driven by Moore’s Law and the need to shrink transistors.</li>
<li><strong>Other:</strong> Includes analog chips (sensors, RF chips, power management). Less dependent on Moore’s Law, with design being more important than shrinking transistors.
<ul>
<li>75% of these chips are produced using older, cheaper 180nm technology (from the late 1990s).</li>
<li>This category has major players in the US, Europe, and Japan, with most production also located in these regions.</li>
<li><strong>Texas Instruments</strong> is the largest analog chipmaker.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="the-memory-market-a-shift-to-east-asia" class="level3">
<h3 class="anchored" data-anchor-id="the-memory-market-a-shift-to-east-asia">The Memory Market: A Shift to East Asia</h3>
<ul>
<li><strong>DRAM:</strong>
<ul>
<li>Advanced fabs cost $20 billion.</li>
<li>The market consolidated from dozens of producers to three:
<ul>
<li><strong>Micron</strong> (US) - with fabs in Japan, Taiwan, Singapore, and the US.</li>
<li><strong>Samsung</strong> (South Korea)</li>
<li><strong>SK Hynix</strong> (South Korea)</li>
</ul></li>
<li>This consolidation and government subsidies led to most DRAM manufacturing shifting to East Asia.</li>
</ul></li>
<li><strong>NAND:</strong>
<ul>
<li>Similar to DRAM, the NAND market is also Asia-centric.</li>
<li>Major players include:
<ul>
<li><strong>Samsung</strong> (South Korea) - largest player with 35% market share.</li>
<li><strong>SK Hynix</strong> (South Korea)</li>
<li><strong>Kioxia</strong> (Japan)</li>
<li><strong>Micron</strong> (US) - some US production, but also fabs in Singapore and Japan.</li>
<li><strong>Western Digital</strong> (US) - some US production, but also fabs in Singapore and Japan.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="the-logic-chip-landscape-rise-of-the-foundries" class="level3">
<h3 class="anchored" data-anchor-id="the-logic-chip-landscape-rise-of-the-foundries">The Logic Chip Landscape: Rise of the Foundries</h3>
<ul>
<li>Advanced logic fabs also cost around $20 billion, leading to fewer companies able to afford them.</li>
<li><strong>Intel</strong> remained a major player with its own fabs.</li>
<li>Many other US logic chipmakers, like <strong>Motorola</strong> and <strong>National Semiconductor</strong>, went bankrupt, were acquired, or saw their market share shrink.</li>
<li>This led to the rise of <strong>fabless firms</strong>, which designed chips in-house but outsourced manufacturing, primarily to <strong>TSMC</strong>.
<ul>
<li>This model lowered startup costs and allowed companies to focus on design.</li>
</ul></li>
<li><strong>Jerry Sanders</strong>, founder of <strong>AMD</strong>, championed the “real men have fabs” philosophy, believing that in-house manufacturing was crucial for success.
<ul>
<li>However, the industry was shifting towards a fabless model as foundries became more efficient and cost-effective.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-36-a-fabulous-revolution" class="level2">
<h2 class="anchored" data-anchor-id="chapter-36-a-fabulous-revolution">Chapter 36: A Fabulous Revolution</h2>
<section id="the-rise-of-fabless-chip-companies" class="level3">
<h3 class="anchored" data-anchor-id="the-rise-of-fabless-chip-companies">The Rise of Fabless Chip Companies</h3>
<ul>
<li>Since the late 1980s, there has been significant growth in <strong>fabless chip firms</strong>.</li>
<li><strong>Chips and Technologies</strong> (founded 1984), is considered the first fabless firm.
<ul>
<li>Though initially doubted, their success with graphics chips for PCs proved the viability of the fabless model.</li>
</ul></li>
<li>Advantages of the fabless model:
<ul>
<li>Lower startup costs, requiring only a good idea and a few million dollars (compared to the billions needed for a fab).</li>
<li>Allowed companies to focus on their strengths in chip design.</li>
</ul></li>
</ul>
</section>
<section id="nvidia-a-fabless-success-story" class="level3">
<h3 class="anchored" data-anchor-id="nvidia-a-fabless-success-story">NVIDIA: A Fabless Success Story</h3>
<ul>
<li><strong>NVIDIA</strong>, founded in 1993, became the dominant player in graphics chips (GPUs).</li>
<li>Early on, they focused on 3D graphics, betting on its future importance.</li>
<li><strong>Key Innovations:</strong>
<ul>
<li>Developed <strong>GPUs</strong> (Graphics Processing Units) specifically for handling complex 3D graphics.</li>
<li>Created a software ecosystem around their GPUs, including <strong>shaders</strong> for realistic image rendering.</li>
<li>Introduced <strong>CUDA</strong> in 2006, a software platform that allowed GPUs to be programmed for general-purpose parallel processing, expanding their use beyond graphics.</li>
</ul></li>
<li>NVIDIA’s success is attributed to:
<ul>
<li>Focusing on their strength in chip design.</li>
<li>Outsourcing manufacturing to TSMC, allowing them to avoid massive fab investment costs and focus resources on R&amp;D and software development.</li>
<li>Recognizing the potential of parallel processing beyond graphics, leading them to become a major player in AI.</li>
</ul></li>
</ul>
</section>
<section id="qualcomm-another-fabless-powerhouse" class="level3">
<h3 class="anchored" data-anchor-id="qualcomm-another-fabless-powerhouse">Qualcomm: Another Fabless Powerhouse</h3>
<ul>
<li>Founded in 1985 by <strong>Erwin Jacobs</strong>, <strong>Qualcomm</strong> became a leader in mobile chip technology.</li>
<li><strong>Key Contributions:</strong>
<ul>
<li>Pioneered <strong>frequency hopping</strong> technology for 2G cell phones, enabling more calls within limited spectrum space.</li>
<li>Developed key technologies for subsequent generations of cellular technology (3G, 4G, etc.), increasing data transmission capabilities.</li>
<li>Designed both <strong>modem chips</strong> (for connecting to cell networks) and <strong>application processors</strong> for smartphones.</li>
</ul></li>
<li>Qualcomm’s success is also attributed to:
<ul>
<li>Focusing on their strengths in wireless communication technology and chip design.</li>
<li>Outsourcing manufacturing to companies like TSMC and Samsung, allowing them to avoid building their own expensive fabs.</li>
<li>Securing fundamental patents in mobile technology, generating significant revenue through licensing.</li>
</ul></li>
</ul>
</section>
<section id="other-notable-fabless-companies-and-their-innovations" class="level3">
<h3 class="anchored" data-anchor-id="other-notable-fabless-companies-and-their-innovations">Other Notable Fabless Companies and their Innovations</h3>
<ul>
<li><strong>Xilinx</strong> and <strong>Altera:</strong> Pioneered <strong>field-programmable gate arrays (FPGAs)</strong>, chips that can be programmed for different uses.</li>
</ul>
</section>
<section id="the-impact-of-the-fabless-model" class="level3">
<h3 class="anchored" data-anchor-id="the-impact-of-the-fabless-model">The Impact of the Fabless Model</h3>
<ul>
<li>Enabled the emergence of new chip categories and applications.</li>
<li>Drove innovation in specialized logic chips, like GPUs for graphics and AI.</li>
<li>Made mobile devices, advanced graphics, and parallel processing possible.</li>
</ul>
</section>
</section>
<section id="chapter-37-morris-changs-grand-alliance" class="level2">
<h2 class="anchored" data-anchor-id="chapter-37-morris-changs-grand-alliance">Chapter 37: Morris Chang’s Grand Alliance</h2>
<section id="the-changing-landscape-of-the-chip-industry" class="level3">
<h3 class="anchored" data-anchor-id="the-changing-landscape-of-the-chip-industry">The Changing Landscape of the Chip Industry</h3>
<ul>
<li>By the 2000s, a new generation of CEOs led the semiconductor industry, focusing on financial metrics and shareholder value.</li>
<li><strong>Morris Chang</strong>, founder of <strong>TSMC</strong>, remained a prominent figure, recognizing the transformative potential of smartphones.</li>
</ul>
</section>
<section id="tsmcs-grand-alliance" class="level3">
<h3 class="anchored" data-anchor-id="tsmcs-grand-alliance">TSMC’s Grand Alliance</h3>
<ul>
<li>Chang’s strategy was to create a <strong>Grand Alliance</strong>, a partnership between TSMC and various players in the semiconductor ecosystem:
<ul>
<li><strong>Chip designers:</strong> Companies like Apple, Qualcomm, and AMD.</li>
<li><strong>Intellectual property providers:</strong> Companies owning patents and designs essential for chip development.</li>
<li><strong>Materials companies:</strong> Suppliers of silicon wafers, gases, and chemicals used in fabrication.</li>
<li><strong>Equipment manufacturers:</strong> Producers of the sophisticated machinery used in chip fabs.</li>
</ul></li>
<li>Benefits of the Grand Alliance for TSMC:
<ul>
<li>Access to the combined R&amp;D capabilities of its partners, exceeding the spending of Samsung and Intel combined.</li>
<li>Setting industry standards for chip manufacturing, as compatibility with TSMC’s processes became essential for most chip designers.</li>
<li>Securing a central position in the semiconductor industry, with TSMC as the primary manufacturer for many leading chip design companies.</li>
</ul></li>
</ul>
</section>
<section id="tsmcs-investment-strategy-during-the-financial-crisis" class="level3">
<h3 class="anchored" data-anchor-id="tsmcs-investment-strategy-during-the-financial-crisis">TSMC’s Investment Strategy During the Financial Crisis</h3>
<ul>
<li>During the 2008-2009 financial crisis, TSMC’s CEO <strong>Rick Tsai</strong> focused on cost-cutting, similar to many companies.</li>
<li>Chang, however, saw the crisis as an opportunity to invest and gain market share.</li>
<li>He dismissed Tsai and resumed direct control of TSMC.</li>
<li>Chang invested heavily in:
<ul>
<li>Expanding production capacity to meet the anticipated demand for smartphone chips.</li>
<li>Rehiring laid-off workers.</li>
<li>Doubling down on R&amp;D to maintain technological leadership.</li>
</ul></li>
<li>This strategy paid off, as TSMC emerged from the crisis stronger and better positioned to capitalize on the booming smartphone market.</li>
</ul>
</section>
<section id="the-decline-of-globalfoundries" class="level3">
<h3 class="anchored" data-anchor-id="the-decline-of-globalfoundries">The Decline of GlobalFoundries</h3>
<ul>
<li><strong>GlobalFoundries</strong>, formed from AMD’s former manufacturing division, initially showed promise as a competitor to TSMC.</li>
<li>The company:
<ul>
<li>Inherited a large fab in Germany.</li>
<li>Began building a new advanced facility in New York.</li>
<li>Partnered with IBM and Samsung for technology development.</li>
<li>Benefited from the demand for a credible alternative to TSMC.</li>
</ul></li>
<li>However, GlobalFoundries faced challenges:
<ul>
<li>Intense competition from TSMC, particularly in winning Apple’s business for iPhone chips.</li>
<li>The 2008-2009 financial crisis, which led to a slump in semiconductor demand.</li>
<li>Technical difficulties with its 28nm manufacturing process.</li>
</ul></li>
<li>In 2014, GlobalFoundries acquired IBM’s microelectronics business, further expanding its size but not necessarily its technological edge.</li>
<li>Despite these moves, GlobalFoundries remained significantly smaller than TSMC:
<ul>
<li>In 2015, TSMC had 50% of the global foundry market, while GlobalFoundries and UMC each had around 10%.</li>
<li>TSMC’s wafer production capacity was 1.8 million per month, compared to GlobalFoundries’ 700,000.</li>
</ul></li>
</ul>
</section>
<section id="the-adoption-of-euv-lithography" class="level3">
<h3 class="anchored" data-anchor-id="the-adoption-of-euv-lithography">The Adoption of EUV Lithography</h3>
<ul>
<li>The industry shift to <strong>EUV (Extreme Ultraviolet) lithography</strong> was crucial for continuing Moore’s Law and enabling the production of smaller, more powerful chips.</li>
<li><strong>TSMC, Intel</strong>, and <strong>Samsung</strong> committed to adopting EUV, albeit with different strategies.</li>
<li><strong>GlobalFoundries</strong> initially planned to adopt EUV but ultimately decided against it:
<ul>
<li>The company was already struggling with its 28nm process and had licensed its 14nm technology from Samsung.</li>
<li>The enormous cost of developing and implementing EUV was deemed too risky for GlobalFoundries’ financial position.</li>
</ul></li>
<li>In 2018, GlobalFoundries halted its EUV program, deciding to focus on less advanced manufacturing nodes and prioritize profitability over cutting-edge technology.</li>
</ul>
</section>
<section id="the-consequences-of-globalfoundries-decision" class="level3">
<h3 class="anchored" data-anchor-id="the-consequences-of-globalfoundries-decision">The Consequences of GlobalFoundries’ Decision</h3>
<ul>
<li>The number of companies capable of manufacturing the most advanced logic chips decreased from four to three (TSMC, Intel, Samsung).</li>
<li>GlobalFoundries effectively removed itself from the competition to produce the most advanced chips, solidifying TSMC’s dominance.</li>
</ul>
</section>
</section>
<section id="chapter-38-apple-silicon" class="level2">
<h2 class="anchored" data-anchor-id="chapter-38-apple-silicon">Chapter 38: Apple Silicon</h2>
<section id="apples-approach-to-hardware-and-software" class="level3">
<h3 class="anchored" data-anchor-id="apples-approach-to-hardware-and-software">Apple’s Approach to Hardware and Software</h3>
<ul>
<li>From the beginning, <strong>Apple</strong> and <strong>Steve Jobs</strong> believed in the tight integration of hardware and software.</li>
<li>Jobs believed that software was for things changing too rapidly, not yet fully understood, or lacking time for hardware implementation.</li>
</ul>
</section>
<section id="apples-transition-to-in-house-chip-design" class="level3">
<h3 class="anchored" data-anchor-id="apples-transition-to-in-house-chip-design">Apple’s Transition to In-House Chip Design</h3>
<ul>
<li>The first iPhone (2007) used Apple’s iOS operating system but relied on chips from various suppliers, including Samsung.</li>
<li>Over time, Apple invested heavily in chip design:
<ul>
<li>Acquired <strong>PA Semi</strong>, a small chip design firm specializing in energy-efficient processing (2008).</li>
<li>Hired top chip designers from across the industry.</li>
</ul></li>
<li>In 2010, Apple released its first in-house designed application processor, the <strong>A4</strong>, used in the iPad and iPhone 4.</li>
<li>Today, Apple designs its own application processors for most devices, as well as specialized chips for accessories like AirPods.</li>
</ul>
</section>
<section id="apples-dependence-on-tsmc-for-chip-fabrication" class="level3">
<h3 class="anchored" data-anchor-id="apples-dependence-on-tsmc-for-chip-fabrication">Apple’s Dependence on TSMC for Chip Fabrication</h3>
<ul>
<li>Despite designing its chips, Apple remains entirely reliant on <strong>TSMC</strong> for manufacturing.</li>
<li>The complexity and cost of advanced chip fabrication have led to a highly specialized industry, with TSMC possessing the necessary expertise and capacity.</li>
<li>Even though iPhones are “Designed by Apple in California, Assembled in China,” the most critical components, the processors, are fabricated solely in Taiwan by TSMC.</li>
</ul>
</section>
<section id="the-importance-of-tsmc-in-the-smartphone-supply-chain" class="level3">
<h3 class="anchored" data-anchor-id="the-importance-of-tsmc-in-the-smartphone-supply-chain">The Importance of TSMC in the Smartphone Supply Chain</h3>
<ul>
<li>Unlike the PC market, where Intel has long dominated processor manufacturing, the smartphone supply chain is heavily reliant on TSMC and, to a lesser extent, Samsung.</li>
<li>This reliance on foundries located in East Asia has significant geopolitical implications, given the proximity to China and its growing technological ambitions.</li>
</ul>
</section>
</section>
<section id="chapter-39-euv" class="level2">
<h2 class="anchored" data-anchor-id="chapter-39-euv">Chapter 39: EUV</h2>
<section id="the-long-road-to-euv-lithography" class="level3">
<h3 class="anchored" data-anchor-id="the-long-road-to-euv-lithography">The Long Road to EUV Lithography</h3>
<ul>
<li><strong>ASML</strong>, a Dutch company, spent nearly two decades developing extreme ultraviolet (EUV) lithography.</li>
<li>EUV was a high-stakes gamble, requiring significant investment and technological breakthroughs.</li>
<li><strong>Intel, Samsung, and TSMC</strong> invested billions in ASML to support EUV development, recognizing its importance for future chip manufacturing.</li>
</ul>
</section>
<section id="the-complexity-of-euv-lithography" class="level3">
<h3 class="anchored" data-anchor-id="the-complexity-of-euv-lithography">The Complexity of EUV Lithography</h3>
<ul>
<li>EUV lithography utilizes light with a wavelength of 13.5 nanometers, much shorter than previous lithography technologies, to etch smaller features onto silicon wafers.</li>
<li>This process requires highly specialized components and intricate engineering:
<ul>
<li><strong>EUV light source:</strong>
<ul>
<li>Developed by <strong>CYMER</strong>, acquired by ASML.</li>
<li>Involves blasting tiny tin droplets with a powerful laser 50,000 times per second to generate EUV light.</li>
<li>Requires lasers with unprecedented power and precision, developed by the German company <strong>TRUMPF</strong>.</li>
</ul></li>
<li><strong>EUV mirrors:</strong>
<ul>
<li>Developed by the German company <strong>ZEISS</strong>.</li>
<li>Made of alternating layers of molybdenum and silicon, each a few nanometers thick.</li>
<li>Designed to reflect EUV light, which is easily absorbed by most materials.</li>
<li>Requires extreme precision and smoothness; irregularities are measured in fractions of a nanometer.</li>
</ul></li>
<li><strong>EUV system integration and software:</strong>
<ul>
<li>ASML manages a complex global supply chain to source and integrate components for its EUV tools.</li>
<li>Employs predictive maintenance algorithms and computational lithography techniques to ensure reliability and precision.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="asmls-key-role-and-global-collaboration" class="level3">
<h3 class="anchored" data-anchor-id="asmls-key-role-and-global-collaboration">ASML’s Key Role and Global Collaboration</h3>
<ul>
<li>ASML doesn’t manufacture all components of its EUV tools in-house; it relies on a network of specialized suppliers, highlighting the global nature of the semiconductor industry.</li>
<li>ASML’s expertise lies in:
<ul>
<li><strong>System integration:</strong> Assembling and fine-tuning components from various suppliers into a functional and reliable EUV tool.</li>
<li><strong>Supply chain management:</strong> Maintaining strict quality control and ensuring the timely delivery of highly specialized components.</li>
<li><strong>Software development:</strong> Creating software that manages the complex operation of EUV tools, including predictive maintenance and computational lithography.</li>
</ul></li>
</ul>
</section>
<section id="the-significance-of-euvs-success" class="level3">
<h3 class="anchored" data-anchor-id="the-significance-of-euvs-success">The Significance of EUV’s Success</h3>
<ul>
<li>EUV’s successful development and deployment were crucial for extending Moore’s Law and enabling the continued miniaturization of transistors.</li>
<li>ASML’s EUV lithography tools became essential for manufacturing the most advanced chips, giving the company a near-monopoly in this critical technology.</li>
</ul>
</section>
</section>
<section id="chapter-40-there-is-no-plan-b" class="level2">
<h2 class="anchored" data-anchor-id="chapter-40-there-is-no-plan-b">Chapter 40: There is no Plan B</h2>
<section id="the-limits-of-existing-lithography-technologies" class="level3">
<h3 class="anchored" data-anchor-id="the-limits-of-existing-lithography-technologies">The Limits of Existing Lithography Technologies</h3>
<ul>
<li>By the mid-2010s, existing lithography technologies using deep ultraviolet (DUV) light were reaching their limits.</li>
<li><strong>Tony Yen</strong>, a lithography expert at TSMC, emphasized that without EUV, there was “no plan B” for continuing to shrink transistors and advancing chip performance.</li>
</ul>
</section>
<section id="tsmcs-commitment-to-euv" class="level3">
<h3 class="anchored" data-anchor-id="tsmcs-commitment-to-euv">TSMC’s Commitment to EUV</h3>
<ul>
<li><strong>Morris Chang</strong> and <strong>Xiangyi Qiang</strong>, head of R&amp;D at TSMC, strongly believed in EUV’s potential and invested heavily in its development and implementation.</li>
<li>TSMC worked closely with ASML to test and improve EUV tools, recognizing the technology’s critical role in their future success.</li>
</ul>
</section>
<section id="globalfoundries-decision-to-abandon-euv" class="level3">
<h3 class="anchored" data-anchor-id="globalfoundries-decision-to-abandon-euv">GlobalFoundries’ Decision to Abandon EUV</h3>
<ul>
<li>Facing financial constraints and technical difficulties, <strong>GlobalFoundries</strong> decided to abandon EUV lithography in 2018.</li>
<li>The company:
<ul>
<li>Had already spent $1.5 billion on EUV development.</li>
<li>Estimated that bringing EUV-based manufacturing online would require billions more in investment.</li>
<li>Decided that the cost of developing and implementing EUV was too high, given their financial position and the competitive landscape.</li>
</ul></li>
<li>This decision marked a turning point, as GlobalFoundries effectively conceded defeat in the race to produce the most advanced chips.</li>
</ul>
</section>
<section id="the-consequences-of-globalfoundries-withdrawal" class="level3">
<h3 class="anchored" data-anchor-id="the-consequences-of-globalfoundries-withdrawal">The Consequences of GlobalFoundries’ Withdrawal</h3>
<ul>
<li>The number of companies capable of manufacturing cutting-edge logic chips further decreased, leaving only three: <strong>TSMC, Intel, and Samsung</strong>.</li>
<li>This consolidation of manufacturing capacity in East Asia raised concerns about the global supply chain’s vulnerability and the geopolitical implications of relying on companies based near China.</li>
</ul>
</section>
</section>
<section id="chapter-41-how-intel-forgot-innovation" class="level2">
<h2 class="anchored" data-anchor-id="chapter-41-how-intel-forgot-innovation">Chapter 41: How Intel Forgot Innovation</h2>
<section id="intels-dominant-position-in-the-2010s" class="level3">
<h3 class="anchored" data-anchor-id="intels-dominant-position-in-the-2010s">Intel’s Dominant Position in the 2010s</h3>
<ul>
<li><strong>Intel</strong> entered the 2010s as a dominant force in the semiconductor industry:
<ul>
<li>Held a near-monopoly in processors for PCs and data centers.</li>
<li>Possessed advanced manufacturing capabilities and a long history of innovation.</li>
<li>Invested heavily in R&amp;D, spending billions annually.</li>
</ul></li>
</ul>
</section>
<section id="intels-missed-opportunities-in-artificial-intelligence" class="level3">
<h3 class="anchored" data-anchor-id="intels-missed-opportunities-in-artificial-intelligence">Intel’s Missed Opportunities in Artificial Intelligence</h3>
<ul>
<li>Despite its strengths, Intel failed to capitalize on the rise of artificial intelligence (AI):
<ul>
<li>Its <strong>CPUs (Central Processing Units)</strong>, while versatile, were not optimized for the parallel processing demands of AI workloads.</li>
<li><strong>NVIDIA</strong>, originally a graphics chip company, recognized the potential of its <strong>GPUs (Graphics Processing Units)</strong> for AI and quickly gained market share.</li>
<li>Cloud computing giants like <strong>Google, Amazon, and Microsoft</strong> also began designing their own AI-optimized chips, further challenging Intel’s dominance.</li>
</ul></li>
</ul>
</section>
<section id="intels-failed-foray-into-the-foundry-business" class="level3">
<h3 class="anchored" data-anchor-id="intels-failed-foray-into-the-foundry-business">Intel’s Failed Foray into the Foundry Business</h3>
<ul>
<li>In the mid-2010s, Intel attempted to compete with TSMC in the foundry business by opening its manufacturing facilities to outside customers.</li>
<li>This effort failed due to:
<ul>
<li><strong>Cultural differences:</strong> Intel’s secretive and less customer-centric approach contrasted with TSMC’s open and collaborative model.</li>
<li><strong>Lack of internal support:</strong> Intel prioritized its own chip design and manufacturing over its foundry business.</li>
<li><strong>Competition from TSMC:</strong> TSMC’s established expertise, scale, and customer relationships proved difficult to overcome.</li>
</ul></li>
</ul>
</section>
<section id="intels-manufacturing-stumbles-and-the-delay-of-moores-law" class="level3">
<h3 class="anchored" data-anchor-id="intels-manufacturing-stumbles-and-the-delay-of-moores-law">Intel’s Manufacturing Stumbles and the Delay of Moore’s Law</h3>
<ul>
<li>Compounding its other challenges, Intel experienced significant delays in its manufacturing roadmap:
<ul>
<li>Repeatedly announced delays in its 10nm and 7nm manufacturing processes, falling behind TSMC and Samsung.</li>
<li>Faced criticism for its lack of transparency regarding the reasons for these delays.</li>
</ul></li>
<li>These delays were partly attributed to Intel’s slow adoption of <strong>EUV lithography</strong>, a technology the company itself had heavily invested in during its development.</li>
</ul>
</section>
<section id="the-consequences-of-intels-decline" class="level3">
<h3 class="anchored" data-anchor-id="the-consequences-of-intels-decline">The Consequences of Intel’s Decline</h3>
<ul>
<li>Intel’s struggles created an opportunity for TSMC and Samsung to further solidify their lead in advanced chip manufacturing.</li>
<li>The United States faced the prospect of losing its last remaining manufacturer of cutting-edge processors, with significant implications for its technological competitiveness and national security.</li>
</ul>
</section>
<section id="the-current-state-of-the-semiconductor-industry" class="level3">
<h3 class="anchored" data-anchor-id="the-current-state-of-the-semiconductor-industry">The Current State of the Semiconductor Industry</h3>
<ul>
<li>By the end of the 2010s, the semiconductor industry had undergone a dramatic transformation:
<ul>
<li>The rise of fabless chip design companies and the dominance of foundries like TSMC reshaped the industry landscape.</li>
<li>The successful development and implementation of EUV lithography proved crucial for continuing Moore’s Law.</li>
<li>Intel, once a dominant force, faced an uncertain future after missing key technological shifts and struggling with manufacturing delays.</li>
</ul></li>
<li>The increasing concentration of advanced chip manufacturing capacity in Taiwan and South Korea raised geopolitical concerns, particularly regarding the reliance on companies located near China.</li>
</ul>
<hr>
</section>
</section>
<section id="chapter-42-made-in-china" class="level2">
<h2 class="anchored" data-anchor-id="chapter-42-made-in-china">Chapter 42: Made in China</h2>
<section id="chinas-digital-paradox-control-vs.-vulnerability" class="level3">
<h3 class="anchored" data-anchor-id="chinas-digital-paradox-control-vs.-vulnerability">China’s Digital Paradox: Control vs.&nbsp;Vulnerability</h3>
<section id="xi-jinpings-vision-of-digital-dominance" class="level4">
<h4 class="anchored" data-anchor-id="xi-jinpings-vision-of-digital-dominance">Xi Jinping’s Vision of Digital Dominance</h4>
<ul>
<li><p><strong>Xi Jinping</strong>, General Secretary of the Chinese Communist Party, declared in 2014: <strong>“Without cyber security, there is no national security. And without informatization, there is no modernization.”</strong></p></li>
<li><p>Xi’s Background and Political Acumen</p>
<ul>
<li>Son of an early Communist Party leader</li>
<li>Studied engineering in college</li>
<li>Rose through political ranks by adapting to different audiences:
<ul>
<li>To nationalists, he promised <strong>“national rejuvenation”</strong> and <strong>“great power status”</strong> through the <strong>“Chinese dream.”</strong></li>
<li>To businesses, he pledged economic reform.</li>
<li>Some foreigners perceived him as a potential advocate for political reform.</li>
</ul></li>
<li>Known for his political skill, concealing his true intentions behind a carefully crafted persona.</li>
</ul></li>
<li><p>Xi’s Perception of the Digital World</p>
<ul>
<li>Believed the digital world posed a primary risk to China.</li>
<li>Aimed to harness the internet for China’s power projection, contradicting Western beliefs in its democratizing potential.</li>
<li>Advocated for a global network under Chinese influence, embodied in his <strong>“one belt, one road”</strong> initiative, which included not only physical infrastructure but also network equipment and censorship tools.</li>
</ul></li>
</ul>
</section>
<section id="chinas-success-in-controlling-the-internet" class="level4">
<h4 class="anchored" data-anchor-id="chinas-success-in-controlling-the-internet">China’s Success in Controlling the Internet</h4>
<ul>
<li>Implemented the world’s most effective system of internet control, using thousands of sensors to monitor online activity.</li>
<li>Erected the <strong>“Great Firewall,”</strong> blocking access to major international websites like Google and Facebook.</li>
<li>This control disproved Western predictions of the internet’s liberalizing influence in China.</li>
<li>Xi mocked the Western belief in the internet’s power to spread democratic values.</li>
<li>He stated, <strong>“The internet has turned the world into a global village,”</strong> while simultaneously restricting access to many global platforms within China.</li>
</ul>
</section>
<section id="taming-tech-giants-and-promoting-domestic-champions" class="level4">
<h4 class="anchored" data-anchor-id="taming-tech-giants-and-promoting-domestic-champions">Taming Tech Giants and Promoting Domestic Champions</h4>
<ul>
<li>China effectively tamed American tech giants:
<ul>
<li>Banned Google and Facebook</li>
<li>Fostered domestic alternatives like <strong>Baidu</strong> and <strong>Tencent</strong>, which rivaled their American counterparts technologically.</li>
</ul></li>
<li>Granted access to the Chinese market to U.S. tech firms like <strong>Apple</strong> and <strong>Microsoft</strong> only after securing their cooperation with Beijing’s censorship demands.</li>
<li>Successfully made the internet subservient to the Communist Party’s agenda, compelling foreign internet and software companies to comply with censorship rules or face exclusion from the vast Chinese market.</li>
</ul>
</section>
</section>
<section id="chinas-achilles-heel-dependence-on-foreign-chip-technology" class="level3">
<h3 class="anchored" data-anchor-id="chinas-achilles-heel-dependence-on-foreign-chip-technology">China’s Achilles’ Heel: Dependence on Foreign Chip Technology</h3>
<section id="the-semiconductor-dilemma-chinas-hidden-vulnerability" class="level4">
<h4 class="anchored" data-anchor-id="the-semiconductor-dilemma-chinas-hidden-vulnerability">The Semiconductor Dilemma: China’s Hidden Vulnerability</h4>
<ul>
<li>Despite its successes, China’s control over its digital sphere masked a critical vulnerability: its dependence on imported semiconductors.
<ul>
<li>Chinese tech giants relied on data centers filled with foreign-made chips, mostly from the U.S.</li>
</ul></li>
<li>Edward Snowden’s 2013 leaks revealed the extent of American network-tapping capabilities, surprising even Chinese cyber experts.</li>
<li>While China excelled at software for e-commerce, online search, and digital payments, it lagged in producing the underlying hardware.</li>
</ul>
</section>
<section id="xi-jinpings-assessment-of-the-semiconductor-risk" class="level4">
<h4 class="anchored" data-anchor-id="xi-jinpings-assessment-of-the-semiconductor-risk">Xi Jinping’s Assessment of the Semiconductor Risk</h4>
<ul>
<li><p>Xi acknowledged this dependence as a strategic weakness: <strong>“However great its size, however high its market capitalization, if an internet enterprise critically relies on the outside world for core components, the vital gate of the supply chain is grasped in the hands of others.”</strong> (2016)</p></li>
<li><p>Core Technologies of Concern:</p>
<ul>
<li><strong>Microsoft Windows:</strong> The dominant operating system in China, despite attempts to create domestic alternatives.</li>
<li><strong>Semiconductors:</strong> The chips powering computers, smartphones, and data centers, seen as even more critical than software.</li>
</ul></li>
<li><p>The Intel-Microsoft Dependency</p>
<ul>
<li>Xi pointed out that Microsoft Windows relied on Intel chips, creating a dependence on American technology for most Chinese computers.</li>
</ul></li>
<li><p><strong>Economic Impact:</strong> China’s spending on semiconductor imports often exceeded that of oil, highlighting their importance in fueling economic growth.</p></li>
<li><p><strong>Geopolitical Risk:</strong> Unlike oil, the semiconductor supply chain was dominated by China’s geopolitical rivals.</p></li>
</ul>
</section>
<section id="chinas-semiconductor-aspiration-achieving-technological-independence" class="level4">
<h4 class="anchored" data-anchor-id="chinas-semiconductor-aspiration-achieving-technological-independence">China’s Semiconductor Aspiration: Achieving Technological Independence</h4>
<ul>
<li><strong>The Challenge of Perception:</strong> Many struggled to understand China’s anxieties, given its seemingly powerful tech sector.</li>
<li><strong>Headline Hype vs.&nbsp;Reality:</strong> Media often portrayed China as a leading tech power, particularly in artificial intelligence.</li>
<li><strong>“AI Superpower” Status:</strong> A book by Kai-Fu Lee, former head of Google China, labeled China as one of the world’s two AI superpowers due to its use of AI for surveillance.</li>
<li><strong>Hidden Dependence:</strong> Even China’s advanced surveillance systems, used to monitor dissidents and minorities, relied on chips from American companies like <strong>Intel</strong> and <strong>NVIDIA.</strong></li>
<li><strong>The Fragile Foundation:</strong> All of China’s crucial technology rested on a foundation of imported silicon, a vulnerability acknowledged by Chinese leaders.</li>
</ul>
</section>
<section id="the-imperative-for-domestic-chip-production" class="level4">
<h4 class="anchored" data-anchor-id="the-imperative-for-domestic-chip-production">The Imperative for Domestic Chip Production</h4>
<ul>
<li><strong>Beyond Supply Chain Security:</strong> Domestic chip production was not just about mitigating supply chain risks; it was also about capturing a larger share of the profits in the global technology market.</li>
<li><strong>“Core Technologies”:</strong> China aspired to produce what its leaders termed “core technologies,” products essential to the global economy, enabling it to move beyond low-profit manufacturing.</li>
<li><strong>The iPhone Example:</strong> China’s role in the iPhone production chain illustrated this challenge; millions of Chinese workers assembled the phones, but most profits went to Apple and chipmakers, not Chinese companies.</li>
</ul>
</section>
<section id="learning-from-other-asian-tech-powers" class="level4">
<h4 class="anchored" data-anchor-id="learning-from-other-asian-tech-powers">Learning from Other Asian Tech Powers</h4>
<ul>
<li>China sought to emulate the strategies of Japan, Taiwan, and South Korea, which had successfully entered the high-value segment of the chip industry. Their strategies included:</li>
</ul>
<ol type="1">
<li><strong>Government Investment and Bank Lending:</strong> Pouring capital into domestic semiconductor companies with government backing and pressure on private banks to provide loans.</li>
<li><strong>Talent Acquisition:</strong> Attracting scientists and engineers trained in U.S. universities and Silicon Valley back to their home countries.</li>
<li><strong>Strategic Partnerships:</strong> Forming partnerships with foreign firms, but with stipulations requiring technology transfer or training for local workers.</li>
<li><strong>Exploiting Competition:</strong> Leveraging competition between Silicon Valley companies, and later between American and Japanese firms, to secure the most favorable deals.</li>
</ol>
<ul>
<li><strong>Taiwan’s Success Story:</strong> KT Lee, a powerful Taiwanese minister, played a key role in establishing <strong>TSMC</strong> (Taiwan Semiconductor Manufacturing Company), a global leader in semiconductor fabrication. His statement to Morris Chang, TSMC’s founder, <strong>“We want to promote a semiconductor industry in Taiwan,”</strong> resonated with Xi Jinping’s ambitions for China.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-43-call-forth-the-assault" class="level2">
<h2 class="anchored" data-anchor-id="chapter-43-call-forth-the-assault">Chapter 43: Call Forth the Assault</h2>
<section id="xis-vision-and-the-davos-speech-january-2017" class="level3">
<h3 class="anchored" data-anchor-id="xis-vision-and-the-davos-speech-january-2017">Xi’s Vision and the Davos Speech (January 2017)</h3>
<ul>
<li>Three days before Trump’s inauguration, Xi Jinping outlined China’s economic vision at the World Economic Forum in Davos.
<ul>
<li>Xi’s message: Win-win outcomes through an innovation-driven growth model.</li>
<li>Xi’s warning: <strong>“No one will emerge as a winner in a trade war,”</strong> a comment interpreted as a dig at Trump.</li>
</ul></li>
<li>Three days later, Trump’s combative inaugural address contrasted with Xi’s message.
<ul>
<li>Trump’s stance: Protectionism for prosperity and strength.</li>
<li>Media portrayal:
<ul>
<li>Xi as a defender of globalization.</li>
<li>Xi’s Davos speech praised as a “robust defense of globalization” (Ian Bremmer, via Twitter).</li>
<li>Headlines highlighted Xi’s pro-globalization stance (Financial Times, Washington Post).</li>
<li>Klaus Schwab (World Economic Forum Chair): The “international community” is looking to China for leadership.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="xis-contrasting-message-to-chinese-leaders" class="level3">
<h3 class="anchored" data-anchor-id="xis-contrasting-message-to-chinese-leaders">Xi’s Contrasting Message to Chinese Leaders</h3>
<ul>
<li>Months before Davos, Xi addressed a different audience in Beijing: Chinese tech leaders, PLA researchers, and the Party elite.</li>
<li>Xi’s message:
<ul>
<li><strong>Focus on “breakthroughs in core technology,”</strong> specifically semiconductors.</li>
<li><strong>“Promote strong alliances and attack strategic passes in a coordinated manner.”</strong></li>
<li><strong>“Assault the fortifications of core technology research and development.”</strong></li>
<li><strong>“Not only call forth the assault, we must also sound the call for assembly”</strong> to “concentrate the most powerful forces.”</li>
<li><strong>Form “shock brigades and special forces to storm the passes.”</strong></li>
</ul></li>
<li>Analysis:
<ul>
<li>Xi’s language reveals a more aggressive approach than his Davos speech suggested.</li>
<li>Xi’s use of military metaphors signals a determined campaign for technological dominance.</li>
</ul></li>
</ul>
</section>
<section id="chinas-technological-vulnerability" class="level3">
<h3 class="anchored" data-anchor-id="chinas-technological-vulnerability">China’s Technological Vulnerability</h3>
<ul>
<li><strong>Growing dependence on foreign semiconductors:</strong> China’s semiconductor imports increased annually.</li>
<li><strong>Shifting industry landscape:</strong>
<ul>
<li><strong>“The scale of investment has risen rapidly and market share has accelerated to the concentration of dominant firms.”</strong> - <em>China’s State Council technology policy report</em></li>
<li>Dominant firms (TSMC, Samsung) are difficult to compete with.</li>
</ul></li>
<li><strong>Exploding demand for chips:</strong> Driven by cloud computing, the Internet of Things, and big data.</li>
<li><strong>China’s vulnerability:</strong>
<ul>
<li>Growing reliance on foreign chips, especially as China pursues AI.</li>
<li>Dependence on companies outside of China for advanced chips.</li>
<li><strong>Staggering dependence on foreign technology at almost every stage of semiconductor production.</strong> This technology is primarily controlled by geopolitical rivals (Taiwan, Japan, South Korea, and the US).</li>
</ul></li>
</ul>
</section>
<section id="chinas-dependence-across-the-semiconductor-supply-chain" class="level3">
<h3 class="anchored" data-anchor-id="chinas-dependence-across-the-semiconductor-supply-chain">China’s Dependence Across the Semiconductor Supply Chain</h3>
<ul>
<li><strong>Software Tools:</strong>
<ul>
<li>Dominated by US firms.</li>
<li>China holds <strong>less than 1% of the global market share.</strong> <em>Source: Georgetown University’s Center for Security and Emerging Technology</em></li>
</ul></li>
<li><strong>Core Intellectual Property (transistor patterns):</strong>
<ul>
<li>China’s market share: <strong>2%.</strong></li>
<li>The majority is held by US and British firms.</li>
</ul></li>
<li><strong>Silicon Wafers and Chip-Making Materials:</strong>
<ul>
<li>China supplies <strong>4%</strong> globally.</li>
</ul></li>
<li><strong>Chip Fabrication Tools:</strong>
<ul>
<li>China supplies <strong>1%</strong> globally.</li>
</ul></li>
<li><strong>Chip Designs:</strong>
<ul>
<li>China holds <strong>5%</strong> of the market.</li>
</ul></li>
<li><strong>Chip Fabrication:</strong>
<ul>
<li>China’s market share: <strong>7%.</strong></li>
<li>Lacks capacity for high-value, leading-edge technology.</li>
</ul></li>
<li><strong>Overall Semiconductor Supply Chain Market Share:</strong>
<ul>
<li>China: <strong>6%</strong></li>
<li>US: <strong>39%</strong></li>
<li>South Korea: <strong>16%</strong></li>
<li>Taiwan: <strong>12%</strong></li>
<li><em>Source: Georgetown University researchers</em></li>
</ul></li>
<li><strong>Key Takeaway:</strong> China remains highly reliant on foreign, particularly American, technology for advanced semiconductors.</li>
</ul>
</section>
<section id="the-made-in-china-2025-plan" class="level3">
<h3 class="anchored" data-anchor-id="the-made-in-china-2025-plan">The “Made in China 2025” Plan</h3>
<ul>
<li><strong>Goal:</strong> Reduce China’s reliance on imported chips.
<ul>
<li>From <strong>85%</strong> (2015) to <strong>30%</strong> by 2025.</li>
</ul></li>
<li><strong>Historical Context:</strong> Previous attempts to build a domestic chip industry had limited success.
<ul>
<li>Mao’s Cultural Revolution: Failed attempt at mass transistor production.</li>
<li>SMIC (Semiconductor Manufacturing International Corporation):
<ul>
<li>Founded with help from Richard Chang.</li>
<li>Faced financial struggles, IP lawsuits, and government interference.</li>
<li>Lagged behind TSMC in manufacturing.</li>
</ul></li>
<li>Other Chinese foundries (Hua Hong, Grace):
<ul>
<li>Limited market share due to government interference and inefficient, geographically dispersed facilities.</li>
</ul></li>
</ul></li>
<li><strong>Foreign Investment:</strong>
<ul>
<li>Potential seen in the Chinese market, but hampered by corporate governance issues and reliance on subsidies.</li>
<li><strong>“When a Chinese firm said, let’s open a joint venture, … I heard, let’s lose money.”</strong> - <em>European semiconductor executive</em></li>
</ul></li>
<li><strong>The “Big Fund” (2014):</strong>
<ul>
<li>Government-backed fund to support the semiconductor industry.</li>
<li>Key investors:
<ul>
<li>China’s Ministry of Finance</li>
<li>China Development Bank</li>
<li>State-owned firms (including China Tobacco)</li>
<li>Municipal governments (Beijing, Shanghai, Wuhan)</li>
</ul></li>
<li>Estimated investment: <strong>Tens of billions of dollars.</strong></li>
</ul></li>
<li><strong>Challenges:</strong>
<ul>
<li>China’s desire for self-sufficiency hindered collaboration with Silicon Valley.</li>
<li>Contrast with other Asian nations (Japan, South Korea, Taiwan) that integrated with the US chip industry.</li>
</ul></li>
<li><strong>Goal Misalignment:</strong>
<ul>
<li>Not simply seeking a larger role within the existing ecosystem.</li>
<li><strong>Aiming to reshape the global semiconductor industry and reduce dependence on the US and its allies.</strong></li>
</ul></li>
</ul>
</section>
<section id="the-economic-and-geopolitical-stakes" class="level3">
<h3 class="anchored" data-anchor-id="the-economic-and-geopolitical-stakes">The Economic and Geopolitical Stakes</h3>
<ul>
<li><strong>Trade Impacts:</strong>
<ul>
<li><strong>Made in China 2025 threatened to disrupt global trade flows.</strong></li>
<li>China’s chip imports in 2017: <strong>$260 billion.</strong>
<ul>
<li>Larger than Saudi Arabia’s oil exports or Germany’s car exports.</li>
<li>Exceeded the value of the global aircraft trade.</li>
</ul></li>
</ul></li>
<li><strong>Regional Impact:</strong>
<ul>
<li>Potential harm to export-dependent economies in Asia.</li>
<li>Semiconductors as a significant percentage of exports:
<ul>
<li>South Korea: <strong>15%</strong></li>
<li>Singapore: <strong>17%</strong></li>
<li>Malaysia: <strong>19%</strong></li>
<li>Philippines: <strong>21%</strong></li>
<li>Taiwan: <strong>36%</strong></li>
</ul></li>
</ul></li>
<li><strong>Taiwan’s Concerns:</strong> The rise of the “<strong>red supply chain”</strong>—mainland Chinese firms competing in areas Taiwan once dominated.</li>
<li><strong>China’s Advantages:</strong>
<ul>
<li>Government subsidies.</li>
<li>State-backed IP theft.</li>
<li>Leverage over foreign firms seeking access to the Chinese market.</li>
</ul></li>
<li><strong>Conclusion:</strong>
<ul>
<li>Xi’s vision for semiconductor independence had the potential to reshape globalization and the semiconductor industry.</li>
<li>The plan’s success would have significant economic and geopolitical ramifications, particularly in Asia.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-44-technology-transfer" class="level2">
<h2 class="anchored" data-anchor-id="chapter-44-technology-transfer">Chapter 44: Technology Transfer</h2>
<section id="the-drive-for-self-sufficiency" class="level3">
<h3 class="anchored" data-anchor-id="the-drive-for-self-sufficiency">The Drive for Self-Sufficiency</h3>
<ul>
<li><strong>China’s goal:</strong> To acquire semiconductor technology and reduce reliance on foreign companies, particularly for data center chips.</li>
</ul>
</section>
<section id="ibms-technology-transfer" class="level3">
<h3 class="anchored" data-anchor-id="ibms-technology-transfer">IBM’s Technology Transfer</h3>
<ul>
<li><strong>Context:</strong>
<ul>
<li>IBM’s sales in China dropped 20% after the Snowden leaks, suggesting government retaliation.</li>
<li>IBM sought to regain market access and leverage its lagging chip technology.</li>
</ul></li>
<li><strong>Strategy:</strong>
<ul>
<li>IBM CEO Rometty proposed opening chip technology to Chinese partners, enabling them to create a “vibrant ecosystem.”</li>
<li>This shift focused on selling services rather than hardware.</li>
</ul></li>
<li><strong>Key Individuals:</strong>
<ul>
<li>Rometty met with top Chinese officials, including Premier Li Keqiang and Vice Premier Ma Kai, who oversaw China’s chip industry.</li>
<li>Shen Chengsheng, former cybersecurity chief of China’s nuclear missile arsenal, worked with IBM’s chip technology, highlighting the strategic importance of the partnership.</li>
</ul></li>
<li><strong>Business Rationale:</strong>
<ul>
<li>IBM’s technology was considered second-rate and needed government support.</li>
<li>Sharing chip designs aligned with IBM’s global shift towards services.</li>
</ul></li>
<li><strong>China’s Perspective:</strong>
<ul>
<li>Viewed the partnership as supporting semiconductor self-sufficiency and national interests.</li>
<li>State-run media explicitly linked the deal to “integrated circuit development.”</li>
</ul></li>
</ul>
</section>
<section id="other-companies-involved-in-technology-transfer" class="level3">
<h3 class="anchored" data-anchor-id="other-companies-involved-in-technology-transfer">Other Companies Involved in Technology Transfer</h3>
<ul>
<li><strong>Qualcomm:</strong>
<ul>
<li>Faced pressure from Chinese regulators to lower licensing fees for smartphone chip technology.</li>
<li>Formed a joint venture with Huaqing Tong, a company with ties to a rising political figure, to develop server chips.</li>
<li>The venture dissolved in 2019, but expertise may have transferred to other Chinese firms.</li>
</ul></li>
<li><strong>AMD:</strong>
<ul>
<li>Struggled financially and sought cash while developing its “Zen” processor series.</li>
<li>In 2016:
<ul>
<li>Sold 85% of its semiconductor assembly, testing, and packaging facilities in Malaysia and China to a Chinese firm for $371 million.</li>
<li>Licensed the production of modified x86 chips for the Chinese market to a consortium of Chinese firms and government bodies.</li>
</ul></li>
<li><strong>Controversy Surrounding the Deal:</strong>
<ul>
<li>Intel reportedly warned the U.S. government about potential harm to U.S. interests.</li>
<li>The deal bypassed CFIUS review.</li>
<li>The Wall Street Journal criticized the deal as selling “crown jewels.”</li>
<li>Pentagon officials expressed skepticism and concerns about technology leakage.</li>
</ul></li>
<li><strong>Sugon’s Involvement:</strong>
<ul>
<li>The joint venture involved Sugon, a Chinese supercomputer firm with ties to the Chinese military.</li>
<li>Sugon advertised its role in “national defense and security.”</li>
<li>Even after being blacklisted by the U.S., Sugon was found using AMD chips, raising questions about continued technology access.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="arm-china-spin-off" class="level3">
<h3 class="anchored" data-anchor-id="arm-china-spin-off">Arm China Spin-Off</h3>
<ul>
<li><strong>Context:</strong>
<ul>
<li>Arm, a British company acquired by SoftBank (a Japanese firm heavily invested in Chinese tech), designed chip architecture.</li>
</ul></li>
<li><strong>The Deal:</strong>
<ul>
<li>In 2018, Arm spun off its China division, selling 51% to Chinese investors.</li>
<li>SoftBank, facing U.S. scrutiny over its China exposure, sold the stake for $775 million, a fraction of Arm’s $40 billion acquisition cost.</li>
</ul></li>
<li><strong>Rationale:</strong>
<ul>
<li>Arm executives acknowledged China’s desire for control over technology, particularly for sensitive applications like military and surveillance.</li>
<li>The spin-off allowed Arm to access the Chinese market while complying with China’s demand for domestic control.</li>
</ul></li>
<li><strong>Lack of Scrutiny:</strong>
<ul>
<li>Regulators in Japan, the UK, and the U.S. did not investigate the implications of the deal.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-4" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-4">Conclusion</h3>
<ul>
<li>China’s large semiconductor market creates strong incentives for foreign firms to transfer technology, even if it risks aiding competitors.</li>
<li>Companies facing financial pressures or market share loss are particularly vulnerable to these incentives.</li>
<li>While individual deals may have sound business logic, the collective impact raises concerns about technology leakage and China’s growing semiconductor capabilities.</li>
<li>U.S. and UK chip architectures, designs, and Taiwanese foundries have played a significant role in advancing China’s supercomputer programs.</li>
<li>China has made progress in reducing reliance on foreign chipmakers, particularly for data centers.</li>
<li>IBM’s expectation of benefiting from technology transfer proved inaccurate, highlighting the potential for China to leverage such deals for its own strategic advantage.</li>
</ul>
</section>
</section>
<section id="chapter-45-mergers-are-bound-to-happen" class="level2">
<h2 class="anchored" data-anchor-id="chapter-45-mergers-are-bound-to-happen">Chapter 45: Mergers Are Bound to Happen</h2>
<section id="zhao-weiguos-journey-to-chip-billionaire" class="level3">
<h3 class="anchored" data-anchor-id="zhao-weiguos-journey-to-chip-billionaire">Zhao Weiguo’s Journey to Chip Billionaire</h3>
<ul>
<li>Zhao Weiguo’s path to becoming a chip billionaire, as celebrated by Chinese media, was unconventional.</li>
</ul>
<section id="humble-beginnings-and-early-career" class="level4">
<h4 class="anchored" data-anchor-id="humble-beginnings-and-early-career">Humble Beginnings and Early Career</h4>
<ul>
<li><strong>Early Life:</strong>
<ul>
<li>Zhao’s family ended up in rural China after his father was exiled during the Cultural Revolution for writing subversive poetry.</li>
<li>Despite growing up raising livestock, Zhao aspired for more than a rural life.</li>
</ul></li>
<li><strong>Education and Early Career:</strong>
<ul>
<li>Zhao gained admission to Tsinghua University, one of China’s top institutions, where he studied electrical engineering.
<ul>
<li>Note: Tsinghua University has been at the forefront of China’s semiconductor efforts since the industry’s beginnings in the country.</li>
<li>It’s unclear how much semiconductor-specific knowledge Zhao acquired during his studies.</li>
</ul></li>
<li>After graduating, he worked at a tech company before transitioning into investing as a vice president at Tsinghua Uni Group.
<ul>
<li><strong>Tsinghua Uni Group:</strong> Established by Tsinghua University to commercialize its research, the company seemingly focused heavily on real estate investments.</li>
</ul></li>
</ul></li>
<li><strong>Investment Success:</strong>
<ul>
<li>Zhao earned a reputation for skillful corporate deal-making, setting him on a path to substantial wealth.</li>
<li><strong>2004:</strong> Zhao founded his own investment firm, Beijing Jiankun Group.
<ul>
<li><strong>Investment Focus:</strong> Real estate, mining, and other sectors where political connections are often critical for success.</li>
<li><strong>Reported Returns:</strong> Zhao reportedly grew an initial investment of 1 million yuan to 4.5 billion yuan.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="entry-into-the-semiconductor-industry" class="level4">
<h4 class="anchored" data-anchor-id="entry-into-the-semiconductor-industry">Entry into the Semiconductor Industry</h4>
<ul>
<li><strong>2009:</strong> Zhao acquired a 49% stake in his former employer, Tsinghua Uni Group, with the university retaining the remaining 51%.
<ul>
<li><strong>Unusual Transaction:</strong> This raised eyebrows as it meant a private real estate investment firm now held significant control over a company meant to commercialize technology from a leading research university.</li>
</ul></li>
<li><strong>Tsinghua Unigroup’s Political Connections:</strong>
<ul>
<li>The company wasn’t a typical business entity. It had strong ties to the Chinese Communist Party:
<ul>
<li>The son of former Chinese President Hu Jintao, reportedly a personal friend of Zhao’s, held the position of Communist Party Secretary for the holding company that owned Unigroup.</li>
<li>The president of Tsinghua University during the 2000s was a former college roommate of Xi Jinping.</li>
</ul></li>
</ul></li>
<li><strong>2013:</strong> Zhao shifted focus to the chip industry, a move that coincided with the Chinese Communist Party’s announcement of major subsidies for domestic semiconductor companies.
<ul>
<li><strong>Zhao’s Claim:</strong> He denies that Tsinghua Unigroup’s semiconductor strategy was a reaction to the government’s plans, stating, “Everyone thinks that the government is pushing the development of the chip sector, but it’s not like that” (Forbes, 2015).</li>
<li><strong>Zhao’s Narrative:</strong> He presents himself as the driving force behind attracting Beijing’s attention to the sector: “Companies did some stuff first, and then the government started to notice, all our deals are market-oriented.”</li>
</ul></li>
</ul>
</section>
</section>
<section id="tsinghua-unigroups-aggressive-acquisition-strategy" class="level3">
<h3 class="anchored" data-anchor-id="tsinghua-unigroups-aggressive-acquisition-strategy">Tsinghua Unigroup’s Aggressive Acquisition Strategy</h3>
<section id="questionable-investment-approach" class="level4">
<h4 class="anchored" data-anchor-id="questionable-investment-approach">Questionable Investment Approach</h4>
<ul>
<li><strong>Analyst Skepticism:</strong> Most analysts wouldn’t describe Zhao’s strategy as “market-oriented.” Instead of targeting the top chip firms, he seemed to pursue any available acquisition.</li>
<li><strong>Zhao’s Analogy:</strong> He compared his investment style to hunting: “If you carry your gun up the mountain, you just don’t know if there’s game there… Maybe you’ll catch a deer, maybe a goat, you just don’t know.”</li>
<li><strong>Significant Spending:</strong> Despite Zhao’s estimated $2 billion fortune, his spending on building a chip empire was astonishing.</li>
</ul>
</section>
<section id="early-acquisitions-and-partnerships" class="level4">
<h4 class="anchored" data-anchor-id="early-acquisitions-and-partnerships">Early Acquisitions and Partnerships</h4>
<ul>
<li><strong>2013:</strong>
<ul>
<li><strong>Domestic Acquisitions:</strong> Tsinghua Unigroup spent billions to acquire two of China’s leading fabless chip design companies:
<ul>
<li><strong>Spreadtrum Communications</strong></li>
<li><strong>RDA Microelectronics</strong></li>
<li>Both companies specialized in low-end chips for smartphones.</li>
</ul></li>
<li><strong>Zhao’s Justification:</strong> He predicted significant “synergies” from the merger, both domestically and internationally.
<ul>
<li>Note: Almost a decade later, there’s little evidence to support these claims of synergy.</li>
</ul></li>
</ul></li>
<li><strong>2014:</strong>
<ul>
<li><strong>Intel Partnership:</strong> Tsinghua Unigroup partnered with Intel to combine Intel’s wireless modem chips with their smartphone processors.
<ul>
<li><strong>Intel’s Goal:</strong> To expand its presence in the Chinese smartphone market.</li>
<li><strong>Zhao’s Goal:</strong> For his companies to gain knowledge from Intel’s chip design expertise.</li>
</ul></li>
<li><strong>Zhao’s Stated Aims:</strong> He acknowledged that semiconductors were a national priority for China and believed the Intel collaboration would “accelerate the technology development and further strengthen the competitiveness and market position of Chinese semiconductor companies.”</li>
</ul></li>
</ul>
</section>
<section id="reckless-spending-and-diversification" class="level4">
<h4 class="anchored" data-anchor-id="reckless-spending-and-diversification">Reckless Spending and Diversification</h4>
<ul>
<li><strong>XMC Funding:</strong>
<ul>
<li><strong>Background:</strong> Tsinghua Unigroup offered to finance XMC (later acquired by YMTC), a Chinese company aiming to enter the NAND memory chip market.</li>
<li><strong>Excessive Investment:</strong> The XMC CEO admitted publicly that while he initially requested $15 billion for a new fabrication plant (“fab”), he was given $24 billion with the reasoning that “if they were going to be serious about being a world leader, then they needed to match the world leader’s investment.”
<ul>
<li>This demonstrates Tsinghua Unigroup’s tendency for excessive spending, even when it seemed economically unjustified.</li>
</ul></li>
</ul></li>
<li><strong>Lack of Focus:</strong>
<ul>
<li><strong>Beyond Semiconductors:</strong> News emerged that Tsinghua Unigroup was investing in other sectors like real estate and online gambling. This lack of focus further fueled concerns about the company’s strategy.</li>
<li><strong>Government Backing:</strong> China’s state-backed “Big Fund” announced a plan to invest over $1 billion in Tsinghua Unigroup, effectively endorsing the company’s approach.</li>
</ul></li>
</ul>
</section>
</section>
<section id="targeting-global-semiconductor-leaders" class="level3">
<h3 class="anchored" data-anchor-id="targeting-global-semiconductor-leaders">Targeting Global Semiconductor Leaders</h3>
<section id="focus-on-taiwan" class="level4">
<h4 class="anchored" data-anchor-id="focus-on-taiwan">Focus on Taiwan</h4>
<ul>
<li><strong>Ambitious Goals:</strong> Zhao’s ambitions extended beyond controlling China’s fabless chip companies or attracting foreign investment into China. He set his sights on dominating the global semiconductor industry.</li>
<li><strong>Recruiting Taiwanese Talent:</strong> He hired several prominent Taiwanese semiconductor executives, including the former CEO of UMC, Taiwan’s second-largest foundry.</li>
<li><strong>2015 Taiwan Visit:</strong>
<ul>
<li>Zhao traveled to Taiwan to advocate for lifting restrictions on Chinese investment in areas like chip design and fabrication.</li>
<li>He successfully acquired a 25% stake in Powertech Technology, a Taiwanese semiconductor assembler and tester, which was permissible under existing regulations.</li>
<li>He pursued stakes and joint ventures with other major Taiwanese chip assemblers.</li>
</ul></li>
<li><strong>Targeting MediaTek and TSMC:</strong> Zhao’s true targets were Taiwan’s industry giants:
<ul>
<li><strong>MediaTek:</strong> The world’s leading chip designer outside of the United States.</li>
<li><strong>TSMC:</strong> The dominant foundry upon which nearly all global fabless chip companies relied.</li>
<li><strong>Proposed Acquisitions:</strong> He suggested buying a 25% stake in TSMC and merging MediaTek with Tsinghua Unigroup’s chip design operations.
<ul>
<li>These proposals were not legally permitted under Taiwan’s foreign investment laws.</li>
</ul></li>
</ul></li>
<li><strong>Pressure Tactics:</strong> Upon returning from Taiwan, Zhao publicly suggested at a Beijing conference that China should ban imports of Taiwanese chips if Taiwan didn’t ease its investment restrictions.</li>
<li><strong>Impact on TSMC and MediaTek:</strong> This pressure campaign put both companies in a difficult position due to their heavy reliance on the Chinese market.
<ul>
<li>Most of TSMC’s chips were used in electronics assembled in China.</li>
<li>The prospect of selling Taiwan’s key technology companies to a state-backed Chinese investor raised serious concerns about Taiwan’s economic independence.</li>
</ul></li>
</ul>
</section>
<section id="taiwans-response-and-internal-debate" class="level4">
<h4 class="anchored" data-anchor-id="taiwans-response-and-internal-debate">Taiwan’s Response and Internal Debate</h4>
<ul>
<li><strong>TSMC and MediaTek’s Cautious Statements:</strong>
<ul>
<li><strong>Morris Chang (TSMC):</strong> He expressed conditional openness to the deal, stating, “if the price is right and if it is beneficial to shareholders.” However, he also cautioned, “if Chinese investors could appoint members to Taiwanese companies’ boards of directors, it will not be that easy to protect intellectual property.”</li>
<li><strong>MediaTek:</strong> The company indicated support for collaboration “to join hands and raise the status and competitiveness of the Chinese and Taiwanese enterprises in the global chip industry,” but only if the Taiwanese government permitted it.</li>
</ul></li>
<li><strong>Taiwanese Government’s Position:</strong>
<ul>
<li><strong>John Deng (Taiwan’s Economy Minister):</strong> He suggested loosening restrictions on Chinese investment in Taiwan’s chip sector.</li>
<li><strong>Deng’s View:</strong> He believed that increased Chinese influence in Taiwan’s chip industry was unavoidable, stating, “You cannot escape from this issue.”</li>
<li><strong>Delayed Policy Changes:</strong> Due to a contentious presidential election in Taiwan, the government postponed any immediate policy decisions.</li>
</ul></li>
</ul>
</section>
<section id="targeting-us-semiconductor-companies" class="level4">
<h4 class="anchored" data-anchor-id="targeting-us-semiconductor-companies">Targeting US Semiconductor Companies</h4>
<ul>
<li><strong>July 2015: Micron Acquisition Attempt:</strong>
<ul>
<li>Tsinghua Unigroup proposed buying Micron, a US memory chip manufacturer, for $23 billion. This would have been the largest-ever Chinese acquisition of a US company across any industry.</li>
<li><strong>Micron’s Rejection:</strong> The company declined the offer, citing concerns about US government security reviews and deeming the deal unrealistic.</li>
</ul></li>
<li><strong>September 2015: Another Failed Attempt:</strong>
<ul>
<li>Tsinghua Unigroup offered $3.7 billion for a 15% stake in another US NAND memory chip company (name not specified in the text).</li>
<li><strong>CFIUS Rejection:</strong> The Committee on Foreign Investment in the United States (CFIUS), which reviews foreign investments for national security risks, blocked the deal.</li>
</ul></li>
<li><strong>Spring 2016: Lattice Semiconductor Investment:</strong>
<ul>
<li>Tsinghua Unigroup quietly acquired a 6% stake in Lattice Semiconductor, another US chip company.</li>
<li><strong>Zhao’s Claim:</strong> He insisted to the Wall Street Journal that this was “purely a financial investment,” adding, “We don’t have any intention at all to try to acquire Lattice.”</li>
<li><strong>Quick Sale:</strong> Within weeks, Tsinghua Unigroup began selling its Lattice shares.</li>
</ul></li>
<li><strong>Canyon Bridge and Imagination Technologies:</strong>
<ul>
<li><strong>Lattice Semiconductor Buyout Attempt:</strong> A California-based investment firm called Canyon Bridge, later revealed to be secretly funded by the Chinese government, made a bid to buy Lattice Semiconductor. This deal was also rejected by the US government.</li>
<li><strong>Imagination Technologies Acquisition:</strong> Canyon Bridge simultaneously purchased Imagination Technologies, a struggling UK-based chip designer. The deal was structured to exclude Imagination’s US assets to avoid US regulatory scrutiny.
<ul>
<li>Notably, three years later, the new owners attempted to appoint board members linked to a Chinese government investment fund, raising red flags for British regulators who had initially approved the acquisition.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="controversial-tactics-and-insider-trading" class="level4">
<h4 class="anchored" data-anchor-id="controversial-tactics-and-insider-trading">Controversial Tactics and Insider Trading</h4>
<ul>
<li><strong>Illegal Practices:</strong> The issue wasn’t just Chinese government-linked entities acquiring foreign chip firms but doing so through methods that violated regulations on market manipulation and insider trading.</li>
<li><strong>Canyon Bridge Insider Trading Case:</strong>
<ul>
<li>During the attempted Lattice Semiconductor purchase, a Canyon Bridge co-founder was found guilty of insider trading for sharing confidential deal information with a contact in Beijing via WeChat and meetings at a Starbucks in Beijing. This contact then used the information to profit from stock purchases.</li>
</ul></li>
<li><strong>Zhao’s Perspective:</strong>
<ul>
<li><strong>Business-Focused:</strong> Zhao maintained that he was simply a dedicated entrepreneur, claiming that mergers between large US and Chinese companies were inevitable.</li>
<li><strong>Zhao’s View:</strong> He believed such deals “should be viewed from a business perspective instead of being treated under nationalist or political contexts.”</li>
</ul></li>
<li><strong>Government-Led Effort:</strong> However, the sheer volume of Chinese state-owned and state-financed private equity firms pursuing global semiconductor companies pointed to a coordinated government-led strategy to gain control of these companies.</li>
<li><strong>Following Directives:</strong> Xi Jinping had publicly called for an “assault” in the semiconductor sector. Tsinghua Unigroup’s actions, along with those of other government-backed investment vehicles, seemed to be a direct response to this directive.</li>
</ul>
</section>
<section id="continued-investment-and-expansion" class="level4">
<h4 class="anchored" data-anchor-id="continued-investment-and-expansion">Continued Investment and Expansion</h4>
<ul>
<li><strong>2017 Funding Announcement:</strong> Amidst its aggressive acquisition spree, Tsinghua Unigroup secured approximately $15 billion from the China Development Bank and $7 billion from the Integrated Circuit Industry Investment Fund, both entities owned and controlled by the Chinese government. This substantial injection of state funds further emphasized the Chinese government’s backing of Tsinghua Unigroup’s ambitions in the global semiconductor industry.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-46-the-rise-of-huawei" class="level2">
<h2 class="anchored" data-anchor-id="chapter-46-the-rise-of-huawei">Chapter 46: The Rise of Huawei</h2>
<section id="huaweis-global-reach-and-struggle" class="level3">
<h3 class="anchored" data-anchor-id="huaweis-global-reach-and-struggle">Huawei’s Global Reach and Struggle</h3>
<ul>
<li><strong>Huawei</strong>, a Chinese technology company, holds a crucial position in the global technology landscape.
<ul>
<li>Its telecom equipment forms the backbone of mobile internet infrastructure.</li>
<li>Its smartphone unit rivals Apple and Samsung in sales.</li>
<li>It provides various tech infrastructures like undersea cables and cloud computing.</li>
</ul></li>
<li>Despite its global presence, Huawei faces scrutiny from the US national security state over its alleged ties to the Chinese government and concerns about espionage.</li>
</ul>
</section>
<section id="comparing-huaweis-trajectory-to-samsungs-success" class="level3">
<h3 class="anchored" data-anchor-id="comparing-huaweis-trajectory-to-samsungs-success">Comparing Huawei’s Trajectory to Samsung’s Success</h3>
<ul>
<li>To understand Huawei’s growth, it is helpful to compare it with <strong>Samsung</strong>, a South Korean tech giant that followed a similar path.</li>
<li>Both companies share a similar operating model:
<ul>
<li><strong>Cultivate Political Relationships:</strong> Secure favorable regulations and access to capital.</li>
<li><strong>Emulate and Outcompete:</strong> Identify products pioneered in the West, produce them at comparable quality, and offer them at lower costs.</li>
<li><strong>Aggressive Globalization:</strong> Expand globally to reach new customers and learn from international competition.</li>
</ul></li>
<li>Samsung’s success, with revenues equivalent to 10% of South Korea’s GDP, demonstrates the effectiveness of this model.</li>
<li>In contrast to Huawei’s global approach, most Chinese tech firms primarily focus on the domestic market, protected by regulation and censorship.</li>
</ul>
</section>
<section id="huaweis-business-model-global-ambition-and-competition" class="level3">
<h3 class="anchored" data-anchor-id="huaweis-business-model-global-ambition-and-competition">Huawei’s Business Model: Global Ambition and Competition</h3>
<ul>
<li><strong>Ren Zhengfei</strong>, Huawei’s founder, adopted a distinct business model:
<ul>
<li>Adapting concepts developed abroad.</li>
<li>Manufacturing high-quality products at competitive prices.</li>
<li>Targeting the global market and directly competing with international rivals.</li>
</ul></li>
<li>This strategy, similar to Samsung’s, positions Huawei to become a central player in the global tech ecosystem.</li>
</ul>
</section>
<section id="huaweis-early-days-from-reseller-to-manufacturer" class="level3">
<h3 class="anchored" data-anchor-id="huaweis-early-days-from-reseller-to-manufacturer">Huawei’s Early Days: From Reseller to Manufacturer</h3>
<ul>
<li><strong>Ren Zhengfei’s Background:</strong>
<ul>
<li>Grew up in a family of teachers in Guizhou province, China.</li>
<li>Trained as an engineer and served in the Chinese army.</li>
<li>Moved to Shenzhen, a Special Economic Zone bordering Hong Kong, to pursue entrepreneurial opportunities.</li>
</ul></li>
<li><strong>Huawei’s Founding:</strong>
<ul>
<li>Established in 1987 with $5,000 in capital.</li>
<li>Initially imported and resold telecom switches from Hong Kong.</li>
<li>When suppliers cut him off, Ren decided to manufacture his own equipment.</li>
</ul></li>
</ul>
</section>
<section id="huaweis-rd-focus-and-allegations-of-intellectual-property-theft" class="level3">
<h3 class="anchored" data-anchor-id="huaweis-rd-focus-and-allegations-of-intellectual-property-theft">Huawei’s R&amp;D Focus and Allegations of Intellectual Property Theft</h3>
<ul>
<li>By the 1990s, Huawei invested heavily in R&amp;D, focusing on building switching equipment.</li>
<li>While acknowledging some past instances, Huawei faces accusations of intellectual property theft:
<ul>
<li>In 2003, admitted to copying 2% of the code in one of its routers from Cisco.</li>
<li>Canadian media reports suggest possible Chinese government-backed espionage against Nortel, potentially benefiting Huawei.</li>
</ul></li>
</ul>
</section>
<section id="huaweis-rd-investment-and-shift-in-ethos" class="level3">
<h3 class="anchored" data-anchor-id="huaweis-rd-investment-and-shift-in-ethos">Huawei’s R&amp;D Investment and Shift in Ethos</h3>
<ul>
<li>Despite allegations, Huawei’s significant R&amp;D spending suggests a shift from simply copying to innovation:
<ul>
<li>Annual R&amp;D budget exceeding $15 billion, rivaling companies like Google, Amazon, and major pharmaceutical and automotive companies.</li>
<li>This commitment to R&amp;D sets Huawei apart from many Chinese firms attempting to enter the chip industry cheaply.</li>
</ul></li>
<li>Huawei claims its R&amp;D focus stems from learning from Silicon Valley:
<ul>
<li>In 1997, Ren led Huawei executives on a US tour, visiting companies like HP, IBM, and Bell Labs, recognizing the importance of R&amp;D and effective management.</li>
</ul></li>
</ul>
</section>
<section id="learning-from-ibm-and-cultivating-wolf-culture" class="level3">
<h3 class="anchored" data-anchor-id="learning-from-ibm-and-cultivating-wolf-culture">Learning from IBM and Cultivating “Wolf Culture”</h3>
<ul>
<li>From 1999, Huawei hired IBM consultants to improve its operations:
<ul>
<li>Spent $50 million on consulting, a significant portion of its revenue at the time.</li>
<li>Employed over 100 IBM staff to revamp business processes, focusing on supply chain management, demand forecasting, marketing, and global sales.</li>
</ul></li>
<li>Alongside Western consulting, Huawei adopted a “<strong>wolf culture</strong>”:
<ul>
<li>Emphasizing a militaristic work ethic and relentless pursuit of success.</li>
<li>This approach, while intense, aligns with the competitive spirit in the chip industry, as seen in the philosophies of leaders like Andy Grove and Morris Chang.</li>
</ul></li>
</ul>
</section>
<section id="government-support-and-huaweis-global-expansion" class="level3">
<h3 class="anchored" data-anchor-id="government-support-and-huaweis-global-expansion">Government Support and Huawei’s Global Expansion</h3>
<ul>
<li>Huawei’s growth was supported by various levels of the Chinese government:
<ul>
<li>Receiving subsidies, state-backed credit, and tax breaks, amounting to an estimated $75 billion according to The Wall Street Journal.</li>
<li>While this level of support is unusual in the West, it is not uncommon for East Asian governments to back strategic industries.</li>
</ul></li>
<li>The extent of state support raised concerns, especially in the US, about Huawei’s relationship with the Chinese government.</li>
<li>Chinese officials actively promoted Huawei’s global expansion, with Vice Premier Wu Banguo visiting the company and supporting its sales efforts in Africa.</li>
<li>This support raises questions about whether Huawei received preferential treatment or benefited from China’s mercantilist trade practices.</li>
<li>Concerns remain regarding the opaque nature of Huawei’s ownership structure and the role of the Chinese Communist Party in its governance.</li>
</ul>
</section>
<section id="huaweis-impact-on-the-global-telecom-market" class="level3">
<h3 class="anchored" data-anchor-id="huaweis-impact-on-the-global-telecom-market">Huawei’s Impact on the Global Telecom Market</h3>
<ul>
<li>Despite concerns, Huawei gained market share globally, impacting established Western telecom equipment providers:
<ul>
<li>Nortel filed for bankruptcy.</li>
<li>Alcatel-Lucent, inheritor of Bell Labs, was sold to Nokia.</li>
</ul></li>
<li>Expanding beyond infrastructure, Huawei entered the smartphone market:
<ul>
<li>Its smartphones became top sellers, trailing only Samsung by 2019.</li>
<li>While making less profit per phone compared to Apple or Samsung, Huawei’s rapid rise challenged these giants.</li>
</ul></li>
</ul>
</section>
<section id="the-2011-japan-earthquake-and-huaweis-chip-design-ambitions" class="level3">
<h3 class="anchored" data-anchor-id="the-2011-japan-earthquake-and-huaweis-chip-design-ambitions">The 2011 Japan Earthquake and Huawei’s Chip Design Ambitions</h3>
<ul>
<li>The 2011 earthquake and tsunami in Japan highlighted Huawei’s supply chain vulnerabilities:
<ul>
<li>The disaster threatened Huawei’s access to crucial components from Japanese suppliers.</li>
<li>While Huawei escaped major disruptions, it prompted a reassessment of its supply chain risks.</li>
</ul></li>
<li>Huawei identified two critical dependencies:
<ul>
<li><strong>Google’s Android operating system:</strong> The software foundation for its smartphones.</li>
<li><strong>Semiconductor supply:</strong> Essential components for all its devices.</li>
</ul></li>
<li>To mitigate risks, Huawei initiated in-house design of essential semiconductors, including:
<ul>
<li><strong>Application processors for smartphones:</strong> Highly complex chips requiring advanced manufacturing.</li>
</ul></li>
<li>Like Apple, Huawei outsourced the fabrication of these advanced chips to Taiwan’s TSMC, becoming its second-largest customer.</li>
</ul>
</section>
<section id="huaweis-challenge-to-us-chip-dominance-and-preparedness-for-5g" class="level3">
<h3 class="anchored" data-anchor-id="huaweis-challenge-to-us-chip-dominance-and-preparedness-for-5g">Huawei’s Challenge to US Chip Dominance and Preparedness for 5G</h3>
<ul>
<li>By developing in-house chip design capabilities, Huawei challenged the US dominance in this lucrative sector.</li>
<li>Huawei’s success mirrored the trajectory of Samsung and Sony, demonstrating its ability to:
<ul>
<li>Master advanced technologies.</li>
<li>Capture global market share.</li>
<li>Invest heavily in R&amp;D.</li>
<li>Compete directly with American tech leaders.</li>
</ul></li>
<li>This positioned Huawei advantageously for the rollout of 5G, the next generation of telecom infrastructure, and the era of ubiquitous computing it would enable.</li>
</ul>
</section>
</section>
<section id="chapter-47-the-5g-future" class="level2">
<h2 class="anchored" data-anchor-id="chapter-47-the-5g-future">Chapter 47: The 5G Future</h2>
<section id="the-evolution-of-telecom-and-the-rise-of-5g" class="level3">
<h3 class="anchored" data-anchor-id="the-evolution-of-telecom-and-the-rise-of-5g">The Evolution of Telecom and the Rise of 5G</h3>
<ul>
<li><strong>Early Telecom:</strong>
<ul>
<li>Telephone switches were initially manual, requiring human operators to connect calls.</li>
<li>By the 1980s, electronic switches, often using semiconductors, replaced manual systems.</li>
<li>Even with these advancements, managing a building’s telephone lines required bulky equipment.</li>
</ul></li>
<li><strong>Modern Telecom:</strong>
<ul>
<li>Today’s telecom providers rely heavily on silicon.</li>
<li>Modern equipment, though still physically compact, can process calls, texts, and video, often sent via radio networks instead of landlines.</li>
</ul></li>
<li><strong>Huawei’s Mastery and the Significance of 5G:</strong>
<ul>
<li>Huawei has excelled in developing the latest equipment for transmitting calls and data over cellular networks, known as <strong>5G</strong>.</li>
<li><strong>5G</strong> represents a significant leap in computing technology, relying heavily on <strong>semiconductors</strong>.</li>
</ul></li>
<li><strong>Generations of Mobile Networks:</strong>
<ul>
<li>The “G” in 5G refers to the generation of mobile networking standards.</li>
<li>Each generation has brought new hardware requirements for phones and cell towers.</li>
<li>Advancements in semiconductors, driven by <strong>Moore’s Law</strong>, have enabled more data transmission (ones and zeros) via radio waves.</li>
</ul></li>
<li><strong>Past Generations and Their Impact:</strong>
<ul>
<li><strong>2G:</strong> Introduced picture texts (MMS).</li>
<li><strong>3G:</strong> Enabled mobile web browsing.</li>
<li><strong>4G:</strong> Made video streaming widely accessible.</li>
</ul></li>
<li><strong>5G’s Transformative Potential:</strong>
<ul>
<li>5G is poised to deliver another major advancement in mobile network capabilities.</li>
<li>It will enable significantly faster data speeds and support a massive increase in connected devices.</li>
</ul></li>
</ul>
</section>
<section id="the-crucial-role-of-semiconductors-in-mobile-networks" class="level3">
<h3 class="anchored" data-anchor-id="the-crucial-role-of-semiconductors-in-mobile-networks">The Crucial Role of Semiconductors in Mobile Networks</h3>
<ul>
<li><strong>Impact of Semiconductors:</strong>
<ul>
<li>Advancements in semiconductors have made smartphones incredibly powerful.</li>
<li>Features like picture texts and video streaming, once considered revolutionary, are now commonplace thanks to these advancements.</li>
</ul></li>
<li><strong>Modem Chips:</strong>
<ul>
<li><strong>Modem chips</strong> manage a phone’s connection with cell networks.</li>
<li>They allow the transmission of vast amounts of data (ones and zeros) as radio waves via the phone’s antenna.</li>
</ul></li>
<li><strong>Semiconductors in Cell Networks:</strong>
<ul>
<li>Similar advancements have occurred in chips used in cell towers and network infrastructure.</li>
<li>These advancements are crucial for managing data transmission, minimizing dropped calls, and ensuring smooth video streaming.</li>
</ul></li>
<li><strong>Challenges of Wireless Data Transmission:</strong>
<ul>
<li>Sending data wirelessly while maintaining quality and speed is complex.</li>
<li>The <strong>radio wave spectrum</strong>, the range of frequencies used for wireless communication, has limited space.</li>
<li>Not all radio wave frequencies are suitable for sending large amounts of data or transmitting over long distances.</li>
</ul></li>
<li><strong>The Importance of Spectrum and Semiconductors:</strong>
<ul>
<li>“Spectrum is far more expensive than silicon.” - Dave Robertson, chip expert at Analog Devices.</li>
<li><strong>Semiconductors</strong> have been essential in maximizing the use of available spectrum to transmit more data wirelessly.</li>
</ul></li>
<li><strong>Innovations in Chip Design:</strong>
<ul>
<li>Companies like <strong>Qualcomm</strong> have developed advanced methods to optimize data transmission within the limited radio spectrum.</li>
<li>Manufacturers like <strong>Analog Devices</strong> produce specialized semiconductors called <strong>radio frequency transceivers</strong>, which send and receive radio waves with greater precision and lower power consumption.</li>
</ul></li>
</ul>
</section>
<section id="g-technology-enabling-the-future-of-wireless" class="level3">
<h3 class="anchored" data-anchor-id="g-technology-enabling-the-future-of-wireless">5G Technology: Enabling the Future of Wireless</h3>
<ul>
<li><strong>Increased Data Transmission:</strong>
<ul>
<li><strong>5G</strong> will significantly increase the amount of data that can be transmitted wirelessly.</li>
<li>It achieves this through:
<ul>
<li><strong>Sophisticated Spectrum Sharing:</strong> Complex algorithms and increased processing power in devices and cell towers allow for more efficient use of existing spectrum space.</li>
<li><strong>New Spectrum Utilization:</strong> 5G utilizes new, previously unused parts of the radio frequency spectrum, expanding available bandwidth.</li>
</ul></li>
</ul></li>
<li><strong>Advanced Semiconductor Capabilities:</strong>
<ul>
<li>Advanced semiconductors in 5G networks enable:
<ul>
<li><strong>Denser Data Encoding:</strong> Packing more ones and zeros into a given radio wave frequency.</li>
<li><strong>Increased Range:</strong> Transmitting radio waves over longer distances.</li>
<li><strong>Precise Targeting (Beamforming):</strong>
<ul>
<li><strong>Beamforming</strong> allows cell towers to pinpoint a device’s location and direct radio waves specifically towards it.</li>
<li>This focused approach reduces power waste, interference, and improves signal strength for all users.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Beyond Faster Phones:</strong>
<ul>
<li>The impact of 5G extends far beyond faster smartphones.</li>
<li>It will revolutionize mobile computing and transform how we interact with technology.</li>
</ul></li>
</ul>
</section>
<section id="the-5g-revolution-connecting-everything-and-generating-data" class="level3">
<h3 class="anchored" data-anchor-id="the-5g-revolution-connecting-everything-and-generating-data">The 5G Revolution: Connecting Everything and Generating Data</h3>
<ul>
<li><strong>Shifting Expectations in Mobile Computing:</strong>
<ul>
<li><strong>1G:</strong> Mobile phones were a luxury.</li>
<li><strong>2G:</strong> Text messaging (SMS) became standard.</li>
<li><strong>Present:</strong> Smartphones and tablets offer near-PC functionality.</li>
<li><strong>5G Future:</strong> Expect seamless connectivity for a vast number of devices, creating a truly interconnected world.</li>
</ul></li>
<li><strong>The Internet of Things (IoT) and Data Explosion:</strong>
<ul>
<li>5G will connect countless devices to the internet, leading to an explosion of data.</li>
<li>This data, when processed effectively, will enhance products and services in countless ways.</li>
</ul></li>
<li><strong>Example: Smart Coffee Makers:</strong>
<ul>
<li>5G-enabled coffee makers could collect and analyze data on temperature, brewing time, and coffee quality, leading to a consistently perfect cup.</li>
</ul></li>
<li><strong>Transforming Industries:</strong>
<ul>
<li>The combination of increased connectivity and data processing will revolutionize industries such as:
<ul>
<li><strong>Agriculture:</strong> Optimizing farming practices (e.g., precision agriculture with connected tractors).</li>
<li><strong>Manufacturing:</strong> Coordinating robots and automating processes on assembly lines.</li>
<li><strong>Healthcare:</strong> Enabling remote patient monitoring and advanced diagnostics through connected medical devices and sensors.</li>
</ul></li>
</ul></li>
<li><strong>Tesla: A Case Study in Connected Cars:</strong>
<ul>
<li>Tesla’s success highlights the potential of integrating advanced computing and connectivity into traditional products.</li>
<li>Tesla cars, often compared to smartphones on wheels, utilize custom-designed chips for a seamless user experience and advanced autonomous driving features.</li>
</ul></li>
<li><strong>The Future of Cars and Semiconductors:</strong>
<ul>
<li>The rise of electric vehicles (EVs), which require specialized semiconductors for power management, coupled with the demand for autonomous driving, will significantly increase the number and importance of chips in cars.</li>
</ul></li>
</ul>
</section>
<section id="huaweis-rise-and-the-geopolitics-of-5g" class="level3">
<h3 class="anchored" data-anchor-id="huaweis-rise-and-the-geopolitics-of-5g">Huawei’s Rise and the Geopolitics of 5G</h3>
<ul>
<li><strong>Huawei’s Leading Position:</strong>
<ul>
<li>Around 2017, as telecom companies prepared for 5G deployment, Huawei emerged as a dominant player.</li>
<li>Their equipment was regarded as high-quality and competitively priced.</li>
<li>Huawei was on track to play a larger role in 5G network construction than Ericsson (Sweden) and Nokia (Finland), its main competitors.</li>
</ul></li>
<li><strong>Huawei’s Semiconductor Reliance:</strong>
<ul>
<li>Despite its leadership, Huawei relied heavily on foreign semiconductor companies:
<ul>
<li>A Nikkei Asia analysis revealed that US-made chips, including those from Lattice Semiconductor (partially owned by China’s Tsinghua Unigroup at the time), Texas Instruments, Analog Devices, Broadcom, and Cypress Semiconductor, constituted almost 30% of the cost of Huawei’s radio systems.</li>
<li>While Huawei designed its main processor chip in-house, it was fabricated by TSMC (Taiwan Semiconductor Manufacturing Company).</li>
</ul></li>
</ul></li>
<li><strong>China’s Semiconductor Ambitions:</strong>
<ul>
<li>Although not fully self-sufficient, Huawei’s advanced chip design capabilities, combined with the rapid growth of China’s semiconductor industry, suggested a future where China could challenge Silicon Valley’s dominance.</li>
</ul></li>
<li><strong>Geopolitical Implications:</strong>
<ul>
<li>This potential shift in the semiconductor landscape had significant implications:
<ul>
<li>It threatened to disrupt established tech companies and global trade flows.</li>
<li>It raised concerns about a potential shift in the balance of military power.</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-48-the-next-offset" class="level2">
<h2 class="anchored" data-anchor-id="chapter-48-the-next-offset">Chapter 48: The Next Offset</h2>
<section id="the-rise-of-chinas-military-power" class="level3">
<h3 class="anchored" data-anchor-id="the-rise-of-chinas-military-power">The Rise of China’s Military Power</h3>
<ul>
<li>The future of warfare hinges on <strong>computing power</strong>, impacting domains like drone swarms, cyberspace, and the electromagnetic spectrum.</li>
<li>The U.S. military’s unchallenged dominance is fading.
<ul>
<li>The U.S. no longer enjoys unrivaled access to global seas and airspace, a reality driven home by the 1991 Persian Gulf War.
<ul>
<li>This conflict demonstrated the effectiveness of precision strikes, prompting other nations, notably China, to bolster their military capabilities.</li>
</ul></li>
</ul></li>
<li>Over the past 30 years, China has heavily invested in high-tech weaponry, shifting from Mao-era low-tech strategies to embrace advanced sensors, communication, and computing.
<ul>
<li>China’s goal is not just to match the U.S. but to develop capabilities that <strong>offset</strong> American advantages. This strategy mirrors the Pentagon’s approach in the 1970s, now turned against them.</li>
</ul></li>
</ul>
</section>
<section id="chinas-military-advantages-undermining-u.s.-strengths" class="level3">
<h3 class="anchored" data-anchor-id="chinas-military-advantages-undermining-u.s.-strengths">China’s Military Advantages: Undermining U.S. Strengths</h3>
<ul>
<li><strong>Precision anti-ship missiles:</strong> These pose a significant threat to U.S. surface ships, especially in crucial areas like the Taiwan Strait, limiting American naval power projection.</li>
<li><strong>Advanced air defense systems:</strong> These challenge America’s air superiority, traditionally a cornerstone of U.S. military doctrine.</li>
<li><strong>Long-range land attack missiles:</strong> These missiles threaten the network of U.S. military bases spanning from Japan to Guam, potentially crippling American force projection in the Pacific.</li>
<li><strong>Anti-satellite weapons:</strong> These weapons jeopardize U.S. communication and GPS networks, which are vital for coordinating military operations.</li>
<li><strong>Cyber warfare capabilities:</strong> While untested in full-scale conflict, China’s cyber capabilities could potentially disrupt or disable entire U.S. military systems.</li>
<li><strong>Electromagnetic spectrum dominance:</strong> China possesses the capability to jam American communications and blind surveillance systems. This could leave the U.S. military unable to effectively engage enemies or cooperate with allies.</li>
</ul>
</section>
<section id="intelligentized-warfare-ai-as-the-future-of-combat" class="level3">
<h3 class="anchored" data-anchor-id="intelligentized-warfare-ai-as-the-future-of-combat">“Intelligentized” Warfare: AI as the Future of Combat</h3>
<ul>
<li>The Chinese military believes warfare is transitioning from information-based to <strong>intelligentized</strong> warfare, leveraging <strong>artificial intelligence (AI)</strong> in weapon systems.</li>
<li>While computing power has always been crucial in warfare, its scale has grown exponentially. What’s new is the emergence of China as a credible challenger in this domain.
<ul>
<li>The Soviet Union, while capable of matching U.S. military might in certain areas, lacked the capacity for a similar level of technological advancement. China aims to rival the U.S. in both quantity and quality of military technology.</li>
</ul></li>
<li>The race for computing power goes beyond mere commerce; it holds significant military implications. The country with superior computing power gains a distinct strategic advantage.</li>
</ul>
</section>
<section id="the-ai-arms-race-chinas-potential-to-surpass-the-u.s." class="level3">
<h3 class="anchored" data-anchor-id="the-ai-arms-race-chinas-potential-to-surpass-the-u.s.">The AI Arms Race: China’s Potential to Surpass the U.S.</h3>
<section id="factors-determining-the-computing-race" class="level4">
<h4 class="anchored" data-anchor-id="factors-determining-the-computing-race">Factors Determining the Computing Race</h4>
<ul>
<li><strong>2021 Report by American Tech and Foreign Policy Experts:</strong>
<ul>
<li>The report, chaired by former Google CEO Eric Schmidt, predicted that China could become the world’s leading AI superpower.</li>
<li>Chinese leadership seems to agree with this assessment, emphasizing the development of military AI.</li>
</ul></li>
<li><strong>Xi Jinping’s Directive:</strong>
<ul>
<li>Xi Jinping has urged the PLA to prioritize the development of “military intelligentization,” further highlighting China’s focus on AI in warfare.</li>
</ul></li>
</ul>
</section>
<section id="applications-of-ai-in-military-systems" class="level4">
<h4 class="anchored" data-anchor-id="applications-of-ai-in-military-systems">Applications of AI in Military Systems</h4>
<ul>
<li><strong>Beyond Killer Robots:</strong> While the concept of <strong>AI weapons</strong> often brings to mind autonomous weapons, AI has broader military applications.</li>
<li><strong>Predictive Maintenance:</strong> AI helps anticipate equipment failures, enhancing the operational readiness of planes, ships, and other assets.</li>
<li><strong>Enhanced Threat Detection:</strong> AI-powered sonar systems in submarines and AI-enhanced analysis of satellite imagery improve the accuracy of threat identification.</li>
<li><strong>Accelerated Weapons Development:</strong> AI can facilitate faster design and development of new weapon systems.</li>
<li><strong>Improved Targeting Precision:</strong> AI allows for more accurate targeting, particularly for moving targets, enhancing the effectiveness of bombs and missiles.</li>
<li><strong>Autonomous Vehicles:</strong> In the air, underwater, and on land, autonomous vehicles are being developed with AI capabilities for maneuvering, enemy identification, and target engagement.
<ul>
<li>While this builds on existing technologies like “fire-and-forget” missiles, the increasing autonomy and intelligence of these systems demand significantly more computing power.</li>
</ul></li>
</ul>
</section>
<section id="chinas-strengths-in-the-ai-race" class="level4">
<h4 class="anchored" data-anchor-id="chinas-strengths-in-the-ai-race">China’s Strengths in the AI Race</h4>
<ul>
<li><strong>Ben Buchanan’s Triad of AI:</strong> Georgetown University’s Ben Buchanan identifies three key elements for AI development: data, algorithms, and computing power. While the U.S. currently leads in computing power, China is rapidly catching up in the other two areas.</li>
<li><strong>Data Access:</strong>
<ul>
<li><strong>China’s Argument:</strong> Proponents of China’s AI development point to the country’s vast surveillance state and massive population as advantages for data collection.</li>
<li><strong>Counterargument:</strong> The type of data collected through mass surveillance might not be as relevant for military AI applications.</li>
<li><strong>Conclusion:</strong> Neither China nor the U.S. has a clear advantage in gathering militarily relevant data.</li>
</ul></li>
<li><strong>Algorithm Development:</strong>
<ul>
<li><strong>China’s Strengths:</strong> China possesses a substantial pool of AI talent, with <strong>29%</strong> of the world’s leading AI researchers being from China, compared to <strong>20%</strong> from the U.S. and <strong>18%</strong> from Europe (Marco Polo think tank).</li>
<li><strong>US Strengths:</strong> The U.S. attracts and retains a significant portion of global AI talent, employing <strong>59%</strong> of the world’s top AI researchers.</li>
<li><strong>Potential Shift:</strong> Changes in U.S. visa policies, increased efforts by China to retain its researchers, and growing opportunities within China’s tech sector could erode America’s advantage in attracting top talent.</li>
</ul></li>
<li><strong>Computing Power:</strong>
<ul>
<li><strong>Current Situation:</strong> While the U.S. maintains a lead in computing power, China’s dependence on foreign semiconductors, particularly U.S.-designed, Taiwan-manufactured processors, is a major vulnerability.
<ul>
<li>This dependence extends to data centers crucial for AI workloads.</li>
<li>A Chinese study estimates that <strong>95% of GPUs</strong> in Chinese servers running AI applications are NVIDIA-designed, highlighting reliance on U.S. technology.</li>
</ul></li>
<li><strong>China’s Domestic Chip Production Efforts:</strong> While China is investing heavily in domestic chip production, experts predict it will be at least five years before they can design and several more before they can manufacture chips that rival the West.</li>
</ul></li>
<li><strong>China’s Acquisition of U.S. Chips:</strong> Despite export controls, the PLA has managed to acquire U.S.-designed chips for military use.
<ul>
<li>A Georgetown University study analyzing 343 PLA procurement contracts for AI-related systems found that less than <strong>20%</strong> involved companies subject to U.S. export controls.</li>
<li>This indicates the effectiveness of China’s <strong>civil-military fusion</strong> policy, enabling the transfer of advanced civilian technology to military applications.</li>
</ul></li>
</ul>
</section>
</section>
<section id="the-pentagons-response-a-new-offset-strategy" class="level3">
<h3 class="anchored" data-anchor-id="the-pentagons-response-a-new-offset-strategy">The Pentagon’s Response: A New Offset Strategy</h3>
<ul>
<li><strong>Recognizing the Gap:</strong> The Pentagon acknowledges that China’s military modernization efforts have significantly narrowed the capability gap, especially in strategically important regions like the Taiwan Strait.</li>
<li><strong>The Need for a New Offset:</strong> Inspired by the success of the 1970s offset strategy, which leveraged technology to counter the Soviet Union’s numerical advantage, the Pentagon is pursuing a similar approach to maintain military superiority over China.
<ul>
<li>Bob Work, former Deputy Secretary of Defense, stated that the U.S. will not engage in a direct numbers race but will instead focus on achieving a decisive technological advantage.</li>
</ul></li>
<li><strong>Focus on AI and Autonomy:</strong> The new offset centers around advancements in <strong>artificial intelligence (AI)</strong> and <strong>autonomy</strong>.
<ul>
<li>The 1970s offset focused on digital microprocessors, information technologies, new sensors, and stealth technology. Similarly, this new offset emphasizes emerging technologies to maintain a strategic edge.</li>
</ul></li>
</ul>
<section id="key-elements-of-the-new-offset-strategy" class="level4">
<h4 class="anchored" data-anchor-id="key-elements-of-the-new-offset-strategy">Key Elements of the New Offset Strategy</h4>
<ul>
<li><strong>Autonomous Platforms:</strong> The U.S. military is deploying autonomous vehicles like the <strong>SailDrone</strong>, an unmanned wind-powered vessel designed for long-duration maritime missions, including submarine tracking and communication interception.
<ul>
<li>These platforms are cost-effective compared to traditional naval vessels, allowing for wider deployment and greater coverage.</li>
<li>Development and deployment of autonomous surface ships, planes, and submarines are underway.</li>
<li>These platforms rely heavily on AI for navigation, decision-making, and mission execution.</li>
</ul></li>
<li><strong>Distributed Computing and Human-Machine Teaming:</strong>
<ul>
<li><strong>DARPA’s Vision:</strong> DARPA (Defense Advanced Research Projects Agency) envisions a battlefield network of interconnected devices, from large ships to small drones, all capable of communication and coordination. This distributed computing approach aims to enhance situational awareness and decision-making.</li>
<li><strong>Human-Machine Teaming:</strong> DARPA is investing in research on how human operators can effectively team with AI-powered systems. For instance, a fighter pilot could be assisted by a squadron of autonomous drones providing additional sensory input and combat support.</li>
</ul></li>
</ul>
</section>
</section>
<section id="the-electromagnetic-spectrum-a-new-battlefield" class="level3">
<h3 class="anchored" data-anchor-id="the-electromagnetic-spectrum-a-new-battlefield">The Electromagnetic Spectrum: A New Battlefield</h3>
<ul>
<li>The increasing reliance on electronic sensors and communication systems makes the <strong>electromagnetic spectrum</strong> a critical domain in modern warfare.</li>
<li>Control over the electromagnetic spectrum allows militaries to:
<ul>
<li>Transmit critical information.</li>
<li>Detect and track enemy forces.</li>
<li>Disrupt enemy communications and sensor systems.</li>
</ul></li>
<li>Examples of Electromagnetic Spectrum Warfare:
<ul>
<li><strong>Russia’s Tactics in Ukraine:</strong> Russia has deployed radar and signal jammers to disrupt Ukrainian communications and hinder their military operations.</li>
<li><strong>GPS Disruption:</strong> Reports suggest that Russia disrupts GPS signals around President Putin during his travels as a security measure, highlighting the vulnerability of satellite-based navigation systems.</li>
</ul></li>
</ul>
<section id="u.s.-countermeasures" class="level4">
<h4 class="anchored" data-anchor-id="u.s.-countermeasures">U.S. Countermeasures:</h4>
<ul>
<li><strong>DARPA’s Focus on Alternative Navigation:</strong> Recognizing the vulnerability of GPS, DARPA is researching alternative navigation systems that do not rely on GPS satellites. These systems would allow U.S. missiles to strike targets even if GPS systems are compromised.</li>
</ul>
</section>
<section id="the-role-of-semiconductors-in-electromagnetic-spectrum-warfare" class="level4">
<h4 class="anchored" data-anchor-id="the-role-of-semiconductors-in-electromagnetic-spectrum-warfare">The Role of Semiconductors in Electromagnetic Spectrum Warfare:</h4>
<ul>
<li>Semiconductors are essential for radar, jamming, and communication systems.</li>
<li><strong>Radio Frequency (RF) Chips and Digital Analog Converters:</strong> These chips are crucial for:
<ul>
<li>Modulating signals to utilize available spectrum space efficiently.</li>
<li>Transmitting signals directionally.</li>
<li>Confusing enemy sensors.</li>
</ul></li>
<li><strong>Digital Signal Processing Chips:</strong> These chips run complex algorithms within radar and jamming systems to:
<ul>
<li>Analyze incoming signals.</li>
<li>Make real-time decisions on signal transmission.</li>
</ul></li>
<li><strong>Impact on Military Operations:</strong> Mastery of the electromagnetic spectrum is paramount for:
<ul>
<li>Maintaining situational awareness.</li>
<li>Coordinating forces effectively.</li>
<li>Denying these capabilities to adversaries.</li>
</ul></li>
</ul>
</section>
</section>
<section id="darpas-electronics-resurgence-initiative" class="level3">
<h3 class="anchored" data-anchor-id="darpas-electronics-resurgence-initiative">DARPA’s Electronics Resurgence Initiative</h3>
<ul>
<li><strong>Addressing the Challenge:</strong> The U.S. military’s reliance on electronics makes it imperative to maintain leadership in semiconductor technology, especially in the face of China’s growing capabilities.</li>
<li><strong>Reviving Chip Innovation:</strong> DARPA launched the <strong>Electronics Resurgence Initiative (ERI)</strong> in <strong>2017</strong> to bolster the development of next-generation military-relevant chip technology.</li>
<li><strong>Historical Context:</strong> DARPA has a history of funding groundbreaking research in microelectronics, but its influence has waned in recent decades as the commercial sector has grown.</li>
<li><strong>Limited Influence:</strong>
<ul>
<li>DARPA’s budget is dwarfed by the R&amp;D spending of major chipmakers like Intel and Qualcomm.</li>
<li>The U.S. government’s share of global chip purchases has shrunk, diminishing its leverage over the industry.</li>
<li>The immense cost of semiconductor manufacturing, particularly at the leading edge, is prohibitive even for the Pentagon.</li>
</ul></li>
</ul>
</section>
<section id="the-pentagons-dependence-on-foreign-chipmakers" class="level3">
<h3 class="anchored" data-anchor-id="the-pentagons-dependence-on-foreign-chipmakers">The Pentagon’s Dependence on Foreign Chipmakers</h3>
<ul>
<li><strong>Outsourcing Production:</strong> Both the U.S. military and intelligence agencies rely on commercial foundries for chip production.
<ul>
<li>While the U.S. maintains some domestic capacity, particularly for specialized analog and RF chips, it depends heavily on foreign companies, mainly TSMC in Taiwan and Samsung in South Korea, for advanced logic chips.</li>
<li>This dependence raises concerns about:
<ul>
<li><strong>Security Risks:</strong> Potential for tampering, backdoors, or deliberate errors introduced during fabrication or assembly.</li>
<li><strong>Supply Chain Vulnerabilities:</strong> Geopolitical tensions or disruptions in Taiwan or South Korea could severely impact U.S. access to advanced chips.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="the-zero-trust-approach-to-microelectronics" class="level3">
<h3 class="anchored" data-anchor-id="the-zero-trust-approach-to-microelectronics">The “Zero-Trust” Approach to Microelectronics</h3>
<ul>
<li><strong>Verifying Chip Integrity:</strong> DARPA is investing in technologies that can guarantee chip integrity and verify that chips are manufactured as intended. These measures are meant to mitigate the risks associated with reliance on foreign chipmakers.</li>
<li><strong>Zero Trust Philosophy:</strong> The core principle is to trust no component or system by default and rigorously verify everything.</li>
<li><strong>Implementation:</strong> This approach involves using technologies like:
<ul>
<li><strong>On-Chip Sensors:</strong> Tiny sensors embedded on chips can detect tampering attempts or unauthorized modifications.</li>
<li><strong>Advanced Verification Techniques:</strong> Sophisticated testing and analysis methods to ensure chips function exactly as designed and are free from vulnerabilities.</li>
</ul></li>
</ul>
</section>
<section id="the-risks-of-the-run-faster-strategy" class="level3">
<h3 class="anchored" data-anchor-id="the-risks-of-the-run-faster-strategy">The Risks of the “Run-Faster” Strategy</h3>
<ul>
<li><strong>Falling Behind:</strong> The U.S. strategy of simply outspending competitors in chip development, known as the “run-faster” strategy, has lost its effectiveness.</li>
<li><strong>Dependence on Taiwan:</strong> The U.S. has become increasingly reliant on Taiwan for the production of cutting-edge logic chips, a strategic vulnerability given China’s claim over the island.</li>
<li><strong>Intel’s Decline:</strong> Intel, once a global leader in chip manufacturing, has fallen behind competitors like TSMC, potentially undermining the U.S.’s position in the industry.</li>
<li><strong>China’s Rise:</strong> China is aggressively investing in its domestic chip industry, aiming to achieve self-sufficiency and technological leadership.</li>
<li><strong>Challenges to U.S. Dominance:</strong>
<ul>
<li>China’s aggressive pursuit of advanced chip technology.</li>
<li>The global interconnectedness of the electronics industry.</li>
<li>The mutual dependence of the U.S. and China on Taiwan for chip fabrication.</li>
</ul></li>
</ul>
</section>
<section id="chinas-semiconductor-ambitions-a-challenge-to-u.s.-dominance" class="level3">
<h3 class="anchored" data-anchor-id="chinas-semiconductor-ambitions-a-challenge-to-u.s.-dominance">China’s Semiconductor Ambitions: A Challenge to U.S. Dominance</h3>
<ul>
<li><strong>Call to Action:</strong> Chinese President Xi Jinping has called for China to become self-reliant in semiconductor technology, recognizing the strategic importance of this industry.</li>
<li><strong>Multi-Pronged Strategy:</strong> China aims to reshape the global chip landscape through:
<ul>
<li><strong>Acquisitions:</strong> Purchasing foreign chip companies to acquire technology and expertise.</li>
<li><strong>Technology Theft:</strong> Engaging in industrial espionage and intellectual property theft to accelerate its technological progress.</li>
<li><strong>Subsidies:</strong> Providing billions of dollars in government subsidies to support domestic chipmakers.</li>
</ul></li>
<li><strong>PLA’s Reliance on Domestic Chip Efforts:</strong> The Chinese military is counting on the success of these initiatives to reduce its dependence on foreign suppliers, particularly for its “military intelligentization” programs.</li>
<li><strong>Continued Access to U.S. Chips:</strong> Despite U.S. export controls, China continues to acquire American chips through various means, including illicit channels.</li>
</ul>
</section>
<section id="conclusion-a-critical-juncture-in-the-tech-war" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-a-critical-juncture-in-the-tech-war">Conclusion: A Critical Juncture in the Tech War</h3>
<ul>
<li>The competition for technological supremacy, particularly in semiconductors, is intensifying between the U.S. and China.</li>
<li>The outcome of this competition will have significant implications for:
<ul>
<li>Military dominance in the 21st century.</li>
<li>Global technological leadership.</li>
<li>The balance of power in the Indo-Pacific region and beyond.</li>
</ul></li>
<li>The U.S. faces a critical challenge in maintaining its technological edge as China pours resources into closing the gap and reshaping the global semiconductor landscape. The stakes are high, and the outcome remains uncertain.</li>
</ul>
<hr>
</section>
</section>
<section id="chapter-49-everything-were-competing-on" class="level2">
<h2 class="anchored" data-anchor-id="chapter-49-everything-were-competing-on">Chapter 49: Everything We’re Competing On</h2>
<section id="u.s.-chip-industry-concerns-about-china" class="level3">
<h3 class="anchored" data-anchor-id="u.s.-chip-industry-concerns-about-china">U.S. Chip Industry Concerns About China</h3>
<ul>
<li><strong>Problem:</strong> China’s increasing push to dominate the global chip industry.
<ul>
<li>China is a critical market for U.S. chip firms.
<ul>
<li>Firms sell directly to Chinese customers.</li>
<li>Chips are assembled into devices in China.</li>
</ul></li>
<li>China’s government adopted a policy to replace foreign chip firms with domestic ones.</li>
<li>U.S. chip firms were pressured to remain silent about Chinese subsidies.</li>
</ul></li>
<li><strong>Concerns:</strong>
<ul>
<li><strong>China’s Massive Semiconductor Subsidies:</strong>
<ul>
<li>China pledged $250 billion to support domestic chip makers.</li>
<li>A U.S. official expressed concern, stating, “This massive $250 billion fund is going to bury us.”</li>
</ul></li>
<li><strong>Fear of Chinese Dominance:</strong>
<ul>
<li>U.S. officials were alarmed by the fear expressed by Intel CEO Brian Krzanich.</li>
<li>Concern arose from China’s success in driving U.S. solar panel manufacturing out of business.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="initial-u.s.-government-response" class="level3">
<h3 class="anchored" data-anchor-id="initial-u.s.-government-response">Initial U.S. Government Response</h3>
<ul>
<li><strong>Slow Response:</strong> Many senior officials in the Obama administration didn’t consider chips a crucial issue.</li>
<li><strong>Shifting Perspectives:</strong>
<ul>
<li>Trade negotiators: Viewed China’s subsidies as a violation of international agreements.</li>
<li>Pentagon: Concerned about China’s use of computing power in weapons systems.</li>
<li>Intelligence agencies and Justice Department: Found evidence of China’s efforts to push out U.S. chip firms.</li>
</ul></li>
<li><strong>Obstacles to Action:</strong>
<ul>
<li>Deeply ingrained belief in globalization and the need to “run faster” (innovate more quickly).</li>
<li>Strong lobbying by the tech industry.</li>
<li>Lack of understanding about semiconductors among Washington officials.</li>
</ul></li>
</ul>
</section>
<section id="late-obama-administration-actions" class="level3">
<h3 class="anchored" data-anchor-id="late-obama-administration-actions">Late Obama Administration Actions</h3>
<ul>
<li><strong>Penny Pritzker’s Address (Late 2016):</strong>
<ul>
<li>Declared the importance of U.S. leadership in semiconductor technology.</li>
<li>Condemned China’s “unfair trade practices,” “massive non-market-based state intervention,” and attempts to acquire companies and technology for government interests rather than commercial objectives.</li>
<li>Ordered a study of the semiconductor supply chain.</li>
<li>Pledged to challenge China’s $150 billion industrial policy aimed at dominating the industry.</li>
</ul></li>
<li><strong>Semiconductor Industry Report:</strong>
<ul>
<li>Commissioned by the White House and issued in late 2016.</li>
<li>Urged the U.S. to “win the race by running faster” – focusing on innovation.</li>
</ul></li>
</ul>
</section>
<section id="critique-of-u.s.-tech-policy" class="level3">
<h3 class="anchored" data-anchor-id="critique-of-u.s.-tech-policy">Critique of U.S. Tech Policy</h3>
<ul>
<li><strong>Flawed Assumptions:</strong>
<ul>
<li><strong>Globalization:</strong> The report claimed “unilateral action is increasingly ineffective in a world where the semiconductor industry is globalized.” This ignored the reality of Taiwan’s dominance in fabrication, not true globalization.</li>
<li><strong>Technology Diffusion:</strong> The report stated, “Policy can, in principle, slow the diffusion of technology, but it cannot stop the spread.” This was not supported by evidence.</li>
</ul></li>
<li><strong>Consequences of Inaction:</strong>
<ul>
<li><strong>Erosion of U.S. Lead:</strong> The U.S. lost its technological edge in fabrication and lithography due to a laissez-faire approach while Asian governments actively supported their chip industries.</li>
<li><strong>Dependence on Vulnerable Chokepoints:</strong> The U.S. became reliant on a few key players, especially Taiwan, for critical semiconductor production.</li>
</ul></li>
<li><strong>Silicon Valley Complicity:</strong> The chip industry, fearing Chinese retaliation, downplayed the severity of the situation and advocated for continued engagement with China.</li>
<li><strong>Dangerous Inertia:</strong> The focus on “multilateralism,” “globalization,” and “innovation” masked the deteriorating U.S. position and the rise of China.</li>
</ul>
</section>
<section id="the-national-security-perspective" class="level3">
<h3 class="anchored" data-anchor-id="the-national-security-perspective">The National Security Perspective</h3>
<ul>
<li><strong>Growing Concerns:</strong>
<ul>
<li>China’s leverage over critical technology systems.</li>
<li>Potential for espionage through Chinese-manufactured electronics.</li>
<li>Reliance on foreign (particularly Chinese) companies for telecom equipment.</li>
</ul></li>
<li><strong>ZTE and Huawei:</strong>
<ul>
<li>Both Chinese telecom equipment providers raised concerns.</li>
<li>ZTE: State-owned.</li>
<li>Huawei: Private, but with alleged close ties to the Chinese government.</li>
<li>Both companies faced accusations of bribery and sanctions violations.</li>
<li><strong>Obama Administration Action:</strong> Restricted U.S. firms from selling to ZTE in 2016. ZTE signed a plea deal, paid a fine, and the restrictions were lifted.</li>
<li>The ZTE case highlighted the global dependence on U.S. chips.</li>
</ul></li>
</ul>
</section>
<section id="trump-administration-shift" class="level3">
<h3 class="anchored" data-anchor-id="trump-administration-shift">Trump Administration Shift</h3>
<ul>
<li><strong>Focus on Technology:</strong> Trump’s focus on trade and tariffs was seen as a distraction from the technological competition with China.</li>
<li><strong>China Hawks on the NSC:</strong>
<ul>
<li>Led by Matt Pottinger.</li>
<li>Believed America’s position had weakened.</li>
<li>Rejected “running faster” as a viable strategy.</li>
<li>Adopted a more aggressive, zero-sum approach.</li>
</ul></li>
<li><strong>Semiconductors as a Priority:</strong> The NSC recognized semiconductors as crucial to 21st-century competition, stating, “Everything we’re competing on in the 21st century, all of it rests on the cornerstone of semiconductor mastery.”</li>
<li><strong>Government-Wide Focus:</strong> Various government entities, from Congress to the Pentagon, began prioritizing semiconductors in their China strategies.</li>
</ul>
</section>
<section id="industry-friction-and-dependence-on-china" class="level3">
<h3 class="anchored" data-anchor-id="industry-friction-and-dependence-on-china">Industry Friction and Dependence on China</h3>
<ul>
<li><strong>Industry Discomfort:</strong> Chip industry leaders were wary of Chinese retaliation and preferred less disruptive government intervention.</li>
<li><strong>Contradictory Messages:</strong>
<ul>
<li><strong>Publicly:</strong> Semiconductor CEOs urged cooperation with China.</li>
<li><strong>Privately:</strong> They admitted this strategy was failing and feared Chinese competition.</li>
</ul></li>
<li><strong>Dependence on China:</strong> The entire chip industry relied on sales to China, making them vulnerable to pressure from Beijing.</li>
<li><strong>“Our Fundamental Problem”:</strong> One U.S. semiconductor executive stated to a White House official, “Our fundamental problem is that our number one customer is our number one competitor.”</li>
</ul>
</section>
<section id="nsc-intervention" class="level3">
<h3 class="anchored" data-anchor-id="nsc-intervention">NSC Intervention</h3>
<ul>
<li><strong>Saving the Industry from Itself:</strong> The NSC believed the U.S. semiconductor industry would continue transferring technology and expertise to China unless drastic measures were taken.</li>
<li><strong>Strengthening Export Controls:</strong> The NSC advocated for stricter export controls to prevent the transfer of critical chip-making technologies.</li>
</ul>
</section>
<section id="shifting-government-focus" class="level3">
<h3 class="anchored" data-anchor-id="shifting-government-focus">Shifting Government Focus</h3>
<ul>
<li><strong>Media Focus on Trade War:</strong> Media attention was on Trump’s tariffs, but the national security bureaucracy saw this as a sideshow to the larger technological struggle.</li>
</ul>
</section>
<section id="the-zte-case-revisited" class="level3">
<h3 class="anchored" data-anchor-id="the-zte-case-revisited">The ZTE Case Revisited</h3>
<ul>
<li><strong>Violation of Plea Agreement (April 2018):</strong> The Trump administration found ZTE in violation of its 2016 plea agreement.</li>
<li><strong>Reimposition of Restrictions:</strong> The Commerce Department, led by Wilbur Ross, prohibited U.S. companies from selling to ZTE.</li>
<li><strong>Trump’s Intervention:</strong> Trump saw ZTE’s potential collapse as leverage in trade negotiations with Xi Jinping and intervened to save the company.</li>
<li><strong>ZTE Agreement:</strong> ZTE paid another fine and regained access to U.S. suppliers.</li>
<li><strong>Differing Views:</strong>
<ul>
<li>Trump: Believed he gained leverage in trade talks.</li>
<li>China Hawks: Believed Trump was manipulated by officials like Treasury Secretary Steven Mnuchin.</li>
</ul></li>
</ul>
</section>
<section id="weaponizing-semiconductors" class="level3">
<h3 class="anchored" data-anchor-id="weaponizing-semiconductors">Weaponizing Semiconductors</h3>
<ul>
<li><strong>The ZTE Case as a Lesson:</strong> The ZTE incident revealed the United States’ power over global tech firms due to their reliance on U.S. chips.</li>
<li><strong>Shifting Power Dynamics:</strong> Semiconductors were no longer just a cornerstone of competition but a potent weapon.</li>
</ul>
</section>
</section>
<section id="chapter-50-fujian-jinhua" class="level2">
<h2 class="anchored" data-anchor-id="chapter-50-fujian-jinhua">Chapter 50: Fujian Jinhua</h2>
<section id="the-micron-case" class="level3">
<h3 class="anchored" data-anchor-id="the-micron-case">The Micron Case</h3>
<ul>
<li><strong>Kenny Wang and Intellectual Property Theft:</strong>
<ul>
<li>Kenny Wang, an employee at Micron’s Taiwan facility, downloaded 900 confidential files.</li>
<li>These files contained Micron’s trade secrets for DRAM chip production, including chip layouts, mask details, and yield information.</li>
<li>Wang transferred the files to a USB drive and uploaded them to Google Drive.</li>
<li>Micron estimated it would take years and millions of dollars to replicate the stolen information.</li>
</ul></li>
<li><strong>The DRAM Market:</strong>
<ul>
<li>Dominated by three companies:
<ul>
<li>Micron (U.S.)</li>
<li>Samsung (South Korea)</li>
<li>SK Hynix (South Korea)</li>
</ul></li>
<li>High barriers to entry due to economies of scale and specialized expertise.</li>
</ul></li>
</ul>
</section>
<section id="jinhuas-strategy" class="level3">
<h3 class="anchored" data-anchor-id="jinhuas-strategy">Jinhua’s Strategy</h3>
<ul>
<li><strong>Fujian Jinhua:</strong>
<ul>
<li>A state-funded Chinese DRAM chip maker.</li>
<li>Received over $5 billion in government subsidies.</li>
</ul></li>
<li><strong>Partnership with UMC:</strong>
<ul>
<li>Jinhua partnered with Taiwan’s UMC (United Microelectronics Corporation), a logic chip maker, to gain DRAM expertise.</li>
<li>UMC received around $700 million from Jinhua.</li>
</ul></li>
<li><strong>Poaching Micron Employees:</strong>
<ul>
<li>UMC hired key personnel from Micron’s Taiwan facility, including Stephen Chen (former president) and J.T. Ho (process manager).</li>
<li>Kenny Wang joined UMC, bringing the stolen Micron files with him.</li>
</ul></li>
</ul>
</section>
<section id="legal-battles-and-chinese-retaliation" class="level3">
<h3 class="anchored" data-anchor-id="legal-battles-and-chinese-retaliation">Legal Battles and Chinese Retaliation</h3>
<ul>
<li><strong>Micron’s Lawsuit:</strong> Micron sued UMC and Jinhua for patent infringement.</li>
<li><strong>UMC and Jinhua’s Counter-Suit:</strong> They counter-sued in a Fujian court.</li>
<li><strong>Fujian Court Ruling:</strong> The Fujian court ruled in favor of UMC and Jinhua, despite the patents being based on stolen Micron technology.</li>
<li><strong>Ban on Micron Sales:</strong> The court banned Micron from selling 26 products in China, its largest market.</li>
<li><strong>Vico Case (Parallel Example):</strong> A similar case involved Vico (U.S.) and AMEC (China), highlighting the tendency of Chinese courts to favor domestic companies in intellectual property disputes.</li>
</ul>
</section>
<section id="the-trump-administrations-response" class="level3">
<h3 class="anchored" data-anchor-id="the-trump-administrations-response">The Trump Administration’s Response</h3>
<ul>
<li><strong>Escalation Beyond Statements:</strong> Unlike the Obama administration, the Trump administration was prepared to take concrete action.</li>
<li><strong>Export Restrictions on Jinhua:</strong> The U.S. banned the sale of critical U.S.-made chip-making equipment to Jinhua.</li>
<li><strong>Japanese Support:</strong> Japan, a key producer of chip-making equipment, supported the U.S. restrictions.</li>
<li><strong>Chokehold on Jinhua:</strong> Without access to U.S. equipment, Jinhua’s production halted, effectively destroying China’s most advanced DRAM company.</li>
</ul>
</section>
<section id="weaponizing-interdependence" class="level3">
<h3 class="anchored" data-anchor-id="weaponizing-interdependence">Weaponizing Interdependence</h3>
<ul>
<li><strong>U.S. Leverage:</strong> The case demonstrated the U.S. government’s ability to leverage its control over critical chokepoints in the semiconductor supply chain.</li>
<li><strong>“Why the Fuck Wouldn’t We Do This”:</strong> Commerce Secretary Wilbur Ross, according to an aide, saw the use of export controls as a powerful and necessary tool.</li>
</ul>
</section>
</section>
<section id="chapter-51-the-assault-on-huawei" class="level2">
<h2 class="anchored" data-anchor-id="chapter-51-the-assault-on-huawei">Chapter 51: The Assault on Huawei</h2>
<section id="huawei-as-a-national-security-threat" class="level3">
<h3 class="anchored" data-anchor-id="huawei-as-a-national-security-threat">Huawei as a National Security Threat</h3>
<ul>
<li><strong>“Spyway”:</strong> Trump labeled Huawei “the spyway” and accused it of espionage.</li>
<li><strong>Beyond Espionage:</strong> The Pentagon and NSC saw Huawei as a strategic threat, representing China’s growing dominance in critical technology sectors.</li>
<li><strong>Matt Turpin’s View:</strong> A Pentagon official, saw Huawei’s access to U.S. technology as a symptom of a larger problem in the U.S.-China tech relationship.</li>
<li><strong>“Proxy for Everything We Had Done Wrong”:</strong> A senior Trump administration official said Huawei represented the failures in the U.S. approach to tech competition with China.</li>
</ul>
</section>
<section id="global-concerns-and-actions" class="level3">
<h3 class="anchored" data-anchor-id="global-concerns-and-actions">Global Concerns and Actions</h3>
<ul>
<li><strong>Australia’s Ban:</strong> Australia banned Huawei from its 5G networks, citing unmitigable security risks.</li>
<li><strong>Other Bans:</strong> Japan, New Zealand, and other countries followed suit.</li>
<li><strong>European Responses:</strong>
<ul>
<li><strong>Divided Approach:</strong> European countries were divided in their response to U.S. pressure to ban Huawei.</li>
<li><strong>Outright Bans:</strong> Poland and other Eastern European countries banned Huawei.</li>
<li><strong>Restrictions:</strong> France imposed strict limitations on Huawei.</li>
<li><strong>Seeking Middle Ground:</strong> Germany faced Chinese pressure to not ban Huawei and attempted to find a compromise.</li>
<li><strong>UK’s Initial Resistance:</strong> The UK initially resisted a ban, but later changed its stance.</li>
</ul></li>
</ul>
</section>
<section id="the-debate-over-huawei" class="level3">
<h3 class="anchored" data-anchor-id="the-debate-over-huawei">The Debate Over Huawei</h3>
<ul>
<li><strong>Technical vs.&nbsp;Strategic:</strong> The debate went beyond technical assessments of Huawei’s security risks to encompass broader strategic concerns about China’s role in global tech infrastructure.</li>
<li><strong>Robert Hannigan’s Argument:</strong> The former head of the UK’s GCHQ (Signals Intelligence Agency) argued that China’s tech power was inevitable and the West should focus on managing the risks rather than trying to halt its rise.</li>
<li><strong>U.S. Zero-Sum Approach:</strong> The U.S. adopted a zero-sum perspective, viewing Huawei’s success as detrimental to U.S. interests.</li>
</ul>
</section>
<section id="escalating-u.s.-actions" class="level3">
<h3 class="anchored" data-anchor-id="escalating-u.s.-actions">Escalating U.S. Actions</h3>
<ul>
<li><strong>Initial Restrictions:</strong> The Trump administration initially banned U.S. companies from directly selling chips to Huawei.</li>
<li><strong>Targeting Huawei’s Supply Chain:</strong> The administration then imposed broader restrictions, prohibiting the sale of any chips made using U.S. technology to Huawei, even if manufactured outside the U.S.</li>
<li><strong>Exploiting Chokepoints:</strong> This strategy exploited the U.S. dominance in critical areas of chip design and manufacturing:
<ul>
<li><strong>Software:</strong> Almost all chips rely on software from U.S. companies (Cadence, Synopsys, Mentor Graphics).</li>
<li><strong>Fabrication:</strong> Advanced logic chips are primarily fabricated by TSMC (Taiwan) and Samsung (South Korea), both reliant on U.S. military support.</li>
<li><strong>EUV Lithography:</strong> The most advanced chips require EUV lithography machines from ASML (Netherlands), which depend on critical components from their U.S. subsidiary.</li>
</ul></li>
</ul>
</section>
<section id="weaponized-interdependence-in-action" class="level3">
<h3 class="anchored" data-anchor-id="weaponized-interdependence-in-action">Weaponized Interdependence in Action</h3>
<ul>
<li><strong>“Weaponized Interdependence”:</strong> Academics Henry Farrell and Abraham Newman coined the term to describe the use of economic interdependence as a tool of coercion.</li>
<li><strong>TSMC’s Compliance:</strong> Despite being Huawei’s largest customer, TSMC complied with U.S. restrictions.</li>
<li><strong>Huawei’s Decline:</strong> The restrictions crippled Huawei’s smartphone and server businesses, forcing it to divest and delaying China’s 5G rollout.</li>
<li><strong>Blacklisting Other Chinese Firms:</strong> The U.S. blacklisted other Chinese tech firms, including Sugon (supercomputers) and Phytium (high-performance computing).</li>
</ul>
</section>
<section id="chinas-response-and-the-future-of-the-tech-war" class="level3">
<h3 class="anchored" data-anchor-id="chinas-response-and-the-future-of-the-tech-war">China’s Response and the Future of the Tech War</h3>
<ul>
<li><strong>Limited Retaliation:</strong> Despite threats, China has not taken significant retaliatory action against U.S. tech firms.</li>
<li><strong>U.S. Escalation Dominance:</strong> The U.S. appears to hold the upper hand in the semiconductor sector, capable of inflicting greater damage through supply chain disruptions.</li>
<li><strong>“A Beautiful Thing”:</strong> A former senior official, reflecting on the effectiveness of weaponized interdependence, called it “a beautiful thing.”</li>
</ul>
</section>
</section>
<section id="chapter-52-chinas-sputnik-moment" class="level2">
<h2 class="anchored" data-anchor-id="chapter-52-chinas-sputnik-moment">Chapter 52: China’s Sputnik Moment</h2>
<section id="wuhan-lockdown-and-ymtc" class="level3">
<h3 class="anchored" data-anchor-id="wuhan-lockdown-and-ymtc">Wuhan Lockdown and YMTC</h3>
<ul>
<li><strong>Yangtze Memory Technologies Corporation (YMTC)</strong>: China’s leading producer of NAND memory chips, located in Wuhan.
<ul>
<li>NAND memory is a type of chip used in smartphones, USB drives, and other devices.</li>
<li>Five companies currently make competitive NAND chips, none headquartered in China.</li>
<li>YMTC is considered China’s best chance to achieve world-class chip manufacturing capabilities in NAND production.</li>
</ul></li>
<li><strong>Government Support for YMTC</strong>:
<ul>
<li>Received at least <strong>$24 billion</strong> in funding from Xinhua Unigroup, China’s National Chip Fund, and the provincial government.</li>
<li>Allowed to operate during the Wuhan COVID lockdown, highlighting the government’s prioritization of the semiconductor industry.
<ul>
<li>Special train cars transported YMTC employees despite travel restrictions.</li>
<li>The company continued hiring even as the rest of the country remained in lockdown.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="chinas-sputnik-moment" class="level3">
<h3 class="anchored" data-anchor-id="chinas-sputnik-moment">China’s “Sputnik Moment”</h3>
<ul>
<li><strong>US Chip Sanctions</strong>: The US ban on selling chips to firms like Huawei is seen as a “Sputnik moment” for China, similar to the US’s reaction to the Soviet Union’s launch of Sputnik in 1957.</li>
<li><strong>Impact of US Restrictions</strong>:
<ul>
<li><strong>Dan Wang</strong>, a China tech policy analyst, argues that US restrictions have inadvertently boosted China’s pursuit of tech dominance.
<ul>
<li>Restrictions catalyzed new government policies and increased funding for the Chinese chip industry.</li>
<li>Without US pressure, Wang believes China’s “Made in China 2025” plan would have likely resulted in wasted resources.</li>
</ul></li>
</ul></li>
<li><strong>Debate on US Strategy</strong>:
<ul>
<li>Should the US attempt to derail China’s chip ecosystem, risking an inevitable counter-reaction?</li>
<li>Or is it more strategic for the US to focus on domestic investment and hope China’s efforts falter?</li>
</ul></li>
<li><strong>China’s Response</strong>:
<ul>
<li>Increased government support for Chinese chipmakers, with <strong>Xi Jinping</strong> appointing <strong>Liu He</strong> as “chip czar” to manage semiconductor efforts.</li>
<li>Billions of dollars in subsidies for chip firms, although the effectiveness of this funding remains to be seen.</li>
</ul></li>
</ul>
</section>
<section id="challenges-and-failures-in-chinas-chip-drive" class="level3">
<h3 class="anchored" data-anchor-id="challenges-and-failures-in-chinas-chip-drive">Challenges and Failures in China’s Chip Drive</h3>
<ul>
<li><strong>Wuhan Hangxin (HSMC) Scam</strong>: An example of the risks associated with excessive subsidies without proper oversight.
<ul>
<li>A group of scammers deceived the Wuhan government into investing in their fake chip company, HSMC.</li>
<li>They used the funds to hire TSMC’s former head of R&amp;D, acquired an ASML lithography machine, and raised more capital from investors.</li>
<li>The HSMC factory, a poorly constructed copy of an older TSMC facility, went bankrupt before producing a single chip.</li>
</ul></li>
<li><strong>Tsinghua Unigroup’s Financial Troubles</strong>:
<ul>
<li>The semiconductor investment fund experienced a cash shortage after a global acquisition spree and defaulted on some of its bonds.</li>
<li>Despite political connections, the firm required government intervention to avoid collapse.</li>
</ul></li>
<li><strong>Lack of Experience and Talent</strong>: A Chinese government official acknowledged the country’s lack of experience, technology, and talent in the chip industry.</li>
<li><strong>Wasteful Spending</strong>: Billions of dollars have been wasted on unrealistic or fraudulent semiconductor projects in China.</li>
</ul>
</section>
<section id="challenges-to-chinas-technological-independence" class="level3">
<h3 class="anchored" data-anchor-id="challenges-to-chinas-technological-independence">Challenges to China’s Technological Independence</h3>
<ul>
<li><strong>Multinational Supply Chains</strong>: Achieving complete technological independence in an industry with such complex and interconnected supply chains is incredibly difficult, even for the US.
<ul>
<li>China lacks competitive firms in key parts of the supply chain, including machinery and software, making independence even more challenging.</li>
</ul></li>
<li><strong>Replicating ASML’s EUV Machines</strong>:
<ul>
<li>EUV machines, crucial for producing advanced chips, took ASML almost three decades to develop and commercialize.</li>
<li>Replicating just the laser component requires assembling <strong>457,329 parts</strong> flawlessly.</li>
<li>Even with stolen design specs, the complexity of these machines cannot be easily replicated without decades of engineering experience and expertise.</li>
</ul></li>
<li><strong>High Cost of Domestication</strong>:
<ul>
<li>Domesticating every aspect of the chip supply chain would be astronomically expensive.</li>
<li>The global chip industry spends over <strong>$100 billion</strong> annually on capital expenditures.</li>
<li>China would need to match this spending while also building a foundation of expertise and infrastructure, costing well over <strong>$1 trillion</strong> over a decade.</li>
</ul></li>
</ul>
</section>
<section id="chinas-pragmatic-approach" class="level3">
<h3 class="anchored" data-anchor-id="chinas-pragmatic-approach">China’s Pragmatic Approach</h3>
<ul>
<li><strong>Focus on Reducing US Reliance</strong>: China recognizes the impossibility of complete domestication and instead aims to lessen its reliance on the US in specific areas and increase its overall influence in the chip industry.</li>
<li><strong>Embracing RISC-V Architecture</strong>:
<ul>
<li>RISC-V is an open-source instruction set architecture, offering a free alternative to the dominant x86 (Intel, AMD) and ARM architectures.</li>
<li>Its open nature potentially reduces security risks, fosters faster innovation, and appeals to Chinese companies seeking geopolitical neutrality.</li>
<li>Alibaba is among the Chinese firms designing processors based on RISC-V.</li>
</ul></li>
<li><strong>Leveraging Older Process Technology</strong>:
<ul>
<li>While smartphones and data centers demand cutting-edge chips, other devices like cars can function on older, cheaper technology.</li>
<li>China is investing heavily in lagging-edge logic chip production, a segment less vulnerable to US export restrictions on older equipment.</li>
</ul></li>
<li><strong>Investing in Emerging Materials</strong>:
<ul>
<li>China is focusing on silicon carbide and gallium nitride, materials with potential in electric vehicle power management systems.</li>
<li>Government subsidies in this area could give Chinese companies a competitive price advantage.</li>
</ul></li>
<li><strong>Growing Market Share</strong>:
<ul>
<li>China’s share of global chip fabrication is projected to rise from <strong>15%</strong> to <strong>24%</strong> by 2030, surpassing Taiwan and South Korea in volume, although potentially lagging behind technologically.</li>
<li>This increased market share could give China more leverage in demanding technology transfer and make it costlier for the US to impose export restrictions.</li>
</ul></li>
</ul>
</section>
<section id="chinas-semiconductor-ambitions-national-goals-over-profits" class="level3">
<h3 class="anchored" data-anchor-id="chinas-semiconductor-ambitions-national-goals-over-profits">China’s Semiconductor Ambitions: National Goals over Profits</h3>
<ul>
<li>Chinese chip firms prioritize national goals over profit-making and going public.</li>
<li>Their focus is on building a domestic chip industry and realizing the “Chinese dream,” as stated by a YMTC executive.</li>
<li>Their dependence on government support aligns them with national objectives.</li>
</ul>
</section>
</section>
<section id="chapter-53-shortages-and-supply-chains" class="level2">
<h2 class="anchored" data-anchor-id="chapter-53-shortages-and-supply-chains">Chapter 53: Shortages and Supply Chains</h2>
<section id="the-global-chip-shortage" class="level3">
<h3 class="anchored" data-anchor-id="the-global-chip-shortage">The Global Chip Shortage</h3>
<ul>
<li><strong>President Biden’s Meeting</strong>:
<ul>
<li>Convened a meeting with CEOs of chipmakers (Intel, TSMC), automakers (Ford, GM), and other companies to address the global chip shortage.</li>
<li>Emphasized the need for increased US investment in semiconductor R&amp;D and manufacturing.</li>
</ul></li>
<li><strong>Causes of the Shortage</strong>:
<ul>
<li><strong>Demand Surge</strong>: The shortage stemmed primarily from a surge in demand for electronics (PCs, servers, 5G phones) during the pandemic, not just supply chain disruptions.
<ul>
<li>Work-from-home and online trends fueled PC and data center demand.</li>
</ul></li>
<li><strong>Auto Industry Miscalculations</strong>:
<ul>
<li>Carmakers exacerbated the shortage by initially canceling chip orders, anticipating a sales slump that didn’t materialize.</li>
<li>Their “just-in-time” manufacturing practices offered little buffer against disruptions.</li>
</ul></li>
<li><strong>Chinese Stockpiling</strong>: Chinese firms, anticipating US sanctions, stockpiled chips, adding to the demand pressure.</li>
</ul></li>
<li><strong>Supply Chain Resilience</strong>:
<ul>
<li>Despite some disruptions (e.g., lockdowns in Malaysia affecting packaging), the semiconductor industry demonstrated remarkable resilience, producing a record <strong>1.1 trillion</strong> chips in 2021 (a <strong>13%</strong> increase from 2020).</li>
<li>The shortage highlighted the industry’s ability to adapt rather than its fragility.</li>
</ul></li>
</ul>
</section>
<section id="geopolitics-and-the-future-of-chipmaking" class="level3">
<h3 class="anchored" data-anchor-id="geopolitics-and-the-future-of-chipmaking">Geopolitics and the Future of Chipmaking</h3>
<ul>
<li><strong>Taiwan’s Strategic Importance</strong>:
<ul>
<li>Taiwan’s dominance in advanced chipmaking, epitomized by TSMC’s success, underscores the strategic importance of the semiconductor industry.</li>
<li>TSMC’s control over a critical chokepoint grants Taiwan significant leverage.</li>
</ul></li>
<li><strong>US Efforts to Secure Supply Chains</strong>:
<ul>
<li>Recognizing the vulnerability of relying on Asian chip production, the US is:
<ul>
<li>Pressuring TSMC and Samsung to build new fabs in the US.</li>
<li>Exploring ways to incentivize or pressure TSMC to locate its most advanced production in the US.</li>
</ul></li>
</ul></li>
<li><strong>Global Competition for Chip Dominance</strong>:
<ul>
<li>The US, Europe, Asia, and China are all vying for a larger share of the chip market, particularly in high-value design and advanced fabrication.</li>
<li>This competition could lead to a realignment of the global semiconductor landscape.</li>
</ul></li>
</ul>
</section>
<section id="south-koreas-balancing-act" class="level3">
<h3 class="anchored" data-anchor-id="south-koreas-balancing-act">South Korea’s Balancing Act</h3>
<ul>
<li><strong>Government Support and Industry Leadership</strong>:
<ul>
<li>South Korea, led by Samsung and SK Hynix, benefits from strong government support and aims to maintain its leading position in memory chips while expanding in logic chip production.</li>
</ul></li>
<li><strong>Samsung’s Ambitious Investments</strong>:
<ul>
<li>Samsung plans to invest over <strong>$100 billion</strong> in its logic chip business by 2030, along with substantial investments in memory chips.</li>
</ul></li>
<li><strong>Pressure from Both Sides</strong>:
<ul>
<li>The US and China are both vying for South Korean chip investment.</li>
<li>Samsung faces US scrutiny over plans to upgrade its Chinese facilities and pressure to restrict the transfer of advanced EUV tools to SK Hynix’s facility in China.</li>
</ul></li>
</ul>
</section>
<section id="taiwans-silicon-shield" class="level3">
<h3 class="anchored" data-anchor-id="taiwans-silicon-shield">Taiwan’s “Silicon Shield”</h3>
<ul>
<li><strong>TSMC’s Continued Dominance</strong>:
<ul>
<li>Taiwan remains committed to protecting its chip industry, seeing it as a source of leverage and a “silicon shield” against Chinese aggression.</li>
<li>TSMC plans to invest over <strong>$100 billion</strong> between 2022 and 2024, mostly in Taiwan, while also upgrading facilities in Nanjing, China, and opening a new fab in Arizona.</li>
</ul></li>
<li><strong>Government Support and Strategic Importance</strong>:
<ul>
<li>The Taiwanese government actively supports TSMC through measures such as currency manipulation and trade negotiations.</li>
<li>TSMC’s founder, Morris Chang, serves as a trade envoy, advocating for free trade in semiconductors.</li>
</ul></li>
</ul>
</section>
<section id="other-players-in-the-global-chip-game" class="level3">
<h3 class="anchored" data-anchor-id="other-players-in-the-global-chip-game">Other Players in the Global Chip Game</h3>
<ul>
<li><strong>European Union</strong>:
<ul>
<li>Aspires to increase its share of advanced chip fabrication but faces challenges due to its low market share in advanced logic chips.</li>
<li>More realistically, Europe may focus on attracting foreign chipmakers to build fabs that can provide a stable supply for European automakers.</li>
</ul></li>
<li><strong>Singapore</strong>:
<ul>
<li>Continues to attract chipmaking investments with substantial incentives, recently securing a <strong>$4 billion</strong> investment from GlobalFoundries for a new fab.</li>
</ul></li>
<li><strong>Japan</strong>:
<ul>
<li>Seeking to revitalize its chipmaking industry, Japan is subsidizing TSMC to build a new facility in partnership with Sony.</li>
<li>This move aims to prevent the further erosion of Japan’s expertise in chipmaking equipment and materials.</li>
</ul></li>
</ul>
</section>
<section id="intels-bid-for-resurgence" class="level3">
<h3 class="anchored" data-anchor-id="intels-bid-for-resurgence">Intel’s Bid for Resurgence</h3>
<ul>
<li><strong>New Leadership and Ambitious Strategy</strong>:
<ul>
<li>Under CEO Pat Gelsinger, Intel is pursuing a three-pronged strategy to regain its leadership position:
<ol type="1">
<li><strong>Manufacturing Leadership</strong>: Aiming to overtake Samsung and TSMC in advanced chipmaking by securing the first next-generation EUV machine, expected in 2025.</li>
<li><strong>Foundry Business</strong>: Launching a foundry business to manufacture chips for other companies, directly competing with Samsung and TSMC. Requires securing customers producing at the cutting edge to be viable.</li>
<li><strong>Government Support</strong>: Leveraging US and European government subsidies to build new fabs domestically while promoting concerns about reliance on Asian chip production.</li>
</ol></li>
</ul></li>
<li><strong>Dependence on TSMC</strong>: Ironically, while advocating for a more balanced supply chain, Intel is increasingly outsourcing its own advanced chip production to TSMC in Taiwan.</li>
</ul>
</section>
<section id="the-taiwan-dilemma-risk-and-interdependence" class="level3">
<h3 class="anchored" data-anchor-id="the-taiwan-dilemma-risk-and-interdependence">The Taiwan Dilemma: Risk and Interdependence</h3>
<ul>
<li><strong>TSMC’s Vulnerability</strong>: TSMC’s dominance makes it a strategic target in potential conflicts between China and Taiwan.
<ul>
<li>TSMC’s chairman downplays the risk of war, highlighting the economic interdependence and shared interest in a peaceful Taiwan Strait.</li>
<li>However, China’s military exercises near Taiwan and its stated goal of “reunification” raise concerns about the long-term stability of the region.</li>
</ul></li>
<li><strong>China’s Military Capabilities</strong>:
<ul>
<li>The PLA possesses a range of capabilities to pressure or attack Taiwan, including amphibious assaults, blockades, and air and missile strikes.</li>
<li>The military balance in the Taiwan Strait has shifted in China’s favor.</li>
</ul></li>
<li><strong>The “Salami Slicing” Strategy</strong>: China could attempt to gradually assert control over Taiwan through incremental actions, such as seizing outlying islands or imposing limited blockades.</li>
<li><strong>US Dilemma</strong>: The US faces a difficult choice in responding to Chinese aggression against Taiwan.
<ul>
<li>Direct military intervention carries significant risks, including escalation to a larger conflict.</li>
<li>Inaction could embolden China and undermine US credibility, potentially leading to a scenario where China gains influence over TSMC’s chip production.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-54-the-taiwan-dilemma" class="level2">
<h2 class="anchored" data-anchor-id="chapter-54-the-taiwan-dilemma">Chapter 54: The Taiwan Dilemma</h2>
<section id="tsmc-and-the-global-chip-supply" class="level3">
<h3 class="anchored" data-anchor-id="tsmc-and-the-global-chip-supply">TSMC and the Global Chip Supply</h3>
<ul>
<li><strong>Investor Concerns</strong>: The growing geopolitical tensions surrounding Taiwan have made investors increasingly aware of the risks to TSMC’s operations.</li>
<li><strong>TSMC’s Reassurance</strong>: TSMC’s chairman downplays the risk of war, emphasizing the global economic interdependence and the shared interest in a stable Taiwan Strait.</li>
<li><strong>China’s Military Exercises</strong>: Despite reassurances, China’s military conducts exercises near Taiwan, simulating amphibious assaults and highlighting the potential for conflict.</li>
</ul>
</section>
<section id="scenarios-for-conflict" class="level3">
<h3 class="anchored" data-anchor-id="scenarios-for-conflict">Scenarios for Conflict</h3>
<ul>
<li><strong>D-Day Style Invasion</strong>:
<ul>
<li>While China could attempt a full-scale amphibious invasion of Taiwan, this option is considered the most challenging and least likely due to the high risk of failure.</li>
</ul></li>
<li><strong>Blockade</strong>:
<ul>
<li>A partial air and maritime blockade would be difficult for Taiwan to overcome alone.</li>
<li>Even with US and Japanese support, breaking a blockade would be challenging and could escalate into a larger war.</li>
</ul></li>
<li><strong>Air and Missile Campaign</strong>:
<ul>
<li>A sustained air and missile campaign could cripple Taiwan’s military and economy without requiring a ground invasion.</li>
</ul></li>
<li><strong>Limited Military Pressure</strong>:
<ul>
<li>China could apply pressure through tactics like harassing shipping traffic or demanding TSMC produce chips for Chinese companies, testing US resolve and potentially eroding Taiwan’s morale.</li>
</ul></li>
</ul>
</section>
<section id="the-stakes-global-economic-impact-of-a-taiwan-crisis" class="level3">
<h3 class="anchored" data-anchor-id="the-stakes-global-economic-impact-of-a-taiwan-crisis">The Stakes: Global Economic Impact of a Taiwan Crisis</h3>
<ul>
<li><strong>Semiconductor Dominance</strong>: Taiwan plays a critical role in the global chip supply chain:
<ul>
<li>Produces <strong>11%</strong> of the world’s memory chips.</li>
<li>Fabricates <strong>37%</strong> of the world’s logic chips, essential for computers, smartphones, and data centers.</li>
</ul></li>
<li><strong>Economic Devastation</strong>: Disrupting Taiwan’s chip production would have severe global consequences:
<ul>
<li><strong>Computing Power</strong>: A <strong>37%</strong> reduction in global computing power, impacting everything from smartphones to data centers.</li>
<li><strong>Electronics Manufacturing</strong>: Delays and shortages in all types of electronics, from PCs and smartphones to cars and appliances.</li>
<li><strong>5G Rollout</strong>: Near halt to the rollout of 5G networks due to reliance on Taiwan-made chips.</li>
<li><strong>Economic Cost</strong>: Trillions of dollars in lost economic output, potentially exceeding the impact of the COVID-19 pandemic.</li>
</ul></li>
<li><strong>Difficult to Replace</strong>: Replicating Taiwan’s chipmaking capacity would take years:
<ul>
<li>Building new fabs would require significant time and investment.</li>
<li>Finding trained personnel and acquiring essential machinery and materials would be challenging, especially in a crisis scenario.</li>
</ul></li>
</ul>
</section>
<section id="taiwans-silicon-shield---protection-or-liability" class="level3">
<h3 class="anchored" data-anchor-id="taiwans-silicon-shield---protection-or-liability">Taiwan’s “Silicon Shield” - Protection or Liability?</h3>
<ul>
<li><strong>Deterrence</strong>: Taiwan’s chip industry serves as a “silicon shield,” making the US and its allies more invested in Taiwan’s security.</li>
<li><strong>Vulnerability</strong>: The concentration of chip production in Taiwan also creates a single point of failure, making the global economy vulnerable to disruptions in the event of a conflict.</li>
</ul>
</section>
<section id="lessons-from-the-russia-ukraine-war" class="level3">
<h3 class="anchored" data-anchor-id="lessons-from-the-russia-ukraine-war">Lessons from the Russia-Ukraine War</h3>
<ul>
<li><strong>Semiconductors as a Strategic Asset</strong>: The war highlights the strategic importance of semiconductors in modern warfare.</li>
<li><strong>Supply Chain Leverage</strong>: The US and its allies have used their control over the chip supply chain to impose significant costs on Russia.</li>
<li><strong>China’s Awareness</strong>: China is acutely aware of the leverage the semiconductor industry provides, leading to calls for securing control over TSMC.</li>
</ul>
</section>
<section id="growing-risks-in-the-taiwan-strait" class="level3">
<h3 class="anchored" data-anchor-id="growing-risks-in-the-taiwan-strait">Growing Risks in the Taiwan Strait</h3>
<ul>
<li><strong>Military Buildup</strong>: China continues to enhance its military capabilities in the Taiwan Strait, increasing the potential for conflict.</li>
<li><strong>Escalation Potential</strong>: Any future crisis in the Taiwan Strait would be far more dangerous than previous confrontations, with higher stakes and greater potential for escalation.</li>
<li><strong>The Digital Battlefield</strong>: A conflict over Taiwan would have profound implications for the global technology sector, potentially disrupting supply chains and reshaping the balance of power in the digital world.</li>
</ul>
</section>
<section id="conclusion-5" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-5">Conclusion</h3>
<section id="the-enduring-legacy-of-the-chip" class="level4">
<h4 class="anchored" data-anchor-id="the-enduring-legacy-of-the-chip">The Enduring Legacy of the Chip</h4>
<ul>
<li><strong>Historical Context</strong>: The invention and development of the integrated circuit were deeply intertwined with Cold War rivalries and the pursuit of technological superiority.</li>
<li><strong>Transformative Impact</strong>: Chips have revolutionized countless aspects of modern life, from communication and entertainment to transportation and healthcare.</li>
<li><strong>Globalized Industry</strong>: The semiconductor industry evolved into a highly globalized enterprise, with countries and companies interconnected through complex supply chains.</li>
</ul>
</section>
<section id="challenges-to-moores-law" class="level4">
<h4 class="anchored" data-anchor-id="challenges-to-moores-law">Challenges to Moore’s Law</h4>
<ul>
<li><strong>Physical Limits</strong>: As transistors shrink to the atomic level, fundamental physical limits may eventually slow down or halt the pace of miniaturization.</li>
<li><strong>Cost and Complexity</strong>: The cost and complexity of developing and manufacturing ever-more advanced chips continue to increase.</li>
</ul>
</section>
<section id="the-future-of-computing" class="level4">
<h4 class="anchored" data-anchor-id="the-future-of-computing">The Future of Computing</h4>
<ul>
<li><strong>Specialization</strong>: The trend toward specialization, with chips optimized for specific tasks like AI and graphics, is likely to continue.</li>
<li><strong>Cloud Computing</strong>: Cloud computing will continue to reshape the industry, with companies like Amazon and Google designing their own chips.</li>
<li><strong>New Architectures</strong>: The industry is exploring new chip architectures and materials to overcome the limitations of traditional silicon-based technology.</li>
</ul>
</section>
<section id="conclusion-6" class="level4">
<h4 class="anchored" data-anchor-id="conclusion-6">Conclusion</h4>
<ul>
<li><strong>Chips and Geopolitics</strong>: The semiconductor industry will remain a focal point of geopolitical competition, with countries vying for control of this critical technology.</li>
<li><strong>Taiwan’s Precarious Position</strong>: Taiwan’s dominance in chipmaking makes it both strategically important and vulnerable, highlighting the delicate balance of power in the region.</li>
<li><strong>Uncertainty and Opportunity</strong>: The future of computing is full of uncertainty but also holds immense potential for innovation and progress.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="conclusion-7" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-7">Conclusion</h2>
<section id="the-birth-of-an-industry-from-cold-war-tensions-to-silicon-valley" class="level3">
<h3 class="anchored" data-anchor-id="the-birth-of-an-industry-from-cold-war-tensions-to-silicon-valley">The Birth of an Industry: From Cold War Tensions to Silicon Valley</h3>
<ul>
<li><strong>1958:</strong> A pivotal year for the semiconductor industry unfolds against the backdrop of the Cold War and U.S.-China tensions:
<ul>
<li>The <strong>shelling of Kinoy Island</strong> by the People’s Liberation Army underscores the escalating global conflict.</li>
<li><strong>Jack Kilby</strong> demonstrates the world’s first integrated circuit at Texas Instruments in Dallas.</li>
<li><strong>Jay Lathrop</strong> joins Texas Instruments, having already filed a patent for photolithographic transistor production.</li>
<li><strong>Morris Chang</strong> arrives at Texas Instruments, renowned for his expertise in minimizing semiconductor fabrication errors.</li>
</ul></li>
<li><strong>Texas Instruments</strong> undergoes a strategic shift under <strong>Pat Haggerty’s</strong> leadership:
<ul>
<li>Haggerty’s vision focuses on developing electronics for <strong>military applications</strong>, moving away from oil exploration instruments.</li>
<li><strong>Weldon Word</strong> and a team of skilled engineers at Texas Instruments work on electronics for advanced weapons and sensors.</li>
</ul></li>
<li><strong>The Cold War fuels U.S. investment in electronics</strong>:
<ul>
<li>Defense spending surges into electronics companies, driven by the need to maintain technological superiority over the Soviet Union and Communist China.</li>
<li>The emphasis shifts from traditional military might to technological advancement, particularly in transistors, sensors, and communication equipment.</li>
</ul></li>
</ul>
<section id="global-talent-converges-on-american-soil" class="level4">
<h4 class="anchored" data-anchor-id="global-talent-converges-on-american-soil">Global Talent Converges on American Soil:</h4>
<ul>
<li><strong>The lure of opportunity and freedom attracts brilliant minds to the United States</strong>:
<ul>
<li><strong>Morris Chang</strong>, fleeing potential persecution in China, exemplifies the exodus of talent seeking refuge and opportunity.</li>
<li><strong>John Bardeen</strong> and <strong>Walter Bratton’s</strong> invention of the transistor at Bell Labs leads to further breakthroughs.</li>
<li><strong>Mohamed Atala</strong> and <strong>Dewan Kang</strong>, Bell Labs colleagues, develop a mass-producible transistor structure.</li>
</ul></li>
<li><strong>Fairchild Semiconductor</strong>, a pivotal company in the industry’s rise, benefits from international expertise:
<ul>
<li>Two of the “traitorous eight” founders, who left Shockley Semiconductor to start Fairchild, were born outside the U.S.</li>
<li><strong>András Groff</strong>, a Hungarian émigré, plays a crucial role in optimizing Fairchild’s chipmaking processes and rises to become CEO.</li>
</ul></li>
<li><strong>Key semiconductor hubs emerge</strong>:
<ul>
<li><strong>Texas</strong>, <strong>Massachusetts</strong>, and <strong>California</strong> become magnets for global talent drawn to the burgeoning semiconductor industry.</li>
</ul></li>
</ul>
</section>
<section id="the-visionaries-and-the-rise-of-silicon-valley" class="level4">
<h4 class="anchored" data-anchor-id="the-visionaries-and-the-rise-of-silicon-valley">The Visionaries and the Rise of Silicon Valley:</h4>
<ul>
<li><strong>Miniaturization as a Catalyst for Change</strong>:
<ul>
<li>Engineers and physicists share a conviction that shrinking transistors holds transformative potential, a belief that exceeds even their wildest expectations.</li>
</ul></li>
<li><strong>Gordon Moore’s Prescient Predictions</strong>:
<ul>
<li>In 1965, <strong>Gordon Moore’s</strong> prediction about <strong>home computers</strong> and <strong>portable communication devices</strong> foreshadows the centrality of chips in modern life.</li>
<li>The concept of producing more transistors daily than the number of cells in the human body would have been unimaginable to the industry’s pioneers.</li>
</ul></li>
</ul>
</section>
<section id="from-defense-to-global-markets-the-ever-increasing-need-for-scale" class="level4">
<h4 class="anchored" data-anchor-id="from-defense-to-global-markets-the-ever-increasing-need-for-scale">From Defense to Global Markets: The Ever-Increasing Need for Scale:</h4>
<ul>
<li><strong>The Semiconductor Industry’s Dependence on Global Markets</strong>:
<ul>
<li>The industry’s reliance on vast global markets grows alongside the increasing scale of production and shrinking transistor size.</li>
<li>Even the <strong>Pentagon’s $700 billion budget</strong> proves insufficient to support domestic production of cutting-edge defense chips.</li>
</ul></li>
<li><strong>Shifting Procurement Strategies</strong>:
<ul>
<li>The Defense Department, while possessing dedicated facilities for large-scale military equipment, relies on commercial chip suppliers, many based in <strong>Taiwan</strong>.</li>
<li>The exorbitant cost of designing and fabricating advanced logic chips necessitates a shift towards external procurement.</li>
</ul></li>
<li><strong>Silicon Valley’s Multifaceted Success</strong>:
<ul>
<li>Beyond scientific and engineering prowess, Silicon Valley’s success hinges on sales, marketing, supply chain management, and relentless cost reduction.</li>
</ul></li>
</ul>
</section>
<section id="entrepreneurship-innovation-and-the-drive-for-efficiency" class="level4">
<h4 class="anchored" data-anchor-id="entrepreneurship-innovation-and-the-drive-for-efficiency">Entrepreneurship, Innovation, and the Drive for Efficiency:</h4>
<ul>
<li><strong>Bob Noyce</strong>:
<ul>
<li>An MIT-trained physicist, <strong>Bob Noyce’s</strong> entrepreneurial vision and ability to identify a market for a yet-to-exist product were instrumental in the industry’s growth.</li>
</ul></li>
<li><strong>Fairchild Semiconductor</strong>:
<ul>
<li><strong>Gordon Moore</strong>, in his 1965 article, highlighted how Fairchild Semiconductor’s success in integrating more components onto chips stemmed from a combination of:
<ul>
<li><strong>Scientific and engineering talent</strong></li>
<li><strong>Effective management practices</strong>, such as maintaining union-free factories and implementing employee stock options, that boosted productivity.</li>
</ul></li>
</ul></li>
<li><strong>Dramatic Cost Reduction</strong>:
<ul>
<li>The price of transistors plummets to <strong>less than a millionth of their 1958 cost</strong> thanks to the relentless drive for efficiency epitomized by a Fairchild employee’s exit survey response: <strong>“I want to get rich.”</strong></li>
</ul></li>
</ul>
</section>
<section id="the-interplay-of-technology-society-and-geopolitics" class="level4">
<h4 class="anchored" data-anchor-id="the-interplay-of-technology-society-and-geopolitics">The Interplay of Technology, Society, and Geopolitics:</h4>
<ul>
<li><strong>Shaping the Semiconductor Landscape</strong>:
<ul>
<li>The development and trajectory of the semiconductor industry are not solely driven by technological advancements; societal and political forces play a significant role.</li>
</ul></li>
<li><strong>DARPA’s Influence</strong>:
<ul>
<li><strong>DARPA</strong>, the Pentagon’s research and development arm, has significantly influenced the industry by funding research into <strong>FinFETs</strong>, the 3D transistor structures used in advanced chips.</li>
</ul></li>
<li><strong>China’s Impact</strong>:
<ul>
<li>China’s substantial subsidies are poised to reshape the semiconductor supply chain, regardless of whether China achieves its goal of semiconductor dominance.</li>
</ul></li>
</ul>
</section>
</section>
<section id="the-end-of-moores-law-challenges-and-the-future-of-computing-power" class="level3">
<h3 class="anchored" data-anchor-id="the-end-of-moores-law-challenges-and-the-future-of-computing-power">The End of Moore’s Law? Challenges and the Future of Computing Power</h3>
<section id="the-limits-of-miniaturization" class="level4">
<h4 class="anchored" data-anchor-id="the-limits-of-miniaturization">The Limits of Miniaturization:</h4>
<ul>
<li><strong>The Potential End of Moore’s Law</strong>:
<ul>
<li><strong>Gordon Moore’s Law</strong>, a prediction, not a law of physics, faces challenges as shrinking transistors approach physical limits.</li>
</ul></li>
<li><strong>Industry Leaders Voice Concerns</strong>:
<ul>
<li>Prominent figures, including <strong>NVIDIA CEO Jensen Huang</strong> and former Stanford president <strong>John Hennessy</strong>, have declared Moore’s Law to be over.</li>
</ul></li>
<li><strong>Rising Costs and Slowing Progress</strong>:
<ul>
<li>The cost of producing ever-smaller chips continues to rise as the pace of cost decline slows significantly.</li>
<li>Tools required for manufacturing, such as <strong>EUV lithography machines</strong> with a price tag exceeding <strong>$100 million</strong>, contribute to the escalating expenses.</li>
</ul></li>
</ul>
</section>
<section id="historical-challenges-and-overcoming-barriers" class="level4">
<h4 class="anchored" data-anchor-id="historical-challenges-and-overcoming-barriers">Historical Challenges and Overcoming Barriers:</h4>
<ul>
<li><strong>Past Predictions of Moore’s Law’s Demise</strong>:
<ul>
<li>This is not the first time Moore’s Law has been declared near its end. In 1988, IBM expert <strong>Eric Block</strong> predicted its demise when transistors reached a quarter of a micron, a barrier surpassed by the industry a decade later.</li>
</ul></li>
<li><strong>Gordon Moore’s Own Concerns</strong>:
<ul>
<li>In 2003, <strong>Gordon Moore</strong> himself acknowledged potential barriers to continued progress within the following decade.</li>
</ul></li>
<li><strong>Overcoming Technological Hurdles</strong>:
<ul>
<li>Despite anticipated limitations, the industry has consistently overcome obstacles. The development and widespread use of <strong>3D FinFET transistors</strong> exemplify this ability to innovate.</li>
</ul></li>
<li><strong>Exceeding Expectations</strong>:
<ul>
<li><strong>Carver Mead</strong>, the originator of the term “Moore’s Law,” once astounded experts with his prediction of chips containing <strong>100 million transistors per square centimeter</strong>.</li>
<li>Modern fabs can now pack hundreds of times more transistors onto a chip than Mead envisioned.</li>
</ul></li>
<li><strong>Jim Keller’s Optimistic Outlook</strong>:
<ul>
<li>Renowned chip designer <strong>Jim Keller</strong> envisions a 50-fold increase in transistor density:
<ul>
<li><strong>Thinner fin-shaped transistors</strong> could allow for a threefold increase in density.</li>
<li><strong>Tube-shaped gate-all-around transistors</strong> could double density by enabling electric field application from all directions.</li>
<li><strong>Stacking these wires</strong> could further increase density eightfold.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="a-new-era-of-chip-design-and-the-evolution-of-computing" class="level4">
<h4 class="anchored" data-anchor-id="a-new-era-of-chip-design-and-the-evolution-of-computing">A New Era of Chip Design and the Evolution of Computing:</h4>
<ul>
<li><strong>Sustained Investment and Innovation</strong>:
<ul>
<li>The semiconductor industry continues to attract substantial investment, demonstrating a belief in continued advancement.</li>
<li>AI chip startups have raised billions, aspiring to emulate NVIDIA’s success.</li>
<li>Tech giants, including Google, Amazon, Microsoft, Apple, Facebook, and Alibaba, are investing heavily in custom chip design.</li>
</ul></li>
<li><strong>The Rise of Specialized Chips</strong>:
<ul>
<li>The traditional dominance of general-purpose microprocessors is being challenged by chips optimized for specific tasks, like <strong>NVIDIA’s GPUs for graphics and AI</strong>.</li>
</ul></li>
<li><strong>Neil Thompson and Svenja Spanut’s Argument</strong>:
<ul>
<li>These researchers argue that we are witnessing a decline in computers as a general-purpose technology.</li>
<li>They predict a future with a divide between applications using powerful customized chips (fast lane) and those relying on general-purpose chips (slow lane).</li>
</ul></li>
<li><strong>Accessibility and Democratization of AI</strong>:
<ul>
<li>While specialized chips represent a shift from general-purpose computing, they have made technologies like AI more accessible and affordable.</li>
<li>Companies like NVIDIA have facilitated the widespread adoption of AI through their specialized chips.</li>
</ul></li>
</ul>
</section>
<section id="the-rise-of-big-tech-in-chip-design" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-big-tech-in-chip-design">The Rise of Big Tech in Chip Design:</h4>
<ul>
<li><strong>Amazon and Google’s Entry</strong>:
<ul>
<li>Motivated by enhancing their cloud computing infrastructure, both companies have ventured into chip design.</li>
<li><strong>Google’s TPU chips</strong>, optimized for AI, are available to the public through their cloud platform.</li>
</ul></li>
<li><strong>A Bifurcated Computing Landscape?</strong>:
<ul>
<li>Some view this trend as a division between a slow lane and a fast lane in computing power.</li>
<li>However, access to the “fast lane” through specialized chips or AI-optimized clouds is increasingly available.</li>
</ul></li>
</ul>
</section>
<section id="new-frontiers-in-chip-integration-and-system-design" class="level4">
<h4 class="anchored" data-anchor-id="new-frontiers-in-chip-integration-and-system-design">New Frontiers in Chip Integration and System Design:</h4>
<ul>
<li><strong>Heterogeneous Integration</strong>:
<ul>
<li>Modern devices often incorporate multiple types of chips, with some focused on general operations and others optimized for specific tasks (e.g., camera processors).</li>
<li>Advanced packaging technologies allow for efficient chip interconnection, enabling flexible configurations and adaptability to evolving needs.</li>
</ul></li>
<li><strong>Holistic System Design</strong>:
<ul>
<li>Chip manufacturers are placing greater emphasis on considering the broader systems in which their chips will function, optimizing for performance and efficiency within those specific environments.</li>
</ul></li>
</ul>
</section>
<section id="the-enduring-importance-of-computing-power-and-the-quest-for-progress" class="level4">
<h4 class="anchored" data-anchor-id="the-enduring-importance-of-computing-power-and-the-quest-for-progress">The Enduring Importance of Computing Power and the Quest for Progress:</h4>
<ul>
<li><strong>Redefining Moore’s Law</strong>:
<ul>
<li>The crucial question is not whether the original definition of Moore’s Law (exponential transistor growth on a chip) is reaching its limit.</li>
<li>The focus should be on whether we are approaching the peak of computing power that can be cost-effectively achieved on a chip.</li>
</ul></li>
<li><strong>Continued Investment and Optimism</strong>:
<ul>
<li>The significant investments and tireless efforts of countless engineers reflect a strong belief in the potential for further advancements in computing power.</li>
</ul></li>
</ul>
</section>
</section>
<section id="from-humble-beginnings-to-a-transformative-force" class="level3">
<h3 class="anchored" data-anchor-id="from-humble-beginnings-to-a-transformative-force">From Humble Beginnings to a Transformative Force</h3>
<ul>
<li><strong>1958</strong>: The year that witnessed the convergence of key figures like Morris Chang, Pat Haggerty, Weldon Word, Jay Lathrop, and Jack Kilby at Texas Instruments also saw a pivotal electronics conference in Washington, D.C.</li>
<li><strong>Unsung Heroes</strong>: Chang, Gordon Moore, and Bob Noyce, future titans of technology, were unknown to the world as they enjoyed a night of camaraderie amidst the snowdrifts.</li>
<li><strong>A Lasting Legacy</strong>: The chips they invented and the industry they built have profoundly shaped our world, providing the unseen circuitry that powers our lives and will continue to mold our future.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>history</category>
  <guid>https://christianjmills.com/posts/chip-war-book-notes/</guid>
  <pubDate>Wed, 28 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>The Kill Chain Book Notes</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/the-kill-chain-book-notes/</link>
  <description><![CDATA[ 




<ul>
<li>Introduction<br>
</li>
<li>Chapter 1: What Happened to Yoda’s Revolution?<br>
</li>
<li>Chapter 2: Little Green Men and Assassin’s Mace<br>
</li>
<li>Chapter 3: A Tale of Two Cities<br>
</li>
<li>Chapter 4: Information Revolution 2.0<br>
</li>
<li>Chapter 5. Something Worse Than Change<br>
</li>
<li>Chapter 6: A Different Kind of Arms Race<br>
</li>
<li>Chapter 7: Human Command, Machine Control<br>
</li>
<li>Chapter 8: A Military Internet of Things<br>
</li>
<li>Chapter 9: Move, Shoot, Communicate<br>
</li>
<li>Chapter 10: Defense Without Dominance<br>
</li>
<li>Chapter 11: Bureaucracy Does Its Thing<br>
</li>
<li>Chapter 12: How the Future Can Win<br>
</li>
<li>Conclusion: A Failure of Imagination</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Book LInks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://www.hachettebookgroup.com/titles/christian-brose/the-kill-chain/9780316533362/">Publisher Page</a></li>
<li><a href="https://www.linkedin.com/in/christian-brose-50b026ab/">Author’s LinkedIn Page</a></li>
</ul>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<section id="playing-a-losing-game" class="level3">
<h3 class="anchored" data-anchor-id="playing-a-losing-game">Playing a Losing Game</h3>
<ul>
<li><p>This book argues that the U.S. military is on a path to lose a future war against China, and that this trajectory must be changed.</p></li>
<li><p>The author, Christian Brose, draws on his extensive experience as a national security and military advisor, most notably serving as staff director for Senator John McCain on the Senate Armed Services Committee.</p></li>
<li><p>This role provided Brose with access to classified information, top defense officials, and insights into the concerning reality of the U.S. military’s eroding advantage over China.</p></li>
</ul>
<section id="a-stark-warning-ignored" class="level4">
<h4 class="anchored" data-anchor-id="a-stark-warning-ignored">A Stark Warning Ignored</h4>
<ul>
<li>In 2017, Brose witnessed Senator McCain’s attempt to warn his Senate colleagues about the U.S. military’s vulnerabilities against China.
<ul>
<li>McCain, troubled by the military’s lagging technological advancement, organized a classified briefing for all 100 senators.</li>
<li>The briefing, based on concerning war game simulations, revealed a bleak outlook: the U.S. consistently lost in simulated conflicts with China.</li>
<li>Despite the gravity of the situation, only a dozen senators attended.</li>
</ul></li>
</ul>
</section>
<section id="a-grim-assessment-of-u.s.-capabilities" class="level4">
<h4 class="anchored" data-anchor-id="a-grim-assessment-of-u.s.-capabilities">A Grim Assessment of U.S. Capabilities</h4>
<ul>
<li><strong>David Ochmanek</strong>, a former Pentagon official, has conducted extensive war game simulations for the Department of Defense, revealing a disturbing pattern:
<ul>
<li><strong>War Game Outcomes:</strong> The U.S. military consistently loses against China and Russia in these simulations, suffering heavy casualties and equipment losses while failing to achieve objectives.</li>
<li><strong>A Shocking Reality:</strong> This finding contradicts the prevailing assumption of U.S. military dominance, leaving many within the defense establishment in disbelief.</li>
</ul></li>
<li><strong>A Consistent Pattern of Defeat:</strong> War game simulations over the past decade consistently show the U.S. losing against China.
<ul>
<li><strong>A Well-Kept Secret:</strong> This information remains largely unknown to the American public and even many members of Congress, despite being acknowledged within the Department of Defense.</li>
</ul></li>
</ul>
</section>
<section id="a-conversation-with-senator-mccain-imagining-a-war-with-china" class="level4">
<h4 class="anchored" data-anchor-id="a-conversation-with-senator-mccain-imagining-a-war-with-china">A Conversation with Senator McCain: Imagining a War with China</h4>
<ul>
<li>Following the poorly attended Senate briefing, Brose and Senator McCain engaged in a sobering thought experiment: imagining a potential war with China.
<ul>
<li>They agreed that the U.S. would not instigate a conflict, but acknowledged potential triggers such as:
<ul>
<li>A maritime incident escalating into conflict.</li>
<li>A Chinese attack on a U.S. ally prompting American intervention.</li>
</ul></li>
<li>They envisioned a scenario where the U.S. would face significant challenges in mobilizing and deploying forces.</li>
</ul></li>
</ul>
</section>
<section id="a-potential-war-with-china-key-vulnerabilities-and-challenges" class="level4">
<h4 class="anchored" data-anchor-id="a-potential-war-with-china-key-vulnerabilities-and-challenges">A Potential War With China: Key Vulnerabilities and Challenges</h4>
<ul>
<li><strong>Geographical Disadvantages and Logistical Nightmares:</strong>
<ul>
<li>Much of the U.S. military’s necessary equipment and personnel would be positioned thousands of miles away from the conflict zone.</li>
<li>Mobilization efforts would be hampered by cyberattacks and attacks on vulnerable supply lines, including cargo ships and aircraft.</li>
</ul></li>
<li><strong>Space and Cyber Warfare Dominance by China:</strong>
<ul>
<li>China would leverage its capabilities to target U.S. satellites, disrupting critical intelligence, communication, and GPS systems.</li>
<li>Command and control networks would be crippled by electronic, cyber, and missile attacks, leaving U.S. forces in disarray.</li>
</ul></li>
<li><strong>Vulnerability of Forward Bases and Critical Infrastructure:</strong>
<ul>
<li>U.S. bases in Japan and Guam would be overwhelmed by barrages of Chinese ballistic and cruise missiles.</li>
<li>China’s hypersonic weapons, capable of maneuvering at high speeds, would render existing U.S. defenses useless.</li>
<li>Runways, operation centers, and fuel depots would be targeted, crippling U.S. operations and forcing evacuations.</li>
</ul></li>
<li><strong>Limitations of Air and Sea Power:</strong>
<ul>
<li>Older, non-stealthy fighter jets (F-15s, F-16s, F-18s) would be ineffective against China’s advanced air defenses.</li>
<li>Limited numbers of stealthy fighter jets (F-22s, F-35s) would be hampered by their short range and dependence on vulnerable aerial refueling tankers.</li>
<li>U.S. aircraft carriers would be forced to operate far from Chinese shores to avoid anti-ship missiles, limiting their effectiveness and making them vulnerable to attack.</li>
<li>China’s “carrier killer” missiles (DF-21 and DF-26) would pose a significant threat, potentially sinking carriers and causing massive casualties.</li>
</ul></li>
<li><strong>Challenges for the Marine Corps and Amphibious Operations:</strong>
<ul>
<li>The Marine Corps’ amphibious assault capabilities, designed for beach landings, would be largely ineffective against heavily defended Chinese territory.</li>
<li>The need to operate within range of Chinese missiles would severely restrict their ability to conduct traditional amphibious operations.</li>
</ul></li>
<li><strong>Logistical Constraints and Depletion of Critical Assets:</strong>
<ul>
<li>Key U.S. assets (submarines, long-range bombers, ground-launched missiles) would need to be relocated to the Pacific, taking crucial time.</li>
<li>Years of underinvestment and acquisition delays would result in a shortage of these assets and a rapid depletion of essential weapons.</li>
</ul></li>
</ul>
</section>
<section id="a-sobering-realization-facing-the-consequences" class="level4">
<h4 class="anchored" data-anchor-id="a-sobering-realization-facing-the-consequences">A Sobering Realization: Facing the Consequences</h4>
<ul>
<li><p><strong>Devastation and Defeat:</strong> Brose and McCain contemplated the potential human and material costs of such a war, including thousands of American casualties, sunken ships, destroyed bases, and a swift defeat.</p></li>
<li><p><strong>Unthinkable Choices:</strong> The potential for such a rapid and devastating loss would present a U.S. president with limited options, potentially including surrender or a futile fight.</p></li>
<li><p><strong>China’s Strategic Advantage:</strong> This outcome would fulfill China’s strategic objective of achieving victory without engaging in protracted warfare, as outlined in Sun Tzu’s “The Art of War.”</p></li>
</ul>
</section>
<section id="a-legacy-of-neglect-failing-to-address-the-challenge" class="level4">
<h4 class="anchored" data-anchor-id="a-legacy-of-neglect-failing-to-address-the-challenge">A Legacy of Neglect: Failing to Address the Challenge</h4>
<ul>
<li>McCain expressed frustration and disappointment that despite past warnings and efforts to address military weaknesses, the U.S. found itself in a precarious position.
<ul>
<li>The 1980s revelation of a “hollow force” sparked outrage and action, yet the current crisis, despite being more dire, had not elicited a similar response.</li>
<li>McCain lamented the lack of awareness and urgency among both the public and elected officials, fearing future generations would judge them harshly for their inaction.</li>
</ul></li>
</ul>
</section>
</section>
<section id="the-illusion-of-american-military-supremacy-mistaking-inputs-for-outcomes" class="level3">
<h3 class="anchored" data-anchor-id="the-illusion-of-american-military-supremacy-mistaking-inputs-for-outcomes">The Illusion of American Military Supremacy: Mistaking Inputs for Outcomes</h3>
<ul>
<li>Despite spending more on defense than any other country, the U.S. military faces an existential crisis, challenging the prevailing notion of its invincibility.
<ul>
<li>This discrepancy between spending and effectiveness highlights a fundamental flaw in how the U.S. approaches national defense.</li>
</ul></li>
<li><strong>The Problem with Platforms:</strong>
<ul>
<li>The U.S. military’s traditional focus on platforms (e.g., ships, planes, tanks) as the primary measure of strength is misguided.</li>
<li>Platforms are seen as tangible symbols of military might, influencing budgets, capabilities, and even institutional identity.</li>
</ul></li>
<li><strong>The Importance of the Kill Chain:</strong>
<ul>
<li><strong>Defining the Kill Chain:</strong>
<ul>
<li>The kill chain is the essential process by which militaries achieve their objectives, involving three key steps:
<ul>
<li><strong>Understanding:</strong> Gathering information about the battlespace and the enemy.</li>
<li><strong>Deciding:</strong> Analyzing information and making strategic and tactical decisions.</li>
<li><strong>Acting:</strong> Executing decisions to achieve desired effects, which may or may not involve lethal force.</li>
</ul></li>
</ul></li>
<li><strong>Closing and Breaking the Kill Chain:</strong>
<ul>
<li><strong>Closing the Kill Chain:</strong> Successfully completing the understand-decide-act cycle to achieve a military objective.</li>
<li><strong>Breaking the Kill Chain:</strong> Disrupting an adversary’s ability to complete the kill chain, neutralizing their effectiveness.</li>
</ul></li>
<li><strong>A Universal Concept:</strong>
<ul>
<li>The kill chain is not unique to the military; it mirrors processes used in business, sports, and everyday life.</li>
<li>This framework highlights that while the military operates in a unique and high-stakes environment, its core functions are relatable and understandable.</li>
</ul></li>
</ul></li>
<li><strong>The Information Revolution and Its Unfulfilled Promise:</strong>
<ul>
<li>The information revolution of the 1980s promised to revolutionize warfare by enabling networked warfare and the disaggregation of the kill chain across multiple platforms.</li>
<li>However, the U.S. defense establishment failed to fully embrace this transformation, clinging to its platform-centric approach.</li>
</ul></li>
<li><strong>The Failure to Adapt:</strong>
<ul>
<li>Despite advancements in information technology, the U.S. military’s kill chain remains slow, inflexible, and reliant on outdated systems.</li>
<li>Military platforms often lack interoperability, hindering their ability to share information and function as a cohesive network.</li>
</ul></li>
<li><strong>The Legacy of Failed Modernization:</strong>
<ul>
<li>Previous attempts to modernize the military often focused on developing better versions of existing platforms using unproven technologies, resulting in costly procurement failures.</li>
<li>The U.S. military’s current predicament is partly a result of learning the wrong lessons from these failures, leading to risk aversion and a reluctance to embrace truly transformative change.</li>
</ul></li>
</ul>
</section>
<section id="the-china-challenge-a-new-era-of-competition" class="level3">
<h3 class="anchored" data-anchor-id="the-china-challenge-a-new-era-of-competition">The China Challenge: A New Era of Competition</h3>
<ul>
<li><strong>A Rapidly Evolving Threat:</strong>
<ul>
<li>The information revolution is accelerating, driven by commercial technology companies, and these advancements have significant military applications.</li>
<li>China, capitalizing on these emerging technologies, poses a rapidly growing and evolving threat to U.S. military dominance.</li>
</ul></li>
<li><strong>China’s Strategic Approach:</strong>
<ul>
<li>China has meticulously studied the U.S. military, identifying its weaknesses and developing strategies to exploit them.</li>
<li>Instead of directly confronting U.S. strengths, China aims to deny the U.S. military the ability to project power and fight in its preferred manner.</li>
</ul></li>
<li><strong>Asymmetric Warfare and Technological Leapfrogging:</strong>
<ul>
<li>China has invested heavily in advanced weapons designed to disrupt U.S. battle networks, destroy expensive platforms, and break the kill chain.</li>
<li>This approach prioritizes achieving a decisive advantage through technological superiority and asymmetric capabilities.</li>
</ul></li>
<li><strong>The Rise of China: Economic and Military Power:</strong>
<ul>
<li>China’s economic growth fuels its military ambitions, potentially enabling it to match or surpass U.S. military spending within a decade.</li>
<li>This shift in the balance of power poses an unprecedented challenge, demanding a fundamental reassessment of U.S. defense strategy.</li>
</ul></li>
<li><strong>China’s Grand Strategy:</strong>
<ul>
<li>China’s ambitions extend beyond regional dominance to becoming the world’s leading power, supplanting the United States.</li>
<li>This strategy entails undermining U.S. influence globally, eroding its alliances, and promoting China’s model of authoritarianism.</li>
</ul></li>
<li><strong>Exploiting Emerging Technologies:</strong>
<ul>
<li>China recognizes the transformative potential of emerging technologies and is investing heavily in artificial intelligence, biotechnology, robotics, and other fields.</li>
<li>These technologies are not only being used to enhance its military but also to strengthen its authoritarian control domestically.</li>
</ul></li>
<li><strong>A Looming Crisis for the U.S. Military:</strong>
<ul>
<li>The U.S. military’s current trajectory puts it at a severe disadvantage against China’s asymmetric capabilities.</li>
<li>Continuing to invest in the same platforms and approaches will only exacerbate this vulnerability, playing into China’s hands.</li>
</ul></li>
</ul>
</section>
<section id="the-need-for-transformation-reimagining-american-military-power" class="level3">
<h3 class="anchored" data-anchor-id="the-need-for-transformation-reimagining-american-military-power">The Need for Transformation: Reimagining American Military Power</h3>
<ul>
<li><strong>Recognizing the Urgency:</strong>
<ul>
<li>The U.S. defense establishment must acknowledge the severity of the situation and the need for radical change.</li>
<li>Complacency and clinging to outdated paradigms will result in catastrophic consequences for U.S. security and global standing.</li>
</ul></li>
<li><strong>Shifting from Inputs to Outcomes:</strong>
<ul>
<li>The focus should shift from simply acquiring platforms to building a more effective kill chain.</li>
<li>This requires prioritizing technologies and capabilities that enhance the U.S. military’s ability to understand, decide, and act faster and more effectively than its competitors.</li>
</ul></li>
<li><strong>From Platforms to Networks:</strong>
<ul>
<li>Instead of relying on small numbers of expensive and vulnerable platforms, the U.S. military must adopt a more networked and distributed approach.</li>
<li>This entails investing in:
<ul>
<li><strong>Interoperable Systems:</strong> Enabling seamless communication and data sharing between platforms.</li>
<li><strong>Resilient Networks:</strong> Developing robust networks that can withstand attacks and disruptions.</li>
<li><strong>Artificial Intelligence:</strong> Leveraging AI for faster and more effective decision-making.</li>
</ul></li>
</ul></li>
<li><strong>From Offensive to Defensive:</strong>
<ul>
<li>The U.S. military must prioritize defensive capabilities that deter Chinese aggression and protect critical assets.</li>
<li>This includes:
<ul>
<li>Strengthening base defenses against missile attacks.</li>
<li>Developing more effective counter-space and cyber capabilities.</li>
<li>Investing in technologies that make U.S. platforms less vulnerable to detection and attack.</li>
</ul></li>
</ul></li>
<li><strong>Embracing Autonomy and Unmanned Systems:</strong>
<ul>
<li>The U.S. military should accelerate the development and deployment of autonomous and unmanned systems.</li>
<li>This shift would:
<ul>
<li>Reduce reliance on vulnerable manned platforms.</li>
<li>Increase the speed and tempo of operations.</li>
<li>Enable the U.S. military to operate more effectively in contested environments.</li>
</ul></li>
</ul></li>
<li><strong>Rethinking Force Structure:</strong>
<ul>
<li>The U.S. military must move away from its traditional force structure of large, heavily manned platforms.</li>
<li>Instead, it should prioritize:
<ul>
<li>Smaller, more agile, and expendable platforms.</li>
<li>A greater emphasis on unmanned and autonomous systems.</li>
<li>A force that is designed for distributed and networked warfare.</li>
</ul></li>
</ul></li>
<li><strong>Overcoming Institutional Inertia:</strong>
<ul>
<li>The biggest obstacle to transformation is not a lack of resources or technology but a lack of imagination and institutional inertia.</li>
<li>Overcoming this will require:
<ul>
<li>Strong leadership willing to challenge the status quo.</li>
<li>A cultural shift that embraces innovation and change.</li>
<li>A willingness to take risks and accept that failure is part of the innovation process.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="conclusion-a-call-to-action" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-a-call-to-action">Conclusion: A Call to Action</h3>
<ul>
<li><strong>The Stakes:</strong>
<ul>
<li>The future of American security and global leadership hangs in the balance.</li>
<li>Failure to adapt to the changing character of warfare will have dire consequences for the U.S. and its allies.</li>
</ul></li>
<li><strong>The Path Forward:</strong>
<ul>
<li>The U.S. must embrace bold and transformative change to maintain its military edge.</li>
<li>This requires a fundamental rethinking of defense strategy, force structure, and acquisition processes.</li>
</ul></li>
<li><strong>The Role of Informed Citizenry:</strong>
<ul>
<li>An informed and engaged citizenry is essential for driving the necessary changes in U.S. national defense.</li>
<li>This book aims to educate the public about the challenges and opportunities presented by emerging technologies and the future of warfare, encouraging a national conversation about the best way to defend America in the 21st century.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-1-what-happened-to-yodas-revolution" class="level2">
<h2 class="anchored" data-anchor-id="chapter-1-what-happened-to-yodas-revolution">Chapter 1: What Happened to Yoda’s Revolution?</h2>
<section id="the-dawn-of-a-new-era-and-the-seeds-of-complacency-1991-2001" class="level3">
<h3 class="anchored" data-anchor-id="the-dawn-of-a-new-era-and-the-seeds-of-complacency-1991-2001">The Dawn of a New Era and the Seeds of Complacency (1991-2001)</h3>
<section id="a-visionarys-warning-andrew-marshall-and-the-future-of-war" class="level4">
<h4 class="anchored" data-anchor-id="a-visionarys-warning-andrew-marshall-and-the-future-of-war">A Visionary’s Warning: Andrew Marshall and the Future of War</h4>
<ul>
<li>In 1991, amidst the backdrop of the Cold War’s end, Andrew Marshall, director of the Office of Net Assessment (ONA), initiated a project to assess the future of warfare.
<ul>
<li><strong>Andrew Marshall</strong>, often referred to as “Yoda,” held this influential position for 42 years, reporting directly to the Secretary of Defense.</li>
<li>The ONA’s primary mission was to evaluate the United States’ strategic standing against its competitors, mainly the Soviet Union.</li>
</ul></li>
<li>Marshall, aided by Army Colonel Andrew Krepenevich, aimed to analyze the impact of emerging technologies and the Soviet Union’s collapse on international security and the U.S.’s role.</li>
<li>This project became particularly relevant after the U.S. waged war against Iraq in response to the invasion of Kuwait, a conflict heavily shaped by Cold War strategies and military structures.</li>
</ul>
</section>
<section id="the-gulf-war-illusion-a-misleading-victory" class="level4">
<h4 class="anchored" data-anchor-id="the-gulf-war-illusion-a-misleading-victory">The Gulf War Illusion: A Misleading Victory</h4>
<ul>
<li>The Gulf War (1991) unfolded as a demonstration of American military might, leaving a lasting impression on a young generation.
<ul>
<li>The conflict showcased technological advancements like stealth bombers, smart bombs, and superior air and ground power.</li>
<li>The U.S. achieved a swift victory with minimal casualties (129 combat deaths).</li>
</ul></li>
<li>Despite the perceived success, Marshall’s 1992 report to the Secretary of Defense offered a different perspective.
<ul>
<li>He highlighted the influence of classified Soviet military writings that predicted a “<strong>military technical revolution</strong>.”
<ul>
<li>This revolution, termed the “<strong>reconnaissance strike complex,</strong>” proposed that advanced sensors and surveillance technologies, coupled with precision weaponry, would create the fastest, most effective kill chain in history.</li>
</ul></li>
<li>While the Soviets saw the Gulf War as a testament to this concept, Marshall argued that the U.S. hadn’t even come close to achieving its full potential in this area.</li>
</ul></li>
<li>A 1993 Pentagon study supported Marshall’s assessment.
<ul>
<li>The study revealed that the U.S. battle network remained largely unchanged since the Vietnam era.</li>
<li>It struggled to engage moving targets and relied heavily on “dumb bombs” instead of “smart” ones.</li>
</ul></li>
<li>Admiral William Owens, future Vice Chairman of the Joint Chiefs of Staff, later stated that the Gulf War was primarily won through “massed brute force,” akin to historical campaigns.</li>
</ul>
</section>
<section id="a-revolution-in-military-affairs-the-need-for-transformation" class="level4">
<h4 class="anchored" data-anchor-id="a-revolution-in-military-affairs-the-need-for-transformation">A Revolution in Military Affairs: The Need for Transformation</h4>
<ul>
<li><p>Marshall envisioned a <strong>revolution in military affairs (RMA),</strong> driven by information technologies.</p>
<ul>
<li>He cited historical examples of RMAs, such as the introduction of machine guns, steam-powered ships, and airplanes, emphasizing that technological advancements alone were insufficient.</li>
<li>Successful RMAs required developing new operational strategies and reforming existing military institutions for new strategic goals.</li>
</ul></li>
<li><p>Marshall warned that the U.S. was in the early stages of such a revolution, one that could last for decades.</p>
<ul>
<li>This RMA would center around information technologies that enhance understanding, decision-making, and action in war.</li>
<li>It would necessitate a shift in the concept of military power, potentially rendering traditional platforms like tanks, manned aircraft, and large ships less effective.</li>
<li>Marshall cautioned that failure to adapt to this RMA would leave the U.S. vulnerable to adversaries who successfully harnessed its potential.</li>
</ul></li>
<li><p>Marshall’s analysts coined the term “<strong>anti-access and area denial capabilities</strong>” to describe how powerful adversaries could leverage this RMA to counter the U.S.’s platform-centric approach.</p></li>
<li><p>Despite its prescience, Marshall’s report failed to instigate significant change.</p>
<ul>
<li>The U.S., after the Soviet Union’s collapse, found itself in a unipolar world, with no immediate peer competitors.</li>
<li>This led to a sense of complacency, with leaders prioritizing a “peace dividend” by downsizing the military and focusing on peacekeeping and humanitarian missions.</li>
<li>The prevailing assumption was that future conflicts would resemble the Gulf War, fought against technologically inferior adversaries, allowing the U.S. to dictate the terms of engagement.</li>
</ul></li>
</ul>
</section>
<section id="the-allure-of-technology-and-the-lack-of-urgency" class="level4">
<h4 class="anchored" data-anchor-id="the-allure-of-technology-and-the-lack-of-urgency">The Allure of Technology and the Lack of Urgency</h4>
<ul>
<li>Despite the lack of substantial change, the concept of RMA gained traction in Washington during the 1990s, driven by the fascination with the burgeoning information age.
<ul>
<li>“Revolution” and “transformation” became buzzwords, leading to numerous initiatives aimed at reimagining the U.S. military.
<ul>
<li>These initiatives included projects like “Army After Next,” “Network-Centric Warfare,” “Joint Vision 2010,” and “Lifting the Fog of War.”</li>
</ul></li>
<li>The 1997 Quadrennial Defense Review, the Pentagon’s key strategy document, explicitly prioritized exploiting the RMA.</li>
</ul></li>
<li>However, despite the rhetoric and investments in defense technology, the U.S.’s way of fighting remained largely unchanged.
<ul>
<li>The interventions in Bosnia (1995) and Kosovo (1999) further reinforced this complacency.
<ul>
<li>These conflicts, won with minimal U.S. casualties (four non-combat deaths), were attributed more to adversary weakness than any significant U.S. transformation.</li>
</ul></li>
</ul></li>
<li>Admiral Owens, after retiring, criticized the military’s “residual overconfidence” and its tendency to draw the wrong lessons from the Gulf War.
<ul>
<li>He warned that without genuine adaptation, the U.S. risked a decline in military strength and capabilities in the coming decades as Cold War-era equipment became obsolete.</li>
</ul></li>
</ul>
</section>
<section id="the-20xx-war-games-a-glimpse-into-a-challenging-future" class="level4">
<h4 class="anchored" data-anchor-id="the-20xx-war-games-a-glimpse-into-a-challenging-future">The 20XX War Games: A Glimpse into a Challenging Future</h4>
<ul>
<li><p>As the 21st century began, Marshall, recognizing the lack of progress, initiated the “<strong>Future Warfare 20XX war game series</strong>.”</p>
<ul>
<li>These war games aimed to simulate future conflicts in a world where the RMA had reached maturity, pitting the U.S. against a hypothetical “large peer competitor” – implicitly China.</li>
</ul></li>
<li><p>The war games were led by Robert Martinage and Michael Vickers, both future senior Pentagon officials.</p></li>
<li><p>Their 2001 report presented a stark assessment:</p>
<ul>
<li>China, by 2025-2030, would possess advanced technologies comparable to the U.S., enabling it to target U.S. assets globally, including the homeland.</li>
<li>The U.S.’s reliance on traditional platforms and its vulnerability to attacks on its communication and logistics networks would render its traditional way of fighting ineffective.</li>
<li>The report stressed the need to fully embrace the RMA, building technologically advanced, networked forces, especially unmanned systems, to counter these threats.</li>
<li>The report warned of an “unforgiving future battlefield” where “if you can be seen, you can be killed.”</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="a-missed-opportunity-the-rumsfeld-era-and-the-war-on-terror-2001-2009" class="level3">
<h3 class="anchored" data-anchor-id="a-missed-opportunity-the-rumsfeld-era-and-the-war-on-terror-2001-2009">A Missed Opportunity: The Rumsfeld Era and the War on Terror (2001-2009)</h3>
<section id="a-false-dawn-the-promise-of-transformation-and-the-reality-of-911" class="level4">
<h4 class="anchored" data-anchor-id="a-false-dawn-the-promise-of-transformation-and-the-reality-of-911">A False Dawn: The Promise of Transformation and the Reality of 9/11</h4>
<ul>
<li>The arrival of Donald Rumsfeld as Secretary of Defense in 2001 initially signaled potential progress.
<ul>
<li>Rumsfeld openly advocated for the RMA and created the Office of Force Transformation to oversee the development of new military technologies and doctrines.</li>
<li>He also signed a new defense strategy that prioritized addressing the operational challenges highlighted in Marshall’s 20XX war games, shifting focus toward emerging great powers like China.</li>
</ul></li>
<li>However, the 9/11 terrorist attacks drastically altered the strategic landscape, leading to a significant shift in priorities.
<ul>
<li>While Rumsfeld still emphasized transformation, the focus shifted towards waging a global war on terror.</li>
</ul></li>
<li>The War on Terror did yield some genuine military innovations, primarily within the Joint Special Operations Command (JSOC).
<ul>
<li>JSOC developed new technologies and tactics for counterterrorism missions, achieving remarkable speed and effectiveness in dismantling terrorist networks.</li>
<li>This innovation, along with the adoption of a counterinsurgency strategy in 2007, played a crucial role in weakening al-Qaeda in Iraq.</li>
</ul></li>
<li>However, the War on Terror ultimately sidetracked the U.S. from addressing the long-term challenge posed by China.
<ul>
<li>While the Bush administration claimed that both priorities could be managed simultaneously, the focus on counterterrorism, particularly the protracted conflict in Iraq, consumed the majority of resources and attention.</li>
</ul></li>
</ul>
</section>
<section id="the-persistence-of-complacency-reliving-past-glories" class="level4">
<h4 class="anchored" data-anchor-id="the-persistence-of-complacency-reliving-past-glories">The Persistence of Complacency: Reliving Past Glories</h4>
<ul>
<li>Despite claims of transformation, the initial victories in Afghanistan and Iraq were, in essence, repetitions of past successes, achieved against significantly weaker opponents.
<ul>
<li>The U.S. retained its ability to dictate the terms of engagement, operate from secure sanctuaries, and leverage its technological superiority.</li>
</ul></li>
<li>The core issue remained unchanged: the lack of urgency to embrace genuine transformation.
<ul>
<li>The perceived ease of these victories reinforced the belief in the U.S.’s military dominance and the validity of its traditional approaches to warfare.</li>
<li>Even as the Iraq War deteriorated into a strategic quagmire, the defense establishment largely dismissed it as an anomaly, clinging to outdated assumptions.</li>
</ul></li>
<li>The U.S. continued to invest heavily in traditional military platforms, planning for future conflicts that mirrored those of the past – fought against technologically inferior adversaries on uncontested battlefields.</li>
</ul>
</section>
<section id="the-real-cost-of-war-neglecting-the-future" class="level4">
<h4 class="anchored" data-anchor-id="the-real-cost-of-war-neglecting-the-future">The Real Cost of War: Neglecting the Future</h4>
<ul>
<li><p>A prevailing narrative within the defense establishment argues that the U.S. military’s lack of preparedness for future challenges stems from the overwhelming demands of the War on Terror, which consumed its budget and bandwidth.</p>
<ul>
<li>While the constant operational tempo undoubtedly took a toll, this narrative only tells part of the story.</li>
</ul></li>
<li><p>The root cause lies in a failure of imagination and a misallocation of resources.</p>
<ul>
<li>The U.S. clung to the idea that a persistent global military presence, rather than investing in and showcasing innovative capabilities, would deter adversaries.</li>
<li>This strategy, however, led to the overextension and exhaustion of the military, with limited strategic gains.</li>
</ul></li>
<li><p>Instead of prioritizing the development of faster, more adaptable kill chains through real-world experimentation, the U.S. poured vast sums into attempting to transform existing platforms, often with little success.</p></li>
<li><p>Billions were wasted on numerous modernization programs that were ultimately canceled without yielding any usable capabilities.</p>
<ul>
<li>Examples include the Army’s Future Combat System ($18.1 billion), the Marine Corps’ Expeditionary Fighting Vehicle ($3.3 billion), and a host of other projects across all services.</li>
</ul></li>
<li><p>Even those programs that weren’t canceled often faced significant delays, cost overruns, and ultimately failed to deliver the promised “transformational” capabilities.</p>
<ul>
<li>This includes high-profile programs like the F-35 Joint Strike Fighter, the Ford-class aircraft carrier, the KC-46 refueling tanker, and the Littoral Combat Ship, as well as numerous lesser-known systems.</li>
<li>Many of these systems were rushed into development before the underlying technologies were mature, leading to persistent problems and escalating costs.</li>
</ul></li>
</ul>
</section>
<section id="a-tower-of-babel-the-failure-of-interoperability" class="level4">
<h4 class="anchored" data-anchor-id="a-tower-of-babel-the-failure-of-interoperability">A Tower of Babel: The Failure of Interoperability</h4>
<ul>
<li>One of the most glaring failures was the lack of interoperability between different military systems, despite the emphasis on information sharing and joint operations.
<ul>
<li>Systems were often designed with incompatible communication and data-sharing protocols, hindering their ability to function as a cohesive network.</li>
</ul></li>
<li>A prime example is the inability of the F-22 and F-35A fighter jets, both Air Force programs built by the same company, to directly share basic targeting data.
<ul>
<li>This lack of seamless integration forced reliance on outdated communication methods, such as voice transmissions.</li>
</ul></li>
<li>This issue of interoperability plagued all branches of the military, stemming from a system that incentivized closed, proprietary technologies, benefiting defense contractors while hindering the development of truly integrated kill chains.</li>
</ul>
</section>
<section id="stifled-innovation-the-price-of-protecting-the-past" class="level4">
<h4 class="anchored" data-anchor-id="stifled-innovation-the-price-of-protecting-the-past">Stifled Innovation: The Price of Protecting the Past</h4>
<ul>
<li><p>While some genuinely revolutionary technologies were explored, they often faced resistance and were ultimately sidelined or abandoned.</p>
<ul>
<li>The Defense Advanced Research Projects Agency (DARPA) made progress in areas like artificial intelligence, but these projects rarely transitioned into operational capabilities.</li>
<li>Other initiatives, such as the development of semi-autonomous long-range anti-ship missiles and unmanned combat air vehicles, struggled for funding and were eventually discontinued.</li>
</ul></li>
<li><p>The Navy’s X-47, the first unmanned aerial vehicle capable of launching from and landing on an aircraft carrier, demonstrated remarkable technological prowess but was canceled despite its success.</p></li>
<li><p>This resistance to innovation stemmed from the prioritization of traditional platforms, particularly manned aircraft, which were seen as central to the identity and budget justifications of the military services.</p>
<ul>
<li>The focus on incremental improvements to these legacy systems, rather than embracing disruptive technologies, hindered the development of truly transformational capabilities.</li>
</ul></li>
</ul>
</section>
<section id="the-wrong-priorities-building-for-the-last-war" class="level4">
<h4 class="anchored" data-anchor-id="the-wrong-priorities-building-for-the-last-war">The Wrong Priorities: Building for the Last War</h4>
<ul>
<li><p>The Pentagon and Congress essentially got military modernization backward, prioritizing incremental upgrades to existing platforms (tanks, manned aircraft, large satellites, and ships) over the development of integrated battle networks.</p>
<ul>
<li>This approach ignored Marshall’s warnings that these legacy systems would become increasingly vulnerable in a future characterized by advanced reconnaissance strike complexes.</li>
</ul></li>
<li><p>The result was a collection of disparate sensors and weapons systems, lacking seamless interoperability and requiring significant time and effort to function cohesively.</p></li>
<li><p>This outcome was not an accident but rather a consequence of a system that valued platforms over networks and incentivized the preservation of existing structures.</p></li>
</ul>
</section>
<section id="the-iraq-war-a-death-knell-for-transformation" class="level4">
<h4 class="anchored" data-anchor-id="the-iraq-war-a-death-knell-for-transformation">The Iraq War: A Death Knell for Transformation</h4>
<ul>
<li><p>The Iraq War ultimately dealt a fatal blow to the concept of RMA, but not in the way Rumsfeld initially envisioned.</p>
<ul>
<li>As the conflict dragged on, revealing critical equipment shortages (body armor, blast-resistant vehicles, and unmanned surveillance aircraft) and mounting casualties, the idea of technological transformation became associated with a failure to adequately equip and support troops in the present.</li>
</ul></li>
<li><p>This fueled a backlash against “revolution,” shifting the focus back to conventional warfare and traditional platforms.</p>
<ul>
<li>By 2008, Secretary of Defense Robert Gates criticized what he termed “next-war-itis,” arguing against prioritizing future needs over current demands.</li>
</ul></li>
<li><p>In reality, the more pervasive affliction was “last-war-itis” – an overreliance on past successes and a reluctance to adapt to a changing strategic environment.</p></li>
<li><p>The U.S., instead of embracing transformation, doubled down on its existing playbook, prioritizing legacy systems and preparing for conflicts that resembled those it had already fought.</p></li>
</ul>
<hr>
</section>
</section>
<section id="the-obama-years-a-decade-of-drift-and-denial-2009-2017" class="level3">
<h3 class="anchored" data-anchor-id="the-obama-years-a-decade-of-drift-and-denial-2009-2017">The Obama Years: A Decade of Drift and Denial (2009-2017)</h3>
<section id="continuing-the-cycle-more-missions-fewer-resources" class="level4">
<h4 class="anchored" data-anchor-id="continuing-the-cycle-more-missions-fewer-resources">Continuing the Cycle: More Missions, Fewer Resources</h4>
<ul>
<li><p>Despite inheriting two wars and a global financial crisis, the Obama administration largely continued the trend of prioritizing present demands over future preparedness.</p>
<ul>
<li>While President Obama campaigned on ending the wars in Iraq and Afghanistan, his tenure saw a continuation of these conflicts and the expansion of military operations into Libya, Yemen, Syria, and elsewhere.</li>
</ul></li>
<li><p>Although Obama called for a “pivot to Asia” to counter China’s rise, and his administration initiated the “Air-Sea Battle” concept to address China’s growing military capabilities in the western Pacific, these efforts were undermined by budgetary constraints.</p></li>
<li><p>The 2011 Budget Control Act, enacted to reduce federal spending, mandated $1 trillion in defense cuts over a decade, triggering a scramble for resources within the defense establishment.</p>
<ul>
<li>This resulted in a prioritization of short-term needs and legacy programs over long-term modernization and innovation.</li>
<li>The military continued to receive more missions but not the resources to effectively execute them or prepare for future challenges.</li>
</ul></li>
</ul>
</section>
<section id="the-tyranny-of-the-present-shackled-to-outdated-systems" class="level4">
<h4 class="anchored" data-anchor-id="the-tyranny-of-the-present-shackled-to-outdated-systems">The Tyranny of the Present: Shackled to Outdated Systems</h4>
<ul>
<li>This constant focus on “current operations” resulted in a military increasingly ill-suited for the evolving character of warfare.
<ul>
<li>The U.S.’s rigid, manually intensive, and slow-to-adapt kill chains struggled to cope with dynamic targets and complex, multifaceted challenges.</li>
</ul></li>
<li>The underlying technologies underpinning the U.S.’s decision-making and action cycles remained largely static, trapped in “black boxes” that were difficult to upgrade.
<ul>
<li>This reflected a dangerous assumption of perpetual dominance, neglecting the critical need for adaptability and innovation.</li>
</ul></li>
</ul>
</section>
<section id="the-ambush-of-the-future-2014-and-beyond" class="level4">
<h4 class="anchored" data-anchor-id="the-ambush-of-the-future-2014-and-beyond">The Ambush of the Future: 2014 and Beyond</h4>
<ul>
<li><p>Andrew Marshall, upon retiring in 2015 after 42 years at the helm of the ONA, witnessed his warnings about the U.S.’s unpreparedness for the future of warfare coming to pass.</p></li>
<li><p>The annexation of Crimea by Russia in February 2014 marked a turning point, signaling a new era of great power competition and the return of interstate conflict.</p></li>
<li><p>The U.S., having prioritized the present at the expense of the future, found itself vulnerable to this “ambush by the future.”</p></li>
<li><p>The very technologies and strategies that Marshall had cautioned against decades earlier – anti-access and area denial capabilities, advanced reconnaissance strike complexes, and the exploitation of information dominance – were now being employed by adversaries, rendering the U.S.’s traditional advantages less certain.</p></li>
</ul>
</section>
</section>
</section>
<section id="chapter-2-little-green-men-and-assassins-mace" class="level2">
<h2 class="anchored" data-anchor-id="chapter-2-little-green-men-and-assassins-mace">Chapter 2: Little Green Men and Assassin’s Mace</h2>
<section id="the-reemergence-of-great-power-competition" class="level3">
<h3 class="anchored" data-anchor-id="the-reemergence-of-great-power-competition">The Reemergence of Great Power Competition</h3>
<section id="russias-ambush-in-ukraine-2014" class="level4">
<h4 class="anchored" data-anchor-id="russias-ambush-in-ukraine-2014">Russia’s Ambush in Ukraine (2014)</h4>
<ul>
<li><p>On February 27, 2014, <strong>“little green men,”</strong> masked soldiers in unmarked green uniforms, began seizing control of strategic locations in Crimea, Ukraine.</p>
<ul>
<li>Speculation immediately arose that these were Russian special forces, a notion initially downplayed by U.S. officials.</li>
<li>This event caught the U.S. government off guard, despite indications of Russian military movements into Crimea.</li>
</ul></li>
<li><p>The “little green men” swiftly took control of Crimea:</p>
<ul>
<li>Seizing control of key infrastructure.</li>
<li>Blockading Ukrainian military forces.</li>
<li>Sealing off the peninsula from the rest of Ukraine.</li>
<li>Forcing the evacuation of 25,000 Ukrainian troops.</li>
</ul></li>
<li><p>On March 21, 2014, Russia annexed Crimea, marking the first violent change of an international border in Europe since World War II.</p></li>
<li><p>The “little green men” employed advanced military tactics and technology:</p>
<ul>
<li>Incited and supported Russian-speaking separatist groups.</li>
<li>Utilized sophisticated Russian military systems, including electronic warfare, communications jammers, air defenses, and long-range precision rocket artillery.
<ul>
<li>Much of this technology surpassed the capabilities of the U.S. military.</li>
</ul></li>
</ul></li>
<li><p><strong>Examples of Russian military superiority as recounted by Ukrainian commanders:</strong></p>
<ul>
<li>Jamming Ukrainian drones, causing them to crash.</li>
<li>Jamming the fuses on Ukrainian warheads, rendering them inert.</li>
<li>Detecting Ukrainian communications signals and using them to target attacks.</li>
<li>Deploying unmanned spotter drones to identify and target armored vehicles.</li>
<li>Using thermobaric warheads to eliminate Ukrainian troops in bunkers and trenches.</li>
<li>Annihilating Ukrainian troop columns with cluster munitions.</li>
<li><strong>Targeted assassination:</strong> Using intercepted cell phone data to geolocate and eliminate a Ukrainian commander.</li>
</ul></li>
<li><p><strong>Russia’s Actions in Ukraine Demonstrated:</strong></p>
<ul>
<li>The emergence of a <strong>“reconnaissance strike complex,”</strong> a network of sensors and shooters enabling rapid and lethal targeting.</li>
<li>A new form of warfare that the U.S. military was ill-prepared to counter.</li>
</ul></li>
</ul>
</section>
<section id="russias-military-expansion-2014-2016" class="level4">
<h4 class="anchored" data-anchor-id="russias-military-expansion-2014-2016">Russia’s Military Expansion (2014-2016)</h4>
<ul>
<li>The same Russian military tactics and technology used in Ukraine surfaced in Syria in 2015, where U.S. forces were engaged in combat.</li>
<li><strong>U.S. forces faced a range of threats from this modernized Russian military:</strong>
<ul>
<li>Jammed communications.</li>
<li>Advanced anti-aircraft missile batteries.</li>
<li>Aggressive maneuvers by Russian warships and submarines.</li>
<li>The use of cruise missiles in close proximity to U.S. Navy ships.</li>
</ul></li>
<li>Russia’s military expansion extended to NATO’s eastern flank:
<ul>
<li>Violation of the Intermediate Nuclear Forces Treaty with the deployment of ground-launched cruise missiles capable of reaching Europe.</li>
<li>Snap military movements near NATO borders, raising concerns about potential aggression.</li>
<li>Threats of nuclear escalation to deter U.S. intervention.</li>
</ul></li>
<li><strong>Analysis of Russia’s Military Capabilities:</strong>
<ul>
<li>In 2016, RAND Corporation analysts David Shlapek and Michael Johnson predicted that Russian forces could reach the capitals of all three Baltic states within 60 hours, overwhelming NATO defenses.</li>
<li>This analysis highlighted the growing concern within the U.S. Department of Defense and Congress that the U.S. military was unprepared for a potential conflict with Russia and could potentially lose.</li>
</ul></li>
<li><strong>Factors Contributing to U.S. Military Weakness:</strong>
<ul>
<li>Withdrawal of combat power from Europe to support operations in the Middle East.</li>
<li>Costly but ineffective military modernization programs.</li>
<li>Divestment from systems and weapons that proved crucial in countering Russia’s tactics.</li>
<li>A military optimized for fighting less technologically advanced adversaries.</li>
</ul></li>
</ul>
</section>
<section id="the-roots-of-miscalculation-russia" class="level4">
<h4 class="anchored" data-anchor-id="the-roots-of-miscalculation-russia">The Roots of Miscalculation: Russia</h4>
<ul>
<li><strong>Post-Cold War Optimism:</strong>
<ul>
<li>The fall of the Soviet Union fostered hope in the West for a democratic and capitalist Russia that could become a U.S. ally.</li>
<li>This optimism led to U.S. assistance for Russia’s transition, including support for nuclear security and integration into global institutions like the G8 and World Trade Organization.</li>
</ul></li>
<li><strong>Divergent Interests:</strong>
<ul>
<li>Despite U.S. efforts, Russia prioritized restoring its great power status over partnership with the West.</li>
<li>Conflicts like Kosovo and Iraq exposed the power imbalance between the two nations.</li>
</ul></li>
<li><strong>Putin’s Rise and Resurgence:</strong>
<ul>
<li>Vladimir Putin, who became president in 1999, viewed the Soviet Union’s collapse as a geopolitical disaster.</li>
<li>He prioritized restoring Russia’s military might and geopolitical influence.</li>
</ul></li>
<li><strong>Military Modernization and Expansion:</strong>
<ul>
<li>Putin accelerated military modernization, focusing on:
<ul>
<li>Technologically advanced weapons.</li>
<li>Long-range missiles and rockets.</li>
<li>Highly capable special operations forces.</li>
<li>Advanced air defenses.</li>
<li>Electronic warfare and cyber weapons.</li>
<li>Anti-satellite capabilities.</li>
<li>Tactical nuclear weapons.</li>
</ul></li>
</ul></li>
<li><strong>The Gerasimov Doctrine:</strong>
<ul>
<li>General Valery Gerasimov, Russia’s chief of the General Staff, outlined a new approach to warfare in 2013 that blended military and non-military tactics.</li>
<li><strong>This doctrine emphasized:</strong>
<ul>
<li>Exploiting political and social fault lines.</li>
<li>Employing misinformation campaigns, political subversion, assassinations, cyberattacks, and social media manipulation.</li>
<li>Expanding the battlefield to encompass all aspects of society.</li>
</ul></li>
</ul></li>
<li><strong>Russia’s Interference in the 2016 U.S. Election:</strong>
<ul>
<li>Russia’s use of the Gerasimov Doctrine extended to interfering in the 2016 U.S. presidential election.</li>
<li>This interference aimed to undermine American democracy and sow discord.</li>
</ul></li>
</ul>
</section>
<section id="the-miscalculations-of-u.s.-policy-toward-russia" class="level4">
<h4 class="anchored" data-anchor-id="the-miscalculations-of-u.s.-policy-toward-russia">The Miscalculations of U.S. Policy Toward Russia</h4>
<ul>
<li>Successive U.S. presidents, from Clinton to Trump, entered office seeking improved relations with Russia, often misinterpreting Russia’s motives.</li>
<li>The bipartisan consensus on engaging Russia blinded U.S. policymakers to the growing threat posed by its military ambitions.</li>
<li>The U.S. focus on economic engagement with China further diverted attention from Russia’s resurgence.</li>
</ul>
</section>
</section>
<section id="chinas-island-ambush-2014" class="level3">
<h3 class="anchored" data-anchor-id="chinas-island-ambush-2014">China’s Island Ambush (2014)</h3>
<ul>
<li><p>While the U.S. was preoccupied with Russia’s actions in Ukraine, China made a strategic move in the South China Sea.</p></li>
<li><p>China ramped up its efforts to assert control over the South China Sea, a region through which $3.4 trillion in global trade (much of it vital to the U.S. economy) flows annually.</p></li>
<li><p><strong>China’s Island-Building Campaign:</strong></p>
<ul>
<li>In 2014, China deployed large dredgers to transform shallow reefs and atolls into artificial islands.</li>
<li>This construction occurred in territories claimed by other nations, directly challenging their sovereignty.</li>
</ul></li>
<li><p><strong>Militarization of Artificial Islands:</strong></p>
<ul>
<li>China began constructing military infrastructure on the artificial islands, including:
<ul>
<li>Runways.</li>
<li>Control towers.</li>
<li>Aircraft hangars.</li>
<li>Military bases.</li>
</ul></li>
</ul></li>
<li><p><strong>Deployment of Advanced Weaponry:</strong></p>
<ul>
<li>The U.S. government observed and publicly criticized China for installing:
<ul>
<li>Long-range radars.</li>
<li>Surface-to-air missile batteries.</li>
<li>Fighter aircraft.</li>
</ul></li>
</ul></li>
<li><p><strong>China’s Denial:</strong></p>
<ul>
<li>Despite clear evidence, Chinese President Xi Jinping denied the militarization of the islands.</li>
</ul></li>
</ul>
</section>
<section id="the-strategic-challenge-of-china" class="level3">
<h3 class="anchored" data-anchor-id="the-strategic-challenge-of-china">The Strategic Challenge of China</h3>
<ul>
<li>China’s actions in the South China Sea were part of a larger pattern of military modernization and expansion.</li>
<li>Unlike Russia, China possessed significantly greater economic and military potential, posing a more formidable long-term challenge to U.S. interests.</li>
</ul>
<section id="the-roots-of-miscalculation-china" class="level4">
<h4 class="anchored" data-anchor-id="the-roots-of-miscalculation-china">The Roots of Miscalculation: China</h4>
<ul>
<li><strong>Post-Cold War Partnership:</strong>
<ul>
<li>The U.S. and China shared common ground during the latter half of the Cold War, aligning to counter Soviet influence.</li>
<li>This partnership shaped a belief in Washington that China could be molded to fit U.S. interests through economic engagement.</li>
</ul></li>
<li><strong>The Gulf War Wake-Up Call (1991):</strong>
<ul>
<li>China closely studied the Gulf War, recognizing the technological superiority of the U.S. military.</li>
<li>The conflict revealed vulnerabilities in China’s own military capabilities, prompting a reassessment of its defense strategy.</li>
</ul></li>
<li><strong>China’s Military Transformation:</strong>
<ul>
<li>Following the Gulf War, China embarked on a comprehensive military modernization program.</li>
<li>This program aimed to develop <strong>“Assassin’s Mace”</strong> weapons, systems designed to exploit vulnerabilities in U.S. military capabilities.</li>
</ul></li>
<li><strong>Targeting U.S. Vulnerabilities:</strong>
<ul>
<li><strong>U.S. Military Bases:</strong> China developed medium-range and long-range ballistic missiles to target U.S. bases in Japan and Guam, intending to overwhelm their defenses.</li>
<li><strong>U.S. Strike Aircraft:</strong> China invested in early warning radars, integrated air and missile defense systems, and powerful jammers to counter U.S. air power.</li>
<li><strong>U.S. Aircraft Carriers:</strong> China developed over-the-horizon radars, reconnaissance satellites, and anti-ship ballistic missiles (like the DF-21 “carrier killer”) to target U.S. aircraft carriers.</li>
<li><strong>Command and Control Systems:</strong> China invested in advanced aircraft, electronic warfare, cyber capabilities, and anti-satellite missiles to disrupt U.S. communications, intelligence gathering, and command and control networks.</li>
</ul></li>
<li><strong>Systems Destruction Warfare:</strong>
<ul>
<li>China’s military doctrine focused on <strong>“systems destruction warfare,”</strong> aiming to cripple the U.S. military’s ability to operate by targeting its supporting infrastructure.</li>
</ul></li>
</ul>
</section>
<section id="chinas-modernization-and-expansion" class="level4">
<h4 class="anchored" data-anchor-id="chinas-modernization-and-expansion">China’s Modernization and Expansion</h4>
<ul>
<li>In addition to “Assassin’s Mace” weapons, China modernized its conventional military forces:
<ul>
<li>Building a blue-water navy with advanced warships and aircraft carriers.</li>
<li>Developing amphibious assault capabilities.</li>
<li>Fielding long-range bombers and advanced fighter jets.</li>
</ul></li>
<li><strong>Nuclear Buildup:</strong>
<ul>
<li>China expanded its nuclear arsenal:
<ul>
<li>Mastering nuclear warhead miniaturization.</li>
<li>Developing a nuclear triad (land-based missiles, submarine-launched missiles, and aircraft-delivered bombs).</li>
<li>Building increasingly sophisticated delivery systems.</li>
</ul></li>
</ul></li>
<li><strong>Technology Theft:</strong>
<ul>
<li>China engaged in widespread theft of intellectual property to accelerate its military modernization:
<ul>
<li>Acquiring nuclear weapons designs.</li>
<li>Stealing designs for advanced military technologies.</li>
<li>Exploiting joint ventures to access proprietary information from U.S. companies.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="the-scale-of-the-china-challenge" class="level4">
<h4 class="anchored" data-anchor-id="the-scale-of-the-china-challenge">The Scale of the China Challenge</h4>
<ul>
<li>China’s military buildup posed a more significant threat than Russia’s due to its greater economic power and sustained investment.</li>
<li>While Russia’s actions in Ukraine served as a wake-up call, China’s long-term strategic ambitions presented a far greater challenge to U.S. military dominance.</li>
</ul>
</section>
<section id="missed-opportunities-and-distractions" class="level4">
<h4 class="anchored" data-anchor-id="missed-opportunities-and-distractions">Missed Opportunities and Distractions</h4>
<ul>
<li>Despite warning signs dating back to the early 1990s, the U.S. failed to adequately address the growing military challenge posed by China.</li>
<li><strong>Factors Contributing to U.S. Inattention:</strong>
<ul>
<li>The aftermath of the September 11th attacks and the wars in the Middle East consumed U.S. foreign policy attention.</li>
<li>The persistence of the belief that economic engagement would liberalize China and align its interests with the West.</li>
<li>Domestic business interests often prioritized economic ties with China over security concerns.</li>
</ul></li>
</ul>
</section>
<section id="the-reemergence-of-great-power-competition-1" class="level4">
<h4 class="anchored" data-anchor-id="the-reemergence-of-great-power-competition-1">The Reemergence of Great Power Competition</h4>
<ul>
<li>The events of 2014, with both Russia and China demonstrating their growing military assertiveness, forced a reassessment of the global security landscape.</li>
<li>The concept of great power competition reemerged as a defining feature of international relations.</li>
</ul>
</section>
<section id="the-u.s.-response" class="level4">
<h4 class="anchored" data-anchor-id="the-u.s.-response">The U.S. Response</h4>
<ul>
<li><strong>Robert Work,</strong> then-Deputy Secretary of Defense, spearheaded efforts to counter the emerging threat from China and Russia.</li>
<li>Work advocated for a <strong>“new offset strategy”</strong> focused on leveraging cutting-edge technologies, like artificial intelligence, to maintain U.S. military superiority.</li>
<li>This strategy aimed to revitalize the concept of a <strong>“revolution in military affairs”</strong> by developing information-centric battle networks.</li>
</ul>
</section>
<section id="challenges-to-u.s.-military-modernization" class="level4">
<h4 class="anchored" data-anchor-id="challenges-to-u.s.-military-modernization">Challenges to U.S. Military Modernization</h4>
<ul>
<li>Despite years of investment, the U.S. military struggled to acquire the advanced technologies needed to maintain its edge.</li>
<li>Many key technologies were being developed by commercial tech companies reluctant to work with the Department of Defense.</li>
<li>The U.S. military’s bureaucratic procurement processes hindered its ability to adapt to the rapidly evolving technological landscape.</li>
</ul>
</section>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<ul>
<li>The events of 2014 exposed the U.S. military’s unpreparedness for the reemergence of great power competition.</li>
<li>The U.S. had become complacent, clinging to outdated assumptions about the global security environment.</li>
<li>Both Russia and China, each with its own motivations and capabilities, emerged as serious challengers to U.S. military dominance.</li>
<li>Addressing these challenges required a fundamental shift in U.S. strategic thinking, military modernization, and technological innovation.</li>
</ul>
</section>
</section>
<section id="chapter-3-a-tale-of-two-cities" class="level2">
<h2 class="anchored" data-anchor-id="chapter-3-a-tale-of-two-cities">Chapter 3: A Tale of Two Cities</h2>
<p>This chapter describes how America’s approach to military technology development shifted during the Cold War and its aftermath, leading to a disconnect between the military and Silicon Valley.</p>
<section id="the-rise-of-the-military-industrial-complex" class="level3">
<h3 class="anchored" data-anchor-id="the-rise-of-the-military-industrial-complex">The Rise of the Military-Industrial Complex</h3>
<ul>
<li><strong>The Military-Industrial Complex</strong>: The close relationship between the Department of Defense, private defense companies, and Congress, formed during the Cold War.
<ul>
<li>This relationship was initially characterized by a sense of urgency and a willingness to take risks to stay ahead of the Soviet Union.</li>
</ul></li>
</ul>
<section id="eisenhowers-approach-picking-winners" class="level4">
<h4 class="anchored" data-anchor-id="eisenhowers-approach-picking-winners">Eisenhower’s Approach: Picking Winners</h4>
<ul>
<li><strong>President Eisenhower’s Philosophy:</strong> Concentrate resources and empower exceptional individuals (“<strong>founders</strong>”) to develop critical military technologies.
<ul>
<li><strong>Example:</strong> General Bernard Schriever and the development of intercontinental ballistic missiles (ICBMs).
<ul>
<li>Schriever was given broad authority, ample funding, and protection from bureaucratic interference.</li>
<li>His team successfully developed ICBMs, laying the groundwork for space exploration, in just five years.</li>
</ul></li>
</ul></li>
<li><strong>Other “Founders” and their Achievements:</strong>
<ul>
<li><strong>Edward Teller:</strong> Developed the hydrogen bomb.</li>
<li><strong>Admiral Hyman Rickover:</strong> Developed miniaturized nuclear reactors for submarines.</li>
<li><strong>Kelly Johnson:</strong> Developed advanced aircraft, including the SR-71 Blackbird.</li>
</ul></li>
<li><strong>Prioritizing Speed and Results:</strong>
<ul>
<li>Efficiency and cost-effectiveness were secondary to rapid development and fielding of advanced weapons.</li>
<li>This approach was accepted as the price of staying ahead in the Cold War.</li>
</ul></li>
<li><strong>Silicon Valley’s Origins:</strong>
<ul>
<li>Defense contracts during and after World War II transformed Silicon Valley from an agricultural region into a hub of electronics and technology innovation.</li>
<li>This military funding fueled the development of technologies like mainframes, microprocessors, and the internet.</li>
<li>Early Silicon Valley embraced working on military technologies, driven by the challenges and the belief in contributing to national security.</li>
</ul></li>
</ul>
</section>
</section>
<section id="the-bureaucratization-of-innovation" class="level3">
<h3 class="anchored" data-anchor-id="the-bureaucratization-of-innovation">The Bureaucratization of Innovation</h3>
<section id="the-shift-toward-bureaucracy" class="level4">
<h4 class="anchored" data-anchor-id="the-shift-toward-bureaucracy">The Shift Toward Bureaucracy</h4>
<ul>
<li><strong>The 1960s and Onward:</strong>
<ul>
<li>The military-industrial complex became increasingly bureaucratic.</li>
<li><strong>Robert McNamara’s Influence (Secretary of Defense, 1960s):</strong>
<ul>
<li>Introduced industrial-age management practices, prioritizing efficiency.</li>
<li>Added layers of oversight, analysis, and management, slowing down innovation.</li>
</ul></li>
</ul></li>
<li><strong>Congressional Constraints:</strong>
<ul>
<li>Budget processes made it difficult to fund new or unconventional ideas.</li>
<li>Multi-year budget cycles favored predictable, established programs over rapid adaptation.</li>
</ul></li>
<li><strong>Consequences:</strong>
<ul>
<li>Military technology development became slower, more expensive, and less creative.</li>
</ul></li>
</ul>
</section>
<section id="the-growing-divide-between-washington-and-silicon-valley" class="level4">
<h4 class="anchored" data-anchor-id="the-growing-divide-between-washington-and-silicon-valley">The Growing Divide Between Washington and Silicon Valley</h4>
<ul>
<li><strong>The Vietnam War Era (Late 1960s - Early 1970s):</strong>
<ul>
<li>Silicon Valley engineers became increasingly uncomfortable working on military projects.</li>
</ul></li>
<li><strong>Circumventing the System:</strong>
<ul>
<li>By the late 1970s, defense innovators were forced to work around the rigid acquisition system to develop advanced technology quickly (e.g., stealth aircraft).</li>
</ul></li>
<li><strong>The Packard Commission (1980s):</strong>
<ul>
<li>Formed to address problems in military acquisition.</li>
<li>General Schriever’s Critique:
<ul>
<li>The system had become too slow, expensive, politicized, and bureaucratic.</li>
<li>Innovation was stifled by micromanagement and a focus on process over results.</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="the-post-cold-war-era-a-widening-chasm" class="level3">
<h3 class="anchored" data-anchor-id="the-post-cold-war-era-a-widening-chasm">The Post-Cold War Era: A Widening Chasm</h3>
<section id="loss-of-urgency-and-misguided-priorities" class="level4">
<h4 class="anchored" data-anchor-id="loss-of-urgency-and-misguided-priorities">Loss of Urgency and Misguided Priorities</h4>
<ul>
<li><strong>The End of the Soviet Threat:</strong>
<ul>
<li>Removed the primary driver of rapid military technological innovation.</li>
<li>The U.S. military was dominant, reducing pressure to stay ahead.</li>
</ul></li>
<li><strong>Defense Industry Consolidation:</strong>
<ul>
<li>William Perry, Deputy Secretary of Defense (1993), predicted consolidation in the defense industry due to declining budgets, leading to mergers and acquisitions.
<ul>
<li>The number of major defense firms shrunk drastically.</li>
</ul></li>
</ul></li>
<li><strong>Changes in Funding and Focus:</strong>
<ul>
<li>Reduced R&amp;D funding, with remaining funds often politically motivated.</li>
<li>Small, fragmented contracts that rarely led to significant programs.</li>
<li>Emphasis on spreading contracts and supporting small businesses over achieving technological breakthroughs.</li>
</ul></li>
<li><strong>Slowing Innovation Cycles and Risk Aversion:</strong>
<ul>
<li>Development cycles for new military systems stretched to decades.</li>
<li>Focus shifted from developing new technologies to maintaining existing ones.</li>
<li>This lack of opportunity for innovation drove talented engineers away from the defense sector.</li>
</ul></li>
<li><strong>The “Valley of Death”:</strong>
<ul>
<li>Many technology companies struggled to transition small projects and demos into large-scale military programs, leading to wasted potential.</li>
</ul></li>
<li><strong>Unattractive Market for Startups:</strong>
<ul>
<li>High failure rates for companies attempting to work with the government.</li>
<li>Difficulty attracting investment compared to the booming commercial tech sector.</li>
</ul></li>
<li><strong>Consequences:</strong>
<ul>
<li>A growing disconnect between the needs of the military and the capabilities of the tech industry.</li>
</ul></li>
</ul>
</section>
<section id="perverse-incentives-and-their-consequences" class="level4">
<h4 class="anchored" data-anchor-id="perverse-incentives-and-their-consequences">Perverse Incentives and Their Consequences</h4>
<ul>
<li><strong>Focus on Efficiency Over Effectiveness:</strong>
<ul>
<li>The defense acquisition system became increasingly optimized for transparency, fairness, and administrative ease at the expense of speed and innovation.</li>
</ul></li>
<li><strong>Risk Aversion and Incrementalism:</strong>
<ul>
<li>Prioritizing technologically acceptable solutions at the lowest cost over potentially revolutionary advancements.</li>
</ul></li>
<li><strong>“Programs of Record” and Inertia:</strong>
<ul>
<li>Established programs, once funded, became difficult to displace, hindering the adoption of new technologies.</li>
</ul></li>
<li><strong>Defense Industry Adaptation:</strong>
<ul>
<li>Companies adapted to the Pentagon’s bureaucratic procurement system, focusing on fulfilling specific requirements rather than driving innovation.</li>
<li>This led to cost overruns, delays, and a resistance to new technologies that threatened existing programs.</li>
</ul></li>
<li><strong>Further Consolidation:</strong>
<ul>
<li>Increased regulations and costs favored larger companies that could navigate the complex system, leading to further consolidation and reduced competition.</li>
</ul></li>
</ul>
</section>
</section>
<section id="the-information-revolution-a-missed-opportunity" class="level3">
<h3 class="anchored" data-anchor-id="the-information-revolution-a-missed-opportunity">The Information Revolution: A Missed Opportunity</h3>
<section id="the-rise-of-silicon-valley-and-commercial-tech" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-silicon-valley-and-commercial-tech">The Rise of Silicon Valley and Commercial Tech</h4>
<ul>
<li><strong>The Commercial Tech Boom:</strong>
<ul>
<li>The internet boom and subsequent technological advancements created a massive commercial market for Silicon Valley.</li>
</ul></li>
<li><strong>Shifting Focus and Funding:</strong>
<ul>
<li>Talented engineers and investors were drawn to the faster pace, larger profits, and less bureaucratic environment of the commercial sector.</li>
<li>Silicon Valley became the epicenter of the information revolution, driven by commercial, not military, applications.</li>
</ul></li>
</ul>
</section>
<section id="the-pentagons-blind-spots" class="level4">
<h4 class="anchored" data-anchor-id="the-pentagons-blind-spots">The Pentagon’s Blind Spots</h4>
<ul>
<li><strong>Focus on Platforms Over Networks:</strong>
<ul>
<li>The defense establishment remained focused on building and buying physical platforms rather than the connections between them.</li>
</ul></li>
<li><strong>Lack of Expertise in Connectivity:</strong>
<ul>
<li>Traditional defense companies lacked expertise in software, IT, and network development, crucial aspects of the information revolution.</li>
</ul></li>
<li><strong>Continued Reliance on Familiar Players:</strong>
<ul>
<li>Despite past failures, the Pentagon continued to award large contracts to traditional defense companies for IT and network projects, leading to further wasted resources.</li>
</ul></li>
<li><strong>Consequences:</strong>
<ul>
<li>The U.S. military, despite its vast resources, fell behind in adapting to the rapid pace of the information revolution.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-an-ambush-by-the-future" class="level4">
<h4 class="anchored" data-anchor-id="conclusion-an-ambush-by-the-future">Conclusion: An Ambush by the Future</h4>
<ul>
<li>The information revolution, driven by commercial forces, happened despite the Pentagon, not because of it.</li>
<li>The U.S. military, blinded by its own bureaucracy, missed the opportunity to harness the transformative power of networked technologies.</li>
<li>This disconnect between Washington and Silicon Valley left the U.S. vulnerable to rivals like China, who were rapidly adopting and adapting these new technologies.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-4-information-revolution-2.0" class="level2">
<h2 class="anchored" data-anchor-id="chapter-4-information-revolution-2.0">Chapter 4: Information Revolution 2.0</h2>
<section id="the-widening-gap-between-military-and-commercial-technology" class="level3">
<h3 class="anchored" data-anchor-id="the-widening-gap-between-military-and-commercial-technology">The Widening Gap Between Military and Commercial Technology</h3>
<section id="nvidia-and-the-power-of-edge-computing" class="level4">
<h4 class="anchored" data-anchor-id="nvidia-and-the-power-of-edge-computing">NVIDIA and the Power of Edge Computing</h4>
<ul>
<li>In 2018, executives from NVIDIA, a computing company, visited the Senate to discuss their partnership with Oak Ridge National Laboratory.</li>
<li>They had built the world’s fastest supercomputer, capable of performing 200 quadrillion operations per second using NVIDIA’s <strong>graphics processing units (GPUs)</strong>.
<ul>
<li><strong>GPUs</strong> were originally designed for video games, which demanded increasingly powerful computing capabilities.</li>
<li>NVIDIA realized that the same technology powering artificial worlds in games could also power intelligent machines in the real world, particularly in <strong>artificial intelligence (AI)</strong> and <strong>machine learning</strong>.</li>
</ul></li>
<li>NVIDIA’s GPUs are now crucial for self-driving vehicles.
<ul>
<li>Their Drive AGX Pegasus chip, the size of a textbook, can conduct 320 trillion operations per second, enabling real-time data processing and interpretation on board the vehicle – a concept known as <strong>edge computing</strong>.</li>
</ul></li>
<li>Despite the military applications of their technology, NVIDIA had no GPUs operating on fielded U.S. military systems at the time.
<ul>
<li>This highlights a significant technological gap between the U.S. military and commercial technology companies.</li>
</ul></li>
<li>The most capable computer in a U.S. military system at the time was in the F-35 Joint Strike Fighter, nicknamed the “Flying Supercomputer.”
<ul>
<li>It could perform 400 billion operations per second, significantly less than NVIDIA’s Drive AGX Pegasus.</li>
</ul></li>
</ul>
</section>
<section id="the-u.s.-military-trapped-in-the-information-ages-past" class="level4">
<h4 class="anchored" data-anchor-id="the-u.s.-military-trapped-in-the-information-ages-past">The U.S. Military: Trapped in the Information Age’s Past</h4>
<ul>
<li>The U.S. military lags behind in utilizing modern information processing techniques.
<ul>
<li>Data collected by military machines is often processed later, either after a mission or streamed back to an operations center, putting a strain on communication networks and relying heavily on human analysis.</li>
</ul></li>
<li>While the Department of Defense built the precursor to the internet, it has fallen behind in adopting and adapting to the rapid pace of the information revolution, driven largely by commercial technology companies.</li>
<li>The information revolution comprises three key elements:
<ol type="1">
<li><strong>Sensors:</strong> Collect information.</li>
<li><strong>Computers:</strong> Process and store information.</li>
<li><strong>Networks:</strong> Move information.</li>
</ol></li>
<li>Advancements in any one element accelerate progress in the other two, leading to exponential growth.</li>
</ul>
<section id="networks-a-tale-of-two-connectivities" class="level5">
<h5 class="anchored" data-anchor-id="networks-a-tale-of-two-connectivities">Networks: A Tale of Two Connectivities</h5>
<ul>
<li>Commercial telecommunications companies have rapidly advanced network speeds, moving from 3G to 4G and soon to 5G.</li>
<li>The Department of Defense, however, lags in network connectivity, often relying on outdated systems and facing interoperability challenges.</li>
</ul>
</section>
<section id="sensors-a-world-awash-in-data" class="level5">
<h5 class="anchored" data-anchor-id="sensors-a-world-awash-in-data">Sensors: A World Awash in Data</h5>
<ul>
<li>The commercial sector has developed a wide array of low-cost, high-quality sensors, enabling machines to see and hear.</li>
<li>This proliferation of sensors has led to increased situational awareness in homes and vehicles, capabilities often lacking in military systems.</li>
<li>In contrast, the Department of Defense often relies on expensive, highly specialized sensors with limited deployment.</li>
</ul>
</section>
<section id="computing-power-the-rise-of-the-cloud-and-edge" class="level5">
<h5 class="anchored" data-anchor-id="computing-power-the-rise-of-the-cloud-and-edge">Computing Power: The Rise of the Cloud and Edge</h5>
<ul>
<li>The rise of cloud computing has provided almost unlimited processing power and data storage, making these services readily available to anyone.</li>
<li>The Department of Defense has been slow to adopt cloud computing, only recently awarding a contract for an enterprise cloud in 2019.</li>
<li><strong>Edge computing</strong> allows for decentralized processing power, creating a network of smart systems that collect, process, and share information.</li>
</ul>
</section>
</section>
<section id="software-the-achilles-heel-of-military-systems" class="level4">
<h4 class="anchored" data-anchor-id="software-the-achilles-heel-of-military-systems">Software: The Achilles’ Heel of Military Systems</h4>
<ul>
<li>Silicon Valley’s approach to software development emphasizes continuous building, testing, and releasing, leading to constant updates and improvements.</li>
<li>In contrast, the Department of Defense prioritizes hardware over software, resulting in multi-year software development cycles that cannot keep pace with technological advancements.</li>
<li>This disparity results in military personnel using equipment with inferior functionality compared to what they use in their daily lives.</li>
</ul>
</section>
</section>
<section id="the-ai-revolution-silicon-valleys-dominance-and-the-pentagons-lag" class="level3">
<h3 class="anchored" data-anchor-id="the-ai-revolution-silicon-valleys-dominance-and-the-pentagons-lag">The AI Revolution: Silicon Valley’s Dominance and the Pentagon’s Lag</h3>
<section id="the-rise-of-ai-and-machine-learning" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-ai-and-machine-learning">The Rise of AI and Machine Learning</h4>
<ul>
<li>The information revolution, with its abundance of data and computing power, fueled the rise of AI and <strong>machine learning</strong>, enabling machines to learn from data without explicit programming.</li>
<li><strong>Deep learning</strong>, using layered algorithms in a neural network, further advanced AI capabilities.
<ul>
<li>NVIDIA’s GPUs were essential for deep learning, allowing machines to process vast amounts of data quickly.</li>
</ul></li>
<li>Google’s AlphaGo and AlphaStar demonstrated the power of AI in complex games like Go and StarCraft II, surpassing human capabilities.</li>
</ul>
</section>
<section id="the-militarys-struggle-to-adapt-to-ai" class="level4">
<h4 class="anchored" data-anchor-id="the-militarys-struggle-to-adapt-to-ai">The Military’s Struggle to Adapt to AI</h4>
<ul>
<li>While AI is integrated into everyday life, its adoption in the U.S. military has been slow.</li>
<li>The Department of Defense’s traditional approach to data as a byproduct, rather than a valuable asset, hinders the development and implementation of machine learning.</li>
<li>Instead of using AI to analyze data, the Pentagon often relies on increasing manpower, leading to inefficiencies.</li>
</ul>
</section>
</section>
<section id="commercial-space-revolution-outpacing-the-government" class="level3">
<h3 class="anchored" data-anchor-id="commercial-space-revolution-outpacing-the-government">Commercial Space Revolution: Outpacing the Government</h3>
<section id="the-rise-of-low-cost-space-launch" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-low-cost-space-launch">The Rise of Low-Cost Space Launch</h4>
<ul>
<li>The emergence of low-cost commercial space launch companies, such as SpaceX, Blue Origin, and OneWeb, has revolutionized access to space.</li>
<li>Reusable rockets have drastically reduced launch costs, leading to more frequent launches and new satellite designs.</li>
</ul>
</section>
<section id="microsatellites-democratizing-space-technology" class="level4">
<h4 class="anchored" data-anchor-id="microsatellites-democratizing-space-technology">Microsatellites: Democratizing Space Technology</h4>
<ul>
<li>The affordability of launches has led to the rise of <strong>microsatellites</strong>, smaller and cheaper satellites that can be mass-produced and replaced more frequently.</li>
<li>This allows for rapid technological advancement, as new technology is deployed more often.</li>
</ul>
</section>
<section id="spacexs-starlink-a-vision-for-global-connectivity" class="level4">
<h4 class="anchored" data-anchor-id="spacexs-starlink-a-vision-for-global-connectivity">SpaceX’s Starlink: A Vision for Global Connectivity</h4>
<ul>
<li>SpaceX’s Starlink program aims to create a constellation of thousands of microsatellites in low-Earth orbit, providing global high-speed internet access.</li>
<li>This has the potential to connect everyone and everything, regardless of location.</li>
</ul>
</section>
</section>
<section id="advanced-manufacturing-on-demand-production-and-its-military-significance" class="level3">
<h3 class="anchored" data-anchor-id="advanced-manufacturing-on-demand-production-and-its-military-significance">Advanced Manufacturing: On-Demand Production and Its Military Significance</h3>
<section id="transforming-manufacturing-with-technology" class="level4">
<h4 class="anchored" data-anchor-id="transforming-manufacturing-with-technology">Transforming Manufacturing with Technology</h4>
<ul>
<li><strong>Advanced manufacturing</strong> allows for on-demand production of complex components and finished goods at the point of need, reducing costs and lead times.</li>
</ul>
</section>
<section id="additive-manufacturing-the-power-of-3d-printing" class="level4">
<h4 class="anchored" data-anchor-id="additive-manufacturing-the-power-of-3d-printing">Additive Manufacturing: The Power of 3D Printing</h4>
<ul>
<li><strong>Additive manufacturing</strong>, also known as 3D printing, enables the creation of complex parts and products from various materials.</li>
<li>Its applications include aerospace, automotive, and other industries.</li>
</ul>
</section>
<section id="the-future-of-manufacturing-localized-and-on-demand" class="level4">
<h4 class="anchored" data-anchor-id="the-future-of-manufacturing-localized-and-on-demand">The Future of Manufacturing: Localized and On-Demand</h4>
<ul>
<li>Advanced manufacturing, particularly additive manufacturing, has the potential to revolutionize production processes, allowing for localized and on-demand manufacturing with minimal waste.</li>
</ul>
</section>
</section>
<section id="biotechnology-redefining-human-potential-and-military-applications" class="level3">
<h3 class="anchored" data-anchor-id="biotechnology-redefining-human-potential-and-military-applications">Biotechnology: Redefining Human Potential and Military Applications</h3>
<section id="the-genomic-revolution" class="level4">
<h4 class="anchored" data-anchor-id="the-genomic-revolution">The Genomic Revolution</h4>
<ul>
<li>Advancements in computing and machine learning have enabled rapid and affordable genome sequencing.</li>
<li><strong>CRISPR</strong> and other genetic engineering technologies allow for the creation of new genetic materials and life forms.</li>
</ul>
</section>
<section id="human-performance-enhancement" class="level4">
<h4 class="anchored" data-anchor-id="human-performance-enhancement">Human Performance Enhancement</h4>
<ul>
<li>Biotechnology offers the potential for enhancing human capabilities through personalized medicine and biotechnologies.</li>
<li>This raises ethical considerations for military applications.</li>
</ul>
</section>
<section id="brain-computer-interface-technology" class="level4">
<h4 class="anchored" data-anchor-id="brain-computer-interface-technology">Brain-Computer Interface Technology</h4>
<ul>
<li><strong>Brain-computer interface (BCI)</strong> technology enables direct communication between the human brain and machines.</li>
<li>Companies like Neuralink are exploring BCI applications for typing, communication, and potential symbiosis with AI.</li>
<li>BCI has potential military applications in controlling drones, prosthetics, and other systems.</li>
</ul>
</section>
</section>
<section id="quantum-information-technology-a-glimpse-into-the-future" class="level3">
<h3 class="anchored" data-anchor-id="quantum-information-technology-a-glimpse-into-the-future">Quantum Information Technology: A Glimpse into the Future</h3>
<section id="quantum-science-exploiting-the-subatomic-world" class="level4">
<h4 class="anchored" data-anchor-id="quantum-science-exploiting-the-subatomic-world">Quantum Science: Exploiting the Subatomic World</h4>
<ul>
<li><strong>Quantum science</strong> explores the unique properties of matter at the subatomic level.</li>
<li><strong>Superposition:</strong> A quantum particle can exist in multiple states simultaneously.</li>
<li><strong>Entanglement:</strong> Two entangled particles are linked, and actions on one instantaneously affect the other, regardless of distance.</li>
</ul>
</section>
<section id="applications-of-quantum-information-technology" class="level4">
<h4 class="anchored" data-anchor-id="applications-of-quantum-information-technology">Applications of Quantum Information Technology</h4>
<ul>
<li><strong>Quantum sensors:</strong> Highly sensitive sensors capable of detecting minute changes in gravity and magnetic fields.</li>
<li><strong>Quantum communications:</strong> Ultra-secure communication systems based on the principles of entanglement.</li>
<li><strong>Quantum computers:</strong> Exponentially faster computers capable of solving problems beyond the reach of classical computers.</li>
</ul>
</section>
<section id="the-military-implications-of-quantum-technology" class="level4">
<h4 class="anchored" data-anchor-id="the-military-implications-of-quantum-technology">The Military Implications of Quantum Technology</h4>
<ul>
<li>Quantum technologies have the potential to revolutionize warfare, impacting sensing, communication, and computation.</li>
</ul>
</section>
</section>
<section id="the-widening-chasm-silicon-valleys-turn-away-from-the-pentagon" class="level3">
<h3 class="anchored" data-anchor-id="the-widening-chasm-silicon-valleys-turn-away-from-the-pentagon">The Widening Chasm: Silicon Valley’s Turn Away from the Pentagon</h3>
<section id="a-clash-of-cultures-and-values" class="level4">
<h4 class="anchored" data-anchor-id="a-clash-of-cultures-and-values">A Clash of Cultures and Values</h4>
<ul>
<li>The relationship between Silicon Valley and the Department of Defense has been strained by a clash of cultures, values, and priorities.</li>
<li>Silicon Valley’s global outlook and focus on innovation sometimes conflict with the Pentagon’s hierarchical structure and risk-averse nature.</li>
</ul>
</section>
<section id="economic-and-ideological-barriers" class="level4">
<h4 class="anchored" data-anchor-id="economic-and-ideological-barriers">Economic and Ideological Barriers</h4>
<ul>
<li>Working with the Pentagon can be slow, bureaucratic, and less profitable than serving commercial markets, deterring some tech companies.</li>
<li>Post-Cold War generations in Silicon Valley may not feel the same connection to the military as previous generations.</li>
<li>Snowden’s revelations fueled distrust of government surveillance and data collection practices.</li>
</ul>
</section>
<section id="case-studies-spacex-and-palantir" class="level4">
<h4 class="anchored" data-anchor-id="case-studies-spacex-and-palantir">Case Studies: SpaceX and Palantir</h4>
<ul>
<li>Both SpaceX and Palantir, despite facing resistance and bureaucratic hurdles, successfully broke into the defense market.</li>
<li>Their experiences highlight the challenges and potential rewards of working with the Department of Defense.</li>
</ul>
</section>
<section id="the-consolidation-dilemma" class="level4">
<h4 class="anchored" data-anchor-id="the-consolidation-dilemma">The Consolidation Dilemma</h4>
<ul>
<li>Both the defense industry and the technology sector have experienced consolidation, leading to fewer, larger companies.</li>
<li>While this has made some tech companies more capable of developing advanced technologies, it has also made them more risk-averse and less inclined to work with the military.</li>
</ul>
</section>
<section id="the-consequences-of-a-divided-landscape" class="level4">
<h4 class="anchored" data-anchor-id="the-consequences-of-a-divided-landscape">The Consequences of a Divided Landscape</h4>
<ul>
<li>The divide between the commercial tech sector and the defense world has significant implications for U.S. national security.</li>
<li>The U.S. military risks falling behind its strategic competitors in accessing and adopting cutting-edge technologies.</li>
</ul>
</section>
</section>
<section id="the-urgency-of-bridging-the-gap" class="level3">
<h3 class="anchored" data-anchor-id="the-urgency-of-bridging-the-gap">The Urgency of Bridging the Gap</h3>
<section id="acknowledging-the-systemic-failure" class="level4">
<h4 class="anchored" data-anchor-id="acknowledging-the-systemic-failure">Acknowledging the Systemic Failure</h4>
<ul>
<li>The failure to effectively integrate commercial technologies into the U.S. military is a systemic issue involving the Department of Defense, Congress, and the defense industry.</li>
<li>This failure stems from risk aversion, bureaucratic processes, and a lack of understanding of emerging technologies.</li>
</ul>
</section>
<section id="rethinking-the-military-industrial-complex" class="level4">
<h4 class="anchored" data-anchor-id="rethinking-the-military-industrial-complex">Rethinking the Military-Industrial Complex</h4>
<ul>
<li>The current system, focused on cost-saving and efficiency, has stiflied innovation and slowed down technology adoption.</li>
<li>A new approach is needed, one that encourages risk-taking, embraces innovation, and fosters collaboration between the military and the commercial tech sector.</li>
</ul>
</section>
<section id="embracing-disruption-and-change" class="level4">
<h4 class="anchored" data-anchor-id="embracing-disruption-and-change">Embracing Disruption and Change</h4>
<ul>
<li>The Department of Defense must become more agile, adaptable, and open to embracing disruptive technologies.</li>
<li>This requires cultural shifts, streamlined acquisition processes, and a willingness to learn from the successes of the commercial tech sector.</li>
</ul>
</section>
<section id="the-future-of-national-security-in-a-technologically-advanced-world" class="level4">
<h4 class="anchored" data-anchor-id="the-future-of-national-security-in-a-technologically-advanced-world">The Future of National Security in a Technologically Advanced World</h4>
<ul>
<li>The United States’ ability to maintain its technological edge in the 21st century depends on its ability to bridge the gap between the defense world and the commercial technology sector.</li>
<li>Failure to do so risks jeopardizing national security and ceding technological dominance to strategic competitors.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-5.-something-worse-than-change" class="level2">
<h2 class="anchored" data-anchor-id="chapter-5.-something-worse-than-change">Chapter 5. Something Worse Than Change</h2>
<section id="the-current-state-of-u.s.-national-defense" class="level3">
<h3 class="anchored" data-anchor-id="the-current-state-of-u.s.-national-defense">The Current State of U.S. National Defense</h3>
<ul>
<li>Leaders in Washington are focused on great power competition and the need for military innovation.</li>
<li>This echoes discussions from the past three decades, but the U.S. is in a weaker position now than it was after the Cold War.</li>
</ul>
<section id="reasons-for-the-decline" class="level4">
<h4 class="anchored" data-anchor-id="reasons-for-the-decline">Reasons for the Decline</h4>
<ul>
<li><strong>Overinvestment in Large Bases and Platforms:</strong> The U.S. military has heavily invested in large bases and expensive platforms that are vulnerable to advanced weaponry developed by rivals.</li>
<li><strong>Delayed Modernization Programs:</strong> Transformational procurement programs initiated in the 1990s and 2000s have experienced significant delays, leaving the U.S. military with aging systems and a lack of replacements.</li>
<li><strong>Strain on Existing Forces:</strong> Years of overseas operations have strained the U.S. military, resulting in a smaller, older force that is still recovering.</li>
<li><strong>Inadequate Technological Adaptation:</strong> The information age revolution has not significantly benefited the military, despite its transformative potential.</li>
<li><strong>Political Dysfunction:</strong> A chaotic and gridlocked political environment in Washington hinders effective decision-making.</li>
</ul>
</section>
<section id="factors-contributing-to-the-decline" class="level4">
<h4 class="anchored" data-anchor-id="factors-contributing-to-the-decline">Factors Contributing to the Decline</h4>
<ul>
<li><strong>Misallocation of Resources:</strong> Trillions of dollars have been spent on defense since 1991, but often on poorly chosen military programs and foreign policies.</li>
<li><strong>Lack of Hard Choices:</strong> Defense leaders have been reluctant to make difficult decisions about cutting military systems and missions.</li>
<li><strong>Overemphasis on Outdated Technologies:</strong> Excessive focus and funding have been directed towards old or unproven technologies based on outdated conceptions of military power.</li>
<li><strong>Unequal Burden of Counterterrorism:</strong> The demands of counterterrorism efforts following the September 11th attacks, while necessary, diverted resources and attention from other defense priorities.</li>
</ul>
</section>
</section>
<section id="the-challenge-of-military-innovation-in-peacetime" class="level3">
<h3 class="anchored" data-anchor-id="the-challenge-of-military-innovation-in-peacetime">The Challenge of Military Innovation in Peacetime</h3>
<ul>
<li>A core question for the future of warfare is whether militaries can innovate and change effectively without the pressure of active conflict.</li>
</ul>
<section id="the-role-of-war-in-driving-innovation" class="level4">
<h4 class="anchored" data-anchor-id="the-role-of-war-in-driving-innovation">The Role of War in Driving Innovation</h4>
<ul>
<li>The U.S. military’s recent innovations, such as those in special operations forces and counterinsurgency warfare, were largely driven by the demands of the wars in Iraq and Afghanistan.</li>
<li>Wartime creates a clear and present need for change and imposes consequences for failing to innovate.</li>
</ul>
</section>
<section id="obstacles-to-peacetime-innovation" class="level4">
<h4 class="anchored" data-anchor-id="obstacles-to-peacetime-innovation">Obstacles to Peacetime Innovation</h4>
<ul>
<li><strong>Lack of Real-World Feedback:</strong> Unlike civilian institutions that have markets or competition to drive improvement, militaries lack routine sources of objective feedback on their performance.</li>
<li><strong>Bureaucratic Resistance to Change:</strong> Military bureaucracies are inherently resistant to change due to their hierarchical structures, risk aversion, and emphasis on tradition.</li>
<li><strong>“Psychology of Military Incompetence”:</strong> Norman Dixon’s concept highlights the dangers of clinging to outdated traditions, misusing technology, ignoring critical information, and underestimating adversaries.</li>
</ul>
</section>
</section>
<section id="historical-examples-of-successful-peacetime-innovation" class="level3">
<h3 class="anchored" data-anchor-id="historical-examples-of-successful-peacetime-innovation">Historical Examples of Successful Peacetime Innovation</h3>
<ul>
<li><strong>U.S. Navy’s Adoption of Aircraft Carriers (1920s-1930s):</strong>
<ul>
<li>Admiral William Moffat, recognizing the potential of aircraft carriers, led a movement within the Navy to challenge the dominance of battleships.</li>
<li>Moffat used analysis, war games, and at-sea experimentation to develop new operational concepts and tactics for carrier warfare.</li>
<li>He championed technological advancements in aircraft and carrier design and advocated for the promotion of aviators within the Navy’s ranks.</li>
<li>Moffat’s efforts were supported by civilian leaders like President Herbert Hoover and Congressman Carl Vinson.</li>
</ul></li>
<li><strong>Development of the Assault Breaker Initiative (Cold War):</strong>
<ul>
<li>The initiative aimed to develop a new way to counter a potential Soviet invasion of Europe without relying on tactical nuclear weapons.</li>
<li>Led by Secretary of Defense Harold Brown, the initiative resulted in the creation of a new kill chain that included intelligence-gathering aircraft, communication relays, stealth aircraft, and long-range precision-guided munitions.</li>
<li>While never used in combat, Assault Breaker significantly concerned Soviet military planners and helped deter conflict.</li>
</ul></li>
</ul>
<section id="key-factors-for-successful-peacetime-innovation" class="level4">
<h4 class="anchored" data-anchor-id="key-factors-for-successful-peacetime-innovation">Key Factors for Successful Peacetime Innovation</h4>
<ul>
<li><strong>Clear Threat Definition:</strong> Identifying specific operational problems that need to be solved through new capabilities and ways of fighting.</li>
<li><strong>Extraordinary Leadership:</strong>
<ul>
<li><strong>Civilian leadership</strong> to provide direction, resources, and political support.</li>
<li><strong>Military mavericks</strong> within the armed forces to champion change and challenge the status quo.</li>
</ul></li>
<li><strong>Focus on Operational and Organizational Transformation:</strong> Prioritizing how technology is used to build new capabilities, operational concepts, and organizational structures, rather than simply acquiring new technology for its own sake.</li>
<li><strong>Constant Real-World Experimentation:</strong> Providing opportunities for military operators to experiment with new technologies, learn from failures, and refine concepts based on real-world feedback.</li>
</ul>
</section>
</section>
<section id="the-erosion-of-u.s.-military-dominance" class="level3">
<h3 class="anchored" data-anchor-id="the-erosion-of-u.s.-military-dominance">The Erosion of U.S. Military Dominance</h3>
<ul>
<li>The U.S. defense establishment has struggled in recent decades due to a lack of meaningful experimentation, bureaucratic processes, and an overemphasis on abstract requirements over practical testing.</li>
</ul>
<section id="the-rise-of-china-as-a-peer-competitor" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-china-as-a-peer-competitor">The Rise of China as a Peer Competitor</h4>
<ul>
<li>The rise of China poses an unprecedented challenge to U.S. military dominance, representing a major shift in the global balance of power.</li>
<li>Unlike the Soviet Union, China is on track to surpass the U.S. in comprehensive national power.</li>
</ul>
</section>
<section id="the-nature-of-the-chinese-communist-party" class="level4">
<h4 class="anchored" data-anchor-id="the-nature-of-the-chinese-communist-party">The Nature of the Chinese Communist Party</h4>
<ul>
<li>China’s ambitions are amplified by its unique history and ideology as the “Middle Kingdom” and its desire to reclaim its perceived rightful place in the world order.</li>
<li>The Chinese Communist Party under Xi Jinping has embraced communist orthodoxy, consolidated power, and demonstrated hostility towards liberal values and institutions.</li>
</ul>
</section>
<section id="chinas-technological-ambitions-and-military-expansion" class="level4">
<h4 class="anchored" data-anchor-id="chinas-technological-ambitions-and-military-expansion">China’s Technological Ambitions and Military Expansion</h4>
<ul>
<li>China is aggressively pursuing technological dominance in areas like 5G, artificial intelligence, and biotechnology, driven by a national strategy to become a global leader in innovation.</li>
<li>The Chinese government is engaged in a systematic campaign to acquire advanced technologies through any means necessary, including intellectual property theft, espionage, and coercion.</li>
<li>China is rapidly expanding its military capabilities, including its navy, and investing in advanced weapons systems designed to challenge U.S. military dominance in the Asia-Pacific region.</li>
</ul>
</section>
<section id="implications-for-the-future-of-warfare" class="level4">
<h4 class="anchored" data-anchor-id="implications-for-the-future-of-warfare">Implications for the Future of Warfare</h4>
<ul>
<li>The proliferation of precision-guided weapons has shifted the advantage from offense to defense, making it increasingly difficult for the U.S. to project power against a peer competitor like China.</li>
<li>The potential erosion of deterrence and the rise of Chinese military dominance in the Asia-Pacific region pose a significant threat to U.S. interests and global stability.</li>
</ul>
</section>
</section>
<section id="the-need-for-change-confronting-the-something-worse" class="level3">
<h3 class="anchored" data-anchor-id="the-need-for-change-confronting-the-something-worse">The Need for Change: Confronting the “Something Worse”</h3>
<ul>
<li>The “something worse than change” is the prospect of losing the ability to deter war with China and the potential consequences of a future conflict.</li>
<li>This requires the U.S. to:
<ul>
<li>Recognize the urgency of the challenge and abandon complacency.</li>
<li>Reimagine the kill chain and adapt to a future of warfare characterized by rapid technological advancements and a more contested environment.</li>
<li>Recommit to innovation, experimentation, and the development of new operational concepts.</li>
<li>Mobilize all elements of national power—economic, diplomatic, and military—to compete effectively with China.</li>
</ul></li>
<li>The stakes of this competition are high, with the potential to shape the future of the international order and determine the kind of world in which Americans will live.</li>
</ul>
</section>
</section>
<section id="chapter-6-a-different-kind-of-arms-race" class="level2">
<h2 class="anchored" data-anchor-id="chapter-6-a-different-kind-of-arms-race">Chapter 6: A Different Kind of Arms Race</h2>
<section id="a-new-global-arms-race-beyond-conventional-weapons" class="level3">
<h3 class="anchored" data-anchor-id="a-new-global-arms-race-beyond-conventional-weapons">A New Global Arms Race: Beyond Conventional Weapons</h3>
<ul>
<li>Representatives from over 80 countries have been discussing a ban on <strong>lethal autonomous weapons</strong> since 2014.
<ul>
<li><strong>Lethal autonomous weapons:</strong> Defined by the Department of Defense as machines activated to select and engage targets without human intervention.</li>
</ul></li>
<li>These weapons, often called “<strong>killer robots</strong>” by opponents, raise ethical concerns about removing humans from the kill chain.
<ul>
<li><strong>Kill chain:</strong> The process of identifying, targeting, and engaging an enemy.</li>
</ul></li>
<li>While China supports banning the <em>use</em> of these weapons, it has not committed to halting their <em>development</em>.
<ul>
<li>China’s definition of lethal autonomous weapons is narrow and does not encompass the full range of systems it’s developing.</li>
</ul></li>
<li>This discrepancy highlights a broader trend of rapidly developing military technologies, sparking fears of a global arms race encompassing:
<ul>
<li>Cyber weapons</li>
<li>AI</li>
<li>Hypersonic technology</li>
<li>5G networks</li>
<li>Quantum computing</li>
<li>Gene editing</li>
<li>Space capabilities</li>
</ul></li>
<li>China’s role in this arms race is particularly concerning due to:
<ul>
<li>Significant economic and military power</li>
<li>Less transparent intentions compared to other nations</li>
<li>A potential ambition to reshape the world order in favor of its illiberal values, including authoritarianism, crony capitalism, and surveillance states.</li>
<li>The perception of the United States as an obstacle to its ambitions.</li>
</ul></li>
<li>This competition for technological dominance is fueled by:
<ul>
<li>Mistrust between major powers</li>
<li>Fear of losing military advantage</li>
</ul></li>
</ul>
</section>
<section id="a-race-unlike-any-other-from-arms-to-cognition" class="level3">
<h3 class="anchored" data-anchor-id="a-race-unlike-any-other-from-arms-to-cognition">A Race Unlike Any Other: From Arms to Cognition</h3>
<ul>
<li>This technological competition differs from traditional arms races in several ways:
<ul>
<li><strong>Scope:</strong> It extends beyond traditional weapons to encompass <strong>enabling technologies</strong> that have broad civilian and military applications.
<ul>
<li><strong>Enabling technologies:</strong> Technologies such as AI, quantum information systems, biotechnologies, and new space technologies that will transform how societies and militaries function.</li>
</ul></li>
<li><strong>Impact:</strong> It will reshape every stage of the kill chain, influencing not just military action but also understanding and decision-making.</li>
<li><strong>Focus:</strong> The primary emphasis will be on accelerating one’s ability to close the kill chain while disrupting adversaries’ capacity to do the same.</li>
<li><strong>Nature:</strong> This competition will be less about amassing weapons and more about achieving cognitive superiority, essentially a race for information dominance.</li>
</ul></li>
</ul>
</section>
<section id="the-hypersonic-challenge-speed-and-unpredictability" class="level3">
<h3 class="anchored" data-anchor-id="the-hypersonic-challenge-speed-and-unpredictability">The Hypersonic Challenge: Speed and Unpredictability</h3>
<ul>
<li><strong>Hypersonic weapons:</strong> Missiles or air vehicles capable of flying at speeds exceeding Mach 5 (3,800 mph), making them both fast and unpredictable.
<ul>
<li>Unlike ballistic missiles, which are fast but predictable, or cruise missiles, which are slower but unpredictable, hypersonic weapons combine speed and maneuverability.</li>
</ul></li>
<li>This combination makes them difficult to track and intercept, posing a significant challenge to existing defense systems.</li>
<li>China has taken an early lead in hypersonic weapon development, investing heavily in research and testing.</li>
<li>While the U.S. is playing catch-up, developing and deploying hypersonic weapons is costly and time-consuming.</li>
<li>Despite these limitations, both countries are pursuing hypersonic weapons due to their strategic importance in maintaining conventional deterrence.</li>
</ul>
</section>
<section id="directed-energy-weapons-a-new-era-of-warfare" class="level3">
<h3 class="anchored" data-anchor-id="directed-energy-weapons-a-new-era-of-warfare">Directed Energy Weapons: A New Era of Warfare</h3>
<ul>
<li><strong>Directed energy weapons:</strong> Weapons that use concentrated energy, such as lasers or microwaves, to disable or destroy targets.</li>
<li>Recent advancements in laser technology have brought directed energy weapons closer to operational viability.</li>
<li>Advantages:
<ul>
<li>Higher rate of fire</li>
<li>Faster engagement</li>
<li>Lower cost per shot</li>
<li>No ammunition resupply required</li>
</ul></li>
<li>Limitations:
<ul>
<li>High power requirements currently limit their deployment to platforms with substantial power sources.</li>
<li>Counters, such as mirrors and heat shields, are being developed.</li>
</ul></li>
<li>While primarily defensive now, directed energy weapons have the potential to revolutionize warfare in the future.</li>
</ul>
</section>
<section id="the-cyber-arms-race-exploiting-digital-vulnerabilities" class="level3">
<h3 class="anchored" data-anchor-id="the-cyber-arms-race-exploiting-digital-vulnerabilities">The Cyber Arms Race: Exploiting Digital Vulnerabilities</h3>
<ul>
<li>The cyber domain has become a key battleground in modern warfare.</li>
<li>Cyberattacks can disable critical military infrastructure and compromise sensitive information.</li>
<li>The interconnected nature of modern military systems, such as the F-35 fighter jet with its millions of lines of code, increases their vulnerability to cyberattacks.</li>
<li>The use of AI in cyberwarfare raises concerns about data poisoning, where adversaries manipulate training data to compromise AI systems, leading to unintended and potentially disastrous consequences.</li>
</ul>
</section>
<section id="enabling-technologies-reshaping-the-kill-chain" class="level3">
<h3 class="anchored" data-anchor-id="enabling-technologies-reshaping-the-kill-chain">Enabling Technologies: Reshaping the Kill Chain</h3>
<ul>
<li><strong>Quantum information systems:</strong> Technologies that leverage quantum mechanics to enhance sensing, computing, and communication.
<ul>
<li><strong>Quantum sensors:</strong> Offer improved battlefield awareness and unprecedented intelligence-gathering capabilities.</li>
<li><strong>Quantum computers:</strong> Hold the potential to process vast amounts of data generated by intelligentized militaries and crack traditional encryption methods.</li>
<li><strong>Quantum-resistant encryption:</strong> Critical for securing information in a future where quantum computers could render current encryption obsolete.</li>
</ul></li>
<li><strong>Biotechnology:</strong>
<ul>
<li>Will enhance understanding of human genetics and enable the development of customized treatments and technologies for augmenting human capabilities.</li>
<li>Raises concerns about potential misuse, particularly in the context of China’s less restrictive ethical boundaries.</li>
</ul></li>
<li><strong>New space capabilities:</strong>
<ul>
<li>The proliferation of satellites, especially small satellites, will enhance communication, intelligence gathering, and targeting.</li>
<li>Development of space-based infrastructure, including power generation, mining, and manufacturing, will be crucial for securing a space-faring future.</li>
<li>The strategic importance of space will likely lead to an extension of military competition beyond Earth.</li>
</ul></li>
<li><strong>Artificial intelligence and machine learning:</strong>
<ul>
<li>Will significantly enhance human understanding in warfare, particularly by processing and analyzing vast amounts of data from various sources.</li>
<li>AI-powered systems can identify patterns, objects, and trends that humans might miss, enabling better and faster decision-making.</li>
<li>Intelligent machines, capable of acting autonomously within human-defined parameters, will revolutionize military operations.</li>
</ul></li>
</ul>
</section>
<section id="challenges-and-risks-of-the-ai-arms-race" class="level3">
<h3 class="anchored" data-anchor-id="challenges-and-risks-of-the-ai-arms-race">Challenges and Risks of the AI Arms Race</h3>
<ul>
<li>The rapid pace of AI development raises concerns about:
<ul>
<li>Premature deployment of insufficiently tested and potentially unreliable systems.</li>
<li>Accidental escalation and unintended consequences.</li>
<li>Ethical implications of increasingly autonomous weapons systems.</li>
</ul></li>
</ul>
</section>
<section id="the-uncomfortable-truth-and-the-need-for-urgency" class="level3">
<h3 class="anchored" data-anchor-id="the-uncomfortable-truth-and-the-need-for-urgency">The Uncomfortable Truth and the Need for Urgency</h3>
<ul>
<li>Arms control agreements, while valuable for establishing norms, may not be effective in preventing the weaponization of emerging technologies.</li>
<li>The United States faces the likelihood of not achieving outright victory in this race, with parity being a more realistic and desirable outcome.</li>
<li>It is crucial for the U.S. to recognize the gravity of this competition and demonstrate a greater sense of urgency in order to avoid falling behind China.</li>
<li>The potential consequences of losing this race are significant, with China aiming to leverage these technologies to become the world’s leading power.</li>
</ul>
</section>
<section id="conclusion-a-different-kind-of-race-a-critical-choice" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-a-different-kind-of-race-a-critical-choice">Conclusion: A Different Kind of Race, a Critical Choice</h3>
<ul>
<li>The race for technological superiority in the 21st century presents unprecedented challenges and risks.</li>
<li>It is not just a competition for military hardware, but a race for cognitive dominance and the ability to control the narrative in an increasingly information-driven world.</li>
<li>The United States faces a critical choice: rise to the challenge with the necessary urgency and commitment, or risk ceding the future to a rival power with a vastly different vision for the world.</li>
</ul>
</section>
</section>
<section id="chapter-7-human-command-machine-control" class="level2">
<h2 class="anchored" data-anchor-id="chapter-7-human-command-machine-control">Chapter 7: Human Command, Machine Control</h2>
<section id="the-ethical-dilemma-of-intelligent-machines-in-war" class="level3">
<h3 class="anchored" data-anchor-id="the-ethical-dilemma-of-intelligent-machines-in-war">The Ethical Dilemma of Intelligent Machines in War</h3>
<ul>
<li>The author recounts a poignant encounter with a Syrian mother who lost all five of her children in a barrel bomb attack, an experience that deeply affected both him and the late Senator John McCain.
<ul>
<li>This encounter underscores the profound human cost of war and serves as a stark reminder of the ethical considerations surrounding the use of force.</li>
</ul></li>
<li>The author grapples with the question of whether, as a potential civilian caught in a conflict, the knowledge of whether the weapon systems targeting him were operated by humans or machines would matter.
<ul>
<li>This question highlights a fundamental debate about the ethics of war in the age of intelligent machines:
<ul>
<li><strong>Is the morality of an action determined by the nature of the actor, or by the consequences of the action itself?</strong></li>
</ul></li>
</ul></li>
<li>The author argues that the current debate about intelligent machines in war often misses the mark by focusing on the wrong questions.
<ul>
<li>He suggests that instead of fixating on the means of warfare (e.g., “killer robots”), we should prioritize the ends (i.e., the ethical use of force) and the principles of human accountability that should govern them.</li>
</ul></li>
</ul>
</section>
<section id="the-importance-of-command-and-control" class="level3">
<h3 class="anchored" data-anchor-id="the-importance-of-command-and-control">The Importance of Command and Control</h3>
<ul>
<li>The author criticizes the term “human-machine teaming” often used to describe the relationship between humans and intelligent machines in a military context.
<ul>
<li>He argues that this term implies a false equivalence between human operators and machines.</li>
</ul></li>
<li>Instead, the author advocates for the concept of <strong>“human command and machine control,”</strong> emphasizing the hierarchical nature of the relationship where humans retain ultimate authority and responsibility.
<ul>
<li>This concept aligns with the long-standing military principles of command and control, ensuring that human judgment and ethics remain central to the use of force.</li>
</ul></li>
<li>The author acknowledges the concerns surrounding the potential for machines to act unethically.
<ul>
<li>However, he argues that humans have always exhibited a capacity for cruelty and that focusing solely on the perceived inhumanity of machines ignores the historical reality of human fallibility in war.</li>
</ul></li>
<li>The author emphasizes that the current debate should center around <strong>narrow artificial intelligence</strong> (AI), which is limited to performing specific tasks, rather than <strong>artificial general intelligence (AGI)</strong> or <strong>superintelligence</strong>, which remain speculative concepts.
<ul>
<li>He underscores that narrow AI, despite its capabilities, operates within the boundaries defined by its human creators.</li>
</ul></li>
</ul>
</section>
<section id="trust-accountability-and-the-limits-of-autonomy" class="level3">
<h3 class="anchored" data-anchor-id="trust-accountability-and-the-limits-of-autonomy">Trust, Accountability, and the Limits of Autonomy</h3>
<ul>
<li><p><strong>Autonomy</strong> in the context of machines, the author clarifies, does not imply independent decision-making but rather the delegation of tasks within predefined parameters set by humans.</p>
<ul>
<li>This concept mirrors the existing military practice of granting autonomy to human subordinates, albeit with clear rules of engagement and accountability mechanisms.</li>
</ul></li>
<li><p>The author proposes a framework for building trust in intelligent machines, drawing parallels to the trust established between human commanders and their subordinates. This framework rests on three pillars:</p>
<ol type="1">
<li><p><strong>Training:</strong> Rigorous training of machines to perform designated tasks effectively and ethically.</p></li>
<li><p><strong>Testing:</strong> Repeated testing to ensure the machine’s reliability, predictability, and adherence to established parameters.</p></li>
<li><p><strong>Trust:</strong> Trust is earned through consistent demonstration of competence and reliability in training and testing, leading to greater confidence in the machine’s ability to perform as intended.</p></li>
</ol></li>
<li><p>The author underscores that accountability remains paramount. Just as commanders are responsible for the actions of their human subordinates, they would bear the responsibility for the actions of the machines under their command.</p>
<ul>
<li>This accountability extends to the entire chain of command, including those involved in training, testing, and deploying the intelligent machines.</li>
</ul></li>
</ul>
</section>
<section id="differentiating-roles-leveraging-human-judgment" class="level3">
<h3 class="anchored" data-anchor-id="differentiating-roles-leveraging-human-judgment">Differentiating Roles: Leveraging Human Judgment</h3>
<ul>
<li>The author argues that one of the potential benefits of increased reliance on intelligent machines is the opportunity to free human operators from mundane and repetitive tasks, allowing them to focus on more complex and ethically demanding aspects of warfare.
<ul>
<li>This shift could lead to a more ethical use of force by allowing humans to leverage their unique capacity for judgment, empathy, and moral reasoning.</li>
</ul></li>
<li>The author acknowledges that current intelligent machines might outperform humans in certain tasks, particularly those requiring speed, accuracy, and consistency in data analysis and pattern recognition.
<ul>
<li>However, he stresses that machines should not be seen as replacements for human judgment in all instances.</li>
</ul></li>
<li>The author contends that while machines can enhance human decision-making by providing valuable insights and recommendations, the ultimate responsibility for decisions, especially those involving the use of lethal force, must remain with human commanders.
<ul>
<li>This approach ensures that human values and ethical considerations remain at the forefront of warfare.</li>
</ul></li>
</ul>
</section>
<section id="legal-and-ethical-considerations" class="level3">
<h3 class="anchored" data-anchor-id="legal-and-ethical-considerations">Legal and Ethical Considerations</h3>
<ul>
<li><p>The author argues that contrary to popular narratives, lethal autonomous weapons systems are not inherently illegal. He outlines the established legal criteria for determining the legality of a weapon:</p>
<ol type="1">
<li><p><strong>Discrimination:</strong> The weapon should be capable of distinguishing between combatants and civilians.</p></li>
<li><p><strong>Proportionality:</strong> The use of the weapon should be proportionate to the military objective, minimizing unnecessary civilian harm.</p></li>
<li><p><strong>Controllability:</strong> The effects of the weapon should be controllable, preventing unintended and widespread harm.</p></li>
</ol></li>
<li><p>The author emphasizes that the legality of a weapon hinges on its inherent design and intended effects, not on the autonomy of the actor deploying it.</p>
<ul>
<li>He suggests that focusing solely on the “autonomy” of a weapon system misses the critical point that even autonomous weapons operate within the parameters defined by their human creators.</li>
</ul></li>
<li><p>The author acknowledges the potential for errors and unintended consequences, even with highly intelligent machines.</p>
<ul>
<li>He argues that transparency, rigorous testing, and clearly defined rules of engagement are crucial for mitigating risks and ensuring accountability.</li>
</ul></li>
</ul>
</section>
<section id="the-importance-of-transparency-and-international-cooperation" class="level3">
<h3 class="anchored" data-anchor-id="the-importance-of-transparency-and-international-cooperation">The Importance of Transparency and International Cooperation</h3>
<ul>
<li>The author criticizes the secrecy surrounding the U.S. drone program, arguing that it created a perception of wrongdoing and hampered public understanding of the ethical considerations involved.
<ul>
<li>He advocates for a more transparent approach to the development and deployment of intelligent machines in warfare.</li>
</ul></li>
<li>The author suggests that the U.S. should lead by example, demonstrating its commitment to ethical development and use of intelligent machines.
<ul>
<li>He proposes inviting international scrutiny and collaboration to establish norms and standards for the responsible use of these technologies.</li>
</ul></li>
<li>The author acknowledges the challenges of international cooperation, particularly with rivals like China and Russia.
<ul>
<li>However, he argues that open dialogue and transparency are essential for building trust and establishing a framework for responsible development and use of intelligent machines in warfare.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-a-reluctant-yes-with-caveats" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-a-reluctant-yes-with-caveats">Conclusion: A Reluctant Yes, With Caveats</h3>
<ul>
<li>The author concludes by advocating for the development of lethal autonomous weapons systems, but with significant caveats.
<ul>
<li>He argues that the U.S. cannot afford to cede this technological advantage to rivals who may not share its ethical commitments.</li>
</ul></li>
<li>The author draws a parallel to the development of nuclear weapons, suggesting that lethal autonomous weapons should be viewed as a deterrent, intended to prevent their use by adversaries.
<ul>
<li>He emphasizes that the ultimate goal should be to deter conflict and prevent the use of these weapons altogether.</li>
</ul></li>
<li>The author stresses the importance of transparency, rigorous testing, and clear accountability mechanisms to ensure that these weapons are developed and used ethically and responsibly.
<ul>
<li>He calls for a national conversation about these technologies, urging Americans to engage in this critical debate and shape the future of warfare.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-8-a-military-internet-of-things" class="level2">
<h2 class="anchored" data-anchor-id="chapter-8-a-military-internet-of-things">Chapter 8: A Military Internet of Things</h2>
<section id="the-need-for-a-new-approach-to-military-technology" class="level3">
<h3 class="anchored" data-anchor-id="the-need-for-a-new-approach-to-military-technology">The Need for a New Approach to Military Technology</h3>
<ul>
<li>In 2014, Senator John McCain, then Chairman of the Senate Armed Services Committee, directed the author to focus on investing in the future of warfare.</li>
<li>This directive stemmed from the realization that the U.S. military had been investing heavily in outdated technologies and needed to adapt to rapidly evolving threats.</li>
<li>The Department of Defense was slow to adapt, often prioritizing traditional weapons systems over emerging technologies.</li>
<li>This lack of foresight necessitated a proactive search for promising technological advancements outside of the traditional defense industry.</li>
</ul>
</section>
<section id="early-examples-of-autonomous-systems" class="level3">
<h3 class="anchored" data-anchor-id="early-examples-of-autonomous-systems">Early Examples of Autonomous Systems</h3>
<ul>
<li><strong>XQ-58A Valkyrie (formerly Low-Cost Attritable Aircraft Technology Program):</strong> An experimental unmanned aircraft developed by the Air Force Research Laboratory.
<ul>
<li><strong>Goals:</strong>
<ul>
<li>Develop a highly capable, unmanned combat aircraft with increased autonomy.</li>
<li>Create a more cost-effective alternative to expensive fighter jets.</li>
</ul></li>
<li><strong>Features:</strong>
<ul>
<li><strong>Attritable:</strong> Designed to be affordable enough to be considered expendable in combat.</li>
<li>Long flight range (twice that of cutting-edge fighter jets).</li>
<li>High subsonic speed.</li>
<li>Missile-like launch and parachute recovery system, eliminating the need for vulnerable runways.</li>
<li>Cost: Several million dollars per unit (fully equipped), allowing for the purchase of roughly a dozen or two Valkyries for the price of one F-35A.</li>
</ul></li>
</ul></li>
<li><strong>Orca (formerly Extra Large Unmanned Undersea Vehicle or XLUUV):</strong> An experimental autonomous submarine developed by the Navy.
<ul>
<li><strong>Features:</strong>
<ul>
<li>51 feet long with a potential length of 85 feet with a payload module.</li>
<li>Range of 6,500 nautical miles.</li>
<li>Payload module allows for the deployment of various payloads.</li>
</ul></li>
<li><strong>Cost:</strong>
<ul>
<li>Approximately $55 million per unit (without payloads and sensors).</li>
<li>Still significantly cheaper than the Navy’s Virginia-class submarine, which costs $3.2 billion per unit.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="the-potential-of-intelligent-machines-in-future-warfare" class="level3">
<h3 class="anchored" data-anchor-id="the-potential-of-intelligent-machines-in-future-warfare">The Potential of Intelligent Machines in Future Warfare</h3>
<ul>
<li>The author argues that the true significance of systems like the Valkyrie and Orca lies in their potential to be integrated into a larger network of intelligent machines.</li>
<li>This network, envisioned as a “military Internet of Things,” would be characterized by:
<ul>
<li><strong>Rapid development and modernization:</strong> Leveraging commercial technologies and focusing on software rather than hardware would allow for faster innovation cycles.</li>
<li><strong>Affordability:</strong> Lower production costs would enable the deployment of larger numbers of autonomous systems.</li>
<li><strong>Flexibility and scalability:</strong> The network could be easily adapted and expanded to meet evolving threats.</li>
</ul></li>
<li>The key to unlocking the full potential of these systems lies in the integration of:
<ul>
<li><strong>Artificial intelligence (AI):</strong> Enabling machines to learn, adapt, and make decisions without direct human intervention.</li>
<li><strong>Vehicle autonomy:</strong> Allowing systems to operate independently and collaboratively with minimal human supervision.</li>
</ul></li>
<li>This shift would move away from the current model of heavily manned and expensive military platforms towards a more distributed and scalable force structure.</li>
</ul>
</section>
<section id="current-limitations-of-u.s.-military-networks-and-the-need-for-change" class="level3">
<h3 class="anchored" data-anchor-id="current-limitations-of-u.s.-military-networks-and-the-need-for-change">Current Limitations of U.S. Military Networks and the Need for Change</h3>
<ul>
<li>The author argues that the U.S. military’s current battle networks, designed around human operators, suffer from significant limitations:
<ul>
<li><strong>Information silos:</strong> Systems often struggle to share information seamlessly, leading to delays and inefficiencies in decision-making.</li>
<li><strong>Linear and rigid structures:</strong> Current networks often operate in predetermined ways, making them inflexible and vulnerable to disruption.</li>
<li><strong>High manpower requirements:</strong> Operating and maintaining complex systems require significant human resources.</li>
<li><strong>Slow decision-making:</strong> The human-centric nature of current systems slows down the speed at which information is processed and acted upon.</li>
</ul></li>
<li>These limitations are contrasted with the advancements in the commercial technology sector, particularly in developing the Internet of Things (IoT).</li>
<li>The IoT demonstrates the power of networked systems to share information seamlessly, enabling rapid decision-making and automated processes.</li>
</ul>
</section>
<section id="the-vision-of-a-military-internet-of-things" class="level3">
<h3 class="anchored" data-anchor-id="the-vision-of-a-military-internet-of-things">The Vision of a Military Internet of Things</h3>
<ul>
<li><strong>Core Principles:</strong>
<ul>
<li><strong>Shift from platforms to networks:</strong> Prioritizing the interconnection and interoperability of systems over individual platform capabilities.</li>
<li><strong>Human command, machine control:</strong> Humans set objectives and make strategic decisions, while machines execute tasks and manage the complexities of the network.</li>
<li><strong>Distributed intelligence:</strong> Intelligence is embedded throughout the network, enabling rapid information sharing and decision-making.</li>
<li><strong>Scalability and affordability:</strong> The network is designed to grow exponentially and incorporate affordable, attritable systems.</li>
</ul></li>
<li><strong>Advantages:</strong>
<ul>
<li><strong>Enhanced situational awareness:</strong> Seamless information sharing provides a comprehensive and real-time understanding of the battlespace.</li>
<li><strong>Accelerated decision-making:</strong> Machines process information and execute tasks at machine speed, enabling faster responses to threats.</li>
<li><strong>Increased efficiency and effectiveness:</strong> Automation and intelligent systems free up human operators to focus on higher-level tasks.</li>
<li><strong>Force multiplication:</strong> One human operator can potentially control numerous intelligent machines, significantly expanding the reach and scale of operations.</li>
<li><strong>Adaptability and resilience:</strong> The network can adapt to changing conditions and withstand the loss of individual nodes.</li>
</ul></li>
</ul>
</section>
<section id="implementing-a-military-internet-of-things-challenges-and-opportunities" class="level3">
<h3 class="anchored" data-anchor-id="implementing-a-military-internet-of-things-challenges-and-opportunities">Implementing a Military Internet of Things: Challenges and Opportunities</h3>
<ul>
<li><strong>Technological challenges:</strong>
<ul>
<li>Developing robust and secure communication protocols for the network.</li>
<li>Ensuring the reliability and trustworthiness of AI and autonomous systems.</li>
<li>Managing the complexity of a vast and interconnected network.</li>
</ul></li>
<li><strong>Organizational and cultural challenges:</strong>
<ul>
<li>Overcoming resistance to change within the military’s traditional, platform-centric mindset.</li>
<li>Adapting training and doctrine to accommodate new technologies and operating concepts.</li>
<li>Addressing ethical concerns surrounding the use of AI and autonomous systems in warfare.</li>
</ul></li>
<li><strong>Opportunities:</strong>
<ul>
<li><strong>Leveraging commercial technologies:</strong> The rapid pace of innovation in the private sector presents opportunities to adopt and adapt existing technologies for military use.</li>
<li><strong>Fostering partnerships:</strong> Collaborating with tech companies and research institutions to accelerate development and innovation.</li>
<li><strong>Investing in research and development:</strong> Prioritizing funding for key technologies such as AI, autonomy, and advanced networking.</li>
</ul></li>
</ul>
</section>
<section id="the-future-of-warfare-a-human-machine-partnership" class="level3">
<h3 class="anchored" data-anchor-id="the-future-of-warfare-a-human-machine-partnership">The Future of Warfare: A Human-Machine Partnership</h3>
<ul>
<li>The author envisions a future where human judgment and moral agency remain central to warfare, but are augmented by the capabilities of a military Internet of Things.</li>
<li>Intelligent machines would handle routine tasks, process information, and execute orders at machine speed, while human operators would focus on:
<ul>
<li>Setting strategic objectives.</li>
<li>Making critical decisions.</li>
<li>Providing ethical oversight.</li>
</ul></li>
<li>This human-machine partnership would enable the U.S. military to:
<ul>
<li>Maintain its technological edge in an era of rapid technological change.</li>
<li>Outmaneuver adversaries in highly contested environments.</li>
<li>Ensure the responsible and ethical use of force.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-embracing-the-inevitable" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-embracing-the-inevitable">Conclusion: Embracing the Inevitable</h3>
<ul>
<li>The emergence of intelligent machines and the growing ubiquity of networked systems represent a fundamental shift in the nature of warfare.</li>
<li>The U.S. military must embrace these changes and adapt its thinking, force structure, and operating concepts to remain competitive in the 21st century.</li>
<li>The transition to a military Internet of Things will require significant investment, innovation, and a willingness to challenge long-held assumptions about the nature of military power.</li>
<li>Ultimately, the successful integration of intelligent machines into the U.S. military will depend on striking the right balance between human control and machine autonomy.</li>
</ul>
</section>
</section>
<section id="chapter-9-move-shoot-communicate" class="level2">
<h2 class="anchored" data-anchor-id="chapter-9-move-shoot-communicate">Chapter 9: Move, Shoot, Communicate</h2>
<section id="the-future-of-warfare-then-and-now" class="level3">
<h3 class="anchored" data-anchor-id="the-future-of-warfare-then-and-now">The Future of Warfare: Then and Now</h3>
<section id="jan-blochs-predictions-and-their-implications-today" class="level4">
<h4 class="anchored" data-anchor-id="jan-blochs-predictions-and-their-implications-today">Jan Bloch’s Predictions and Their Implications Today</h4>
<ul>
<li><strong>Jan Bloch</strong>, a Polish banker and military scholar, published a book in 1898 predicting how technology would transform warfare.
<ul>
<li>He accurately foresaw the lethality of modern battlefields due to technological advancements like:
<ul>
<li><strong>Machine guns</strong></li>
<li><strong>Smokeless gunpowder:</strong> This innovation would “lift the fog of war,” leaving armies exposed after initial volleys.</li>
<li><strong>Long-range artillery:</strong> Bloch calculated these were 116 times deadlier than those used a few decades prior.</li>
<li><strong>Improved rifles:</strong> Offering greater speed, accuracy, and range.</li>
<li>Other innovations: Including <strong>railroads, telegraphs, and steamships</strong>.</li>
</ul></li>
<li>Bloch believed this increase in lethality would make large-scale wars “impossible.”</li>
<li>However, World War I proved him wrong, though the conflict unfolded largely as he predicted, with trench warfare and high casualties (40 million deaths in four years).</li>
</ul></li>
</ul>
</section>
<section id="lessons-from-world-war-i-technological-advancements-and-doctrinal-lag" class="level4">
<h4 class="anchored" data-anchor-id="lessons-from-world-war-i-technological-advancements-and-doctrinal-lag">Lessons from World War I: Technological Advancements and Doctrinal Lag</h4>
<ul>
<li>World War I’s carnage resulted partly from militaries using antiquated tactics with modern technology.
<ul>
<li><strong>Technological advancements favored defenders</strong>, but offensive tactics remained unchanged, leading to devastating losses.</li>
<li><strong>Military technological parity</strong> among the great powers exacerbated the destructiveness.</li>
</ul></li>
</ul>
</section>
<section id="parallels-to-todays-security-environment-the-rise-of-china" class="level4">
<h4 class="anchored" data-anchor-id="parallels-to-todays-security-environment-the-rise-of-china">Parallels to Today’s Security Environment: The Rise of China</h4>
<ul>
<li>The proliferation of information technologies and precision strike weapons, particularly in China, is challenging America’s military dominance, creating an environment similar to the pre-World War I era.
<ul>
<li><strong>China’s military modernization</strong> is eroding U.S. advantages, especially in offensive capabilities.</li>
<li><strong>Military technological parity</strong> is re-emerging, with both the U.S. and China possessing similar advanced technologies.</li>
<li>The critical question becomes <strong>how to gain an advantage</strong> in this new era of warfare.</li>
</ul></li>
</ul>
</section>
</section>
<section id="the-enduring-competitions-of-warfare" class="level3">
<h3 class="anchored" data-anchor-id="the-enduring-competitions-of-warfare">The Enduring Competitions of Warfare</h3>
<ul>
<li><strong>Military planners</strong> face the difficult task of making investment decisions with incomplete information about future threats and technological advancements.
<ul>
<li>The goal is to <strong>discern how to gain a future advantage</strong> in the enduring competitions that define warfare.</li>
</ul></li>
</ul>
<section id="offense-vs.-defense" class="level4">
<h4 class="anchored" data-anchor-id="offense-vs.-defense">Offense vs.&nbsp;Defense</h4>
<ul>
<li>This fundamental competition involves attackers seeking to overcome defenders and vice versa.</li>
</ul>
</section>
<section id="the-kill-chain" class="level4">
<h4 class="anchored" data-anchor-id="the-kill-chain">The Kill Chain</h4>
<ul>
<li>This competition centers around which military can better:
<ul>
<li><strong>Understand</strong> the battlespace.</li>
<li><strong>Make decisions</strong> based on that understanding.</li>
<li><strong>Take actions</strong> to achieve their objectives.</li>
<li><strong>Deny</strong> these advantages to their opponents.</li>
</ul></li>
</ul>
</section>
<section id="the-three-elements-of-warfare-move-shoot-communicate" class="level4">
<h4 class="anchored" data-anchor-id="the-three-elements-of-warfare-move-shoot-communicate">The Three Elements of Warfare: Move, Shoot, Communicate</h4>
<ul>
<li>These operational considerations are crucial within the broader framework of offense vs.&nbsp;defense and the kill chain.</li>
</ul>
</section>
</section>
<section id="movement-shifting-advantages-and-the-rise-of-ubiquitous-sensing" class="level3">
<h3 class="anchored" data-anchor-id="movement-shifting-advantages-and-the-rise-of-ubiquitous-sensing">Movement: Shifting Advantages and the Rise of Ubiquitous Sensing</h3>
<section id="traditional-assumptions-of-u.s.-military-movement" class="level4">
<h4 class="anchored" data-anchor-id="traditional-assumptions-of-u.s.-military-movement">Traditional Assumptions of U.S. Military Movement</h4>
<ul>
<li>The U.S. has assumed it can:
<ul>
<li>Move large forces over long distances.</li>
<li>Rely on small numbers of advanced systems to hide, penetrate, and overmatch adversaries.</li>
<li>Maintain superior quality over quantity.</li>
<li>Ensure unfettered logistical support.</li>
</ul></li>
</ul>
</section>
<section id="the-impact-of-chinas-military-modernization-and-emerging-technologies" class="level4">
<h4 class="anchored" data-anchor-id="the-impact-of-chinas-military-modernization-and-emerging-technologies">The Impact of China’s Military Modernization and Emerging Technologies</h4>
<ul>
<li>China’s military modernization and emerging technologies challenge these assumptions:
<ul>
<li><strong>Ubiquitous sensors</strong> make hiding increasingly difficult and finding easier.
<ul>
<li>Examples:
<ul>
<li>Russian involvement in Ukraine exposed through social media imagery.</li>
<li>Chinese military installations in the South China Sea revealed by commercial satellite imagery.</li>
</ul></li>
</ul></li>
<li><strong>Large constellations of satellites</strong> will provide constant surveillance, eliminating hiding places for large military assets.</li>
<li><strong>Advanced sensors</strong>, like passive radar, are making stealth technologies less effective.</li>
<li><strong>Networks of intelligent machines</strong> will fuse sensor data, further eroding hiding opportunities.</li>
</ul></li>
</ul>
</section>
<section id="the-future-of-hiding-and-the-rise-of-deception" class="level4">
<h4 class="anchored" data-anchor-id="the-future-of-hiding-and-the-rise-of-deception">The Future of Hiding and the Rise of Deception</h4>
<ul>
<li><strong>Active deception</strong> of sensors may be the best hope for hiding.
<ul>
<li>This could involve targeting the algorithms that interpret sensor data.</li>
</ul></li>
</ul>
</section>
<section id="the-return-of-mass-to-the-battlefield-and-the-rise-of-battle-networks" class="level4">
<h4 class="anchored" data-anchor-id="the-return-of-mass-to-the-battlefield-and-the-rise-of-battle-networks">The Return of Mass to the Battlefield and the Rise of Battle Networks</h4>
<ul>
<li><strong>Military Internet of Things (IoT)</strong> will enable the deployment of vast numbers of intelligent machines, shifting the advantage to those who can field larger forces.
<ul>
<li>This challenges the traditional trade-off between quantity and quality, as militaries will be able to achieve both.</li>
<li>Example: The 2019 Iranian drone and missile attack on Saudi oil facilities demonstrates the potential of massed, attritable systems.</li>
</ul></li>
</ul>
</section>
<section id="the-increasing-speed-and-expanding-scope-of-movement" class="level4">
<h4 class="anchored" data-anchor-id="the-increasing-speed-and-expanding-scope-of-movement">The Increasing Speed and Expanding Scope of Movement</h4>
<ul>
<li>Military IoT will lead to:
<ul>
<li><strong>Exponential increase</strong> in the number of actions and the speed at which they occur.</li>
<li><strong>Collapsed timelines</strong> for decision-making, requiring greater automation.</li>
</ul></li>
<li><strong>Hypersonic weapons</strong> will further accelerate the speed of warfare, compressing strategic decisions to tactical timelines.
<ul>
<li>This could lead to a form of “mutually assured hypersonic destruction,” similar to the logic of nuclear deterrence.</li>
</ul></li>
</ul>
</section>
<section id="transformation-of-logistics" class="level4">
<h4 class="anchored" data-anchor-id="transformation-of-logistics">Transformation of Logistics</h4>
<ul>
<li><strong>Intelligent machines</strong> and <strong>advanced manufacturing</strong> will revolutionize logistics:
<ul>
<li>Systems will become easier, cheaper, and faster to produce.</li>
<li><strong>3D printing</strong> will enable on-demand production of weapons and equipment near the battlefield.</li>
</ul></li>
</ul>
</section>
<section id="the-growing-importance-of-the-digital-and-space-domains" class="level4">
<h4 class="anchored" data-anchor-id="the-growing-importance-of-the-digital-and-space-domains">The Growing Importance of the Digital and Space Domains</h4>
<ul>
<li>As physical movement becomes more difficult, militaries will prioritize:
<ul>
<li><strong>Cyber maneuver warfare:</strong> Offering speed, stealth, and plausible deniability.</li>
<li><strong>Space-based operations:</strong> Establishing persistent presence and logistical hubs in orbit.</li>
<li><strong>Expansion of the battlefield</strong> to include the space between Earth and the Moon.</li>
</ul></li>
</ul>
</section>
</section>
<section id="shooting-longer-ranges-increased-accuracy-and-overwhelming-effects" class="level3">
<h3 class="anchored" data-anchor-id="shooting-longer-ranges-increased-accuracy-and-overwhelming-effects">Shooting: Longer Ranges, Increased Accuracy, and Overwhelming Effects</h3>
<section id="traditional-u.s.-approach-to-shooting" class="level4">
<h4 class="anchored" data-anchor-id="traditional-u.s.-approach-to-shooting">Traditional U.S. Approach to Shooting</h4>
<ul>
<li>Assumptions have driven a preference for:
<ul>
<li>Small numbers of highly accurate weapons.</li>
<li>Shorter-range engagement.</li>
<li>Effective hiding as the best defense.</li>
</ul></li>
</ul>
</section>
<section id="the-impact-of-chinas-military-modernization-and-emerging-technologies-1" class="level4">
<h4 class="anchored" data-anchor-id="the-impact-of-chinas-military-modernization-and-emerging-technologies-1">The Impact of China’s Military Modernization and Emerging Technologies</h4>
<ul>
<li>China’s advancements in long-range, accurate, and lethal weapons are challenging these assumptions.
<ul>
<li>This affects U.S. air and maritime operations in East Asia and, to a lesser extent, U.S. forces in Europe and the Middle East.</li>
<li>Example: Iran’s downing of a U.S. Global Hawk drone in 2019.</li>
</ul></li>
</ul>
</section>
<section id="the-changing-character-of-shooting-from-kinetic-to-non-kinetic-effects" class="level4">
<h4 class="anchored" data-anchor-id="the-changing-character-of-shooting-from-kinetic-to-non-kinetic-effects">The Changing Character of Shooting: From Kinetic to Non-Kinetic Effects</h4>
<ul>
<li>While traditional weapons remain relevant, militaries will increasingly leverage:
<ul>
<li><strong>Cyberattacks:</strong> To cripple adversaries’ ability to wage war before deploying physical forces.</li>
<li><strong>Electronic warfare:</strong> To disrupt command and control systems.</li>
<li><strong>Directed energy weapons:</strong> Offering speed-of-light attacks.</li>
</ul></li>
</ul>
</section>
<section id="increasing-range-overcoming-physical-and-economic-limitations" class="level4">
<h4 class="anchored" data-anchor-id="increasing-range-overcoming-physical-and-economic-limitations">Increasing Range: Overcoming Physical and Economic Limitations</h4>
<ul>
<li>Non-kinetic weapons are not bound by the traditional limitations of range.</li>
<li>New technologies, such as hypersonic weapons and electromagnetic railguns, will also increase the range of kinetic fires.</li>
<li>This will eliminate safe havens and expand the battlefield to include:
<ul>
<li>Outer space.</li>
<li>Logistics networks.</li>
<li>Information and communications systems.</li>
<li>Domestic critical infrastructure.</li>
</ul></li>
</ul>
</section>
<section id="enhancing-accuracy-the-power-of-intelligent-machines-and-sensor-fusion" class="level4">
<h4 class="anchored" data-anchor-id="enhancing-accuracy-the-power-of-intelligent-machines-and-sensor-fusion">Enhancing Accuracy: The Power of Intelligent Machines and Sensor Fusion</h4>
<ul>
<li>Accuracy will improve through:
<ul>
<li>Faster data collection and sharing facilitated by intelligent machines.</li>
<li>Real-time precision strike capabilities enabled by military IoT.</li>
<li>Sensor fusion to overcome limitations of individual sensors and enhance target identification.</li>
</ul></li>
</ul>
</section>
<section id="increasing-effects-volume-velocity-and-the-overwhelm-advantage" class="level4">
<h4 class="anchored" data-anchor-id="increasing-effects-volume-velocity-and-the-overwhelm-advantage">Increasing Effects: Volume, Velocity, and the Overwhelm Advantage</h4>
<ul>
<li>The future of shooting involves:
<ul>
<li><strong>Vast numbers of armed intelligent machines</strong> capable of delivering both kinetic and non-kinetic effects.</li>
<li><strong>Increased volume and velocity of fire</strong> due to the sheer number of weapons and faster decision-making.</li>
<li><strong>Overwhelm tactics</strong> to overcome even well-defended targets through mass and attrition.</li>
</ul></li>
</ul>
</section>
</section>
<section id="communicate-decentralization-resilience-and-the-human-machine-nexus" class="level3">
<h3 class="anchored" data-anchor-id="communicate-decentralization-resilience-and-the-human-machine-nexus">Communicate: Decentralization, Resilience, and the Human-Machine Nexus</h3>
<section id="traditional-u.s.-military-communications-centralized-and-vulnerable" class="level4">
<h4 class="anchored" data-anchor-id="traditional-u.s.-military-communications-centralized-and-vulnerable">Traditional U.S. Military Communications: Centralized and Vulnerable</h4>
<ul>
<li>The U.S. relies on a <strong>centralized “hub-and-spoke” model</strong> for military communications, making it vulnerable to attack.</li>
<li>This model is:
<ul>
<li>Manpower-intensive.</li>
<li>Energy-intensive.</li>
<li>Bandwidth-dependent.</li>
<li>Physically large and susceptible to disruption.</li>
</ul></li>
</ul>
</section>
<section id="the-future-of-military-communications-decentralized-resilient-and-machine-driven" class="level4">
<h4 class="anchored" data-anchor-id="the-future-of-military-communications-decentralized-resilient-and-machine-driven">The Future of Military Communications: Decentralized, Resilient, and Machine-Driven</h4>
<ul>
<li>Militaries will prioritize:
<ul>
<li><strong>Resilient networks</strong> that can withstand attacks, recover quickly, and reconstitute themselves.</li>
<li><strong>Beyond-line-of-sight communications</strong> for extended range.</li>
<li><strong>Software-defined communications</strong> for frequency agility.</li>
<li><strong>Decentralized “mesh” networks</strong> that are more difficult to disrupt than centralized systems.</li>
</ul></li>
</ul>
</section>
<section id="enabling-technologies-for-decentralized-communications" class="level4">
<h4 class="anchored" data-anchor-id="enabling-technologies-for-decentralized-communications">Enabling Technologies for Decentralized Communications</h4>
<ul>
<li>Key enablers include:
<ul>
<li><strong>Ubiquitous space-based communications networks</strong> for global coverage and reduced jamming vulnerability.</li>
<li><strong>Intelligent machines with edge computing capabilities</strong> to process information locally, reducing reliance on centralized hubs.</li>
</ul></li>
</ul>
</section>
<section id="the-evolving-role-of-manned-systems-and-the-rise-of-human-machine-teaming" class="level4">
<h4 class="anchored" data-anchor-id="the-evolving-role-of-manned-systems-and-the-rise-of-human-machine-teaming">The Evolving Role of Manned Systems and the Rise of Human-Machine Teaming</h4>
<ul>
<li><strong>Manned systems</strong> will transition from platforms for moving, shooting, and communicating to mobile command and control centers.</li>
<li><strong>Human-machine teaming</strong> will become increasingly important, with:
<ul>
<li>Humans providing high-level decision-making and ethical oversight.</li>
<li>Machines performing tasks that require speed, scale, and precision.</li>
</ul></li>
</ul>
</section>
<section id="the-future-of-command-and-control-from-virtual-reality-to-brain-computer-interface" class="level4">
<h4 class="anchored" data-anchor-id="the-future-of-command-and-control-from-virtual-reality-to-brain-computer-interface">The Future of Command and Control: From Virtual Reality to Brain-Computer Interface</h4>
<ul>
<li>Future command and control will leverage:
<ul>
<li><strong>Virtual and augmented reality</strong> for immersive battlefield awareness.</li>
<li><strong>Brain-computer interface</strong> for direct communication between humans and intelligent machines.</li>
</ul></li>
</ul>
</section>
<section id="data-as-a-key-terrain-and-the-challenge-of-algorithmic-deception" class="level4">
<h4 class="anchored" data-anchor-id="data-as-a-key-terrain-and-the-challenge-of-algorithmic-deception">Data as a Key Terrain and the Challenge of Algorithmic Deception</h4>
<ul>
<li>Protecting military data will be crucial, as it underpins the effectiveness of artificial intelligence.
<ul>
<li>Adversaries will seek to poison data sets and deceive algorithms.</li>
<li>Countering these threats will require:
<ul>
<li><strong>Rapid algorithm updates</strong> to patch vulnerabilities and adapt to new tactics.</li>
<li><strong>Sensor fusion</strong> to provide context and reduce the likelihood of deception.</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="implications-for-the-united-states-reimagining-national-defense" class="level3">
<h3 class="anchored" data-anchor-id="implications-for-the-united-states-reimagining-national-defense">Implications for the United States: Reimagining National Defense</h3>
<section id="reassessing-assumptions-and-embracing-new-approaches" class="level4">
<h4 class="anchored" data-anchor-id="reassessing-assumptions-and-embracing-new-approaches">Reassessing Assumptions and Embracing New Approaches</h4>
<ul>
<li>The U.S. must adapt its military to a changing threat environment and technological landscape.</li>
<li>This requires rethinking assumptions about:
<ul>
<li>Force structure: From small numbers of exquisite systems to larger numbers of more affordable and attritable platforms.</li>
<li>Operational concepts: From reliance on dominance to strategies that account for contested environments.</li>
<li>Technological development: Prioritizing technologies that enhance resilience, agility, and the ability to operate in contested domains.</li>
</ul></li>
</ul>
</section>
<section id="recognizing-the-erosion-of-dominance-and-preparing-for-a-different-future" class="level4">
<h4 class="anchored" data-anchor-id="recognizing-the-erosion-of-dominance-and-preparing-for-a-different-future">Recognizing the Erosion of Dominance and Preparing for a Different Future</h4>
<ul>
<li>The U.S. must acknowledge that its military dominance is eroding.</li>
<li>China’s rise as a peer competitor necessitates a fundamental shift in thinking about national defense.</li>
<li>The future security environment will be characterized by:
<ul>
<li><strong>Military technological parity</strong> between great powers.</li>
<li><strong>Contested environments</strong> across all domains, including cyber and space.</li>
<li><strong>Accelerated decision-making timelines</strong> driven by the speed of warfare.</li>
</ul></li>
</ul>
</section>
<section id="embracing-uncertainty-and-the-need-for-adaptation" class="level4">
<h4 class="anchored" data-anchor-id="embracing-uncertainty-and-the-need-for-adaptation">Embracing Uncertainty and the Need for Adaptation</h4>
<ul>
<li>The exact trajectory of technological development and the future of warfare are uncertain.</li>
<li>The U.S. must remain adaptable, constantly reassessing its assumptions and adjusting its strategies.</li>
<li>The key to success lies in anticipating change, embracing innovation, and outmaneuvering adversaries in the enduring competitions that define warfare.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-10-defense-without-dominance" class="level2">
<h2 class="anchored" data-anchor-id="chapter-10-defense-without-dominance">Chapter 10: Defense Without Dominance</h2>
<section id="the-need-for-a-new-defense-strategy" class="level3">
<h3 class="anchored" data-anchor-id="the-need-for-a-new-defense-strategy">The Need for a New Defense Strategy</h3>
<ul>
<li>In 2017, John McCain urged the Secretary of Defense to shift national defense focus from counterterrorism to the challenges posed by <strong>great power competitors</strong>, primarily China.
<ul>
<li><strong>Great power competitors</strong>: Nations with significant economic, technological, and military capabilities that can challenge U.S. interests and influence on a global scale.</li>
</ul></li>
<li>This shift was deemed necessary due to America’s declining military advantage and the increasing capabilities of China’s military.</li>
<li>McCain stressed the need for prioritization and strategic thinking in the face of finite resources.</li>
<li>He argued that the new defense strategy presented a crucial opportunity to develop an effective approach to China.</li>
</ul>
</section>
<section id="the-importance-of-strategy-and-choice" class="level3">
<h3 class="anchored" data-anchor-id="the-importance-of-strategy-and-choice">The Importance of Strategy and Choice</h3>
<ul>
<li>McCain criticized the misuse of the word “strategy” in Washington, where it often masked the lack of real prioritization.</li>
<li>He believed that effective strategies require making hard choices, prioritizing critical goals, and accepting trade-offs.</li>
<li>This approach stood in contrast to the common practice of creating all-inclusive but ultimately meaningless “laundry lists” of priorities.</li>
</ul>
</section>
<section id="the-2018-national-defense-strategy-a-step-in-the-right-direction" class="level3">
<h3 class="anchored" data-anchor-id="the-2018-national-defense-strategy-a-step-in-the-right-direction">The 2018 National Defense Strategy: A Step in the Right Direction</h3>
<ul>
<li>The 2018 National Defense Strategy, influenced by McCain’s advocacy, marked a positive step towards addressing the challenges of great power competition.</li>
<li><strong>Key Strengths:</strong>
<ul>
<li>Clearly identified long-term strategic competition with China and Russia as the top priority for the Department of Defense.</li>
<li>Provided detailed guidance for policy and programmatic choices in classified form.</li>
</ul></li>
<li>Despite its strengths, the 2018 strategy was seen as a starting point that required further development and bolder action.</li>
</ul>
</section>
<section id="the-need-for-a-more-radical-shift-defense-without-dominance" class="level3">
<h3 class="anchored" data-anchor-id="the-need-for-a-more-radical-shift-defense-without-dominance">The Need for a More Radical Shift: Defense Without Dominance</h3>
<ul>
<li>The author argues that the scale of change required necessitates a move beyond incremental adjustments.</li>
<li><strong>Defense without dominance</strong>: A strategic approach that acknowledges the decline of U.S. military superiority and focuses on defending core interests rather than pursuing global dominance.
<ul>
<li>Requires a fundamental shift in mindset, moving away from the offensive, power-projection model that has characterized U.S. military strategy since World War II.</li>
</ul></li>
</ul>
</section>
<section id="rethinking-americas-goals-in-an-era-of-great-power-competition" class="level3">
<h3 class="anchored" data-anchor-id="rethinking-americas-goals-in-an-era-of-great-power-competition">Rethinking America’s Goals in an Era of Great Power Competition</h3>
<ul>
<li>The post-Cold War era, characterized by American dominance, allowed the U.S. to pursue expansive global goals.
<ul>
<li>This period was an anomaly in history, where great power competition is the norm.</li>
</ul></li>
<li>The return of great power competition, particularly with China, necessitates a reassessment of U.S. goals and a return to prioritizing core interests.
<ul>
<li><strong>Core Interests</strong>: Those interests deemed so vital to a nation’s security, prosperity, and values that it is prepared to defend them with military force.</li>
</ul></li>
<li>The author argues for a more realistic and focused approach, recognizing that great powers can limit each other’s ambitions.</li>
</ul>
</section>
<section id="denying-china-military-dominance-the-primary-objective" class="level3">
<h3 class="anchored" data-anchor-id="denying-china-military-dominance-the-primary-objective">Denying China Military Dominance: The Primary Objective</h3>
<ul>
<li>The author contends that preventing Chinese military dominance in Asia should be the overarching objective of U.S. defense strategy.
<ul>
<li>Chinese military dominance could have detrimental consequences for the U.S. and its allies, potentially granting China control over vital economic centers and granting it leverage in international disputes.</li>
</ul></li>
<li>This goal requires prioritizing the Indo-Pacific region and making difficult choices about resource allocation and military deployments.</li>
</ul>
</section>
<section id="homeland-defense-a-new-old-imperative" class="level3">
<h3 class="anchored" data-anchor-id="homeland-defense-a-new-old-imperative">Homeland Defense: A New (Old) Imperative</h3>
<ul>
<li>For the first time since the 19th century, the U.S. faces a credible threat of conventional military attack on its homeland.
<ul>
<li>China’s development of long-range precision strike capabilities has made U.S. territory vulnerable.</li>
</ul></li>
<li>This new reality necessitates a significant shift in U.S. defense posture, requiring investments in homeland defense and a reevaluation of the military’s role in protecting the U.S. from conventional attack.</li>
</ul>
</section>
<section id="embracing-a-defensive-mindset-and-a-new-american-way-of-war" class="level3">
<h3 class="anchored" data-anchor-id="embracing-a-defensive-mindset-and-a-new-american-way-of-war">Embracing a Defensive Mindset and a New American Way of War</h3>
<ul>
<li>The author calls for a shift from an offensive to a defensive mindset, adapting to the challenges posed by China’s military capabilities.</li>
<li>This new approach emphasizes:
<ul>
<li><strong>Denial:</strong> Preventing adversaries from achieving their objectives by making it too costly or difficult.</li>
<li><strong>Deterrence:</strong> Dissuading adversaries from taking aggressive actions by demonstrating the ability and willingness to inflict unacceptable costs.</li>
</ul></li>
<li>This shift requires a move away from the traditional U.S. military model of power projection and dominance towards a more agile and resilient force structure.</li>
</ul>
</section>
<section id="building-a-different-kind-of-military-for-a-different-kind-of-war" class="level3">
<h3 class="anchored" data-anchor-id="building-a-different-kind-of-military-for-a-different-kind-of-war">Building a Different Kind of Military for a Different Kind of War</h3>
<ul>
<li>The current U.S. military, designed for a different era, is ill-suited to the challenges of great power competition with China.</li>
<li><strong>Key Weaknesses:</strong>
<ul>
<li>Reliance on small numbers of expensive, heavily manned, and vulnerable systems.</li>
<li>Centralized networks susceptible to disruption.</li>
<li>Limited ability to operate effectively in contested environments.</li>
</ul></li>
<li><strong>Attributes of a Future Force:</strong>
<ul>
<li><strong>Distributed Systems:</strong> Larger numbers of smaller, more dispersed systems to complicate enemy targeting and enhance survivability.</li>
<li><strong>Expendable Systems:</strong> Lower-cost, easily replaceable systems to mitigate the impact of losses and make it more expensive for adversaries to engage U.S. forces.</li>
<li><strong>Unmanned Systems:</strong> Greater reliance on unmanned systems to reduce risk to human life and operate more effectively in high-threat environments.</li>
<li><strong>Decentralized Networks:</strong> More resilient and adaptable networks that are difficult to disrupt and can continue to function even under attack.</li>
<li><strong>Software-Defined Capabilities:</strong> Greater emphasis on software, artificial intelligence, and autonomous systems to enhance decision-making, speed, and lethality.</li>
</ul></li>
</ul>
</section>
<section id="the-importance-of-allies-strength-in-partnerships" class="level3">
<h3 class="anchored" data-anchor-id="the-importance-of-allies-strength-in-partnerships">The Importance of Allies: Strength in Partnerships</h3>
<ul>
<li>The author stresses the critical role of allies in balancing Chinese power and deterring aggression.</li>
<li>While acknowledging the need for allies to share the burden of defense, the author criticizes the Trump administration’s approach to alliances as counterproductive.</li>
<li>He argues for a more collaborative and mutually beneficial approach, recognizing that allies provide:
<ul>
<li><strong>Forward Presence:</strong> Access to bases and territory that enhances U.S. military posture and reduces reliance on long-range power projection.</li>
<li><strong>Operational Support:</strong> Contributions to collective defense efforts, increasing overall capability and capacity.</li>
<li><strong>Political and Diplomatic Leverage:</strong> Amplified pressure on adversaries and greater legitimacy for U.S. actions.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-embracing-change-and-reimagining-defense" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-embracing-change-and-reimagining-defense">Conclusion: Embracing Change and Reimagining Defense</h3>
<ul>
<li>The author emphasizes the need for urgent and substantial changes to U.S. defense strategy to adapt to the realities of great power competition with China.</li>
<li>This requires a shift in mindset, a reassessment of goals, and a willingness to make difficult choices.</li>
<li>Failure to adapt risks leaving the U.S. vulnerable to Chinese coercion and unable to defend its core interests.</li>
<li>The future of U.S. national security depends on the ability to embrace change and reimagine defense in an era of renewed great power rivalry.</li>
</ul>
</section>
</section>
<section id="chapter-11-bureaucracy-does-its-thing" class="level2">
<h2 class="anchored" data-anchor-id="chapter-11-bureaucracy-does-its-thing">Chapter 11: Bureaucracy Does Its Thing</h2>
<section id="the-case-of-the-uss-harry-truman-a-microcosm-of-bureaucratic-inertia" class="level3">
<h3 class="anchored" data-anchor-id="the-case-of-the-uss-harry-truman-a-microcosm-of-bureaucratic-inertia">The Case of the USS Harry Truman: A Microcosm of Bureaucratic Inertia</h3>
<ul>
<li>In 2019, Secretary of Defense James Mattis and Secretary of the Navy Richard Spencer sought to modernize the Navy’s fleet by retiring the USS Harry Truman, an aircraft carrier, to free up funds for new technologies.</li>
</ul>
<section id="the-rationale-for-retiring-the-truman" class="level4">
<h4 class="anchored" data-anchor-id="the-rationale-for-retiring-the-truman">The Rationale for Retiring the Truman</h4>
<ul>
<li>The Truman was due for a costly mid-life refueling.</li>
<li>Retiring the ship would save $3.5 billion in refueling costs and $30 billion in operating and maintenance costs over its remaining lifespan.</li>
<li>These savings could fund investments in unmanned vessels and other advanced capabilities.</li>
</ul>
</section>
<section id="congressional-and-industry-backlash" class="level4">
<h4 class="anchored" data-anchor-id="congressional-and-industry-backlash">Congressional and Industry Backlash</h4>
<ul>
<li>Congress, caught off guard by the proposal, reacted negatively due to a lack of prior consultation and the perceived risk of replacing a proven asset with unproven technologies.</li>
<li>Congressional representatives from states heavily invested in the Truman’s maintenance and shipbuilding industry, along with lobbyists and unions, mobilized to block the retirement.</li>
</ul>
</section>
<section id="the-white-house-reversal" class="level4">
<h4 class="anchored" data-anchor-id="the-white-house-reversal">The White House Reversal</h4>
<ul>
<li>Vice President Mike Pence, in a politically motivated move, announced the reversal of the Truman’s retirement during a visit to the ship in Virginia, a key state for the upcoming presidential election.</li>
</ul>
</section>
<section id="the-outcome" class="level4">
<h4 class="anchored" data-anchor-id="the-outcome">The Outcome</h4>
<ul>
<li>The Truman’s retirement was canceled, and Congress allocated additional funds to keep it operational, diverting resources from future capabilities.</li>
<li>This epitomizes the difficulty of enacting meaningful change within the defense establishment due to bureaucratic inertia, political maneuvering, and the influence of special interest groups.</li>
</ul>
</section>
</section>
<section id="the-budget-process-a-cycle-of-short-term-thinking" class="level3">
<h3 class="anchored" data-anchor-id="the-budget-process-a-cycle-of-short-term-thinking">The Budget Process: A Cycle of Short-Term Thinking</h3>
<ul>
<li>The annual defense budget process, totaling nearly $700 billion for fiscal year 2020, exemplifies the prioritization of short-term needs over long-term strategic investments.</li>
</ul>
<section id="challenges-of-the-budget-process" class="level4">
<h4 class="anchored" data-anchor-id="challenges-of-the-budget-process">Challenges of the Budget Process:</h4>
<ul>
<li><strong>Lengthy and Inflexible:</strong> The multi-year budget planning cycle (currently five years) hinders adaptability to emerging technologies and changing security threats.</li>
<li><strong>Congressional Constraints:</strong> Congress often restricts the Pentagon’s budgetary flexibility, limiting the ability to reallocate funds to new priorities. For example, reprogramming funds often requires approval from multiple congressional committees and is capped at a tiny fraction of the total budget (less than 0.009%).</li>
<li><strong>Focus on Existing Programs:</strong> The majority of the budget is pre-allocated to existing programs, making it challenging to secure funding for new technologies.</li>
</ul>
</section>
<section id="the-power-of-communities-of-interest" class="level4">
<h4 class="anchored" data-anchor-id="the-power-of-communities-of-interest">The Power of “Communities of Interest”</h4>
<ul>
<li><strong>Decentralized Power Structure:</strong> Power within the Pentagon is distributed among various “communities of interest” (e.g., different branches of the military, specific weapons programs). These groups wield significant influence over budgetary decisions.</li>
<li><strong>Bottom-Up Budgeting:</strong> Budget proposals often originate from these communities, focused on maintaining existing programs rather than driving innovation or embracing disruptive technologies.</li>
<li><strong>Short-Term Incentives:</strong> Military personnel and civilian officials are incentivized to prioritize the programs and platforms within their communities of interest, as this impacts their careers and funding.</li>
</ul>
</section>
</section>
<section id="a-flawed-system-from-requirements-to-acquisition" class="level3">
<h3 class="anchored" data-anchor-id="a-flawed-system-from-requirements-to-acquisition">A Flawed System: From Requirements to Acquisition</h3>
<ul>
<li>The U.S. defense establishment faces systemic challenges beyond budgeting, hindering its ability to adapt and modernize effectively.</li>
</ul>
<section id="the-requirements-process-stifling-innovation" class="level4">
<h4 class="anchored" data-anchor-id="the-requirements-process-stifling-innovation">The Requirements Process: Stifling Innovation</h4>
<ul>
<li><strong>Purpose:</strong> To determine and validate necessary military capabilities for development or acquisition.</li>
<li><strong>Challenges:</strong>
<ul>
<li><strong>Bureaucratic Delays:</strong> The process can take years, leaving the military with outdated or inadequate equipment.</li>
<li><strong>Consensus-Driven:</strong> This often leads to a focus on the lowest common denominator and a resistance to high-risk, high-reward technologies.</li>
<li><strong>Lack of Vision:</strong> The process frequently fails to anticipate future needs or consider the potential of emerging technologies.</li>
</ul></li>
</ul>
</section>
<section id="the-acquisition-process-slow-and-risk-averse" class="level4">
<h4 class="anchored" data-anchor-id="the-acquisition-process-slow-and-risk-averse">The Acquisition Process: Slow and Risk-Averse</h4>
<ul>
<li><strong>Purpose:</strong> To acquire the capabilities identified in the requirements process.</li>
<li><strong>Challenges:</strong>
<ul>
<li><strong>Excessive Bureaucracy:</strong> The process is notoriously slow, risk-averse, and bogged down in regulations and paperwork.</li>
<li><strong>Focus on Traditional Systems:</strong> There’s a bias toward acquiring familiar technologies and upgrading existing systems, even when revolutionary solutions are available.</li>
<li><strong>Lack of Accountability:</strong> The diffuse decision-making structure often means that no single individual is empowered to take risks or accelerate the acquisition of vital technologies.</li>
</ul></li>
</ul>
</section>
</section>
<section id="the-political-and-cultural-dimensions-of-inertia" class="level3">
<h3 class="anchored" data-anchor-id="the-political-and-cultural-dimensions-of-inertia">The Political and Cultural Dimensions of Inertia</h3>
<ul>
<li><strong>Short-Term Political Incentives:</strong> Elected officials prioritize immediate concerns of their constituents and are less likely to champion long-term investments in defense innovation that may not yield immediate political benefits.</li>
<li><strong>The Influence of Special Interests:</strong> While lobbying by defense contractors plays a role, the bigger issue is the dwindling number of major defense companies and the outsized influence of those focused on legacy systems. This limits competition and innovation.</li>
<li><strong>Decline in Military Experience in Congress:</strong> The declining number of lawmakers with direct military experience can lead to both excessive deference to the military’s judgment and a lack of understanding of its complexities.</li>
<li><strong>Lack of Technical Expertise:</strong> The absence of technical backgrounds among political and military leaders hinders the understanding and adoption of emerging technologies.</li>
<li><strong>Resistance to Disruption:</strong> The shift to new technologies, while necessary, will inevitably cause economic and social disruption, creating resistance from those whose livelihoods depend on legacy systems.</li>
</ul>
</section>
<section id="the-trump-factor" class="level3">
<h3 class="anchored" data-anchor-id="the-trump-factor">The Trump Factor</h3>
<ul>
<li>While not solely responsible for the dysfunction, the Trump presidency has exacerbated existing problems.</li>
<li><strong>Politicization of the Military:</strong> Trump has frequently used the military for political purposes, diverting resources and attention away from long-term strategic priorities.</li>
<li><strong>Leadership Vacancies:</strong> Prolonged vacancies in key civilian positions within the Department of Defense have hampered decision-making and stalled progress on essential initiatives.</li>
</ul>
</section>
<section id="a-crisis-of-leadership-and-imagination" class="level3">
<h3 class="anchored" data-anchor-id="a-crisis-of-leadership-and-imagination">A Crisis of Leadership and Imagination</h3>
<ul>
<li>The challenges facing the U.S. defense establishment run deeper than any single administration or political party. There’s a fundamental failure:
<ul>
<li><strong>Failure of Imagination:</strong> To anticipate and adapt to the rapidly evolving landscape of warfare in the 21st century.</li>
<li><strong>Failure of Leadership:</strong> To make difficult choices, challenge the status quo, and prioritize long-term national security over short-term political expediency.</li>
</ul></li>
</ul>
</section>
<section id="urgent-need-for-change-a-call-to-action" class="level3">
<h3 class="anchored" data-anchor-id="urgent-need-for-change-a-call-to-action">Urgent Need for Change: A Call to Action</h3>
<ul>
<li>The U.S. must urgently address these systemic issues to maintain its military edge and confront future challenges.</li>
<li>Overcoming bureaucratic inertia, political dysfunction, and a culture of short-term thinking is paramount.</li>
<li>Failure to do so risks the security and prosperity of the United States in an increasingly dangerous world.</li>
</ul>
</section>
</section>
<section id="chapter-12-how-the-future-can-win" class="level2">
<h2 class="anchored" data-anchor-id="chapter-12-how-the-future-can-win">Chapter 12: How the Future Can Win</h2>
<section id="the-need-for-change-in-u.s.-defense" class="level3">
<h3 class="anchored" data-anchor-id="the-need-for-change-in-u.s.-defense">The Need for Change in U.S. Defense</h3>
<p>This chapter argues that the U.S. defense establishment needs significant change to adapt to future challenges. The author uses the case study of the JSTARS program and draws parallels to historical examples like the adoption of aircraft carriers and ICBMs to illustrate the need for a new approach. The chapter focuses on two key elements:</p>
<ul>
<li><strong>Incentives:</strong> Rewarding innovation, agility, and the development of technologies that address future threats.</li>
<li><strong>Imagination:</strong> Moving beyond traditional platforms and doctrines to embrace new ways of warfare and leverage emerging technologies.</li>
</ul>
</section>
<section id="case-study-the-jstars-program" class="level3">
<h3 class="anchored" data-anchor-id="case-study-the-jstars-program">Case Study: The JSTARS Program</h3>
<ul>
<li><strong>The Problem:</strong> The Air Force’s plan to replace the aging JSTARS aircraft, a vital intelligence, surveillance, and reconnaissance (ISR) platform, with a new version of the same aircraft.
<ul>
<li>This plan was flawed because the new JSTARS would be vulnerable to attacks from advanced adversaries like China and Russia.</li>
</ul></li>
<li><strong>The Solution:</strong> The Air Force proposed disaggregating JSTARS’s capabilities, distributing them across a network of unmanned aircraft and satellites. This approach offered greater resilience and survivability.</li>
<li><strong>The Challenge:</strong> Powerful members of Congress and defense contractors who stood to benefit from the continued production of the traditional JSTARS aircraft opposed the Air Force’s plan.</li>
<li><strong>The Success:</strong> The Air Force’s success in shifting to the new program stemmed from several factors:
<ul>
<li><strong>Political Strategy:</strong> Early and candid engagement with key stakeholders in Congress.</li>
<li><strong>Transparency:</strong> Providing detailed information about the threat to JSTARS and the advantages of the new program.</li>
<li><strong>Industry Engagement:</strong> Informing defense companies about the new plan, enabling them to lobby Congress.</li>
<li><strong>Compromise:</strong> Basing elements of the future program in the same state that would have hosted JSTARS, securing support from potential opponents.</li>
</ul></li>
<li><strong>The Lesson:</strong> Even good ideas require political maneuvering and strategic compromise to succeed within the existing defense system.</li>
</ul>
</section>
<section id="obstacles-to-change-and-reasons-for-hope" class="level3">
<h3 class="anchored" data-anchor-id="obstacles-to-change-and-reasons-for-hope">Obstacles to Change and Reasons for Hope</h3>
<ul>
<li><strong>Obstacles:</strong> The U.S. defense establishment faces significant obstacles to change, including:
<ul>
<li><strong>Parochial Military Services:</strong> Prioritizing their own interests over joint solutions.</li>
<li><strong>Self-Interested Companies:</strong> Focusing on profits and protecting existing programs.</li>
<li><strong>Distracted Political Leaders:</strong> Lacking focus on long-term defense planning and more concerned with short-term political gains.</li>
</ul></li>
<li><strong>Reasons for Hope:</strong> Despite these obstacles, the United States possesses key elements for successful adaptation:
<ul>
<li><strong>Financial Resources:</strong> Ample funding for defense.</li>
<li><strong>Technological Leadership:</strong> Access to cutting-edge technologies.</li>
<li><strong>Skilled Workforce:</strong> A talented pool of engineers and innovators.</li>
</ul></li>
<li><strong>The Core Issue:</strong> The main obstacle lies in Washington, D.C., and stems from:
<ul>
<li><strong>Dysfunctional Political System:</strong> Hampering the ability to make tough but necessary decisions.</li>
<li><strong>Lack of Vision:</strong> A failure to envision and implement necessary defense reforms.</li>
<li><strong>Urgency Deficit:</strong> A lack of urgency to drive change.</li>
</ul></li>
</ul>
</section>
<section id="restructuring-incentives-for-a-future-ready-military" class="level3">
<h3 class="anchored" data-anchor-id="restructuring-incentives-for-a-future-ready-military">Restructuring Incentives for a Future-Ready Military</h3>
<ul>
<li><strong>The Imperative:</strong> To prepare for future threats, the U.S. must restructure its defense incentives to favor:
<ul>
<li><strong>Networked Kill Chains:</strong> Over legacy platforms.</li>
<li><strong>New Ways of War:</strong> Over familiar doctrines.</li>
<li><strong>Defense:</strong> Over offense.</li>
<li><strong>Future Needs:</strong> Over present requirements.</li>
<li><strong>Software:</strong> Over hardware.</li>
<li><strong>Rapid Capability Development:</strong> Over acquisition compliance and cost accounting.</li>
<li><strong>Technological Diversity:</strong> Over reliance on traditional defense contractors.</li>
</ul></li>
<li><strong>The Mechanism:</strong> Achieving this shift necessitates:
<ul>
<li><strong>Leadership Ownership:</strong> Senior leaders in the Department of Defense and Congress must champion and drive change.</li>
<li><strong>Collaboration:</strong> A partnership between the Pentagon and Congress to establish shared expectations and present a unified front to stakeholders.</li>
<li><strong>Long-Term Vision:</strong> Recognizing that transforming the military is a multi-year process requiring sustained commitment.</li>
</ul></li>
<li><strong>Defining the Problems:</strong> Translating vague concepts into actionable operational problems, such as:
<ul>
<li><strong>Denying China Military Dominance:</strong> Specifically, developing the capability to neutralize 350 Chinese ships within the first three days of a conflict, a challenge requiring advanced ISR, real-time information sharing, and rapid decision-making.</li>
</ul></li>
<li><strong>Shifting the Paradigm:</strong> Moving away from traditional requirements and budget processes towards:
<ul>
<li><strong>Mission-Focused Competitions:</strong> Allocating significant funding to real-world competitions that identify the best solutions to specific operational challenges.</li>
<li><strong>Rewarding Winners:</strong> Providing substantial funding and fielding opportunities to the winners of these competitions, regardless of their affiliation (military service, established company, or startup).</li>
<li><strong>Embracing Rivalry:</strong> Leveraging the inherent rivalries between military branches and companies to drive innovation and accelerate the development of effective solutions.</li>
</ul></li>
<li><strong>Transitioning Incrementally:</strong> Acknowledging that the shift from legacy platforms to future technologies will be gradual:
<ul>
<li><strong>Initial Enhancement:</strong> New technologies will initially enhance existing platforms.</li>
<li><strong>Gradual Replacement:</strong> Over time, new technologies may replace legacy systems entirely.</li>
<li><strong>Mission Adaptation:</strong> Traditional platforms may find new roles, such as homeland defense, as their relevance in high-intensity conflicts diminishes.</li>
</ul></li>
<li><strong>The Power of Demonstration:</strong> Showing, not just telling, to build support for change:
<ul>
<li><strong>Deterrence through Demonstration:</strong> Convincing adversaries of U.S. military capabilities by showcasing new technologies.</li>
<li><strong>Domestic Persuasion:</strong> Demonstrating the effectiveness of new solutions to skeptical military leaders and policymakers to build domestic political support.</li>
</ul></li>
</ul>
</section>
<section id="fostering-a-vibrant-defense-technology-ecosystem" class="level3">
<h3 class="anchored" data-anchor-id="fostering-a-vibrant-defense-technology-ecosystem">Fostering a Vibrant Defense Technology Ecosystem</h3>
<ul>
<li><strong>The Problem:</strong> A lack of private investment in defense technology due to:
<ul>
<li><strong>Perceived Risk:</strong> The defense sector is viewed as a risky investment with a high failure rate for new technologies.</li>
<li><strong>Lack of Government Commitment:</strong> The government often fails to purchase promising technologies at scale, discouraging private investment.</li>
</ul></li>
<li><strong>The Solution:</strong> Creating incentives for private investment by:
<ul>
<li><strong>Picking Winners:</strong> Identifying and investing heavily in companies developing essential technologies like AI and autonomous systems.</li>
<li><strong>Clear Signals:</strong> Sending strong signals to the market about the government’s commitment to purchasing these technologies in large quantities.</li>
<li><strong>Multiplier Effect:</strong> Large government contracts will attract significantly more private investment, creating a virtuous cycle of innovation and growth.</li>
</ul></li>
<li><strong>Rethinking Earmarks:</strong> Reconsidering the ban on congressional earmarks, with safeguards for transparency and accountability, to enable Congress to directly fund promising defense technologies.</li>
<li><strong>The Importance of Lobbying:</strong> Encouraging companies developing future-oriented military capabilities to actively lobby for their programs and secure political support.<br>
</li>
<li><strong>Addressing the “Culture Problem”:</strong> The U.S. defense establishment needs to overcome its risk-averse, bureaucratic culture and embrace agility, competition, and a willingness to fail.</li>
</ul>
</section>
<section id="conclusion-the-future-can-win" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-the-future-can-win">Conclusion: The Future Can Win</h3>
<ul>
<li><strong>The Choice:</strong> The U.S. has a choice: cling to the familiar but increasingly obsolete or embrace change and build a military capable of winning future conflicts.</li>
<li><strong>The Stakes:</strong> The stakes are high, with nothing less than America’s national security hanging in the balance.</li>
<li><strong>The Path Forward:</strong> The path forward is clear:
<ul>
<li><strong>Define problems precisely.</strong></li>
<li><strong>Compete for solutions.</strong></li>
<li><strong>Pick winners.</strong></li>
<li><strong>Fund what matters.</strong></li>
</ul></li>
<li><strong>The Call to Action:</strong> The future of U.S. defense depends on the willingness of its leaders to embrace change, demonstrate courage, and make the tough decisions necessary to build a military ready for the challenges ahead.</li>
</ul>
</section>
</section>
<section id="conclusion-a-failure-of-imagination" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-a-failure-of-imagination">Conclusion: A Failure of Imagination</h2>
<section id="reflections-on-mccains-passing-and-the-state-of-america" class="level3">
<h3 class="anchored" data-anchor-id="reflections-on-mccains-passing-and-the-state-of-america">Reflections on McCain’s Passing and the State of America</h3>
<ul>
<li>On three occasions since John McCain’s death, the author experienced profound emotional responses:
<ul>
<li><strong>First Occasion:</strong> Upon receiving news of McCain’s passing, the author was overcome with gratitude for the time spent with him, realizing the incredible experiences they shared due to McCain’s influence.</li>
<li><strong>Second Occasion:</strong> During McCain’s memorial service, the author hoped for positive change in Washington, a desire for unity and a focus on national security, but remained pessimistic. This pessimism stemmed from the belief that the political divisions and mistrust would resurface, hindering progress.</li>
<li><strong>Third Occasion:</strong> Visiting McCain’s grave, the author felt sadness, recognizing that the situation in Washington had worsened since McCain’s death, becoming more divided and dysfunctional.</li>
</ul></li>
</ul>
</section>
<section id="americas-defense-opportunities-and-obstacles" class="level3">
<h3 class="anchored" data-anchor-id="americas-defense-opportunities-and-obstacles">America’s Defense: Opportunities and Obstacles</h3>
<ul>
<li>Despite the current political climate, there is a significant opportunity to reshape national defense.</li>
<li>Positive Signs:
<ul>
<li>Increased motivation within the defense establishment to adapt to new threats and technologies.</li>
<li>Dedicated personnel.</li>
<li>Advanced technology.</li>
<li>Ample financial resources.</li>
</ul></li>
<li>Major Obstacle: America’s inability to overcome internal challenges and make necessary changes.</li>
</ul>
</section>
<section id="the-persistent-problem-a-failure-of-imagination" class="level3">
<h3 class="anchored" data-anchor-id="the-persistent-problem-a-failure-of-imagination">The Persistent Problem: A Failure of Imagination</h3>
<ul>
<li>The author asserts that the root cause of the current national defense crisis is a <strong>failure of imagination</strong>, a term often used by McCain.</li>
<li>This failure manifests in the inability to:
<ul>
<li>Envision the potential consequences of inaction.</li>
<li>Comprehend the severity of the challenges faced.</li>
<li>Break free from the belief in America’s guaranteed success due to its past dominance.</li>
</ul></li>
</ul>
</section>
<section id="the-consequences-of-inaction" class="level3">
<h3 class="anchored" data-anchor-id="the-consequences-of-inaction">The Consequences of Inaction</h3>
<ul>
<li>If America fails to adapt:
<ul>
<li>Others will seize the opportunity to advance their military capabilities.</li>
<li>The United States will lose control over its destiny, becoming vulnerable to its rivals.</li>
<li>Change will be forced upon America, likely through negative events such as war or a breakdown of deterrence.</li>
</ul></li>
</ul>
</section>
<section id="call-to-action" class="level3">
<h3 class="anchored" data-anchor-id="call-to-action">Call to Action</h3>
<ul>
<li>The responsibility for safeguarding America’s future rests on the current generation.</li>
<li>While hope is essential, it is not a strategy.</li>
<li>Action is urgently needed to address the challenges and avert potential disasters.</li>
</ul>
</section>
<section id="conclusion-1" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-1">Conclusion</h3>
<ul>
<li>While the author acknowledges the difficulty of implementing necessary changes in a dysfunctional political environment, they emphasize the dire consequences of inaction.</li>
<li>The author concludes with a stark warning: failure to adapt will result in a loss of control over America’s fate.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>history</category>
  <guid>https://christianjmills.com/posts/the-kill-chain-book-notes/</guid>
  <pubDate>Tue, 27 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Office Hours 7: Replicate</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-007/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<ul>
<li>The session is a Q&amp;A about Replicate, a platform for running machine learning models.</li>
<li>Attendees include Emil Wallner (host), Joe (Replicate team), Zeke (Replicate team), and other individuals.</li>
<li>The notes below cover all the questions asked and the answers provided during the session.</li>
</ul>
</section>
<section id="pushing-models-to-replicate" class="level3">
<h3 class="anchored" data-anchor-id="pushing-models-to-replicate">Pushing Models to Replicate</h3>
<section id="what-types-of-student-projects-would-excite-the-replicate-team" class="level4">
<h4 class="anchored" data-anchor-id="what-types-of-student-projects-would-excite-the-replicate-team">What types of student projects would excite the Replicate team?</h4>
<ul>
<li><strong>Fine-tuned models with unique applications:</strong>
<ul>
<li>Replicate values innovative uses of models, particularly in image generation, and seeks to foster a similar community around language models.</li>
</ul></li>
<li><strong>Applications built on top of language models:</strong>
<ul>
<li>The team is interested in seeing projects that leverage Replicate’s capabilities to chain prompts, execute operations across different models, and build sophisticated application layers.</li>
</ul></li>
</ul>
</section>
<section id="how-enterprise-ready-is-replicate" class="level4">
<h4 class="anchored" data-anchor-id="how-enterprise-ready-is-replicate">How enterprise-ready is Replicate?</h4>
<ul>
<li><strong>Progress toward Enterprise Readiness:</strong>
<ul>
<li>Replicate is actively working on becoming more enterprise-ready.</li>
<li>They are currently working on achieving SOC 2 compliance, with Type 1 audit completed and Type 2 in progress.</li>
</ul></li>
<li><strong>Data Security and Compliance:</strong>
<ul>
<li>Replicate acknowledges the importance of data security and offers flexible data retention policies to address specific user concerns.</li>
<li>Users with data sensitivity concerns are encouraged to reach out to Replicate directly.</li>
</ul></li>
<li><strong>Discord as a Resource:</strong>
<ul>
<li>For detailed discussions on enterprise readiness and data security, the Replicate Discord channel is a valuable resource.</li>
</ul></li>
</ul>
</section>
<section id="whats-required-to-push-an-open-source-function-calling-model-compatible-with-the-openai-api-specification" class="level4">
<h4 class="anchored" data-anchor-id="whats-required-to-push-an-open-source-function-calling-model-compatible-with-the-openai-api-specification">What’s required to push an open-source function-calling model compatible with the OpenAI API specification?</h4>
<ul>
<li><strong>OpenAI API Compatibility:</strong>
<ul>
<li>Replicate has an alternative API compatible with OpenAI but available only for a select set of language models they maintain.</li>
<li>They are exploring expanding this functionality to users.</li>
</ul></li>
<li><strong>Limitations with List Input Types:</strong>
<ul>
<li>Currently, Replicate’s predictor doesn’t fully support list input types (lists or lists of dictionaries), posing a challenge for exact OpenAI API replication.</li>
</ul></li>
<li><strong>Workarounds and Future Plans:</strong>
<ul>
<li>While exact replication isn’t immediately feasible, workarounds using COG’s current input types exist.</li>
<li>Replicate aims to introduce support for list input types to improve OpenAI compatibility.</li>
</ul></li>
</ul>
</section>
</section>
<section id="building-applications-on-replicate" class="level3">
<h3 class="anchored" data-anchor-id="building-applications-on-replicate">Building Applications on Replicate</h3>
<section id="what-are-examples-of-application-layers-on-top-of-llms-that-the-replicate-team-would-like-to-see" class="level4">
<h4 class="anchored" data-anchor-id="what-are-examples-of-application-layers-on-top-of-llms-that-the-replicate-team-would-like-to-see">What are examples of application layers on top of LLMs that the Replicate team would like to see?</h4>
<ul>
<li><strong>Existing Applications and Future Potential:</strong>
<ul>
<li>While not many application layers exist yet, Replicate has observed interesting use cases like web scraping and internal projects.</li>
</ul></li>
<li><strong>Promoting Application Building:</strong>
<ul>
<li>Replicate acknowledges the need to showcase application building possibilities and plans updates to COG to simplify the process.</li>
</ul></li>
<li><strong>New Capabilities with Secrets Management:</strong>
<ul>
<li>The recent introduction of secrets enables charging users for usage in chained operations, opening possibilities for creating complex workflows on Replicate.</li>
</ul></li>
</ul>
</section>
<section id="what-is-replicates-approach-to-logging-evals-and-secrets" class="level4">
<h4 class="anchored" data-anchor-id="what-is-replicates-approach-to-logging-evals-and-secrets">What is Replicate’s approach to logging, evals, and secrets?</h4>
<ul>
<li><strong>Logging Predictions:</strong>
<ul>
<li>Replicate logs inputs, outputs, and content printed to logs within the <code>predict</code> function.</li>
<li>Each prediction has a permanent link for accessing these logs, aiding debugging and collaboration.</li>
<li>Example: The formatted prompt and random seed were deemed important and thus included in the logs of a specific model.</li>
</ul></li>
<li><strong>Secrets Management:</strong>
<ul>
<li>Replicate now allows secret input types for sensitive information like API tokens.</li>
<li>When defining a <code>predict</code> method with <code>type=secret</code>, an API signature is generated with a <code>secret</code> type argument, ensuring secure handling and redaction in logs and shared predictions.</li>
<li>Current Limitation: Secrets are not accessible during model setup, requiring workarounds for tasks like downloading weights.</li>
</ul></li>
<li><strong>Evals (Model Evaluation):</strong>
<ul>
<li>Replicate has not yet focused extensively on providing tools for evaluating model performance over time or analyzing user interaction patterns.</li>
<li>Future Considerations: There’s interest in incorporating such features, potentially starting with exploratory data analysis (EDA) on prediction logs.</li>
</ul></li>
</ul>
</section>
<section id="data-retention" class="level4">
<h4 class="anchored" data-anchor-id="data-retention">Data Retention</h4>
<ul>
<li><strong>Data Retention Policies:</strong>
<ul>
<li>Replicate retains prediction data for a certain period, which is not explicitly stated in the session.</li>
<li>The data is encrypted and not shared with external parties.</li>
</ul></li>
<li><strong>Flexible Retention and User Concerns:</strong>
<ul>
<li>They offer flexible retention options for users with specific data sensitivity needs, particularly regarding privacy and legal compliance.</li>
</ul></li>
</ul>
</section>
<section id="user-feedback-mechanism" class="level4">
<h4 class="anchored" data-anchor-id="user-feedback-mechanism">User Feedback Mechanism</h4>
<ul>
<li><strong>Current Feedback Options:</strong>
<ul>
<li>While some Replicate web apps, such as the Llama 2 chat application, have built-in feedback mechanisms, there is no platform-wide solution for capturing user feedback on model predictions.</li>
</ul></li>
<li><strong>Future Considerations:</strong>
<ul>
<li>Replicate is exploring the implementation of a thumbs-up/thumbs-down feedback mechanism or annotation system for logging user evaluations.</li>
</ul></li>
<li><strong>Alternative Solutions:</strong>
<ul>
<li>Users can create their own feedback logging systems by associating prediction IDs with feedback data stored in a separate database.</li>
<li>This allows users to track model performance based on their specific criteria and use cases.</li>
</ul></li>
</ul>
</section>
</section>
<section id="revenue-sharing" class="level3">
<h3 class="anchored" data-anchor-id="revenue-sharing">Revenue Sharing</h3>
<ul>
<li><strong>Potential Revenue-Sharing Model:</strong>
<ul>
<li>Replicate is actively discussing the implementation of a revenue-sharing model to encourage collaboration and incentivize model development.</li>
<li>The specifics of this model, such as the revenue split and payment mechanisms, are still under consideration.</li>
</ul></li>
<li><strong>User Benefits and Future Implications:</strong>
<ul>
<li>If implemented, this model could provide financial benefits to model creators based on the usage of their models.</li>
<li>It could foster a more vibrant and active community around model development on the platform.</li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/office-hours-007/</guid>
  <pubDate>Sun, 25 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Notes on Weapons of Mass Instruction: A Schoolteacher’s Journey Through the Dark World of Compulsory Schooling</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/weapons-of-mass-instruction-book-notes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
These notes are part of the following collection:
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="../../series/notes/education-notes.html"><strong>Education</strong></a></p>
</div>
</div>
<ul>
<li>Prologue: Against School<br>
</li>
<li>Chapter 1: Everything You Know About Schools Is Wrong<br>
</li>
<li>Chapter 2: Walkabout, London<br>
</li>
<li>Chapter 3: Fat Stanley and the Lancaster Amish<br>
</li>
<li>Chapter 4: David Sarnoff’s Classroom<br>
</li>
<li>Chapter 5. Hector Isn’t the Problem<br>
</li>
<li>Chapter 6: The Camino de Santiago<br>
</li>
<li>Chapter 7: Weapons of Mass Instruction<br>
</li>
<li>Chapter 8: What is Education?<br>
</li>
<li>Chapter 9: A Letter to My Granddaughter About Dartmouth<br>
</li>
<li>Chapter 10: Incident at Highland High</li>
<li>Afterword: Invitation to an Open Conspiracy</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Book Links:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Book Links:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://newsociety.com/books/w/weapons-of-mass-instruction">Publisher Page</a></li>
</ul>
</div>
</div>
<section id="prologue-against-school" class="level2">
<h2 class="anchored" data-anchor-id="prologue-against-school">Prologue: Against School</h2>
<section id="boredom-in-the-classroom" class="level3">
<h3 class="anchored" data-anchor-id="boredom-in-the-classroom">Boredom in the Classroom</h3>
<ul>
<li><strong>Gatto’s Experience:</strong>
<ul>
<li>Taught for 30 years, observing pervasive boredom in schools.</li>
<li>Students found work stupid, meaningless, and unengaging.</li>
<li>Teachers were equally bored, blaming students’ lack of interest and focus on grades.</li>
<li><strong>Gatto’s Grandfather’s Lesson:</strong> Boredom is the individual’s responsibility, not an external condition.</li>
</ul></li>
<li><strong>Root of the Problem:</strong>
<ul>
<li>Schools perpetuate childishness by treating boredom and obedience as the norm.</li>
<li>Gatto observed that breaking free from these structures could foster curiosity, adventure, and resilience in students.</li>
</ul></li>
</ul>
</section>
<section id="questioning-the-system" class="level3">
<h3 class="anchored" data-anchor-id="questioning-the-system">Questioning the System</h3>
<ul>
<li><strong>A System Functioning as Designed:</strong>
<ul>
<li>What if schools are intentionally designed to produce the observed outcomes?</li>
<li>Could the goal be to prevent genuine growth and maintain a controllable populace?</li>
<li>Is forced schooling truly necessary, especially considering successful individuals who thrived without it?</li>
</ul></li>
<li><strong>Historical Perspective:</strong>
<ul>
<li>Many accomplished figures throughout American history lacked formal schooling.</li>
<li>Formal schooling does not guarantee success.</li>
<li>Compulsory schooling became widespread in the US between 1905 and 1915.</li>
</ul></li>
</ul>
</section>
<section id="the-true-purpose-of-public-schools" class="level3">
<h3 class="anchored" data-anchor-id="the-true-purpose-of-public-schools">The True Purpose of Public Schools</h3>
<ul>
<li><strong>Traditional Justifications (False):</strong>
<ul>
<li>To create good people.</li>
<li>To create good citizens.</li>
<li>To foster personal growth.</li>
</ul></li>
<li><strong>Actual Purpose (Revealed):</strong>
<ul>
<li><strong>H. L. Mencken (The American Mercury, April 1924):</strong>
<ul>
<li><blockquote class="blockquote">
<p>“The aim of public education is not to fill the young of the species with knowledge and awaken their intelligence… The aim is simply to reduce as many individuals as possible to the same safe level, to breed and train a standardized citizenry, to put down dissent and originality.”</p>
</blockquote></li>
</ul></li>
<li><strong>The Prussian Model:</strong>
<ul>
<li>American education is rooted in the Prussian system.</li>
<li>Designed to create a manageable populace through:
<ul>
<li>Mediocre intellect.</li>
<li>Suppression of individuality.</li>
<li>Limited leadership skills.</li>
<li>Docile and incomplete citizens.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="evidence-of-prussian-influence" class="level3">
<h3 class="anchored" data-anchor-id="evidence-of-prussian-influence">Evidence of Prussian Influence</h3>
<ul>
<li><strong>Prominent Figures:</strong>
<ul>
<li><strong>William James:</strong> Alluded to the Prussian model in the early 20th century.</li>
<li><strong>Orestes Brownson:</strong> Denounced the Prussianization of American schools in the 1840s.</li>
<li><strong>Horace Mann:</strong> Advocated for the Prussian system in his 1853 report to the Massachusetts Board of Education.</li>
</ul></li>
<li><strong>Historical Context:</strong>
<ul>
<li>Prussian influence in America during the Revolutionary War and early nation-building.</li>
</ul></li>
</ul>
</section>
<section id="james-bryant-conant-and-the-transformation-of-american-education" class="level3">
<h3 class="anchored" data-anchor-id="james-bryant-conant-and-the-transformation-of-american-education">James Bryant Conant and the Transformation of American Education</h3>
<ul>
<li><strong>Key Figure:</strong> James Bryant Conant (President of Harvard, influential figure in 20th-century education).</li>
<li><strong>Conant’s Revolution:</strong>
<ul>
<li>The modern school system resulted from a deliberate revolution between 1905 and 1930 (as stated in “The Child, the Parent, and the State,” 1959).</li>
</ul></li>
<li><strong>Alexander Inglis’s “Principles of Secondary Education” (1918):</strong>
<ul>
<li>Outlines the true purposes of compulsory schooling.</li>
<li>Designed to disrupt the unity of the working class and maintain control.</li>
</ul></li>
</ul>
</section>
<section id="the-six-basic-functions-of-modern-schooling-according-to-inglis" class="level3">
<h3 class="anchored" data-anchor-id="the-six-basic-functions-of-modern-schooling-according-to-inglis">The Six Basic Functions of Modern Schooling (According to Inglis)</h3>
<ol type="1">
<li><strong>Adjustive or Adaptive Function:</strong> Establish unquestioning obedience to authority.</li>
<li><strong>Integrating Function:</strong> Enforce conformity and predictability.</li>
<li><strong>Diagnostic and Directive Function:</strong> Determine and assign social roles through standardized testing and cumulative records.</li>
<li><strong>Differentiating Function:</strong> Limit education based on predetermined social roles.</li>
<li><strong>Selective Function:</strong> Weed out the “unfit” through grades, remedial placements, and social humiliation.</li>
<li><strong>Propedeutic Function:</strong> Cultivate a small elite to manage the system and control the masses.</li>
</ol>
</section>
<section id="perpetuating-the-system" class="level3">
<h3 class="anchored" data-anchor-id="perpetuating-the-system">Perpetuating the System</h3>
<ul>
<li><strong>Inglis and Conant:</strong> Key proponents of the Prussian-inspired system.</li>
<li><strong>Financial Incentives:</strong> Industrialists like Carnegie and Rockefeller recognized the economic benefits of a dumbed-down, consumerist society.</li>
<li><strong>Woodrow Wilson (1909):</strong>
<ul>
<li><blockquote class="blockquote">
<p>“We want one class of persons to have a liberal education and we want another class of persons…to forego the privileges of a liberal education and fit themselves to perform specific, difficult manual tasks.”</p>
</blockquote></li>
</ul></li>
</ul>
</section>
<section id="schooling-for-consumption" class="level3">
<h3 class="anchored" data-anchor-id="schooling-for-consumption">Schooling for Consumption</h3>
<ul>
<li><strong>Creating Consumers:</strong>
<ul>
<li>Mass production requires mass consumption.</li>
<li>Schooling discourages critical thinking, leaving individuals susceptible to marketing and consumerism.</li>
</ul></li>
<li><strong>Extending Childhood:</strong>
<ul>
<li><strong>Elwood P. Cubberley (“Public Education in the United States”, 1934):</strong> Schooling extended childhood by 2-6 years.</li>
<li><strong>Cubberley (“Public School Administration”, 1922):</strong>
<ul>
<li><blockquote class="blockquote">
<p>“Our schools are factories in which the raw products, children, are to be shaped and fashioned…and it is the business of the school to build its pupils according to the specifications laid down.”</p>
</blockquote></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="the-modern-condition-a-nation-of-children" class="level3">
<h3 class="anchored" data-anchor-id="the-modern-condition-a-nation-of-children">The Modern Condition: A Nation of Children</h3>
<ul>
<li><strong>Consequences of Extended Childhood:</strong>
<ul>
<li>Inability to form lasting relationships.</li>
<li>Lack of financial responsibility.</li>
<li>Dependence on external entertainment.</li>
<li>Apathy and unquestioning obedience.</li>
</ul></li>
<li><strong>Surrendering Freedom:</strong> Accepting limitations on freedom of speech and thought.</li>
</ul>
</section>
<section id="a-path-for-parents-raising-leaders-not-servants" class="level3">
<h3 class="anchored" data-anchor-id="a-path-for-parents-raising-leaders-not-servants">A Path for Parents: Raising Leaders, Not Servants</h3>
<ul>
<li><strong>Challenge the System:</strong> Recognize and resist the true nature of schooling.</li>
<li><strong>Encourage Critical Thinking:</strong> Teach children to question authority and think independently.</li>
<li><strong>Embrace Boredom:</strong> Allow children to develop inner resources and self-sufficiency.</li>
<li><strong>Provide Meaningful Learning:</strong> Expose children to complex and challenging subjects.</li>
<li><strong>Foster Independence:</strong> Encourage solitude and self-directed learning.</li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<ul>
<li><strong>Genius is Common:</strong> Schooling suppresses natural intelligence and creativity.</li>
<li><strong>A Call to Action:</strong> Resist the system and empower children to reach their full potential.</li>
</ul>
</section>
</section>
<section id="chapter-1-everything-you-know-about-schools-is-wrong" class="level2">
<h2 class="anchored" data-anchor-id="chapter-1-everything-you-know-about-schools-is-wrong">Chapter 1: Everything You Know About Schools Is Wrong</h2>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<ul>
<li><strong>Premise:</strong> Institutional schooling, contrary to popular belief, is a flawed system deliberately designed to control and limit human potential rather than foster it.</li>
<li><strong>Goal:</strong> To expose the hidden history, motivations, and consequences of compulsory schooling in America, revealing its true purpose as a tool for social engineering and economic control.</li>
<li><strong>Methodology:</strong> Examination of historical data, government documents, academic writings, and personal experiences to deconstruct the myths surrounding public education and reveal its true nature.</li>
</ul>
</section>
<section id="the-hidden-history-of-compulsory-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-hidden-history-of-compulsory-schooling">The Hidden History of Compulsory Schooling</h3>
<section id="the-factory-inspectors-survey-1909" class="level4">
<h4 class="anchored" data-anchor-id="the-factory-inspectors-survey-1909">The Factory Inspector’s Survey (1909)</h4>
<ul>
<li>A survey of 500 working children in 20 factories revealed that 412 of them preferred the harsh conditions of factory work to returning to school. (Source: Helen Todd, <em>Why Children Work</em>, McClure’s Magazine, April 1913)
<ul>
<li><strong>Archive:</strong> <a href="https://uofi.app.box.com/s/agtvym7n0hvf4qw2dr5d24txsgwrgc42">Why Children Work: The Children’s Answer By Helen M. Todd</a></li>
<li>Helen Todd received various reasons from children for favoring factory work, including:
<ol type="1">
<li><strong>Monetary Factors:</strong>
<ul>
<li>Being paid for the factory work they do.</li>
<li>The ability to support their families financially, afford more food, shoes for babies, and other basic needs.</li>
</ul></li>
<li><strong>Difficulty and Relevance of Schoolwork:</strong>
<ul>
<li>Perceived difficulty in understanding schoolwork compared to factory work.</li>
<li>Learning being perceived as hard.</li>
<li>Some children feeling unable to learn.</li>
<li>Perception that school education is not relevant to their ability to earn.</li>
</ul></li>
<li><strong>The Environment at School and Factory:</strong>
<ul>
<li>Preference for the factory environment as there is less judgment compared to school.</li>
<li>The factory environment doesn’t involve name-calling or bullying as in school.</li>
<li>They can avoid the corporal punishment experienced at school for:
<ul>
<li>Failure to learn</li>
<li>Whispering</li>
<li>Having string in their pocket</li>
<li>Squeaky seats</li>
<li>Late arrival</li>
<li>Forgetting pages of the book</li>
</ul></li>
</ul></li>
</ol></li>
</ul></li>
<li><strong>Implication:</strong> This finding challenges the conventional narrative that school is a universally desired and beneficial experience, suggesting that early schools were deeply flawed and potentially more unbearable than child labor.</li>
</ul>
</section>
<section id="the-rise-of-the-experts-1919-1933" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-the-experts-1919-1933">The Rise of the “Experts” (1919-1933)</h4>
<ul>
<li><strong>Professor Arthur Calhoun</strong> (Social History of the Family, 1919) observed a shift from family-centered child rearing to a system where <strong>community experts</strong> increasingly controlled education. (page 175)
<ul>
<li>Calhoun believed this change aligned with the eugenics movement, promoting the idea of selective breeding and social control through education. (page 331)</li>
<li><strong>Smithsonian Archive:</strong> <a href="https://library.si.edu/digital-library/book/socialhistoryof02calh">A Social History of the American Family From Colonial Times to the Present Volume 3</a></li>
</ul></li>
<li><strong>Mayor John Hyland</strong> of New York City (1922) claimed that an “<strong>invisible government</strong>” had seized control of the city’s schools, likening the situation to an octopus capturing its prey.
<ul>
<li>Hyland pointed to the <strong>Rockefeller Foundation</strong> as a driving force behind this shift in power.</li>
</ul></li>
<li>By 1928, <em>A Sociological Philosophy of Education</em> asserted that teachers were responsible for “running not merely schools, but the world.”
<ul>
<li><strong>Book:</strong> <a href="https://books.googleusercontent.com/books/content?req=AKW5QafjppMzEtdAqelLkYKjXw1x-F2OLHg2Pe90zK_uc-9EEus2N4IEzEg_ZLII7r0kPvIE2hhmKdK91b0Yv1U9sMmHEC1zPqIwlHpXNr1-xqTfeZFT20rnIgjy9c7yEHg90_ntnPsCKE9kl5Eu-tEuC0r8Pyv28sE8v9Oa0A0IGTTLtsz0a2mXSfhx1VeZwIr9cPnvBkDsW-11pIKaNB3UPZisouDw-LPKXxnqQ3G_yvwY0KK48KlRdephQfBjnOin6pWrXLljwVceTIFBfRmRaqpgvmrNh0XpdgwcQecg5qcdHY6nGQw">A Sociological Philosophy of Education by Ross Lee Finney</a></li>
</ul></li>
<li><strong>Edward Thorndyke</strong> (Columbia Teachers College, 1929), a prominent figure in <strong>Educational Psychology</strong>, declared that traditional <strong>academic subjects are of little value</strong>.
<ul>
<li>This statement reflects a move away from traditional academic goals towards a focus on social engineering and behavioral conditioning.</li>
</ul></li>
<li><strong>William Kilpatrick</strong> (Columbia Teachers College, <em>Education and the Social Crisis</em>, 1929) advocated for expert control over child rearing, arguing that families were ill-equipped compared to trained professionals.
<ul>
<li>This perspective underscores the growing influence of a technocratic elite seeking to manage society through scientific methods.</li>
</ul></li>
<li><strong>Max Mason</strong>, President of the Rockefeller Foundation (April 11, 1933), announced a national program aimed at controlling human behavior, with schools playing a central role.
<ul>
<li>This announcement signaled an open embrace of social engineering as a primary goal of education.</li>
<li>The program drew inspiration from <strong>Max Muller</strong>, a geneticist who believed in the possibility of controlling human evolution through genetic manipulation.</li>
<li><strong>Report:</strong> <a href="https://www.rockefellerfoundation.org/wp-content/uploads/Annual-Report-1933-1.pdf">The Rockefeller Foundation Annual Report (1933)</a></li>
<li><strong>Book Chaper:</strong> <a href="https://www.dianebpaul.com/uploads/2/3/2/9/23295024/rockefeller_foundation.pdf">DB Paul, The Rockefeller Foundation and the Origins of Behavioral Genetics. In K Benson, et al., eds., The Expansion of American Biology (New Brunswick, NJ: Rutgers Univ. Press, 1991), 263-283.</a></li>
</ul></li>
</ul>
</section>
<section id="the-eugenics-connection" class="level4">
<h4 class="anchored" data-anchor-id="the-eugenics-connection">The Eugenics Connection</h4>
<ul>
<li>The influence of eugenics, a movement advocating for selective breeding to improve the human race, played a significant role in shaping early 20th-century education reform.
<ul>
<li><strong>Goal:</strong> To separate “worthwhile breeding stock” from the “evolutionary dead-end material” (Source: Muller’s geneticist’s manifesto, signed by 22 prominent biologists).</li>
<li><strong>Impact:</strong> This ideology promoted segregation and discrimination within the education system, reinforcing social hierarchies based on perceived intellectual ability and social worth.</li>
</ul></li>
</ul>
</section>
<section id="the-post-war-shift-from-education-to-indoctrination" class="level4">
<h4 class="anchored" data-anchor-id="the-post-war-shift-from-education-to-indoctrination">The Post-War Shift: From Education to Indoctrination</h4>
<ul>
<li>World War II temporarily drove eugenics underground, but its core principles continued to influence education policy.
<ul>
<li>The focus shifted towards using schools as tools for social control and economic manipulation, aligning with the needs of a burgeoning industrial capitalist system.</li>
</ul></li>
<li>Two congressional investigations (1915 and 1959) revealed that school policy was being shaped by corporate interests operating outside of public scrutiny.
<ul>
<li><strong>Findings:</strong> Both investigations concluded that major foundations like Carnegie and Rockefeller exerted significant influence over education policy through funding, research, and advocacy.</li>
<li><strong>Outcome:</strong> These investigations were largely ignored, and their findings suppressed, highlighting the lack of transparency and accountability within the education system.</li>
</ul></li>
</ul>
</section>
<section id="the-behavioral-revolution-1967-1974" class="level4">
<h4 class="anchored" data-anchor-id="the-behavioral-revolution-1967-1974">The Behavioral Revolution (1967-1974)</h4>
<ul>
<li>Teacher training underwent a radical transformation, driven by private foundations, universities, and government agencies, with the goal of aligning education with the needs of the emerging global economy.</li>
<li><strong>Three key milestones:</strong>
<ul>
<li><strong>1. Designing Education for the Future:</strong> A government initiative that redefined education as a means to achieve national economic and social goals.
<ul>
<li><strong>Education Resources Information Center:</strong> <a href="https://eric.ed.gov/?id=ED018008">Designing Education for the Future: An Eight-State Project</a></li>
</ul></li>
<li><strong>2. The Behavioral Science Teacher Education Project (BSTEP):</strong> A large-scale project (Contract No.&nbsp;OEC-09-320424-4042) outlining plans to transform schools into laboratories for behavioral conditioning.
<ul>
<li><strong>Goals:</strong> To create a system where individuals are tracked from birth, exposed to subliminal influence, and conditioned to conform to predetermined beliefs and behaviors.</li>
<li><strong>Methods:</strong> Advocated for the use of chemical experimentation on minors, foreshadowing the rise of drugs like Ritalin and Adderall in classrooms.</li>
<li><strong>Feasibility Study:</strong> <a href="https://eric.ed.gov/?id=ED041868">Behavioral Science Teacher Education Program. Final Report</a></li>
</ul></li>
<li><strong>3. Bloom’s Taxonomy of Educational Objectives:</strong> A comprehensive manual by <strong>Benjamin Bloom</strong> (University of Chicago) that aimed to classify and control all aspects of human learning.
<ul>
<li><strong>Purpose:</strong> To provide educators with a framework for shaping students’ thoughts, feelings, and actions through carefully designed instruction.</li>
<li><strong>Book:</strong> <a href="https://web.archive.org/web/20201212072520id_/https://www.uky.edu/~rsand1/china2018/texts/Bloom%20et%20al%20-Taxonomy%20of%20Educational%20Objectives.pdf">Taxonomy of Educational Objectives, Handbook 1: Cognitive Domain</a></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="teachers-as-therapists" class="level4">
<h4 class="anchored" data-anchor-id="teachers-as-therapists">Teachers as Therapists</h4>
<ul>
<li>Rising school violence in the 1960s, partly attributed to policies restricting disciplinary action, provided a pretext for further intervention.
<ul>
<li>The <strong>Ford Foundation’s</strong> policy mandating “<strong>due process</strong>” in schools hampered teachers’ ability to maintain order and address disruptive behavior effectively.</li>
</ul></li>
<li>BSTEP advocated for training teachers as “<strong>teacher therapists</strong>,” tasked with applying behavioral psychology techniques to manage students’ emotions and modify their behavior.</li>
<li>This shift marked a significant departure from traditional teaching roles, transforming educators into agents of social control.</li>
</ul>
</section>
<section id="we-dont-need-brains" class="level4">
<h4 class="anchored" data-anchor-id="we-dont-need-brains">“We Don’t Need Brains”</h4>
<ul>
<li><strong>Historical Context:</strong> Between 1896 and 1920, industrialists and financiers like <strong>Andrew Carnegie</strong> and <strong>John D. Rockefeller</strong>, through their foundations, heavily influenced the development of compulsory schooling in the US.</li>
<li><strong>Motivations:</strong>
<ul>
<li>To create a workforce that was obedient, compliant, and trained for specific tasks rather than independent thinking and innovation.</li>
</ul></li>
<li><strong>Evidence:</strong>
<ul>
<li><strong>The General Education Board</strong> (funded by Rockefeller), in its 1906 <strong>Occasional Letter No.&nbsp;1</strong>, stated its aim:
<ul>
<li><blockquote class="blockquote">
<p>“In our dreams, people yield themselves with perfect docility to our molding hands…We shall not try to make these people or any of their children into philosophers or men of learning…The task…is very simple. We will organize children and teach them to do in a perfect way the things their fathers and mothers are doing in an imperfect way.”</p>
</blockquote></li>
<li><strong>Book:</strong> <a href="https://www.loc.gov/resource/gdcmassbookdig.countryschooloft00gates/?st=pdf&amp;pdfPage=1">The country school of to-morrow</a></li>
</ul></li>
</ul></li>
<li>This statement reveals a clear intention to use schooling to maintain a social hierarchy by limiting the aspirations and potential of the working class.</li>
</ul>
</section>
<section id="the-literacy-decline-a-case-study-in-failure" class="level4">
<h4 class="anchored" data-anchor-id="the-literacy-decline-a-case-study-in-failure">The Literacy Decline: A Case Study in Failure</h4>
<ul>
<li><strong>World War II Literacy Data:</strong> A high literacy rate (96%) was observed among men drafted during World War II (schooled in the 1930s), with only 4% deemed illiterate. (Source: Army enlistment tests)</li>
<li><strong>Korean War Literacy Decline:</strong> A significant drop in literacy (down to 81%) was observed among men drafted during the Korean War (schooled in the 1940s).</li>
<li><strong>Vietnam War Literacy Crisis:</strong> Illiteracy rates continued to rise, reaching 27% among men drafted during the Vietnam War (schooled in the 1950s and 1960s).</li>
<li><strong>Analysis:</strong>
<ul>
<li>Despite increased years of schooling, more qualified teachers, and “improved” educational materials, literacy rates steadily declined.</li>
<li>This suggests that changes in teaching methods, particularly the shift from <strong>phonetic</strong> to <strong>non-phonetic</strong> reading instruction, played a significant role in the decline.</li>
<li>The lack of a phonetic foundation disproportionately impacted Black Americans, who historically had limited access to formal education and relied on schools to teach basic literacy skills.</li>
<li>The <strong>Adult Literacy Survey</strong> and the <strong>National Assessment of Educational Progress</strong> later reported a 40% illiteracy rate among Black Americans and 17% among White Americans.</li>
</ul></li>
</ul>
</section>
<section id="william-torrey-harris-the-architect-of-american-indoctrination" class="level4">
<h4 class="anchored" data-anchor-id="william-torrey-harris-the-architect-of-american-indoctrination">William Torrey Harris: The Architect of American Indoctrination</h4>
<ul>
<li><strong>Background:</strong> <strong>William Torrey Harris</strong>, U.S. Commissioner of Education (1889-1906), was a leading proponent of Hegelian philosophy and a close friend of Andrew Carnegie.</li>
<li><strong>Influence:</strong> Harris played a pivotal role in shaping the American education system, promoting standardization and German-style compulsory schooling.</li>
<li><strong>Philosophy:</strong>
<ul>
<li><strong>Harris believed that children were property of the state and that education’s purpose was to create citizens who were obedient, subservient to authority, and alienated from their individuality.</strong></li>
<li>He advocated for schools that were designed to “<strong>transcend the beauty of nature</strong>” and promote withdrawal from the external world.</li>
</ul></li>
<li><strong>Key Quotes:</strong>
<ul>
<li><blockquote class="blockquote">
<p>“<strong>Ninety-nine students out of a hundred are automata, careful to walk in prescribed paths, careful to follow the prescribed custom. This is not an accident but the result of substantial education which, scientifically defined, is the subsumption of the individual.</strong>” (Source: <em>The Philosophy of Education</em>, 1906)</p>
</blockquote></li>
<li><blockquote class="blockquote">
<p>“<strong>The great purpose of school [is] self-alienation…It is to master the physical self, to transcend the beauty of nature. School should develop the power to withdraw from the external world.</strong>” (Source: <em>The Philosophy of Education</em>, 1906)</p>
</blockquote></li>
</ul></li>
<li><strong>Impact:</strong> Harris’s ideas laid the groundwork for an education system designed to create a compliant workforce rather than critical thinkers. His influence can still be felt in the emphasis on standardized testing, conformity, and the suppression of creativity within many schools today.</li>
</ul>
</section>
<section id="the-fourth-purpose-creating-human-resources" class="level4">
<h4 class="anchored" data-anchor-id="the-fourth-purpose-creating-human-resources">The Fourth Purpose: Creating Human Resources</h4>
<ul>
<li><strong>Original Purpose of Schooling:</strong> The traditional goals of education—moral development, civic responsibility, and personal growth—were gradually supplanted by a new objective: to produce human resources for the industrial economy.</li>
<li><strong>Corporate Influence:</strong> As schools became increasingly intertwined with the needs of business and industry, the curriculum shifted towards vocational training, obedience to authority, and the acceptance of a hierarchical social order.</li>
<li><strong>Woodrow Wilson’s Vision (1909):</strong> In a speech to businessmen, Wilson stated,
<ul>
<li><blockquote class="blockquote">
<p>“<strong>We want one class to have a liberal education. We want another class, a very much larger class of necessity, to forego the privilege of a liberal education and fit themselves to perform specific, difficult manual tasks.</strong>”</p>
</blockquote></li>
</ul></li>
<li><strong>Centralized Control:</strong> The rise of the “<strong>Education Trust</strong>” in 1917, comprised of representatives from powerful foundations, elite universities, and the National Education Association, further consolidated control over education policy in the hands of a select few.</li>
<li><strong>Consequences:</strong> This shift in purpose transformed schools from institutions of learning into factories for producing compliant workers, undermining the ideals of a free and democratic society.</li>
</ul>
</section>
<section id="the-problem-of-overproduction" class="level4">
<h4 class="anchored" data-anchor-id="the-problem-of-overproduction">The Problem of Overproduction</h4>
<ul>
<li><strong>Definition:</strong> <strong>Overproduction</strong>, also known as <strong>overcapacity</strong>, occurs when businesses produce more goods and services than the market can consume, leading to falling prices, economic instability, and social unrest.</li>
<li><strong>Historical Context:</strong> In the 19th century, America’s independent and resourceful population, coupled with its high levels of innovation, frequently led to overproduction and economic downturns.</li>
<li><strong>The Role of Education:</strong>
<ul>
<li>Policymakers and business leaders began to view education as a tool to manage overproduction by shaping consumer demand and limiting independent economic activity.</li>
</ul></li>
<li><strong>Solution:</strong> By conditioning citizens from a young age to become reliable employees rather than self-sufficient producers, the threat of overproduction could be mitigated.</li>
<li><strong>Consequences:</strong> This approach transformed education from a means of fostering independence and innovation into a tool for controlling the workforce and maintaining economic stability for the benefit of those in power.</li>
</ul>
</section>
<section id="the-alternative-a-return-to-open-source-learning" class="level4">
<h4 class="anchored" data-anchor-id="the-alternative-a-return-to-open-source-learning">The Alternative: A Return to Open-Source Learning</h4>
<ul>
<li><strong>The American Experiment:</strong> For the first two centuries of its existence, the United States thrived on a system of open-source learning, where individuals were free to pursue knowledge and skills through apprenticeship, self-study, and community engagement.</li>
<li><strong>Examples:</strong> Figures like Benjamin Franklin, Thomas Jefferson, and David Farragut exemplified the success of this approach, demonstrating that traditional education was not a prerequisite for achieving greatness.</li>
<li><strong>The Value of Self-Reliance:</strong> This system fostered independence, ingenuity, and a spirit of innovation, propelling America to the forefront of global progress.</li>
<li><strong>The Need for a Paradigm Shift:</strong> Gatto argues for a return to the principles of open-source learning, recognizing that the current system of compulsory schooling stifles creativity, limits human potential, and perpetuates social inequalities.</li>
</ul>
</section>
<section id="conclusion-reclaiming-education" class="level4">
<h4 class="anchored" data-anchor-id="conclusion-reclaiming-education">Conclusion: Reclaiming Education</h4>
<ul>
<li><strong>The Illusion of Progress:</strong> Gatto challenges the narrative that the current education system is the result of natural progress, arguing that it was deliberately designed to serve the interests of a select few.</li>
<li><strong>The Urgency of Reform:</strong> The consequences of this system—declining literacy rates, rising social inequality, and a culture of conformity—demand urgent attention and a radical rethinking of education’s purpose.</li>
<li><strong>A Call to Action:</strong> The book serves as a wake-up call to reclaim the transformative power of education, urging readers to question assumptions, challenge the status quo, and create alternative systems that empower individuals and foster a more just and equitable society.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-2-walkabout-london" class="level2">
<h2 class="anchored" data-anchor-id="chapter-2-walkabout-london">Chapter 2: Walkabout, London</h2>
<section id="the-power-of-open-source-learning" class="level3">
<h3 class="anchored" data-anchor-id="the-power-of-open-source-learning">The Power of Open-Source Learning</h3>
<ul>
<li><strong>Open-source learning</strong> is argued to be of higher quality than rule-driven, standardized schooling.</li>
<li>This type of learning prioritizes individual exploration and real-world experience.</li>
</ul>
<section id="personal-anecdote-uncle-buds-miracle" class="level4">
<h4 class="anchored" data-anchor-id="personal-anecdote-uncle-buds-miracle">Personal Anecdote: Uncle Bud’s Miracle</h4>
<ul>
<li>Gatto’s uncle, Bud Zimmer, lacked formal education but became a successful steel plant manager, overseeing Harvard graduates.</li>
<li>Bud’s experience highlighted the limitations of equating schooling with education.</li>
</ul>
</section>
<section id="examples-of-successful-individuals-who-didnt-follow-traditional-paths" class="level4">
<h4 class="anchored" data-anchor-id="examples-of-successful-individuals-who-didnt-follow-traditional-paths">Examples of Successful Individuals Who Didn’t Follow Traditional Paths</h4>
<ul>
<li><strong>Jonathan Goodwin (Fast Company, November 2007 cover story):</strong>
<ul>
<li><strong>Background:</strong> Junior high school dropout from a poor Kansas farm family.</li>
<li><strong>Open-Source Path:</strong> Learned auto mechanics through odd jobs at a local garage.</li>
<li><strong>Success:</strong> Founded a successful business converting cars to achieve high gas mileage and low emissions, earning over a million dollars per year.</li>
</ul></li>
<li><strong>David Farragut:</strong> Became a US Navy admiral at age twelve, commanding a captured British ship.</li>
<li><strong>George Washington:</strong> Dropped out of school at age twelve.</li>
<li><strong>Thomas Jefferson:</strong> Managed a plantation and 250 employees at age twelve after his parents’ deaths.</li>
<li><strong>Danica Patrick:</strong>
<ul>
<li><strong>Background:</strong> Dropped out of high school at age sixteen.</li>
<li><strong>Open-Source Path:</strong> Moved to London independently to pursue a career in auto racing.</li>
<li><strong>Success:</strong> Became the first woman to win a major IndyCar race.</li>
</ul></li>
<li><strong>Nick Schulman:</strong>
<ul>
<li><strong>Background:</strong> Dropped out of school in eighth grade.</li>
<li><strong>Open-Source Path:</strong> Became skilled at poker.</li>
<li><strong>Success:</strong> Won $2 million on the World Poker Tour by age twenty-one.</li>
</ul></li>
<li><strong>Diablo Cody:</strong>
<ul>
<li><strong>Background:</strong> Worked as a stripper.</li>
<li><strong>Open-Source Path:</strong> Used her experiences to write a screenplay.</li>
<li><strong>Success:</strong> Won an Oscar for Best Original Screenplay for the movie <em>Juno</em>.</li>
</ul></li>
</ul>
</section>
</section>
<section id="open-source-learning-a-definition-and-key-principles" class="level3">
<h3 class="anchored" data-anchor-id="open-source-learning-a-definition-and-key-principles">Open-Source Learning: A Definition and Key Principles</h3>
<ul>
<li><strong>Definition:</strong> Open-source learning allows for diverse starting points on the path to self-mastery, where sequences are personalized, and everyone is a potential teacher.</li>
<li><strong>Key Principles:</strong>
<ul>
<li>Teaching is a function, not a profession. Anyone can teach.</li>
<li>Students determine their teachers.</li>
<li>No licensing is required to teach.</li>
<li>Students are active participants, not passive recipients.</li>
<li>Failure is not a setback, but an opportunity for growth.</li>
</ul></li>
</ul>
<section id="shen-wenrong-and-the-dismantling-of-the-phoenix-steel-plant" class="level4">
<h4 class="anchored" data-anchor-id="shen-wenrong-and-the-dismantling-of-the-phoenix-steel-plant">Shen Wenrong and the Dismantling of the Phoenix Steel Plant</h4>
<ul>
<li>A thousand Chinese peasants, led by Shen Wenrong, dismantled and moved a massive German steel plant in one year, three times faster than German specialists estimated.</li>
<li>Shen’s team lacked formal education, computers, and traditional offices.</li>
<li><strong>Key Takeaway:</strong> Challenges perceived as requiring specialists can often be solved by ordinary people with practical experience and ingenuity.</li>
</ul>
</section>
</section>
<section id="richard-bransons-walkabout-and-the-importance-of-early-independence" class="level3">
<h3 class="anchored" data-anchor-id="richard-bransons-walkabout-and-the-importance-of-early-independence">Richard Branson’s Walkabout and the Importance of Early Independence</h3>
<ul>
<li><strong>Richard Branson:</strong>
<ul>
<li><strong>Background:</strong> High school dropout and self-made billionaire entrepreneur (Virgin Airlines, Virgin Records).</li>
<li><strong>Early Open-Source Learning:</strong> At age four, his mother dropped him off in an unfamiliar area and challenged him to find his way home, fostering self-reliance.</li>
</ul></li>
<li><strong>Early Independence:</strong>
<ul>
<li>By age twelve, Branson was making 100-mile bike rides alone.</li>
<li>Launched his first successful business at age nineteen.</li>
</ul></li>
<li><strong>Glenn Doman and Early Childhood Learning:</strong>
<ul>
<li><strong>Glenn Doman:</strong> Author of <em>Teach Your Baby to Read</em>.</li>
<li><strong>Core Belief:</strong> Babies are capable of learning complex information (reading, math) much earlier than traditionally believed.</li>
<li><strong>Obstacles:</strong> Delaying learning increases its difficulty.</li>
<li><strong>The Institutes for the Achievement of Human Potential:</strong> Doman’s school with no entrance requirements where children learned at their own pace, demonstrating the potential of individualized learning.</li>
<li><strong>Book:</strong> <a href="https://www.gentlerevolution.com/products/how-to-teach-your-baby-to-read-40th-anniversary">How To Teach Your Baby To Read</a></li>
</ul></li>
</ul>
</section>
<section id="the-human-genome-project-and-unconventional-success" class="level3">
<h3 class="anchored" data-anchor-id="the-human-genome-project-and-unconventional-success">The Human Genome Project and Unconventional Success</h3>
<ul>
<li>The Human Genome Project, a massive scientific undertaking, was led by:
<ul>
<li><strong>Craig Venter:</strong> A former poor student and surfer.</li>
<li><strong>Francis Collins:</strong> A homeschooler who followed his interests.</li>
</ul></li>
<li><strong>Key Takeaway:</strong> Traditional educational credentials are not always reliable predictors of intellectual capacity or scientific contribution.</li>
</ul>
</section>
<section id="marilee-jones-and-the-limitations-of-degrees-as-proxies-for-education" class="level3">
<h3 class="anchored" data-anchor-id="marilee-jones-and-the-limitations-of-degrees-as-proxies-for-education">Marilee Jones and the Limitations of Degrees as Proxies for Education</h3>
<ul>
<li><strong>Marilee Jones:</strong>
<ul>
<li><strong>Background:</strong> Successful MIT admissions director for 28 years.</li>
<li><strong>Downfall:</strong> Fired for falsifying her credentials, despite her exceptional performance.</li>
<li><strong>Key Takeaway:</strong> Degrees should not be automatic substitutes for proven ability and experience.</li>
</ul></li>
</ul>
<section id="ingvar-kamprad-and-the-founding-of-ikea" class="level4">
<h4 class="anchored" data-anchor-id="ingvar-kamprad-and-the-founding-of-ikea">Ingvar Kamprad and the Founding of IKEA</h4>
<ul>
<li><strong>Ingvar Kamprad:</strong>
<ul>
<li><strong>Background:</strong> Diagnosed with dyslexia, he began as a fish peddler.</li>
<li><strong>Open-Source Learning:</strong> Developed practical business skills through real-world experience.</li>
<li><strong>Success:</strong> Founded IKEA, a global furniture empire, proving that learning disabilities are not barriers to entrepreneurial success.</li>
</ul></li>
</ul>
</section>
<section id="charles-webb-the-graduate-and-rejecting-materialism" class="level4">
<h4 class="anchored" data-anchor-id="charles-webb-the-graduate-and-rejecting-materialism">Charles Webb, <em>The Graduate</em>, and Rejecting Materialism</h4>
<ul>
<li><strong>Charles Webb:</strong>
<ul>
<li><strong>Background:</strong> Author of the novel <em>The Graduate</em>, which critiques consumerism.</li>
<li><strong>Unconventional Path:</strong> After achieving wealth and fame, Webb gave away his fortune and lived a simple life, highlighting the limitations of material success.</li>
</ul></li>
</ul>
</section>
</section>
<section id="the-plight-of-dropouts-a-misunderstood-resource" class="level3">
<h3 class="anchored" data-anchor-id="the-plight-of-dropouts-a-misunderstood-resource">The Plight of Dropouts: A Misunderstood Resource</h3>
<ul>
<li><strong>Societal Perspective:</strong> 7,000 students drop out of school daily in the US, often facing stigma and limited opportunities.</li>
<li><strong>Alternative View:</strong> Dropouts could be seen as individuals who don’t conform to standardized systems, potentially possessing unique strengths and entrepreneurial potential.</li>
</ul>
<section id="examples-of-successful-individuals-who-didnt-graduate-college" class="level4">
<h4 class="anchored" data-anchor-id="examples-of-successful-individuals-who-didnt-graduate-college">Examples of Successful Individuals Who Didn’t Graduate College</h4>
<ul>
<li><strong>Abraham Lincoln:</strong> Had less than a year of formal schooling.</li>
<li><strong>Andrew Carnegie and John D. Rockefeller:</strong> Both were elementary school dropouts who became titans of industry.</li>
<li><strong>Lula da Silva:</strong> Rose from poverty to become President of Brazil without a formal degree.</li>
<li><strong>Adolf Hitler:</strong> Exploited the education system of the “best-schooled nation in history” to gain power, demonstrating that even highly educated societies are vulnerable to manipulation.</li>
<li><strong>Thomas Edison:</strong>
<ul>
<li><strong>Background:</strong> Dropped out of elementary school.</li>
<li><strong>Open-Source Learning:</strong> Pursued his interests and learned through experimentation.</li>
<li><strong>Success:</strong> Became a prolific inventor (electric light, phonograph) and founded General Electric, holding 1,093 patents.</li>
</ul></li>
<li><strong>George Bernard Shaw:</strong> Dropped out of school at fourteen and became a renowned playwright.</li>
</ul>
</section>
<section id="challenging-assumptions-about-education-and-success" class="level4">
<h4 class="anchored" data-anchor-id="challenging-assumptions-about-education-and-success">Challenging Assumptions About Education and Success</h4>
<ul>
<li>The achievements of individuals with unconventional backgrounds challenge the notion that formal schooling is the only path to success.</li>
<li>Gatto questions why these alternative narratives are not highlighted more prominently in education.</li>
</ul>
</section>
<section id="the-international-happiness-survey" class="level4">
<h4 class="anchored" data-anchor-id="the-international-happiness-survey">The International Happiness Survey</h4>
<ul>
<li>The United States consistently ranks as mediocre in happiness, suggesting that material wealth and standardized education do not necessarily equate to well-being.</li>
</ul>
</section>
</section>
<section id="the-artificial-extension-of-childhood" class="level3">
<h3 class="anchored" data-anchor-id="the-artificial-extension-of-childhood">The Artificial Extension of Childhood</h3>
<ul>
<li><strong>Adolescence:</strong> A historically recent concept that prolongs childhood.</li>
<li><strong>Pre-Industrial America:</strong> Children contributed to society at a young age, learning through real-world experiences and apprenticeships.</li>
<li><strong>Post-Civil War Shift:</strong> Compulsory schooling laws and the rise of factories created a system where children were segregated from adult life and prepared for industrial work.</li>
</ul>
<section id="the-impact-of-industrialization-on-education-and-society" class="level4">
<h4 class="anchored" data-anchor-id="the-impact-of-industrialization-on-education-and-society">The Impact of Industrialization on Education and Society</h4>
<ul>
<li>The rise of factories and industrialization led to a need for a compliant workforce, which influenced the development of compulsory schooling.</li>
<li>Forced schooling, modeled after German systems, aimed to create a more manageable and less independent workforce.</li>
</ul>
</section>
<section id="andrew-carnegie-and-the-trade-off-of-merit-for-social-stability" class="level4">
<h4 class="anchored" data-anchor-id="andrew-carnegie-and-the-trade-off-of-merit-for-social-stability">Andrew Carnegie and the Trade-Off of Merit for Social Stability</h4>
<ul>
<li><strong>Andrew Carnegie:</strong> Steel magnate and philanthropist who recognized the drawbacks of standardized education.</li>
<li><strong>Carnegie’s Perspective:</strong> While acknowledging that some talented individuals would be overlooked, he believed that mass education was necessary for social control and economic growth.</li>
</ul>
</section>
<section id="william-torrey-harris-and-the-goal-of-self-alienation" class="level4">
<h4 class="anchored" data-anchor-id="william-torrey-harris-and-the-goal-of-self-alienation">William Torrey Harris and the Goal of Self-Alienation</h4>
<ul>
<li><strong>William Torrey Harris:</strong> US Commissioner of Education (1889-1906), advocated for schooling that promoted self-alienation to benefit the state and corporations.</li>
<li><strong>Harris’s View:</strong> Schools should prioritize obedience and conformity over individual expression.</li>
</ul>
</section>
</section>
<section id="the-dangers-of-centralized-control-and-the-need-for-dialectical-thinking" class="level3">
<h3 class="anchored" data-anchor-id="the-dangers-of-centralized-control-and-the-need-for-dialectical-thinking">The Dangers of Centralized Control and the Need for Dialectical Thinking</h3>
<ul>
<li><strong>Centralized Economies:</strong> Tend towards oligarchies, stifle innovation, and prioritize stability over creative destruction.</li>
<li><strong>Dialectical Thinking:</strong> The ability to question assumptions and consider multiple perspectives, which is essential for a healthy society but undermined by standardized education.</li>
<li><strong>The Importance of Personal Production:</strong> Early America valued self-sufficiency, but the shift towards consumerism has made people more dependent on corporations and less resilient.</li>
</ul>
<section id="the-role-of-schooling-in-promoting-consumption" class="level4">
<h4 class="anchored" data-anchor-id="the-role-of-schooling-in-promoting-consumption">The Role of Schooling in Promoting Consumption</h4>
<ul>
<li>Schools often prioritize obedience, conformity, and test-taking over critical thinking and self-reliance.</li>
<li>This system prepares students to be passive consumers rather than active producers and critical thinkers.</li>
</ul>
</section>
<section id="the-decline-of-american-innovation" class="level4">
<h4 class="anchored" data-anchor-id="the-decline-of-american-innovation">The Decline of American Innovation</h4>
<ul>
<li>The rise of standardized education coincides with a decline in patent applications by Americans.</li>
<li>This suggests that suppressing creativity and independent thinking can have negative consequences for innovation.</li>
</ul>
</section>
<section id="g.-stanley-hall-and-the-invention-of-adolescence" class="level4">
<h4 class="anchored" data-anchor-id="g.-stanley-hall-and-the-invention-of-adolescence">G. Stanley Hall and the Invention of Adolescence</h4>
<ul>
<li><strong>G. Stanley Hall:</strong> Psychologist who popularized the concept of adolescence as a period of storm and stress, justifying the extension of compulsory schooling into the teenage years.</li>
<li><strong>Hall’s Influence:</strong> His ideas contributed to the medicalization of youth and the view that teenagers require extensive supervision and control.</li>
</ul>
</section>
<section id="the-erosion-of-american-individualism" class="level4">
<h4 class="anchored" data-anchor-id="the-erosion-of-american-individualism">The Erosion of American Individualism</h4>
<ul>
<li>Forced schooling has contributed to the decline of American individualism and self-reliance, replacing it with conformity and dependence on institutions.</li>
</ul>
</section>
<section id="the-consequences-of-suppressing-imagination" class="level4">
<h4 class="anchored" data-anchor-id="the-consequences-of-suppressing-imagination">The Consequences of Suppressing Imagination</h4>
<ul>
<li>The suppression of imagination through standardized education creates a more manageable but less innovative and adaptable society.</li>
</ul>
</section>
</section>
<section id="the-honor-roll-of-school-failures" class="level3">
<h3 class="anchored" data-anchor-id="the-honor-roll-of-school-failures">The Honor Roll of School Failures</h3>
<ul>
<li><strong>Successful Individuals Who Did Not Excel in Traditional Schooling:</strong>
<ul>
<li>Craig Venter</li>
<li>Franklin D. Roosevelt</li>
<li>George W. Bush</li>
<li>John Kerry</li>
<li>Al Gore</li>
<li>Dick Cheney</li>
<li>Paul Wellstone</li>
<li>Bill Gates (Microsoft)</li>
<li>Paul Allen (Microsoft)</li>
<li>Steve Jobs (Apple)</li>
<li>Steve Wozniak (Apple)</li>
<li>Michael Dell (Dell Computers)</li>
<li>Larry Ellison (Oracle)</li>
<li>Ted Turner (CNN)</li>
<li>William Faulkner</li>
<li>Warren Avis (Avis Rent a Car)</li>
<li>Edward Hamilton (book retailer)</li>
<li>Paul Orfalea (Kinko’s)</li>
<li>Sean Fanning (Napster)</li>
</ul></li>
<li><strong>Key Takeaway:</strong> Traditional academic success is a poor predictor of entrepreneurial spirit, innovation, or real-world achievement.</li>
</ul>
<section id="lou-wasserman-from-movie-usher-to-hollywood-mogul" class="level4">
<h4 class="anchored" data-anchor-id="lou-wasserman-from-movie-usher-to-hollywood-mogul">Lou Wasserman: From Movie Usher to Hollywood Mogul</h4>
<ul>
<li><strong>Lou Wasserman:</strong>
<ul>
<li><strong>Background:</strong> Movie usher who dropped out of school at thirteen.</li>
<li><strong>Open-Source Learning:</strong> Developed entrepreneurial skills through his work experience.</li>
<li><strong>Success:</strong> Founded MCA, a powerful Hollywood talent agency, demonstrating the value of street smarts and practical experience.</li>
</ul></li>
</ul>
</section>
<section id="warren-buffett-an-early-entrepreneurial-prodigy" class="level4">
<h4 class="anchored" data-anchor-id="warren-buffett-an-early-entrepreneurial-prodigy">Warren Buffett: An Early Entrepreneurial Prodigy</h4>
<ul>
<li><strong>Warren Buffett:</strong>
<ul>
<li><strong>Background:</strong> Began his first business at age six.</li>
<li><strong>Early Open-Source Learning:</strong> Developed business acumen through various ventures, including selling Coca-Cola, golf balls, and renting pinball machines.</li>
<li><strong>Success:</strong> Became one of the world’s wealthiest men through his investment firm, Berkshire Hathaway.</li>
</ul></li>
</ul>
</section>
</section>
<section id="why-doesnt-school-teach-real-world-skills" class="level3">
<h3 class="anchored" data-anchor-id="why-doesnt-school-teach-real-world-skills">Why Doesn’t School Teach Real-World Skills?</h3>
<ul>
<li>Schools often prioritize abstract knowledge over practical skills and entrepreneurial thinking.</li>
<li>This disconnect leaves students ill-prepared for the complexities of the modern economy.</li>
</ul>
<section id="the-potential-of-65-million-children-as-producers" class="level4">
<h4 class="anchored" data-anchor-id="the-potential-of-65-million-children-as-producers">The Potential of 65 Million Children as Producers</h4>
<ul>
<li>Imagine the possibilities if the 65 million children currently in the US school system were encouraged to develop their entrepreneurial potential and become producers rather than just consumers.</li>
</ul>
</section>
</section>
<section id="the-power-of-mixing-ages-and-experiences" class="level3">
<h3 class="anchored" data-anchor-id="the-power-of-mixing-ages-and-experiences">The Power of Mixing Ages and Experiences</h3>
<ul>
<li><strong>Pre-Industrial Society:</strong> Children learned from adults in mixed-age settings, gaining valuable experience and mentorship.</li>
<li><strong>Modern Society:</strong> Age segregation limits opportunities for intergenerational learning and the transmission of practical skills.</li>
</ul>
</section>
<section id="the-decline-of-american-manufacturing-and-the-rise-of-financial-bubbles" class="level3">
<h3 class="anchored" data-anchor-id="the-decline-of-american-manufacturing-and-the-rise-of-financial-bubbles">The Decline of American Manufacturing and the Rise of Financial Bubbles</h3>
<ul>
<li>The US has shifted from a manufacturing-based economy to one increasingly reliant on financial speculation and debt.</li>
<li>This shift, facilitated by a decline in practical skills and an increase in risk-taking, has created instability and economic inequality.</li>
</ul>
<section id="the-school-bubble-a-drain-on-resources-and-innovation" class="level4">
<h4 class="anchored" data-anchor-id="the-school-bubble-a-drain-on-resources-and-innovation">The School Bubble: A Drain on Resources and Innovation</h4>
<ul>
<li>The education system has become a massive industry that consumes vast resources without necessarily producing commensurate returns in terms of innovation or economic growth.</li>
<li>This “school bubble” diverts resources from more productive sectors of the economy.</li>
</ul>
</section>
</section>
<section id="st.-paul-and-the-rule-book-dragon" class="level3">
<h3 class="anchored" data-anchor-id="st.-paul-and-the-rule-book-dragon">St.&nbsp;Paul and the Rule Book Dragon</h3>
<ul>
<li><strong>St.&nbsp;Paul’s Message:</strong> In his letters to early Christian communities, Paul emphasized the importance of adaptability and love over rigid adherence to rules.</li>
<li><strong>The Dangers of Excessive Regulation:</strong> Over-regulation stifles creativity, innovation, and personal responsibility.</li>
</ul>
<section id="the-return-of-the-rule-choked-society" class="level4">
<h4 class="anchored" data-anchor-id="the-return-of-the-rule-choked-society">The Return of the Rule-Choked Society</h4>
<ul>
<li>Modern society has become increasingly rule-bound, with surveillance technology and bureaucratic systems limiting individual freedom and autonomy.</li>
<li>This trend mirrors the rule-heavy environment of ancient Israel, which St.&nbsp;Paul challenged.</li>
</ul>
</section>
<section id="the-insurgency-against-the-system" class="level4">
<h4 class="anchored" data-anchor-id="the-insurgency-against-the-system">The Insurgency Against the System</h4>
<ul>
<li><strong>Signs of Resistance:</strong> The growth of homeschooling, the internet’s democratizing influence, and the rise of alternative economies all point to a growing dissatisfaction with the status quo.</li>
<li><strong>Identity Theft and Copyright Infringement:</strong> These forms of crime can be seen as acts of rebellion against systems that restrict individual autonomy and access to information.</li>
</ul>
</section>
<section id="the-failure-of-the-military-industrial-complex" class="level4">
<h4 class="anchored" data-anchor-id="the-failure-of-the-military-industrial-complex">The Failure of the Military-Industrial Complex</h4>
<ul>
<li><strong>The Limits of Military Technology:</strong> The US military’s technological superiority has proven ineffective against unconventional tactics and determined adversaries.</li>
<li><strong>The Importance of Clear Objectives:</strong> The lack of clear objectives in recent US military interventions has undermined morale and made it difficult to achieve lasting victory.</li>
</ul>
</section>
<section id="the-time-of-the-sweat-bath" class="level4">
<h4 class="anchored" data-anchor-id="the-time-of-the-sweat-bath">The Time of the Sweat Bath</h4>
<ul>
<li>We are living in a time of unprecedented challenges, characterized by environmental degradation, economic instability, and social unrest.</li>
<li><strong>The Need for New Solutions:</strong> Traditional institutions and approaches are failing to address these challenges, necessitating a radical shift in thinking and action.</li>
</ul>
</section>
<section id="choosing-allies-for-the-future" class="level4">
<h4 class="anchored" data-anchor-id="choosing-allies-for-the-future">Choosing Allies for the Future</h4>
<ul>
<li>In times of crisis, adaptability, creativity, and independent thinking are more valuable than conformity and obedience.</li>
<li>We need to support individuals who challenge the status quo and offer new solutions.</li>
</ul>
</section>
</section>
<section id="the-importance-of-self-awareness-and-rejecting-the-human-resource-mentality" class="level3">
<h3 class="anchored" data-anchor-id="the-importance-of-self-awareness-and-rejecting-the-human-resource-mentality">The Importance of Self-Awareness and Rejecting the “Human Resource” Mentality</h3>
<ul>
<li><strong>Know Thyself:</strong> Understanding one’s strengths, values, and purpose is essential for a fulfilling life.</li>
<li><strong>Rejecting the “Human Resource” Label:</strong> Embracing self-reliance and pursuing meaningful work rather than simply being a cog in a machine.</li>
</ul>
<section id="the-power-of-open-source-learning-in-a-changing-world" class="level4">
<h4 class="anchored" data-anchor-id="the-power-of-open-source-learning-in-a-changing-world">The Power of Open-Source Learning in a Changing World</h4>
<ul>
<li>Open-source learning, with its emphasis on adaptability, experimentation, and personal growth, is essential for navigating the complexities of the 21st century.</li>
<li>It’s time to move beyond the limitations of standardized education and embrace a more personalized and empowering approach to learning.</li>
</ul>
</section>
</section>
</section>
<section id="chapter-3-fat-stanley-and-the-lancaster-amish" class="level2">
<h2 class="anchored" data-anchor-id="chapter-3-fat-stanley-and-the-lancaster-amish">Chapter 3: Fat Stanley and the Lancaster Amish</h2>
<p>This analysis explores the limitations of traditional schooling and highlights the value of self-directed education, drawing parallels between the experiences of “Fat Stanley,” a truant student, and the educational practices of the Amish community.</p>
<section id="the-illusion-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-illusion-of-schooling">The Illusion of Schooling</h3>
<ul>
<li><strong>Schooling</strong>, often mistaken for education, focuses on:
<ul>
<li>Habit formation</li>
<li>Attitude training</li>
<li>External control rather than internal motivation</li>
<li>This approach can be unpleasant and stifling for individuals.</li>
</ul></li>
<li><strong>Education</strong>, in contrast, emphasizes:
<ul>
<li>Self-mastery</li>
<li>Self-enlargement</li>
<li>Self-transcendence</li>
<li>Exploration of individual potential</li>
</ul></li>
<li>While schooling can complement education, Gatto argues that education is paramount for a fulfilling life.</li>
</ul>
</section>
<section id="success-without-schooling-examples" class="level3">
<h3 class="anchored" data-anchor-id="success-without-schooling-examples">Success Without Schooling: Examples</h3>
<ul>
<li><strong>Mary Shelley:</strong>
<ul>
<li>Wrote <em>Frankenstein</em> at 18, now considered a literary masterpiece.</li>
</ul></li>
<li><strong>William Shakespeare:</strong>
<ul>
<li>Had limited formal education but remains a global icon of literature.</li>
</ul></li>
<li><strong>Inventive individuals across fields</strong> often achieve success with minimal formal schooling, emphasizing the importance of self-directed learning.</li>
</ul>
</section>
<section id="the-essence-of-true-education" class="level3">
<h3 class="anchored" data-anchor-id="the-essence-of-true-education">The Essence of True Education</h3>
<ul>
<li><strong>Self-initiated learning</strong> is crucial for genuine education.</li>
<li>Key elements of self-directed education include:
<ul>
<li><strong>Broad experience:</strong> Gaining knowledge and skills from diverse sources beyond the classroom.</li>
<li><strong>Introspection:</strong> Reflecting on experiences and insights to deepen understanding.</li>
<li><strong>Focus and Concentration:</strong> Developing the ability to sustain attention on one’s goals despite distractions.</li>
<li><strong>Curiosity and Patience:</strong> Cultivating a thirst for knowledge and a willingness to persevere in the face of challenges.</li>
<li><strong>Trial and Error:</strong> Embracing experimentation, learning from mistakes, and adapting strategies accordingly.</li>
<li><strong>Feedback Integration:</strong> Actively seeking and utilizing feedback from the environment to refine understanding and approaches.</li>
</ul></li>
</ul>
</section>
<section id="a-case-for-criticism" class="level3">
<h3 class="anchored" data-anchor-id="a-case-for-criticism">A Case for Criticism</h3>
<ul>
<li>Gatto highlights the importance of embracing criticism for personal growth.</li>
<li>An anecdote about a family member who “doesn’t take criticism well” exemplifies the detrimental effects of such an attitude.</li>
</ul>
</section>
<section id="fat-stanley-a-lesson-in-unconventional-learning" class="level3">
<h3 class="anchored" data-anchor-id="fat-stanley-a-lesson-in-unconventional-learning">Fat Stanley: A Lesson in Unconventional Learning</h3>
<ul>
<li><strong>Fat Stanley</strong>, a 13-year-old student, rarely attended school.
<ul>
<li>He excelled in using his fists to deter bullies.</li>
</ul></li>
<li>Gatto’s inquiry into Stanley’s absences revealed a unique approach to learning:
<ul>
<li>Stanley had five aunts and uncles who owned businesses.</li>
<li>He worked for each relative, gaining practical experience and business acumen.</li>
<li>His goal was to become self-employed, like his relatives.</li>
<li>Stanley valued this hands-on education more than formal schooling.</li>
</ul></li>
<li>Stanley’s perspective:
<ul>
<li><blockquote class="blockquote">
<p>“This way I get a chance to see how the different businesses work. You tell me what books I have to read and I’ll read them, but I don’t have time to waste in school unless I want to end up like you, working for somebody else.”</p>
</blockquote></li>
</ul></li>
<li>Impressed by Stanley’s initiative and his mother’s support, Gatto chose to support his alternative education.</li>
</ul>
</section>
<section id="the-flaws-of-mass-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-flaws-of-mass-schooling">The Flaws of Mass Schooling</h3>
<ul>
<li>Traditional schooling often fails to cater to the diverse learning styles and needs of individual children.</li>
<li>Gatto argues that schooling primarily conditions students for conformity and obedience, not self-direction.</li>
<li><strong>Negative consequences of this system include:</strong>
<ul>
<li><strong>Waiting and Submission:</strong> Students are taught to prioritize external validation and passively follow instructions.</li>
<li><strong>Artificial Ranking:</strong> Schooling instills a sense of competition and creates a hierarchy of winners and losers, impacting self-esteem and future opportunities.</li>
<li><strong>Irrelevant Curriculum:</strong> Classroom work often feels disconnected from students’ real-life experiences, leading to disengagement and apathy.</li>
<li><strong>Suppression of Self-Discovery:</strong> The structured environment of traditional schooling can hinder the natural curiosity and exploration essential for true learning.</li>
</ul></li>
</ul>
</section>
<section id="the-amish-model-community-and-self-reliance" class="level3">
<h3 class="anchored" data-anchor-id="the-amish-model-community-and-self-reliance">The Amish Model: Community and Self-Reliance</h3>
<ul>
<li>Gatto contrasts the schooling model with the practices of the <strong>Old Order Amish</strong>, a community known for its:
<ul>
<li><strong>Small business and farm-based economy</strong></li>
<li><strong>Emphasis on practical skills, self-sufficiency, and community well-being</strong></li>
</ul></li>
<li>The Amish prioritize the development of:
<ul>
<li>Competence in essential life skills</li>
<li>Self-reliance</li>
<li>Dependability</li>
<li>Honesty</li>
<li>Neighborliness</li>
<li>Compassion</li>
<li>Piety</li>
<li>Commitment to the common good</li>
</ul></li>
<li>The Amish success challenges conventional assumptions about business and success, demonstrating that alternative paths to prosperity exist.</li>
</ul>
</section>
<section id="consumption-vs.-community-a-tale-of-two-systems" class="level3">
<h3 class="anchored" data-anchor-id="consumption-vs.-community-a-tale-of-two-systems">Consumption vs.&nbsp;Community: A Tale of Two Systems</h3>
<ul>
<li>Gatto argues that the dominant economic system encourages:
<ul>
<li>A relentless pursuit of novelty and fashion</li>
<li>Unnecessary consumption driven by manufactured desires and the fear of social shame</li>
<li>This cycle perpetuates a culture of “out with the old, in with the new,” contrasting sharply with the Amish values of sustainability and community.</li>
</ul></li>
</ul>
</section>
<section id="the-bell-curve-and-its-discontents" class="level3">
<h3 class="anchored" data-anchor-id="the-bell-curve-and-its-discontents">The Bell Curve and Its Discontents</h3>
<ul>
<li>School bells are used as a metaphor for the constant interruptions and distractions that prevent deep focus and meaningful learning.</li>
<li>Gatto argues that the emphasis on standardized testing and grading fosters a culture of shame and humiliation, hindering genuine intellectual growth.</li>
<li>This system, according to Gatto, produces:
<ul>
<li>A workforce conditioned for obedience and conformity.</li>
<li>A populace susceptible to manipulation through consumerism and superficial desires.</li>
</ul></li>
</ul>
</section>
<section id="the-amish-resistance-protecting-community-and-values" class="level3">
<h3 class="anchored" data-anchor-id="the-amish-resistance-protecting-community-and-values">The Amish Resistance: Protecting Community and Values</h3>
<ul>
<li>The <strong>Amish</strong> have actively resisted attempts to impose compulsory schooling that conflicts with their values.</li>
<li>In the landmark case <strong>Yoder v. Wisconsin (1976)</strong>, the Amish successfully argued that:
<ul>
<li>Government-mandated schooling undermined their community’s social fabric and family life.</li>
<li>The separation of knowledge from practical experience and the competitive nature of schooling were detrimental to their way of life.</li>
</ul></li>
<li>As part of their compromise with the state of Wisconsin, the Amish demanded:
<ul>
<li>Small, localized schools within walking distance of students’ homes.</li>
<li>Continuity in teachers to foster strong relationships and understanding.</li>
<li>A shorter school year focused on essential knowledge and skills.</li>
<li>Parental control over educational decisions.</li>
<li>Teachers who respected and understood Amish values and rural life.</li>
<li>An educational approach that balanced academic knowledge with practical wisdom.</li>
<li>Integration of apprenticeships and real-world experiences into the curriculum.</li>
</ul></li>
</ul>
</section>
<section id="lessons-from-stanley-and-the-amish" class="level3">
<h3 class="anchored" data-anchor-id="lessons-from-stanley-and-the-amish">Lessons from Stanley and the Amish</h3>
<ul>
<li>Both Stanley’s story and the Amish way of life challenge the assumption that standardized schooling is the only path to success and fulfillment.</li>
<li>Key takeaways include:
<ul>
<li><strong>Embracing Individuality:</strong> Recognize and nurture the unique talents and learning styles of each child.</li>
<li><strong>Rethinking “Success”:</strong> Challenge the societal definition of success solely based on material wealth and status.</li>
<li><strong>Prioritizing Community:</strong> Foster a sense of belonging, cooperation, and mutual support within communities.</li>
<li><strong>Valuing Practical Skills:</strong> Encourage the acquisition of real-world skills and knowledge applicable to daily life.</li>
<li><strong>Promoting Self-Direction:</strong> Empower individuals to take ownership of their education and pursue their passions.</li>
<li><strong>Honoring Individual Freedom:</strong> Respect the right of individuals and communities to choose alternative educational paths aligned with their values.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-a-call-for-educational-transformation" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-a-call-for-educational-transformation">Conclusion: A Call for Educational Transformation</h3>
<ul>
<li>Gatto urges a reevaluation of the current schooling system, advocating for a shift towards:
<ul>
<li>Personalized learning experiences</li>
<li>Community-based education</li>
<li>A focus on practical skills and self-reliance</li>
<li>The fostering of critical thinking, creativity, and a lifelong love of learning</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-4-david-sarnoffs-classroom" class="level2">
<h2 class="anchored" data-anchor-id="chapter-4-david-sarnoffs-classroom">Chapter 4: David Sarnoff’s Classroom</h2>
<section id="introduction-and-context" class="level3">
<h3 class="anchored" data-anchor-id="introduction-and-context">Introduction and Context</h3>
<ul>
<li>The letter is written by Gatto in School District 3, Manhattan, to their assistant principal, Murray.</li>
<li>Gatto has 28 years of experience in the district.</li>
<li>The letter expresses deep dissatisfaction with the state of education in their district, arguing that it fails to equip students with essential skills and competencies.</li>
<li>Gatto draws a stark contrast between the inadequate education system and the self-driven success story of David Sarnoff, a prominent figure in the history of technology.</li>
<li>The letter serves as a scathing critique of the bureaucratic structures, flawed policies, and prevailing attitudes that Gatto believes are actively harming students’ futures.</li>
</ul>
</section>
<section id="a-critique-of-school-district-3s-educational-approach" class="level3">
<h3 class="anchored" data-anchor-id="a-critique-of-school-district-3s-educational-approach">A Critique of School District 3’s Educational Approach</h3>
<section id="the-failure-to-teach-essential-skills" class="level4">
<h4 class="anchored" data-anchor-id="the-failure-to-teach-essential-skills">The Failure to Teach Essential Skills</h4>
<ul>
<li>Gatto argues that School District 3 fails to teach students the essential skills needed to thrive in the evolving global economy.
<ul>
<li><strong>Evidence:</strong> A brochure from Harvard University outlining nine essential skills for success in the new international economy is cited as a benchmark.
<ul>
<li><h4 id="nine-essential-skills" class="anchored">Nine Essential Skills:</h4>
<ul>
<li>Ability to ask hard questions of data from various sources.</li>
<li>Ability to define problems independently.</li>
<li>Ability to extract useful information from irrelevant data.</li>
<li>Ability to conceptualize.</li>
<li>Ability to reorganize information for new perspectives.</li>
<li>Possessing a mind fluent in different modes of thought (deductive, inductive, heuristic, intuitive).</li>
<li>Facility in collaboration.</li>
<li>Skill in discussing issues, problems, or techniques.</li>
<li>Skill in rhetoric and persuasion.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Gatto contends that the district actively avoids teaching these skills to maintain existing power structures.</li>
<li>Gatto laments the abandonment of practical skills training (e.g., shop, cooking) that were once common and valuable.</li>
</ul>
</section>
<section id="the-david-sarnoff-example-a-case-for-self-driven-education" class="level4">
<h4 class="anchored" data-anchor-id="the-david-sarnoff-example-a-case-for-self-driven-education">The David Sarnoff Example: A Case for Self-Driven Education</h4>
<ul>
<li>Gatto presents David Sarnoff’s life as a counterpoint to the failures of the education system.
<ul>
<li><strong>David Sarnoff’s Accomplishments:</strong>
<ul>
<li>Learned English and became a successful newsboy within five months of arriving in New York City at age nine, after his father died.</li>
<li>Owned his own newsstand at fourteen, using newspapers as his primary learning source.</li>
<li>Became an office boy at Marconi Wireless at fourteen through sheer initiative.</li>
<li>Taught himself telegraphy, leading to a successful career in the burgeoning field of radio technology.</li>
<li>Became president of RCA at age 39.</li>
</ul></li>
</ul></li>
<li><strong>Key Takeaway:</strong> Sarnoff’s success was a result of self-directed learning, initiative, and real-world experience, not formal education.</li>
<li>Gatto implies that the current school system stifles these qualities in students.</li>
</ul>
</section>
<section id="the-mask-of-school-reform" class="level4">
<h4 class="anchored" data-anchor-id="the-mask-of-school-reform">The Mask of School Reform</h4>
<ul>
<li>Gatto recounts a visit to a well-regarded alternative school in East Harlem, led by the respected educator Debbie Meyer.</li>
<li>Despite the school’s positive reputation, Gatto observes significant shortcomings stemming from bureaucratic constraints and traditional attitudes.
<ul>
<li><strong>Constraints and Shortcomings:</strong>
<ul>
<li>A pervasive culture of negativity and limitations (“you can’t do this, you can’t do that”).</li>
<li>Excessive emphasis on standardized tests.</li>
<li>Suppression of imagination and creativity among both students and teachers.</li>
<li>A trivialized community service program (two hours per week), rendering it meaningless.</li>
</ul></li>
</ul></li>
<li>Gatto concludes that even this supposedly innovative school falls short of providing a truly valuable education, especially when compared to the self-driven model embodied by David Sarnoff.</li>
</ul>
</section>
<section id="statistical-evidence-of-failure" class="level4">
<h4 class="anchored" data-anchor-id="statistical-evidence-of-failure">Statistical Evidence of Failure</h4>
<ul>
<li>Gatto cites a report by the State Commission of Education ranking School District 3 last in New York State in key educational metrics.
<ul>
<li><strong>Key Statistics:</strong>
<ul>
<li>Last place out of 736 school districts in third-grade math and reading.</li>
<li>Near the bottom in fifth-grade writing, sixth-grade reading, math, and social studies.</li>
<li>Poor performance in seventh-grade honor math and honor biology.</li>
</ul></li>
</ul></li>
<li>Gatto points out the irony of such poor performance given the district’s affluent location and access to resources.</li>
<li>Gatto uses the report to emphasize the severity of the district’s failure, arguing that “last isn’t an easy degree of failure to achieve.”</li>
</ul>
</section>
<section id="a-culture-of-complacency-and-corruption" class="level4">
<h4 class="anchored" data-anchor-id="a-culture-of-complacency-and-corruption">A Culture of Complacency and Corruption</h4>
<ul>
<li>Gatto argues that a culture of complacency, self-preservation, and corruption within the district perpetuates its failures.
<ul>
<li><strong>Evidence:</strong>
<ul>
<li>High teacher turnover rate (22% annually) is attributed to a “caste system” that rewards favored teachers with desirable assignments while burdening others with impossible workloads.</li>
<li>Inflated administrative bureaucracy and a “shadow economy” divert resources away from teaching and contribute to a deceptive student-teacher ratio.</li>
<li>Administrators prioritize their careers and maintaining the status quo over meaningful educational reform.</li>
<li>A principal’s statement that students’ futures are predetermined, highlighting a defeatist attitude toward disadvantaged students.</li>
</ul></li>
</ul></li>
<li><strong>Key Argument:</strong> Gatto suggests that the system is intentionally designed to disadvantage students from less privileged backgrounds, arguing that “we’re both involved in a social engineering project whose mission is to weaken children’s minds and give them bad characters.”</li>
</ul>
</section>
<section id="the-roots-of-educational-failure" class="level4">
<h4 class="anchored" data-anchor-id="the-roots-of-educational-failure">The Roots of Educational Failure</h4>
<ul>
<li>Gatto identifies two specific district policies that have had a detrimental impact on students’ ability to learn and thrive.
<ul>
<li><strong>Policy 1: Tolerance of Disruptive Behavior:</strong>
<ul>
<li>The decision, influenced by the Ford Foundation, to not control disruptive classroom behavior out of concern for students’ self-esteem is criticized as misguided and harmful.</li>
<li>Gatto contends that this policy has created a chaotic learning environment that hinders all students, including those who are well-behaved.</li>
</ul></li>
<li><strong>Policy 2: Recruitment of Disruptive Students:</strong>
<ul>
<li>The district’s practice of recruiting disruptive students from other areas to mask declining enrollment is condemned as a cynical maneuver that exacerbates the existing problems.</li>
</ul></li>
</ul></li>
<li><strong>Outcome:</strong> These policies, combined with a lack of accountability for administrators, have resulted in a decline in educational standards and a system that fails to serve its students.</li>
</ul>
</section>
<section id="the-perpetuation-of-passivity" class="level4">
<h4 class="anchored" data-anchor-id="the-perpetuation-of-passivity">The Perpetuation of Passivity</h4>
<ul>
<li>Gatto argues that the current education system functions as a “narcotic,” addicting children to passivity, entertainment, and a detachment from reality.
<ul>
<li><strong>Evidence:</strong>
<ul>
<li>Students’ lack of interest in exploration, play, and personal growth.</li>
<li>Excessive consumption of television, music videos, and computer games.</li>
<li>The observation that children from stable, two-parent households where the mother does not work engage in far less passive entertainment.</li>
</ul></li>
</ul></li>
<li><strong>Conclusion:</strong> The education system, instead of fostering critical thinking and engagement with the world, cultivates a dependence on superficial stimulation and an inability to cope with the demands of a meaningful life.</li>
</ul>
</section>
</section>
<section id="a-call-to-action-and-a-bleak-outlook" class="level3">
<h3 class="anchored" data-anchor-id="a-call-to-action-and-a-bleak-outlook">A Call to Action and a Bleak Outlook</h3>
<ul>
<li>Gatto announces their intention to circulate the letter to the new school board, hoping, albeit with skepticism, to spark reflection and change.</li>
<li>Gatto expresses a sense of hopelessness about the likelihood of real reform, believing that self-preservation and entrenched interests will always prevail over genuine efforts to improve the education system.</li>
<li>The letter ends on a pessimistic note, implying that the cycle of failure will continue unless those in power are willing to prioritize the well-being and future of the students above all else.</li>
</ul>
</section>
</section>
<section id="chapter-5.-hector-isnt-the-problem" class="level2">
<h2 class="anchored" data-anchor-id="chapter-5.-hector-isnt-the-problem">Chapter 5. Hector Isn’t the Problem</h2>
<section id="i-quit-a-teachers-disillusionment" class="level3">
<h3 class="anchored" data-anchor-id="i-quit-a-teachers-disillusionment">I Quit: A Teacher’s Disillusionment</h3>
<ul>
<li>Gatto, a 30-year veteran teacher in Manhattan’s Community School District 3, recounts their extensive experience:
<ul>
<li>Teaching in all five district secondary schools.</li>
<li>Facing repeated attempts by administrations to remove them.</li>
<li>Experiencing two license suspensions for insubordination and covert termination during medical leave.</li>
<li>Achieving success as a lecturer at CUNY’s education department, ranking first in student-faculty ratings.</li>
<li>Implementing successful initiatives:
<ul>
<li>New York City’s most successful permanent school fundraiser.</li>
<li>30,000 hours of volunteer community service by an eighth-grade class.</li>
<li>A student-run food cooperative.</li>
<li>Securing over 1,000 apprenticeships.</li>
<li>Directing the collection of tens of thousands of books for student libraries.</li>
<li>Producing four talking job dictionaries for the blind.</li>
<li>Writing two original student musicals.</li>
</ul></li>
<li>Being named New York State Teacher of the Year.</li>
</ul></li>
<li>Despite these achievements, Gatto reached a point of overwhelming disgust and frustration, leading them to quit.</li>
</ul>
</section>
<section id="i-quit-i-think-a-scathing-critique-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="i-quit-i-think-a-scathing-critique-of-schooling">I Quit, I Think: A Scathing Critique of Schooling</h3>
<ul>
<li>Gatto’s essay, “I Quit, I Think,” published in the Wall Street Journal, outlines their reasons for leaving the profession:
<ul>
<li><strong>Government schooling is the most radical adventure in history</strong>, killing the family by:
<ul>
<li>Monopolizing childhood’s best times.</li>
<li>Teaching disrespect for home and parents.</li>
</ul></li>
<li>The structure of schooling is rooted in an <strong>Egyptian, not Greek or Roman, blueprint</strong>, based on the belief that:
<ul>
<li><strong>Human value is scarce</strong>, symbolized by a pyramid’s narrow peak.</li>
<li>This idea, passed down through the Puritans, found scientific expression in the <strong>bell curve</strong>, which suggests talent is biologically determined.</li>
<li><strong>School serves as the church of this religious notion, with rituals to maintain orthodoxy.</strong></li>
</ul></li>
<li><strong>Professional educators benefit from making the simple seem complex</strong>, subordinating the public to their expertise.</li>
<li><strong>School, as a jobs program, contract provider, and guardian of the social order, resists reform.</strong></li>
<li><strong>Reform efforts fail to fundamentally change the system.</strong></li>
<li><strong>Standardized measures like age grading and testing are arbitrary and harmful</strong>:
<ul>
<li>Children develop at different paces, and judging them by uniform standards is illogical.</li>
<li>Gatto uses the example of David (reading at age 4) and Rachel (reading at age 9), who show no difference in reading ability at age 13.</li>
<li>School, however, would label Rachel as learning disabled and hold David back, creating artificial categories and dependencies.</li>
</ul></li>
<li>Gatto argues that <strong>learning disabilities and giftedness are “sacred myths,”</strong> perpetuating the school system.</li>
<li><strong>True education is not standardized;</strong> there are countless ways to learn, like fingerprints.</li>
<li><strong>State-certified teachers are not essential for education and may hinder it.</strong></li>
<li><strong>Good schools need free-market choices and variety, not more money or time.</strong></li>
<li><strong>National curriculum and testing are based on ignorance of how people learn.</strong></li>
<li>Gatto concludes, unable to participate in a system that harms children, and seeks alternative work.</li>
</ul></li>
</ul>
</section>
<section id="a-religion-of-schooling-and-the-myth-of-dumbness" class="level3">
<h3 class="anchored" data-anchor-id="a-religion-of-schooling-and-the-myth-of-dumbness">A Religion of Schooling and the Myth of Dumbness</h3>
<ul>
<li>Gatto reflects on their 30-year career, questioning how they participated in an <strong>indoctrinating and sorting machine</strong> that steals children’s potential.</li>
<li>School, they argue, is a <strong>religion</strong>; understanding its “holy mission” is crucial to understanding its workings.</li>
<li>While human failings exist within the system, they are not the root cause; <strong>schooling itself is designed to produce “dumbness.”</strong></li>
<li><strong>This new dumbness is not mere ignorance but a categorization of relative stupidity</strong>, creating artificial hierarchies like:
<ul>
<li>Gifted and talented</li>
<li>Mainstream</li>
<li>Special Ed</li>
</ul></li>
<li>These categories ration learning, benefiting the system and social order.</li>
<li>The <strong>“new dumb” are perceived as dangerous and require conditioning with “commercially prepared disinformation.”</strong></li>
<li>This dumbness particularly harms middle and upper-middle-class children, already pressured to conform, leaving them vulnerable to existential crises later in life.</li>
<li>Gatto cites English historian Alan Bullock: <strong>“Evil is a state of incompetence.”</strong> Schooling, they argue, has filled the 20th century with evil by breaking children to a system that rewards compliance over critical thinking.</li>
<li>This system produces individuals dependent on group approval, exemplified by a National Merit Scholar in Gatto’s family who aspired to be “a small part in a great machine.”</li>
<li><strong>The “dumbed down” cannot think independently, constantly seeking external validation and vulnerable to manipulation.</strong></li>
<li>Gatto challenges prevalent explanations for “dumbness”:
<ul>
<li><strong>Biological determinism (the bell curve)</strong></li>
<li><strong>Capitalist oppression (neo-Marxism)</strong></li>
<li><strong>Moral failing (Calvinism)</strong></li>
<li><strong>Natural selection (Darwinism)</strong></li>
<li><strong>Social utility (pragmatic elitism)</strong></li>
<li><strong>Karmic retribution (Buddhism)</strong></li>
</ul></li>
<li>All these explanations, Gatto contends, justify the existence of a vast bureaucracy to manage the “problem” of the “dumb.”</li>
<li>Gatto’s proposition: <strong>mass dumbness is a fabrication, not a reality.</strong> It was invented to serve the system.</li>
</ul>
</section>
<section id="hector-the-horse-tamer-a-case-study" class="level3">
<h3 class="anchored" data-anchor-id="hector-the-horse-tamer-a-case-study">Hector, the Horse Tamer: A Case Study</h3>
<ul>
<li>Gatto introduces <strong>Hector Rodriguez, a 13-year-old student</strong>, observed one November day:
<ul>
<li>Small, olive-skinned, with large black eyes.</li>
<li>Trying to slip past the Central Park skating rink gate despite having a paid ticket.</li>
</ul></li>
<li>Hector’s actions, puzzling at first, demonstrate his experimental nature—testing the gate’s security with a safety net (the ticket).</li>
<li>School records reveal Hector’s history:
<ul>
<li>Labeled an “outlaw” for minor infractions that would not have been criminalized in the past.</li>
<li>Attending one of New York State’s lowest-rated schools, facing potential state takeover.</li>
<li>Placed in the “Mainstream D” category, the lowest of the low, above only Special Ed.</li>
<li>Standardized test scores placed him three years behind his peers.</li>
</ul></li>
<li>Despite this, Hector displays initiative and a desire to challenge norms, as seen in his gate-crashing experiment.</li>
<li>His “criminal” record includes:
<ul>
<li>Being caught with a fake gun in his former elementary school during Christmas break.</li>
<li>Intending to “free the slaves” (the younger children) like a modern-day Spartacus.</li>
</ul></li>
<li>This incident highlights the school’s perception of Hector as a problem, as expressed by the principal: “Gatto, what have you done to me?”</li>
<li>A year later, Hector’s high school record shows:
<ul>
<li>Failing every subject.</li>
<li>Excessive absences and truancy.</li>
</ul></li>
<li>The system paints a picture of Hector as a lost cause:
<ul>
<li>Poor, small, minority, ignored, “dumb,” a trouble-maker, a failure.</li>
</ul></li>
<li>Gatto asks: <strong>What is society to do with its Hectors?</strong></li>
<li>Hector represents millions of children deemed problematic by the education system.</li>
<li>Gatto argues that <strong>schooling was reimagined to control children like Hector</strong>, turning it into:
<ul>
<li>A warehouse</li>
<li>A behavior modification clinic</li>
<li>A tool for attitude adjustment</li>
</ul></li>
<li>This system is justified as a defense against chaos, with Hector representing the chaos that needs taming.</li>
<li>The principal, in the documentary about Gatto’s class, acknowledges the system’s flaws but defends it as better than chaos.</li>
<li>Gatto challenges this notion: <strong>Is chaos the only alternative to a stifling system?</strong></li>
<li><strong>The real demon, Gatto argues, is the misperception that Hector is the problem.</strong></li>
<li><strong>Forced schooling, presented as a bulwark against chaos, is actually the source of the problem.</strong></li>
<li>The belief that <strong>human nature’s irrationality must be suppressed</strong> is presented as a dangerous dogma driving the education system.</li>
</ul>
</section>
</section>
<section id="chapter-6-the-camino-de-santiago" class="level2">
<h2 class="anchored" data-anchor-id="chapter-6-the-camino-de-santiago">Chapter 6: The Camino de Santiago</h2>
<section id="confessions-of-a-tv-free-america-advisor" class="level3">
<h3 class="anchored" data-anchor-id="confessions-of-a-tv-free-america-advisor">Confessions of a TV Free America Advisor</h3>
<ul>
<li>Gatto, a school teacher and advisor for TV Free America, observed negative behavioral patterns in TV-addicted children:
<ul>
<li>Irresponsibility</li>
<li>Childishness</li>
<li>Dishonesty</li>
<li>Maliciousness</li>
<li>Lack of purpose</li>
</ul></li>
<li>These children seemed to lose the ability to behave with integrity and grow up, as if their spirits were dwarfed by consuming too many fabricated stories and explanations.</li>
<li>Gatto felt that computers often worsened the problem, leading to:
<ul>
<li>Exposure to pornography</li>
<li>Playing against programs instead of other people</li>
<li>Passive consumption rather than active participation</li>
<li>Crossing the line into a passive state even with the internet, unless good discipline was exercised.</li>
</ul></li>
</ul>
</section>
<section id="suppression-of-natural-feedback-circuits" class="level3">
<h3 class="anchored" data-anchor-id="suppression-of-natural-feedback-circuits">Suppression of Natural Feedback Circuits</h3>
<ul>
<li>Gatto sought a solution to counteract the negative effects of excessive media consumption, recognizing that traditional preaching was ineffective.</li>
<li>Gatto believed that relief could be found by encouraging physical activity and real-life experiences, as opposed to passively consuming media.</li>
<li>The core issue identified was the suppression of <strong>natural feedback circuits</strong>, which are essential for learning from mistakes.</li>
<li>Gatto uses the example of learning to sail:
<ul>
<li>A novice sailor will inevitably make mistakes, such as tacking too far left or right.</li>
<li>However, through practice and feedback, the sailor learns to adjust and improve.</li>
</ul></li>
<li>Similarly, mastering speech requires significant practice and feedback.</li>
<li>Gatto argues that bureaucracies, including school systems, often fail because they cannot efficiently respond to feedback.
<ul>
<li>They are bound by rigid rules and resistant to input from parents, teachers, students, or outside sources.</li>
</ul></li>
<li>Gatto observed that the rigid structure of traditional schooling limited students’ opportunities for growth through feedback.</li>
</ul>
</section>
<section id="a-guerrilla-curriculum-inspired-by-the-camino-de-santiago" class="level3">
<h3 class="anchored" data-anchor-id="a-guerrilla-curriculum-inspired-by-the-camino-de-santiago">A Guerrilla Curriculum Inspired by the Camino de Santiago</h3>
<ul>
<li>Gatto’s solution was a <strong>guerrilla curriculum</strong> designed to restore natural feedback circuits in children.</li>
<li>This curriculum targeted inactivity and activities that did not significantly engage feedback mechanisms.</li>
<li>Gatto believed that sufficient activity, regardless of its specific nature, would motivate children to reduce their screen time.</li>
<li>The goal was to shift children from being passive spectators to active participants in their own lives.</li>
<li><strong>Inspiration from the Camino de Santiago:</strong>
<ul>
<li>The Camino de Santiago is a medieval pilgrimage route across northern Spain, ending at the burial place of the Apostle James in Santiago de Compostela.</li>
<li>Thousands of people undertake this pilgrimage annually, seeking personal growth, self-reliance, connection with nature, and time for reflection.</li>
<li>Gatto drew inspiration from the Camino, recognizing that a similar pilgrimage could help children reconnect with themselves, their families, and the natural world.</li>
</ul></li>
</ul>
<section id="the-new-york-city-pilgrimage" class="level4">
<h4 class="anchored" data-anchor-id="the-new-york-city-pilgrimage">The New York City Pilgrimage</h4>
<ul>
<li>Gatto, with the support of parents, sent 13-year-old students on solo journeys on foot through New York City’s five boroughs.</li>
<li>These expeditions involved:
<ul>
<li>Walking the circumference of Manhattan (approximately 30 miles)</li>
<li>Exploring different neighborhoods, observing and analyzing their characteristics</li>
<li>Mapping Central Park, university campuses, business districts, churches, and museums</li>
<li>Visiting government departments, such as the Board of Education or police headquarters, individually</li>
</ul></li>
<li>Students documented their observations, conducted interviews, researched, and created guide pamphlets.</li>
<li>Gatto encouraged solo expeditions as they offered the most significant learning opportunities, but students could also opt for shorter trips.</li>
<li>The key requirement was a willingness to walk alone and engage in meaningful exploration and study.</li>
</ul>
</section>
<section id="a-visitors-key-to-iceland-and-its-influence" class="level4">
<h4 class="anchored" data-anchor-id="a-visitors-key-to-iceland-and-its-influence">A Visitor’s Key to Iceland and Its Influence</h4>
<ul>
<li>Gatto found further inspiration for the curriculum in “A Visitor’s Key to Iceland,” a unique guidebook.</li>
<li>The guidebook meticulously describes every road in Iceland, bringing the land and its history to life through vivid anecdotes.</li>
<li>Inspired by this approach, Gatto’s students created their own “visitors’ keys” to various aspects of New York City:
<ul>
<li>Safe spots for playing hooky</li>
<li>Notable pizza parlors</li>
<li>Architectural features of brownstone buildings</li>
<li>Swimming pools in the five boroughs, including sociological analyses of their cultural context</li>
</ul></li>
<li>Many projects involved gathering knowledge and perspectives from elderly individuals, both those confined to homes and those spending time in public spaces.</li>
<li>As students engaged in these production-oriented activities, the allure of screens diminished.</li>
</ul>
</section>
</section>
<section id="results-and-reflections" class="level3">
<h3 class="anchored" data-anchor-id="results-and-reflections">Results and Reflections</h3>
<ul>
<li>Gatto observed that engaging with reality through intellectually stimulating work activated feedback circuits in most students, leading to substantial personal growth.</li>
<li>By April, many students who had initially displayed negative behaviors transformed into interesting and productive individuals.</li>
<li>Gatto emphasizes that embracing challenges is fundamental to self-mastery and competence, a concept likely discovered in humanity’s early days.</li>
<li>Gatto was surprised by how easily this transformation was achieved, requiring neither exceptional talent nor financial resources.</li>
<li>While implementing the curriculum with 130 students annually was challenging, Gatto believes it would be significantly easier in a system that prioritized learning over social control.</li>
<li>Gatto received numerous awards from the school establishment, which was unaware of the curriculum’s unconventional nature.</li>
<li>Gatto emphasizes the importance of allowing children to learn through real-life experiences rather than imposing limitations.</li>
</ul>
</section>
<section id="urgent-appointments-with-reality" class="level3">
<h3 class="anchored" data-anchor-id="urgent-appointments-with-reality">Urgent Appointments with Reality</h3>
<ul>
<li>Gatto argues that everyone has “appointments to keep with reality,” including:
<ul>
<li>Real work to do</li>
<li>Real skills to learn</li>
<li>Real battles to fight</li>
<li>Real risks to take</li>
<li>Real ideas to grapple with</li>
<li>A constant awareness of death’s inevitability</li>
</ul></li>
<li>According to Gatto, television, computers, and government schooling have diverted children from these essential experiences, resulting in a generation of emotionally and developmentally stunted individuals.</li>
<li>Gatto believes that restoring opportunities for real-life engagement will alleviate these problems and allow children to mature naturally.</li>
</ul>
</section>
<section id="breaking-free-from-the-electronic-trance" class="level3">
<h3 class="anchored" data-anchor-id="breaking-free-from-the-electronic-trance">Breaking Free from the Electronic Trance</h3>
<ul>
<li>While acknowledging the potential benefits of technology, Gatto cautions against becoming overly reliant on it.</li>
<li>Gatto suggests that reducing reliance on screens can be as simple as physically unplugging.</li>
<li>Exposing young people to the richness of real life can naturally diminish their dependence on television.</li>
<li>Gatto highlights the importance of showing, rather than telling, children the value of experiences beyond the screen.</li>
<li>Gatto expresses concerns about the potential negative impacts of excessive computer use, similar to those associated with television.</li>
</ul>
</section>
<section id="the-camino-de-santiago-as-a-model-for-education-reform" class="level3">
<h3 class="anchored" data-anchor-id="the-camino-de-santiago-as-a-model-for-education-reform">The Camino de Santiago as a Model for Education Reform</h3>
<ul>
<li>Gatto proposes a radical education reform:
<ul>
<li>Eliminate two years of high school and use the funds to send every student on their own “Camino de Santiago.”</li>
</ul></li>
<li>This experience, inspired by the pilgrimage, would involve significant personal journeys, fostering self-reliance, exploration, and reflection.</li>
<li>Gatto emphasizes that these journeys do not need to be as physically demanding as those undertaken by adventurers like George Mee or Tani Abe.</li>
<li>Gatto firmly believes that all young people should experience a significant personal “Camino” as part of their education.</li>
<li>Gatto encourages individuals to take on this responsibility themselves if governments fail to implement such a program.</li>
</ul>
</section>
</section>
<section id="chapter-7-weapons-of-mass-instruction" class="level2">
<h2 class="anchored" data-anchor-id="chapter-7-weapons-of-mass-instruction">Chapter 7: Weapons of Mass Instruction</h2>
<section id="schools-deficiencies-statistics-and-observations" class="level3">
<h3 class="anchored" data-anchor-id="schools-deficiencies-statistics-and-observations">School’s Deficiencies: Statistics and Observations</h3>
<ul>
<li>Only <strong>31%</strong> of college-educated Americans can fully comprehend a newspaper story, down from <strong>40%</strong> a decade ago.
<ul>
<li>Source: <em>National Commission on the Future of Higher Education</em>, August 2006</li>
</ul></li>
<li><strong>35%</strong> of young people regret their university experience, not considering the time and money invested worth it.
<ul>
<li>More than half said they learned nothing of use.</li>
<li>Source: <em>Wilson Quarterly</em>, Autumn 2006</li>
</ul></li>
</ul>
</section>
<section id="jacques-lusserins-critique-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="jacques-lusserins-critique-of-schooling">Jacques Lusserin’s Critique of Schooling</h3>
<ul>
<li>Jacques Lusserin, a blind French teenager who led a resistance group during World War II, criticizes schooling in his autobiography, <em>And Then There Was Light</em>.
<ul>
<li>In Chapter 4, he describes the classroom experience as a “<strong>moral disaster,</strong>” likening the compulsory confinement of students to a foul odor.</li>
<li>He argues that school suppresses anger, independence, curiosity, and other natural impulses, creating an environment where true moral development is impossible.
<ul>
<li>He connects this to his ability to commit violence shortly after leaving this environment.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="examining-the-purpose-and-effects-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="examining-the-purpose-and-effects-of-schooling">Examining the Purpose and Effects of Schooling</h3>
<ul>
<li>Gatto questions the benefits of schooling, given its historically negative portrayal.
<ul>
<li>He acknowledges the system must offer some benefits but questions what they are and who they serve.</li>
<li>He suggests the focus on winning in school supersedes the goal of learning, leading to scandals where even elite students lack knowledge.</li>
</ul></li>
<li>Gatto examines the cultural implications of entrusting children to strangers for instruction for extended periods, questioning the underlying message this practice sends.</li>
<li>He presents various cultural artifacts as evidence of schooling’s negative perception:
<ul>
<li><strong>Horace’s ode:</strong> Describes the torments of schooling.</li>
<li><strong>Pompeii mosaics:</strong> Illustrate painful school discipline.</li>
<li><strong>Washington Irving’s “The Legend of Sleepy Hollow”:</strong> Celebrates a protagonist who turns the tables on an insufferable schoolmaster.</li>
<li><strong>World War I era song “School Days”:</strong> Romantically links school learning with corporal punishment.</li>
<li><strong>Hollywood film “Teaching Miss Tingle”:</strong> Depicts a schoolteacher kidnapped and tortured by her students.</li>
<li><strong>Websites:</strong> Dedicated to disrupting school routines.</li>
</ul></li>
</ul>
</section>
<section id="gattos-personal-experience-and-methodology" class="level3">
<h3 class="anchored" data-anchor-id="gattos-personal-experience-and-methodology">Gatto’s Personal Experience and Methodology</h3>
<ul>
<li>Gatto, a teacher of 30 years, realized early in his career that school diminishes intellectual power, creativity, and character.
<ul>
<li>He compares the school system to a penitentiary, with rules and procedures acting as guards.</li>
</ul></li>
<li>Inspired by Lusserin, Gatto sought to peacefully sabotage the system.
<ul>
<li>He developed a formula for individualized learning:
<ul>
<li><strong>Step 1: Comprehensive Student Biography</strong>
<ul>
<li>Assemble a detailed biography of each student, going beyond school records to include information from family, friends, and others who know the student well.</li>
</ul></li>
<li><strong>Step 2: Personal Wishes and Weaknesses</strong>
<ul>
<li>Ask each student to list:
<ul>
<li><strong>Three things they want to learn by the year’s end.</strong></li>
<li><strong>Three weaknesses they want to overcome.</strong></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>This approach motivated students, encouraging hard work and self-directed learning.</li>
<li>Gatto also embarked on extensive research into the history and purpose of schooling:
<ul>
<li>He read thousands of books, traveled extensively, and engaged in debates about education.</li>
<li>His research culminated in a book, <em>The Underground History of American Education</em>, which a major publisher refused to publish, deeming it too controversial.</li>
</ul></li>
<li>Gatto’s teaching practices were informed by his research and daring field experiments conducted with his students (referred to as “gatos-gorillas”):
<ul>
<li>They infiltrated public events and institutions, conducted polls, and staged dramatic performances.</li>
<li>Their goal:
<ul>
<li>Promote independence, self-reliance, and critical thinking.</li>
<li>Expose the barriers schooling creates that limit intellectual and behavioral growth.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="school-as-a-system-designed-to-maintain-the-status-quo" class="level3">
<h3 class="anchored" data-anchor-id="school-as-a-system-designed-to-maintain-the-status-quo">School as a System Designed to Maintain the Status Quo</h3>
<ul>
<li>Gatto argues that school, like any bureaucracy, prioritizes self-preservation over its stated mission.
<ul>
<li>He cites Robert Michel’s study of bureaucracies, which found that their primary goal is always to preserve themselves.</li>
</ul></li>
<li>Gatto contends that school operates on illusions, mirroring the economic system’s reliance on “bubbles.”</li>
<li>He questions whether schooling is designed to produce truly educated individuals or to maintain a system of control that benefits a select few.</li>
</ul>
</section>
<section id="adam-smiths-perspective-on-education-vs.-schooling" class="level3">
<h3 class="anchored" data-anchor-id="adam-smiths-perspective-on-education-vs.-schooling">Adam Smith’s Perspective on Education vs.&nbsp;Schooling</h3>
<ul>
<li>Gatto highlights Adam Smith’s distinction between <strong>education</strong> and <strong>schooling</strong> in <em>The Wealth of Nations</em>:
<ul>
<li><strong>Schooling:</strong> Focuses on training for specific roles in society, often limiting intellectual development.</li>
<li><strong>Education:</strong> Aims to compensate for the negative psychological effects of capitalism, fostering critical thinking, creativity, and well-rounded individuals.</li>
</ul></li>
<li>Smith argued that capitalism creates four damaging effects on workers:
<ul>
<li>Cowardice</li>
<li>Stupidity</li>
<li>Sluggishness</li>
<li>Indifference to anything beyond basic needs</li>
</ul></li>
<li>According to Smith, education is necessary to counteract these effects.</li>
<li>Gatto’s curriculum aimed to address these issues, focusing on personal growth and critical engagement with the world.</li>
</ul>
</section>
<section id="william-playfairs-counterargument-the-policy-of-keeping-people-dumb" class="level3">
<h3 class="anchored" data-anchor-id="william-playfairs-counterargument-the-policy-of-keeping-people-dumb">William Playfair’s Counterargument: The Policy of Keeping People Dumb</h3>
<ul>
<li>William Playfair, Smith’s publisher, believed education for the masses threatened social order.
<ul>
<li>He argued that widespread knowledge would lead to social upheaval and economic instability.</li>
<li>He coined the phrase “a little knowledge is a dangerous thing,” advocating for limited education that would maintain the existing power structure.</li>
</ul></li>
<li>Playfair’s philosophy aligns with the ancient Chinese concept of “The Policy of Keeping People Dumb.”</li>
<li>Gatto suggests that modern leaders, while less overt, still employ this strategy to maintain control.</li>
</ul>
</section>
<section id="the-lincoln-elective-program-a-case-study-in-school-system-failure" class="level3">
<h3 class="anchored" data-anchor-id="the-lincoln-elective-program-a-case-study-in-school-system-failure">The Lincoln Elective Program: A Case Study in School System Failure</h3>
<ul>
<li>Gatto recounts his experience with an elective program at Lincoln Academy, a public junior high school in a wealthy, intellectually vibrant area of Manhattan.</li>
<li>Despite its location and resources, the school was plagued by violence, apathy, and a disconnect between the administration’s rhetoric and the reality of student experiences.</li>
<li>Gatto’s attempt to engage students in an elective on epic poetry was met with resistance and revealed a system where students lacked agency and genuine choice.</li>
</ul>
</section>
<section id="school-as-a-breeding-ground-for-contempt" class="level3">
<h3 class="anchored" data-anchor-id="school-as-a-breeding-ground-for-contempt">School as a Breeding Ground for Contempt</h3>
<ul>
<li>Gatto cites a 2005 Indiana University study on anti-smoking programs in schools.
<ul>
<li>The study found that all school-based programs, despite significant funding, failed.</li>
<li>The lead researcher, Dr.&nbsp;Sarah Wee, suggested that school environments inherently breed contempt in students, undermining any initiative.</li>
</ul></li>
<li>Gatto connects this finding to the story of Roger Gaufrin, the sole survivor of the Oradour-sur-Glane massacre in World War II.
<ul>
<li>Gaufrin’s contempt for school, which led him to disobey his teachers’ instructions to gather in the town square, saved his life.</li>
</ul></li>
</ul>
</section>
<section id="the-pervasive-irrelevance-of-school-curricula" class="level3">
<h3 class="anchored" data-anchor-id="the-pervasive-irrelevance-of-school-curricula">The Pervasive Irrelevance of School Curricula</h3>
<ul>
<li>Gatto argues that school curricula are often irrelevant to students’ lives and future needs.</li>
<li>He attributes this to the political nature of schooling, where powerful entities influence what is taught and omitted.</li>
<li>Examples of irrelevance:
<ul>
<li><strong>Lack of environmental education in Australia:</strong> Despite the country’s fragile ecosystem and the impact of human activities (e.g., sheep farming), schools avoid addressing these critical issues due to political pressure.</li>
<li><strong>Limited coverage of sensitive historical topics:</strong> Schools often gloss over or omit controversial aspects of history (e.g., religious wars, social inequality), depriving students of a complete understanding of the past.</li>
<li><strong>Emphasis on reading over speaking:</strong> Despite the importance of spoken language in everyday life, schools prioritize reading and writing, neglecting this crucial skill.</li>
<li><strong>Neglect of statistics in mathematics:</strong> While statistical reasoning is essential for navigating the modern world, school math curricula often focus on abstract concepts with limited practical application.</li>
</ul></li>
</ul>
</section>
<section id="the-illusion-of-choice-and-the-suppression-of-critical-thought" class="level3">
<h3 class="anchored" data-anchor-id="the-illusion-of-choice-and-the-suppression-of-critical-thought">The Illusion of Choice and the Suppression of Critical Thought</h3>
<ul>
<li>Gatto uses the example of evolution to illustrate how schools present biased perspectives as absolute truth.
<ul>
<li>He contrasts the theories of Charles Darwin (survival of the fittest) and Alfred Russel Wallace (adaptation and cooperation):
<ul>
<li><strong>Darwin’s theory:</strong>
<ul>
<li>Aligned with the prevailing social and political ideology of 19th-century Britain, justifying imperialism, social Darwinism, and eugenics.</li>
<li>Gained prominence due to Darwin’s social standing and connections.</li>
</ul></li>
<li><strong>Wallace’s theory:</strong>
<ul>
<li>Challenged the status quo by advocating for social justice and cooperation.</li>
<li>Largely ignored or dismissed due to Wallace’s lower social class and radical views.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Gatto argues that schools omit Wallace’s perspective to maintain a specific narrative that supports existing power structures.</li>
</ul>
</section>
<section id="the-control-of-information-from-explosives-to-education" class="level3">
<h3 class="anchored" data-anchor-id="the-control-of-information-from-explosives-to-education">The Control of Information: From Explosives to Education</h3>
<ul>
<li>Gatto highlights the historical shift in access to information, using explosives as an example:
<ul>
<li>In the early 20th century, instructions for making explosives were readily available, reflecting a time when self-reliance and the ability to defend oneself were valued.</li>
<li>Today, such information is heavily restricted, reflecting a shift towards greater government control and a distrust of citizens’ ability to handle powerful knowledge.</li>
</ul></li>
<li>Gatto argues that this control extends to education, where schools limit access to information that could challenge the status quo or empower individuals to think critically about the world around them.</li>
</ul>
</section>
<section id="school-as-a-tool-for-creating-physical-and-psychological-ugliness" class="level3">
<h3 class="anchored" data-anchor-id="school-as-a-tool-for-creating-physical-and-psychological-ugliness">School as a Tool for Creating Physical and Psychological Ugliness</h3>
<ul>
<li>Gatto contends that school contributes to physical and psychological ugliness in students.
<ul>
<li>He argues that the enforced immobility, stress, and unhealthy diets prevalent in schools lead to obesity, low vitality, and a lack of grace.</li>
</ul></li>
<li>He highlights the hypocrisy of a system that promotes physical education while simultaneously fostering environments detrimental to physical well-being.</li>
<li>Gatto connects this to the unspoken bias towards physical appearance in elite college admissions:
<ul>
<li>Universities prioritize attractive, athletic candidates, recognizing the advantages these qualities offer in life.</li>
<li>This preference is rarely acknowledged or discussed in high schools, perpetuating a system where students are judged not solely on their intellectual merits but also on superficial traits.</li>
</ul></li>
</ul>
</section>
<section id="the-enduring-relevance-of-learning-and-the-need-for-change" class="level3">
<h3 class="anchored" data-anchor-id="the-enduring-relevance-of-learning-and-the-need-for-change">The Enduring Relevance of Learning and the Need for Change</h3>
<ul>
<li>Gatto cites Langdon Winner’s book, <em>Autonomous Technology</em>, which argues that modern society is characterized by a reliance on technology that most people do not understand.
<ul>
<li>Winner compares this to a “fundamental bewilderment” similar to that of a newborn child.</li>
</ul></li>
<li>Gatto suggests that school, instead of equipping students to navigate this complexity, perpetuates a state of dependence and intellectual immaturity.</li>
<li>He argues that true learning happens despite school, not because of it, as the emphasis on winning overshadows genuine intellectual curiosity.</li>
<li>He cites Seymour Papert’s belief that learning can be as natural and enjoyable as a child learning to talk, suggesting that traditional schooling is an outdated model.</li>
<li>Gatto points to the rise of homeschooling and the increasing dropout rate as evidence of a growing dissatisfaction with the current system.</li>
</ul>
</section>
<section id="conclusion-reclaiming-education-and-empowering-individuals" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-reclaiming-education-and-empowering-individuals">Conclusion: Reclaiming Education and Empowering Individuals</h3>
<ul>
<li>Gatto argues that school, as it currently exists, functions as a tool for social control, limiting students’ potential and perpetuating a system of inequality.</li>
<li>He advocates for a shift towards true education that:
<ul>
<li>Prioritizes critical thinking, creativity, and self-directed learning.</li>
<li>Provides students with a complete and accurate understanding of the world, even when it challenges prevailing narratives.</li>
<li>Empowers individuals to question, explore, and reach their full potential.</li>
</ul></li>
</ul>
</section>
<section id="the-question-of-intent" class="level3">
<h3 class="anchored" data-anchor-id="the-question-of-intent">The Question of Intent</h3>
<ul>
<li>The irrelevance of school offerings raises questions about the underlying intent.</li>
<li><strong>Is it incompetence or a deliberate design?</strong>
<ul>
<li>Frontline educators (superintendents, principals) may genuinely be unsure but are constrained by the system.</li>
<li>However, the possibility of a darker intent at the policy level cannot be dismissed.</li>
</ul></li>
<li><strong>Social Engineering through Schooling:</strong>
<ul>
<li>Schooling benefits those in power, raising the possibility of its use for social engineering.</li>
<li>Evidence suggests this is indeed the case.</li>
</ul></li>
</ul>
</section>
<section id="walter-lippmanns-indictment-of-modern-education" class="level3">
<h3 class="anchored" data-anchor-id="walter-lippmanns-indictment-of-modern-education">Walter Lippmann’s Indictment of Modern Education</h3>
<ul>
<li><strong>Excerpt from a 1940 speech by Walter Lippmann to the Association for the Advancement of Science:</strong>
<ul>
<li><blockquote class="blockquote">
<p>“During the past 40 or 50 years, those who are responsible for education have progressively removed from the curriculum the Western culture which produced the modern democratic state. The schools and colleges have therefore been sending out into the world men who no longer understand the creative principle of the society in which they must live. Deprived of their cultural tradition, the newly educated Western men no longer possess in the form and substance of their own minds and spirits and ideas the premises, the rationale, the logic, the methods, the values of the deposited wisdom which are the genius of the development of Western civilization. The prevailing education is destined, if it continues, to destroy Western civilization and is in fact destroying it.”</p>
</blockquote></li>
</ul></li>
<li>Lippmann argues that modern education has stripped away Western culture, leaving graduates ill-equipped to understand or contribute to society.</li>
</ul>
</section>
<section id="carol-quigleys-tragedy-and-hope" class="level3">
<h3 class="anchored" data-anchor-id="carol-quigleys-tragedy-and-hope">Carol Quigley’s “Tragedy and Hope”</h3>
<ul>
<li><strong>Dr.&nbsp;Carol Quigley</strong>, Georgetown University scholar, explored the dismantling of Western culture in his 1966 book, <strong>“Tragedy and Hope: A History of the World in Our Time.”</strong></li>
<li><strong>Suppression of “Tragedy and Hope”:</strong>
<ul>
<li>The book was so revealing that its publisher destroyed the plates after the first printing and refused to reprint despite high demand.</li>
<li>Dr.&nbsp;Quigley was told the book met with public indifference.</li>
<li>Since then, numerous bootleg copies have circulated.</li>
<li><strong>Caution:</strong> Some recent printings may be altered; older versions are recommended.</li>
</ul></li>
<li><strong>Quigley’s Influence:</strong>
<ul>
<li>Quigley was President Bill Clinton’s tutor at Georgetown.</li>
<li>Clinton acknowledged Quigley in his acceptance speech for the Democratic Party presidential nomination.</li>
</ul></li>
</ul>
</section>
<section id="scientific-management-and-subordination-in-schooling" class="level3">
<h3 class="anchored" data-anchor-id="scientific-management-and-subordination-in-schooling">Scientific Management and Subordination in Schooling</h3>
<ul>
<li><strong>Scientific management</strong>, as championed by Frederick Taylor (<strong>“Principles of Scientific Management,”</strong> 1911), prioritizes <strong>subordination</strong> above all else.
<ul>
<li>This principle permeates various sectors: business, government, schooling, religion, social work, etc.</li>
</ul></li>
<li><strong>Hierarchy and Predictability:</strong>
<ul>
<li>Bureaucracies rely on hierarchy, where productivity is secondary to obedience.</li>
<li>Subordination ensures employees are confined to their roles, making them predictable and controllable.</li>
</ul></li>
<li><strong>Eliminating Independent Thinkers:</strong>
<ul>
<li>Educated individuals and those with strong principles pose a threat to scientific management.</li>
<li>They are capable of critical thought, questioning authority, and acting on their own moral compass.</li>
</ul></li>
<li><strong>The Ideal Hireling:</strong>
<ul>
<li>The ideal worker is unquestioningly obedient, enthusiastic, and eager to please.</li>
<li>This training begins in the first grade with the word “don’t.”</li>
</ul></li>
</ul>
</section>
<section id="the-dont-drill-limiting-childrens-potential" class="level3">
<h3 class="anchored" data-anchor-id="the-dont-drill-limiting-childrens-potential">The “Don’t” Drill: Limiting Children’s Potential</h3>
<ul>
<li>Primary school, instead of nurturing self-development, focuses on limitations.</li>
<li><strong>Examples of “don’ts” in school:</strong>
<ul>
<li>Don’t run, talk, climb trees, play rough.</li>
<li>Don’t talk without raising your hand, fidget, get out of your seat, stare out the window, take your shoes off.</li>
<li>Don’t eat or drink in class, laugh, take too long.</li>
<li>Don’t read ahead, go off the path, say “I’m bored.”</li>
<li>Don’t mix with older kids, complain, bring toys.</li>
</ul></li>
<li><strong>Implied “don’ts”:</strong>
<ul>
<li>Don’t have your own ideas, show initiative, be independent, make your own choices, take responsibility for your own learning.</li>
</ul></li>
<li><strong>Consequences of Constant Negativity:</strong>
<ul>
<li>The endless “don’ts” stifle creativity, curiosity, and a sense of agency.</li>
<li>They foster indifference, leading to escapism through negative outlets (violence, drugs, etc.).</li>
</ul></li>
</ul>
</section>
<section id="discouraging-direct-experience-a-school-trip-permission-form" class="level3">
<h3 class="anchored" data-anchor-id="discouraging-direct-experience-a-school-trip-permission-form">Discouraging Direct Experience: A School Trip Permission Form</h3>
<ul>
<li>A 2005 permission form from Queen Elizabeth Junior and Senior High School (Calgary, Canada) exemplifies how schools discourage direct experience.</li>
<li><strong>Exaggerated List of Potential Hazards:</strong>
<ul>
<li>The form lists numerous mundane risks associated with a museum trip (bus travel, weather, tripping hazards, etc.).</li>
</ul></li>
<li><strong>Creating Fear and Aversion to Risk:</strong>
<ul>
<li>This approach fosters a culture of fear and discourages parents and children from engaging in real-world experiences.</li>
</ul></li>
<li><strong>Implication:</strong> Children are better off confined within the controlled environment of school, where such perils are supposedly minimized.</li>
</ul>
</section>
<section id="collectivization-and-disconnection-in-education" class="level3">
<h3 class="anchored" data-anchor-id="collectivization-and-disconnection-in-education">Collectivization and Disconnection in Education</h3>
<ul>
<li><strong>Following the Prussian model (William Torrey Harris), schools prioritize collectivism over individuality.</strong></li>
<li><strong>Categorizing Children:</strong>
<ul>
<li>Children are treated as members of groups rather than unique individuals.</li>
<li>Examples: race, academic ability, socioeconomic status, etc.</li>
</ul></li>
<li><strong>The Lowest Common Denominator:</strong>
<ul>
<li>Collectivism leads to a focus on the average, neglecting the needs of individual students.</li>
<li>This results in a lowering of standards and a focus on the lowest common denominator.</li>
</ul></li>
<li><strong>Example: New York City Schools (2002-2008):</strong>
<ul>
<li>Increased spending and teacher hiring did not improve outcomes when standards were lowered.</li>
</ul></li>
</ul>
</section>
<section id="the-connected-mind-vs.-school-induced-disconnection" class="level3">
<h3 class="anchored" data-anchor-id="the-connected-mind-vs.-school-induced-disconnection">The Connected Mind vs.&nbsp;School-Induced Disconnection</h3>
<ul>
<li><strong>The Educated Mind:</strong>
<ul>
<li>A truly educated mind is connected to ideas, experiences, people, and itself.</li>
<li>It embraces diverse perspectives, engages in real-world experiences, and values self-knowledge.</li>
</ul></li>
<li><strong>School-Induced Disconnection:</strong>
<ul>
<li>Schools, however, prioritize disconnection:
<ul>
<li>Separation from families, traditions, communities, religions, peers, interests.</li>
<li>Disconnection from the Western intellectual tradition.</li>
<li>Limited opportunities for risk-taking and adventure.</li>
</ul></li>
<li>This leaves graduates ill-equipped for life’s complexities.</li>
</ul></li>
</ul>
</section>
<section id="the-talking-choo-choo-syndrome-artificial-extension-of-childhood" class="level3">
<h3 class="anchored" data-anchor-id="the-talking-choo-choo-syndrome-artificial-extension-of-childhood">The Talking Choo-Choo Syndrome: Artificial Extension of Childhood</h3>
<ul>
<li><strong>Gatto’s experience critiquing a private school curriculum:</strong>
<ul>
<li>While impressed with the school’s environment, two concerns arose:
<ol type="1">
<li>Students were not encouraged to participate in discussions about their own education.</li>
<li>The use of a simplified version of Homer’s “Odyssey” raised concerns about diluting challenging material.</li>
</ol></li>
</ul></li>
<li><strong>The Talking Choo-Choo Analogy:</strong>
<ul>
<li>A talking choo-choo in a workbook symbolizes the trend of simplifying and infantilizing education.</li>
<li>This “German disease” artificially extends childhood and undermines intellectual development.</li>
</ul></li>
<li><strong>Perpetuating Childishness:</strong>
<ul>
<li>This approach creates a dependence on simplified information and a fear of complex ideas.</li>
<li>It fosters a culture of instant gratification and a lack of critical thinking.</li>
</ul></li>
<li><strong>Examples of the Talking Choo-Choo Syndrome:</strong>
<ul>
<li>Slasher films, pornography, fast food, tabloid news.</li>
<li>The glorification of youth and the reluctance to engage with adult complexities.</li>
</ul></li>
<li><strong>Historical Roots:</strong>
<ul>
<li>This strategy of control through infantilization can be traced back to:
<ul>
<li>John Calvin’s “Institutes” (1535)</li>
<li>Baruch Spinoza’s “Tractate” (1670)</li>
<li>Johann Gottlieb Fichte’s educational reforms in 19th-century Prussia.</li>
</ul></li>
</ul></li>
<li><strong>The Welfare State and Infantilization:</strong>
<ul>
<li>The welfare state, while seemingly benevolent, can perpetuate dependence and discourage self-reliance.</li>
</ul></li>
</ul>
</section>
<section id="beatrix-potter-a-counterpoint-to-talking-choo-choo-education" class="level3">
<h3 class="anchored" data-anchor-id="beatrix-potter-a-counterpoint-to-talking-choo-choo-education">Beatrix Potter: A Counterpoint to Talking Choo-Choo Education</h3>
<ul>
<li><strong>Beatrix Potter’s Children’s Stories:</strong>
<ul>
<li>Potter’s stories, though featuring animals, do not shy away from darkness, violence, and death.</li>
<li>This reflects the realities of life and challenges children to confront difficult subjects.</li>
</ul></li>
<li><strong>Embracing Complexity:</strong>
<ul>
<li>Children are drawn to Potter’s work because it acknowledges the complexity of the world, unlike sanitized, “talking choo-choo” narratives.</li>
</ul></li>
<li><strong>Potter’s Educational Philosophy:</strong>
<ul>
<li>Potter believed in exposing children to real-world experiences and encouraging their intellectual curiosity.</li>
<li>She rejected the artificial extension of childhood and the dumbing down of education.</li>
</ul></li>
</ul>
</section>
<section id="alina-del-don-detaching-the-training-wheels-at-age-three" class="level3">
<h3 class="anchored" data-anchor-id="alina-del-don-detaching-the-training-wheels-at-age-three">Alina Del Don: Detaching the Training Wheels at Age Three</h3>
<ul>
<li><strong>Alina Del Don</strong>, a basketball prodigy, displayed remarkable independence at a young age.</li>
<li><strong>Detaching the Training Wheels:</strong>
<ul>
<li>At three years old, she independently removed the training wheels from her bicycle.</li>
<li>This act symbolizes a rejection of limitations and a willingness to embrace challenges.</li>
</ul></li>
<li><strong>Implications for Education:</strong>
<ul>
<li>Del Don’s example highlights the importance of fostering self-reliance and encouraging children to push their boundaries.</li>
</ul></li>
</ul>
</section>
<section id="abandoning-the-illusion-of-extended-childhood" class="level3">
<h3 class="anchored" data-anchor-id="abandoning-the-illusion-of-extended-childhood">Abandoning the Illusion of Extended Childhood</h3>
<ul>
<li><strong>Treat Children as Capable Individuals:</strong>
<ul>
<li>Parents should view their children as capable individuals rather than perpetually dependent “kids.”</li>
<li>This means:
<ul>
<li>Involving them in age-appropriate discussions about family finances, responsibilities, and decision-making.</li>
<li>Encouraging independence and self-sufficiency.</li>
<li>Providing opportunities for real-world experiences and risk-taking.</li>
</ul></li>
</ul></li>
<li><strong>Rejecting Adolescence as a Social Construct:</strong>
<ul>
<li>The concept of “adolescence” is a relatively recent invention that artificially prolongs childhood.</li>
<li>Young people are capable of much more than society gives them credit for.</li>
</ul></li>
</ul>
</section>
<section id="john-latsis-success-without-formal-education" class="level3">
<h3 class="anchored" data-anchor-id="john-latsis-success-without-formal-education">John Latsis: Success Without Formal Education</h3>
<ul>
<li><strong>John Latsis</strong>, a self-made billionaire, achieved extraordinary success without formal education.</li>
<li><strong>From Laborer to Shipping Tycoon:</strong>
<ul>
<li>He started working at age 12, eventually becoming a shipping magnate through hard work, determination, and a keen business sense.</li>
</ul></li>
<li><strong>A Bygone Era:</strong>
<ul>
<li>Latsis’ story, once common, is now rare as schools emphasize specialized employment over entrepreneurialism.</li>
</ul></li>
</ul>
</section>
<section id="tanya-eby-and-george-meehan-triumphs-of-the-unschooled-spirit" class="level3">
<h3 class="anchored" data-anchor-id="tanya-eby-and-george-meehan-triumphs-of-the-unschooled-spirit">Tanya Eby and George Meehan: Triumphs of the Unschooled Spirit</h3>
<ul>
<li><strong>Tanya Eby:</strong>
<ul>
<li>The first woman to circumnavigate the globe solo, overcoming challenges and teaching herself navigation along the way.</li>
<li>Her struggles in traditional schooling led her to seek alternative paths to learning and self-discovery.</li>
</ul></li>
<li><strong>George Meehan:</strong>
<ul>
<li>Completed the longest walk in human history (from Tierra del Fuego to Point Barrow, Alaska) with minimal resources and no formal education beyond the third grade.</li>
<li>His journey exemplifies the resilience, resourcefulness, and determination of the human spirit.</li>
</ul></li>
<li><strong>Lessons from Tanya and George:</strong>
<ul>
<li>Both individuals achieved extraordinary feats outside the confines of formal education.</li>
<li>Their stories challenge conventional notions of what is possible and highlight the importance of self-directed learning.</li>
</ul></li>
</ul>
</section>
<section id="the-cauldron-of-broken-time-the-fragmentation-of-attention" class="level3">
<h3 class="anchored" data-anchor-id="the-cauldron-of-broken-time-the-fragmentation-of-attention">The Cauldron of Broken Time: The Fragmentation of Attention</h3>
<ul>
<li><strong>The Importance of Uninterrupted Time:</strong>
<ul>
<li>Uninterrupted time is crucial for deep thinking, reflection, and the synthesis of information.</li>
</ul></li>
<li><strong>Schools as Interruption Factories:</strong>
<ul>
<li>The school environment is characterized by constant interruptions: bells, announcements, visitors, etc.</li>
</ul></li>
<li><strong>Consequences of Fragmented Attention:</strong>
<ul>
<li>This constant fragmentation hinders concentration, making it difficult for students (and teachers) to engage deeply with material.</li>
</ul></li>
<li><strong>Claire Wolfe’s Insight:</strong>
<ul>
<li>Writer Claire Wolfe emphasizes the importance of “uninterrupted waking time” for meaningful learning and intellectual exploration.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-1" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-1">Conclusion</h3>
<ul>
<li>The current education system, with its emphasis on subordination, disconnection, and the artificial extension of childhood, hinders true learning and personal growth.</li>
<li>It is imperative to challenge these harmful practices and create alternative paths to education that empower individuals to reach their full potential.</li>
</ul>
</section>
</section>
<section id="chapter-8-what-is-education" class="level2">
<h2 class="anchored" data-anchor-id="chapter-8-what-is-education">Chapter 8: What is Education?</h2>
<section id="salters-perspective-europe-as-an-unfathomable-classroom" class="level3">
<h3 class="anchored" data-anchor-id="salters-perspective-europe-as-an-unfathomable-classroom">Salter’s Perspective: Europe as an Unfathomable Classroom</h3>
<ul>
<li><strong>James Salter</strong>, a travel writer, admired Europe and its unique ability to answer Kant’s questions.</li>
<li>Salter believed Europe provided <strong>education</strong>:
<ul>
<li><strong>Not traditional school lessons</strong>, but a deeper understanding of life.</li>
<li><strong>A guide on:</strong>
<ul>
<li><strong>How to endure.</strong></li>
<li><strong>How to appreciate:</strong>
<ul>
<li>Leisure</li>
<li>Food</li>
<li>Love</li>
<li>Conversation</li>
<li>Nakedness</li>
<li>Architecture</li>
<li>Streets</li>
</ul></li>
</ul></li>
<li><strong>A new way of thinking, fresh and insightful.</strong></li>
</ul></li>
<li><strong>Europe’s Impact:</strong>
<ul>
<li><strong>History’s Shadow:</strong> Being surrounded by Europe’s rich history makes one aware of their small place in time.</li>
<li><strong>Knowing nothing is equivalent to having done nothing.</strong></li>
<li><strong>Self-obsession is like “worshipping a dust moat.”</strong></li>
<li><strong>Europe is an “immense and unfathomable classroom,” beyond any catalog or description.</strong></li>
</ul></li>
<li><strong>Salter’s Comparison</strong>: Salter contrasts the vastness of European education with the limitations of traditional schooling.</li>
<li><strong>Challenge to the Reader:</strong> Look at America as Salter did Europe. Did your schooling teach you how we arrived at our current state?</li>
</ul>
</section>
<section id="gattos-testimony-a-scathing-critique-of-the-school-system" class="level3">
<h3 class="anchored" data-anchor-id="gattos-testimony-a-scathing-critique-of-the-school-system">Gatto’s Testimony: A Scathing Critique of the School System</h3>
<ul>
<li><strong>Date:</strong> October 23, 1991</li>
<li><strong>Occasion:</strong> Testimony before the U.S. Senate Committee on Labor and Human Relations</li>
<li><strong>Topic:</strong> The future of schools in the year 2000</li>
<li><strong>Gatto’s Pessimistic View:</strong>
<ul>
<li><strong>Schools in 2000 will likely mirror those of 1990 and 1890.</strong></li>
<li><strong>Schools have resisted meaningful change for over a century.</strong></li>
<li><strong>The current system is deeply flawed.</strong></li>
</ul></li>
</ul>
<section id="a-historical-perspective-1790-vs.-today" class="level4">
<h4 class="anchored" data-anchor-id="a-historical-perspective-1790-vs.-today">A Historical Perspective: 1790 vs.&nbsp;Today</h4>
<ul>
<li><strong>1790:</strong>
<ul>
<li><strong>Education was readily attainable in America.</strong></li>
<li><strong>Schooling was:</strong>
<ul>
<li>Voluntary</li>
<li>Short in duration</li>
<li>Did not monopolize a child’s time</li>
<li>Did not burden families</li>
<li>Did not instill servile habits in the young</li>
<li>Did not indoctrinate with pre-determined thoughts</li>
</ul></li>
<li>Fewer people claiming to provide education resulted in greater freedom to learn.</li>
</ul></li>
<li><strong>Gatto’s Example: In Massachusetts, literacy rates were higher when schooling was voluntary.</strong></li>
<li><strong>Today:</strong>
<ul>
<li>The possibility of obtaining a quality education is threatened by compulsory schooling.</li>
<li>Political roadblocks hinder change:
<ul>
<li>The current system financially benefits those in power.</li>
<li>Schools provide lucrative contracts and jobs, creating conflicts of interest for politicians.</li>
<li>Politicians are beholden to donors with vested interests in maintaining the status quo.</li>
</ul></li>
<li><strong>Gatto’s Assertion:</strong> Genuine change must come from individuals (parents, students, and teachers) who challenge the system.</li>
<li>Homeschooling is a prime example of this rebellion.</li>
<li>The system has had a century to prove itself and has failed.</li>
</ul></li>
</ul>
</section>
<section id="reimagining-education-a-call-for-fundamental-change" class="level4">
<h4 class="anchored" data-anchor-id="reimagining-education-a-call-for-fundamental-change">Reimagining Education: A Call for Fundamental Change</h4>
<ul>
<li><strong>Step 1: Define an Educated Person:</strong>
<ul>
<li>A nationwide debate is needed to establish a clear definition of what constitutes an educated person.</li>
<li>Professional pedagogy has failed to provide a concrete definition beyond vague generalizations.</li>
<li>A shared understanding of educational goals is crucial for meaningful reform.</li>
</ul></li>
<li><strong>Exposing the Fallacy of Standardized Testing:</strong>
<ul>
<li><strong>Current educational emphasis on standardized test scores is misguided.</strong></li>
<li><strong>High test scores do not necessarily translate to real-world competence or success.</strong></li>
<li><strong>Example:</strong>** Many successful individuals (including U.S. presidents and corporate executives) have achieved success despite mediocre test scores.</li>
<li><strong>Inconsistency:</strong> While consumers demand performance data in other areas (e.g., horse racing), they are denied this information when it comes to educators.</li>
<li><strong>Distinction:</strong> High standards are not synonymous with standardized testing.</li>
<li><strong>Newspeak Manipulation:</strong> The public has been conditioned to equate the two.</li>
<li><strong>Gatto’s Proposal:</strong> Schools should guarantee the development of valuable human competencies or lose their power to enforce attendance.</li>
</ul></li>
</ul>
</section>
<section id="gattos-definition-of-an-educated-person-key-characteristics" class="level4">
<h4 class="anchored" data-anchor-id="gattos-definition-of-an-educated-person-key-characteristics">Gatto’s Definition of an Educated Person: Key Characteristics</h4>
<ul>
<li><strong>Time Management:</strong> Educated individuals utilize time effectively and find solace in solitude.</li>
<li><strong>Relationships:</strong> They form meaningful connections due to their understanding of relationship dynamics.</li>
<li><strong>Mortality:</strong> They possess a deep understanding and acceptance of their own mortality, learning and growing from each stage of life.</li>
<li><strong>Values:</strong> They develop a strong personal value system, critically evaluating external influences.</li>
<li><strong>Cultural Awareness:</strong> They are knowledgeable about their own culture and the values of other cultures.</li>
<li><strong>Creativity:</strong> They possess the power to generate new ideas and experiences.</li>
<li><strong>Truth Seekers:</strong> They discover truth independently through critical thinking and evidence, rather than blindly accepting the opinions of others.</li>
<li><strong>Empathy and Service:</strong> They are attuned to the needs of others and find fulfillment in meeting those needs.</li>
<li><strong>Financial Independence:</strong> While capable of earning a living, they do not rely solely on material wealth for happiness.</li>
<li><strong>Balance:</strong> They embrace variety and seek new experiences while recognizing the importance of a stable home and responsibilities.</li>
</ul>
</section>
<section id="a-curriculum-for-true-education-essential-life-themes" class="level4">
<h4 class="anchored" data-anchor-id="a-curriculum-for-true-education-essential-life-themes">A Curriculum for True Education: Essential Life Themes</h4>
<ol type="1">
<li><strong>Birth and Self-Discovery:</strong>
<ul>
<li>Understanding one’s origins, family history, and cultural influences is crucial.</li>
<li><strong>Key Questions:</strong>
<ul>
<li>“Who am I?”</li>
<li>“What are my limits and possibilities?”</li>
<li>“What motivates those around me?”</li>
</ul></li>
</ul></li>
<li><strong>Exploration of the Physical World:</strong>
<ul>
<li>Direct, hands-on experience is essential.</li>
<li><strong>Compulsory schooling hinders this exploration by confining children and relying on abstract concepts.</strong></li>
<li><strong>Missed opportunities for exploration have lasting consequences.</strong></li>
</ul></li>
<li><strong>The Art of Human Connection:</strong>
<ul>
<li>Experiencing various forms of relationships firsthand is vital:
<ul>
<li>Family</li>
<li>Friendships</li>
<li>Companionships</li>
<li>Love</li>
<li>Hate</li>
<li>Community</li>
<li>Networking</li>
</ul></li>
<li><strong>Each form has its own benefits and risks.</strong></li>
<li><strong>Lack of experience leads to emotional stunting.</strong></li>
<li><strong>Criticism of School Socialization:</strong> Schools often confine children to networks, the weakest form of human connection.</li>
</ul></li>
<li><strong>Vocational Exploration:</strong>
<ul>
<li><strong>Central Question:</strong> How can one contribute to society while earning a living?</li>
</ul></li>
<li><strong>The Transition to Adulthood:</strong>
<ul>
<li><strong>Key Questions:</strong>
<ul>
<li>What differentiates an adult from a child?</li>
<li>What responsibilities accompany adulthood?</li>
<li>What leads to maturity and independence?</li>
</ul></li>
</ul></li>
<li><strong>Confronting Mortality:</strong>
<ul>
<li><strong>Death is the final stage in the cycle of life.</strong></li>
<li><strong>Awareness of death gives meaning to life.</strong></li>
<li><strong>Finite time makes choices meaningful.</strong></li>
<li><strong>Legacy:</strong> It is our duty to leave the world as good or better than we found it.</li>
</ul></li>
</ol>
</section>
<section id="dismantling-the-cathedral-of-education" class="level4">
<h4 class="anchored" data-anchor-id="dismantling-the-cathedral-of-education">Dismantling the “Cathedral” of Education</h4>
<ul>
<li><strong>To truly educate, schools must:</strong>
<ul>
<li><strong>Abandon:</strong>
<ul>
<li>The “walled compound” mentality</li>
<li>Reliance on a “priesthood” of certified teachers who prioritize obedience and political correctness</li>
<li>Dependence on the state and its economic interests</li>
</ul></li>
<li><strong>Embrace:</strong>
<ul>
<li>Decentralization</li>
<li>Diversity of thought</li>
<li>Individual empowerment</li>
</ul></li>
</ul></li>
<li><strong>Short-Term Gain vs.&nbsp;Long-Term Loss:</strong> While the current system benefits those in control, it ultimately weakens society, hindering adaptability and progress.</li>
<li><strong>Historical Parallel:</strong> The Soviet Union’s collapse serves as a cautionary tale.</li>
</ul>
</section>
<section id="a-vision-for-a-new-school-decentralized-flexible-and-empowering" class="level4">
<h4 class="anchored" data-anchor-id="a-vision-for-a-new-school-decentralized-flexible-and-empowering">A Vision for a New School: Decentralized, Flexible, and Empowering</h4>
<ul>
<li><strong>Breaking the Monopoly:</strong> Ending compulsory schooling would disrupt the current educational monopoly and:
<ul>
<li>Reduce corruption</li>
<li>Encourage innovation</li>
<li>Empower parents and students</li>
<li>Foster a free market of learning opportunities</li>
</ul></li>
<li><strong>Key Features:</strong>
<ul>
<li><strong>Location:</strong> Learning can take place anywhere, not just within traditional school walls.</li>
<li><strong>Decertified Teaching:</strong> Anyone with valuable skills can share their knowledge, regardless of formal credentials.</li>
<li><strong>Financial Control:</strong> Taxpayer money would be redirected to families, allowing them to choose educational services.</li>
<li><strong>Flexible Learning:</strong>
<ul>
<li>Time commitments</li>
<li>Learning spaces</li>
<li>Study options</li>
<li>Sequencing</li>
</ul></li>
<li><strong>Elimination of Standardized Testing:</strong>
<ul>
<li><strong>Focus on Authentic Assessment:</strong> Replace standardized tests with more meaningful measures of learning.</li>
<li><strong>Reasons for Elimination:</strong>
<ul>
<li>Tests do not accurately reflect real-world skills or character.</li>
<li>They stifle imagination and creativity.</li>
<li>They perpetuate dishonesty.</li>
<li>They are a relic of authoritarian cultures.</li>
<li>They create artificial problems and waste resources.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Addressing the Reading “Problem”:</strong>
<ul>
<li><strong>Natural Learning:</strong> Learning to read is a natural process that typically requires around 30 hours under the right conditions.</li>
<li><strong>Obstacles to Literacy:</strong> The current system, with its emphasis on:
<ul>
<li>Age-segregated classrooms</li>
<li>Forced instruction</li>
<li>Pressure and ranking</li>
<li>Creates a negative association with reading, leading to indifference or aversion.</li>
</ul></li>
</ul></li>
<li><strong>Solution:</strong> A more natural and individualized approach is needed.</li>
</ul>
</section>
<section id="embracing-the-power-of-informal-learning" class="level4">
<h4 class="anchored" data-anchor-id="embracing-the-power-of-informal-learning">Embracing the Power of Informal Learning</h4>
<ul>
<li><strong>The Information Age Paradox:</strong> Despite a lack of formal schooling, millions have learned to navigate the complexities of computers and technology.</li>
<li><strong>Real-World Learning:</strong> Skills like computer literacy and driving are often acquired through self-directed learning, experimentation, and observation.</li>
<li><strong>Lessons from Driving:</strong>
<ul>
<li>Driving involves complex physical and cognitive skills yet is successfully learned by most without formal schooling.</li>
<li>Drivers are not graded; they either pass or fail a competency-based test.</li>
<li>This system highlights trust in individual competence over formal credentials.</li>
</ul></li>
<li><strong>The Illusion of Control:</strong> Schools often take credit for advancements that occur independently.</li>
</ul>
</section>
<section id="conclusion-a-call-to-action" class="level4">
<h4 class="anchored" data-anchor-id="conclusion-a-call-to-action">Conclusion: A Call to Action</h4>
<ul>
<li><strong>The Path Forward:</strong>
<ul>
<li>Recognize the limitations of the current system.</li>
<li>Embrace a more decentralized and individualized approach to education.</li>
<li>Empower parents and students as active participants in the learning process.</li>
</ul></li>
<li><strong>A Call to Leadership:</strong> Gatto challenges Senators to demonstrate courage by challenging the status quo and advocating for meaningful reform.</li>
<li><strong>The Power of “Productive Sabotage”:</strong> Parents, students, and even teachers must work to dismantle the system from within, like “noble termites.”</li>
</ul>
</section>
</section>
<section id="a-grandfathers-wish-education-for-christina" class="level3">
<h3 class="anchored" data-anchor-id="a-grandfathers-wish-education-for-christina">A Grandfather’s Wish: Education for Christina</h3>
<ul>
<li><strong>Education should foster individuality and strength of character.</strong></li>
<li><strong>It should equip individuals to face challenges and embrace their unique paths.</strong></li>
<li><strong>It should provide guiding principles and the courage to confront adversity.</strong></li>
<li><strong>It should foster a deep understanding of life, death, and what truly matters.</strong></li>
</ul>
</section>
</section>
<section id="chapter-9-a-letter-to-my-granddaughter-about-dartmouth" class="level2">
<h2 class="anchored" data-anchor-id="chapter-9-a-letter-to-my-granddaughter-about-dartmouth">Chapter 9: A Letter to My Granddaughter About Dartmouth</h2>
<section id="family-matters" class="level3">
<h3 class="anchored" data-anchor-id="family-matters">Family Matters</h3>
<ul>
<li>Gatto’s granddaughter, Christina, is a rebellious and accomplished individual.
<ul>
<li>Rode her bike on Fifth Avenue in defiance of a city ban.</li>
<li>Captain of a national champion debating team.</li>
<li>Legally changed her name from Gudrun to Christina.</li>
</ul></li>
<li>Gatto comes from a long line of “boat rockers” and contrarians.
<ul>
<li>His wife Janet’s family was outlawed by the British Crown.</li>
<li>His great-great-grandmother from Glenorchy wore a top hat, a symbol of unconventionality.</li>
<li>The outlaw Rob Roy considered Gatto’s wife’s clan to be his own.</li>
</ul></li>
<li>Gatto and his wife Janet were married in a Buddhist temple near Columbia University in New York City.
<ul>
<li>They chose this location because they were both unemployed, broke, and underage for a civil marriage.</li>
<li>The Buddhist temple offered free marriage ceremonies, unlike other religious institutions they approached.</li>
<li>Janet was pregnant with Gatto’s daughter (Christina’s mother) at the time of their marriage.</li>
</ul></li>
<li>Gatto recounts the struggles and triumphs of his ancestors:
<ul>
<li><strong>His grandmother:</strong> Fired from a job for attempting to organize a union.</li>
<li><strong>Gatto:</strong> Fired from a job on Madison Avenue for incompetence.</li>
<li><strong>His great-great-grandfather Giovanni (Italian side):</strong>
<ul>
<li>A Presbyterian, journalist, and Freemason, he faced persecution in early 20th century Italy.</li>
<li>Forced to flee Italy with his wife, Lucrezia, who lost her inheritance and title for marrying him.</li>
<li>Found success in Pittsburgh working for Mellon Bank but died young from an extravagant lifestyle.</li>
<li>Buried in an unmarked grave by Lucrezia for having a mistress.</li>
</ul></li>
<li><strong>His great-grandfather Harry Taylor Zimmer (German side):</strong>
<ul>
<li>Town printer and traveling circus owner in Monongahela, Pennsylvania.</li>
<li>A staunch Republican in a predominantly Democratic town.</li>
<li>Ran for mayor multiple times, using his printing press to launch scathing attacks on opponents.</li>
<li>Openly supported German victory during World War II, making Gatto’s childhood walks to school eventful.</li>
</ul></li>
</ul></li>
<li>Gatto highlights the protective presence of his uncle, Bud Zimmer:
<ul>
<li>The toughest man in town, Bud’s reputation shielded Gatto from bullies.</li>
<li>Bud served as a field officer in World War II, his unit featured in newsreels.</li>
<li>His wartime service earned him a management position at Rockwell’s plant, despite lacking a college degree.</li>
</ul></li>
</ul>
</section>
<section id="dartmouth-college" class="level3">
<h3 class="anchored" data-anchor-id="dartmouth-college">Dartmouth College</h3>
<ul>
<li>Gatto advises his granddaughter, Christina, to reconsider her pursuit of an Ivy League education at Dartmouth.
<ul>
<li>He believes that such institutions promote an illusion of social privilege and limit personal growth.</li>
</ul></li>
<li>He criticizes the modern education system:
<ul>
<li><strong>Promotes a hierarchical view of education:</strong> Elite colleges are falsely touted as the sole gateways to success.</li>
<li><strong>Instills a false sense of urgency:</strong> Students feel pressured to gain acceptance into prestigious colleges, leading to unhealthy competition and anxiety.</li>
<li><strong>Perpetuates social inequality:</strong> Gatto uses George Orwell’s <em>Animal Farm</em> analogy to criticize the elitist mindset prevalent in prestigious institutions.</li>
</ul></li>
<li>He challenges the notion that college guarantees success:
<ul>
<li>Financial success can be achieved through alternative paths.</li>
<li>True fulfillment comes from finding purpose and adding value to society.</li>
</ul></li>
<li>He argues that true education is a personal journey of self-discovery:
<ul>
<li>It’s about developing critical thinking skills and navigating the complexities of the world.</li>
</ul></li>
<li>He outlines eight essential elements of true learning:
<ol type="1">
<li><strong>Self-knowledge:</strong> Understanding one’s character, strengths, weaknesses, and tendencies.</li>
<li><strong>Observation:</strong> Cultivating sharp observational skills to gather accurate information.</li>
<li><strong>Feedback:</strong> Learning to receive and evaluate criticism effectively.</li>
<li><strong>Analysis:</strong> Developing the ability to break down complex problems into manageable components.</li>
<li><strong>Mirroring:</strong> Cultivating empathy and the ability to understand diverse perspectives.</li>
<li><strong>Expression:</strong> Mastering clear and effective communication in both written and spoken forms.</li>
<li><strong>Judgment:</strong> Developing the ability to discern truth from falsehood and make sound decisions.</li>
<li><strong>Adding Value:</strong> Contributing meaningfully to society and every interaction.</li>
</ol></li>
<li>Gatto emphasizes that true learning extends beyond the confines of formal education and requires active engagement with the world.</li>
</ul>
</section>
<section id="the-new-atlantis" class="level3">
<h3 class="anchored" data-anchor-id="the-new-atlantis">The New Atlantis</h3>
<ul>
<li>Gatto argues that the current education system, particularly in elite institutions like Dartmouth, is modeled after Francis Bacon’s <em>The New Atlantis</em>.</li>
<li>He outlines the core principles of Bacon’s vision:
<ul>
<li><strong>Utility over Reflection:</strong> Education should primarily focus on training a workforce for the needs of corporations and government institutions.</li>
<li><strong>Social Control:</strong> Universities should function as instruments to maintain social order and stability.</li>
<li><strong>Surveillance and Control:</strong> Implement systems to monitor and regulate the behavior and aspirations of the masses.</li>
<li><strong>Managed Morality:</strong> Promote a culture of permissiveness in personal morals while emphasizing conformity in professional life.</li>
<li><strong>Co-option of Potential Leaders:</strong> Identify and absorb talented individuals from lower classes into the ruling structure to prevent dissent.</li>
</ul></li>
<li>Gatto argues that this system has led to several negative consequences:
<ul>
<li><strong>Social Unrest:</strong> A growing sense of disillusionment and distrust in leadership due to increasing inequality and lack of opportunity.</li>
<li><strong>Economic Inequality:</strong> The widening gap between the rich and the poor, fueled by corporate greed and the exploitation of workers.</li>
<li><strong>Contingent Labor:</strong> The rise of temporary and insecure employment, creating a precarious workforce without benefits or long-term security.</li>
<li><strong>Lean Production:</strong> The relentless pursuit of efficiency and profit maximization at the expense of worker well-being and job satisfaction.</li>
</ul></li>
<li>Gatto concludes by emphasizing that addressing these issues requires political action and a fundamental shift in societal values rather than relying solely on traditional education systems.
<ul>
<li>He urges his granddaughter to be an agent of change and fight for a more just and equitable society.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-10-incident-at-highland-high" class="level2">
<h2 class="anchored" data-anchor-id="chapter-10-incident-at-highland-high">Chapter 10: Incident at Highland High</h2>
<section id="the-illusion-of-education-and-the-reality-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-illusion-of-education-and-the-reality-of-schooling">The Illusion of Education and the Reality of Schooling</h3>
<ul>
<li>Gatto’s central argument is that <strong>schooling</strong>, as it exists, is not synonymous with <strong>education</strong>.</li>
<li>He urges readers to:
<ul>
<li><strong>Question their own schooling experiences:</strong> Examine the costs and compromises made in the name of education.</li>
<li><strong>See through the illusions schooling perpetuates:</strong> Recognize the disconnect between the promises of schooling and its actual outcomes.</li>
<li><strong>Understand the lasting influence of schooling:</strong> Acknowledge how its structures and ideologies continue to shape our thinking long after formal education ends.</li>
</ul></li>
</ul>
</section>
<section id="schoolings-imperial-ambition" class="level3">
<h3 class="anchored" data-anchor-id="schoolings-imperial-ambition">Schooling’s Imperial Ambition</h3>
<ul>
<li><strong>Schooling’s Expansion:</strong>
<ul>
<li>Originating as a limited endeavor in colonial America (2 hours/day, a few months/year), schooling has steadily expanded its reach.</li>
<li>It now encroaches upon personal time and resists boundaries like summer vacation.</li>
<li>The concept of “<strong>lifelong learning</strong>” often translates to “lifelong schooling,” promoting the idea that more schooling is always the solution.</li>
</ul></li>
<li><strong>Schooling as a False Solution:</strong>
<ul>
<li>Gatto argues that societal issues (incoherence, aimlessness, incompetence, class hatred) often attributed to a lack of schooling are, in fact, exacerbated by it.</li>
<li>More schooling, he contends, cannot fix problems created by the institution itself.</li>
</ul></li>
<li><strong>Schooling’s Assault on Alternative Forms of Development:</strong>
<ul>
<li>Schooling undermines and seeks to supplant other vital sources of growth and learning:
<ul>
<li><strong>Family:</strong> Dismissed as a “retrograde institution” to be replaced by idealized, expert-designed models.</li>
<li><strong>Church:</strong> Seen as a threat to Gattoity of expert opinion and therefore targeted for removal.</li>
<li><strong>Tradition, Ethnic Loyalty, Loyalty to Place:</strong> Deemed obstacles to progress and slated for eradication.</li>
</ul></li>
<li>This systematic dismantling of alternative influences, Gatto argues, cripples individual sovereignty, erodes ideals of liberty, and disrupts the natural transmission of knowledge and values across generations.</li>
</ul></li>
</ul>
</section>
<section id="schooling-vs.-education-key-distinctions" class="level3">
<h3 class="anchored" data-anchor-id="schooling-vs.-education-key-distinctions">Schooling vs.&nbsp;Education: Key Distinctions</h3>
<ul>
<li>Gatto presents several key distinctions between schooling and education:
<ul>
<li><strong>Source of Organization:</strong>
<ul>
<li><strong>Schooling:</strong> Controlled externally through command and control structures.</li>
<li><strong>Education:</strong> Self-directed and driven by internal motivation.</li>
</ul></li>
<li><strong>Connection to Learning Sources:</strong>
<ul>
<li><strong>Schooling:</strong> Isolates students from diverse learning opportunities to maintain administrative efficiency.</li>
<li><strong>Education:</strong> Actively seeks out a rich network of connections – random, intentional, varied, and often unexpected – recognizing that resourcefulness, self-sufficiency, and innovation thrive on diverse inputs.</li>
</ul></li>
<li><strong>Role of Feedback:</strong>
<ul>
<li><strong>Schooling:</strong> Relies on external rules and evaluations, limiting opportunities for independent judgment and self-correction.</li>
<li><strong>Education:</strong> Emphasizes the crucial role of natural feedback loops. Students learn to attend to these loops, not to conform to external dictates, fostering self-reliance and personalized learning pathways.</li>
</ul></li>
<li><strong>Focus of Learning:</strong>
<ul>
<li><strong>Schooling:</strong> Prioritizes subject knowledge and specialization, aiming to produce efficient clerks for predefined roles within existing systems.</li>
<li><strong>Education:</strong> Values broad contexts and connections between disciplines, recognizing that true understanding and innovation often emerge from cross-fertilization of ideas.
<ul>
<li>Example: John Cancius, a non-specialist and college dropout, developed a breakthrough cancer treatment precisely because he wasn’t confined by specialized knowledge.</li>
</ul></li>
</ul></li>
<li><strong>Approach to Knowledge:</strong>
<ul>
<li><strong>Schooling:</strong> Emphasizes memorization and acceptance of established truths, discouraging critical thinking.</li>
<li><strong>Education:</strong> Cultivates a state of internal debate and questioning, constantly seeking to challenge and refine existing knowledge.
<ul>
<li>This echoes Schumpeter’s concept of “<strong>creative destruction</strong>” – the driving force of capitalism – where questioning established norms and seeking better alternatives fuels progress.</li>
</ul></li>
</ul></li>
<li><strong>Impact on Well-being:</strong>
<ul>
<li>Gatto cites the <strong>International Happiness Survey</strong>, which consistently identifies three key factors for a happy life:
<ul>
<li>Good relationships.</li>
<li>Good health.</li>
<li>Satisfying work.</li>
</ul></li>
<li><strong>Schooling, however, often undermines these factors:</strong>
<ul>
<li>It promotes unhealthy lifestyles and offers little support for developing strong relationships.</li>
<li>Tracking systems and segregation by background exacerbate class prejudice, hindering relationships across difference.</li>
<li>The work imposed rarely connects with the genuine interests and passions of young people.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="a-dark-force-at-work" class="level3">
<h3 class="anchored" data-anchor-id="a-dark-force-at-work">A Dark Force at Work?</h3>
<ul>
<li>Gatto acknowledges the potential for criticism: Are his views exaggerated? Is schooling not an essential institution with flaws that can be rationally addressed?</li>
<li>He counters by suggesting the presence of a “<strong>dark force</strong>” – a deliberate, hidden agenda operating within the institution of schooling.</li>
<li>He argues that without exposing and confronting this hidden force, any talk of “school reform” is futile.</li>
<li>To support his claim, he presents three “hair-raising school stories” designed to illustrate the seemingly irrational and even sinister nature of schooling’s influence:
<ul>
<li>The incidents described are meant to raise questions about the true motives and mechanisms of power at play within the education system.</li>
</ul></li>
</ul>
</section>
<section id="incident-at-nuremberg-homeschooling-as-a-threat" class="level3">
<h3 class="anchored" data-anchor-id="incident-at-nuremberg-homeschooling-as-a-threat">Incident at Nuremberg: Homeschooling as a Threat</h3>
<ul>
<li><strong>Date:</strong> January 29, 2008</li>
<li><strong>Location:</strong> Nuremberg, Germany</li>
<li><strong>Victim:</strong> Melissa Busekros, a 16-year-old girl</li>
<li><strong>Event:</strong>
<ul>
<li>Melissa is forcibly removed from her home by 15 police officers and city officials.</li>
<li>Her “crime” is homeschooling, a practice outlawed in Germany since 1937 under the Nazi regime.</li>
</ul></li>
<li><strong>Author’s Response:</strong>
<ul>
<li>He expresses his disgust by writing to the German ambassador in Washington, highlighting the disturbing parallels between contemporary Germany and its Nazi past.</li>
</ul></li>
<li><strong>Details of the Incident:</strong>
<ul>
<li>Despite no history of behavioral issues, Melissa is subjected to a 240-minute psychiatric interrogation focused solely on her reasons for homeschooling.</li>
<li>The interrogation concludes that Melissa suffers from “school phobia,” a dubious diagnosis used to justify the forceful intervention.</li>
<li>German authorities cite Melissa’s “delayed development” by one year as evidence of harm, despite lacking any internationally recognized standard for such assessment.</li>
<li>The court order authorizes the forceful removal of Melissa, deeming it necessary to protect her from her parents’ “illegal conduct” of homeschooling.</li>
<li>The German Education Authority vows to “bring convictions of the family into line,” employing language reminiscent of totalitarian regimes.</li>
</ul></li>
<li><strong>Author’s Analysis:</strong>
<ul>
<li>He questions the reasoning, philosophy, and values driving such extreme measures against a peaceful family exercising their right to choose an alternative educational path.</li>
<li>He draws parallels between this incident and Germany’s dark history of persecution, from witch hunts to the Holocaust, suggesting a dangerous pattern of suppressing individual liberty and enforcing conformity through state power.</li>
<li>He criticizes the German education system’s rigid adherence to rules and its stifling of individual initiative, citing the ThyssenKrupp steel plant debacle as evidence of its negative economic consequences.</li>
</ul></li>
<li><strong>Outcome:</strong>
<ul>
<li>Gatto’s letter to the German ambassador receives no reply.</li>
<li>The incident highlights the extreme measures employed to enforce compulsory schooling and the silencing of dissenting voices.</li>
</ul></li>
</ul>
</section>
<section id="incident-at-highland-high-suppressing-inconvenient-truths" class="level3">
<h3 class="anchored" data-anchor-id="incident-at-highland-high-suppressing-inconvenient-truths">Incident at Highland High: Suppressing Inconvenient Truths</h3>
<ul>
<li><strong>Date:</strong> March 25, 2004</li>
<li><strong>Location:</strong> Highland High School, Rockland County, New York</li>
<li><strong>Event:</strong>
<ul>
<li>Gatto is invited to speak at Highland High by school board member John Jankowicz, who is concerned about the negative effects of the school’s rigid, test-driven approach to education.</li>
</ul></li>
<li><strong>Gatto’s Observations:</strong>
<ul>
<li>He notes the affluence of the school and the students’ sense of entitlement, masking a deeper lack of intellectual curiosity and critical thinking skills.</li>
<li>He recognizes the pervasive climate of fear and dishonesty surrounding college admissions, used as a tool to control student behavior.</li>
</ul></li>
<li><strong>Gatto’s Talk:</strong>
<ul>
<li>He decides to address the students’ anxieties by deconstructing the myths surrounding college admissions, using real-world examples to challenge their assumptions.</li>
<li>He presents evidence that many successful individuals, including industry leaders, writers, and even politicians, did not conform to the traditional model of academic success.</li>
<li>He cites examples of college dropouts who have achieved extraordinary things, challenging the notion that elite college acceptance is the only path to a meaningful life.</li>
<li>He encourages students to question Gattoity of school officials and to demand transparency regarding their own educators’ academic records.</li>
<li>He shares information about the admission policies of prestigious universities, emphasizing that factors beyond grades and test scores, such as initiative, creativity, and real-world experience, are highly valued.</li>
<li>He presents Richard Branson’s entrepreneurial success as an example of a high school dropout who defied expectations and achieved extraordinary things.</li>
</ul></li>
<li><strong>Police Intervention:</strong>
<ul>
<li>In the midst of Gatto’s calm and factual presentation, a police detail suddenly enters the auditorium and orders everyone to leave.</li>
<li>The officer in charge uses a bullhorn to assert control, creating a deliberately intimidating atmosphere.</li>
</ul></li>
<li><strong>Aftermath:</strong>
<ul>
<li>Gatto learns that the superintendent, McCarthy, deemed the talk “inflammatory” and called the police to shut it down.</li>
<li>This extreme reaction, despite Gatto’s calm demeanor and factual content, suggests a deep-seated resistance to any challenge of the established schooling narrative.</li>
<li>Gatto’s scheduled evening talk for parents is also canceled, further demonstrating the school’s determination to suppress dissenting views.</li>
</ul></li>
<li><strong>Media Coverage and Silence:</strong>
<ul>
<li>The local newspaper, the Mid-Hudson Highland Post, publishes a sanitized account of the incident, omitting any mention of the police intervention.</li>
<li>The superintendent falsely claims that Gatto showed a “violent film,” further highlighting the school’s dishonest attempts to control the narrative.</li>
<li>Gatto’s subsequent attempts to gather perspectives from the superintendent, principal, parents’ association, and student newspaper are met with complete silence.</li>
</ul></li>
<li><strong>Analysis:</strong>
<ul>
<li>The incident at Highland High demonstrates the power of fear and control within the school system.</li>
<li>It shows how easily authorities can silence dissenting voices and suppress information that challenges the status quo.</li>
<li>The lack of transparency and accountability further reinforces the idea of a hidden agenda at work.</li>
</ul></li>
</ul>
</section>
<section id="incident-at-walden-crushing-local-control-and-common-sense" class="level3">
<h3 class="anchored" data-anchor-id="incident-at-walden-crushing-local-control-and-common-sense">Incident at Walden: Crushing Local Control and Common Sense</h3>
<ul>
<li><strong>Date:</strong> 1991</li>
<li><strong>Location:</strong> Walden, Vermont, a rural town with four historic one-room schoolhouses</li>
<li><strong>Event:</strong>
<ul>
<li>The state of Vermont threatens to close Walden’s beloved one-room schools, citing the cost of making them wheelchair accessible as prohibitive.</li>
<li>This is despite the schools’ strong academic performance, the community’s satisfaction, and the children’s evident well-being.</li>
<li>A plan is put forward to build a centralized concrete block school and bus students from up to 50 miles away.</li>
</ul></li>
<li><strong>Author’s Involvement:</strong>
<ul>
<li>He is invited to Walden to advocate for the preservation of the one-room schools.</li>
<li>He reviews the state’s proposal and finds the estimated costs for renovations to be grossly inflated.</li>
<li>He seeks expert testimony from a renowned architect familiar with construction costs in Vermont.</li>
</ul></li>
<li><strong>Expert Opinion and Fear:</strong>
<ul>
<li>The architect confirms that the state’s estimates are ten times higher than the actual cost, suggesting a deliberate attempt to mislead the community.</li>
<li>He reveals that the contract for the new school has likely already been promised to a specific firm, further highlighting the corruption at play.</li>
<li>However, the architect refuses to testify publicly, fearing professional repercussions from the state government.</li>
</ul></li>
<li><strong>Outcome:</strong>
<ul>
<li>Despite Gatto’s best efforts and the community’s desire to preserve their schools, the state’s repeated threats and the climate of fear prove too powerful.</li>
<li>Walden reluctantly approves the bond issue, goes into debt, and builds the centralized school, sacrificing their unique educational environment and sense of community control.</li>
</ul></li>
<li><strong>Analysis:</strong>
<ul>
<li>The Walden incident demonstrates how a powerful entity like the state government can exploit its authority and financial leverage to impose its will on a community.</li>
<li>It highlights the corrupt practices often used to justify decisions made behind closed doors, benefiting select interests at the expense of local needs and desires.</li>
<li>The architect’s fear of speaking out reveals the insidious reach of such systems and the potential for silencing dissent even within professional circles.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-the-urgent-need-for-subversion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-the-urgent-need-for-subversion">Conclusion: The Urgent Need for Subversion</h3>
<ul>
<li>Gatto uses these three incidents to illustrate the pervasive and often hidden forces at play within the institution of schooling.</li>
<li>He argues that these forces prioritize control, conformity, and the maintenance of power over the genuine needs and well-being of students.</li>
<li>He concludes that true education requires a conscious effort to subvert the harmful aspects of schooling, to question its assumptions, and to seek out alternative paths to knowledge and personal fulfillment.</li>
<li>Gatto issues a call to action:
<ul>
<li>Recognize the dark side of schooling and its impact on individuals and society.</li>
<li>Actively resist its attempts to limit thinking, creativity, and individual potential.</li>
<li>Seek out alternative educational experiences that nurture curiosity, critical thinking, and a love of learning.</li>
</ul></li>
<li>Gatto believes that by understanding and challenging the hidden agendas of schooling, individuals can reclaim their right to a meaningful and empowering education. He leaves the reader with the responsibility to carry on this fight:
<ul>
<li><blockquote class="blockquote">
<p>“But you’ll have to convince yourself of the substance of my allegation, that some sort of dark matter, some powerful but invisible force is at work in schooling. If you are to become strong enough to defend yourself and your family, I can’t do the work for you. You can’t memorize my conclusions.”</p>
</blockquote></li>
<li><blockquote class="blockquote">
<p>“Because you choose not to see the dark world school represents, because you only pay attention to its stupidities, it gets worse all the time.”</p>
</blockquote></li>
<li><blockquote class="blockquote">
<p>“Do I mean to imply that Highland School is the worst school in America? Hardly. For all I know, it is one of the best. Certainly it’s one of the richest. What you need to ask yourself is how many school districts from coast to coast find truth unbearable because it gets in the way of their real mission.”</p>
</blockquote></li>
<li><blockquote class="blockquote">
<p>“Unless the ends of the operation are put on public trial, and its sexual relationship with economics and social management exposed to the light and ended, each reform effort will only be another illusion, another room added to the National House of Mirrors.”</p>
</blockquote></li>
<li><blockquote class="blockquote">
<p>“Our government thinks some companies are too big to be allowed to fail, and that schooling is too important to allow education to get in its way.”</p>
</blockquote></li>
</ul></li>
</ul>
</section>
</section>
<section id="afterword-invitation-to-an-open-conspiracy" class="level2">
<h2 class="anchored" data-anchor-id="afterword-invitation-to-an-open-conspiracy">Afterword: Invitation to an Open Conspiracy</h2>
<section id="afterward" class="level3">
<h3 class="anchored" data-anchor-id="afterward">Afterward</h3>
<ul>
<li><strong>Verse:</strong> Mark 9:42</li>
<li><strong>Content:</strong> Whoever causes a child to sin would be better off thrown into the sea with a millstone around their neck.</li>
</ul>
</section>
<section id="invitation-to-an-open-conspiracy-the-bartleby-project" class="level3">
<h3 class="anchored" data-anchor-id="invitation-to-an-open-conspiracy-the-bartleby-project">Invitation to an Open Conspiracy: The Bartleby Project</h3>
<ul>
<li><strong>Source:</strong> <em>Weapons of Mass Instruction</em> by John Taylor Gatto (2008)</li>
</ul>
<section id="the-purpose-of-the-bartleby-project" class="level4">
<h4 class="anchored" data-anchor-id="the-purpose-of-the-bartleby-project">The Purpose of the Bartleby Project</h4>
<ul>
<li><strong>Goal:</strong> Destroy the standardized testing industry.</li>
<li><strong>Method:</strong> Open conspiracy with individuals acting as independent unit commanders.</li>
<li><strong>Reasoning:</strong>
<ul>
<li>Standardized testing is more damaging than beneficial to individuals and society.</li>
<li>Test destruction, not reform, is the only solution.</li>
</ul></li>
</ul>
</section>
<section id="the-problems-with-standardized-testing" class="level4">
<h4 class="anchored" data-anchor-id="the-problems-with-standardized-testing">The Problems With Standardized Testing</h4>
<ul>
<li><strong>Ineffectiveness:</strong>
<ul>
<li>Information generated is unreliable and misleading.</li>
<li>Data is unused in adult life.</li>
<li>No correlation between test performance and future success.</li>
</ul></li>
<li><strong>Damaging Effects:</strong>
<ul>
<li>Significant personal and social harm to students.</li>
<li>Ranking system creates winners and losers, fostering a sense of inferiority.</li>
</ul></li>
<li><strong>Tool of Social Control:</strong>
<ul>
<li>Weaponized by social engineers to control institutional schooling.</li>
<li>Used to classify individuals as human resources.</li>
</ul></li>
<li><strong>Waste of Resources:</strong>
<ul>
<li>Hundreds of millions of school days lost to test preparation, administration, and recovery.</li>
<li>Tens of billions of dollars diverted to private companies.</li>
</ul></li>
</ul>
</section>
<section id="the-outlaw-ethic-of-institutional-schooling" class="level4">
<h4 class="anchored" data-anchor-id="the-outlaw-ethic-of-institutional-schooling">The Outlaw Ethic of Institutional Schooling</h4>
<ul>
<li><strong>Example:</strong> New York City Public Schools’ failure to provide mandated physical education.
<ul>
<li>Only 1 in 25 students receive the legal minimum of 24 minutes of physical education per day (New York Sun, May 8, 2008).</li>
<li>Parents concerned about lack of physical education, but have no significant voice in school decisions.</li>
</ul></li>
<li><strong>Consequences:</strong>
<ul>
<li>National epidemic of childhood obesity and diabetes.</li>
<li>Physical and psychological harm to students.</li>
</ul></li>
<li><strong>Institutional Hypocrisy:</strong>
<ul>
<li>NYC Board of Education claims to be “beginning to realize” the importance of student health after a century of control (New York Sun, May 8, 2008).</li>
<li>Schools continue to prioritize confinement over physical activity.</li>
</ul></li>
<li><strong>Conclusion:</strong>
<ul>
<li>Institutional schooling operates with an outlaw ethic, disregarding student well-being.</li>
<li>Schools will act against student and faculty interests under pressure.</li>
</ul></li>
</ul>
</section>
<section id="the-decline-of-american-education" class="level4">
<h4 class="anchored" data-anchor-id="the-decline-of-american-education">The Decline of American Education</h4>
<ul>
<li><strong>Post-World War II:</strong> Schooling replaced education.
<ul>
<li>Standardization based on the German model.</li>
<li>Standardized testing implemented and gradually gained importance (fully implemented by 1963).</li>
</ul></li>
<li><strong>1950s:</strong> Curriculum dumbed down, teachers became less connected to the community.</li>
<li><strong>1960s:</strong> Test scores become the primary measure of excellence.</li>
<li><strong>1970s:</strong> Schools become a lucrative business, further incentivizing the status quo.
<ul>
<li>Eccentricity in teaching is persecuted.</li>
<li>Tracking systems solidify the division of students based on perceived ability.</li>
<li>Curriculum for affluent students is equivalent to that of working-class students in the 1940s-50s.</li>
</ul></li>
</ul>
</section>
<section id="the-assumption-of-inherent-inferiority" class="level4">
<h4 class="anchored" data-anchor-id="the-assumption-of-inherent-inferiority">The Assumption of Inherent Inferiority</h4>
<ul>
<li><strong>Prevalent Belief:</strong> The majority of the population is inherently incapable of intellectual growth beyond a mental age of 12.</li>
<li><strong>Proponents:</strong>
<ul>
<li>Abraham Lincoln ridiculed this view in 1859 (Richard Hofstadter’s <em>Anti-Intellectualism in American Life</em>).</li>
<li>Edward Thorndike, inventor of educational psychology at Columbia Teachers College.</li>
<li>H.H. Goddard, Chairman of the Psychology Department at Princeton.</li>
<li>James Bryant Conant, President of Harvard.</li>
<li>Major private foundations (e.g., Rockefeller, Carnegie).</li>
<li>Historical figures like Plato, John Calvin, Benedict Spinoza, Johann Fichte, Charles Darwin, and Francis Galton.</li>
</ul></li>
<li><strong>Consequences:</strong>
<ul>
<li>Justification for limited educational expectations.</li>
<li>Acceptance of rigid social class systems.</li>
</ul></li>
<li><strong>American Exceptionalism (Pre-Civil War):</strong>
<ul>
<li>Ordinary citizens controlled education.</li>
<li>Egalitarian ethic prevailed.</li>
<li>Self-education thrived, enabling social mobility.</li>
</ul></li>
<li><strong>Post-WWII Shift:</strong>
<ul>
<li>The German model eroded opportunities for escape from the system.</li>
<li>Decline in national prospects and material wealth due to the suppression of individual potential.</li>
</ul></li>
</ul>
</section>
<section id="the-power-of-citizen-action-and-the-bartleby-solution" class="level4">
<h4 class="anchored" data-anchor-id="the-power-of-citizen-action-and-the-bartleby-solution">The Power of Citizen Action and The Bartleby Solution</h4>
<ul>
<li><strong>Foundational Rights:</strong> American founding documents guarantee inalienable rights, including liberty, that are undermined by compulsory schooling.</li>
<li><strong>Need for Drastic Action:</strong> Revitalizing education requires a complete rejection of government control (Alexander Sholzhenitsyn, “How to Revitalize Russia,” <em>Pravda</em>, September 18, 1988).</li>
<li><strong>The Bartleby Solution:</strong>
<ul>
<li>Inspired by Herman Melville’s short story “Bartleby, the Scrivener” (1853).
<ul>
<li>Bartleby, a copyist, exercises passive resistance by responding to requests with, “I would prefer not to.”</li>
<li>This simple act disrupts the workplace and exposes the limitations of control.</li>
</ul></li>
<li>Students are called upon to peacefully refuse standardized tests.</li>
<li>Write “I would prefer not to take this test” on the test forms.</li>
</ul></li>
</ul>
</section>
<section id="implementing-the-bartleby-project" class="level4">
<h4 class="anchored" data-anchor-id="implementing-the-bartleby-project">Implementing the Bartleby Project</h4>
<ul>
<li><strong>Decentralized Structure:</strong>
<ul>
<li>No formal organization or leadership to prevent co-option or corruption.</li>
<li>Individuals act independently, guided by the shared goal.</li>
</ul></li>
<li><strong>Target Audience:</strong> 60 million American students.</li>
<li><strong>Messaging:</strong>
<ul>
<li>Tests are unnecessary and harmful to education.</li>
<li>Students have the right to refuse.</li>
</ul></li>
<li><strong>Anticipated Challenges:</strong>
<ul>
<li>Intimidation and threats of retribution from authorities.</li>
<li>Denial of college admissions (unlikely due to colleges needing students).</li>
</ul></li>
</ul>
</section>
<section id="the-success-of-bartleby-moments" class="level4">
<h4 class="anchored" data-anchor-id="the-success-of-bartleby-moments">The Success of “Bartleby Moments”</h4>
<ul>
<li><strong>Historical Examples of Citizen-Led Change:</strong>
<ul>
<li>The end of the Vietnam War.</li>
<li>The fall of the Berlin Wall.</li>
<li>The collapse of the Soviet Union.</li>
</ul></li>
<li><strong>Common Thread:</strong> Peaceful, persistent resistance by ordinary people.</li>
</ul>
</section>
<section id="the-future-of-education-embracing-the-bartleby-spirit" class="level4">
<h4 class="anchored" data-anchor-id="the-future-of-education-embracing-the-bartleby-spirit">The Future of Education: Embracing the Bartleby Spirit</h4>
<ul>
<li><strong>Smith College’s Decision (May 27, 2008):</strong>
<ul>
<li>No longer requiring SAT scores for admission.</li>
<li>Prioritizing writing, character, talent, and extracurricular achievements.</li>
<li>No decline in academic ability observed.</li>
</ul></li>
<li><strong>Call to Action:</strong>
<ul>
<li>Reject compromise.</li>
<li>Embrace the power of “I would prefer not to.”</li>
<li>Students must lead the way in dismantling the testing empire and reclaiming true education.</li>
</ul></li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>education</category>
  <category>history</category>
  <guid>https://christianjmills.com/posts/weapons-of-mass-instruction-book-notes/</guid>
  <pubDate>Sun, 25 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 15: Modal - Simple Scalable Serverless Services</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li><strong>Speaker:</strong> Charles (<a href="https://twitter.com/charles_irl"><span class="citation" data-cites="charles_irl">@charles_irl</span></a> on Twitter)</li>
<li><strong>Topic:</strong> A deeper dive into Modal, focusing on its broader applications beyond fine-tuning LLMs.</li>
<li><strong>Slides:</strong> <a href="https://docs.google.com/presentation/d/14uDnzd06j9i0zAQ3lTmB7QHBSO45BIsVGUZBZ3HKxGo/edit#slide=id.g2c7588f453b_0_272">Simple Scalable Serverless Services</a></li>
</ul>
</section>
<section id="modal-overview" class="level2">
<h2 class="anchored" data-anchor-id="modal-overview">Modal Overview</h2>
<section id="modal-vision-scalable-cost-efficient-serverless-services" class="level3">
<h3 class="anchored" data-anchor-id="modal-vision-scalable-cost-efficient-serverless-services">Modal Vision: Scalable, Cost-Efficient, Serverless Services</h3>
<ul>
<li>Modal’s vision is to enable the deployment of scalable services that are cost-efficient and serverless, all while being simple and easy to use.</li>
</ul>
</section>
<section id="defining-scalable-services" class="level3">
<h3 class="anchored" data-anchor-id="defining-scalable-services">Defining “Scalable Services”</h3>
<section id="three-key-service-requirements-inputoutput-storage-compute" class="level4">
<h4 class="anchored" data-anchor-id="three-key-service-requirements-inputoutput-storage-compute">Three Key Service Requirements: Input/Output, Storage, Compute</h4>
<ol type="1">
<li><strong>Input/Output:</strong> Connecting the service to the outside world and its information.
<ul>
<li>This enables services to receive input and provide output over networks, unlike isolated scripts or notebooks.</li>
</ul></li>
<li><strong>Storage:</strong> Preserving information for later use.
<ul>
<li>Databases and file storage are crucial for storing and retrieving data within the service.</li>
</ul></li>
<li><strong>Compute:</strong> Manipulating and processing information.
<ul>
<li>Even simple storage solutions benefit from compute capabilities for efficient access and retrieval.</li>
</ul></li>
</ol>
</section>
<section id="scalability-as-table-stakes" class="level4">
<h4 class="anchored" data-anchor-id="scalability-as-table-stakes">Scalability as Table Stakes</h4>
<ul>
<li>Modern services are expected to scale to handle:
<ul>
<li>Global user bases accessing services concurrently.</li>
<li>Massive data storage needs, potentially reaching petabytes or more.</li>
<li>Computationally intensive tasks distributed across multiple machines.</li>
</ul></li>
</ul>
</section>
<section id="challenges-and-importance-of-scalability" class="level4">
<h4 class="anchored" data-anchor-id="challenges-and-importance-of-scalability">Challenges and Importance of Scalability</h4>
<ul>
<li>Failing to scale can lead to:
<ul>
<li>Service outages when traffic surges.</li>
<li>Poor user experiences due to slow response times.</li>
</ul></li>
</ul>
</section>
<section id="distributed-systems-for-scalability" class="level4">
<h4 class="anchored" data-anchor-id="distributed-systems-for-scalability">Distributed Systems for Scalability</h4>
<ul>
<li>Scalability is typically achieved through distributed systems, spreading the workload across numerous machines and data centers.</li>
<li>However, building and managing distributed systems is complex and challenging.</li>
</ul>
</section>
</section>
<section id="modals-solution-simple-scalable-services-with-python" class="level3">
<h3 class="anchored" data-anchor-id="modals-solution-simple-scalable-services-with-python">Modal’s Solution: Simple Scalable Services with Python</h3>
<ul>
<li>Modal aims to simplify the creation of scalable services using Python.</li>
</ul>
<section id="pythonic-tools-for-building-services" class="level4">
<h4 class="anchored" data-anchor-id="pythonic-tools-for-building-services">Pythonic Tools for Building Services</h4>
<ul>
<li><strong>Web Endpoints and Servers:</strong> Easily define web endpoints and servers that scale without complex configurations.
<ul>
<li>Modal handles the complexities of distribution and scaling, requiring minimal configuration from the developer.</li>
</ul></li>
<li><strong>Storage Options:</strong>
<ul>
<li><strong>Caching and Distributed Storage:</strong> Modal provides distributed dictionaries and queues for efficient inter-process communication in scaled environments.</li>
<li><strong>Volumes:</strong> Abstract away the complexities of distributed file systems, offering a local file system interface for storing data like weights and datasets.</li>
</ul></li>
<li><strong>Compute with Python Functions:</strong> Python functions serve as the fundamental units of work in Modal.
<ul>
<li>Define functions that execute upon endpoint requests or as cron jobs.</li>
</ul></li>
</ul>
</section>
</section>
<section id="modal-dashboard-overview" class="level3">
<h3 class="anchored" data-anchor-id="modal-dashboard-overview">Modal Dashboard Overview</h3>
<section id="model-inference-function-example" class="level4">
<h4 class="anchored" data-anchor-id="model-inference-function-example">Model Inference Function Example</h4>
<ul>
<li>Modal’s dashboard visualizes resource usage for running functions.</li>
<li>Example: A model inference function triggered by user requests, scaling resources like CPU, memory, and GPU usage based on demand.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/images/model-inference-function-example.png" class="img-fluid figure-img"></p>
<figcaption>Model Inference Function Example</figcaption>
</figure>
</div>
</section>
<section id="scaling-up-and-down-resources" class="level4">
<h4 class="anchored" data-anchor-id="scaling-up-and-down-resources">Scaling Up and Down Resources</h4>
<ul>
<li>Modal dynamically adjusts resource allocation based on real-time needs, ensuring optimal performance and cost efficiency.</li>
</ul>
</section>
<section id="handling-multiple-inputs" class="level4">
<h4 class="anchored" data-anchor-id="handling-multiple-inputs">Handling Multiple Inputs</h4>
<ul>
<li>Functions can be designed to handle multiple inputs concurrently, maximizing resource utilization.</li>
</ul>
</section>
<section id="cron-jobs-with-modal" class="level4">
<h4 class="anchored" data-anchor-id="cron-jobs-with-modal">Cron Jobs with Modal</h4>
<ul>
<li>Schedule periodic function execution for tasks like:
<ul>
<li>Regularly displaying generated content.</li>
<li>Pulling data from production databases to data warehouses.</li>
<li>Performing regular data analysis.</li>
<li>Fine-tuning and retraining models on a cadence.</li>
<li>Rerunning evaluations with live user data.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/images/cron-jobs-with-modal.png" class="img-fluid figure-img"></p>
<figcaption>Cron Jobs with Modal</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="qa-session-1" class="level2">
<h2 class="anchored" data-anchor-id="qa-session-1">Q&amp;A Session 1</h2>
<section id="database-service-availability" class="level4">
<h4 class="anchored" data-anchor-id="database-service-availability">Database Service Availability</h4>
<ul>
<li>Modal does not currently offer a managed database service, particularly serverless Postgres.</li>
</ul>
</section>
<section id="challenges-of-serverless-postgres" class="level4">
<h4 class="anchored" data-anchor-id="challenges-of-serverless-postgres">Challenges of Serverless Postgres</h4>
<ul>
<li>Two main types of databases:
<ul>
<li><strong>OLTP (Online Transaction Processing):</strong> Difficult to scale due to row-level operations and complex joins.</li>
<li><strong>OLAP (Online Analytical Processing):</strong> More straightforward to run on Modal using examples with tools like DuckDB and parquet files stored in S3.</li>
</ul></li>
</ul>
</section>
<section id="running-analytical-workloads-on-modal" class="level4">
<h4 class="anchored" data-anchor-id="running-analytical-workloads-on-modal">Running Analytical Workloads on Modal</h4>
<ul>
<li>Modal provides examples for running analytical workloads:
<ul>
<li>Downloading parquet files from S3.</li>
<li>Performing analysis using tools like DuckDB.</li>
</ul></li>
</ul>
</section>
<section id="challenges-of-scaling-transaction-processing" class="level4">
<h4 class="anchored" data-anchor-id="challenges-of-scaling-transaction-processing">Challenges of Scaling Transaction Processing</h4>
<ul>
<li>Distributed transaction processing databases are more challenging to build and scale effectively.</li>
</ul>
</section>
<section id="recommendations-for-serverless-postgres-neon-superbase" class="level4">
<h4 class="anchored" data-anchor-id="recommendations-for-serverless-postgres-neon-superbase">Recommendations for Serverless Postgres: Neon, Superbase</h4>
<ul>
<li>For serverless Postgres, Modal recommends using external services like <a href="https://neon.tech/">Neon</a> or <a href="https://www.superbase.com/">Superbase</a>, which integrate well with Modal’s serverless API apps.</li>
</ul>
</section>
</section>
<section id="storage-in-modal" class="level2">
<h2 class="anchored" data-anchor-id="storage-in-modal">Storage in Modal</h2>
<section id="importance-of-data-storage" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-data-storage">Importance of Data Storage</h3>
<ul>
<li>Data storage is paramount, often defining the value of applications.</li>
</ul>
</section>
<section id="focus-on-long-term-storage" class="level3">
<h3 class="anchored" data-anchor-id="focus-on-long-term-storage">Focus on Long-Term Storage</h3>
<ul>
<li>This section emphasizes long-term storage solutions rather than in-memory dictionaries and queues.</li>
</ul>
</section>
<section id="file-system-abstractions-volumes" class="level3">
<h3 class="anchored" data-anchor-id="file-system-abstractions-volumes">File System Abstractions: Volumes</h3>
<section id="use-cases-storing-weights-datasets" class="level4">
<h4 class="anchored" data-anchor-id="use-cases-storing-weights-datasets">Use Cases: Storing Weights, Datasets</h4>
<ul>
<li>Volumes provide a distributed file system abstraction, ideal for storing:
<ul>
<li>Model weights.</li>
<li>Datasets, including large ones (terabyte-scale or even low petabyte-scale).</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/images/storage-volume.png" class="img-fluid figure-img"></p>
<figcaption>Storage Volume</figcaption>
</figure>
</div>
</section>
<section id="examples-of-stored-volumes" class="level4">
<h4 class="anchored" data-anchor-id="examples-of-stored-volumes">Examples of Stored Volumes</h4>
<ul>
<li>Model weights from Axolotl fine-tuning runs.</li>
<li>CIFAR-10 data and models.</li>
<li>Raw Wikipedia dataset from Hugging Face Datasets in Arrow file format.</li>
</ul>
</section>
<section id="handling-large-datasets" class="level4">
<h4 class="anchored" data-anchor-id="handling-large-datasets">Handling Large Datasets</h4>
<ul>
<li>Modal offers examples for storing and working with very large datasets on the order of terabytes or even low petabytes.</li>
</ul>
</section>
<section id="volumes-optimized-for-write-once-read-many-workloads" class="level4">
<h4 class="anchored" data-anchor-id="volumes-optimized-for-write-once-read-many-workloads">Volumes: Optimized for Write Once, Read Many Workloads</h4>
<ul>
<li>Modal’s volumes are designed for workloads where data is written infrequently but read frequently.</li>
<li>This design choice optimizes for:
<ul>
<li>Datasets that are not frequently overwritten.</li>
<li>Model weights where new versions are written, but existing versions are not modified.</li>
</ul></li>
</ul>
<section id="explanation-of-write-once-read-many" class="level5">
<h5 class="anchored" data-anchor-id="explanation-of-write-once-read-many">Explanation of Write Once, Read Many</h5>
<ul>
<li>Data is written once and then read many times, common for datasets and model weights.</li>
</ul>
</section>
<section id="benefits-for-scaling" class="level5">
<h5 class="anchored" data-anchor-id="benefits-for-scaling">Benefits for Scaling</h5>
<ul>
<li>Scaling read operations is significantly easier than scaling write operations, making volumes well-suited for read-heavy workloads.</li>
</ul>
</section>
</section>
</section>
</section>
<section id="qa-session-2" class="level2">
<h2 class="anchored" data-anchor-id="qa-session-2">Q&amp;A Session 2</h2>
<section id="storage-pricing" class="level4">
<h4 class="anchored" data-anchor-id="storage-pricing">Storage Pricing</h4>
<ul>
<li>While Modal does not currently charge for storage, it plans to implement pricing eventually.</li>
<li>The goal is to price storage at a rate comparable to S3, Modal’s underlying storage provider.</li>
</ul>
</section>
<section id="addressing-other-storage-related-questions" class="level4">
<h4 class="anchored" data-anchor-id="addressing-other-storage-related-questions">Addressing Other Storage-Related Questions</h4>
<ul>
<li><strong>Petabyte-Sized Datasets and S3:</strong> Very large datasets may be stored directly on S3 rather than Modal’s volumes.</li>
<li><strong>Data Transport Costs:</strong> Modal does not currently charge for data ingress or egress, but may implement pricing if it becomes a significant cost.</li>
<li><strong>Explanation of Mounts:</strong> Mounts make data from the local machine available to code running on Modal. This is useful for:
<ul>
<li>Accessing code files.</li>
<li>Including assets for static sites.</li>
</ul></li>
</ul>
</section>
</section>
<section id="input-and-output-in-modal" class="level2">
<h2 class="anchored" data-anchor-id="input-and-output-in-modal">Input and Output in Modal</h2>
<section id="fastapi-integration" class="level3">
<h3 class="anchored" data-anchor-id="fastapi-integration">FastAPI Integration</h3>
<section id="benefits-of-using-fastapi-with-modal" class="level4">
<h4 class="anchored" data-anchor-id="benefits-of-using-fastapi-with-modal">Benefits of Using FastAPI with Modal</h4>
<ul>
<li>Asynchronous Python: FastAPI enables asynchronous programming without the complexities of manually managing asynchronous operations.</li>
<li>Documentation: FastAPI provides excellent documentation.</li>
<li>Scalability: Asynchronous programming in FastAPI aligns well with Modal’s scaling capabilities.</li>
<li>Performance: Asynchronous operations can improve performance, especially with Modal’s distributed architecture.</li>
</ul>
<section id="asynchronous-python-documentation-scalability-performance" class="level5">
<h5 class="anchored" data-anchor-id="asynchronous-python-documentation-scalability-performance">Asynchronous Python, Documentation, Scalability, Performance</h5>
<ul>
<li>FastAPI simplifies asynchronous programming and offers performance benefits when used with Modal.</li>
</ul>
</section>
<section id="modals-handling-of-synchronous-and-asynchronous-functions" class="level5">
<h5 class="anchored" data-anchor-id="modals-handling-of-synchronous-and-asynchronous-functions">Modal’s Handling of Synchronous and Asynchronous Functions</h5>
<ul>
<li>Modal seamlessly handles both synchronous and asynchronous functions, avoiding common errors associated with mixing the two.</li>
</ul>
</section>
<section id="flexibility-and-performance-with-async" class="level5">
<h5 class="anchored" data-anchor-id="flexibility-and-performance-with-async">Flexibility and Performance with Async</h5>
<ul>
<li>Developers can gradually introduce asynchronous code into their Modal projects without major refactoring.</li>
</ul>
</section>
</section>
<section id="web-endpoints-for-exposing-services" class="level4">
<h4 class="anchored" data-anchor-id="web-endpoints-for-exposing-services">Web Endpoints for Exposing Services</h4>
<ul>
<li>FastAPI, based on the ASGI protocol, offers a robust way to define and expose web services.</li>
</ul>
<section id="fastapi-as-a-dependency" class="level5">
<h5 class="anchored" data-anchor-id="fastapi-as-a-dependency">FastAPI as a Dependency</h5>
<ul>
<li>FastAPI is a dependency of Modal, simplifying project setup and dependency management.</li>
</ul>
</section>
<section id="creating-urls-from-python-functions" class="level5">
<h5 class="anchored" data-anchor-id="creating-urls-from-python-functions">Creating URLs from Python Functions</h5>
<ul>
<li>Modal can automatically create URLs from Python functions, simplifying web service creation.</li>
</ul>
</section>
</section>
<section id="asynchronous-server-gateway-interface-asgi" class="level4">
<h4 class="anchored" data-anchor-id="asynchronous-server-gateway-interface-asgi">Asynchronous Server Gateway Interface (ASGI)</h4>
<section id="flexibility-beyond-fastapi" class="level5">
<h5 class="anchored" data-anchor-id="flexibility-beyond-fastapi">Flexibility Beyond FastAPI</h5>
<ul>
<li>Modal supports any ASGI-compliant web framework, providing flexibility beyond FastAPI.</li>
</ul>
</section>
</section>
<section id="wsgi-and-flask-support" class="level4">
<h4 class="anchored" data-anchor-id="wsgi-and-flask-support">WSGI and Flask Support</h4>
<section id="comparison-of-wsgi-and-asgi" class="level5">
<h5 class="anchored" data-anchor-id="comparison-of-wsgi-and-asgi">Comparison of WSGI and ASGI</h5>
<ul>
<li>Modal also supports WSGI (Web Server Gateway Interface), an older protocol commonly used with frameworks like Flask.</li>
<li>While WSGI offers a mature ecosystem, it lacks native asynchronous support, potentially impacting performance compared to ASGI.</li>
</ul>
</section>
<section id="potential-trade-offs-with-wsgi" class="level5">
<h5 class="anchored" data-anchor-id="potential-trade-offs-with-wsgi">Potential Trade-offs with WSGI</h5>
<ul>
<li>WSGI may provide a wider range of existing projects and libraries but might lack the performance advantages of ASGI.</li>
</ul>
</section>
</section>
<section id="running-arbitrary-web-servers" class="level4">
<h4 class="anchored" data-anchor-id="running-arbitrary-web-servers">Running Arbitrary Web Servers</h4>
<ul>
<li>Modal allows running arbitrary web servers, even those not written in Python, by treating them as subprocesses.</li>
</ul>
</section>
</section>
</section>
<section id="qa-session-3" class="level2">
<h2 class="anchored" data-anchor-id="qa-session-3">Q&amp;A Session 3</h2>
<section id="ddos-attack-prevention" class="level4">
<h4 class="anchored" data-anchor-id="ddos-attack-prevention">DDoS Attack Prevention</h4>
<ul>
<li>Modal does not currently have built-in DDoS protection but acknowledges its importance and plans to offer it in the future.</li>
</ul>
<section id="current-mitigation-strategies" class="level5">
<h5 class="anchored" data-anchor-id="current-mitigation-strategies">Current Mitigation Strategies</h5>
<ul>
<li>Developers can implement authentication middleware in FastAPI or Flask to restrict access.</li>
</ul>
</section>
<section id="importance-of-authentication-and-rate-limiting" class="level5">
<h5 class="anchored" data-anchor-id="importance-of-authentication-and-rate-limiting">Importance of Authentication and Rate Limiting</h5>
<ul>
<li>Authentication and rate limiting are crucial for preventing unauthorized access and mitigating DDoS attacks.</li>
</ul>
</section>
<section id="potential-for-cloudflare-ddos-protection" class="level5">
<h5 class="anchored" data-anchor-id="potential-for-cloudflare-ddos-protection">Potential for Cloudflare DDoS Protection</h5>
<ul>
<li>Integrating with services like Cloudflare for DDoS protection is worth exploring.</li>
</ul>
</section>
</section>
<section id="websockets-and-max-execution-time" class="level4">
<h4 class="anchored" data-anchor-id="websockets-and-max-execution-time">WebSockets and Max Execution Time</h4>
<ul>
<li>For questions related to WebSockets and maximum execution time, Modal recommends reaching out on their Slack channel for more specific guidance.</li>
</ul>
</section>
<section id="clarification-on-djangos-async-support" class="level4">
<h4 class="anchored" data-anchor-id="clarification-on-djangos-async-support">Clarification on Django’s Async Support</h4>
<ul>
<li>A participant clarifies that Django supports asynchronous views and requests when running under ASGI.</li>
</ul>
</section>
<section id="addressing-storage-related-questions" class="level4">
<h4 class="anchored" data-anchor-id="addressing-storage-related-questions">Addressing Storage-Related Questions</h4>
<ul>
<li>Modal reiterates its stance on storage pricing and data transport costs, aiming for transparency and aligning with S3’s pricing model.</li>
</ul>
</section>
</section>
<section id="serverless-nature-of-modal" class="level2">
<h2 class="anchored" data-anchor-id="serverless-nature-of-modal">Serverless Nature of Modal</h2>
<section id="importance-of-serverless-architecture" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-serverless-architecture">Importance of Serverless Architecture</h3>
<ul>
<li>Serverless architecture is a key aspect of Modal, contributing to its cost-efficiency and developer experience.</li>
</ul>
</section>
<section id="serverless-for-cost-efficiency-and-developer-experience" class="level3">
<h3 class="anchored" data-anchor-id="serverless-for-cost-efficiency-and-developer-experience">Serverless for Cost Efficiency and Developer Experience</h3>
<ul>
<li>Modal’s serverless nature offers both financial and ergonomic benefits for development teams.</li>
</ul>
</section>
<section id="variable-resource-utilization" class="level3">
<h3 class="anchored" data-anchor-id="variable-resource-utilization">Variable Resource Utilization</h3>
<ul>
<li>Service resource usage fluctuates over time due to factors like:
<ul>
<li>Time zone-dependent usage patterns.</li>
<li>Traffic spikes from external events.</li>
</ul></li>
</ul>
<section id="provisioning-for-peaks-and-cost-implications" class="level4">
<h4 class="anchored" data-anchor-id="provisioning-for-peaks-and-cost-implications">Provisioning for Peaks and Cost Implications</h4>
<ul>
<li>Traditional approaches involve provisioning resources for peak usage, leading to wasted resources and unnecessary costs during off-peak times.</li>
</ul>
</section>
<section id="resource-utilization-challenges" class="level4">
<h4 class="anchored" data-anchor-id="resource-utilization-challenges">Resource Utilization Challenges</h4>
<ul>
<li>Optimizing resource utilization becomes crucial to minimize costs, as exemplified by Amazon’s journey into cloud computing.</li>
</ul>
</section>
<section id="the-rise-of-cloud-computing" class="level4">
<h4 class="anchored" data-anchor-id="the-rise-of-cloud-computing">The Rise of Cloud Computing</h4>
<ul>
<li>Cloud computing emerged partly from the need to utilize idle resources effectively.</li>
</ul>
</section>
</section>
<section id="manual-provisioning-and-its-drawbacks" class="level3">
<h3 class="anchored" data-anchor-id="manual-provisioning-and-its-drawbacks">Manual Provisioning and Its Drawbacks</h3>
<ul>
<li>Manually scaling resources up and down can reduce costs but is reactive, stressful, and may not handle sudden traffic spikes well.</li>
</ul>
<section id="handling-traffic-spikes" class="level4">
<h4 class="anchored" data-anchor-id="handling-traffic-spikes">Handling Traffic Spikes</h4>
<ul>
<li>Manual provisioning struggles to respond quickly to unexpected surges in traffic.</li>
</ul>
</section>
<section id="reducing-costs-but-potentially-sacrificing-user-experience" class="level4">
<h4 class="anchored" data-anchor-id="reducing-costs-but-potentially-sacrificing-user-experience">Reducing Costs but Potentially Sacrificing User Experience</h4>
<ul>
<li>While manual provisioning can save costs, it can also lead to poor user experiences during scaling events.</li>
</ul>
</section>
</section>
<section id="automatic-provisioning-and-autoscaling" class="level3">
<h3 class="anchored" data-anchor-id="automatic-provisioning-and-autoscaling">Automatic Provisioning and Autoscaling</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/images/auto-scaling.png" class="img-fluid figure-img"></p>
<figcaption>Auto-Scaling Resource Utilization</figcaption>
</figure>
</div>
<section id="kubernetes-and-autoscaling" class="level4">
<h4 class="anchored" data-anchor-id="kubernetes-and-autoscaling">Kubernetes and Autoscaling</h4>
<ul>
<li>Tools like Kubernetes automate provisioning and scaling, dynamically adjusting resources based on demand.</li>
</ul>
</section>
<section id="lag-in-autoscaling" class="level4">
<h4 class="anchored" data-anchor-id="lag-in-autoscaling">Lag in Autoscaling</h4>
<ul>
<li>Autoscaling typically involves a lag between resource demand and allocation.</li>
</ul>
</section>
<section id="granularity-of-autoscaling" class="level4">
<h4 class="anchored" data-anchor-id="granularity-of-autoscaling">Granularity of Autoscaling</h4>
<ul>
<li>Smaller units of autoscaling allow for more precise resource allocation.</li>
</ul>
</section>
</section>
<section id="achieving-serverless-matching-costs-to-resource-utilization" class="level3">
<h3 class="anchored" data-anchor-id="achieving-serverless-matching-costs-to-resource-utilization">Achieving Serverless: Matching Costs to Resource Utilization</h3>
<ul>
<li>Serverless computing aims to align costs directly with resource consumption.</li>
</ul>
<section id="scaling-to-zero" class="level4">
<h4 class="anchored" data-anchor-id="scaling-to-zero">Scaling to Zero</h4>
<ul>
<li>A defining characteristic of serverless is the ability to scale resources down to zero when not in use.</li>
</ul>
</section>
<section id="functions-as-a-service-faas" class="level4">
<h4 class="anchored" data-anchor-id="functions-as-a-service-faas">Functions as a Service (FaaS)</h4>
<ul>
<li>Serverless is often implemented using Functions as a Service (FaaS), where individual functions are executed on demand.</li>
</ul>
</section>
</section>
<section id="benefits-of-serverless-cost-savings-improved-user-experience" class="level3">
<h3 class="anchored" data-anchor-id="benefits-of-serverless-cost-savings-improved-user-experience">Benefits of Serverless: Cost Savings, Improved User Experience</h3>
<ul>
<li>Serverless offers:
<ul>
<li>Reduced costs by paying only for resources consumed.</li>
<li>Improved user experiences by dynamically scaling to meet demand.</li>
</ul></li>
</ul>
</section>
<section id="why-use-a-serverless-platform-like-modal" class="level3">
<h3 class="anchored" data-anchor-id="why-use-a-serverless-platform-like-modal">Why Use a Serverless Platform Like Modal?</h3>
<ul>
<li>Managing serverless infrastructure requires significant engineering effort.</li>
</ul>
<section id="why-use-a-serverless-platform-like-modal-1" class="level4">
<h4 class="anchored" data-anchor-id="why-use-a-serverless-platform-like-modal-1">Why Use a Serverless Platform Like Modal?</h4>
<ul>
<li>Serverless platforms like Modal offer economies of scale, handling the complexities of:
<ul>
<li>Resource allocation.</li>
<li>Autoscaling.</li>
<li>Infrastructure management.</li>
</ul></li>
</ul>
</section>
<section id="amortizing-engineering-complexity" class="level4">
<h4 class="anchored" data-anchor-id="amortizing-engineering-complexity">Amortizing Engineering Complexity</h4>
<ul>
<li>Modal amortizes the engineering complexity of serverless across its entire user base.</li>
</ul>
</section>
<section id="smoothing-fluctuations-with-multiple-users" class="level4">
<h4 class="anchored" data-anchor-id="smoothing-fluctuations-with-multiple-users">Smoothing Fluctuations with Multiple Users</h4>
<ul>
<li>Fluctuations in individual users’ resource usage are smoothed out by the aggregate usage of all users on the platform.</li>
</ul>
</section>
<section id="economics-of-serverless-computing" class="level4">
<h4 class="anchored" data-anchor-id="economics-of-serverless-computing">Economics of Serverless Computing</h4>
<ul>
<li>The “Berkeley View” paper highlights the economic benefits of serverless computing, emphasizing economies of scale and resource utilization.</li>
</ul>
<section id="berkeley-paper-on-serverless" class="level5">
<h5 class="anchored" data-anchor-id="berkeley-paper-on-serverless">Berkeley Paper on Serverless</h5>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/1902.03383">Cloud Programming Simplified: A Berkeley View on Serverless Computing</a></li>
</ul>
</section>
</section>
</section>
</section>
<section id="remote-procedure-calling-rpc-in-modal" class="level2">
<h2 class="anchored" data-anchor-id="remote-procedure-calling-rpc-in-modal">Remote Procedure Calling (RPC) in Modal</h2>
<section id="rpc-as-the-core-idea-behind-serverless" class="level3">
<h3 class="anchored" data-anchor-id="rpc-as-the-core-idea-behind-serverless">RPC as the Core Idea Behind Serverless</h3>
<ul>
<li>Remote Procedure Calling (RPC) is fundamental to serverless computing and Modal’s functionality.</li>
</ul>
</section>
<section id="how-rpc-works" class="level3">
<h3 class="anchored" data-anchor-id="how-rpc-works">How RPC Works</h3>
<ul>
<li>In RPC, local code invokes functions that execute on remote machines, abstracting away the complexities of network communication.</li>
<li><strong>Book:</strong> <a href="https://book.systemsapproach.org/index.html">Computer Networks: A Systems Approach</a>
<ul>
<li><strong>Section:</strong> <a href="https://book.systemsapproach.org/e2e/rpc.html#remote-procedure-call">5.3 Remote Procedure Call</a></li>
</ul></li>
</ul>
<section id="transparency-and-seamlessness" class="level4">
<h4 class="anchored" data-anchor-id="transparency-and-seamlessness">Transparency and Seamlessness</h4>
<ul>
<li>RPC strives for transparency, making remote function calls appear as if they were local.</li>
</ul>
</section>
</section>
<section id="modals-implementation-with-grpc" class="level3">
<h3 class="anchored" data-anchor-id="modals-implementation-with-grpc">Modal’s Implementation with gRPC</h3>
<ul>
<li>Modal utilizes gRPC as its RPC framework.</li>
</ul>
</section>
<section id="understanding-modals-behavior" class="level3">
<h3 class="anchored" data-anchor-id="understanding-modals-behavior">Understanding Modal’s Behavior</h3>
<section id="why-modal-feels-different-from-local-python" class="level4">
<h4 class="anchored" data-anchor-id="why-modal-feels-different-from-local-python">Why Modal Feels Different from Local Python</h4>
<ul>
<li>Modal’s RPC mechanisms introduce differences compared to traditional local Python execution.</li>
</ul>
</section>
<section id="code-execution-on-modals-machines" class="level4">
<h4 class="anchored" data-anchor-id="code-execution-on-modals-machines">Code Execution on Modal’s Machines</h4>
<ul>
<li>Code, including functions, is sent to Modal’s infrastructure for execution.</li>
</ul>
</section>
<section id="dynamic-function-execution" class="level4">
<h4 class="anchored" data-anchor-id="dynamic-function-execution">Dynamic Function Execution</h4>
<ul>
<li>Modal dynamically uploads and executes functions defined in local scripts.</li>
</ul>
</section>
<section id="handling-global-scope-and-imports" class="level4">
<h4 class="anchored" data-anchor-id="handling-global-scope-and-imports">Handling Global Scope and Imports</h4>
<ul>
<li>Understanding how Modal manages global scope and imports is crucial for writing effective Modal code.</li>
</ul>
</section>
</section>
<section id="running-code-on-gpus" class="level3">
<h3 class="anchored" data-anchor-id="running-code-on-gpus">Running Code on GPUs</h3>
<ul>
<li>Modal enables running code on GPUs even if the local machine lacks them.</li>
</ul>
</section>
<section id="demo-mini-modal" class="level3">
<h3 class="anchored" data-anchor-id="demo-mini-modal">Demo: Mini Modal</h3>
<section id="simulating-modal-locally" class="level4">
<h4 class="anchored" data-anchor-id="simulating-modal-locally">Simulating Modal Locally</h4>
<ul>
<li><strong><a href="https://github.com/charlesfrye/minimodal">MiniModal</a>:</strong> A simplified local simulation of Modal’s core concepts.</li>
</ul>
</section>
<section id="understanding-modals-internals" class="level4">
<h4 class="anchored" data-anchor-id="understanding-modals-internals">Understanding Modal’s Internals</h4>
<ul>
<li>Mini Modal provides insights into Modal’s internal workings, particularly its handling of virtual environments and code execution.</li>
</ul>
</section>
<section id="separating-virtual-environments" class="level4">
<h4 class="anchored" data-anchor-id="separating-virtual-environments">Separating Virtual Environments</h4>
<ul>
<li>Mini Modal demonstrates the isolation of virtual environments, a key aspect of Modal’s functionality.</li>
</ul>
</section>
</section>
</section>
<section id="qa-session-4" class="level2">
<h2 class="anchored" data-anchor-id="qa-session-4">Q&amp;A Session 4</h2>
<section id="how-modal-hosts-suno.ai" class="level4">
<h4 class="anchored" data-anchor-id="how-modal-hosts-suno.ai">How Modal Hosts Suno.ai</h4>
<ul>
<li><a href="https://suno.com/">Suno.ai</a>, a generative AI application, utilizes various Modal features, including functions, cron jobs, volumes, and web endpoints.</li>
</ul>
<section id="suno.ais-use-of-modals-features" class="level5">
<h5 class="anchored" data-anchor-id="suno.ais-use-of-modals-features">Suno.ai’s Use of Modal’s Features</h5>
<ul>
<li>A blog post details Suno.ai’s reasons for choosing Modal and how they leverage its features.</li>
</ul>
</section>
<section id="blog-post-about-suno.ais-choice-of-modal" class="level5">
<h5 class="anchored" data-anchor-id="blog-post-about-suno.ais-choice-of-modal">Blog Post about Suno.ai’s Choice of Modal</h5>
<ul>
<li>The blog post provides insights into Suno.ai’s decision to use Modal and their experience with the platform.</li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-015/</guid>
  <pubDate>Sun, 25 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Notes on The Learning Game꞉ Teaching Kids to Think for Themselves, Embrace Challenge, and Love Learning</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/the-learning-game-book-notes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
These notes are part of the following collection:
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="../../series/notes/education-notes.html"><strong>Education</strong></a></p>
</div>
</div>
<ul>
<li>Executive Summary</li>
<li>The Problem with the “Game of School”<br>
</li>
<li>Reimagining Education<br>
</li>
<li>Part 1: School<br>
</li>
<li>Part 2: How Kids Learn<br>
</li>
<li>Part 3: The Power of Games<br>
</li>
<li>Part 4: Raising Successful Kids<br>
</li>
<li>Part 5: The Model Parent<br>
</li>
<li>Conclusion: Design Your Learning Game</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Book LInks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://harriman.house/books/the-learning-game/">Publisher Page</a></li>
<li><a href="https://afabrega.com/">Author’s Website</a></li>
</ul>
</div>
</div>
<section id="executive-summary" class="level2">
<h2 class="anchored" data-anchor-id="executive-summary">Executive Summary</h2>
<p>This book critiques the modern education system, arguing that it stifles curiosity and creativity in children. It advocates for a shift from instruction-based learning to a more engaging, game-like approach that empowers children to think independently, embrace failure, and develop a lifelong love of learning.</p>
<p>The author draws upon personal experience as a teacher and insights from various fields, including psychology, game design, and philosophy, to offer practical strategies for parents and educators to design a “Learning Game” that fosters genuine learning.</p>
<p>The book challenges common misconceptions about learning styles, the role of memorization, and the fear of failure, proposing alternative methods like story-driven learning, mental models, and elastic thinking.</p>
</section>
<section id="the-problem-with-the-game-of-school" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-with-the-game-of-school">The Problem with the “Game of School”</h2>
<section id="authors-personal-journey" class="level3">
<h3 class="anchored" data-anchor-id="authors-personal-journey">Author’s Personal Journey</h3>
<ul>
<li>The author attended 10 schools across 7 countries, experiencing diverse educational systems and adapting to new environments.</li>
<li>She realized that succeeding in school often meant playing the “game” - following rules, pleasing teachers, and achieving good grades - rather than deeply engaging with learning.</li>
<li>Her true passion for learning flourished outside the classroom, where she could pursue personal interests and explore creatively.</li>
</ul>
</section>
<section id="the-pervasive-game-of-school" class="level3">
<h3 class="anchored" data-anchor-id="the-pervasive-game-of-school">The Pervasive “Game of School”</h3>
<ul>
<li>The author observed the same “game” being played in classrooms worldwide, with students expected to conform and obey rather than think critically and independently.</li>
<li>This realization led her to question the effectiveness of an educational system that stifles curiosity and enforces a standardized approach to learning.</li>
</ul>
</section>
<section id="impact-on-childrens-love-of-learning" class="level3">
<h3 class="anchored" data-anchor-id="impact-on-childrens-love-of-learning">Impact on Children’s Love of Learning</h3>
<ul>
<li>Young children possess a natural desire to learn, but this enthusiasm often dwindles as they progress through a rigid and prescriptive school system.</li>
<li>The lack of choice, autonomy, and personalized learning experiences contributes to disengagement and a reliance on extrinsic motivation (grades).</li>
</ul>
</section>
</section>
<section id="reimagining-education" class="level2">
<h2 class="anchored" data-anchor-id="reimagining-education">Reimagining Education</h2>
<section id="key-questions-for-transforming-education" class="level3">
<h3 class="anchored" data-anchor-id="key-questions-for-transforming-education">Key Questions for Transforming Education</h3>
<ul>
<li>How can we shift from a “game of school” to a “game of learning” that fosters lifelong curiosity and a genuine passion for knowledge?</li>
<li>How can we tailor education to individual needs and empower children to take ownership of their learning journeys?</li>
<li>How do we equip children with the tools and mindsets to thrive in a world of constant change and embrace challenges as opportunities for growth?</li>
</ul>
</section>
<section id="the-learning-game-approach" class="level3">
<h3 class="anchored" data-anchor-id="the-learning-game-approach">The “Learning Game” Approach</h3>
<ul>
<li>Encourages parents and educators to challenge traditional assumptions about education and actively participate in shaping their children’s learning experiences.</li>
<li>Emphasizes the importance of:
<ul>
<li><strong>Curiosity-driven Exploration:</strong> Allowing children to pursue their passions and interests, even if they deviate from conventional academic paths.</li>
<li><strong>Critical Thinking and Questioning:</strong> Encouraging children to challenge assumptions, seek evidence, and think independently.</li>
<li><strong>Personal Relevance and Real-World Application:</strong> Connecting learning to children’s lives and demonstrating the practical applications of knowledge.</li>
<li><strong>Embrace of Mistakes and Challenges:</strong> Fostering a growth mindset where mistakes are viewed as opportunities for learning and challenges are embraced as catalysts for development.</li>
</ul></li>
</ul>
</section>
</section>
<section id="part-1-school" class="level2">
<h2 class="anchored" data-anchor-id="part-1-school">Part 1: School</h2>
<section id="chapter-1-seven-dangerous-lessons-taught-in-schools" class="level3">
<h3 class="anchored" data-anchor-id="chapter-1-seven-dangerous-lessons-taught-in-schools">Chapter 1: Seven Dangerous Lessons Taught in Schools</h3>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> “<a href="https://newsociety.com/books/d/dumbing-us-down-25th-anniversary-edition">Dumbing Us Down, The Hidden Curriculum of Compulsory Schooling</a>” by John Taylor Gatto.</li>
</ul>
</div>
</div>
<p>This chapter, drawing upon John Taylor Gatto’s book “Dumbing Us Down,” outlines seven detrimental lessons ingrained in the traditional education system:</p>
<ol type="1">
<li><strong>Confusion:</strong> Subjects taught in isolation, lacking real-world context, leaving students confused about how knowledge connects.
<ul>
<li><strong>Alternative:</strong> Teach concepts in context, applying them to solve problems or build projects.</li>
</ul></li>
<li><strong>Class Position:</strong> Obsession with ranking and labeling students, fostering competition instead of collaboration.
<ul>
<li><strong>Alternative:</strong> Encourage collaboration, letting kids define success on their own terms, valuing individual strengths and contributions.</li>
</ul></li>
<li><strong>Indifference:</strong> Discouraging deep engagement by forcing rapid subject switching, mirroring the fragmented attention of the digital age.
<ul>
<li><strong>Alternative:</strong> Let kids follow their interests, allowing them to dive deep into topics that excite them, fostering focus and depth.</li>
</ul></li>
<li><strong>Emotional Dependency:</strong> Students conditioned to mirror teachers’ emotions, hindering their ability to develop emotional regulation and resilience.
<ul>
<li><strong>Alternative:</strong> Encourage kids to explore and manage their own feelings, fostering emotional intelligence and resilience.</li>
</ul></li>
<li><strong>Intellectual Dependency:</strong> Prioritizing conformity and obedience over independent thought and challenging the status quo.
<ul>
<li><strong>Alternative:</strong> Encourage divergent thinking, questioning, and the development of individual perspectives, valuing critical thinking over rote memorization.</li>
</ul></li>
<li><strong>Provisional Self-Esteem:</strong> Tying self-worth to external validation from teachers and grades, rather than internal standards and self-assessment.
<ul>
<li><strong>Alternative:</strong> Encourage kids to develop an internal measuring stick, fostering self-confidence and self-reliance based on personal growth and effort.</li>
</ul></li>
<li><strong>Students Can’t Hide:</strong> Constant surveillance and lack of privacy, hindering experimentation, risk-taking, and the development of self-directed learning.
<ul>
<li><strong>Alternative:</strong> Provide opportunities for privacy, creative exploration, and independent action, allowing kids to learn through trial and error.</li>
</ul></li>
</ol>
</section>
<section id="chapter-2-how-did-we-get-here" class="level3">
<h3 class="anchored" data-anchor-id="chapter-2-how-did-we-get-here">Chapter 2: How Did We Get Here?</h3>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Blog Post:</strong> <a href="https://afabrega.com/my-blog/the-origin-of-the-modern-school-system">The Origin of the Modern School System</a></li>
</ul>
</div>
</div>
<p>This chapter traces the historical development of the education system, revealing the origins of its flaws:</p>
<ul>
<li><strong>Prussia:</strong>
<ul>
<li>The modern school system originated in Prussia, designed to create loyal, literate soldiers after their defeat by Napoleon.</li>
<li>This model emphasized standardized curriculum, teacher certification, and mandated attendance, prioritizing obedience and indoctrination.</li>
</ul></li>
<li><strong>The USA:</strong>
<ul>
<li>In the 20th century, the focus shifted from training soldiers to producing factory managers, leading to the adoption of the “factory model” in American schools.</li>
<li>This model emphasized standardization, efficiency, age-based grouping, specialized teachers, and long school days, mirroring the assembly line approach.</li>
<li>This model has yielded disappointing results, with stagnant test scores, declining public confidence, and a disconnect from real-world success.</li>
</ul></li>
</ul>
<p>This historical context reveals how the education system prioritizes state and industrial needs over genuine learning, leading to the current instruction-based model.</p>
</section>
<section id="chapter-3-how-tests-and-rewards-go-wrong" class="level3">
<h3 class="anchored" data-anchor-id="chapter-3-how-tests-and-rewards-go-wrong">Chapter 3: How Tests and Rewards Go Wrong</h3>
<p>This chapter examines the detrimental effects of standardized testing and extrinsic rewards:</p>
<ul>
<li><strong>Standardized Tests:</strong>
<ul>
<li>Initially designed to measure student progress, standardized tests have become the primary focus of education, leading to several negative consequences.</li>
<li>They create stressful learning environments, compromise mental health, do not accurately reflect real-world success, and incentivize cheating.</li>
</ul></li>
<li><strong>Extrinsic Rewards:</strong>
<ul>
<li>Schools rely on extrinsic rewards like pizza parties or prizes, offering short-term motivation but undermining long-term engagement.</li>
<li>Extrinsic motivators create dependence on external validation, hindering the development of intrinsic motivation.</li>
</ul></li>
</ul>
<p>The chapter suggests alternative assessment methods, including portfolios and projects, and emphasizes the importance of intrinsic motivation, encouraging:</p>
<ul>
<li>Providing choices and fostering accountability.</li>
<li>Involving children in decision-making.</li>
<li>Offering specific feedback that focuses on effort and the learning process, not just outcomes.</li>
<li>Engaging in “why” conversations to connect learning to real-world relevance and purpose.</li>
<li>Prioritizing fun and intrinsic enjoyment in the learning process.</li>
</ul>
</section>
<section id="chapter-4-lessons-to-unlearn-from-school" class="level3">
<h3 class="anchored" data-anchor-id="chapter-4-lessons-to-unlearn-from-school">Chapter 4: Lessons to Unlearn from School</h3>
<p>This chapter highlights five counterproductive lessons learned in traditional school that need to be unlearned:</p>
<ol type="1">
<li><strong>Fearing Mistakes:</strong> Shift from penalizing errors to embracing them as valuable learning opportunities.</li>
<li><strong>Fitting In:</strong> Encourage individuality, divergent thinking, and “coloring outside the lines” over conformity and seeking validation through sameness.</li>
<li><strong>Waiting for Instructions:</strong> Cultivate problem-solving skills, resourcefulness, and the ability to learn independently without relying on constant direction.</li>
<li><strong>Learning Just in Case:</strong> Embrace “learning on demand,” where knowledge and skills are acquired as needed, driven by curiosity and real-world application.</li>
<li><strong>Fear of Questioning Authority:</strong> Foster critical thinking, challenging assumptions, and seeking evidence-based answers over blind acceptance of authority.</li>
</ol>
</section>
<section id="chapter-5-the-game-of-school" class="level3">
<h3 class="anchored" data-anchor-id="chapter-5-the-game-of-school">Chapter 5: The Game of School</h3>
<p>This chapter contrasts the “game of school,” characterized by compliance and seeking external validation, with the “learning game,” emphasizing:</p>
<ul>
<li><strong>Game of School:</strong> Mastering the system through superficial engagement, prioritizing grades over true understanding, and focusing on short-term performance.</li>
<li><strong>Learning Game:</strong> Embracing curiosity-driven exploration, taking ownership of the learning process, valuing the journey of discovery over external rewards.</li>
</ul>
<p>The chapter advocates for guiding children towards the learning game, fostering intrinsic motivation, and equipping them with the skills and mindset to become lifelong learners.</p>
</section>
</section>
<section id="part-2-how-kids-learn" class="level2">
<h2 class="anchored" data-anchor-id="part-2-how-kids-learn">Part 2: How Kids Learn</h2>
<section id="chapter-6-learning-to-love-learning" class="level3">
<h3 class="anchored" data-anchor-id="chapter-6-learning-to-love-learning">Chapter 6: Learning to Love Learning</h3>
<ul>
<li><strong>Separating Work and Play:</strong> Traditional education often separates learning from joy by framing schoolwork as “real work” and personal projects as mere play. This undermines the potential for genuine learning that blossoms when children are intrinsically motivated.</li>
<li><strong>The Power of Personal Projects:</strong>
<ul>
<li>Personal projects, like building a tree house, offer opportunities for children to engage deeply in learning experiences they direct themselves. This mirrors the work of innovators like Darwin and Newton, whose successes stemmed from pursuing their own curiosities.</li>
<li>Examples like Mark Zuckerberg, Elon Musk, and Jenny Britton Bauer illustrate that groundbreaking achievements often arise from intensely pursuing personal passions, even if they fall outside traditional academic paths.</li>
<li><strong>Vuja De:</strong> Seeing a familiar situation with a fresh perspective that leads to new insights.</li>
<li><strong>Recommendation:</strong> Encourage children to pursue their own projects. Help them see these endeavors as valuable learning experiences, fostering their passions and cultivating a love for learning.</li>
</ul></li>
</ul>
</section>
<section id="chapter-7-story-driven-learning" class="level3">
<h3 class="anchored" data-anchor-id="chapter-7-story-driven-learning">Chapter 7: Story-Driven Learning</h3>
<ul>
<li><p><strong>The Power of Stories:</strong> Humans are naturally wired to learn through stories. Stories make abstract concepts concrete, provide relatable examples, and offer memorable narratives that engage our emotions and enhance recall.</p></li>
<li><p><strong>Learning from Role Models:</strong> Stories provide us with heroes to admire and emulate. By connecting with the experiences of individuals who have mastered specific skills or concepts, we can find inspiration and practical strategies for our own learning journeys.</p>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Newsletter:</strong> <a href="https://www.readtheprofile.com/t/interviews">The Profile - Interviews</a>
<ul>
<li>Interviews Polina Pompliano, offering stories of unique individuals for learning.</li>
</ul></li>
</ul>
</div>
</div></li>
</ul></li>
<li><p><strong>How to Use Story-Driven Learning:</strong></p>
<ul>
<li>Identify individuals who embody the skills or knowledge you want to acquire. Explore their stories through books, articles, documentaries, or podcasts.</li>
<li>Connect the abstract concepts to the practical applications demonstrated in the individual’s life. For example, learn about decision-making through the story of a successful poker player who utilizes probability theory.</li>
<li><strong>Recommendation:</strong> Encourage children to explore topics they’re interested in through stories. Help them find biographies, documentaries, or articles about people who excel in those areas. This makes learning relatable and engaging.</li>
</ul></li>
</ul>
</section>
<section id="chapter-8-learning-through-memorization" class="level3">
<h3 class="anchored" data-anchor-id="chapter-8-learning-through-memorization">Chapter 8: Learning Through Memorization</h3>
<ul>
<li><p><strong>Rethinking Memorization in the Digital Age:</strong> With information readily accessible, rote memorization of isolated facts holds less importance. Instead, prioritize understanding fundamental concepts, developing critical thinking skills, and building a foundation of applicable knowledge.</p></li>
<li><p><strong>Pair Memory with Meaning:</strong></p>
<ul>
<li>Encourage understanding the “why” behind the “what.” Simply memorizing facts without comprehending their meaning limits genuine learning and the ability to apply knowledge effectively.</li>
</ul></li>
<li><p><strong>Focus on Essential Knowledge:</strong></p>
<ul>
<li>Prioritize memorizing information with practical, real-world application over trivial facts easily retrieved online. Focus on concepts crucial for decision-making and understanding how the world works.</li>
</ul></li>
<li><p><strong>Effective Memorization Techniques:</strong></p>
<ul>
<li><p><strong>Memory Palace:</strong> This technique leverages our natural ability to remember places and vivid imagery.</p>
<ol type="1">
<li>Imagine a familiar location (e.g., your childhood home).</li>
<li>Associate items to be memorized with specific locations within this “palace” (e.g., placing grocery items in different rooms).</li>
<li>Create unusual, memorable scenes involving these items (e.g., apples singing in the mailbox).</li>
<li>To recall the items, mentally walk through the “palace” and retrieve the vivid associations.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Blog Post:</strong> <a href="https://artofmemory.com/blog/how-to-build-a-memory-palace/">How to Build a Memory Palace</a></li>
<li><strong>Book:</strong> <a href="https://joshuafoer.com/moonwalking-with-einstein/">Moonwalking with Einstein</a></li>
</ul>
</div>
</div></li>
</ul></li>
<li><p><strong>Recommendation:</strong> Teach children effective memorization techniques like the Memory Palace method. This makes memorization more engaging and helps them retain important information.</p></li>
</ul>
</section>
<section id="chapter-9-the-learning-style-myth" class="level3">
<h3 class="anchored" data-anchor-id="chapter-9-the-learning-style-myth">Chapter 9: The Learning Style Myth</h3>
<ul>
<li><strong>Challenging the Myth:</strong> The notion that individuals have one dominant learning style (visual, auditory, kinesthetic) lacks scientific support. Sensory modalities are interconnected, and we learn best by engaging multiple senses simultaneously.</li>
<li><strong>Problems with Learning Styles:</strong>
<ul>
<li><strong>No Single Style:</strong> We do not have a single, fixed learning style. Preferences can vary depending on the context and the type of information being processed.</li>
<li><strong>Ineffective Customization:</strong> Tailoring teaching to supposed learning styles does not improve learning outcomes.</li>
<li><strong>Fixed Mindset:</strong> Labeling children as specific learner types can foster limiting beliefs about their abilities.</li>
</ul></li>
<li><strong>Recommendations:</strong>
<ul>
<li><strong>Debunk the Myth:</strong> Help children understand they don’t have just one learning style.</li>
<li><strong>Embrace Flexibility:</strong> Emphasize that learning preferences are adaptable and can change based on the situation.</li>
<li><strong>Encourage a Diverse Toolkit:</strong> Help children develop a range of learning strategies and encourage them to identify the most effective tools for different tasks.</li>
<li><strong>Provide Multi-Sensory Experiences:</strong> Offer diverse learning opportunities that engage multiple senses.</li>
</ul></li>
</ul>
</section>
<section id="chapter-10-confusion-sparks-curiosity" class="level3">
<h3 class="anchored" data-anchor-id="chapter-10-confusion-sparks-curiosity">Chapter 10: Confusion Sparks Curiosity</h3>
<ul>
<li><p><strong>Embracing Confusion:</strong> Instead of viewing confusion as a negative experience, reframe it as an opportunity for growth. Cognitive disequilibrium, the feeling of discomfort when encountering new information, drives us to seek answers and deepen our understanding.</p>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Psychological Concept:</strong> <a href="https://link.springer.com/referenceworkentry/10.1007/978-0-387-79061-9_598">Cognitive disequilibrium</a></li>
</ul>
</div>
</div></li>
</ul></li>
<li><p><strong>Benefits of Confusion:</strong></p>
<ul>
<li><strong>Deeper Processing:</strong> Confusion prompts us to engage more deeply with information to resolve inconsistencies with our existing knowledge.</li>
<li><strong>Curiosity and Motivation:</strong> Confusion can spark curiosity, leading to increased motivation and engagement in the learning process.</li>
</ul></li>
<li><p><strong>Learning Through Connections:</strong> Present new information within a relevant context to help children see the connections between different subjects and real-world applications.</p></li>
<li><p><strong>A Case Study: Synthesis:</strong> The Synthesis class at Ad Astra School, founded by Elon Musk, uses simulations and challenges to help kids embrace confusion and develop problem-solving skills.</p>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Learning Platform:</strong> <a href="https://www.synthesis.com/">Synthesis</a></li>
</ul>
</div>
</div></li>
</ul></li>
<li><p><strong>Principles for Exploring Confusion:</strong></p>
<ul>
<li><strong>Expose Kids to Challenges:</strong> Encourage them to tackle challenging problems and unfamiliar situations.</li>
<li><strong>Reframe Confusion:</strong> Help children view confusion as a positive step in the learning process, not a sign of failure.</li>
<li><strong>Support Productive Struggle:</strong> Provide guidance and support, but allow children to grapple with challenges and discover solutions independently.</li>
</ul></li>
<li><p><strong>Recommendation:</strong> Create learning environments that embrace confusion and encourage experimentation. Encourage children to view challenges as exciting opportunities for growth.</p></li>
</ul>
</section>
</section>
<section id="part-3-the-power-of-games" class="level2">
<h2 class="anchored" data-anchor-id="part-3-the-power-of-games">Part 3: The Power of Games</h2>
<section id="chapter-11-the-architecture-of-great-games" class="level3">
<h3 class="anchored" data-anchor-id="chapter-11-the-architecture-of-great-games">Chapter 11: The Architecture of Great Games</h3>
<p>This chapter explores how to leverage game design principles to enhance learning experiences.</p>
<section id="why-games-captivate-the-power-of-flow" class="level4">
<h4 class="anchored" data-anchor-id="why-games-captivate-the-power-of-flow">Why Games Captivate: The Power of Flow</h4>
<ul>
<li><strong>Engagement and Flow:</strong> Games captivate players by inducing a state of “flow,” characterized by:
<ul>
<li>Clear goals</li>
<li>Unambiguous feedback</li>
<li>Goldilocks challenge level (not too easy, not too hard)</li>
</ul></li>
<li><strong>Flow fosters intrinsic motivation</strong>, where enjoyment stems from the activity itself, not external rewards.</li>
<li><strong>Games vs.&nbsp;Classrooms:</strong> Traditional classrooms often lack the elements needed for flow:
<ul>
<li>Unclear goals</li>
<li>Ambiguous feedback</li>
<li>One-size-fits-all challenges</li>
</ul></li>
</ul>
</section>
<section id="beyond-pointsification-true-gamification" class="level4">
<h4 class="anchored" data-anchor-id="beyond-pointsification-true-gamification">Beyond Pointsification: True Gamification</h4>
<ul>
<li><strong>Pointsification:</strong> Superficial use of game elements (points, badges, leaderboards) that relies on external motivation. While it may yield short-term results, it’s unsustainable and doesn’t cultivate a genuine love for learning.</li>
<li><strong>True Gamification:</strong> Understanding and integrating what makes games truly engaging:
<ul>
<li><strong>Meaningful challenges:</strong> Aligned with players’ genuine interests.</li>
<li><strong>Immersive experiences:</strong> Capable of inducing a flow state.</li>
</ul></li>
</ul>
<section id="example-new-york-public-library" class="level5">
<h5 class="anchored" data-anchor-id="example-new-york-public-library">Example: New York Public Library</h5>
<ul>
<li><strong>Challenge:</strong> Attract young people to physical libraries in the digital age.</li>
<li><strong>Solution:</strong> A game that turns participants into published authors by locking them in the library overnight with the challenge of writing a book.</li>
<li><strong>Result:</strong> Participants found the challenge meaningful, enjoyed their time at the library, and developed a newfound appreciation for the space.</li>
</ul>
</section>
</section>
<section id="the-super-mario-effect-embracing-failure" class="level4">
<h4 class="anchored" data-anchor-id="the-super-mario-effect-embracing-failure">The Super Mario Effect: Embracing Failure</h4>
<ul>
<li><strong>Reframing Failure:</strong> Games encourage persistence despite repeated failures. Players focus on the ultimate goal, viewing mistakes as part of the learning process.</li>
<li><strong>The Super Mario Effect:</strong> Prioritizing the end goal over the fear of failure.</li>
<li><strong>Shifting Focus in Education:</strong> From grades to mastery, from penalizing mistakes to encouraging iterative learning.</li>
</ul>
</section>
<section id="the-benefits-of-video-games" class="level4">
<h4 class="anchored" data-anchor-id="the-benefits-of-video-games">The Benefits of Video Games</h4>
<ul>
<li><strong>Developing Thinking Skills:</strong> Games are simulations that provide a safe space to practice problem-solving and strategic thinking.</li>
<li><strong>Fostering Self-Directed Learning:</strong> Games empower players to learn at their own pace, explore their interests, and develop a growth mindset.</li>
</ul>
</section>
</section>
<section id="chapter-12-the-psychology-of-healthy-gaming" class="level3">
<h3 class="anchored" data-anchor-id="chapter-12-the-psychology-of-healthy-gaming">Chapter 12: The Psychology of Healthy Gaming</h3>
<p>This chapter delves into the motivations behind children’s screen time and offers strategies for fostering healthy technology use.</p>
<section id="understanding-motivation-self-determination-theory" class="level4">
<h4 class="anchored" data-anchor-id="understanding-motivation-self-determination-theory">Understanding Motivation: Self-Determination Theory</h4>
<ul>
<li><p><strong>Three Basic Needs:</strong> Humans are driven by the need for:</p>
<ul>
<li><strong>Autonomy:</strong> Making our own choices.</li>
<li><strong>Competency:</strong> Developing skills and knowledge.</li>
<li><strong>Relatedness:</strong> Connecting with others.</li>
</ul></li>
<li><p><strong>The Online Appeal:</strong> The digital world often provides kids with more opportunities to satisfy these needs than traditional environments like schools.</p></li>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.nirandfar.com/indistractable/">Indistractable: How to Control Your Attention and Choose Your Life</a></li>
</ul>
</div>
</div></li>
</ul>
</section>
<section id="motivation-school-vs.-online" class="level4">
<h4 class="anchored" data-anchor-id="motivation-school-vs.-online">Motivation: School vs.&nbsp;Online</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 41%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>Need</th>
<th>School</th>
<th>Online</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Autonomy</td>
<td>Strict rules, limited choices</td>
<td>Freedom to choose, less adult control</td>
</tr>
<tr class="even">
<td>Competency</td>
<td>Standardized learning, limited agency</td>
<td>Personalized learning, self-directed exploration</td>
</tr>
<tr class="odd">
<td>Relatedness</td>
<td>Structured interactions, limited free time</td>
<td>Easy to connect with like-minded peers</td>
</tr>
</tbody>
</table>
</section>
<section id="navigating-screen-time-7-tactics-for-parents" class="level4">
<h4 class="anchored" data-anchor-id="navigating-screen-time-7-tactics-for-parents">Navigating Screen Time: 7 Tactics for Parents</h4>
<ol type="1">
<li><strong>Discuss Pros and Cons:</strong> Have open conversations about technology’s benefits and drawbacks.</li>
<li><strong>Show Empathy:</strong> Validate children’s feelings and acknowledge their struggle with limits.</li>
<li><strong>Share Your Own Challenges:</strong> Model healthy tech habits and be transparent about your own struggles.</li>
<li><strong>Collaborate on Boundaries:</strong> Involve children in setting screen time limits to foster a sense of ownership.</li>
<li><strong>Offer Offline Fulfillment:</strong> Provide ample opportunities for play, socializing, and pursuing passions offline.</li>
<li><strong>Encourage Creation over Consumption:</strong> Promote active engagement with technology through learning, making, and connecting.</li>
<li><strong>Provide a Better Yes:</strong> Ensure that saying no to screens means saying yes to something more engaging and fulfilling.</li>
</ol>
</section>
<section id="healthy-gaming-4-tactics" class="level4">
<h4 class="anchored" data-anchor-id="healthy-gaming-4-tactics">Healthy Gaming: 4 Tactics</h4>
<ol type="1">
<li><strong>Focus on Purposeful Play:</strong> Encourage gaming with a goal beyond escapism, such as socializing, learning, or skill-building.</li>
<li><strong>Maintain a Healthy Limit:</strong> Keep gaming under 21 hours per week to maximize benefits and minimize potential negative effects.</li>
<li><strong>Reverse the Order:</strong> Encourage studying after gaming to capitalize on the brain’s tendency to consolidate learning during sleep.</li>
<li><strong>Choose Social Over Competitive:</strong> Limit competitive play against strangers, emphasizing cooperative games or competing with known individuals.</li>
</ol>
</section>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>By understanding the psychological needs driving children’s tech use and applying game design principles thoughtfully, parents and educators can harness the power of games to foster learning, creativity, and healthy development.</p>
</section>
</section>
<section id="part-4-raising-successful-kids" class="level2">
<h2 class="anchored" data-anchor-id="part-4-raising-successful-kids">Part 4: Raising Successful Kids</h2>
<section id="chapter-13-skin-in-the-game" class="level3">
<h3 class="anchored" data-anchor-id="chapter-13-skin-in-the-game">Chapter 13: Skin in the Game</h3>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.penguinrandomhouse.com/books/537828/skin-in-the-game-by-nassim-nicholas-taleb/">Skin in the Game: Hidden Asymmetries in Daily Life</a></li>
</ul>
</div>
</div>
<section id="skin-in-the-game-for-kids" class="level4">
<h4 class="anchored" data-anchor-id="skin-in-the-game-for-kids">Skin in the Game for Kids</h4>
<ul>
<li><strong>Traditional school provides limited “skin in the game”:</strong> While grades offer some accountability, they lack relevance to the real world.</li>
<li><strong>Real-world problem-solving offers higher stakes:</strong> Children crave opportunities to tackle meaningful challenges with tangible outcomes.</li>
<li><strong>Benefits of Skin in the Game:</strong>
<ul>
<li><strong>Enhanced Learning:</strong> High stakes increase focus, motivation, and information retention.</li>
<li><strong>Memorable Experiences:</strong> Lessons learned through experience stick with us longer.</li>
<li><strong>Increased Engagement:</strong> Real-world application makes learning exciting and meaningful.</li>
</ul></li>
<li><strong>Synthesis - A Case Study:</strong>
<ul>
<li><strong>Conundrums:</strong> Synthesis initially presented complex ethical and practical dilemmas for children to debate.</li>
<li><strong>Simulations:</strong> Evolved to include competitive simulations with real winners and losers, raising the stakes and encouraging strategic thinking and decision-making.</li>
</ul></li>
</ul>
</section>
<section id="skin-in-the-game-for-parents" class="level4">
<h4 class="anchored" data-anchor-id="skin-in-the-game-for-parents">Skin in the Game for Parents</h4>
<ul>
<li><strong>Moving Beyond Outsourcing Education:</strong> Parents need to be active participants in their children’s education, not just rely on schools.</li>
<li><strong>Benefits of Parental Involvement:</strong>
<ul>
<li><strong>Stability for Children:</strong> Consistent support and understanding from someone who knows them well.</li>
<li><strong>Deeper Insights:</strong> Direct involvement provides unparalleled understanding of a child’s strengths, weaknesses, and learning style.</li>
<li><strong>Addressing Learning Gaps:</strong> Personalized attention can fill gaps and tailor the learning experience.</li>
<li><strong>Maximizing Quality Time:</strong> Leverage the formative years to directly impact a child’s future.</li>
</ul></li>
</ul>
</section>
<section id="how-to-increase-parental-involvement" class="level4">
<h4 class="anchored" data-anchor-id="how-to-increase-parental-involvement">How to Increase Parental Involvement:</h4>
<ul>
<li><strong>Explore Educational Options:</strong> Research and experiment with different programs, methods, and schools.</li>
<li><strong>Focus on One Subject:</strong> Start small by teaching a subject at home, even for a couple of hours a week.</li>
<li><strong>Pursue Passion Projects Together:</strong> Engage in activities the child is passionate about, learning and growing alongside them.</li>
<li><strong>Allow for Change:</strong> Be flexible and let children change their minds about activities they dislike.</li>
<li><strong>Take Responsibility:</strong> Avoid blaming teachers or schools when challenges arise, focus on finding solutions.</li>
</ul>
</section>
</section>
<section id="chapter-14-raising-antifragile-kids" class="level3">
<h3 class="anchored" data-anchor-id="chapter-14-raising-antifragile-kids">Chapter 14: Raising Antifragile Kids</h3>
<section id="the-downside-of-overprotection" class="level4">
<h4 class="anchored" data-anchor-id="the-downside-of-overprotection">The Downside of Overprotection:</h4>
<ul>
<li><strong>Shielding from Discomfort:</strong> Constantly protecting children from setbacks, disappointment, and failure hinders their development.</li>
<li><strong>Consequences of Overprotection:</strong>
<ul>
<li><strong>Inability to Handle Setbacks:</strong> Dependence on adults for problem-solving leads to discouragement when facing challenges.</li>
<li><strong>Low Self-Esteem:</strong> Feeling incapable of handling situations independently.</li>
</ul></li>
</ul>
</section>
<section id="the-power-of-anti-fragility" class="level4">
<h4 class="anchored" data-anchor-id="the-power-of-anti-fragility">The Power of Anti-Fragility:</h4>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.penguinrandomhouse.com/books/176227/antifragile-by-nassim-nicholas-taleb/">Antifragile: Things That Gain from Disorder</a></li>
</ul>
</div>
</div></li>
<li><p><strong>Definition:</strong> Antifragility, a term coined by Nassim Taleb, describes things that grow stronger when exposed to stress and randomness.</p></li>
<li><p><strong>Children are Antifragile:</strong> They thrive when allowed to face and overcome moderate challenges.</p></li>
<li><p><strong>Benefits of Embracing Challenges:</strong></p>
<ul>
<li><strong>Resilience:</strong> Developing the ability to bounce back from setbacks.</li>
<li><strong>Independence:</strong> Learning to solve problems and make decisions autonomously.</li>
<li><strong>Self-Confidence:</strong> Gaining belief in their own abilities through facing and overcoming challenges.</li>
</ul></li>
</ul>
</section>
<section id="fostering-antifragility" class="level4">
<h4 class="anchored" data-anchor-id="fostering-antifragility">Fostering Antifragility:</h4>
<ul>
<li><strong>Allow for Natural Consequences:</strong> Resist the urge to constantly intervene and solve problems for children.</li>
<li><strong>Encourage Risk-Taking:</strong> Create opportunities for safe, age-appropriate risks and challenges.</li>
<li><strong>Promote Problem-Solving:</strong> Guide children to find solutions independently before offering assistance.</li>
<li><strong>Model Resilience:</strong> Demonstrate healthy coping mechanisms and a positive attitude towards challenges.</li>
</ul>
</section>
</section>
<section id="chapter-15-how-to-develop-character-like-the-stoics" class="level3">
<h3 class="anchored" data-anchor-id="chapter-15-how-to-develop-character-like-the-stoics">Chapter 15: How to Develop Character Like the Stoics</h3>
<section id="the-importance-of-character-development" class="level4">
<h4 class="anchored" data-anchor-id="the-importance-of-character-development">The Importance of Character Development:</h4>
<ul>
<li><strong>Historical Perspective:</strong> Education in the past emphasized character development and producing virtuous citizens.</li>
<li><strong>Stoicism:</strong> A philosophy that stresses self-control, perseverance, and moral virtue.</li>
<li><strong>Relevancy of Stoicism:</strong> Stoic principles remain relevant today and can guide children towards becoming well-rounded adults.</li>
</ul>
</section>
<section id="the-four-stoic-virtues" class="level4">
<h4 class="anchored" data-anchor-id="the-four-stoic-virtues">The Four Stoic Virtues:</h4>
<ul>
<li><strong>Courage:</strong> Facing adversity with bravery and taking action despite fear.</li>
<li><strong>Temperance:</strong> Practicing moderation and avoiding extremes, finding a balance between recklessness and cowardice.</li>
<li><strong>Justice:</strong> Acting with fairness, honesty, and respect towards others, prioritizing the good of society.</li>
<li><strong>Wisdom:</strong> Applying knowledge and experience to make sound judgments and live a virtuous life.</li>
</ul>
</section>
<section id="four-tactics-for-developing-stoic-virtues" class="level4">
<h4 class="anchored" data-anchor-id="four-tactics-for-developing-stoic-virtues">Four Tactics for Developing Stoic Virtues:</h4>
<ul>
<li><strong>Read Stories of Heroes:</strong> Provide concrete examples of virtuous behavior through inspiring tales from history and mythology.</li>
<li><strong>Focus on What’s Controllable:</strong> Teach children to differentiate between things they can and cannot control and focus their efforts accordingly.</li>
<li><strong>Keep a Virtue Journal:</strong> Encourage self-reflection on how they demonstrate or could have better demonstrated virtues in daily life.</li>
<li><strong>Virtue as a Muscle:</strong> Explain that character strengthens over time with consistent effort and reflection, just like physical muscles.</li>
</ul>
</section>
</section>
<section id="chapter-16-range-and-specific-knowledge" class="level3">
<h3 class="anchored" data-anchor-id="chapter-16-range-and-specific-knowledge">Chapter 16: Range and Specific Knowledge</h3>
<section id="helping-kids-develop-range" class="level4">
<h4 class="anchored" data-anchor-id="helping-kids-develop-range">Helping Kids Develop Range</h4>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://davidepstein.com/range/">Range: Why Generalists Triumph in a Specialized World</a></li>
</ul>
</div>
</div></li>
<li><p><strong>Early Specialization vs.&nbsp;Range:</strong> While early specialization works in predictable fields, a broad base of knowledge is crucial in our complex world.</p></li>
<li><p><strong>Benefits of Range:</strong> Adaptability, creativity, and the ability to draw on diverse experiences to solve problems.</p></li>
<li><p><strong>Developing Range:</strong></p>
<ul>
<li><strong>Sampling Period:</strong> Encourage trying new activities without pressure to commit long-term.</li>
<li><strong>Unstructured Play:</strong> Foster imagination, creativity, and autonomy through play without predefined goals or adult direction.</li>
<li><strong>Self-Reflection:</strong> Prompt reflection on experiences to identify preferences, strengths, and areas for growth.</li>
<li><strong>Diverse Learning Diet:</strong> Expose children to various subjects, cultures, and ways of thinking through books, museums, travel, etc.</li>
</ul></li>
</ul>
</section>
<section id="discovering-specific-knowledge" class="level4">
<h4 class="anchored" data-anchor-id="discovering-specific-knowledge">Discovering Specific Knowledge:</h4>
<ul>
<li><strong>Definition:</strong> The unique combination of traits, experiences, and passions that allow an individual to make a unique contribution to the world.</li>
<li><strong>Identifying Specific Knowledge:</strong>
<ul>
<li><strong>Observe Natural Abilities:</strong> Pay attention to activities children excel at effortlessly or find intrinsically rewarding.</li>
<li><strong>Explore Passions:</strong> Encourage deep dives into subjects that spark their curiosity and enthusiasm.</li>
<li><strong>Embrace Late Blooming:</strong> Recognize that specific knowledge often emerges over time through exploration and experimentation.</li>
</ul></li>
</ul>
</section>
<section id="helping-kids-develop-specific-knowledge" class="level4">
<h4 class="anchored" data-anchor-id="helping-kids-develop-specific-knowledge">Helping Kids Develop Specific Knowledge:</h4>
<ul>
<li><strong>Focus on Play, Not Pressure:</strong> Avoid forcing specific knowledge; it should arise organically from genuine interest and enjoyment.</li>
<li><strong>Encourage Exploration:</strong> Provide space, resources, and support for children to pursue their passions.</li>
<li><strong>Guide, Don’t Control:</strong> Offer gentle guidance and mentorship without dictating their path.</li>
<li><strong>Build a Strong Foundation:</strong> Ensure a broad base of knowledge and skills (range) to provide context and fuel for discovering specific knowledge.</li>
</ul>
</section>
</section>
<section id="chapter-17-the-art-of-failing-and-quitting" class="level3">
<h3 class="anchored" data-anchor-id="chapter-17-the-art-of-failing-and-quitting">Chapter 17: The Art of Failing and Quitting</h3>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.johnholtgws.com/shop/p/how-children-fail">How Children Fail</a></li>
</ul>
</div>
</div>
<section id="the-art-of-failure" class="level4">
<h4 class="anchored" data-anchor-id="the-art-of-failure">The Art of Failure:</h4>
<ul>
<li><strong>Reframing Failure:</strong> Shift from viewing failure as negative to seeing it as a necessary step in the learning process.</li>
<li><strong>Benefits of Embracing Failure:</strong>
<ul>
<li><strong>Innovation and Progress:</strong> Failure often precedes breakthroughs and discoveries.</li>
<li><strong>Learning from Mistakes:</strong> Analyzing failures helps us refine our approaches and make better decisions in the future.</li>
</ul></li>
<li><strong>Encouraging Constructive Failure:</strong>
<ul>
<li><strong>Provide Opportunities for Small Failures:</strong> Create safe spaces for experimentation and risk-taking.</li>
<li><strong>Celebrate Failure as a Learning Experience:</strong> Encourage reflection and identify takeaways from setbacks.</li>
<li><strong>Model Healthy Self-Talk:</strong> Demonstrate positive self-talk and reframing negative thoughts after setbacks.</li>
<li><strong>Share Personal Failures:</strong> Show vulnerability by openly discussing your own experiences with failure.</li>
<li><strong>Highlight Stories of Resilience:</strong> Emphasize that many successful people overcame significant failures.</li>
</ul></li>
</ul>
</section>
<section id="the-art-of-quitting" class="level4">
<h4 class="anchored" data-anchor-id="the-art-of-quitting">The Art of Quitting:</h4>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Talk:</strong> <a href="https://www.youtube.com/watch?v=D73mm29XXAw">Prof Deepak Malhotra - HBS - 2012 Speech to Graduating Harvard MBA Students</a></li>
</ul>
</div>
</div></li>
<li><p><strong>Rethinking Quitting:</strong> Recognize quitting as a valuable tool for redirecting effort towards more fulfilling and impactful pursuits.</p></li>
<li><p><strong>Benefits of Quitting:</strong></p>
<ul>
<li><strong>Time Management:</strong> Free up time and energy to focus on activities that align with strengths and passions.</li>
<li><strong>Pursuing Specific Knowledge:</strong> Allowing children to disengage from unfulfilling activities helps them hone in on their unique talents.</li>
</ul></li>
<li><p><strong>Developing Healthy Quitting Habits:</strong></p>
<ul>
<li><strong>Establish Clear Quitting Principles:</strong> Help children differentiate between valid and invalid reasons for quitting (e.g., lack of interest vs.&nbsp;temporary difficulty).</li>
<li><strong>Encourage Reflection:</strong> Guide them to reflect on their experiences and articulate their reasons for wanting to quit.</li>
<li><strong>Support Decision-Making:</strong> Empower children to make informed choices about continuing or quitting activities.</li>
</ul></li>
</ul>
</section>
<section id="the-one-question-to-avoid" class="level4">
<h4 class="anchored" data-anchor-id="the-one-question-to-avoid">The One Question to Avoid:</h4>
<ul>
<li><strong>“What do you want to be when you grow up?”:</strong> This question is limiting, outdated, and potentially harmful.</li>
<li><strong>Why It’s Problematic:</strong>
<ul>
<li><strong>Fixed Mindset:</strong> Implies a single, predetermined path and discourages exploration.</li>
<li><strong>Limited Vision:</strong> Many future jobs haven’t been invented yet, and children’s interests evolve over time.</li>
<li><strong>Single Identity:</strong> People often have multiple careers and passions throughout their lives.</li>
</ul></li>
</ul>
</section>
<section id="better-alternatives" class="level4">
<h4 class="anchored" data-anchor-id="better-alternatives">Better Alternatives:</h4>
<ul>
<li><p><strong>“What do you love to do?”:</strong> Focus on uncovering passions and interests rather than job titles.</p></li>
<li><p><strong>“What are you curious about?”</strong>: Encourage exploration and a love of learning.</p></li>
<li><p><strong>Present Careers as Actions:</strong> Frame careers as verbs (things people do) instead of nouns (fixed identities).</p>
<ul>
<li><div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://adamgrant.net/book/think-again/">Think Again: The Power of Knowing What You Don’t Know</a></li>
</ul>
</div>
</div></li>
</ul></li>
</ul>
</section>
</section>
<section id="conclusion-1" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-1">Conclusion</h3>
<p>Raising successful children requires a shift from traditional models. We must empower children to face challenges, make decisions, and develop resilience through skin in the game. Parents should actively engage in their children’s education, guiding them to cultivate both range and specific knowledge. By embracing failure and quitting as valuable learning opportunities, we can help children discover their passions, hone their unique talents, and ultimately lead fulfilling and impactful lives.</p>
</section>
</section>
<section id="part-5-the-model-parent" class="level2">
<h2 class="anchored" data-anchor-id="part-5-the-model-parent">Part 5: The Model Parent</h2>
<section id="chapter-18-mental-models-for-parents" class="level3">
<h3 class="anchored" data-anchor-id="chapter-18-mental-models-for-parents">Chapter 18: Mental Models for Parents</h3>
<p>This chapter emphasizes the power of <strong>mental models</strong> in parenting.</p>
<p><strong>What are mental models?</strong></p>
<ul>
<li>Mental models are generalized rules of thumb about how the world works, helping us make sense of our experiences.</li>
<li>They act like maps, enabling us to connect information, recognize patterns, and gain a broader perspective for better decision-making.</li>
<li>Mental models are essential for clear, rational, and effective thinking, and they are relevant in various disciplines.</li>
<li>We need a diverse set of mental models from multiple disciplines to understand and navigate the complexities of life.</li>
</ul>
<p><strong>Why are mental models important for parents?</strong></p>
<ul>
<li>Parenting presents constantly evolving challenges with children’s ever-changing needs and an overwhelming amount of (often conflicting) advice.</li>
<li>Mental models provide a framework for processing information, evaluating options, and responding effectively to children’s behavior.</li>
</ul>
<p><strong>Five Mental Models for Parents:</strong></p>
<ol type="1">
<li><strong>Maslow’s Hammer:</strong> Avoid relying on a single parenting tactic (like a hammer seeing every problem as a nail). Children need diverse approaches as they grow and face new challenges.</li>
<li><strong>Reactance:</strong> Recognize that pressure often breeds resistance. Giving children autonomy and choices, rather than imposing our will, can be more effective.</li>
<li><strong>Nudges:</strong> Instead of just lecturing, create environments that naturally nudge children toward positive choices. For example, make healthy snacks more accessible than unhealthy ones.</li>
<li><strong>Reframing:</strong> Help children reframe challenges by shifting their perspective. Encourage them to find positive aspects or opportunities within difficult situations.</li>
<li><strong>Inversion:</strong> Teach children to approach problems by considering the opposite perspective (what they <em>don’t</em> want), then work backward to identify desirable actions.</li>
</ol>
<p><strong>Building Your Own Mental Models:</strong></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong><a href="https://fs.blog/">Farnham Street</a>:</strong> Organization offering resources and a course on mental models, including those relevant to parenting.
<ul>
<li><strong>Article:</strong> <a href="https://fs.blog/mental-models/">Mental Models: The Best Way to Make Intelligent Decisions (~100 Models Explained)</a></li>
</ul></li>
<li><strong>Superthinking by Gabriel Weinberg and Loring McCann:</strong> Book exploring over 100 mental models and their practical applications.
<ul>
<li><strong>Book:</strong> <a href="https://www.penguinrandomhouse.com/books/562923/super-thinking-by-gabriel-weinberg-and-lauren-mccann/">Super Thinking: The Big Book of Mental Models</a></li>
</ul></li>
</ul>
</div>
</div>
<ul>
<li><p><strong>Practice:</strong> Observe your child’s behavior for patterns, connect the dots with past experiences, and identify recurring themes.</p></li>
<li><p><strong>Document:</strong> Keep notes on your child’s behavior and your responses to recognize long-term trends and develop child-specific mental models.</p></li>
<li><p><strong>Use Checklists:</strong> Create checklists of strategies for common challenges, experiment to find what works, and update them as your child grows.</p></li>
</ul>
</section>
<section id="chapter-19-the-thinking-toolkit" class="level3">
<h3 class="anchored" data-anchor-id="chapter-19-the-thinking-toolkit">Chapter 19: The Thinking Toolkit</h3>
<p>This chapter argues that good thinking is a skill set anyone can develop. It focuses on three thinking tools:</p>
<section id="the-thinking-hats" class="level4">
<h4 class="anchored" data-anchor-id="the-thinking-hats">The Thinking Hats</h4>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.debono.com/Books/teach-your-child-how-to-think">Teach Your Child How To Think</a></li>
<li><strong>Book:</strong> <a href="https://www.debono.com/Books/six-thinking-hats">Six Thinking Hats</a></li>
</ul>
</div>
</div>
<p>Developed by Edward de Bono, the Six Thinking Hats encourage a well-rounded thinking process:</p>
<ol type="1">
<li><strong>White Hat (Facts):</strong> Focuses on objective information, gathering data, and identifying what’s known and unknown.</li>
<li><strong>Red Hat (Emotions):</strong> Explores feelings, intuitions, and emotional responses related to the situation.</li>
<li><strong>Black Hat (Caution):</strong> Engages in critical thinking, identifying risks, flaws, and potential downsides.</li>
<li><strong>Yellow Hat (Optimism):</strong> Explores the positive aspects, benefits, and potential advantages.</li>
<li><strong>Green Hat (Creativity):</strong> Encourages brainstorming, out-of-the-box thinking, and exploring new possibilities.</li>
<li><strong>Blue Hat (Metacognition):</strong> Oversees the thinking process itself, monitoring progress, managing the use of other hats, and reflecting on the overall approach.</li>
</ol>
<p><strong>Benefits of Using the Six Thinking Hats:</strong></p>
<ul>
<li><strong>Broadened Perspective:</strong> Helps children see situations from multiple angles instead of fixating on a single viewpoint.</li>
<li><strong>Improved Decision-Making:</strong> Encourages consideration of various factors before reaching a conclusion.</li>
<li><strong>Enhanced Creativity:</strong> Promotes the generation of novel ideas and solutions.</li>
<li><strong>Increased Wisdom:</strong> Develops the habit of thoughtful observation, careful consideration, and balanced judgment.</li>
</ul>
</section>
<section id="thinking-in-bets" class="level4">
<h4 class="anchored" data-anchor-id="thinking-in-bets">Thinking in Bets</h4>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.penguinrandomhouse.com/books/552885/thinking-in-bets-by-annie-duke/">Thinking in Bets: Making Smarter Decisions When You Don’t Have All the Facts</a></li>
</ul>
</div>
</div>
<p>This section highlights the importance of probabilistic thinking and making decisions with the understanding that the future is uncertain:</p>
<ul>
<li><strong>Avoid Resulting:</strong> Don’t judge the quality of a decision solely on its outcome, as luck plays a role. Instead, focus on the decision-making process itself.</li>
</ul>
<p><strong>Lessons for Children:</strong></p>
<ol type="1">
<li><strong>Think in Probabilities:</strong> Encourage children to express likelihood in terms of percentages rather than absolutes. Help them understand that multiple outcomes are possible.</li>
<li><strong>Keep an Open Mind:</strong> Promote flexibility and adaptability in thinking. Encourage children to consider various perspectives and be open to changing their minds.</li>
<li><strong>Collaborate:</strong> Facilitate group discussions where children can challenge each other’s thinking, identify biases, and learn from different viewpoints.</li>
<li><strong>Embrace Updates:</strong> Create a safe space for children to reflect on their decisions, acknowledge mistakes, and adjust their beliefs based on new information.</li>
</ol>
</section>
<section id="elastic-thinking" class="level4">
<h4 class="anchored" data-anchor-id="elastic-thinking">Elastic Thinking</h4>
<div class="callout callout-style-default callout-tip callout-titled" title="Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Book:</strong> <a href="https://www.amazon.com/gp/product/0141987391/">Elastic</a></li>
</ul>
</div>
</div>
<p>This section emphasizes the unique human capacity for creative and adaptable thinking:</p>
<p><strong>Three Types of Thinking:</strong></p>
<ol type="1">
<li><strong>Automatic:</strong> Reflexive responses to stimuli (common to most animals).</li>
<li><strong>Analytical:</strong> Logical, step-by-step reasoning (enhanced through education and practiced by computers).</li>
<li><strong>Elastic:</strong> Creative, spontaneous, and adaptable problem-solving in unfamiliar situations.</li>
</ol>
<p><strong>Cultivating Elastic Thinking in Children:</strong></p>
<ul>
<li><strong>Embrace Novelty:</strong> Move away from the rigid, rule-bound structure of traditional schooling.</li>
<li><strong>Encourage Exploration:</strong> Provide ample opportunities for unstructured play, self-directed projects, and experimentation.</li>
<li><strong>Value the Process:</strong> Focus on the journey of discovery and learning from mistakes rather than just achieving a predetermined outcome.</li>
</ul>
</section>
</section>
</section>
<section id="conclusion-design-your-learning-game" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-design-your-learning-game">Conclusion: Design Your Learning Game</h2>
<p>This section offers guidance for parents seeking to create a more engaging and effective learning environment for their children:</p>
<p><strong>Key Takeaways:</strong></p>
<ol type="1">
<li><strong>Encourage Independence:</strong> Avoid over-instruction; give children the space and resources to figure things out for themselves.</li>
<li><strong>Reframe Failure:</strong> Treat mistakes as valuable learning opportunities, not something to fear.</li>
<li><strong>Provide Meaningful Feedback:</strong> Focus praise on effort, ethics, the learning process, and a growth mindset, rather than just outcomes or innate ability.</li>
<li><strong>Grant Autonomy and Accountability:</strong> Involve children in decision-making, treat them like capable individuals, and trust them with responsibility.</li>
<li><strong>Support Passion Projects:</strong> Encourage children to pursue their own interests and devote time to self-directed learning endeavors.</li>
<li><strong>Expand Assessment Methods:</strong> Move beyond standardized tests and grades; embrace diverse ways for children to demonstrate knowledge and skills.</li>
<li><strong>Unlock Intrinsic Motivation:</strong> Minimize reliance on extrinsic rewards; help children discover the joy and satisfaction of learning for its own sake.</li>
<li><strong>Embrace Discomfort:</strong> Teach children to navigate challenges, uncertainty, and the feeling of not fitting in, building resilience.</li>
<li><strong>Allow for Confusion:</strong> Recognize that a healthy dose of confusion can spark curiosity and lead to deeper understanding.</li>
<li><strong>Encourage Questioning:</strong> Cultivate a skeptical mindset; empower children to inquire, seek evidence, and challenge assumptions.</li>
<li><strong>Cherish “Why” Questions:</strong> View these questions as signs of genuine curiosity and a desire to make sense of the world.</li>
<li><strong>Connect with Stories:</strong> Make learning relatable and memorable by tying information to compelling narratives and real-life examples.</li>
<li><strong>Develop Character:</strong> Emphasize ethical decision-making, courage, justice, temperance, and wisdom, drawing inspiration from stories of true heroes.</li>
<li><strong>Go Beyond Memorization:</strong> Focus on understanding concepts, their significance, and how to apply them in real-life scenarios.</li>
<li><strong>Identify and Leverage Strengths:</strong> Help children discover their talents, passions, and learning preferences through exploration and experimentation.</li>
<li><strong>Cultivate Skilled Thinking:</strong> Teach children mental models, critical thinking strategies, and a toolbox of approaches to problem-solving.</li>
<li><strong>Embrace Learning Preferences:</strong> Help children recognize and utilize their preferred learning styles while also expanding their repertoire.</li>
<li><strong>Leverage Video Games:</strong> Recognize the potential of well-designed games to engage children, provide immediate feedback, and teach valuable skills.</li>
<li><strong>Address Online Behavior:</strong> Have open conversations about online habits, finding healthy ways to fulfill the needs met through screen time in the real world.</li>
<li><strong>Gamify Learning (Thoughtfully):</strong> Incorporate game-like elements to make learning more engaging without turning it into a superficial point-gathering system.</li>
<li><strong>Increase Stakes (Safely):</strong> Connect learning to real-world scenarios and challenges, providing a sense of purpose and consequence without life-altering risks.</li>
<li><strong>Engage Deeply:</strong> Be an active participant in your child’s learning journey, understanding their needs, and partnering with them to support their growth.</li>
<li><strong>Utilize Mental Models (Parenting):</strong> Apply the concept of mental models to better understand and respond to your child’s behavior, creating a more harmonious dynamic.</li>
<li><strong>Avoid Overprotection:</strong> Allow your child to face age-appropriate challenges and develop resilience through experience.</li>
<li><strong>Find Balance:</strong> Strive for a balanced approach that encourages both challenge and support, knowing when to push and when to offer guidance and encouragement.</li>
</ol>


</section>

 ]]></description>
  <category>education</category>
  <category>notes</category>
  <guid>https://christianjmills.com/posts/the-learning-game-book-notes/</guid>
  <pubDate>Sat, 03 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Notes on Dumbing Us Down: The Hidden Curriculum of Compulsory Schooling</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/dumbing-us-down-book-notes/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
These notes are part of the following collection:
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="../../series/notes/education-notes.html"><strong>Education</strong></a></p>
</div>
</div>
<ul>
<li>Executive Summary</li>
<li>About the Author: John Taylor Gatto<br>
</li>
<li>Chapter 1: The Seven-Lesson Schoolteacher<br>
</li>
<li>Chapter 2: The Psychopathic School<br>
</li>
<li>Chapter 3: The Green Monongahela<br>
</li>
<li>Chapter 4: We Need Less School, Not More<br>
</li>
<li>Chapter 5: The Congregational Principle<br>
</li>
<li>Actionable Recommendations</li>
<li>Glossary</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Book LInks:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://newsociety.com/books/d/dumbing-us-down-25th-anniversary-edition">Publisher Page</a></li>
</ul>
</div>
</div>
<section id="executive-summary" class="level2">
<h2 class="anchored" data-anchor-id="executive-summary">Executive Summary</h2>
<p>John Taylor Gatto, a former New York State Teacher of the Year, argues that the American compulsory schooling system is inherently flawed, serving as a tool for social control and economic manipulation rather than genuine education.</p>
<p>He outlines seven harmful lessons instilled in students: confusion, class position, indifference, emotional dependency, intellectual dependency, provisional self-esteem, and constant surveillance.</p>
<p>Gatto advocates for a decentralized, community-based approach to education that prioritizes individual growth, self-reliance, and engagement with the real world, drawing inspiration from the successes of homeschooling and the historical model of colonial New England’s congregational principle.</p>
<p>He calls for radical reform, including decertification of teaching, privatization, and a return to family-centric learning.</p>
</section>
<section id="about-the-author-john-taylor-gatto" class="level2">
<h2 class="anchored" data-anchor-id="about-the-author-john-taylor-gatto">About the Author: John Taylor Gatto</h2>
<section id="personal-background-and-influences" class="level3">
<h3 class="anchored" data-anchor-id="personal-background-and-influences">Personal Background and Influences</h3>
<ul>
<li>Gatto draws from his 30-year experience teaching in diverse NYC schools, from affluent Upper West Side to underprivileged Harlem.</li>
<li>His upbringing in Monongahela, Pennsylvania, a tight-knit, working-class town, instilled in him a strong sense of community and self-reliance.</li>
<li>Contrasting the values of his hometown with the impersonal nature of Manhattan fueled his critical perspective on societal structures.</li>
<li>His grandfather, the town printer and former newspaper publisher, fostered Gatto’s independent thinking and provided valuable life lessons.</li>
</ul>
</section>
<section id="classroom-as-a-laboratory" class="level3">
<h3 class="anchored" data-anchor-id="classroom-as-a-laboratory">Classroom as a Laboratory</h3>
<ul>
<li>Gatto views his classrooms as spaces to observe and study the full spectrum of human potential and the factors that influence its expression.</li>
<li>He challenges the notion of intelligence as a normally distributed trait, having witnessed remarkable abilities in the most unexpected students.</li>
<li>This led him to question if the very structure of schooling, with its rigid schedules, constant monitoring, and lack of autonomy, stifles natural learning.</li>
</ul>
</section>
<section id="guerilla-exercises-to-empower-students" class="level3">
<h3 class="anchored" data-anchor-id="guerilla-exercises-to-empower-students">Guerilla Exercises to Empower Students</h3>
<ul>
<li>Gatto implements unconventional teaching methods that prioritize student freedom and self-directed learning:
<ul>
<li>Provides privacy and reduces surveillance</li>
<li>Offers choices in learning activities</li>
<li>Creates diverse learning environments and social interactions</li>
</ul></li>
<li>He aims to empower students to become their own teachers and shape their own education.</li>
</ul>
</section>
<section id="teaching-as-sculpture-not-painting" class="level3">
<h3 class="anchored" data-anchor-id="teaching-as-sculpture-not-painting">Teaching as Sculpture, Not Painting</h3>
<ul>
<li>Gatto uses the analogy of sculpture to describe his teaching philosophy:
<ul>
<li><strong>Traditional teaching:</strong> Like painting, it focuses on adding information onto a blank canvas (the student’s mind).</li>
<li><strong>Gatto’s approach:</strong> Like sculpting, it involves removing barriers that prevent inherent potential from emerging.</li>
</ul></li>
<li>He shifted away from seeing himself as the expert filling empty vessels to recognizing the innate abilities within each child.</li>
</ul>
</section>
<section id="threats-to-the-system" class="level3">
<h3 class="anchored" data-anchor-id="threats-to-the-system">Threats to the System</h3>
<ul>
<li>Gatto believes his teaching philosophy poses two major threats:
<ul>
<li><strong>To the school system:</strong> It challenges the fundamental assumptions that underpin the institution, such as the perceived difficulty of learning.</li>
<li><strong>To the economy:</strong> It could produce critically thinking individuals who disrupt the existing economic order that relies on conformity and a fixed social hierarchy.</li>
</ul></li>
</ul>
</section>
<section id="principles-of-successful-teaching" class="level3">
<h3 class="anchored" data-anchor-id="principles-of-successful-teaching">Principles of Successful Teaching</h3>
<ul>
<li><strong>Unconditional Trust:</strong> Allowing students to make mistakes and learn from them is crucial for self-mastery.</li>
<li><strong>Challenging Assumptions:</strong> Questioning traditional notions of valuable knowledge and a fulfilling life.</li>
<li><strong>Focus on Individual Paths:</strong> Encouraging students to pursue their own unique interests and truths.</li>
</ul>
</section>
<section id="the-invisible-curriculum-and-its-consequences" class="level3">
<h3 class="anchored" data-anchor-id="the-invisible-curriculum-and-its-consequences">The Invisible Curriculum and its Consequences</h3>
<ul>
<li>Gatto argues that compulsory schooling, despite its stated goals, promotes an “invisible curriculum” that:
<ul>
<li>Reinforces the legitimacy of the institution itself.</li>
<li>Prepares students for a society stratified by social class (caste).</li>
</ul></li>
<li>He acknowledges his own complicity in perpetuating this system, even unintentionally.</li>
</ul>
</section>
<section id="focusing-on-the-wrongs" class="level3">
<h3 class="anchored" data-anchor-id="focusing-on-the-wrongs">Focusing on the Wrongs</h3>
<ul>
<li>Gatto aims to illuminate the flaws of the education system:
<ul>
<li><strong>What he does right:</strong> Getting out of the way of students’ natural curiosity and providing space, time, and respect.</li>
<li><strong>What he does wrong:</strong> Unintentionally reinforcing the hidden curriculum and hindering true learning.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-1-the-seven-lesson-schoolteacher" class="level2">
<h2 class="anchored" data-anchor-id="chapter-1-the-seven-lesson-schoolteacher">Chapter 1: The Seven-Lesson Schoolteacher</h2>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>This chapter stems from Gatto’s 1991 New York State Teacher of the Year acceptance speech, where he ironically highlights the seven damaging lessons he teaches, revealing the hidden curriculum of compulsory schooling.</p>
</section>
<section id="lesson-1-confusion" class="level3">
<h3 class="anchored" data-anchor-id="lesson-1-confusion">Lesson 1: Confusion</h3>
<ul>
<li>Gatto argues that schools teach information out of context, creating a fragmented and disconnected learning experience.</li>
<li>The curriculum lacks coherence and is overloaded with disparate subjects and activities, leaving students feeling overwhelmed and panicked.</li>
<li>The constant exposure to numerous, often unconnected, adults further contributes to confusion.</li>
<li>Schools prioritize superficial jargon over genuine enthusiasm and in-depth understanding.</li>
<li>This systematic confusion conditions students to accept it as their destiny, inhibiting their ability to seek meaning and make connections.</li>
</ul>
</section>
<section id="lesson-2-class-position" class="level3">
<h3 class="anchored" data-anchor-id="lesson-2-class-position">Lesson 2: Class Position</h3>
<ul>
<li>Schools enforce a rigid class system based on academic performance and standardized testing.</li>
<li>Students are numbered and categorized, discouraged from aspiring beyond their assigned class.</li>
<li>Gatto admits to using false promises of upward mobility through test scores to motivate students, perpetuating the illusion of meritocracy.</li>
<li>He acknowledges the incompatibility of truth and school teaching, highlighting how the system reinforces social stratification.</li>
</ul>
</section>
<section id="lesson-3-indifference" class="level3">
<h3 class="anchored" data-anchor-id="lesson-3-indifference">Lesson 3: Indifference</h3>
<ul>
<li>Schools cultivate indifference by demanding enthusiasm during lessons but enforcing detachment at the sound of the bell.</li>
<li>Students are conditioned to switch their emotions on and off, preventing them from fully engaging with any subject.</li>
<li>The bell system signals that no work is worth finishing, fostering a lack of care and follow-through.</li>
<li>This learned indifference prepares students for a world without meaningful work, perpetuating a cycle of apathy.</li>
</ul>
</section>
<section id="lesson-4-emotional-dependency" class="level3">
<h3 class="anchored" data-anchor-id="lesson-4-emotional-dependency">Lesson 4: Emotional Dependency</h3>
<ul>
<li>Schools train students to be emotionally dependent on external authority figures.</li>
<li>Rewards and punishments are used to control behavior and suppress individuality, teaching students to surrender their will to the established hierarchy.</li>
<li>Gatto emphasizes the absence of genuine rights within schools, replaced by privileges granted or revoked at the whim of authority.</li>
<li>This dependency extends to personal decisions, with teachers intervening and dictating acceptable behavior.</li>
</ul>
</section>
<section id="lesson-5-intellectual-dependency" class="level3">
<h3 class="anchored" data-anchor-id="lesson-5-intellectual-dependency">Lesson 5: Intellectual Dependency</h3>
<ul>
<li>The most crucial lesson taught is intellectual dependency, conditioning students to rely on experts for knowledge and meaning.</li>
<li>Students are discouraged from independent thought, learning to passively accept information as presented by teachers.</li>
<li>Curiosity is suppressed, replaced by conformity to prescribed thinking.</li>
<li>This dependency prepares students for a workforce that follows orders without questioning, perpetuating a system reliant on unquestioning obedience.</li>
</ul>
</section>
<section id="lesson-6-provisional-self-esteem" class="level3">
<h3 class="anchored" data-anchor-id="lesson-6-provisional-self-esteem">Lesson 6: Provisional Self-Esteem</h3>
<ul>
<li>Schools link self-esteem to external evaluations, fostering a dependence on expert opinion.</li>
<li>Constant grading, testing, and reporting create a culture of judgment and dissatisfaction, undermining students’ self-worth.</li>
<li>Gatto argues that the system benefits from perpetuating dissatisfaction, mirroring the consumerist economy’s reliance on manufactured needs.</li>
<li>Students are discouraged from trusting their own judgment and that of their parents, relying instead on the pronouncements of certified officials.</li>
</ul>
</section>
<section id="lesson-7-one-cant-hide" class="level3">
<h3 class="anchored" data-anchor-id="lesson-7-one-cant-hide">Lesson 7: One Can’t Hide</h3>
<ul>
<li>Schools create an environment of constant surveillance, denying students privacy and autonomy.</li>
<li>Students are encouraged to tattle on each other and even on their own families, fostering an atmosphere of distrust and suspicion.</li>
<li>Homework extends surveillance into the home, hindering independent learning and family time.</li>
<li>This constant monitoring teaches students that privacy is illegitimate and that authority figures are always watching, preparing them for a society under constant control.</li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>Gatto argues that these seven lessons create a national curriculum that serves the interests of a centralized, hierarchical society at the expense of individual development and genuine education. He contends that this system is structurally unreformable, calling for a fundamental rethinking of educational approaches.</p>
</section>
</section>
<section id="chapter-2-the-psychopathic-school" class="level2">
<h2 class="anchored" data-anchor-id="chapter-2-the-psychopathic-school">Chapter 2: The Psychopathic School</h2>
<section id="introduction-1" class="level3">
<h3 class="anchored" data-anchor-id="introduction-1">Introduction</h3>
<p>This chapter originates from Gatto’s 1990 New York City Teacher of the Year acceptance speech, where he expands on the destructive nature of compulsory schooling and its connection to broader social ills.</p>
</section>
<section id="the-social-crisis-and-the-school-crisis" class="level3">
<h3 class="anchored" data-anchor-id="the-social-crisis-and-the-school-crisis">The Social Crisis and the School Crisis</h3>
<ul>
<li>Gatto links the crisis in American education to a larger social crisis marked by declining educational rankings, high rates of drug addiction, teenage suicide, and marriage instability.</li>
<li>He attributes these problems to a loss of identity and community, highlighting the isolation of children and the elderly from meaningful participation in society.</li>
<li>He criticizes the prevalence of networks over communities, lamenting the lack of genuine connections and the resulting sense of loneliness.</li>
</ul>
</section>
<section id="the-irrelevance-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-irrelevance-of-schooling">The Irrelevance of Schooling</h3>
<ul>
<li>Gatto argues that schools are increasingly irrelevant to the real world, failing to prepare students for the actual demands of various professions.</li>
<li>He emphasizes that schools primarily teach obedience, not critical thinking or practical skills.</li>
<li>He compares the school institution to a psychopath, lacking conscience and prioritizing conformity over individual growth.</li>
</ul>
</section>
<section id="the-origins-of-compulsory-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-origins-of-compulsory-schooling">The Origins of Compulsory Schooling</h3>
<ul>
<li>Gatto traces the origins of compulsory schooling to 19th-century Massachusetts, highlighting the resistance it faced from families who valued individual choice and local control.</li>
<li>He cites evidence suggesting that literacy rates were higher before compulsory schooling was implemented.</li>
<li>He draws parallels with the success of homeschooling, showcasing its ability to foster independent thinking and accelerate learning.</li>
</ul>
</section>
<section id="schooling-vs.-education" class="level3">
<h3 class="anchored" data-anchor-id="schooling-vs.-education">Schooling vs.&nbsp;Education</h3>
<ul>
<li>Gatto distinguishes between schooling and education, asserting that schools are designed for population management, not genuine learning.</li>
<li>He criticizes the school system’s emphasis on producing predictable and controllable individuals, arguing that this renders them irrelevant and useless in a rapidly changing world.</li>
<li>He attributes social problems like drug abuse, mindless competition, and materialism to the dependency and aimlessness fostered by the current educational paradigm.</li>
</ul>
</section>
<section id="the-effects-of-time-deprivation-and-abstraction" class="level3">
<h3 class="anchored" data-anchor-id="the-effects-of-time-deprivation-and-abstraction">The Effects of Time Deprivation and Abstraction</h3>
<ul>
<li>Gatto highlights the limited time available for children to develop their unique identities, with schooling, homework, and television consuming most of their waking hours.</li>
<li>He emphasizes the detrimental effects of abstract learning detached from real-world experience.</li>
<li>He lists specific pathologies resulting from this system, including indifference, lack of curiosity, a poor sense of the future, cruelty, difficulty with intimacy, materialism, dependency, passivity, and timidity.</li>
</ul>
</section>
<section id="a-call-for-change" class="level3">
<h3 class="anchored" data-anchor-id="a-call-for-change">A Call for Change</h3>
<ul>
<li>Gatto calls for a sustained national debate on the purpose and structure of education, urging a move away from top-down control and towards grassroots solutions.</li>
<li>He promotes homeschooling as a viable alternative, advocating for the redirection of funds to family-centric education.</li>
<li>He emphasizes the need to reject the mechanical and anti-human aspects of the current system, returning to a philosophy that prioritizes self-knowledge, family, and community.</li>
</ul>
</section>
</section>
<section id="chapter-3-the-green-monongahela" class="level2">
<h2 class="anchored" data-anchor-id="chapter-3-the-green-monongahela">Chapter 3: The Green Monongahela</h2>
<section id="introduction-2" class="level3">
<h3 class="anchored" data-anchor-id="introduction-2">Introduction</h3>
<p>Gatto reflects on his childhood in Monongahela, Pennsylvania, and how his experiences shaped his philosophy of education.</p>
</section>
<section id="early-education-on-the-river" class="level3">
<h3 class="anchored" data-anchor-id="early-education-on-the-river">Early Education on the River</h3>
<ul>
<li>The Monongahela River served as Gatto’s first classroom, fostering his observation skills and love of nature.</li>
<li>He learned from the diverse people in his community, from riverboat workers to train conductors, absorbing lessons about work, responsibility, and adventure.</li>
<li>These experiences instilled in him a sense of purpose and belonging, contrasting sharply with the sterile environment of institutional schooling.</li>
</ul>
</section>
<section id="leaving-monongahela-and-finding-significance-in-teaching" class="level3">
<h3 class="anchored" data-anchor-id="leaving-monongahela-and-finding-significance-in-teaching">Leaving Monongahela and Finding Significance in Teaching</h3>
<ul>
<li>Gatto recounts his disillusionment with his advertising career, seeking meaning beyond superficial consumerism.</li>
<li>He found his calling as a teacher, drawn to the potential for making a genuine difference in the lives of young people.</li>
<li>He contrasts the sense of purpose he felt in teaching with the emptiness of his corporate job.</li>
</ul>
</section>
<section id="leaving-advertising-for-teaching" class="level3">
<h3 class="anchored" data-anchor-id="leaving-advertising-for-teaching">Leaving Advertising for Teaching</h3>
<ul>
<li>Gatto describes his initial struggles as a substitute teacher in New York City, grappling with challenging working conditions and a lack of support from the system.</li>
<li>He recounts a near-violent encounter with a student, highlighting the chaotic and demoralizing environment of many urban schools.</li>
</ul>
</section>
<section id="milagros-and-the-power-of-a-student" class="level3">
<h3 class="anchored" data-anchor-id="milagros-and-the-power-of-a-student">Milagros and the Power of a Student</h3>
<ul>
<li>Gatto’s perspective shifted when he encountered Milagros, a gifted reader stuck in a low-level class due to bureaucratic indifference.</li>
<li>He championed her cause, challenging the school authorities and ultimately securing her placement in a more appropriate learning environment.</li>
<li>Milagros’ heartfelt expression of gratitude, “A teacher like you cannot be found,” solidified Gatto’s commitment to teaching.</li>
</ul>
</section>
<section id="milagros-accomplishments" class="level3">
<h3 class="anchored" data-anchor-id="milagros-accomplishments">Milagros’ Accomplishments</h3>
<ul>
<li>Gatto learns years later that Milagros went on to become a successful teacher herself, validating his belief in the transformative power of individual encouragement and recognizing potential.</li>
<li>He reflects on the possibility that his intervention served as a catalyst for Milagros, drawing a parallel with the influential figures from his own childhood.</li>
</ul>
</section>
</section>
<section id="chapter-4-we-need-less-school-not-more" class="level2">
<h2 class="anchored" data-anchor-id="chapter-4-we-need-less-school-not-more">Chapter 4: We Need Less School, Not More</h2>
<section id="introduction-3" class="level3">
<h3 class="anchored" data-anchor-id="introduction-3">Introduction</h3>
<p>This chapter delves into the detrimental effects of expanding the scope of institutional schooling, advocating for a reduction in its influence.</p>
</section>
<section id="communities-vs.-networks" class="level3">
<h3 class="anchored" data-anchor-id="communities-vs.-networks">Communities vs.&nbsp;Networks</h3>
<ul>
<li>Gatto distinguishes between communities and networks, emphasizing the vital role of communities in fostering holistic human development.</li>
<li>He argues that networks, while efficient, drain vitality from communities and families, offering temporary, mechanical solutions to complex human problems.</li>
<li>He criticizes the notion of replacing a bad network with a good one, highlighting the inherent limitations of network-based solutions.</li>
</ul>
</section>
<section id="the-limits-of-networks" class="level3">
<h3 class="anchored" data-anchor-id="the-limits-of-networks">The Limits of Networks</h3>
<ul>
<li>Gatto uses the example of weight loss to illustrate the shortcomings of quick-fix, network-driven solutions.</li>
<li>He contrasts the fleeting nature of network relationships with the enduring bonds of family and community.</li>
<li>He criticizes the narrow focus of networks, which require individuals to suppress aspects of their personality, leading to fragmentation and a sense of disconnection.</li>
</ul>
</section>
<section id="the-fragmentation-of-modern-life" class="level3">
<h3 class="anchored" data-anchor-id="the-fragmentation-of-modern-life">The Fragmentation of Modern Life</h3>
<ul>
<li>Gatto argues that excessive networking leads to a fragmented sense of self, with individuals compartmentalizing their lives into specialized roles.</li>
<li>He attributes social problems like divorce and a feeling of being “out of control” to this fragmentation, highlighting the emotional toll of prioritizing network interests.</li>
</ul>
</section>
<section id="the-success-of-homeschooling" class="level3">
<h3 class="anchored" data-anchor-id="the-success-of-homeschooling">The Success of Homeschooling</h3>
<ul>
<li>Gatto champions the success of homeschooling, demonstrating that certified schools are not necessary for acquiring a good education.</li>
<li>He points to the growing homeschooling movement as evidence of a desire for alternatives to the dominant educational paradigm.</li>
<li>He emphasizes that homeschooling allows children to learn in a context that fosters self-reliance and independent thinking.</li>
</ul>
</section>
<section id="schools-as-networks" class="level3">
<h3 class="anchored" data-anchor-id="schools-as-networks">Schools as Networks</h3>
<ul>
<li>Gatto reiterates the distinction between communities and networks, applying this framework to schools.</li>
<li>He criticizes schools for isolating children from the diversity of real life and for imposing artificial structures that stifle individuality.</li>
<li>He argues that schools destroy community vitality by preempting time and energy that could be devoted to building genuine connections.</li>
</ul>
</section>
<section id="schools-destroying-community-vitality" class="level3">
<h3 class="anchored" data-anchor-id="schools-destroying-community-vitality">Schools Destroying Community Vitality</h3>
<ul>
<li>Gatto details specific ways in which schools undermine community and family life:
<ul>
<li>Separating children from the working world and from interaction with different age groups.</li>
<li>Interrupting learning with bells and schedules, devaluing the importance of sustained engagement.</li>
<li>Suppressing individuality and enforcing conformity through rigid rules and punishments.</li>
<li>Fostering competition and envy through grading and ranking systems.</li>
</ul></li>
<li>He concludes that we need less schooling, not more, to allow communities and families to reclaim their vital roles in child development.</li>
</ul>
</section>
<section id="human-beings-beyond-rationality" class="level3">
<h3 class="anchored" data-anchor-id="human-beings-beyond-rationality">Human Beings Beyond Rationality</h3>
<ul>
<li>Gatto challenges the Enlightenment’s emphasis on rationality, arguing that humans are more than just machines and that our deepest needs cannot be met through purely rational systems.</li>
<li>He criticizes the dehumanizing effects of networks, which prioritize efficiency over emotional well-being.</li>
<li>He asserts that networks inherently make people lonely, failing to provide the authentic connections that nourish the human spirit.</li>
</ul>
</section>
<section id="loneliness-in-a-crowd" class="level3">
<h3 class="anchored" data-anchor-id="loneliness-in-a-crowd">Loneliness in a Crowd</h3>
<ul>
<li>Gatto describes the paradoxical experience of feeling lonely even when surrounded by people in network-dominated environments.</li>
<li>He argues that networks, no matter how numerous, cannot substitute for genuine community, leaving individuals feeling isolated and unseen.</li>
<li>He emphasizes the transient nature of network relationships, contrasting them with the enduring bonds of family and community.</li>
</ul>
</section>
<section id="the-natural-order-of-society" class="level3">
<h3 class="anchored" data-anchor-id="the-natural-order-of-society">The Natural Order of Society</h3>
<ul>
<li>Gatto traces the historical development of society, asserting that families came first, followed by communities, and only later by institutions.</li>
<li>He criticizes the modern tendency for institutions to claim authority over families and communities, demanding primary loyalty and dictating how people should live.</li>
<li>He challenges the notion of the state as a surrogate parent, arguing that this undermines the essential role of families in shaping individual values and identity.</li>
</ul>
</section>
<section id="the-destructive-claim-of-institutional-prerogative" class="level3">
<h3 class="anchored" data-anchor-id="the-destructive-claim-of-institutional-prerogative">The Destructive Claim of Institutional Prerogative</h3>
<ul>
<li>Gatto examines the harmful effects of institutional dominance on individuals and families.</li>
<li>He criticizes the narrow focus of institutions, which prioritize specialized performance over holistic development.</li>
<li>He argues that defining success within institutional frameworks leads to alienation from oneself and from others.</li>
</ul>
</section>
<section id="the-united-states-as-a-nation-of-institutions" class="level3">
<h3 class="anchored" data-anchor-id="the-united-states-as-a-nation-of-institutions">The United States as a Nation of Institutions</h3>
<ul>
<li>Gatto laments the transformation of the United States from a nation of communities to a nation of institutions.</li>
<li>He attributes the decline of community life to the isolating effects of large cities and the competition from institutions for the time and attention of citizens.</li>
<li>He points to low voter turnout as evidence of alienation and disengagement from civic life.</li>
</ul>
</section>
<section id="alienation-from-community-life" class="level3">
<h3 class="anchored" data-anchor-id="alienation-from-community-life">Alienation from Community Life</h3>
<ul>
<li>Gatto criticizes the prevalence of “pseudo-communities” – simulated gatherings that lack the genuine connections and shared responsibilities of true communities.</li>
<li>He argues that institutional simulations of community fail to meet fundamental human needs, leading to feelings of isolation and dissatisfaction.</li>
</ul>
</section>
<section id="the-jeopardy-of-human-needs" class="level3">
<h3 class="anchored" data-anchor-id="the-jeopardy-of-human-needs">The Jeopardy of Human Needs</h3>
<ul>
<li>Gatto argues that institutional goals, even when well-intentioned, cannot fully align with the unique needs of individuals.</li>
<li>He emphasizes the lack of conscience in institutions, which operate based on impersonal accounting methods rather than genuine concern for human well-being.</li>
<li>He criticizes the tendency for institutions to prioritize uniformity and control over individual expression and variety.</li>
</ul>
</section>
<section id="the-damage-of-institutional-intervention" class="level3">
<h3 class="anchored" data-anchor-id="the-damage-of-institutional-intervention">The Damage of Institutional Intervention</h3>
<ul>
<li>Gatto warns against the dangers of ceding power to institutions, comparing it to anointing a machine as king.</li>
<li>He emphasizes the pervasive reach of technology, which amplifies the influence of institutions and makes escape from their control increasingly difficult.</li>
</ul>
</section>
<section id="institutional-survival-as-the-primary-goal" class="level3">
<h3 class="anchored" data-anchor-id="institutional-survival-as-the-primary-goal">Institutional Survival as the Primary Goal</h3>
<ul>
<li>Gatto cites the observation of a French sociologist that every institution’s primary goal is its own survival and growth, often overshadowing its stated mission.</li>
<li>He uses the examples of postal services and the military to illustrate this principle, highlighting the tendency for institutions to prioritize the interests of their employees over their intended beneficiaries.</li>
</ul>
</section>
<section id="schools-as-protective-institutions-for-teachers" class="level3">
<h3 class="anchored" data-anchor-id="schools-as-protective-institutions-for-teachers">Schools as Protective Institutions for Teachers</h3>
<ul>
<li>Gatto argues that schools have become protective institutions for teachers, rather than places of learning for students.</li>
<li>He criticizes the New York City public school system for its poor performance despite its vast resources and coercive power.</li>
</ul>
</section>
<section id="freedom-from-institutional-intervention" class="level3">
<h3 class="anchored" data-anchor-id="freedom-from-institutional-intervention">Freedom from Institutional Intervention</h3>
<ul>
<li>Gatto contrasts the liberating atmosphere of communities with limited institutional influence to the stifling environment of urban centers dominated by networks and institutions.</li>
<li>He suggests that freedom from institutional intervention allows for greater self-reliance, community spirit, and individual growth.</li>
</ul>
</section>
<section id="education-as-an-economic-good" class="level3">
<h3 class="anchored" data-anchor-id="education-as-an-economic-good">Education as an Economic Good</h3>
<ul>
<li>Gatto challenges the prevailing view of education as an economic good, arguing that this reinforces a consumerist mindset and perpetuates unsustainable patterns of consumption.</li>
<li>He questions the wisdom of linking educational success to material wealth, considering the social and environmental costs of rampant consumerism.</li>
</ul>
</section>
<section id="the-absurdity-of-economic-education" class="level3">
<h3 class="anchored" data-anchor-id="the-absurdity-of-economic-education">The Absurdity of Economic Education</h3>
<ul>
<li>Gatto exposes the absurdity of equating education with economic advancement, highlighting the emptiness of a life defined by material possessions.</li>
<li>He urges a reevaluation of our priorities, suggesting that genuine education should foster values beyond material acquisition.</li>
</ul>
</section>
<section id="the-true-purpose-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-true-purpose-of-schooling">The True Purpose of Schooling</h3>
<ul>
<li>Gatto questions the true purpose of mass schooling, rejecting the notions that it aims to create a wealthy elite or to prepare students for meaningful work.</li>
<li>He criticizes the system’s reliance on competition, social stratification, and material rewards, arguing that this contradicts the principles of a just and equitable society.</li>
</ul>
</section>
<section id="natural-limits-of-communities" class="level3">
<h3 class="anchored" data-anchor-id="natural-limits-of-communities">Natural Limits of Communities</h3>
<ul>
<li>Gatto contrasts the natural limits of communities with the indefinite expansion of institutions and networks.</li>
<li>He argues that communities foster a sense of belonging and importance because they are small enough for individuals to make a noticeable impact.</li>
<li>He criticizes pseudo-communities for creating a sense of anonymity and alienation, leading to a reliance on consumerism to fulfill basic human needs.</li>
</ul>
</section>
<section id="pseudo-communities" class="level3">
<h3 class="anchored" data-anchor-id="pseudo-communities">Pseudo-Communities</h3>
<ul>
<li>Gatto describes the characteristics of pseudo-communities:
<ul>
<li>Transient relationships and weak bonds.</li>
<li>A tendency to view problems as someone else’s responsibility.</li>
<li>A desire to escape and “trade up” to a supposedly better place.</li>
</ul></li>
<li>He contrasts these with the enduring connections and shared purpose of genuine communities.</li>
</ul>
</section>
<section id="the-indefinite-expansion-of-networks" class="level3">
<h3 class="anchored" data-anchor-id="the-indefinite-expansion-of-networks">The Indefinite Expansion of Networks</h3>
<ul>
<li>Gatto argues that networks, unlike communities, have an inherent tendency to expand indefinitely, fueled by the profit motive of those who benefit from their growth.</li>
<li>He criticizes the push for expanding the scope of schooling, recognizing it as a ploy for increased control and financial gain.</li>
</ul>
</section>
<section id="measuring-success-in-networks" class="level3">
<h3 class="anchored" data-anchor-id="measuring-success-in-networks">Measuring Success in Networks</h3>
<ul>
<li>Gatto contrasts the multifaceted satisfactions of community life with the narrow, quantitative measures of success prevalent in networks.</li>
<li>He criticizes the competitive nature of networks, which pits individuals against each other for material rewards and recognition.</li>
</ul>
</section>
<section id="the-contradictions-of-school-competition" class="level3">
<h3 class="anchored" data-anchor-id="the-contradictions-of-school-competition">The Contradictions of School Competition</h3>
<ul>
<li>Gatto argues that competition within institutions like schools is fundamentally different from competition in the free market.</li>
<li>He points out that school competition is often subjective and arbitrary, leading to envy, dissatisfaction, and a reliance on manipulation rather than genuine effort.</li>
</ul>
</section>
<section id="truth-in-communities-vs.-networks" class="level3">
<h3 class="anchored" data-anchor-id="truth-in-communities-vs.-networks">Truth in Communities vs.&nbsp;Networks</h3>
<ul>
<li>Gatto highlights the importance of honesty in communities, where reputation and trust are paramount.</li>
<li>He contrasts this with the prevalence of lying and deception within institutions, where individuals are often seen as adversaries and manipulation is considered part of the game.</li>
</ul>
</section>
<section id="the-cathedral-of-reims-as-a-model-of-community" class="level3">
<h3 class="anchored" data-anchor-id="the-cathedral-of-reims-as-a-model-of-community">The Cathedral of Reims as a Model of Community</h3>
<ul>
<li>Gatto uses the example of the Cathedral of Reims, built over centuries by a community of skilled artisans, as a testament to the power of shared purpose and uncoerced collaboration.</li>
<li>He emphasizes the absence of individual recognition and self-promotion among the builders, highlighting the collectivist spirit that drove the project.</li>
</ul>
</section>
<section id="the-essence-of-communities" class="level3">
<h3 class="anchored" data-anchor-id="the-essence-of-communities">The Essence of Communities</h3>
<ul>
<li>Gatto defines communities as extensions of family, where individuals find meaning in belonging to a larger group with shared values and responsibilities.</li>
<li>He emphasizes the importance of face-to-face interaction, mutual support, and the acceptance of human variety as essential elements of thriving communities.</li>
</ul>
</section>
<section id="the-allure-of-artificial-integration" class="level3">
<h3 class="anchored" data-anchor-id="the-allure-of-artificial-integration">The Allure of Artificial Integration</h3>
<ul>
<li>Gatto warns against the allure of artificial integration offered by institutions and networks, which promise a sense of belonging but ultimately fail to deliver.</li>
<li>He argues that this artificial integration is superficial and fleeting, leaving individuals feeling isolated and unfulfilled.</li>
</ul>
</section>
<section id="the-new-world-order-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-new-world-order-of-schooling">The New World Order of Schooling</h3>
<ul>
<li>Gatto criticizes proposals to expand the role of schools into providing all-encompassing services, such as meals, therapy, and recreation.</li>
<li>He argues that this “New World Order” of schooling would further weaken families and communities by usurping their traditional functions.</li>
<li>He sees schools as already contributing to the breakdown of family life by isolating children from their parents and undermining their sense of belonging.</li>
</ul>
</section>
<section id="the-maximum-efficiency-of-schools" class="level3">
<h3 class="anchored" data-anchor-id="the-maximum-efficiency-of-schools">The Maximum Efficiency of Schools</h3>
<ul>
<li>Gatto asserts that schools have reached their maximum efficiency, meaning that any further expansion will likely worsen rather than improve outcomes.</li>
<li>He calls for a shift in focus from increasing the scale of schooling to rethinking its fundamental purpose and structure.</li>
</ul>
</section>
<section id="the-true-purpose-of-education" class="level3">
<h3 class="anchored" data-anchor-id="the-true-purpose-of-education">The True Purpose of Education</h3>
<ul>
<li>Gatto outlines his vision for genuine education:
<ul>
<li>Fostering individuality and originality.</li>
<li>Equipping students with the tools to tackle life’s challenges.</li>
<li>Guiding them towards a personal code of values.</li>
<li>Instilling a love of learning and a sense of purpose.</li>
</ul></li>
<li>He argues that mass schooling fails to achieve these goals, prioritizing conformity and obedience over individual development.</li>
</ul>
</section>
<section id="social-engineering-and-the-one-right-way" class="level3">
<h3 class="anchored" data-anchor-id="social-engineering-and-the-one-right-way">Social Engineering and the One Right Way</h3>
<ul>
<li>Gatto criticizes the “one right way” approach to education, arguing that it is based on a flawed theory of social engineering that seeks to control and homogenize individuals.</li>
<li>He advocates for a more decentralized approach that recognizes the diversity of human potential and allows for individual choice.</li>
</ul>
</section>
<section id="the-hive-society" class="level3">
<h3 class="anchored" data-anchor-id="the-hive-society">The Hive Society</h3>
<ul>
<li>Gatto warns against the dangers of creating a “hive society,” where individuality is suppressed and conformity reigns supreme.</li>
<li>He attributes the rise of social pathologies like drug addiction and violence to the stifling effects of institutional control.</li>
</ul>
</section>
<section id="the-flawed-theory-and-structure-of-mass-education" class="level3">
<h3 class="anchored" data-anchor-id="the-flawed-theory-and-structure-of-mass-education">The Flawed Theory and Structure of Mass Education</h3>
<ul>
<li>Gatto reiterates his belief that the current system of mass education is fundamentally flawed and cannot be reformed through incremental changes.</li>
<li>He argues that it undermines the principles of democracy by prioritizing uniformity and control over individual liberty.</li>
</ul>
</section>
<section id="the-cost-of-education-vs.-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-cost-of-education-vs.-schooling">The Cost of Education vs.&nbsp;Schooling</h3>
<ul>
<li>Gatto emphasizes the distinction between education, which is inherently inexpensive and self-directed, and schooling, which is a costly and inefficient system.</li>
<li>He encourages families to reclaim their educational authority and to seek alternatives to the institutional model.</li>
</ul>
</section>
<section id="bertrand-russells-critique-of-american-schooling" class="level3">
<h3 class="anchored" data-anchor-id="bertrand-russells-critique-of-american-schooling">Bertrand Russell’s Critique of American Schooling</h3>
<ul>
<li>Gatto cites Bertrand Russell’s criticism of American schooling, highlighting its anti-democratic tendencies and its production of conformist, uncritical citizens.</li>
<li>He agrees with Russell’s assessment that mass schooling hinders the development of “inner freedom” and creates a shallow, materialistic culture.
<ul>
<li><a href="https://archive.org/stream/in.ernet.dli.2015.139389/2015.139389.The-Basic-Writings-Of-Bertrand-Russell_djvu.txt">The Basic Writings Of Bertrand Russell - The Aims of Education</a></li>
</ul></li>
</ul>
</section>
<section id="american-national-unity-and-the-role-of-schooling" class="level3">
<h3 class="anchored" data-anchor-id="american-national-unity-and-the-role-of-schooling">American National Unity and the Role of Schooling</h3>
<ul>
<li>Gatto argues that the quest for national unity has led to misguided attempts to homogenize the population through forced schooling.</li>
<li>He suggests that this approach has backfired, undermining the very values it sought to promote.</li>
</ul>
</section>
<section id="building-families-and-communities" class="level3">
<h3 class="anchored" data-anchor-id="building-families-and-communities">Building Families and Communities</h3>
<ul>
<li>Gatto advocates for a return to strong families and communities as the foundation for a healthy society.</li>
<li>He suggests that rebuilding these units will empower individuals to take charge of their own education and to contribute to the common good.</li>
</ul>
</section>
<section id="breaking-up-institutional-schools" class="level3">
<h3 class="anchored" data-anchor-id="breaking-up-institutional-schools">Breaking Up Institutional Schools</h3>
<ul>
<li>Gatto proposes radical reforms to the schooling system:
<ul>
<li>Decertifying teaching and allowing anyone to compete in the educational marketplace.</li>
<li>Privatizing education and giving families control over their educational choices.</li>
<li>Trusting the free market to deliver diverse and effective learning opportunities.</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-5-the-congregational-principle" class="level2">
<h2 class="anchored" data-anchor-id="chapter-5-the-congregational-principle">Chapter 5: The Congregational Principle</h2>
<section id="introduction-4" class="level3">
<h3 class="anchored" data-anchor-id="introduction-4">Introduction</h3>
<p>Gatto explores the history of colonial New England’s Congregationalist movement as a model for a decentralized, community-based approach to education.</p>
</section>
<section id="the-surrealism-of-educational-reform" class="level3">
<h3 class="anchored" data-anchor-id="the-surrealism-of-educational-reform">The Surrealism of Educational Reform</h3>
<ul>
<li>Gatto criticizes the ongoing push for centralized educational reforms, arguing that these proposals ignore the lessons of history and perpetuate a system that has consistently failed to deliver on its promises.</li>
<li>He suggests that the search for “one right answer” to the educational crisis is misguided, advocating for a more pluralistic approach that embraces local control and individual choice.</li>
</ul>
</section>
<section id="colonial-new-england-and-a-different-theory-of-institutions" class="level3">
<h3 class="anchored" data-anchor-id="colonial-new-england-and-a-different-theory-of-institutions">Colonial New England and a Different Theory of Institutions</h3>
<ul>
<li>Gatto contrasts the centralized, top-down approach of modern schooling with the decentralized, community-based model of colonial New England.</li>
<li>He highlights the Congregationalist principle of local autonomy and self-governance, where congregations determined their own affairs without external interference.</li>
</ul>
</section>
<section id="the-salem-procedure" class="level3">
<h3 class="anchored" data-anchor-id="the-salem-procedure">The Salem Procedure</h3>
<ul>
<li>Gatto describes the “Salem Procedure” of 1629, where the First Puritan Church at Salem established the principle of congregational authority.</li>
<li>He emphasizes the significance of this act, which shifted power from certified experts to the members of the congregation themselves.</li>
</ul>
</section>
<section id="localism-and-decentralization" class="level3">
<h3 class="anchored" data-anchor-id="localism-and-decentralization">Localism and Decentralization</h3>
<ul>
<li>Gatto explains how the Congregationalist system fostered localism and decentralization:
<ul>
<li>Each congregation had the freedom to interpret doctrine and to address local issues through open debate among its members.</li>
<li>They took responsibility for their own problems, rather than relying on central authorities for solutions.</li>
</ul></li>
</ul>
</section>
<section id="the-congregational-monopoly" class="level3">
<h3 class="anchored" data-anchor-id="the-congregational-monopoly">The Congregational Monopoly</h3>
<ul>
<li>Gatto acknowledges the irony of the Congregationalists’ initial insistence on religious uniformity, despite their commitment to local control.</li>
<li>He describes their opposition to other denominations, such as Unitarianism, and their attempts to maintain their religious monopoly.</li>
</ul>
</section>
<section id="the-transformation-of-congregationalism" class="level3">
<h3 class="anchored" data-anchor-id="the-transformation-of-congregationalism">The Transformation of Congregationalism</h3>
<ul>
<li>Gatto highlights the remarkable transformation of Congregationalism over time, as it gradually embraced greater tolerance and diversity.</li>
<li>He attributes this evolution to the inherent dynamism of the Congregationalist principle, which allowed for internal debate and self-correction.</li>
</ul>
</section>
<section id="the-dialectical-nature-of-congregationalism" class="level3">
<h3 class="anchored" data-anchor-id="the-dialectical-nature-of-congregationalism">The Dialectical Nature of Congregationalism</h3>
<ul>
<li>Gatto explains how the Congregationalist approach to decision-making resembled the dialectical process, where opposing viewpoints are synthesized to arrive at a more comprehensive understanding.</li>
<li>He argues that this process fostered critical thinking, intellectual growth, and a willingness to adapt to changing circumstances.</li>
</ul>
</section>
<section id="local-choice-and-variety" class="level3">
<h3 class="anchored" data-anchor-id="local-choice-and-variety">Local Choice and Variety</h3>
<ul>
<li>Gatto emphasizes the diversity of local cultures that flourished in colonial New England, despite the initial emphasis on religious conformity.</li>
<li>He uses the examples of Dedham and Sudbury, neighboring towns with distinct economic and social structures, to illustrate the flexibility and adaptability of the Congregationalist system.</li>
</ul>
</section>
<section id="the-necessity-of-exclusion" class="level3">
<h3 class="anchored" data-anchor-id="the-necessity-of-exclusion">The Necessity of Exclusion</h3>
<ul>
<li>Gatto acknowledges the controversial practice of exclusion in colonial New England, where towns often restricted membership to those who shared their values and beliefs.</li>
<li>He argues that this exclusion, while problematic, was necessary to maintain a degree of social cohesion and to allow for the effective functioning of the dialectical process.</li>
</ul>
</section>
<section id="the-paradox-of-local-choice" class="level3">
<h3 class="anchored" data-anchor-id="the-paradox-of-local-choice">The Paradox of Local Choice</h3>
<ul>
<li>Gatto explores the paradoxical nature of local choice, highlighting both its positive and negative aspects.</li>
<li>He acknowledges the potential for local tyranny and exclusion, while emphasizing the crucial role of choice in fostering individual development, community spirit, and democratic values.</li>
</ul>
</section>
<section id="local-knowledge-and-love" class="level3">
<h3 class="anchored" data-anchor-id="local-knowledge-and-love">Local Knowledge and Love</h3>
<ul>
<li>Gatto quotes Wendell Berry’s argument in favor of local knowledge and action, emphasizing the importance of understanding and caring for specific places and people.</li>
<li>He contrasts this with the abstract, global thinking that often leads to destructive interventions based on incomplete information and a lack of genuine connection to the places being affected.</li>
</ul>
</section>
<section id="the-negative-side-of-localism" class="level3">
<h3 class="anchored" data-anchor-id="the-negative-side-of-localism">The Negative Side of Localism</h3>
<ul>
<li>Gatto provides examples of the negative consequences of local control in colonial New England, such as the persecution of Quakers and the exclusion of other religious groups.</li>
<li>He acknowledges the potential for intolerance and discrimination when communities have the power to choose their own members.</li>
</ul>
</section>
<section id="the-mystery-of-congregational-reform" class="level3">
<h3 class="anchored" data-anchor-id="the-mystery-of-congregational-reform">The Mystery of Congregational Reform</h3>
<ul>
<li>Gatto marvels at the ability of Congregationalist communities to reform themselves over time, embracing greater tolerance and diversity without external pressure or legal compulsion.</li>
<li>He attributes this self-correction to the inherent dynamics of the Congregationalist system, which allowed for free debate, dissent, and the natural consequences of poor choices.</li>
</ul>
</section>
<section id="unconditional-local-choice-and-self-correction" class="level3">
<h3 class="anchored" data-anchor-id="unconditional-local-choice-and-self-correction">Unconditional Local Choice and Self-Correction</h3>
<ul>
<li>Gatto argues that the absence of a central orthodoxy and the freedom to “vote with their feet” allowed for a marketplace of ideas in colonial New England.</li>
<li>He suggests that this system naturally rewarded good practices and punished bad ones, leading to a gradual improvement in social conditions.</li>
</ul>
</section>
<section id="the-value-of-choice-and-the-danger-of-central-orthodoxy" class="level3">
<h3 class="anchored" data-anchor-id="the-value-of-choice-and-the-danger-of-central-orthodoxy">The Value of Choice and the Danger of Central Orthodoxy</h3>
<ul>
<li>Gatto emphasizes the importance of choice in fostering a democratic society, arguing that ceding power to central authorities in the name of fairness can ultimately undermine individual liberty and lead to tyranny.</li>
<li>He uses the example of a national curriculum to illustrate the dangers of imposing a single, uniform approach to education, stifling innovation and local adaptation.</li>
</ul>
</section>
<section id="the-failures-of-central-planning" class="level3">
<h3 class="anchored" data-anchor-id="the-failures-of-central-planning">The Failures of Central Planning</h3>
<ul>
<li>Gatto points to the failures of centralized planning in the 20th century, arguing that attempts to legislate social change often have unintended consequences and fail to address the root causes of problems.</li>
<li>He uses examples like affirmative action, desegregation, and drug prohibition to illustrate this point, suggesting that these measures may have exacerbated the very issues they sought to address.</li>
</ul>
</section>
<section id="questionable-victories" class="level3">
<h3 class="anchored" data-anchor-id="questionable-victories">Questionable Victories</h3>
<ul>
<li>Gatto questions the effectiveness of social change imposed through legal coercion, arguing that it often creates resentment and undermines genuine progress.</li>
<li>He suggests that true social change must be rooted in a shift in public consensus, rather than forced compliance.</li>
</ul>
</section>
<section id="the-dangers-of-compulsion" class="level3">
<h3 class="anchored" data-anchor-id="the-dangers-of-compulsion">The Dangers of Compulsion</h3>
<ul>
<li>Gatto warns against the dangers of relying on compulsion to achieve social goals, arguing that it often diminishes the quality of human life and creates a culture of resistance and evasion.</li>
<li>He contrasts this with the effectiveness of voluntary cooperation and self-motivation, which foster a sense of ownership and responsibility.</li>
</ul>
</section>
<section id="the-growth-of-the-school-monopoly" class="level3">
<h3 class="anchored" data-anchor-id="the-growth-of-the-school-monopoly">The Growth of the School Monopoly</h3>
<ul>
<li>Gatto criticizes the unchecked growth of the government school monopoly, which has become increasingly powerful despite its consistent failures to deliver on its promises.</li>
<li>He attributes this growth to the influence of special interest groups, such as teacher colleges, textbook publishers, and educational bureaucrats, who benefit from the status quo.</li>
</ul>
</section>
<section id="the-prohibitions-of-compulsory-schooling" class="level3">
<h3 class="anchored" data-anchor-id="the-prohibitions-of-compulsory-schooling">The Prohibitions of Compulsory Schooling</h3>
<ul>
<li>Gatto outlines the numerous prohibitions imposed by compulsory schooling:
<ul>
<li>Limiting educational choices to a narrow range of government-approved options.</li>
<li>Denying parents and communities the freedom to shape their own educational systems.</li>
<li>Stifling innovation and creativity through standardized curricula and testing regimes.</li>
</ul></li>
</ul>
</section>
<section id="the-power-of-the-congregational-principle" class="level3">
<h3 class="anchored" data-anchor-id="the-power-of-the-congregational-principle">The Power of the Congregational Principle</h3>
<ul>
<li>Gatto argues that the Congregationalist principle, even without its religious context, offers a valuable model for a decentralized, community-based approach to education.</li>
<li>He emphasizes the power of small groups working together towards shared goals, fostering individual growth and a sense of belonging.</li>
</ul>
</section>
<section id="learning-from-dedhams-transformation" class="level3">
<h3 class="anchored" data-anchor-id="learning-from-dedhams-transformation">Learning from Dedham’s Transformation</h3>
<ul>
<li>Gatto uses the example of Dedham’s transformation from a religiously intolerant community to a more inclusive one as evidence of the self-correcting nature of the Congregationalist system.</li>
<li>He suggests that allowing for local choice, even with its potential for error, ultimately leads to greater tolerance and understanding.</li>
</ul>
</section>
<section id="the-failure-of-centrally-planned-schools" class="level3">
<h3 class="anchored" data-anchor-id="the-failure-of-centrally-planned-schools">The Failure of Centrally Planned Schools</h3>
<ul>
<li>Gatto reiterates his critique of centrally planned schools, arguing that they cannot adequately address the diverse needs of individuals and communities.</li>
<li>He emphasizes the importance of allowing for local experimentation and adaptation, trusting families and communities to find solutions that work for them.</li>
</ul>
</section>
<section id="two-wrong-ways-to-view-education" class="level3">
<h3 class="anchored" data-anchor-id="two-wrong-ways-to-view-education">Two Wrong Ways to View Education</h3>
<ul>
<li>Gatto identifies two flawed perspectives on education:
<ul>
<li>Viewing it as an engineering problem that can be solved through standardized solutions.</li>
<li>Searching for villains to blame for educational failures, rather than examining the system itself.</li>
</ul></li>
</ul>
</section>
<section id="the-allure-of-quick-fixes" class="level3">
<h3 class="anchored" data-anchor-id="the-allure-of-quick-fixes">The Allure of Quick Fixes</h3>
<ul>
<li>Gatto criticizes the American tendency to seek quick fixes and magical solutions to complex problems, perpetuated by the advertising industry and a culture of instant gratification.</li>
<li>He argues that genuine solutions require a deeper understanding of human nature and a willingness to engage in sustained effort.</li>
</ul>
</section>
<section id="the-mechanical-view-of-human-nature" class="level3">
<h3 class="anchored" data-anchor-id="the-mechanical-view-of-human-nature">The Mechanical View of Human Nature</h3>
<ul>
<li>Gatto challenges the mechanical view of human nature, which reduces individuals to interchangeable parts in a system designed for efficiency and control.</li>
<li>He argues that this perspective ignores the complexity and uniqueness of each human being, ultimately leading to dehumanization and alienation.</li>
</ul>
</section>
<section id="schools-teaching-people-as-machines" class="level3">
<h3 class="anchored" data-anchor-id="schools-teaching-people-as-machines">Schools Teaching People as Machines</h3>
<ul>
<li>Gatto describes how the structure and methodology of modern schooling reinforce the mechanical view of human nature:
<ul>
<li>Bells and schedules dictate the rhythm of the day, treating students like programmable machines.</li>
<li>Grades and rankings reduce complex qualities to numerical scores, devaluing individual expression.</li>
<li>Standardized curricula and testing regimes stifle creativity and independent thinking.</li>
</ul></li>
</ul>
</section>
<section id="the-consequences-of-the-machine-model" class="level3">
<h3 class="anchored" data-anchor-id="the-consequences-of-the-machine-model">The Consequences of the Machine Model</h3>
<ul>
<li>Gatto quotes Octavio Paz’s criticism of the American educational system, which he describes as a “conspiracy” that prevents individuals from fully developing their potential.</li>
<li>He argues that this system creates a culture of dependency and immaturity, leaving people ill-equipped to navigate the complexities of life.</li>
</ul>
</section>
<section id="the-uniform-failure-of-government-schools" class="level3">
<h3 class="anchored" data-anchor-id="the-uniform-failure-of-government-schools">The Uniform Failure of Government Schools</h3>
<ul>
<li>Gatto highlights the consistent failure of government schools to achieve their stated goals, despite decades of reform efforts and vast expenditures.</li>
<li>He argues that this failure is systemic, stemming from the flawed assumptions underlying the model itself.</li>
</ul>
</section>
<section id="looking-to-the-past-for-solutions" class="level3">
<h3 class="anchored" data-anchor-id="looking-to-the-past-for-solutions">Looking to the Past for Solutions</h3>
<ul>
<li>Gatto proposes looking back to the Congregationalist model of colonial New England for inspiration, urging a return to decentralized, community-based approaches to education.</li>
<li>He encourages experimentation and local innovation, trusting families and communities to find solutions that best meet their unique needs.</li>
</ul>
</section>
<section id="embracing-the-congregational-principle" class="level3">
<h3 class="anchored" data-anchor-id="embracing-the-congregational-principle">Embracing the Congregational Principle</h3>
<ul>
<li>Gatto encourages a rediscovery of the Congregationalist principle, adapting its core values to the modern context:
<ul>
<li>Empowering individuals to take charge of their own learning.</li>
<li>Fostering a sense of community and belonging through shared responsibility for education.</li>
<li>Embracing diversity and respecting individual differences.</li>
</ul></li>
</ul>
</section>
<section id="decertifying-learning-and-embracing-competition" class="level3">
<h3 class="anchored" data-anchor-id="decertifying-learning-and-embracing-competition">Decertifying Learning and Embracing Competition</h3>
<ul>
<li>Gatto calls for the decertification of teaching, breaking the monopoly of certified experts and allowing anyone with a passion for education to compete in a free market.</li>
<li>He suggests that this would lead to greater diversity, innovation, and responsiveness to the needs of individual learners.</li>
</ul>
</section>
</section>
<section id="actionable-recommendations" class="level2">
<h2 class="anchored" data-anchor-id="actionable-recommendations">Actionable Recommendations</h2>
<ul>
<li><strong>Decentralize education:</strong> Support initiatives that promote local control, such as charter schools, homeschooling, and community-based learning centers.</li>
<li><strong>Decertify teaching:</strong> Advocate for the removal of mandatory teacher certification, allowing anyone with a passion for education to teach.</li>
<li><strong>Privatize education:</strong> Promote policies that empower families to choose their own educational paths, such as vouchers and tax credits for educational expenses.</li>
<li><strong>Reduce the scope of schooling:</strong> Advocate for shorter school days, shorter school years, and a reduced emphasis on standardized testing, allowing children more time for self-directed learning and family involvement.</li>
<li><strong>Encourage community involvement:</strong> Support programs that integrate children into the life of their communities through apprenticeships, internships, and community service opportunities.</li>
<li><strong>Promote self-knowledge and personal values:</strong> Encourage children to explore their own interests, to develop their own sense of purpose, and to cultivate a personal code of ethics.</li>
<li><strong>Support alternative learning models:</strong> Explore and promote innovative approaches to education, such as Montessori, Waldorf, and unschooling.</li>
<li><strong>Become a saboteur:</strong> Find ways to subvert the oppressive mechanisms of the school system from within, empowering students to think critically and to challenge the status quo.</li>
<li><strong>Join the conversation:</strong> Engage in discussions about education reform with family, friends, community members, and policymakers.</li>
<li><strong>Share Gatto’s work:</strong> Spread awareness of Gatto’s ideas and his critique of forced schooling, encouraging others to question the dominant educational paradigm.</li>
</ul>
</section>
<section id="glossary" class="level2">
<h2 class="anchored" data-anchor-id="glossary">Glossary</h2>
<ul>
<li><strong>Congregational principle:</strong> A system of local self-governance, where communities determine their own affairs without external interference.</li>
<li><strong>Dialectical process:</strong> A method of reasoning that involves synthesizing opposing viewpoints to arrive at a more comprehensive understanding.</li>
<li><strong>Homeschooling:</strong> Educating children at home, typically by parents or guardians, rather than in a formal school setting.</li>
<li><strong>Institutional schooling:</strong> The dominant model of education in modern societies, characterized by centralized control, standardized curricula, and compulsory attendance.</li>
<li><strong>Network:</strong> A system of interconnected individuals or groups, often focused on a specific purpose or interest. Networks tend to be more superficial and transient than communities, with weaker bonds and a narrower range of interaction.</li>
<li><strong>Provisional self-esteem:</strong> A sense of self-worth that is contingent upon external evaluations and the approval of authority figures.</li>
<li><strong>Pseudo-community:</strong> A simulated gathering or association that lacks the genuine connections, shared values, and enduring bonds of a true community.</li>
<li><strong>Social engineering:</strong> The attempt to control and manipulate human behavior through social policies and institutions.</li>
<li><strong>The Seven-Lesson Schoolteacher:</strong> The title of John Taylor Gatto’s essay, in which he outlines seven harmful lessons instilled by the compulsory schooling system: confusion, class position, indifference, emotional dependency, intellectual dependency, provisional self-esteem, and constant surveillance.</li>
<li><strong>The Psychopathic School:</strong> The title of another John Taylor Gatto essay which describes the school system as lacking conscience and serving the interests of a centralized, industrial economy at the expense of individual growth and well-being.</li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>education</category>
  <category>history</category>
  <guid>https://christianjmills.com/posts/dumbing-us-down-book-notes/</guid>
  <pubDate>Sat, 03 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 14: Explaining the Basics of Retrieval Augmented Generation</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-014/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Summary</li>
<li>Demystifying RAG</li>
<li>The Compact MVP: A Simple RAG Implementation</li>
<li>Understanding Bi-Encoders in Vector Search</li>
<li>Improving Retrieval with Re-ranking</li>
<li>Keyword Search</li>
<li>Leveraging Metadata for Targeted Retrieval</li>
<li>Putting it All Together: The Complete MVP++ Pipeline</li>
<li>Beyond the Basics: Future Exploration and Resources</li>
<li>Q&amp;A Session</li>
</ul>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p><a href="https://ben.clavie.eu/">Ben Clavié</a> deconstructs the concept of Retrieval-Augmented Generation (RAG) and guides the audience through building a robust, basic RAG pipeline. He emphasizes that RAG is not a standalone technology, but a pipeline combining retrieval and generation, and each component needs individual attention for optimization. Ben advocates for a “MVP++” approach, incorporating essential elements like bi-encoders, re-ranking, keyword search (TF-IDF/BM25), and metadata filtering for a well-rounded system.</p>
</section>
<section id="demystifying-rag" class="level2">
<h2 class="anchored" data-anchor-id="demystifying-rag">Demystifying RAG</h2>
<ul>
<li><strong>RAG: Overused and Misunderstood</strong>
<ul>
<li>The term “RAG” is often used incorrectly to represent an end-to-end system, creating confusion.</li>
</ul></li>
<li><strong>RAG as a Pipeline: Retrieval + Generation</strong>
<ul>
<li>RAG simply combines retrieval (finding relevant information) and generation (creating text) using Large Language Models (LLMs).</li>
<li>It’s not a single technology, but a pipeline requiring optimization at each stage: retrieval, generation, and their connection.</li>
</ul></li>
<li><strong>Importance of Identifying Specific RAG Issues</strong>
<ul>
<li>“My RAG doesn’t work” is too broad. Pinpointing the failing component (retrieval, LLM utilization) is crucial for debugging.</li>
</ul></li>
</ul>
</section>
<section id="the-compact-mvp-a-simple-rag-implementation" class="level2">
<h2 class="anchored" data-anchor-id="the-compact-mvp-a-simple-rag-implementation">The Compact MVP: A Simple RAG Implementation</h2>
<ul>
<li><strong>Basic Pipeline Components and Flow</strong>
<ul>
<li>Query embedding</li>
<li>Document embedding</li>
<li>Cosine similarity search for relevant documents</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 478.00 336.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 332.8)">
<title>bencoder_approach</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-332.8 474,-332.8 474,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-136C20,-136 450,-136 450,-136 456,-136 462,-142 462,-148 462,-148 462,-272.8 462,-272.8 462,-278.8 456,-284.8 450,-284.8 450,-284.8 20,-284.8 20,-284.8 14,-284.8 8,-278.8 8,-272.8 8,-272.8 8,-148 8,-148 8,-142 14,-136 20,-136"></path>
<text text-anchor="middle" x="235" y="-268.2" font-family="Times,serif" font-size="14.00" fill="red">This is called a 'bi-encoder' approach</text>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M136,-328.8C136,-328.8 106,-328.8 106,-328.8 100,-328.8 94,-322.8 94,-316.8 94,-316.8 94,-304.8 94,-304.8 94,-298.8 100,-292.8 106,-292.8 106,-292.8 136,-292.8 136,-292.8 142,-292.8 148,-298.8 148,-304.8 148,-304.8 148,-316.8 148,-316.8 148,-322.8 142,-328.8 136,-328.8"></path>
<text text-anchor="middle" x="121" y="-306.6" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Embedding_Model -->
<g id="node3" class="node">
<title>Query_Embedding_Model</title>
<path fill="#ffc9c9" stroke="black" d="M169.1,-252C169.1,-252 72.9,-252 72.9,-252 66.9,-252 60.9,-246 60.9,-240 60.9,-240 60.9,-228 60.9,-228 60.9,-222 66.9,-216 72.9,-216 72.9,-216 169.1,-216 169.1,-216 175.1,-216 181.1,-222 181.1,-228 181.1,-228 181.1,-240 181.1,-240 181.1,-246 175.1,-252 169.1,-252"></path>
<text text-anchor="middle" x="121" y="-229.8" font-family="Times,serif" font-size="14.00">Embedding Model</text>
</g>
<!-- Query&#45;&gt;Query_Embedding_Model -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Embedding_Model</title>
<path fill="none" stroke="black" d="M121,-292.45C121,-283.58 121,-272.56 121,-262.56"></path>
<polygon fill="black" stroke="black" points="124.5,-262.25 121,-252.25 117.5,-262.25 124.5,-262.25"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M376.77,-328.8C376.77,-328.8 321.23,-328.8 321.23,-328.8 315.23,-328.8 309.23,-322.8 309.23,-316.8 309.23,-316.8 309.23,-304.8 309.23,-304.8 309.23,-298.8 315.23,-292.8 321.23,-292.8 321.23,-292.8 376.77,-292.8 376.77,-292.8 382.77,-292.8 388.77,-298.8 388.77,-304.8 388.77,-304.8 388.77,-316.8 388.77,-316.8 388.77,-322.8 382.77,-328.8 376.77,-328.8"></path>
<text text-anchor="middle" x="349" y="-306.6" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Embedding_Model -->
<g id="node5" class="node">
<title>Document_Embedding_Model</title>
<path fill="#ffc9c9" stroke="black" d="M397.1,-252C397.1,-252 300.9,-252 300.9,-252 294.9,-252 288.9,-246 288.9,-240 288.9,-240 288.9,-228 288.9,-228 288.9,-222 294.9,-216 300.9,-216 300.9,-216 397.1,-216 397.1,-216 403.1,-216 409.1,-222 409.1,-228 409.1,-228 409.1,-240 409.1,-240 409.1,-246 403.1,-252 397.1,-252"></path>
<text text-anchor="middle" x="349" y="-229.8" font-family="Times,serif" font-size="14.00">Embedding Model</text>
</g>
<!-- Documents&#45;&gt;Document_Embedding_Model -->
<g id="edge3" class="edge">
<title>Documents-&gt;Document_Embedding_Model</title>
<path fill="none" stroke="black" d="M349,-292.45C349,-283.58 349,-272.56 349,-262.56"></path>
<polygon fill="black" stroke="black" points="352.5,-262.25 349,-252.25 345.5,-262.25 352.5,-262.25"></polygon>
</g>
<!-- Query_Embedding_Pooling -->
<g id="node4" class="node">
<title>Query_Embedding_Pooling</title>
<path fill="#ffc9c9" stroke="black" d="M214.41,-180C214.41,-180 27.59,-180 27.59,-180 21.59,-180 15.59,-174 15.59,-168 15.59,-168 15.59,-156 15.59,-156 15.59,-150 21.59,-144 27.59,-144 27.59,-144 214.41,-144 214.41,-144 220.41,-144 226.41,-150 226.41,-156 226.41,-156 226.41,-168 226.41,-168 226.41,-174 220.41,-180 214.41,-180"></path>
<text text-anchor="middle" x="121" y="-157.8" font-family="Times,serif" font-size="14.00">Embedding pooling (into 1 vector)</text>
</g>
<!-- Query_Embedding_Model&#45;&gt;Query_Embedding_Pooling -->
<g id="edge2" class="edge">
<title>Query_Embedding_Model-&gt;Query_Embedding_Pooling</title>
<path fill="none" stroke="black" d="M121,-215.7C121,-207.98 121,-198.71 121,-190.11"></path>
<polygon fill="black" stroke="black" points="124.5,-190.1 121,-180.1 117.5,-190.1 124.5,-190.1"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node7" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M298.8,-108C298.8,-108 171.2,-108 171.2,-108 165.2,-108 159.2,-102 159.2,-96 159.2,-96 159.2,-84 159.2,-84 159.2,-78 165.2,-72 171.2,-72 171.2,-72 298.8,-72 298.8,-72 304.8,-72 310.8,-78 310.8,-84 310.8,-84 310.8,-96 310.8,-96 310.8,-102 304.8,-108 298.8,-108"></path>
<text text-anchor="middle" x="235" y="-85.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Embedding_Pooling&#45;&gt;Cosine_Similarity_Search -->
<g id="edge5" class="edge">
<title>Query_Embedding_Pooling-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M148.89,-143.88C163.79,-134.72 182.33,-123.34 198.38,-113.48"></path>
<polygon fill="black" stroke="black" points="200.31,-116.41 207.01,-108.19 196.65,-110.44 200.31,-116.41"></polygon>
</g>
<!-- Document_Embedding_Pooling -->
<g id="node6" class="node">
<title>Document_Embedding_Pooling</title>
<path fill="#ffc9c9" stroke="black" d="M442.41,-180C442.41,-180 255.59,-180 255.59,-180 249.59,-180 243.59,-174 243.59,-168 243.59,-168 243.59,-156 243.59,-156 243.59,-150 249.59,-144 255.59,-144 255.59,-144 442.41,-144 442.41,-144 448.41,-144 454.41,-150 454.41,-156 454.41,-156 454.41,-168 454.41,-168 454.41,-174 448.41,-180 442.41,-180"></path>
<text text-anchor="middle" x="349" y="-157.8" font-family="Times,serif" font-size="14.00">Embedding pooling (into 1 vector)</text>
</g>
<!-- Document_Embedding_Model&#45;&gt;Document_Embedding_Pooling -->
<g id="edge4" class="edge">
<title>Document_Embedding_Model-&gt;Document_Embedding_Pooling</title>
<path fill="none" stroke="black" d="M349,-215.7C349,-207.98 349,-198.71 349,-190.11"></path>
<polygon fill="black" stroke="black" points="352.5,-190.1 349,-180.1 345.5,-190.1 352.5,-190.1"></polygon>
</g>
<!-- Document_Embedding_Pooling&#45;&gt;Cosine_Similarity_Search -->
<g id="edge6" class="edge">
<title>Document_Embedding_Pooling-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M321.11,-143.88C306.21,-134.72 287.67,-123.34 271.62,-113.48"></path>
<polygon fill="black" stroke="black" points="273.35,-110.44 262.99,-108.19 269.69,-116.41 273.35,-110.44"></polygon>
</g>
<!-- Results -->
<g id="node8" class="node">
<title>Results</title>
<path fill="#b2f3bb" stroke="black" d="M251.73,-36C251.73,-36 218.27,-36 218.27,-36 212.27,-36 206.27,-30 206.27,-24 206.27,-24 206.27,-12 206.27,-12 206.27,-6 212.27,0 218.27,0 218.27,0 251.73,0 251.73,0 257.73,0 263.73,-6 263.73,-12 263.73,-12 263.73,-24 263.73,-24 263.73,-30 257.73,-36 251.73,-36"></path>
<text text-anchor="middle" x="235" y="-13.8" font-family="Times,serif" font-size="14.00">Results</text>
</g>
<!-- Cosine_Similarity_Search&#45;&gt;Results -->
<g id="edge7" class="edge">
<title>Cosine_Similarity_Search-&gt;Results</title>
<path fill="none" stroke="black" d="M235,-71.7C235,-63.98 235,-54.71 235,-46.11"></path>
<polygon fill="black" stroke="black" points="238.5,-46.1 235,-36.1 231.5,-46.1 238.5,-46.1"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<ul>
<li><div class="callout callout-style-default callout-note callout-titled" title="Code Example: Vector Search with NumPy">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Code Example: Vector Search with NumPy
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Demonstrates a basic RAG pipeline without a vector database, emphasizing simplicity.</li>
<li>Uses NumPy for cosine similarity search for demonstration purposes.</li>
</ul>
<div class="sourceCode" id="annotated-cell-2" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the embedding model</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-2-2" class="code-annotation-target"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sentence_transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SentenceTransformer</span>
<span id="annotated-cell-2-3">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SentenceTransformer(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Alibaba-NLP/gte-base-en-v1.5"</span>)</span>
<span id="annotated-cell-2-4"></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-2-5" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fetch some text content...</span></span>
<span id="annotated-cell-2-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> wikipediaapi <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Wikipedia</span>
<span id="annotated-cell-2-7">wiki <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Wikipedia(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RAGBot/0.0'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en'</span>)</span>
<span id="annotated-cell-2-8">doc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wiki.page(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hayao_Miyazaki'</span>).text</span>
<span id="annotated-cell-2-9">paragraphs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> doc.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="annotated-cell-2-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ...And embed it.</span></span>
<span id="annotated-cell-2-11">docs_embed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.encode(paragraphs, normalize_embeddings<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="annotated-cell-2-12"></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-2-13" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Embed the query</span></span>
<span id="annotated-cell-2-14">query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What was Studio Ghibli's first film?"</span></span>
<span id="annotated-cell-2-15">query_embed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.encode(query, normalize_embeddings<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="annotated-cell-2-16"></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-2-17" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Find the 3 closest paragraphs to the query</span></span>
<span id="annotated-cell-2-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="annotated-cell-2-19">similarities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(docs_embed, query_embed.T)</span>
<span id="annotated-cell-2-20">top_3_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> similarities.topk(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>).indices.tolist()</span>
<span id="annotated-cell-2-21">most_similar_documents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [paragraphs[idx] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> idx <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> top_3_idx]</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-2" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="2,3" data-code-annotation="1">Load Bi-Encoder</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="5,6,7,8,9,10,11" data-code-annotation="2">Embed Documents</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="13,14,15" data-code-annotation="3">Embed Query</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="17,18,19,20,21" data-code-annotation="4">Cosine Similarity Search</span>
</dd>
</dl>
</div>
</div></li>
</ul>
</section>
<section id="understanding-bi-encoders-in-vector-search" class="level2">
<h2 class="anchored" data-anchor-id="understanding-bi-encoders-in-vector-search">Understanding Bi-Encoders in Vector Search</h2>
<ul>
<li><p><strong>Vector Databases: When and Why?</strong></p>
<ul>
<li>Useful for efficiently searching large document sets using Approximate Search techniques
<ul>
<li><strong>HNSW</strong>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/1603.09320">Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs</a></li>
<li><strong>Article:</strong> <a href="https://www.pinecone.io/learn/series/faiss/hnsw/">Hierarchical Navigable Small Worlds (HNSW)</a></li>
</ul></li>
<li><strong>IVFPQ</strong>
<ul>
<li><strong>Article:</strong> <a href="https://www.pinecone.io/learn/series/faiss/product-quantization/">Product Quantization: Compressing high-dimensional vectors by 97%</a></li>
</ul></li>
</ul></li>
<li>Not necessary for small datasets (e.g., 500 documents)
<ul>
<li>Modern CPU can search through hundreds of vectors in milliseconds</li>
</ul></li>
</ul></li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 478.00 351.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 347.8)">
<title>bencoder_approach</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-347.8 474,-347.8 474,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-153.8C20,-153.8 450,-153.8 450,-153.8 456,-153.8 462,-159.8 462,-165.8 462,-165.8 462,-266.8 462,-266.8 462,-272.8 456,-278.8 450,-278.8 450,-278.8 20,-278.8 20,-278.8 14,-278.8 8,-272.8 8,-266.8 8,-266.8 8,-165.8 8,-165.8 8,-159.8 14,-153.8 20,-153.8"></path>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M136,-343.8C136,-343.8 106,-343.8 106,-343.8 100,-343.8 94,-337.8 94,-331.8 94,-331.8 94,-319.8 94,-319.8 94,-313.8 100,-307.8 106,-307.8 106,-307.8 136,-307.8 136,-307.8 142,-307.8 148,-313.8 148,-319.8 148,-319.8 148,-331.8 148,-331.8 148,-337.8 142,-343.8 136,-343.8"></path>
<text text-anchor="middle" x="121" y="-321.6" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Embedding_Model -->
<g id="node3" class="node">
<title>Query_Embedding_Model</title>
<path fill="#fddde6" stroke="black" d="M169.1,-270.8C169.1,-270.8 72.9,-270.8 72.9,-270.8 66.9,-270.8 60.9,-264.8 60.9,-258.8 60.9,-258.8 60.9,-246.8 60.9,-246.8 60.9,-240.8 66.9,-234.8 72.9,-234.8 72.9,-234.8 169.1,-234.8 169.1,-234.8 175.1,-234.8 181.1,-240.8 181.1,-246.8 181.1,-246.8 181.1,-258.8 181.1,-258.8 181.1,-264.8 175.1,-270.8 169.1,-270.8"></path>
<text text-anchor="middle" x="121" y="-248.6" font-family="Times,serif" font-size="14.00">Embedding Model</text>
</g>
<!-- Query&#45;&gt;Query_Embedding_Model -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Embedding_Model</title>
<path fill="none" stroke="black" d="M121,-307.61C121,-299.59 121,-289.85 121,-280.87"></path>
<polygon fill="black" stroke="black" points="124.5,-280.83 121,-270.83 117.5,-280.83 124.5,-280.83"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M376.77,-343.8C376.77,-343.8 321.23,-343.8 321.23,-343.8 315.23,-343.8 309.23,-337.8 309.23,-331.8 309.23,-331.8 309.23,-319.8 309.23,-319.8 309.23,-313.8 315.23,-307.8 321.23,-307.8 321.23,-307.8 376.77,-307.8 376.77,-307.8 382.77,-307.8 388.77,-313.8 388.77,-319.8 388.77,-319.8 388.77,-331.8 388.77,-331.8 388.77,-337.8 382.77,-343.8 376.77,-343.8"></path>
<text text-anchor="middle" x="349" y="-321.6" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Embedding_Model -->
<g id="node5" class="node">
<title>Document_Embedding_Model</title>
<path fill="#fddde6" stroke="black" d="M397.1,-270.8C397.1,-270.8 300.9,-270.8 300.9,-270.8 294.9,-270.8 288.9,-264.8 288.9,-258.8 288.9,-258.8 288.9,-246.8 288.9,-246.8 288.9,-240.8 294.9,-234.8 300.9,-234.8 300.9,-234.8 397.1,-234.8 397.1,-234.8 403.1,-234.8 409.1,-240.8 409.1,-246.8 409.1,-246.8 409.1,-258.8 409.1,-258.8 409.1,-264.8 403.1,-270.8 397.1,-270.8"></path>
<text text-anchor="middle" x="349" y="-248.6" font-family="Times,serif" font-size="14.00">Embedding Model</text>
</g>
<!-- Documents&#45;&gt;Document_Embedding_Model -->
<g id="edge3" class="edge">
<title>Documents-&gt;Document_Embedding_Model</title>
<path fill="none" stroke="black" d="M349,-307.61C349,-299.59 349,-289.85 349,-280.87"></path>
<polygon fill="black" stroke="black" points="352.5,-280.83 349,-270.83 345.5,-280.83 352.5,-280.83"></polygon>
</g>
<!-- Query_Embedding_Pooling -->
<g id="node4" class="node">
<title>Query_Embedding_Pooling</title>
<path fill="#fddde6" stroke="black" d="M214.41,-197.8C214.41,-197.8 27.59,-197.8 27.59,-197.8 21.59,-197.8 15.59,-191.8 15.59,-185.8 15.59,-185.8 15.59,-173.8 15.59,-173.8 15.59,-167.8 21.59,-161.8 27.59,-161.8 27.59,-161.8 214.41,-161.8 214.41,-161.8 220.41,-161.8 226.41,-167.8 226.41,-173.8 226.41,-173.8 226.41,-185.8 226.41,-185.8 226.41,-191.8 220.41,-197.8 214.41,-197.8"></path>
<text text-anchor="middle" x="121" y="-175.6" font-family="Times,serif" font-size="14.00">Embedding pooling (into 1 vector)</text>
</g>
<!-- Query_Embedding_Model&#45;&gt;Query_Embedding_Pooling -->
<g id="edge2" class="edge">
<title>Query_Embedding_Model-&gt;Query_Embedding_Pooling</title>
<path fill="none" stroke="black" d="M121,-234.61C121,-226.59 121,-216.85 121,-207.87"></path>
<polygon fill="black" stroke="black" points="124.5,-207.83 121,-197.83 117.5,-207.83 124.5,-207.83"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node7" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M297.8,-109C297.8,-109 170.2,-109 170.2,-109 164.2,-109 158.2,-103 158.2,-97 158.2,-97 158.2,-85 158.2,-85 158.2,-79 164.2,-73 170.2,-73 170.2,-73 297.8,-73 297.8,-73 303.8,-73 309.8,-79 309.8,-85 309.8,-85 309.8,-97 309.8,-97 309.8,-103 303.8,-109 297.8,-109"></path>
<text text-anchor="middle" x="234" y="-86.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Embedding_Pooling&#45;&gt;Cosine_Similarity_Search -->
<g id="edge5" class="edge">
<title>Query_Embedding_Pooling-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M143.33,-161.65C160.58,-148.4 184.65,-129.91 203.66,-115.31"></path>
<polygon fill="black" stroke="black" points="205.92,-117.98 211.72,-109.11 201.66,-112.43 205.92,-117.98"></polygon>
</g>
<!-- Document_Embedding_Pooling -->
<g id="node6" class="node">
<title>Document_Embedding_Pooling</title>
<path fill="#fddde6" stroke="black" d="M442.41,-197.8C442.41,-197.8 255.59,-197.8 255.59,-197.8 249.59,-197.8 243.59,-191.8 243.59,-185.8 243.59,-185.8 243.59,-173.8 243.59,-173.8 243.59,-167.8 249.59,-161.8 255.59,-161.8 255.59,-161.8 442.41,-161.8 442.41,-161.8 448.41,-161.8 454.41,-167.8 454.41,-173.8 454.41,-173.8 454.41,-185.8 454.41,-185.8 454.41,-191.8 448.41,-197.8 442.41,-197.8"></path>
<text text-anchor="middle" x="349" y="-175.6" font-family="Times,serif" font-size="14.00">Embedding pooling (into 1 vector)</text>
</g>
<!-- Document_Embedding_Model&#45;&gt;Document_Embedding_Pooling -->
<g id="edge4" class="edge">
<title>Document_Embedding_Model-&gt;Document_Embedding_Pooling</title>
<path fill="none" stroke="black" d="M349,-234.61C349,-226.59 349,-216.85 349,-207.87"></path>
<polygon fill="black" stroke="black" points="352.5,-207.83 349,-197.83 345.5,-207.83 352.5,-207.83"></polygon>
</g>
<!-- Document_Embedding_Pooling&#45;&gt;Cosine_Similarity_Search -->
<g id="edge6" class="edge">
<title>Document_Embedding_Pooling-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M326.28,-161.65C308.72,-148.4 284.22,-129.91 264.88,-115.31"></path>
<polygon fill="black" stroke="black" points="266.76,-112.34 256.67,-109.11 262.55,-117.93 266.76,-112.34"></polygon>
<text text-anchor="middle" x="359.9" y="-131.2" font-family="Times,serif" font-size="14.00">Vector DB goes here</text>
</g>
<!-- Results -->
<g id="node8" class="node">
<title>Results</title>
<path fill="#b2f3bb" stroke="black" d="M250.73,-36C250.73,-36 217.27,-36 217.27,-36 211.27,-36 205.27,-30 205.27,-24 205.27,-24 205.27,-12 205.27,-12 205.27,-6 211.27,0 217.27,0 217.27,0 250.73,0 250.73,0 256.73,0 262.73,-6 262.73,-12 262.73,-12 262.73,-24 262.73,-24 262.73,-30 256.73,-36 250.73,-36"></path>
<text text-anchor="middle" x="234" y="-13.8" font-family="Times,serif" font-size="14.00">Results</text>
</g>
<!-- Cosine_Similarity_Search&#45;&gt;Results -->
<g id="edge7" class="edge">
<title>Cosine_Similarity_Search-&gt;Results</title>
<path fill="none" stroke="black" d="M234,-72.81C234,-64.79 234,-55.05 234,-46.07"></path>
<polygon fill="black" stroke="black" points="237.5,-46.03 234,-36.03 230.5,-46.03 237.5,-46.03"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<ul>
<li><p><strong>Bi-Encoders: Separate Encoding for Queries and Documents</strong></p>
<ul>
<li>Encode documents and queries independently.</li>
<li>Pre-computed document representations allow for efficient inference, as only the query needs encoding at runtime.</li>
<li>Comes with retrieval performance tradeoffs</li>
</ul></li>
</ul>
</section>
<section id="improving-retrieval-with-re-ranking" class="level2">
<h2 class="anchored" data-anchor-id="improving-retrieval-with-re-ranking">Improving Retrieval with Re-ranking</h2>
<ul>
<li><strong>Bi-Encoder Limitations: Context Unawareness</strong>
<ul>
<li>Bi-encoders encode documents and queries separately, potentially missing nuanced relationships between them.</li>
</ul></li>
<li><strong>Cross-Encoders: Joint Encoding for Better Relevance Scoring</strong>
<ul>
<li>Encode query-document pairs together, allowing for a more context-aware relevance score.</li>
<li>Effectively a binary classifier
<ul>
<li>Uses the probability of being the positive class as the similarity score.</li>
</ul></li>
<li>Computationally expensive for large datasets.</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 406.00 244.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 240.8)">
<title>bi_encoder</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-240.8 402,-240.8 402,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-8C20,-8 378,-8 378,-8 384,-8 390,-14 390,-20 390,-20 390,-216.8 390,-216.8 390,-222.8 384,-228.8 378,-228.8 378,-228.8 20,-228.8 20,-228.8 14,-228.8 8,-222.8 8,-216.8 8,-216.8 8,-20 8,-20 8,-14 14,-8 20,-8"></path>
<text text-anchor="middle" x="199" y="-212.2" font-family="Times,serif" font-size="14.00">Bi-Encoder</text>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M310,-196C310,-196 280,-196 280,-196 274,-196 268,-190 268,-184 268,-184 268,-172 268,-172 268,-166 274,-160 280,-160 280,-160 310,-160 310,-160 316,-160 322,-166 322,-172 322,-172 322,-184 322,-184 322,-190 316,-196 310,-196"></path>
<text text-anchor="middle" x="295" y="-173.8" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Bi_Encoder -->
<g id="node3" class="node">
<title>Query_Bi_Encoder</title>
<path fill="#fddde6" stroke="black" d="M369.58,-124C369.58,-124 220.42,-124 220.42,-124 214.42,-124 208.42,-118 208.42,-112 208.42,-112 208.42,-100 208.42,-100 208.42,-94 214.42,-88 220.42,-88 220.42,-88 369.58,-88 369.58,-88 375.58,-88 381.58,-94 381.58,-100 381.58,-100 381.58,-112 381.58,-112 381.58,-118 375.58,-124 369.58,-124"></path>
<text text-anchor="middle" x="295" y="-101.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Query&#45;&gt;Query_Bi_Encoder -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Bi_Encoder</title>
<path fill="none" stroke="black" d="M295,-159.7C295,-151.98 295,-142.71 295,-134.11"></path>
<polygon fill="black" stroke="black" points="298.5,-134.1 295,-124.1 291.5,-134.1 298.5,-134.1"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M130.77,-196C130.77,-196 75.23,-196 75.23,-196 69.23,-196 63.23,-190 63.23,-184 63.23,-184 63.23,-172 63.23,-172 63.23,-166 69.23,-160 75.23,-160 75.23,-160 130.77,-160 130.77,-160 136.77,-160 142.77,-166 142.77,-172 142.77,-172 142.77,-184 142.77,-184 142.77,-190 136.77,-196 130.77,-196"></path>
<text text-anchor="middle" x="103" y="-173.8" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Bi_Encoder -->
<g id="node4" class="node">
<title>Document_Bi_Encoder</title>
<path fill="#fddde6" stroke="black" d="M177.58,-124C177.58,-124 28.42,-124 28.42,-124 22.42,-124 16.42,-118 16.42,-112 16.42,-112 16.42,-100 16.42,-100 16.42,-94 22.42,-88 28.42,-88 28.42,-88 177.58,-88 177.58,-88 183.58,-88 189.58,-94 189.58,-100 189.58,-100 189.58,-112 189.58,-112 189.58,-118 183.58,-124 177.58,-124"></path>
<text text-anchor="middle" x="103" y="-101.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Documents&#45;&gt;Document_Bi_Encoder -->
<g id="edge2" class="edge">
<title>Documents-&gt;Document_Bi_Encoder</title>
<path fill="none" stroke="black" d="M103,-159.7C103,-151.98 103,-142.71 103,-134.11"></path>
<polygon fill="black" stroke="black" points="106.5,-134.1 103,-124.1 99.5,-134.1 106.5,-134.1"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node5" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M262.8,-52C262.8,-52 135.2,-52 135.2,-52 129.2,-52 123.2,-46 123.2,-40 123.2,-40 123.2,-28 123.2,-28 123.2,-22 129.2,-16 135.2,-16 135.2,-16 262.8,-16 262.8,-16 268.8,-16 274.8,-22 274.8,-28 274.8,-28 274.8,-40 274.8,-40 274.8,-46 268.8,-52 262.8,-52"></path>
<text text-anchor="middle" x="199" y="-29.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge3" class="edge">
<title>Query_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M271.27,-87.7C259.06,-78.8 244.01,-67.82 230.82,-58.2"></path>
<polygon fill="black" stroke="black" points="232.6,-55.17 222.46,-52.1 228.48,-60.82 232.6,-55.17"></polygon>
</g>
<!-- Document_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge4" class="edge">
<title>Document_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M126.73,-87.7C138.94,-78.8 153.99,-67.82 167.18,-58.2"></path>
<polygon fill="black" stroke="black" points="169.52,-60.82 175.54,-52.1 165.4,-55.17 169.52,-60.82"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 192.00 244.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 240.8)">
<title>cross_encoder</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-240.8 188,-240.8 188,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_1</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-8C20,-8 164,-8 164,-8 170,-8 176,-14 176,-20 176,-20 176,-216.8 176,-216.8 176,-222.8 170,-228.8 164,-228.8 164,-228.8 20,-228.8 20,-228.8 14,-228.8 8,-222.8 8,-216.8 8,-216.8 8,-20 8,-20 8,-14 14,-8 20,-8"></path>
<text text-anchor="middle" x="92" y="-212.2" font-family="Times,serif" font-size="14.00">Cross-Encoder</text>
</g>
<!-- Query_2 -->
<g id="node1" class="node">
<title>Query_2</title>
<path fill="#a4d8ff" stroke="black" d="M156,-196C156,-196 126,-196 126,-196 120,-196 114,-190 114,-184 114,-184 114,-172 114,-172 114,-166 120,-160 126,-160 126,-160 156,-160 156,-160 162,-160 168,-166 168,-172 168,-172 168,-184 168,-184 168,-190 162,-196 156,-196"></path>
<text text-anchor="middle" x="141" y="-173.8" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Cross_Encoder -->
<g id="node3" class="node">
<title>Cross_Encoder</title>
<path fill="#fed8a7" stroke="black" d="M129.7,-124C129.7,-124 54.3,-124 54.3,-124 48.3,-124 42.3,-118 42.3,-112 42.3,-112 42.3,-100 42.3,-100 42.3,-94 48.3,-88 54.3,-88 54.3,-88 129.7,-88 129.7,-88 135.7,-88 141.7,-94 141.7,-100 141.7,-100 141.7,-112 141.7,-112 141.7,-118 135.7,-124 129.7,-124"></path>
<text text-anchor="middle" x="92" y="-101.8" font-family="Times,serif" font-size="14.00">Cross-Encoder</text>
</g>
<!-- Query_2&#45;&gt;Cross_Encoder -->
<g id="edge1" class="edge">
<title>Query_2-&gt;Cross_Encoder</title>
<path fill="none" stroke="black" d="M128.89,-159.7C123.13,-151.47 116.14,-141.48 109.79,-132.42"></path>
<polygon fill="black" stroke="black" points="112.58,-130.29 103.97,-124.1 106.84,-134.3 112.58,-130.29"></polygon>
</g>
<!-- Documents_2 -->
<g id="node2" class="node">
<title>Documents_2</title>
<path fill="#feec98" stroke="black" d="M83.77,-196C83.77,-196 28.23,-196 28.23,-196 22.23,-196 16.23,-190 16.23,-184 16.23,-184 16.23,-172 16.23,-172 16.23,-166 22.23,-160 28.23,-160 28.23,-160 83.77,-160 83.77,-160 89.77,-160 95.77,-166 95.77,-172 95.77,-172 95.77,-184 95.77,-184 95.77,-190 89.77,-196 83.77,-196"></path>
<text text-anchor="middle" x="56" y="-173.8" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Documents_2&#45;&gt;Cross_Encoder -->
<g id="edge2" class="edge">
<title>Documents_2-&gt;Cross_Encoder</title>
<path fill="none" stroke="black" d="M64.9,-159.7C69,-151.73 73.95,-142.1 78.49,-133.26"></path>
<polygon fill="black" stroke="black" points="81.74,-134.6 83.2,-124.1 75.52,-131.4 81.74,-134.6"></polygon>
</g>
<!-- Similarity_Score -->
<g id="node4" class="node">
<title>Similarity_Score</title>
<path fill="#b2f3bb" stroke="black" d="M133.88,-52C133.88,-52 50.12,-52 50.12,-52 44.12,-52 38.12,-46 38.12,-40 38.12,-40 38.12,-28 38.12,-28 38.12,-22 44.12,-16 50.12,-16 50.12,-16 133.88,-16 133.88,-16 139.88,-16 145.88,-22 145.88,-28 145.88,-28 145.88,-40 145.88,-40 145.88,-46 139.88,-52 133.88,-52"></path>
<text text-anchor="middle" x="92" y="-29.8" font-family="Times,serif" font-size="14.00">Similarity Score</text>
</g>
<!-- Cross_Encoder&#45;&gt;Similarity_Score -->
<g id="edge3" class="edge">
<title>Cross_Encoder-&gt;Similarity_Score</title>
<path fill="none" stroke="black" d="M92,-87.7C92,-79.98 92,-70.71 92,-62.11"></path>
<polygon fill="black" stroke="black" points="95.5,-62.1 92,-52.1 88.5,-62.1 95.5,-62.1"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<ul>
<li><p><strong>Re-ranking in Practice: Addressing Computational Costs</strong></p>
<ul>
<li>Leverage a powerful but computationally expensive model (like cross-encoders) to score a subset of your documents, previously retrieved by more efficient model</li>
<li><strong>Examples of other re-ranking approaches:</strong>
<ul>
<li><strong><a href="https://github.com/sunnweiwei/RankGPT">RankGPT</a>:</strong> LLMs as Re-Ranking Agent</li>
<li><strong><a href="https://github.com/castorini/rank_llm">RankLLM</a>:</strong> Repository for prompt-decoding using LLMs</li>
</ul></li>
</ul></li>
<li><p><strong><a href="https://github.com/AnswerDotAI/rerankers">rerankers</a>:</strong> A lightweight unified API for various reranking models.</p></li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 406.00 372.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 368.8)">
<title>reranking</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-368.8 402,-368.8 402,4 -4,4"></polygon>
<text text-anchor="middle" x="199" y="-348.2" font-family="Times,serif" font-size="14.00">Compact Pipeline + Reranking</text>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-208C20,-208 378,-208 378,-208 384,-208 390,-214 390,-220 390,-220 390,-248 390,-248 390,-254 384,-260 378,-260 378,-260 20,-260 20,-260 14,-260 8,-254 8,-248 8,-248 8,-220 8,-220 8,-214 14,-208 20,-208"></path>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M118,-324C118,-324 88,-324 88,-324 82,-324 76,-318 76,-312 76,-312 76,-300 76,-300 76,-294 82,-288 88,-288 88,-288 118,-288 118,-288 124,-288 130,-294 130,-300 130,-300 130,-312 130,-312 130,-318 124,-324 118,-324"></path>
<text text-anchor="middle" x="103" y="-301.8" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Bi_Encoder -->
<g id="node3" class="node">
<title>Query_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M177.58,-252C177.58,-252 28.42,-252 28.42,-252 22.42,-252 16.42,-246 16.42,-240 16.42,-240 16.42,-228 16.42,-228 16.42,-222 22.42,-216 28.42,-216 28.42,-216 177.58,-216 177.58,-216 183.58,-216 189.58,-222 189.58,-228 189.58,-228 189.58,-240 189.58,-240 189.58,-246 183.58,-252 177.58,-252"></path>
<text text-anchor="middle" x="103" y="-229.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Query&#45;&gt;Query_Bi_Encoder -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Bi_Encoder</title>
<path fill="none" stroke="black" d="M103,-287.7C103,-279.98 103,-270.71 103,-262.11"></path>
<polygon fill="black" stroke="black" points="106.5,-262.1 103,-252.1 99.5,-262.1 106.5,-262.1"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M322.77,-324C322.77,-324 267.23,-324 267.23,-324 261.23,-324 255.23,-318 255.23,-312 255.23,-312 255.23,-300 255.23,-300 255.23,-294 261.23,-288 267.23,-288 267.23,-288 322.77,-288 322.77,-288 328.77,-288 334.77,-294 334.77,-300 334.77,-300 334.77,-312 334.77,-312 334.77,-318 328.77,-324 322.77,-324"></path>
<text text-anchor="middle" x="295" y="-301.8" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Bi_Encoder -->
<g id="node4" class="node">
<title>Document_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M369.58,-252C369.58,-252 220.42,-252 220.42,-252 214.42,-252 208.42,-246 208.42,-240 208.42,-240 208.42,-228 208.42,-228 208.42,-222 214.42,-216 220.42,-216 220.42,-216 369.58,-216 369.58,-216 375.58,-216 381.58,-222 381.58,-228 381.58,-228 381.58,-240 381.58,-240 381.58,-246 375.58,-252 369.58,-252"></path>
<text text-anchor="middle" x="295" y="-229.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Documents&#45;&gt;Document_Bi_Encoder -->
<g id="edge2" class="edge">
<title>Documents-&gt;Document_Bi_Encoder</title>
<path fill="none" stroke="black" d="M295,-287.7C295,-279.98 295,-270.71 295,-262.11"></path>
<polygon fill="black" stroke="black" points="298.5,-262.1 295,-252.1 291.5,-262.1 298.5,-262.1"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node5" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M262.8,-180C262.8,-180 135.2,-180 135.2,-180 129.2,-180 123.2,-174 123.2,-168 123.2,-168 123.2,-156 123.2,-156 123.2,-150 129.2,-144 135.2,-144 135.2,-144 262.8,-144 262.8,-144 268.8,-144 274.8,-150 274.8,-156 274.8,-156 274.8,-168 274.8,-168 274.8,-174 268.8,-180 262.8,-180"></path>
<text text-anchor="middle" x="199" y="-157.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge3" class="edge">
<title>Query_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M126.73,-215.7C138.94,-206.8 153.99,-195.82 167.18,-186.2"></path>
<polygon fill="black" stroke="black" points="169.52,-188.82 175.54,-180.1 165.4,-183.17 169.52,-188.82"></polygon>
</g>
<!-- Document_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge4" class="edge">
<title>Document_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M271.27,-215.7C259.06,-206.8 244.01,-195.82 230.82,-186.2"></path>
<polygon fill="black" stroke="black" points="232.6,-183.17 222.46,-180.1 228.48,-188.82 232.6,-183.17"></polygon>
</g>
<!-- Reranking -->
<g id="node7" class="node">
<title>Reranking</title>
<path fill="#fed8a7" stroke="black" d="M224.32,-108C224.32,-108 173.68,-108 173.68,-108 167.68,-108 161.68,-102 161.68,-96 161.68,-96 161.68,-84 161.68,-84 161.68,-78 167.68,-72 173.68,-72 173.68,-72 224.32,-72 224.32,-72 230.32,-72 236.32,-78 236.32,-84 236.32,-84 236.32,-96 236.32,-96 236.32,-102 230.32,-108 224.32,-108"></path>
<text text-anchor="middle" x="199" y="-85.8" font-family="Times,serif" font-size="14.00">Reranking</text>
</g>
<!-- Cosine_Similarity_Search&#45;&gt;Reranking -->
<g id="edge5" class="edge">
<title>Cosine_Similarity_Search-&gt;Reranking</title>
<path fill="none" stroke="black" d="M199,-143.7C199,-135.98 199,-126.71 199,-118.11"></path>
<polygon fill="black" stroke="black" points="202.5,-118.1 199,-108.1 195.5,-118.1 202.5,-118.1"></polygon>
</g>
<!-- Results -->
<g id="node6" class="node">
<title>Results</title>
<path fill="#b2f3bb" stroke="black" d="M215.73,-36C215.73,-36 182.27,-36 182.27,-36 176.27,-36 170.27,-30 170.27,-24 170.27,-24 170.27,-12 170.27,-12 170.27,-6 176.27,0 182.27,0 182.27,0 215.73,0 215.73,0 221.73,0 227.73,-6 227.73,-12 227.73,-12 227.73,-24 227.73,-24 227.73,-30 221.73,-36 215.73,-36"></path>
<text text-anchor="middle" x="199" y="-13.8" font-family="Times,serif" font-size="14.00">Results</text>
</g>
<!-- Reranking&#45;&gt;Results -->
<g id="edge6" class="edge">
<title>Reranking-&gt;Results</title>
<path fill="none" stroke="black" d="M199,-71.7C199,-63.98 199,-54.71 199,-46.11"></path>
<polygon fill="black" stroke="black" points="202.5,-46.1 199,-36.1 195.5,-46.1 202.5,-46.1"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="keyword-search" class="level2">
<h2 class="anchored" data-anchor-id="keyword-search">Keyword Search</h2>
<ul>
<li><p>Also called “full-text search”</p></li>
<li><p><strong>Embeddings Are Not Enough: Lossy Compression and Jargon</strong></p>
<ul>
<li>Embeddings compress information, potentially losing details crucial for accurate retrieval, especially with domain-specific jargon and acronyms.</li>
</ul></li>
<li><p><strong>TF-IDF and BM25</strong></p>
<ul>
<li>Emphasizes the importance of incorporating traditional keyword search alongside embedding-based methods.</li>
<li><strong>TF-IDF (Term Frequency-Inverse Document Frequency)</strong>
<ul>
<li>Assigns a weight to words or groups of words based on their rarity</li>
<li><strong>Stanford IR Book:</strong> <a href="https://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html">Inverse document frequency</a></li>
</ul></li>
<li><strong>BM25 (Best-Matching 25)</strong>
<ul>
<li><strong>Wikipedia:</strong> <a href="https://en.wikipedia.org/wiki/Okapi_BM25">Okapi BM25</a></li>
<li><strong>Stanford IR Book:</strong> <a href="https://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html">Okapi BM25: a non-binary model</a></li>
</ul></li>
</ul></li>
<li><p><strong>BM25 Performance and Relevance in Modern Pipelines</strong></p>
<ul>
<li>Highlights BM25’s continued relevance and effectiveness, often outperforming or complementing more complex methods.
<ul>
<li><div class="callout callout-style-default callout-note callout-titled" title="Results Table">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Results Table
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<div style="overflow-x:auto; max-height:500px">
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 4%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 9%">
<col style="width: 10%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th>Model (→) Dataset (↓)</th>
<th>BM25</th>
<th>DeepCT</th>
<th>SPARTA</th>
<th>docT5query</th>
<th>DPR</th>
<th>ANCE</th>
<th>TAS-B</th>
<th>GenQ</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MS MARCO</td>
<td>0.228</td>
<td>0.296‡</td>
<td>0.351‡</td>
<td>0.338‡</td>
<td>0.177</td>
<td>0.388‡</td>
<td>0.408‡</td>
<td>0.408‡</td>
</tr>
<tr class="even">
<td>TREC-COVID</td>
<td>0.656</td>
<td>0.406</td>
<td>0.538</td>
<td>0.713</td>
<td>0.332</td>
<td>0.654</td>
<td>0.481</td>
<td>0.619</td>
</tr>
<tr class="odd">
<td>BioASQ</td>
<td>0.465</td>
<td>0.407</td>
<td>0.351</td>
<td>0.431</td>
<td>0.127</td>
<td>0.306</td>
<td>0.383</td>
<td>0.398</td>
</tr>
<tr class="even">
<td>NFCorpus</td>
<td>0.325</td>
<td>0.283</td>
<td>0.301</td>
<td>0.328</td>
<td>0.189</td>
<td>0.237</td>
<td>0.319</td>
<td>0.319</td>
</tr>
<tr class="odd">
<td>NQ</td>
<td>0.329</td>
<td>0.188</td>
<td>0.398</td>
<td>0.399</td>
<td>0.474‡</td>
<td>0.446</td>
<td>0.463</td>
<td>0.358</td>
</tr>
<tr class="even">
<td>HotpotQA</td>
<td>0.603</td>
<td>0.503</td>
<td>0.492</td>
<td>0.580</td>
<td>0.391</td>
<td>0.456</td>
<td>0.584</td>
<td>0.534</td>
</tr>
<tr class="odd">
<td>FiQA-2018</td>
<td>0.236</td>
<td>0.191</td>
<td>0.198</td>
<td>0.291</td>
<td>0.112</td>
<td>0.295</td>
<td>0.300</td>
<td>0.308</td>
</tr>
<tr class="even">
<td>Signal-1M (RT)</td>
<td>0.330</td>
<td>0.269</td>
<td>0.252</td>
<td>0.307</td>
<td>0.155</td>
<td>0.249</td>
<td>0.289</td>
<td>0.281</td>
</tr>
<tr class="odd">
<td>TREC-NEWS</td>
<td>0.398</td>
<td>0.220</td>
<td>0.258</td>
<td>0.420</td>
<td>0.161</td>
<td>0.382</td>
<td>0.377</td>
<td>0.396</td>
</tr>
<tr class="even">
<td>Robust04</td>
<td>0.408</td>
<td>0.287</td>
<td>0.276</td>
<td>0.437</td>
<td>0.252</td>
<td>0.392</td>
<td>0.427</td>
<td>0.362</td>
</tr>
<tr class="odd">
<td>ArguAna</td>
<td>0.315</td>
<td>0.309</td>
<td>0.279</td>
<td>0.349</td>
<td>0.175</td>
<td>0.415</td>
<td>0.429</td>
<td>0.493</td>
</tr>
<tr class="even">
<td>Touché-2020</td>
<td>0.367</td>
<td>0.156</td>
<td>0.175</td>
<td>0.347</td>
<td>0.131</td>
<td>0.240</td>
<td>0.162</td>
<td>0.182</td>
</tr>
<tr class="odd">
<td>CQADupStack</td>
<td>0.299</td>
<td>0.268</td>
<td>0.257</td>
<td>0.325</td>
<td>0.153</td>
<td>0.296</td>
<td>0.314</td>
<td>0.347</td>
</tr>
<tr class="even">
<td>Quora</td>
<td>0.789</td>
<td>0.691</td>
<td>0.630</td>
<td>0.802</td>
<td>0.248</td>
<td>0.852</td>
<td>0.835</td>
<td>0.830</td>
</tr>
<tr class="odd">
<td>DBPedia</td>
<td>0.313</td>
<td>0.177</td>
<td>0.314</td>
<td>0.331</td>
<td>0.263</td>
<td>0.281</td>
<td>0.384</td>
<td>0.328</td>
</tr>
<tr class="even">
<td>SCIDOCS</td>
<td>0.158</td>
<td>0.124</td>
<td>0.126</td>
<td>0.162</td>
<td>0.077</td>
<td>0.122</td>
<td>0.149</td>
<td>0.143</td>
</tr>
<tr class="odd">
<td>FEVER</td>
<td>0.753</td>
<td>0.353</td>
<td>0.596</td>
<td>0.714</td>
<td>0.562</td>
<td>0.669</td>
<td>0.700</td>
<td>0.669</td>
</tr>
<tr class="even">
<td>Climate-FEVER</td>
<td>0.213</td>
<td>0.066</td>
<td>0.082</td>
<td>0.201</td>
<td>0.148</td>
<td>0.198</td>
<td>0.228</td>
<td>0.175</td>
</tr>
<tr class="odd">
<td>SciFact</td>
<td>0.665</td>
<td>0.630</td>
<td>0.582</td>
<td>0.675</td>
<td>0.318</td>
<td>0.507</td>
<td>0.643</td>
<td>0.644</td>
</tr>
<tr class="even">
<td><strong>Avg. Performance vs.&nbsp;BM25</strong></td>
<td></td>
<td><strong>- 27.9%</strong></td>
<td><strong>- 20.3%</strong></td>
<td><strong>+ 1.6%</strong></td>
<td><strong>- 47.7%</strong></td>
<td><strong>- 7.4%</strong></td>
<td><strong>- 2.8%</strong></td>
<td><strong>- 3.6%</strong></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div></li>
<li><strong>Source:</strong> <a href="https://arxiv.org/abs/2104.08663">BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models</a></li>
</ul></li>
<li>Especially powerful on longer documents and documents containing a lot of domain-specific jargon</li>
<li>Virtually unnoticeable inference-time compute overhead</li>
</ul></li>
</ul>
<section id="the-tf-idf-mvp" class="level3">
<h3 class="anchored" data-anchor-id="the-tf-idf-mvp">The TF-IDF MVP++</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 760.00 404.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 400)">
<title>tfidf_mvp_plusplus</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-400 756,-400 756,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-280C20,-280 378,-280 378,-280 384,-280 390,-286 390,-292 390,-292 390,-320 390,-320 390,-326 384,-332 378,-332 378,-332 20,-332 20,-332 14,-332 8,-326 8,-320 8,-320 8,-292 8,-292 8,-286 14,-280 20,-280"></path>
</g>
<g id="clust2" class="cluster">
<title>cluster_1</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M410,-280C410,-280 732,-280 732,-280 738,-280 744,-286 744,-292 744,-292 744,-320 744,-320 744,-326 738,-332 732,-332 732,-332 410,-332 410,-332 404,-332 398,-326 398,-320 398,-320 398,-292 398,-292 398,-286 404,-280 410,-280"></path>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M335,-396C335,-396 305,-396 305,-396 299,-396 293,-390 293,-384 293,-384 293,-372 293,-372 293,-366 299,-360 305,-360 305,-360 335,-360 335,-360 341,-360 347,-366 347,-372 347,-372 347,-384 347,-384 347,-390 341,-396 335,-396"></path>
<text text-anchor="middle" x="320" y="-373.8" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Bi_Encoder -->
<g id="node3" class="node">
<title>Query_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M177.58,-324C177.58,-324 28.42,-324 28.42,-324 22.42,-324 16.42,-318 16.42,-312 16.42,-312 16.42,-300 16.42,-300 16.42,-294 22.42,-288 28.42,-288 28.42,-288 177.58,-288 177.58,-288 183.58,-288 189.58,-294 189.58,-300 189.58,-300 189.58,-312 189.58,-312 189.58,-318 183.58,-324 177.58,-324"></path>
<text text-anchor="middle" x="103" y="-301.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Query&#45;&gt;Query_Bi_Encoder -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Bi_Encoder</title>
<path fill="none" stroke="black" d="M292.96,-368.28C261.23,-358.04 207.6,-340.74 165.41,-327.13"></path>
<polygon fill="black" stroke="black" points="166.36,-323.76 155.77,-324.02 164.21,-330.42 166.36,-323.76"></polygon>
</g>
<!-- Query_tfidf -->
<g id="node5" class="node">
<title>Query_tfidf</title>
<path fill="#cfbffe" stroke="black" d="M550.34,-324C550.34,-324 417.66,-324 417.66,-324 411.66,-324 405.66,-318 405.66,-312 405.66,-312 405.66,-300 405.66,-300 405.66,-294 411.66,-288 417.66,-288 417.66,-288 550.34,-288 550.34,-288 556.34,-288 562.34,-294 562.34,-300 562.34,-300 562.34,-312 562.34,-312 562.34,-318 556.34,-324 550.34,-324"></path>
<text text-anchor="middle" x="484" y="-301.8" font-family="Times,serif" font-size="14.00">tf-idf (weighted full text)</text>
</g>
<!-- Query&#45;&gt;Query_tfidf -->
<g id="edge3" class="edge">
<title>Query-&gt;Query_tfidf</title>
<path fill="none" stroke="black" d="M347.08,-365.44C370.79,-355.32 405.82,-340.37 434.52,-328.12"></path>
<polygon fill="black" stroke="black" points="436.16,-331.23 443.98,-324.08 433.41,-324.79 436.16,-331.23"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M485.77,-396C485.77,-396 430.23,-396 430.23,-396 424.23,-396 418.23,-390 418.23,-384 418.23,-384 418.23,-372 418.23,-372 418.23,-366 424.23,-360 430.23,-360 430.23,-360 485.77,-360 485.77,-360 491.77,-360 497.77,-366 497.77,-372 497.77,-372 497.77,-384 497.77,-384 497.77,-390 491.77,-396 485.77,-396"></path>
<text text-anchor="middle" x="458" y="-373.8" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Bi_Encoder -->
<g id="node4" class="node">
<title>Document_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M369.58,-324C369.58,-324 220.42,-324 220.42,-324 214.42,-324 208.42,-318 208.42,-312 208.42,-312 208.42,-300 208.42,-300 208.42,-294 214.42,-288 220.42,-288 220.42,-288 369.58,-288 369.58,-288 375.58,-288 381.58,-294 381.58,-300 381.58,-300 381.58,-312 381.58,-312 381.58,-318 375.58,-324 369.58,-324"></path>
<text text-anchor="middle" x="295" y="-301.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Documents&#45;&gt;Document_Bi_Encoder -->
<g id="edge2" class="edge">
<title>Documents-&gt;Document_Bi_Encoder</title>
<path fill="none" stroke="black" d="M418.13,-359.88C395.84,-350.31 367.88,-338.3 344.24,-328.15"></path>
<polygon fill="black" stroke="black" points="345.31,-324.8 334.74,-324.07 342.55,-331.23 345.31,-324.8"></polygon>
</g>
<!-- Document_tfidf -->
<g id="node6" class="node">
<title>Document_tfidf</title>
<path fill="#cfbffe" stroke="black" d="M724.34,-324C724.34,-324 591.66,-324 591.66,-324 585.66,-324 579.66,-318 579.66,-312 579.66,-312 579.66,-300 579.66,-300 579.66,-294 585.66,-288 591.66,-288 591.66,-288 724.34,-288 724.34,-288 730.34,-288 736.34,-294 736.34,-300 736.34,-300 736.34,-312 736.34,-312 736.34,-318 730.34,-324 724.34,-324"></path>
<text text-anchor="middle" x="658" y="-301.8" font-family="Times,serif" font-size="14.00">tf-idf (weighted full text)</text>
</g>
<!-- Documents&#45;&gt;Document_tfidf -->
<g id="edge4" class="edge">
<title>Documents-&gt;Document_tfidf</title>
<path fill="none" stroke="black" d="M497.99,-363C527.15,-352.8 567.1,-338.82 599.79,-327.37"></path>
<polygon fill="black" stroke="black" points="600.96,-330.67 609.24,-324.07 598.64,-324.07 600.96,-330.67"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node7" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M358.8,-252C358.8,-252 231.2,-252 231.2,-252 225.2,-252 219.2,-246 219.2,-240 219.2,-240 219.2,-228 219.2,-228 219.2,-222 225.2,-216 231.2,-216 231.2,-216 358.8,-216 358.8,-216 364.8,-216 370.8,-222 370.8,-228 370.8,-228 370.8,-240 370.8,-240 370.8,-246 364.8,-252 358.8,-252"></path>
<text text-anchor="middle" x="295" y="-229.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge5" class="edge">
<title>Query_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M149.97,-287.88C176.68,-278.14 210.32,-265.87 238.47,-255.61"></path>
<polygon fill="black" stroke="black" points="239.99,-258.78 248.18,-252.07 237.59,-252.21 239.99,-258.78"></polygon>
</g>
<!-- Document_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge6" class="edge">
<title>Document_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M295,-287.7C295,-279.98 295,-270.71 295,-262.11"></path>
<polygon fill="black" stroke="black" points="298.5,-262.1 295,-252.1 291.5,-262.1 298.5,-262.1"></polygon>
</g>
<!-- BM25 -->
<g id="node10" class="node">
<title>BM25</title>
<path fill="#eebefa" stroke="black" d="M546.46,-252C546.46,-252 421.54,-252 421.54,-252 415.54,-252 409.54,-246 409.54,-240 409.54,-240 409.54,-228 409.54,-228 409.54,-222 415.54,-216 421.54,-216 421.54,-216 546.46,-216 546.46,-216 552.46,-216 558.46,-222 558.46,-228 558.46,-228 558.46,-240 558.46,-240 558.46,-246 552.46,-252 546.46,-252"></path>
<text text-anchor="middle" x="484" y="-229.8" font-family="Times,serif" font-size="14.00">BM25 (full-text) search</text>
</g>
<!-- Query_tfidf&#45;&gt;BM25 -->
<g id="edge8" class="edge">
<title>Query_tfidf-&gt;BM25</title>
<path fill="none" stroke="black" d="M484,-287.7C484,-279.98 484,-270.71 484,-262.11"></path>
<polygon fill="black" stroke="black" points="487.5,-262.1 484,-252.1 480.5,-262.1 487.5,-262.1"></polygon>
</g>
<!-- Document_tfidf&#45;&gt;BM25 -->
<g id="edge9" class="edge">
<title>Document_tfidf-&gt;BM25</title>
<path fill="none" stroke="black" d="M615.43,-287.88C591.44,-278.22 561.27,-266.09 535.9,-255.88"></path>
<polygon fill="black" stroke="black" points="537.01,-252.55 526.43,-252.07 534.4,-259.05 537.01,-252.55"></polygon>
</g>
<!-- Combine_Scores -->
<g id="node11" class="node">
<title>Combine_Scores</title>
<path fill="#95f2d7" stroke="black" d="M440.42,-180C440.42,-180 337.58,-180 337.58,-180 331.58,-180 325.58,-174 325.58,-168 325.58,-168 325.58,-156 325.58,-156 325.58,-150 331.58,-144 337.58,-144 337.58,-144 440.42,-144 440.42,-144 446.42,-144 452.42,-150 452.42,-156 452.42,-156 452.42,-168 452.42,-168 452.42,-174 446.42,-180 440.42,-180"></path>
<text text-anchor="middle" x="389" y="-157.8" font-family="Times,serif" font-size="14.00">Combine the scores</text>
</g>
<!-- Cosine_Similarity_Search&#45;&gt;Combine_Scores -->
<g id="edge11" class="edge">
<title>Cosine_Similarity_Search-&gt;Combine_Scores</title>
<path fill="none" stroke="black" d="M318.24,-215.7C330.19,-206.8 344.92,-195.82 357.85,-186.2"></path>
<polygon fill="black" stroke="black" points="360.1,-188.88 366.03,-180.1 355.92,-183.27 360.1,-188.88"></polygon>
</g>
<!-- Results -->
<g id="node8" class="node">
<title>Results</title>
<path fill="#b2f3bb" stroke="black" d="M405.73,-36C405.73,-36 372.27,-36 372.27,-36 366.27,-36 360.27,-30 360.27,-24 360.27,-24 360.27,-12 360.27,-12 360.27,-6 366.27,0 372.27,0 372.27,0 405.73,0 405.73,0 411.73,0 417.73,-6 417.73,-12 417.73,-12 417.73,-24 417.73,-24 417.73,-30 411.73,-36 405.73,-36"></path>
<text text-anchor="middle" x="389" y="-13.8" font-family="Times,serif" font-size="14.00">Results</text>
</g>
<!-- Reranking -->
<g id="node9" class="node">
<title>Reranking</title>
<path fill="#fed8a7" stroke="black" d="M414.32,-108C414.32,-108 363.68,-108 363.68,-108 357.68,-108 351.68,-102 351.68,-96 351.68,-96 351.68,-84 351.68,-84 351.68,-78 357.68,-72 363.68,-72 363.68,-72 414.32,-72 414.32,-72 420.32,-72 426.32,-78 426.32,-84 426.32,-84 426.32,-96 426.32,-96 426.32,-102 420.32,-108 414.32,-108"></path>
<text text-anchor="middle" x="389" y="-85.8" font-family="Times,serif" font-size="14.00">Reranking</text>
</g>
<!-- Reranking&#45;&gt;Results -->
<g id="edge7" class="edge">
<title>Reranking-&gt;Results</title>
<path fill="none" stroke="black" d="M389,-71.7C389,-63.98 389,-54.71 389,-46.11"></path>
<polygon fill="black" stroke="black" points="392.5,-46.1 389,-36.1 385.5,-46.1 392.5,-46.1"></polygon>
</g>
<!-- BM25&#45;&gt;Combine_Scores -->
<g id="edge10" class="edge">
<title>BM25-&gt;Combine_Scores</title>
<path fill="none" stroke="black" d="M460.52,-215.7C448.44,-206.8 433.55,-195.82 420.48,-186.2"></path>
<polygon fill="black" stroke="black" points="422.34,-183.22 412.21,-180.1 418.19,-188.85 422.34,-183.22"></polygon>
</g>
<!-- Combine_Scores&#45;&gt;Reranking -->
<g id="edge12" class="edge">
<title>Combine_Scores-&gt;Reranking</title>
<path fill="none" stroke="black" d="M389,-143.7C389,-135.98 389,-126.71 389,-118.11"></path>
<polygon fill="black" stroke="black" points="392.5,-118.1 389,-108.1 385.5,-118.1 392.5,-118.1"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
</section>
<section id="leveraging-metadata-for-targeted-retrieval" class="level2">
<h2 class="anchored" data-anchor-id="leveraging-metadata-for-targeted-retrieval">Leveraging Metadata for Targeted Retrieval</h2>
<ul>
<li><strong>Real-World Data Has Context: Metadata Matters</strong>
<ul>
<li>Real-world documents often possess valuable metadata (e.g., author, date, department) that can significantly improve retrieval accuracy.</li>
<li>Pure Semantic or Keyword Search can struggle with metadata
<ul>
<li><strong>Example Query:</strong> “Can you get me the cruise division financial report for Q4 2022?”
<ul>
<li>Model must accurately represent all of “ﬁnancial report”, “cruise division”, “Q4” and “2022”, into a single vector
<ul>
<li>Otherwise it will fetch documents that look relevant but aren’t meeting one or more of those criteria.</li>
</ul></li>
<li>If the number of documents you search for (“k”) is set too high, you will be passing irrelevant ﬁnancial reports to your LLM</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Entity Detection and Metadata Filtering: A Practical Example</strong>
<ul>
<li>Use entity detection models like GLiNER to automatically extract relevant metadata (e.g., document type, time period, department).</li>
<li><strong>GLiNER</strong>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2311.08526">GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer</a></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/urchade/GLiNER">GLiNER</a></li>
<li><strong>:hugs: Spaces Demo:</strong> <a href="https://huggingface.co/spaces/tomaarsen/gliner_medium-v2.1">GLiNER-medium-v2.1, zero-shot NER</a></li>
</ul></li>
<li>Filter documents based on extracted metadata to ensure relevance and reduce noise.</li>
</ul></li>
<li><strong>Storing and Using Metadata for Pre-filtering</strong>
<ul>
<li>Store metadata alongside documents in the database.</li>
<li>During retrieval, pre-filter documents based on query-specific metadata to narrow down the search space.</li>
</ul></li>
</ul>
</section>
<section id="putting-it-all-together-the-complete-mvp-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="putting-it-all-together-the-complete-mvp-pipeline">Putting it All Together: The Complete MVP++ Pipeline</h2>
<section id="the-final-compact-mvp" class="level3">
<h3 class="anchored" data-anchor-id="the-final-compact-mvp">The Final Compact MVP++</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="672" height="480" viewbox="0.00 0.00 760.00 476.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 472)">
<title>tfidf_mvp_plusplus</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-472 756,-472 756,4 -4,4"></polygon>
<g id="clust1" class="cluster">
<title>cluster_0</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M20,-352C20,-352 378,-352 378,-352 384,-352 390,-358 390,-364 390,-364 390,-392 390,-392 390,-398 384,-404 378,-404 378,-404 20,-404 20,-404 14,-404 8,-398 8,-392 8,-392 8,-364 8,-364 8,-358 14,-352 20,-352"></path>
</g>
<g id="clust2" class="cluster">
<title>cluster_1</title>
<path fill="none" stroke="black" stroke-dasharray="5,2" d="M410,-352C410,-352 732,-352 732,-352 738,-352 744,-358 744,-364 744,-364 744,-392 744,-392 744,-398 738,-404 732,-404 732,-404 410,-404 410,-404 404,-404 398,-398 398,-392 398,-392 398,-364 398,-364 398,-358 404,-352 410,-352"></path>
</g>
<!-- Query -->
<g id="node1" class="node">
<title>Query</title>
<path fill="#a4d8ff" stroke="black" d="M335,-468C335,-468 305,-468 305,-468 299,-468 293,-462 293,-456 293,-456 293,-444 293,-444 293,-438 299,-432 305,-432 305,-432 335,-432 335,-432 341,-432 347,-438 347,-444 347,-444 347,-456 347,-456 347,-462 341,-468 335,-468"></path>
<text text-anchor="middle" x="320" y="-445.8" font-family="Times,serif" font-size="14.00">Query</text>
</g>
<!-- Query_Bi_Encoder -->
<g id="node3" class="node">
<title>Query_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M177.58,-396C177.58,-396 28.42,-396 28.42,-396 22.42,-396 16.42,-390 16.42,-384 16.42,-384 16.42,-372 16.42,-372 16.42,-366 22.42,-360 28.42,-360 28.42,-360 177.58,-360 177.58,-360 183.58,-360 189.58,-366 189.58,-372 189.58,-372 189.58,-384 189.58,-384 189.58,-390 183.58,-396 177.58,-396"></path>
<text text-anchor="middle" x="103" y="-373.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Query&#45;&gt;Query_Bi_Encoder -->
<g id="edge1" class="edge">
<title>Query-&gt;Query_Bi_Encoder</title>
<path fill="none" stroke="black" d="M292.96,-440.28C261.23,-430.04 207.6,-412.74 165.41,-399.13"></path>
<polygon fill="black" stroke="black" points="166.36,-395.76 155.77,-396.02 164.21,-402.42 166.36,-395.76"></polygon>
</g>
<!-- Query_tfidf -->
<g id="node5" class="node">
<title>Query_tfidf</title>
<path fill="#cfbffe" stroke="black" d="M550.34,-396C550.34,-396 417.66,-396 417.66,-396 411.66,-396 405.66,-390 405.66,-384 405.66,-384 405.66,-372 405.66,-372 405.66,-366 411.66,-360 417.66,-360 417.66,-360 550.34,-360 550.34,-360 556.34,-360 562.34,-366 562.34,-372 562.34,-372 562.34,-384 562.34,-384 562.34,-390 556.34,-396 550.34,-396"></path>
<text text-anchor="middle" x="484" y="-373.8" font-family="Times,serif" font-size="14.00">tf-idf (weighted full text)</text>
</g>
<!-- Query&#45;&gt;Query_tfidf -->
<g id="edge3" class="edge">
<title>Query-&gt;Query_tfidf</title>
<path fill="none" stroke="black" d="M347.08,-437.44C370.79,-427.32 405.82,-412.37 434.52,-400.12"></path>
<polygon fill="black" stroke="black" points="436.16,-403.23 443.98,-396.08 433.41,-396.79 436.16,-403.23"></polygon>
</g>
<!-- Documents -->
<g id="node2" class="node">
<title>Documents</title>
<path fill="#feec98" stroke="black" d="M485.77,-468C485.77,-468 430.23,-468 430.23,-468 424.23,-468 418.23,-462 418.23,-456 418.23,-456 418.23,-444 418.23,-444 418.23,-438 424.23,-432 430.23,-432 430.23,-432 485.77,-432 485.77,-432 491.77,-432 497.77,-438 497.77,-444 497.77,-444 497.77,-456 497.77,-456 497.77,-462 491.77,-468 485.77,-468"></path>
<text text-anchor="middle" x="458" y="-445.8" font-family="Times,serif" font-size="14.00">Documents</text>
</g>
<!-- Document_Bi_Encoder -->
<g id="node4" class="node">
<title>Document_Bi_Encoder</title>
<path fill="#ffc9c9" stroke="black" d="M369.58,-396C369.58,-396 220.42,-396 220.42,-396 214.42,-396 208.42,-390 208.42,-384 208.42,-384 208.42,-372 208.42,-372 208.42,-366 214.42,-360 220.42,-360 220.42,-360 369.58,-360 369.58,-360 375.58,-360 381.58,-366 381.58,-372 381.58,-372 381.58,-384 381.58,-384 381.58,-390 375.58,-396 369.58,-396"></path>
<text text-anchor="middle" x="295" y="-373.8" font-family="Times,serif" font-size="14.00">Bi-Encoder (Embed + Pool)</text>
</g>
<!-- Documents&#45;&gt;Document_Bi_Encoder -->
<g id="edge2" class="edge">
<title>Documents-&gt;Document_Bi_Encoder</title>
<path fill="none" stroke="black" d="M418.13,-431.88C395.84,-422.31 367.88,-410.3 344.24,-400.15"></path>
<polygon fill="black" stroke="black" points="345.31,-396.8 334.74,-396.07 342.55,-403.23 345.31,-396.8"></polygon>
</g>
<!-- Document_tfidf -->
<g id="node6" class="node">
<title>Document_tfidf</title>
<path fill="#cfbffe" stroke="black" d="M724.34,-396C724.34,-396 591.66,-396 591.66,-396 585.66,-396 579.66,-390 579.66,-384 579.66,-384 579.66,-372 579.66,-372 579.66,-366 585.66,-360 591.66,-360 591.66,-360 724.34,-360 724.34,-360 730.34,-360 736.34,-366 736.34,-372 736.34,-372 736.34,-384 736.34,-384 736.34,-390 730.34,-396 724.34,-396"></path>
<text text-anchor="middle" x="658" y="-373.8" font-family="Times,serif" font-size="14.00">tf-idf (weighted full text)</text>
</g>
<!-- Documents&#45;&gt;Document_tfidf -->
<g id="edge4" class="edge">
<title>Documents-&gt;Document_tfidf</title>
<path fill="none" stroke="black" d="M497.99,-435C527.15,-424.8 567.1,-410.82 599.79,-399.37"></path>
<polygon fill="black" stroke="black" points="600.96,-402.67 609.24,-396.07 598.64,-396.07 600.96,-402.67"></polygon>
</g>
<!-- Cosine_Similarity_Search -->
<g id="node9" class="node">
<title>Cosine_Similarity_Search</title>
<path fill="#b2f3bb" stroke="black" d="M358.8,-252C358.8,-252 231.2,-252 231.2,-252 225.2,-252 219.2,-246 219.2,-240 219.2,-240 219.2,-228 219.2,-228 219.2,-222 225.2,-216 231.2,-216 231.2,-216 358.8,-216 358.8,-216 364.8,-216 370.8,-222 370.8,-228 370.8,-228 370.8,-240 370.8,-240 370.8,-246 364.8,-252 358.8,-252"></path>
<text text-anchor="middle" x="295" y="-229.8" font-family="Times,serif" font-size="14.00">Cosine similarity search</text>
</g>
<!-- Query_Bi_Encoder&#45;&gt;Cosine_Similarity_Search -->
<g id="edge7" class="edge">
<title>Query_Bi_Encoder-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M118.05,-359.77C135.33,-340.66 165.15,-309.68 195,-288 211.23,-276.21 230.42,-265.4 247.63,-256.65"></path>
<polygon fill="black" stroke="black" points="249.56,-259.6 256.95,-252.02 246.44,-253.34 249.56,-259.6"></polygon>
</g>
<!-- Metadata_Filtering -->
<g id="node7" class="node">
<title>Metadata_Filtering</title>
<path fill="#d2bab0" stroke="black" d="M373.62,-324C373.62,-324 216.38,-324 216.38,-324 210.38,-324 204.38,-318 204.38,-312 204.38,-312 204.38,-300 204.38,-300 204.38,-294 210.38,-288 216.38,-288 216.38,-288 373.62,-288 373.62,-288 379.62,-288 385.62,-294 385.62,-300 385.62,-300 385.62,-312 385.62,-312 385.62,-318 379.62,-324 373.62,-324"></path>
<text text-anchor="middle" x="295" y="-301.8" font-family="Times,serif" font-size="14.00">Metadata Document Filtering</text>
</g>
<!-- Document_Bi_Encoder&#45;&gt;Metadata_Filtering -->
<g id="edge5" class="edge">
<title>Document_Bi_Encoder-&gt;Metadata_Filtering</title>
<path fill="none" stroke="black" d="M295,-359.7C295,-351.98 295,-342.71 295,-334.11"></path>
<polygon fill="black" stroke="black" points="298.5,-334.1 295,-324.1 291.5,-334.1 298.5,-334.1"></polygon>
</g>
<!-- BM25 -->
<g id="node12" class="node">
<title>BM25</title>
<path fill="#eebefa" stroke="black" d="M546.46,-252C546.46,-252 421.54,-252 421.54,-252 415.54,-252 409.54,-246 409.54,-240 409.54,-240 409.54,-228 409.54,-228 409.54,-222 415.54,-216 421.54,-216 421.54,-216 546.46,-216 546.46,-216 552.46,-216 558.46,-222 558.46,-228 558.46,-228 558.46,-240 558.46,-240 558.46,-246 552.46,-252 546.46,-252"></path>
<text text-anchor="middle" x="484" y="-229.8" font-family="Times,serif" font-size="14.00">BM25 (full-text) search</text>
</g>
<!-- Query_tfidf&#45;&gt;BM25 -->
<g id="edge10" class="edge">
<title>Query_tfidf-&gt;BM25</title>
<path fill="none" stroke="black" d="M484,-359.87C484,-335.67 484,-291.21 484,-262.39"></path>
<polygon fill="black" stroke="black" points="487.5,-262.19 484,-252.19 480.5,-262.19 487.5,-262.19"></polygon>
</g>
<!-- Metadata_Filtering_2 -->
<g id="node8" class="node">
<title>Metadata_Filtering_2</title>
<path fill="#d2bab0" stroke="black" d="M708.62,-324C708.62,-324 551.38,-324 551.38,-324 545.38,-324 539.38,-318 539.38,-312 539.38,-312 539.38,-300 539.38,-300 539.38,-294 545.38,-288 551.38,-288 551.38,-288 708.62,-288 708.62,-288 714.62,-288 720.62,-294 720.62,-300 720.62,-300 720.62,-312 720.62,-312 720.62,-318 714.62,-324 708.62,-324"></path>
<text text-anchor="middle" x="630" y="-301.8" font-family="Times,serif" font-size="14.00">Metadata Document Filtering</text>
</g>
<!-- Document_tfidf&#45;&gt;Metadata_Filtering_2 -->
<g id="edge6" class="edge">
<title>Document_tfidf-&gt;Metadata_Filtering_2</title>
<path fill="none" stroke="black" d="M651.08,-359.7C647.93,-351.81 644.12,-342.3 640.62,-333.55"></path>
<polygon fill="black" stroke="black" points="643.81,-332.09 636.84,-324.1 637.31,-334.69 643.81,-332.09"></polygon>
</g>
<!-- Metadata_Filtering&#45;&gt;Cosine_Similarity_Search -->
<g id="edge8" class="edge">
<title>Metadata_Filtering-&gt;Cosine_Similarity_Search</title>
<path fill="none" stroke="black" d="M295,-287.7C295,-279.98 295,-270.71 295,-262.11"></path>
<polygon fill="black" stroke="black" points="298.5,-262.1 295,-252.1 291.5,-262.1 298.5,-262.1"></polygon>
</g>
<!-- Metadata_Filtering_2&#45;&gt;BM25 -->
<g id="edge11" class="edge">
<title>Metadata_Filtering_2-&gt;BM25</title>
<path fill="none" stroke="black" d="M594.28,-287.88C574.5,-278.39 549.73,-266.51 528.67,-256.42"></path>
<polygon fill="black" stroke="black" points="530.13,-253.24 519.6,-252.07 527.1,-259.55 530.13,-253.24"></polygon>
</g>
<!-- Combine_Scores -->
<g id="node13" class="node">
<title>Combine_Scores</title>
<path fill="#95f2d7" stroke="black" d="M440.42,-180C440.42,-180 337.58,-180 337.58,-180 331.58,-180 325.58,-174 325.58,-168 325.58,-168 325.58,-156 325.58,-156 325.58,-150 331.58,-144 337.58,-144 337.58,-144 440.42,-144 440.42,-144 446.42,-144 452.42,-150 452.42,-156 452.42,-156 452.42,-168 452.42,-168 452.42,-174 446.42,-180 440.42,-180"></path>
<text text-anchor="middle" x="389" y="-157.8" font-family="Times,serif" font-size="14.00">Combine the scores</text>
</g>
<!-- Cosine_Similarity_Search&#45;&gt;Combine_Scores -->
<g id="edge13" class="edge">
<title>Cosine_Similarity_Search-&gt;Combine_Scores</title>
<path fill="none" stroke="black" d="M318.24,-215.7C330.19,-206.8 344.92,-195.82 357.85,-186.2"></path>
<polygon fill="black" stroke="black" points="360.1,-188.88 366.03,-180.1 355.92,-183.27 360.1,-188.88"></polygon>
</g>
<!-- Results -->
<g id="node10" class="node">
<title>Results</title>
<path fill="#b2f3bb" stroke="black" d="M405.73,-36C405.73,-36 372.27,-36 372.27,-36 366.27,-36 360.27,-30 360.27,-24 360.27,-24 360.27,-12 360.27,-12 360.27,-6 366.27,0 372.27,0 372.27,0 405.73,0 405.73,0 411.73,0 417.73,-6 417.73,-12 417.73,-12 417.73,-24 417.73,-24 417.73,-30 411.73,-36 405.73,-36"></path>
<text text-anchor="middle" x="389" y="-13.8" font-family="Times,serif" font-size="14.00">Results</text>
</g>
<!-- Reranking -->
<g id="node11" class="node">
<title>Reranking</title>
<path fill="#fed8a7" stroke="black" d="M414.32,-108C414.32,-108 363.68,-108 363.68,-108 357.68,-108 351.68,-102 351.68,-96 351.68,-96 351.68,-84 351.68,-84 351.68,-78 357.68,-72 363.68,-72 363.68,-72 414.32,-72 414.32,-72 420.32,-72 426.32,-78 426.32,-84 426.32,-84 426.32,-96 426.32,-96 426.32,-102 420.32,-108 414.32,-108"></path>
<text text-anchor="middle" x="389" y="-85.8" font-family="Times,serif" font-size="14.00">Reranking</text>
</g>
<!-- Reranking&#45;&gt;Results -->
<g id="edge9" class="edge">
<title>Reranking-&gt;Results</title>
<path fill="none" stroke="black" d="M389,-71.7C389,-63.98 389,-54.71 389,-46.11"></path>
<polygon fill="black" stroke="black" points="392.5,-46.1 389,-36.1 385.5,-46.1 392.5,-46.1"></polygon>
</g>
<!-- BM25&#45;&gt;Combine_Scores -->
<g id="edge12" class="edge">
<title>BM25-&gt;Combine_Scores</title>
<path fill="none" stroke="black" d="M460.52,-215.7C448.44,-206.8 433.55,-195.82 420.48,-186.2"></path>
<polygon fill="black" stroke="black" points="422.34,-183.22 412.21,-180.1 418.19,-188.85 422.34,-183.22"></polygon>
</g>
<!-- Combine_Scores&#45;&gt;Reranking -->
<g id="edge14" class="edge">
<title>Combine_Scores-&gt;Reranking</title>
<path fill="none" stroke="black" d="M389,-143.7C389,-135.98 389,-126.71 389,-118.11"></path>
<polygon fill="black" stroke="black" points="392.5,-118.1 389,-108.1 385.5,-118.1 392.5,-118.1"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="code-example-implementing-the-mvp-with-lancedb" class="level3">
<h3 class="anchored" data-anchor-id="code-example-implementing-the-mvp-with-lancedb">Code Example: Implementing the MVP++ with LanceDB</h3>
<ul>
<li>Uses LanceDB for its ease of use and built-in components.</li>
<li><strong>Vector Databases</strong>
<ul>
<li><a href="https://lancedb.com/">LanceDB</a></li>
<li><a href="https://weaviate.io/">Weaviate</a></li>
<li><a href="https://www.trychroma.com/">Chroma</a></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fetch some text content in two different categories</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> wikipediaapi <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Wikipedia</span>
<span id="cb1-3">wiki <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Wikipedia(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RAGBot/0.0'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en'</span>)</span>
<span id="cb1-4">docs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>: x,</span>
<span id="cb1-5">         <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"category"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person"</span>}</span>
<span id="cb1-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> wiki.page(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hayao_Miyazaki'</span>).text.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)]</span>
<span id="cb1-7">docs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>: x,</span>
<span id="cb1-8">          <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"category"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"film"</span>}</span>
<span id="cb1-9">         <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> wiki.page(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Spirited_Away'</span>).text.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)]</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Enter LanceDB</span></span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> lancedb</span>
<span id="cb1-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> lancedb.pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LanceModel, Vector</span>
<span id="cb1-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> lancedb.embedding <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_registry</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialise the embedding model</span></span>
<span id="cb1-17">model_registry <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_registry().get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sentence-transformers"</span>)</span>
<span id="cb1-18">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_registry.create(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BAAI/bge-small-en-v1.5"</span>)</span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a Model to store attributes for filtering</span></span>
<span id="cb1-21"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Document(LanceModel):                    </span>
<span id="cb1-22">    text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.SourceField()</span>
<span id="cb1-23">    vector: Vector(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.VectorField()</span>
<span id="cb1-24">    category: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-25"></span>
<span id="cb1-26">db <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lancedb.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".my_db"</span>)</span>
<span id="cb1-27">tbl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> db.create_table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my_table"</span>, schema<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Document)</span>
<span id="cb1-28"></span>
<span id="cb1-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Embed the documents and store them in the database</span></span>
<span id="cb1-30">tbl.add(docs)                                        </span>
<span id="cb1-31"></span>
<span id="cb1-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate the full-text (tf-idf) search index</span></span>
<span id="cb1-33">tbl.create_fts_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)                         </span>
<span id="cb1-34"></span>
<span id="cb1-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialise a reranker -- here, Cohere's API one</span></span>
<span id="cb1-36"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> lancedb.rerankers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> CohereReranker</span>
<span id="cb1-37"></span>
<span id="cb1-38">reranker <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CohereReranker()                        </span>
<span id="cb1-39"></span>
<span id="cb1-40">query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What is Chihiro's new name given to her by the witch?"</span></span>
<span id="cb1-41"></span>
<span id="cb1-42">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (tbl.search(query, query_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hybrid"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hybrid means text + vector</span></span>
<span id="cb1-43">           .where(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"category = 'film'"</span>, prefilter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Restrict to only docs in the 'film' category</span></span>
<span id="cb1-44">           .limit(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get 10 results from first-pass retrieval</span></span>
<span id="cb1-45">           .rerank(reranker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>reranker) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># For the reranker to compute the final ranking</span></span>
<span id="cb1-46">          )</span></code></pre></div>
</section>
</section>
<section id="beyond-the-basics-future-exploration-and-resources" class="level2">
<h2 class="anchored" data-anchor-id="beyond-the-basics-future-exploration-and-resources">Beyond the Basics: Future Exploration and Resources</h2>
<ul>
<li><strong><a href="https://github.com/AnswerDotAI/RAGatouille">RAGatouille</a>:</strong> Easily use and train state of the art late-interaction retrieval methods (ColBERT) in any RAG pipeline.</li>
<li><strong><a href="https://github.com/AnswerDotAI/rerankers">rerankers</a>:</strong> A lightweight unified API for various reranking models.</li>
<li><strong>Video Tutorial:</strong> <a href="https://www.youtube.com/watch?v=jkrNMKz9pWU">A Hackers’ Guide to Language Models</a></li>
<li><strong>ColBERT</strong>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2004.12832">ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT</a></li>
<li><strong>HuggingFace Hub:</strong> <a href="https://huggingface.co/colbert-ir/colbertv2.0">colbert-ir/colbertv2.0</a></li>
</ul></li>
<li><strong>Sparse Vectors:</strong> <a href="https://docs.pinecone.io/guides/data/understanding-hybrid-search">Understanding hybrid search</a></li>
<li><strong>Multi-vector Retrievers:</strong> <a href="https://blog.langchain.dev/semi-structured-multi-modal-rag/">Multi-Vector Retriever for RAG on tables, text, and images</a></li>
</ul>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<section id="fine-tuning-bi-encoders-and-cross-encoders" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-bi-encoders-and-cross-encoders">Fine-tuning Bi-Encoders and Cross-Encoders</h3>
<ul>
<li><p><strong>Q:</strong> Does the fine-tuning approach for bi-encoder models impact the fine-tuning of cross-encoder models and vice versa?</p></li>
<li><p><strong>A:</strong> While domain-specific, generally aim for complementarity. Fine-tune bi-encoders for broader retrieval, capturing potential candidates. Rely on cross-encoders (re-rankers) for precise filtering and ranking.</p></li>
</ul>
</section>
<section id="combining-bi-encoder-and-tf-idf-scores" class="level3">
<h3 class="anchored" data-anchor-id="combining-bi-encoder-and-tf-idf-scores">Combining Bi-Encoder and TF-IDF Scores</h3>
<ul>
<li><p><strong>Q:</strong> What are the advantages and disadvantages of using a weighted average of bi-encoder and TF-IDF scores for selecting re-ranker questions compared to taking the top X from each ranker?</p></li>
<li><p><strong>A:</strong> Both methods are valid and depend on the data. Weighted averages can be effective, but in domains like biomedicine, where document specificity is crucial, taking the top X from both ensures representation for potentially poorly embedded queries.</p></li>
</ul>
</section>
<section id="rags-future-with-million-token-context-lengths" class="level3">
<h3 class="anchored" data-anchor-id="rags-future-with-million-token-context-lengths">RAG’s Future with Million-Token Context Lengths</h3>
<ul>
<li><p><strong>Q:</strong> How will the emergence of million-token context lengths impact the relevance of RAG in the future?</p></li>
<li><p><strong>A:</strong> RAG remains relevant even with extended context windows. Just as RAM doesn’t replace hard drives, large context windows won’t replace the need for efficient retrieval from vast external knowledge stores. Long context windows provide more flexibility in retrieval speed and allow for incorporating longer documents.</p></li>
</ul>
</section>
<section id="chunking-strategies" class="level3">
<h3 class="anchored" data-anchor-id="chunking-strategies">Chunking Strategies</h3>
<ul>
<li><p><strong>Q:</strong> What are your thoughts on different chunking strategies?</p></li>
<li><p><strong>A:</strong> While LLMs for pre-chunking are promising but currently immature, maintaining semantic continuity within chunks is vital. The recommended approach is 300 tokens per chunk, avoiding sentence interruptions and including overlapping context (50 tokens) between consecutive chunks.</p></li>
</ul>
</section>
<section id="fine-tuning-bi-encoders" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-bi-encoders">Fine-tuning Bi-Encoders</h3>
<ul>
<li><p><strong>Q:</strong> Should bi-encoders always be fine-tuned with labeled data or is it acceptable to use them off-the-shelf and rely on a re-ranker?</p></li>
<li><p><strong>A:</strong> Fine-tuning encoders (both bi- and cross-) with labeled data consistently improves results. If data and resources are available, fine-tuning is highly recommended. However, for MVPs with limited resources, leveraging pre-trained models with re-ranking is a viable option.</p></li>
</ul>
</section>
<section id="colbert-clarification-and-discussion" class="level3">
<h3 class="anchored" data-anchor-id="colbert-clarification-and-discussion">Colbert Clarification and Discussion</h3>
<ul>
<li><p><strong>Discussion:</strong> Clarifying the role of ColBERT in RAG pipelines.</p>
<ul>
<li><p><strong>ColBERT as a First-Stage Retriever:</strong> Ideally replaces the bi-encoder in new pipelines, not used as a re-ranker.</p></li>
<li><p><strong>ColBERT as a Re-Ranker:</strong> Can be used when pipeline changes are not feasible, but less optimal.</p></li>
<li><p><strong>ColBERT Overview:</strong> A bi-encoder variant where documents and queries are represented as bags of embeddings (one per token). This approach enhances out-of-domain performance due to its multi-vector representation, capturing more granular information.</p></li>
</ul></li>
</ul>
</section>
<section id="tools-for-fine-tuning-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="tools-for-fine-tuning-embeddings">Tools for Fine-tuning Embeddings</h3>
<ul>
<li><p><strong>Q:</strong> Recommendations for tools to fine-tune embeddings for retrieval.</p></li>
<li><p><strong>A:</strong> <a href="https://sbert.net/">Sentence Transformers</a>, particularly version 3.0, is highly recommended for its user-friendliness and comprehensive implementation of essential features.</p></li>
</ul>
</section>
<section id="fine-tuning-embeddings-workflow" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-embeddings-workflow">Fine-tuning Embeddings Workflow</h3>
<ul>
<li><p><strong>Q:</strong> Can you describe the workflow for fine-tuning an embedding model?</p></li>
<li><p><strong>A:</strong></p>
<ol type="1">
<li><strong>Gather Data:</strong> Obtain queries and their corresponding relevant and non-relevant documents.</li>
<li><strong>Define Loss Function:</strong> Use a suitable loss function like <a href="https://doordash.engineering/2021/09/08/using-twin-neural-networks-to-train-catalog-item-embeddings/">triplet loss</a>, which leverages positive and negative examples to guide the model.</li>
<li><strong>Consider Hard Negatives:</strong> Enhance training by retrieving hard negatives—documents similar to positive examples but irrelevant to the query.</li>
<li><strong>Data Analysis and Generation:</strong> Thoroughly analyze existing queries or generate synthetic ones using LLMs to augment training data.</li>
</ol></li>
</ul>
</section>
<section id="impact-of-long-context-windows-on-rag" class="level3">
<h3 class="anchored" data-anchor-id="impact-of-long-context-windows-on-rag">Impact of Long Context Windows on RAG</h3>
<ul>
<li><p><strong>Q:</strong> How do long context windows change the strategies and possibilities within RAG?</p></li>
<li><p><strong>A:</strong> Long context windows enable:</p>
<ul>
<li><p><strong>Longer Documents:</strong> Incorporating longer documents or concatenated chunks into the context.</p></li>
<li><p><strong>Reduced Retrieval Overhead:</strong> Relaxing the reliance on highly precise retrieval (e.g., Recall@3) as more documents can fit within the context window. This allows for faster, less resource-intensive retrieval methods.</p></li>
</ul></li>
</ul>
</section>
<section id="fine-tuning-encoder-tutorials" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-encoder-tutorials">Fine-tuning Encoder Tutorials</h3>
<ul>
<li><p><strong>Q:</strong> Recommendations for tutorials on fine-tuning encoders.</p></li>
<li><p><strong>A:</strong> The <a href="https://www.sbert.net/docs/sentence_transformer/training_overview.html">Sentence Transformers documentation</a> is a valuable resource but can be challenging for beginners.</p></li>
</ul>
</section>
<section id="go-to-embedding-models" class="level3">
<h3 class="anchored" data-anchor-id="go-to-embedding-models">Go-to Embedding Models</h3>
<ul>
<li><p><strong>Q:</strong> Go-to embedding models for different scenarios.</p></li>
<li><p><strong>A:</strong></p>
<ul>
<li><p><strong>Demos:</strong> <a href="https://cohere.com/">Cohere</a>’s embedding models due to their API accessibility, performance, and affordability.</p></li>
<li><p><strong>Production:</strong> Multi-vector models like ColBERT are preferred.</p></li>
</ul></li>
<li><p><strong>General Recommendations:</strong></p>
<ul>
<li><p><strong>Model Size:</strong> Stick to models with parameters between 100 million and 1 billion; larger LLMs as encoders often have unfavorable latency-performance trade-offs.</p></li>
<li><p><strong>Avoid Overly Large Models:</strong> Using excessively large LLMs for embedding can lead to diminishing returns in performance and increased latency.</p></li>
</ul></li>
</ul>
</section>
<section id="using-elasticsearch-for-rag" class="level3">
<h3 class="anchored" data-anchor-id="using-elasticsearch-for-rag">Using Elasticsearch for RAG</h3>
<ul>
<li><p><strong>Q:</strong> Can Elasticsearch, a widely used search engine, be integrated into RAG pipelines, especially for organizations already invested in it?</p></li>
<li><p><strong>A:</strong></p>
<ul>
<li><p><strong>Hybrid Approach:</strong> Use Elasticsearch’s BM25 capabilities for initial retrieval and integrate a separate re-ranking pipeline (potentially using a cross-encoder).</p></li>
<li><p><strong>Vector Database Integration:</strong> Leverage Elasticsearch’s vector database offerings to incorporate semantic search capabilities.</p></li>
</ul></li>
</ul>
</section>
<section id="bm25-score-in-re-ranking" class="level3">
<h3 class="anchored" data-anchor-id="bm25-score-in-re-ranking">BM25 Score in Re-ranking</h3>
<ul>
<li><p><strong>Q:</strong> Is it beneficial to incorporate BM25 similarity scores during the re-ranking stage?</p></li>
<li><p><strong>A:</strong> No, BM25 scores are primarily used for candidate retrieval and are not typically required by cross-encoders during re-ranking.</p></li>
</ul>
</section>
<section id="strategies-for-chunks-exceeding-context-window" class="level3">
<h3 class="anchored" data-anchor-id="strategies-for-chunks-exceeding-context-window">Strategies for Chunks Exceeding Context Window</h3>
<ul>
<li><p><strong>Q:</strong> Strategies for handling situations where document chunks exceed the context window size.</p></li>
<li><p><strong>A:</strong> Solutions depend on the specific constraints:</p>
<ul>
<li><p><strong>Latency Tolerance:</strong> User experience dictates acceptable processing time.</p></li>
<li><p><strong>Document Length and Diversity Requirements:</strong></p></li>
<li><p><strong>Precomputed Summaries:</strong> Maintain a separate database mapping documents to their summaries, generated offline. Retrieve relevant chunks and feed summaries into the context window to provide concise context.</p></li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-014/</guid>
  <pubDate>Fri, 02 Aug 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 13: When to Fine-Tune with Paige Bailey</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-013/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Google AI Landscape and Gemini</li>
<li>Understanding Context Windows</li>
<li>Fine-tuning vs.&nbsp;Prompting vs.&nbsp;Retrieval</li>
<li>Prompting Strategies and Examples</li>
<li>Retrieval Augmented Generation</li>
<li>Fine-tuning Considerations and Gemma</li>
</ul>
<section id="google-ai-landscape-and-gemini" class="level2">
<h2 class="anchored" data-anchor-id="google-ai-landscape-and-gemini">Google AI Landscape and Gemini</h2>
<ul>
<li><p><strong>Vertex AI:</strong></p>
<ul>
<li><strong><a href="https://cloud.google.com/vertex-ai?hl=en">Vertex AI</a>:</strong> Collection of APIs, compute infrastructure, model deployment tools available through Google Cloud, geared towards enterprise use. Comparable to Azure Open AI services.</li>
<li><strong><a href="https://ai.google.dev/">Gemini Developer API</a> (through <a href="https://ai.google.dev/aistudio">AI Studio</a>):</strong> Easier path for rapid prototyping and personal projects. Comparable to OpenAI APIs.</li>
</ul></li>
<li><p><strong>Gemini Flash Fine-Tuning:</strong></p>
<ul>
<li><strong><a href="https://deepmind.google/technologies/gemini/flash/">Gemini 1.5 Flash</a>:</strong> Google’s most performant, efficient, and cost-effective model, boasting a 1 million token context window (and growing).</li>
<li>Supports fine-tuning and is part of an early tester program.</li>
</ul></li>
<li><p><strong>Gemini Nano &amp; Gemma:</strong></p>
<ul>
<li><strong><a href="https://deepmind.google/technologies/gemini/nano/">Gemini Nano</a>:</strong> Brief mention of its planned integration into Chrome and Pixel/Android devices (details deferred).</li>
<li><strong><a href="https://ai.google.dev/gemma">Gemma</a>:</strong>
<ul>
<li>Open-source versions of Gemini, available on Hugging Face, Kaggle, and Ollama, making local experimentation easy.</li>
<li>Kaggle hosts checkpoints, code samples, and runnable notebooks.</li>
</ul></li>
</ul></li>
</ul>
<section id="generative-ai-and-google" class="level3">
<h3 class="anchored" data-anchor-id="generative-ai-and-google">Generative AI and Google</h3>
<ul>
<li>Google’s history in machine learning: TensorFlow, transformer models (BERT, AlphaFold, AlphaStar, AlphaGo, T5), and now Gemini.</li>
<li>Generative AI extends beyond text and code, mentioning:
<ul>
<li><strong><a href="https://deepmind.google/technologies/imagen-2/">Imagen 2</a>:</strong> Detailed image generation.</li>
<li><strong><a href="https://cloud.google.com/speech-to-text/v2/docs/chirp-model">Chirp</a>:</strong> Speech-to-text with multilingual capabilities and a small model footprint.</li>
</ul></li>
<li><strong>Gemini:</strong> Google’s flagship model (currently on version 1.5)</li>
</ul>
</section>
<section id="gemini-model-features" class="level3">
<h3 class="anchored" data-anchor-id="gemini-model-features">Gemini Model Features</h3>
<ul>
<li><strong>Multimodal Understanding:</strong> Processes images, audio, text, code, video, and more simultaneously.</li>
<li><strong>State-of-the-art Performance:</strong> Excels across various tasks, though reliant on academic benchmarks (discussed later).</li>
<li><strong>Embedded Reasoning:</strong> Strong capabilities in chain-of-thought and step-by-step reasoning.</li>
<li><strong>Scalable Deployment:</strong> Optimized for both large-scale (Google products) and small-scale (edge devices) use cases.</li>
<li><strong>Efficiency and Privacy:</strong> Focus on cost-effective token analysis, reduced inference compute, and on-device processing for privacy preservation.</li>
<li><strong>Model Options:</strong>
<ul>
<li><strong><a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/">Gemini 1.5 Pro</a>:</strong> High-performance, efficient model.</li>
<li><strong>Gemini Nano:</strong> Ultra-small model for edge deployments.</li>
<li><strong>Gemma:</strong> Open-sourced models (2B and 7B parameters)</li>
</ul></li>
<li>Key considerations for integration: user experience, performance, and cost trade-offs.</li>
<li><strong>Available Options:</strong>
<ul>
<li><strong>Gemini 1.5 Flash:</strong> Fast, 1 million token context window.</li>
<li><strong>Gemini 1.5 Pro:</strong> 2 million token context window</li>
</ul></li>
<li><strong>Gemini Flash for Code:</strong>
<ul>
<li>Performs well for code generation and structured outputs like JSON out-of-the-box.</li>
<li>Fine-tuning and using code examples in the context window further enhance results.</li>
<li>Applicable to code generation, translation, debugging, code review, etc.</li>
</ul></li>
</ul>
</section>
</section>
<section id="understanding-context-windows" class="level2">
<h2 class="anchored" data-anchor-id="understanding-context-windows">Understanding Context Windows</h2>
<ul>
<li><strong>Importance of Context Window Size:</strong>
<ul>
<li>Historically limited to 2,000-8,000 tokens, hindering model capability.</li>
<li>Current models: GPT-4 Turbo (128,000+), Claude (2,000), Gemini (2 million).</li>
</ul></li>
<li><strong>Impact of Larger Context Windows:</strong>
<ul>
<li>Can handle massive amounts of data (emails, texts, videos, codebases, research papers).</li>
<li>Reduces the need for fine-tuning, as more information can be provided at inference time.</li>
<li>Allows for more complex and nuanced outputs.</li>
</ul></li>
</ul>
</section>
<section id="fine-tuning-vs.-prompting-vs.-retrieval" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuning-vs.-prompting-vs.-retrieval">Fine-tuning vs.&nbsp;Prompting vs.&nbsp;Retrieval</h2>
<section id="common-questions-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="common-questions-trade-offs">Common Questions &amp; Trade-offs</h3>
<ul>
<li>Key decision points when working with large language models.</li>
<li><strong>Considerations:</strong>
<ul>
<li><strong>Prompt Design:</strong> Simple, cost-effective, but may require detailed prompts.</li>
<li><strong>Fine-Tuning:</strong>
<ul>
<li>Increasingly difficult to justify due to maintenance overhead and rapid release of new open-source models.</li>
<li>Recommended only when other options fail or for on-premise/local data requirements.</li>
</ul></li>
</ul></li>
<li><strong>Recommendations:</strong>
<ul>
<li><strong>Start with Closed-Source APIs:</strong> Rapid iteration, prove product-market fit, focus on UX.</li>
<li><strong>Hire ML Team When Necessary:</strong> If highly specialized fine-tuning becomes essential.</li>
</ul></li>
</ul>
</section>
<section id="model-evaluation-its-importance" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation-its-importance">Model Evaluation &amp; Its Importance</h3>
<ul>
<li><strong>Limitations of Academic Benchmarks:</strong>
<ul>
<li><strong>Example:</strong> <a href="https://huggingface.co/datasets/openai/openai_humaneval">HumanEval</a>
<ul>
<li>Often misinterpreted as involving human evaluation (it doesn’t).</li>
<li>Tests a narrow scope of Python function completion with simplistic tasks.</li>
<li>Not representative of real-world software engineering or other programming languages.</li>
</ul></li>
</ul></li>
<li><strong><a href="https://huggingface.co/datasets/THUDM/humaneval-x">HumanEval X</a>:</strong> Created to address some limitations of HumanEval, but still has limitations.</li>
<li><strong>Key Takeaways:</strong>
<ul>
<li>Carefully consider the relevance and limitations of evaluation metrics.</li>
<li>Prioritize custom evaluations tailored to your specific use case and business needs.</li>
</ul></li>
</ul>
</section>
</section>
<section id="prompting-strategies-and-examples" class="level2">
<h2 class="anchored" data-anchor-id="prompting-strategies-and-examples">Prompting Strategies and Examples</h2>
<section id="power-of-prompting-video-understanding" class="level3">
<h3 class="anchored" data-anchor-id="power-of-prompting-video-understanding">Power of Prompting &amp; Video Understanding</h3>
<ul>
<li><strong>Detailed Example:</strong>
<ul>
<li>Using Gemini in AI Studio to analyze a 44-minute video.</li>
<li>Asking the model to find a specific event (paper removed from a pocket), identify information on the paper, and provide the timestamp.</li>
<li>Demonstrates the ability to understand and extract information from lengthy video content, potentially revolutionizing video analysis workflows.</li>
</ul></li>
<li><strong>Implications:</strong>
<ul>
<li>Transforms how we interact with video content, making it searchable and analyzable at scale.</li>
<li>Also applicable to large text documents (PDFs with images, graphs, code) for summarization, analysis, and research.</li>
</ul></li>
<li><strong>Prefix Caching:</strong>
<ul>
<li>Optimizes API calls for repeated analysis of the same codebase or repository.</li>
<li>Improves latency and grounds responses within a consistent context.</li>
</ul></li>
</ul>
</section>
<section id="ai-studio-overview-examples" class="level3">
<h3 class="anchored" data-anchor-id="ai-studio-overview-examples">AI Studio Overview &amp; Examples</h3>
<ul>
<li><strong>Key Features:</strong>
<ul>
<li>Adjust stop sequences, top-k configurations, and temperature.</li>
<li>Toggle between Gemini models (Pro, Flash, etc.).</li>
<li>Access prompt gallery, cookbook, and getting started resources.</li>
<li>View past prompts and outputs.</li>
</ul></li>
<li><strong>Examples:</strong>
<ul>
<li>Scraping GitHub issues and Stack Overflow questions for analysis.</li>
<li>Converting COBOL code to Java with specific instructions and architecture preferences.</li>
</ul></li>
<li><strong>Key Takeaway:</strong> With detailed instructions, models can achieve impressive results, much like a skilled contractor team.</li>
</ul>
</section>
</section>
<section id="retrieval-augmented-generation" class="level2">
<h2 class="anchored" data-anchor-id="retrieval-augmented-generation">Retrieval Augmented Generation</h2>
<section id="retrieval-in-google-products" class="level3">
<h3 class="anchored" data-anchor-id="retrieval-in-google-products">Retrieval in Google Products</h3>
<ul>
<li><strong><a href="https://gemini.google.com/app">gemini.google.com</a> (formerly Bard):</strong>
<ul>
<li>Example: Querying for information about the San Francisco Ferry Building and requesting recommendations.</li>
<li>Results are grounded in Google Search, with an option to view source citations and confidence levels.</li>
</ul></li>
<li><strong>Personalized Retrieval:</strong> The concept can be extended to internal corporate data and codebases.</li>
</ul>
</section>
</section>
<section id="fine-tuning-considerations-and-gemma" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuning-considerations-and-gemma">Fine-tuning Considerations and Gemma</h2>
<ul>
<li><strong>Fine-Tuning:</strong>
<ul>
<li>Should be approached with caution and a clear understanding of the maintenance commitment.</li>
<li>Consider the rapid evolution of open-source models.</li>
</ul></li>
<li><strong>Gemma Family:</strong>
<ul>
<li>Solid starting point for open-source fine-tuning.</li>
<li>Available in 2B and 7B parameter sizes, with both instruction-tuned and non-instruction-tuned variants.</li>
<li><strong><a href="https://huggingface.co/blog/codegemma">CodeGemma</a>:</strong> For code-related tasks.</li>
<li><strong>RecurrentGemma:</strong> For sequential data.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2404.07839">RecurrentGemma: Moving Past Transformers for Efficient Open Language Models</a></li>
<li><strong>HuggingFace Hub:</strong> <a href="google/recurrentgemma-2b-it">google/recurrentgemma-2b-it</a></li>
</ul></li>
<li><strong>PaliGemma:</strong> Open-vision language model.
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2407.07726">PaliGemma: A versatile 3B VLM for transfer</a></li>
<li><strong>Blog Post:</strong> <a href="https://huggingface.co/blog/paligemma">PaliGemma – Google’s Cutting-Edge Open Vision Language Model</a></li>
</ul></li>
</ul></li>
<li><strong>Resources:</strong>
<ul>
<li><a href="https://cloud.google.com/model-garden?hl=en">Model Garden on Vertex AI</a></li>
<li><a href="https://huggingface.co/google">HuggingFace Hub</a></li>
</ul></li>
<li><strong>Deployment:</strong> Easy one-click deployment to Google Cloud.</li>
<li><strong>Model Builders:</strong> Provides automatic comparisons and prompt management.</li>
</ul>


</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-013/</guid>
  <pubDate>Thu, 25 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conference Talk 12: Slaying OOMs with PyTorch FSDP and torchao</title>
  <dc:creator>Christian Mills</dc:creator>
  <link>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/notes/mastering-llms-course-notes.html"><strong>Mastering LLMs Course Notes</strong></a>: My notes from the course <strong>Mastering LLMs: A Conference For Developers &amp; Data Scientists</strong> by <strong>Hamel Husain</strong> and <strong>Dan Becker</strong>.</li>
</ul>
</div>
</div>
<ul>
<li>Introduction</li>
<li>Understanding Model Memory</li>
<li>Optimizing Memory Usage</li>
<li>Model Parallelism with FSDP</li>
<li>Benchmarking FSDP2</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Presentation Resources">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Presentation Resources
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://drive.google.com/drive/u/0/folders/1HmGNC4v4L5nXhtdDMVCpUBrme1ELp-2C">Slaying OOMs</a></li>
</ul>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li>OOM errors are a common challenge when working with large PyTorch models.</li>
<li>Traditional solutions like reducing batch size or model size are limited in effectiveness.</li>
</ul>
</section>
<section id="understanding-model-memory" class="level2">
<h2 class="anchored" data-anchor-id="understanding-model-memory">Understanding Model Memory</h2>
<ul>
<li><strong>VRAM Constraint:</strong> Modern GPUs have limited VRAM (e.g., 24GB for 3090s and 4090s), leading to challenges when training large models.</li>
<li><strong>Model Memory Components:</strong>
<ul>
<li><strong>Parameters:</strong> Model weights, typically stored in FP16 (2 bytes per parameter). For a 7B parameter LLaMa model, this translates to 14GB.</li>
<li><strong>Gradients:</strong> Calculated during backpropagation, require the same storage size as parameters (another 14GB for LLaMa 7B).</li>
<li><strong>Optimizer State:</strong> Optimizers like Adam store additional information, often twice the size of parameters (28GB for LLaMa 7B).</li>
<li><strong>Activations:</strong> Intermediate outputs of model layers.
<ul>
<li>The size is harder to estimate and depends on factors like batch size and context length.</li>
<li>Activations tend to dominate memory usage at larger batch sizes and context lengths.</li>
</ul></li>
</ul></li>
<li><strong>Example:</strong> A full fine-tuning of a 7B parameter LLaMa model can easily exceed 56GB (14GB parameters + 14GB gradients + 28GB optimizer state), exceeding the VRAM capacity of most consumer GPUs.</li>
<li><strong>Forum Post:</strong> <a href="https://dev-discuss.pytorch.org/t/how-to-measure-memory-usage-from-your-model-without-running-it/2024/1">How to measure memory usage from your model without running it?</a></li>
</ul>
</section>
<section id="optimizing-memory-usage" class="level2">
<h2 class="anchored" data-anchor-id="optimizing-memory-usage">Optimizing Memory Usage</h2>
<section id="optimizer-memory" class="level3">
<h3 class="anchored" data-anchor-id="optimizer-memory">Optimizer Memory</h3>
<ul>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a></li>
<li>While alternative optimizers like SGD might seem appealing due to their lower memory overhead, Adam remains dominant in practice due to its effectiveness.</li>
<li>Replacing Adam is challenging and might not yield significant memory savings.</li>
</ul>
</section>
<section id="parameter-quantization" class="level3">
<h3 class="anchored" data-anchor-id="parameter-quantization">Parameter Quantization</h3>
<ul>
<li><p><strong>4-bit Quantization:</strong> Reduces the precision of model parameters from FP16 to INT4 (half a byte per parameter).</p></li>
<li><p>This technique can significantly reduce memory footprint, for example, bringing the size of a 7B parameter LLaMa model down from 14GB to 3.5GB.</p></li>
<li><p><strong>Torch Compile:</strong> This tool can be leveraged to create efficient quantization kernels directly from Python code, eliminating the need for custom CUDA kernels.</p>
<ul>
<li><p>Decorate <code>quantize_tensor</code> and <code>dequantize_tensor</code> functions with <code>@torch.compile()</code></p></li>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb1-2">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"TORCH_LOGS"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_code"</span></span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@torch.compile</span>()</span>
<span id="cb1-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> quantize_tensor(x_fp32):</span>
<span id="cb1-7">    absmax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(x_fp32))</span>
<span id="cb1-8">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">127.0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> absmax</span>
<span id="cb1-9">    x_int8 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x_fp32).to(torch.int8)</span>
<span id="cb1-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x_int8, c</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@torch.compile</span>()</span>
<span id="cb1-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> dequantize_tensor(x_int8, c):</span>
<span id="cb1-14">    x_fp32 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_int8.to(torch.float32) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> c</span>
<span id="cb1-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x_fp32</span>
<span id="cb1-16"></span>
<span id="cb1-17">x_int8, c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> quantize_tensor(torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>))</span>
<span id="cb1-18">x_fp32 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dequantize_tensor(x_int8, c)</span></code></pre></div>
</div>
</div></li>
<li><p><strong>Docs:</strong> <a href="https://pytorch.org/docs/stable/generated/torch.compile.html">https://pytorch.org/docs/stable/generated/torch.compile.html</a></p></li>
<li><p><strong>Tutorial:</strong> <a href="https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html">Introduction to <code>torch.compile</code></a></p></li>
</ul></li>
</ul>
</section>
<section id="gradient-optimization-with-lora" class="level3">
<h3 class="anchored" data-anchor-id="gradient-optimization-with-lora">Gradient Optimization with LoRA</h3>
<ul>
<li>Directly quantizing gradients to 4-bit negatively impacts convergence.</li>
<li><strong>Low-Rank Adaptation (LoRA):</strong> Circumvents this issue by training only a small subset of parameters (adapters) while keeping the majority frozen.</li>
<li><strong>QLoRA:</strong> This technique combines LoRA with parameter quantization to achieve significant memory savings without compromising accuracy.</li>
</ul>
</section>
<section id="challenges-and-solutions-with-qlora" class="level3">
<h3 class="anchored" data-anchor-id="challenges-and-solutions-with-qlora">Challenges and Solutions with QLoRA</h3>
<ul>
<li><p>QLoRA implementation can be complex, often requiring custom CUDA kernels (e.g., the original implementation by Tim Detmers consists of 4,000 lines of CUDA code).</p>
<ul>
<li>Weights aren’t in int4 but NF4 which is closer to a normal distribution</li>
<li>Can’t matrix multiply NF4 tensors
<ul>
<li>need to dequantize and matmul</li>
</ul></li>
<li>Can’t use the same max for everything otherwise you’re too sensitive to outliers</li>
<li>Quantization typically done in blocks with independent scales</li>
<li>QLoRA quantizes the scales (double quantization)</li>
</ul></li>
<li><p><strong>Simplified Implementation with Torch Compile:</strong> <a href="https://github.com/drisspg">Driss Guessous</a>, a PyTorch developer, implemented QLoRA in approximately 900 lines of Python code using Torch Compile.</p>
<ul>
<li><strong>Code:</strong> <a href="https://www.github.com/torchao/dtypes/nf4tensor.py">torchao/dtypes/nf4tensor.py</a></li>
</ul></li>
<li><p><strong>Tensor Subclasses:</strong> PyTorch’s tensor subclassing feature enables the creation of custom data types like NF4 (used in QLoRA), allowing for more efficient representation and manipulation of quantized tensors.</p>
<ul>
<li><div class="callout callout-style-default callout-note callout-titled" title="Example:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> F.linear(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>, weight.to(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>.dtype))</span></code></pre></div>
</div>
</div></li>
<li><p><strong>Docs:</strong> <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a></p></li>
<li><p><strong><a href="https://github.com/albanD/subclass_zoo/">subclass_zoo</a>:</strong> Contains a number of examples of Tensor subclasses in PyTorch</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="model-parallelism-with-fsdp" class="level2">
<h2 class="anchored" data-anchor-id="model-parallelism-with-fsdp">Model Parallelism with FSDP</h2>
<section id="data-parallism" class="level3">
<h3 class="anchored" data-anchor-id="data-parallism">Data Parallism</h3>
<ul>
<li><strong>Data parallelism:</strong> Split batches across multipls devices and keep a copy of the gradients, model params, and optimizer state on each device</li>
<li>Data parallelism alone, while helpful, might not be sufficient for extremely large models.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/images/oom-with-data-parallelism.png" class="img-fluid figure-img"></p>
<figcaption>OOM With Data Parallelism - Slaying OOMs: Slide 19</figcaption>
</figure>
</div>
</section>
<section id="fsdp" class="level3">
<h3 class="anchored" data-anchor-id="fsdp">FSDP</h3>
<ul>
<li><strong>Fully Sharded Data Parallel (FSDP):</strong> Distributes model parameters (and by consequence the gradients, and optimizer states) across multiple GPUs, allowing for training models that exceed the memory capacity of a single device.
<ul>
<li>Memory corresponding to the layer getting processed will be freed when the layer is done.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/images/fsdp-memory-step.png" class="img-fluid figure-img"></p>
<figcaption>FSDP Memory - Slaying OOMs: Slide 21</figcaption>
</figure>
</div>
<ul>
<li><p><strong>Sharding:</strong> Dividing model components into smaller chunks (shards) that can be placed on different GPUs.</p></li>
<li><p><strong>All Gather Operations:</strong> Used to gather necessary data from different GPUs during model training.</p></li>
<li><p><strong>Layers</strong>:</p>
<ul>
<li>Every PyTorch <code>nn</code> module is a tree of more <code>nn</code> modules.</li>
<li>The user’s wrapping policy determines what gets treated as its own “layer”.</li>
<li>What you decided to wrap influences memory usage
<ul>
<li>Smaller blobs = less memory needs to be all-gathered at a time.</li>
</ul></li>
</ul></li>
<li><p><strong>CPU Offloading:</strong></p>
<ul>
<li><p>Can keep parameters on the CPU and move them to the GPU when computing forward + backward.</p></li>
<li><p>The optimizer update will be done on CPU, so the optim state lives there too.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/images/fsdp-memory-step-cpu-offloading.png" class="img-fluid figure-img"></p>
<figcaption>FSDP CPU Offloading - Slaying OOMs: Slide 25</figcaption>
</figure>
</div></li>
</ul></li>
</ul>
</section>
<section id="fsdp1-vs.-fsdp2" class="level3">
<h3 class="anchored" data-anchor-id="fsdp1-vs.-fsdp2">FSDP1 vs.&nbsp;FSDP2</h3>
<ul>
<li><p><strong>Goal:</strong> Make all-gather efficient</p></li>
<li><p><strong>Constraint:</strong> <a href="https://developer.nvidia.com/nccl">NCCL</a> (NVIDIA Collective Communications Library) requires each GPU contribute same-size Tensors</p></li>
<li><p><strong>FSDP1:</strong></p>
<ul>
<li><p>Flattens and concatenates all tensors before sharding, potentially leading to type and metadata conflicts.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/images/flatparam-fsdp-1.png" class="img-fluid figure-img"></p>
<figcaption>FlatParam FSDP - Slaying OOMs: Slide 28</figcaption>
</figure>
</div>
<ul>
<li><code>t1</code> and the first part of <code>t2</code> get combined into a single tensor</li>
<li>The second part of <code>t2</code> gets combined with <code>t3</code> into a single tensor</li>
<li><code>t2</code> gets split between GPUs</li>
<li>Forces <code>t1</code>, <code>t2</code>, and <code>t3</code> to all have the same d-type and other metadata</li>
</ul></li>
<li><p>Can lead to non-deterministic memory spikes, making memory management challenging.</p></li>
</ul></li>
<li><p><strong>FSDP2 (Per-Parameter FSDP):</strong></p>
<ul>
<li><p>Introduces distributed tensors (D-tensors) that allow for sharding individual tensors, preserving their original data types and metadata.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/images/per-parameter-fsdp-2.png" class="img-fluid figure-img"></p>
<figcaption>Per-Parameter FSDP - Slaying OOMs: Slide 30</figcaption>
</figure>
</div></li>
<li><p>Offers better memory determinism, ensuring more predictable and manageable memory usage.</p></li>
<li><p>Enables more flexible and efficient training scenarios, especially when combined with techniques like QLoRA.</p></li>
<li><p>Requires extra copies during all-gather compared to FSDP1</p></li>
<li><p><strong>Forum Post:</strong> <a href="https://dev-discuss.pytorch.org/t/fsdp-cudacachingallocator-an-outsider-newb-perspective/1486/1">FSDP &amp; CUDACachingAllocator: an outsider newb perspective</a></p></li>
</ul></li>
</ul>
</section>
<section id="cpu-offloading" class="level3">
<h3 class="anchored" data-anchor-id="cpu-offloading">CPU Offloading</h3>
<ul>
<li>Leverages CPU memory to store parameters and optimizer states, further reducing the memory load on GPUs.</li>
<li>Offloads the optimizer step to the CPU, allowing GPUs to focus on computationally intensive forward and backward passes.</li>
</ul>
</section>
</section>
<section id="benchmarking-fsdp2" class="level2">
<h2 class="anchored" data-anchor-id="benchmarking-fsdp2">Benchmarking FSDP2</h2>
<section id="benchmarking-plan" class="level3">
<h3 class="anchored" data-anchor-id="benchmarking-plan">Benchmarking Plan</h3>
<ul>
<li><strong>Goal:</strong> Run benchmarks, identify performance gaps between FSDP2 and the baseline (FSDP1 &amp; bnb), and explore ways to improve FSDP2’s speed.</li>
<li><strong>Hardware:</strong> Two NVIDIA 3090 GPUs (consumer-grade, 24GB VRAM each) acquired from Vast AI.</li>
<li><strong>Baseline:</strong> Answer.ai’s train.py with FSDP1 and bnb, using a batch size of 8.</li>
</ul>
</section>
<section id="initial-benchmarking-and-discrepancies" class="level3">
<h3 class="anchored" data-anchor-id="initial-benchmarking-and-discrepancies">Initial Benchmarking and Discrepancies</h3>
<ul>
<li><p><strong>Benchmarking Environments:</strong></p>
<ul>
<li><p><a href="https://github.com/AnswerDotAI/fsdp_qLoRA/blob/main/train.py">Answer.ai’s train.py</a> (command-line configuration)</p>
<ul>
<li><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb3-1">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">python</span> train.py <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--model_name</span> meta-llama/Llama-2-7b-hf <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--batch_size</span> 8 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--context_length</span> 2048 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--train_type</span></span>
<span id="cb3-2">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">qLoRA</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--use_gradient_checkpointing</span> True <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--reentrant_checkpointing</span> True <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--dataset</span> dummy <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--dataset_samples</span></span>
<span id="cb3-3">  <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">48</span></span></code></pre></div></li>
</ul></li>
<li><p><a href="https://github.com/pytorch/torchtune/blob/1fa1f04baf124c074dcd93831fa38c8b657af1e9/recipes/configs/dev/llama2/7B_qLoRA_fsdp2.yaml">TorchTune recipe</a> (YAML configuration)</p></li>
</ul></li>
<li><p><strong>Initial Findings:</strong></p>
<ul>
<li><table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>batch size</th>
<th>peak memory</th>
<th>runtime for a step</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>train.py</td>
<td>8</td>
<td>12.88 GiB</td>
<td>14.0s</td>
</tr>
<tr class="even">
<td>torchtune</td>
<td>8</td>
<td>12.60 GiB</td>
<td>16.5s</td>
</tr>
</tbody>
</table></li>
<li><p>FSDP2 showed better peak memory usage.</p></li>
<li><p>FSDP2 was slower in runtime.</p></li>
</ul></li>
<li><p><strong>Tracing Analysis (Perfetto):</strong></p>
<ul>
<li><strong>Blog Posts:</strong>
<ul>
<li><a href="https://pytorch.org/blog/understanding-gpu-memory-1/">Understanding GPU Memory 1: Visualizing All Allocations over Time</a></li>
<li><a href="https://pytorch.org/blog/understanding-gpu-memory-2/">Understanding GPU Memory 2: Finding and Removing Reference Cycles</a></li>
</ul></li>
<li><strong>Traces:</strong>
<ul>
<li><strong>Google Drive:</strong> <a href="https://drive.google.com/file/d/1ObfUUySBwuaCSLMXRxFiM1w7XYMebxvB/view">answer.ai train.py</a></li>
<li><strong>Google Drive:</strong> <a href="https://drive.google.com/file/d/1BpdlZZ55746IHcifho2u2okJQ1ihr8dY/view">torchtune</a></li>
</ul></li>
<li><strong><a href="https://ui.perfetto.dev/">Perfetto</a>:</strong> A production-grade open-source stack for performance instrumentation and trace analysis</li>
<li><strong>Significant difference in the number of optimizer steps:</strong> The optimizer took much longer in FSDP2.</li>
<li><strong>Double the number of operations:</strong> Indicating FSDP2 might be training on more parameters than the baseline.</li>
</ul></li>
</ul>
</section>
<section id="identifying-the-root-causes" class="level3">
<h3 class="anchored" data-anchor-id="identifying-the-root-causes">Identifying the Root Causes</h3>
<ul>
<li><strong>Root Cause 1: Configuration Discrepancy</strong>
<ul>
<li>TorchTune recipe LoRA-fied to the output projection (adding two low rank adapters per layer), resulting in 64 additional parameters compared to train.py.</li>
</ul></li>
<li><strong>Root Cause 2: Tensor Subclass Dispatch Overhead</strong>
<ul>
<li>Distributed tensors (D-tensors) introduce overhead due to metadata unwrapping during kernel calls.</li>
<li>This overhead was amplified by the increased number of parameters, making the optimizer step significantly slower in FSDP2.</li>
</ul></li>
</ul>
</section>
<section id="addressing-the-discrepancies-and-further-benchmarking" class="level3">
<h3 class="anchored" data-anchor-id="addressing-the-discrepancies-and-further-benchmarking">Addressing the Discrepancies and Further Benchmarking</h3>
<ul>
<li><strong>Ensuring Apples-to-Apples Comparison:</strong>
<ul>
<li>Standardized the dataset, parameter count, and wrapping policy across benchmarks.</li>
</ul></li>
<li><strong>Results After Standardization:</strong>
<ul>
<li>Still slower runtime for FSDP2.</li>
<li>Significantly improved peak memory usage.</li>
</ul></li>
<li><strong>Further Analysis:</strong>
<ul>
<li>Focused on forward pass, backward pass, and optimizer as the main culprits for the remaining performance gap.</li>
</ul></li>
</ul>
</section>
<section id="deep-dive-into-performance-gaps" class="level3">
<h3 class="anchored" data-anchor-id="deep-dive-into-performance-gaps">Deep Dive into Performance Gaps</h3>
<ul>
<li><strong>Gap 1: Optimizer Step Slowdown</strong>
<ul>
<li><strong>Problem:</strong> D-tensor overhead resulted in a 3x slower optimizer step.</li>
<li><strong>Solution:</strong> Collaborated with Intel to develop a fused Adam optimizer kernel for single dispatch and vectorization, leading to an 8x speedup.</li>
</ul></li>
<li><strong>Gap 2: Larger All Gather Operations</strong>
<ul>
<li><strong>Problem 1:</strong> FSDP2 packed more data (scalars and quantization factors) into the all gather operation, unlike the baseline.</li>
<li><strong>Problem 2:</strong> Output projection wasn’t quantized in FSDP2 when opting out of LoRA, leading to a 4x larger size compared to the baseline.</li>
<li><strong>Solution:</strong>
<ul>
<li>Problem 1 is expected behavior.</li>
<li>Problem 2 will be addressed by TorchTune in future releases.</li>
</ul></li>
</ul></li>
<li><strong>Gap 3: Overhead from Dequantization</strong>
<ul>
<li><strong>Problem:</strong> FSDP2’s dequantization process from NF4 to BF16 for CUDA kernels was less efficient than the specialized implementation used in the baseline.</li>
<li><strong>Solution:</strong> Explore using Torch Compile, custom Torch kernels, or Triton kernels for faster dequantization.</li>
</ul></li>
<li><strong>Gap 4: Different Rope Algorithms</strong>
<ul>
<li><strong>Problem:</strong> TorchTune and the baseline employed different Rope algorithms, leading to different operations before the SDPA.</li>
<li><strong>Solution:</strong> TorchTune to offer a wider selection of Rope algorithms.</li>
</ul></li>
<li><strong>Gap 5: Overlapping Communication and Computation</strong>
<ul>
<li><strong>Problem:</strong> FSDP2’s stricter memory management exposed inefficiencies in overlapping CPU offloading with computation. The computation tasks were much smaller than the communication tasks, leading to idle time.</li>
<li><strong>Solution:</strong> Adjusted the wrapping policy to group layers differently, enabling better overlap and reducing idle time. This solution is only feasible with FSDP2 due to its ability to handle mixed precision within a layer.</li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>notes</category>
  <category>llms</category>
  <guid>https://christianjmills.com/posts/mastering-llms-course-notes/conference-talk-012/</guid>
  <pubDate>Wed, 24 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://christianjmills.com/images/empty.gif" medium="image" type="image/gif"/>
</item>
</channel>
</rss>
