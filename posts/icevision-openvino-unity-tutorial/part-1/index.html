<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Christian Mills">
<meta name="dcterms.date" content="2022-08-08">
<meta name="description" content="Train a YOLOX model using IceVision and export it to OpenVINO.">

<title>Christian Mills - A Step-by-Step Guide to Object Detection in Unity with IceVision and OpenVINO Pt. 1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Christian Mills - A Step-by-Step Guide to Object Detection in Unity with IceVision and OpenVINO Pt. 1">
<meta property="og:description" content="Train a YOLOX model using IceVision and export it to OpenVINO.">
<meta property="og:image" content="christianjmills.com/posts/icevision-openvino-unity-tutorial/social-media/cover.jpg">
<meta property="og:site-name" content="Christian Mills">
<meta name="twitter:title" content="Christian Mills - A Step-by-Step Guide to Object Detection in Unity with IceVision and OpenVINO Pt. 1">
<meta name="twitter:description" content="Train a YOLOX model using IceVision and export it to OpenVINO.">
<meta name="twitter:image" content="christianjmills.com/posts/icevision-openvino-unity-tutorial/social-media/cover.jpg">
<meta name="twitter:creator" content="@cdotjdotmills">
<meta name="twitter:site" content="@cdotjdotmills">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Christian Mills</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/tutorials/index.html" rel="" target="">
 <span class="menu-text">Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/notes/index.html" rel="" target="">
 <span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../services.html" rel="" target="">
 <span class="menu-text">Services</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:christian@christianjmills.com" rel="" target=""><i class="bi bi-envelope-fill" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cj-mills" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/cdotjdotmills" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../blog.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tutorial-links" id="toc-tutorial-links" class="nav-link active" data-scroll-target="#tutorial-links">Tutorial Links</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#setup-conda-environment" id="toc-setup-conda-environment" class="nav-link" data-scroll-target="#setup-conda-environment">Setup Conda Environment</a></li>
  <li><a href="#import-dependencies" id="toc-import-dependencies" class="nav-link" data-scroll-target="#import-dependencies">Import Dependencies</a></li>
  <li><a href="#configure-kaggle-api" id="toc-configure-kaggle-api" class="nav-link" data-scroll-target="#configure-kaggle-api">Configure Kaggle API</a></li>
  <li><a href="#download-the-dataset" id="toc-download-the-dataset" class="nav-link" data-scroll-target="#download-the-dataset">Download the Dataset</a></li>
  <li><a href="#inspect-the-dataset" id="toc-inspect-the-dataset" class="nav-link" data-scroll-target="#inspect-the-dataset">Inspect the Dataset</a></li>
  <li><a href="#create-dataset-parser" id="toc-create-dataset-parser" class="nav-link" data-scroll-target="#create-dataset-parser">Create Dataset Parser</a></li>
  <li><a href="#define-dataloader-objects" id="toc-define-dataloader-objects" class="nav-link" data-scroll-target="#define-dataloader-objects">Define DataLoader Objects</a></li>
  <li><a href="#finetune-the-model" id="toc-finetune-the-model" class="nav-link" data-scroll-target="#finetune-the-model">Finetune the Model</a></li>
  <li><a href="#prepare-model-for-export" id="toc-prepare-model-for-export" class="nav-link" data-scroll-target="#prepare-model-for-export">Prepare Model for Export</a></li>
  <li><a href="#export-the-model" id="toc-export-the-model" class="nav-link" data-scroll-target="#export-the-model">Export the Model</a></li>
  <li><a href="#verify-openvino-inference" id="toc-verify-openvino-inference" class="nav-link" data-scroll-target="#verify-openvino-inference">Verify OpenVINO Inference</a></li>
  <li><a href="#define-post-processing-steps" id="toc-define-post-processing-steps" class="nav-link" data-scroll-target="#define-post-processing-steps">Define Post-processing Steps</a></li>
  <li><a href="#generate-colormap" id="toc-generate-colormap" class="nav-link" data-scroll-target="#generate-colormap">Generate Colormap</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">A Step-by-Step Guide to Object Detection in Unity with IceVision and OpenVINO Pt. 1</h1>
  <div class="quarto-categories">
    <div class="quarto-category">icevision</div>
    <div class="quarto-category">openvino</div>
    <div class="quarto-category">yolox</div>
    <div class="quarto-category">object-detection</div>
    <div class="quarto-category">unity</div>
    <div class="quarto-category">tutorial</div>
  </div>
  </div>

<div>
  <div class="description">
    Train a <a href="https://arxiv.org/abs/2107.08430">YOLOX</a> model using <a href="https://airctic.com/0.12.0/">IceVision</a> and export it to <a href="https://docs.openvino.ai/latest/index.html">OpenVINO</a>.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Christian Mills </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 8, 2022</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#overview">Overview</a></li>
<li><a href="#setup-conda-environment">Setup Conda Environment</a></li>
<li><a href="#import-dependencies">Import Dependencies</a></li>
<li><a href="#configure-kaggle-api">Configure Kaggle API</a></li>
<li><a href="#download-the-dataset">Download the Dataset</a></li>
<li><a href="#inspect-the-dataset">Inspect the Dataset</a></li>
<li><a href="#create-dataset-parser">Create Dataset Parser</a></li>
<li><a href="#define-dataloader-objects">Define DataLoader Objects</a></li>
<li><a href="#finetune-the-model">Finetune the Model</a></li>
<li><a href="#prepare-model-for-export">Prepare Model for Export</a></li>
<li><a href="#export-the-model">Export the Model</a></li>
<li><a href="#verify-openvino-inference">Verify OpenVINO Inference</a></li>
<li><a href="#define-post-processing-steps">Define Post-processing Steps</a></li>
<li><a href="#generate-colormap">Generate Colormap</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ARCHIVED
</div>
</div>
<div class="callout-body-container callout-body">
<p>This tutorial will no longer receive updates as the IceVision library no longer appears in development. For the latest and improved version of this tutorial that uses PyTorch directly, please visit the new tutorial linked below:</p>
<ul>
<li><a href="../../../series/tutorials/pytorch-train-object-detector-yolox-series.html">Training YOLOX Models for Real-Time Object Detection in Pytorch</a></li>
</ul>
</div>
</div>
<section id="tutorial-links" class="level2">
<h2 class="anchored" data-anchor-id="tutorial-links">Tutorial Links</h2>
<ul>
<li><a href="../part-1/">Part 1</a>: Train a YOLOX model using IceVision and export it to OpenVINO.</li>
<li><a href="../part-2/">Part 2</a>: Create a dynamic link library (DLL) file in Visual Studio to perform object detection with a YOLOX model using OpenVINO.</li>
<li><a href="../part-3/">Part 3</a>: Perform object detection in a Unity project with OpenVINO.</li>
<li><a href="https://github.com/cj-mills/icevision-openvino-unity-tutorial">GitHub Repository</a></li>
</ul>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In this three-part tutorial series, we will explore how to use <a href="https://airctic.com/0.11.0/">IceVision</a> and <a href="https://docs.openvino.ai/latest/">OpenVINO</a> to perform end-to-end object detection in <a href="https://unity.com/">Unity</a>. In part 1, we will train a <a href="https://github.com/Megvii-BaseDetection/YOLOX">YOLOX</a> model using IceVision and export it to OpenVINO. In part 2, we will create a dynamic link library (<a href="https://docs.microsoft.com/en-us/troubleshoot/windows-client/deployment/dynamic-link-library">DLL</a>) file in Visual Studio to perform object detection with a YOLOX model using OpenVINO. Finally, in part 3, we will integrate the trained model into a Unity project to perform real-time object detection. By the end of this series, you will have a working object detection system that you can use in your Unity projects.</p>
<p><strong>Unity Demo</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><video src="./videos/HaGRID-demo-1.mp4" class="img-fluid" controls=""><a href="./videos/HaGRID-demo-1.mp4">Video</a></video></p>
</figure>
</div>
<p>The tutorial uses a downscaled subsample of the <a href="https://github.com/hukenovs/hagrid">HaGRID</a> (HAnd Gesture Recognition Image Dataset), which contains annotated sample images for 18 distinct hand gestures and an additional <code>no_gesture</code> class to account for idle hands.</p>
<div>
<details>
<summary>
<strong>Reference Images</strong>
</summary>
<br>
<div style="overflow-x:auto; overflow-y: auto; max-height:500px">

<table>
<thead>
<tr>
<th>
Class
</th>
<th>
Image
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
call
</td>
<td>
<img alt="call" src="./images/call.jpg">
</td>
</tr>
<tr>
<td>
dislike
</td>
<td>
<img alt="dislike" src="./images/dislike.jpg">
</td>
</tr>
<tr>
<td>
fist
</td>
<td>
<img alt=" fist" src="./images/fist.jpg">
</td>
</tr>
<tr>
<td>
four
</td>
<td>
<img alt="four" src="./images/four.jpg">
</td>
</tr>
<tr>
<td>
like
</td>
<td>
<img alt=" like" src="./images/like.jpg">
</td>
</tr>
<tr>
<td>
mute
</td>
<td>
<img alt=" mute" src="./images/mute.jpg">
</td>
</tr>
<tr>
<td>
ok
</td>
<td>
<img alt=" ok" src="./images/ok.jpg">
</td>
</tr>
<tr>
<td>
one
</td>
<td>
<img alt=" one" src="./images/one.jpg">
</td>
</tr>
<tr>
<td>
palm
</td>
<td>
<img alt=" palm" src="./images/palm.jpg">
</td>
</tr>
<tr>
<td>
peace
</td>
<td>
<img alt="peace" src="./images/peace.jpg">
</td>
</tr>
<tr>
<td>
peace_inverted
</td>
<td>
<img alt="peace_inverted" src="./images/peace_inverted.jpg">
</td>
</tr>
<tr>
<td>
rock
</td>
<td>
<img alt="rock" src="./images/rock.jpg">
</td>
</tr>
<tr>
<td>
stop
</td>
<td>
<img alt="stop" src="./images/stop.jpg">
</td>
</tr>
<tr>
<td>
stop_inverted
</td>
<td>
<img alt="stop_inverted" src="./images/stop_inverted.jpg">
</td>
</tr>
<tr>
<td>
three
</td>
<td>
<img alt="three" src="./images/three.jpg">
</td>
</tr>
<tr>
<td>
three2
</td>
<td>
<img alt="three2" src="./images/three2.jpg">
</td>
</tr>
<tr>
<td>
two_up
</td>
<td>
<img alt=" two_up" src="./images/two_up.jpg">
</td>
</tr>
<tr>
<td>
two_up_inverted
</td>
<td>
<img alt="two_up_inverted" src="./images/two_up_inverted.jpg">
</td>
</tr>
</tbody>

</table>
</div>
</details>
</div>
<p>One could use a model trained on this dataset to allow users to control a Unity application using hand gestures.</p>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>In part 1 of this tutorial series, we will learn how to train a YOLOX Tiny model using IceVision and export it to OpenVINO’s Intermediate Representation (<a href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_IR_and_opsets.html">IR</a>) format. We will start by setting up a <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/concepts/environments.html">Conda environment</a> and importing the necessary dependencies. Then, we will configure the <a href="https://github.com/Kaggle/kaggle-api">Kaggle API</a> to download the dataset we will use to train our model. After inspecting the dataset, we will create a parser to process the training samples and define DataLoader objects. Then, we will fine-tune the model and export it. Finally, we will perform inference with the exported model and define post-processing steps for the model output. We will then generate a colormap to visualize model predictions. By the end of this post, you will have a trained YOLOX model that you can deploy in your applications.</p>
<p>You can find links to view the training code and run it on <a href="https://colab.research.google.com/?utm_source=scs-index">Google Colab</a> and <a href="https://www.kaggle.com/docs/notebooks">Kaggle</a> below.</p>
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook</th>
<th>Colab</th>
<th>Kaggle</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/cj-mills/icevision-openvino-unity-tutorial/blob/main/notebooks/Icevision-YOLOX-to-OpenVINO-Tutorial-HaGRID.ipynb">GitHub Repository</a></td>
<td><a href="https://colab.research.google.com/github/cj-mills/icevision-openvino-unity-tutorial/blob/main/notebooks/Icevision-YOLOX-to-OpenVINO-Tutorial-HaGRID-Colab.ipynb">Open In Colab</a></td>
<td><a href="https://kaggle.com/kernels/welcome?src=https://github.com/cj-mills/icevision-openvino-unity-tutorial/blob/main/notebooks/Icevision-YOLOX-to-OpenVINO-Tutorial-HaGRID-Kaggle.ipynb">Open in Kaggle</a></td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p><strong>Note:</strong> The free GPU tier for Google Colab takes approximately 11 minutes per epoch, while the free GPU tier for Kaggle Notebooks takes around 15 minutes per epoch.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Update <code>May 17, 2023</code>:</strong> Google Colab and Kaggle Notebooks now use an updated Python version that conflicts with this tutorial’s package versions. Please create a local conda environment to run the tutorial code.</p>
</blockquote>
</section>
<section id="setup-conda-environment" class="level2">
<h2 class="anchored" data-anchor-id="setup-conda-environment">Setup Conda Environment</h2>
<p>The IceVision library builds upon specific versions of libraries like <a href="https://docs.fast.ai/">fastai</a> and <a href="https://mmdetection.readthedocs.io/en/latest/">mmdetection</a>, and the cumulative dependency requirements mean it is best to use a dedicated <a href="https://docs.python.org/3/tutorial/venv.html">virtual environment</a>. Below are the steps to create a virtual environment using <a href="https://docs.conda.io/en/latest/">Conda</a>. Be sure to execute each command in the provided order.</p>
<blockquote class="blockquote">
<p><strong>Important:</strong> IceVision currently only supports Linux/macOS. Try using <a href="https://docs.microsoft.com/en-us/windows/wsl/install">WSL</a> (Windows Subsystem for Linux) if training locally on Windows.</p>
</blockquote>
<p><strong>Install CUDA Toolkit</strong></p>
<p>You might need to install the CUDA Toolkit on your system if you plan to run the training code locally. CUDA requires an Nvidia GPU. Version 11.1.0 of the toolkit is available at the link below. Both Google Colab and Kaggle Notebooks already have CUDA installed.</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-11.1.0-download-archive">CUDA Toolkit 11.1.0</a></li>
<li><a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA Toolkit Archive</a></li>
</ul>
<p><strong>Conda environment setup steps</strong></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new conda environment</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> create <span class="at">--name</span> icevision python==3.8</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># activate the environment</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate icevision</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># install PyTorch and torchvision</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install torch==1.10.0+cu111 torchvision==0.11.1+cu111 <span class="at">-f</span> https://download.pytorch.org/whl/torch_stable.html</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># install mmcv-full</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install mmcv-full==1.3.17 <span class="at">-f</span> https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># install mmdet</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install mmdet==2.17.0</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># install icevision</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install icevision==0.11.0</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># install icedata</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install icedata==0.5.1</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># install setuptools</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install setuptools==59.5.0</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># install OpenVINO developer tools</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install openvino-dev</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># install package for generating visually distinct colours</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install distinctipy</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># install jupyter</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install jupyter</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># install onnxruntime</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install onnxruntime</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># install onnx-simplifier</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install onnx-simplifier</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># install the kaggle api</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install kaggle</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <a href="https://pypi.org/project/mmdet/"><code>mmdet</code></a> package contains the pretrained YOLOX Tiny model we will finetune with IceVision. The package depends on the <a href="https://mmcv.readthedocs.io/en/latest/"><code>mmcv-full</code></a> library, which is picky about the CUDA version used by <a href="https://pytorch.org/">PyTorch</a>. We need to install the PyTorch version with the exact CUDA version expected by <code>mmcv-full</code>.</p>
<p>The <a href="https://pypi.org/project/icevision/"><code>icevision</code></a> package provides the functionality for data curation, data transforms, and training loops we’ll use to train the model. The <a href="https://airctic.github.io/icedata/"><code>icedata</code></a> package provides the functionality we’ll use to create a custom parser to read the dataset.</p>
<p>The <a href="https://pypi.org/project/openvino-dev/"><code>openvino-dev</code></a> pip package contains the model-conversion script to convert trained models from <a href="https://onnx.ai/">ONNX</a> to OpenVINO’s IR format.</p>
<p>We’ll use the <a href="https://pypi.org/project/distinctipy/"><code>distinctipy</code></a> pip package to generate a visually distinct colormap for drawing bounding boxes on images.</p>
<p>The ONNX models generated by PyTorch are not always the most concise. We can use the <a href="https://pypi.org/project/onnx-simplifier/">onnx-simplifier</a> package to tidy up the exported model. This step is entirely optional.</p>
<p><strong>Original ONNX model (<a href="https://netron.app/">Netron</a>)</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/onnx-model.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Simplified ONNX model (<a href="https://netron.app/">Netron</a>)</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/onnx-model-simplified.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Colab and Kaggle Setup Requirements</strong></p>
<p>When running the training code on Google Colab and Kaggle Notebooks, we need to uninstall several packages before installing IceVision and its dependencies to avoid conflicts. The platform-specific setup steps are at the top of the notebooks linked above.</p>
</section>
<section id="import-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="import-dependencies">Import Dependencies</h2>
<p>We will start by importing the IceVision library and configuring Pandas. When you import the IceVision library for the first time, it will automatically download some additional resources that it needs to function correctly.</p>
<p><strong>Import IceVision library</strong></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import all the necessary modules from the icevision package</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> icevision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Import and configure Pandas</strong></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the pandas package</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the max column width to None</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'max_colwidth'</span>, <span class="va">None</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the max number of rows and columns to None</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_rows'</span>, <span class="va">None</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="configure-kaggle-api" class="level2">
<h2 class="anchored" data-anchor-id="configure-kaggle-api">Configure Kaggle API</h2>
<p>The Kaggle API tool requires an API Key for a Kaggle account. Sign in or create a Kaggle account using the link below, then click the <code>Create New API Token</code> button.</p>
<ul>
<li><strong>Kaggle Account Settings:</strong> <a href="https://www.kaggle.com/me/account">https://www.kaggle.com/me/account</a></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/kaggle-create-new-api-token.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Enter Kaggle username and API token</strong></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>creds <span class="op">=</span> <span class="st">'{"username":"","key":""}'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Save Kaggle credentials if none are present</strong></p>
<ul>
<li><strong>Source:</strong> <a href="https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb">https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb</a></li>
</ul>
<hr>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the path to the kaggle.json file</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>cred_path <span class="op">=</span> Path(<span class="st">'~/.kaggle/kaggle.json'</span>).expanduser()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if the file already exists</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> cred_path.exists():</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the directory if it does not exist</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    cred_path.parent.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save the API key to the file</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    cred_path.write_text(creds)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set the file permissions to be readable and writable by the current user</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    cred_path.chmod(<span class="bn">0o600</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Import Kaggle API</strong></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the API module from the kaggle package</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> kaggle <span class="im">import</span> api</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="download-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="download-the-dataset">Download the Dataset</h2>
<p>Now that we have our Kaggle credentials set, we need to define the dataset and where to store it. I made two versions of the dataset available on Kaggle. One contains approximately thirty thousand training samples, and the other has over one hundred and twenty thousand.</p>
<ul>
<li><a href="https://www.kaggle.com/datasets/innominate817/hagrid-sample-30k-384p">HaGRID Sample 30k 384p</a></li>
<li><a href="https://www.kaggle.com/datasets/innominate817/hagrid-sample-120k-384p">HaGRID Sample 120k 384p</a></li>
</ul>
<p>We’ll use the default archive and data folders for the fastai library (installed with IceVision) to store the compressed and uncompressed datasets.</p>
<p><strong>Define path to dataset</strong></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the URLs object from the fastai.data.external module</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.data.external <span class="im">import</span> URLs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the name of the dataset</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>dataset_name <span class="op">=</span> <span class="st">'hagrid-sample-30k-384p'</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># dataset_name = 'hagrid-sample-120k-384p'</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct the Kaggle dataset name by combining the username and dataset name</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>kaggle_dataset <span class="op">=</span> <span class="ss">f'innominate817/</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the path to the directory where datasets are stored</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>archive_dir <span class="op">=</span> URLs.path()</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the path to the data directory</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>dataset_dir <span class="op">=</span> archive_dir<span class="op">/</span><span class="st">'../data'</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>archive_path <span class="op">=</span> Path(<span class="ss">f'</span><span class="sc">{</span>archive_dir<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">.zip'</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>dataset_path <span class="op">=</span> Path(<span class="ss">f'</span><span class="sc">{</span>dataset_dir<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define method to extract the dataset from an archive file</strong></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> file_extract(fname, dest<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Extract the specified file to the destination directory using `tarfile` or `zipfile`.</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co">        fname (str): The path to the file to be extracted.</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">        dest (str): The path to the directory where the file will be extracted. If not specified, the file will be extracted to the same directory as the source file.</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co">        None</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Raises:</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co">        Exception: If the file has an unrecognized file extension.</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set the destination directory to the parent directory of the file if not specified</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dest <span class="kw">is</span> <span class="va">None</span>: dest <span class="op">=</span> Path(fname).parent</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the file path to a string</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    fname <span class="op">=</span> <span class="bu">str</span>(fname)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check the file extension and extract the file using the appropriate module</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> fname.endswith(<span class="st">'gz'</span>):</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        tarfile.<span class="bu">open</span>(fname, <span class="st">'r:gz'</span>).extractall(dest)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> fname.endswith(<span class="st">'zip'</span>):</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        zipfile.ZipFile(fname).extractall(dest)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">Exception</span>(<span class="ss">f'Unrecognized archive: </span><span class="sc">{</span>fname<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The archive file for the 30K dataset is 4GB, so we don’t want to download it more than necessary.</p>
<p><strong>Download the dataset if it is not present</strong></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if the dataset zip file already exists</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> archive_path.exists():</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Download the dataset from Kaggle</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    api.dataset_download_cli(kaggle_dataset, path<span class="op">=</span>archive_dir)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract the dataset zip file to the data directory</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    file_extract(fname<span class="op">=</span>archive_path, dest<span class="op">=</span>dataset_dir)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="inspect-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="inspect-the-dataset">Inspect the Dataset</h2>
<p>We can start inspecting the dataset once it finishes downloading. In this step, we will get the file paths for the images and annotations and examine one of the training images. That will give us a better understanding of the dataset and its structure.</p>
<p><strong>Define paths to image and annotation folders</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list of the items in the 'dataset_path' directory</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>dir_content <span class="op">=</span> <span class="bu">list</span>(dataset_path.ls())</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the path of the 'ann_train_val' directory</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>annotation_dir <span class="op">=</span> dataset_path<span class="op">/</span><span class="st">'ann_train_val'</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the 'ann_train_val' directory from the list of items</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>dir_content.remove(annotation_dir)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the path of the remaining directory, which is assumed to be the image directory</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>img_dir <span class="op">=</span> dir_content[<span class="dv">0</span>]</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the paths of the annotation and image directories</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>annotation_dir, img_dir</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>(Path('/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val'),
 Path('/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/hagrid_30k'))</code></pre>
<p>The bounding box annotations for each image are stored in JSON files organized by object class. The files contain annotations for all 552,992 images from the full HaGRID dataset.</p>
<p><strong>Inspect the annotation folder</strong></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a list of files in the 'annotation_dir' directory</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>file_list <span class="op">=</span> <span class="bu">list</span>(annotation_dir.ls())</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the names of the files using a Pandas DataFrame</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame([<span class="bu">file</span>.name <span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> file_list])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
call.json
</td>
</tr>
<tr>
<th>
1
</th>
<td>
dislike.json
</td>
</tr>
<tr>
<th>
2
</th>
<td>
fist.json
</td>
</tr>
<tr>
<th>
3
</th>
<td>
four.json
</td>
</tr>
<tr>
<th>
4
</th>
<td>
like.json
</td>
</tr>
<tr>
<th>
5
</th>
<td>
mute.json
</td>
</tr>
<tr>
<th>
6
</th>
<td>
ok.json
</td>
</tr>
<tr>
<th>
7
</th>
<td>
one.json
</td>
</tr>
<tr>
<th>
8
</th>
<td>
palm.json
</td>
</tr>
<tr>
<th>
9
</th>
<td>
peace.json
</td>
</tr>
<tr>
<th>
10
</th>
<td>
peace_inverted.json
</td>
</tr>
<tr>
<th>
11
</th>
<td>
rock.json
</td>
</tr>
<tr>
<th>
12
</th>
<td>
stop.json
</td>
</tr>
<tr>
<th>
13
</th>
<td>
stop_inverted.json
</td>
</tr>
<tr>
<th>
14
</th>
<td>
three.json
</td>
</tr>
<tr>
<th>
15
</th>
<td>
three2.json
</td>
</tr>
<tr>
<th>
16
</th>
<td>
two_up.json
</td>
</tr>
<tr>
<th>
17
</th>
<td>
two_up_inverted.json
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p>The sample images are stored in folders separated by object class.</p>
<p><strong>Inspect the image folder</strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a list of folders in the 'img_dir' directory</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>folder_list <span class="op">=</span> <span class="bu">list</span>(img_dir.ls())</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the names of the folders using a Pandas DataFrame</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame([folder.name <span class="cf">for</span> folder <span class="kw">in</span> folder_list])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
train_val_call
</td>
</tr>
<tr>
<th>
1
</th>
<td>
train_val_dislike
</td>
</tr>
<tr>
<th>
2
</th>
<td>
train_val_fist
</td>
</tr>
<tr>
<th>
3
</th>
<td>
train_val_four
</td>
</tr>
<tr>
<th>
4
</th>
<td>
train_val_like
</td>
</tr>
<tr>
<th>
5
</th>
<td>
train_val_mute
</td>
</tr>
<tr>
<th>
6
</th>
<td>
train_val_ok
</td>
</tr>
<tr>
<th>
7
</th>
<td>
train_val_one
</td>
</tr>
<tr>
<th>
8
</th>
<td>
train_val_palm
</td>
</tr>
<tr>
<th>
9
</th>
<td>
train_val_peace
</td>
</tr>
<tr>
<th>
10
</th>
<td>
train_val_peace_inverted
</td>
</tr>
<tr>
<th>
11
</th>
<td>
train_val_rock
</td>
</tr>
<tr>
<th>
12
</th>
<td>
train_val_stop
</td>
</tr>
<tr>
<th>
13
</th>
<td>
train_val_stop_inverted
</td>
</tr>
<tr>
<th>
14
</th>
<td>
train_val_three
</td>
</tr>
<tr>
<th>
15
</th>
<td>
train_val_three2
</td>
</tr>
<tr>
<th>
16
</th>
<td>
train_val_two_up
</td>
</tr>
<tr>
<th>
17
</th>
<td>
train_val_two_up_inverted
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p><strong>Get image file paths</strong></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a list of image files in the 'img_dir' directory</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>files <span class="op">=</span> get_image_files(img_dir)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the number of image files in the list</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(files)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>31833</code></pre>
<p><strong>Inspect files</strong></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the first and last file in the 'files' list</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>file1, file2 <span class="op">=</span> files[<span class="dv">0</span>], files[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first and last files using a Pandas DataFrame</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame([file1, file2])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/hagrid_30k/train_val_call/00005c9c-3548-4a8f-9d0b-2dd4aff37fc9.jpg
</td>
</tr>
<tr>
<th>
1
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/hagrid_30k/train_val_two_up_inverted/fff4d2f6-9890-4225-8d9c-73a02ba8f9ac.jpg
</td>
</tr>
</tbody>

</table>
</div>
<p>The sample images are all downscaled to 384p.</p>
<p><strong>Inspect one of the training images</strong></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the PIL library</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Open the first file in the 'files' list as a RGB image</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> PIL.Image.<span class="bu">open</span>(files[<span class="dv">0</span>]).convert(<span class="st">'RGB'</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the dimensions of the image</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Image Dims: </span><span class="sc">{</span>img<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the image</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Image Dims: (512, 384)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_28_1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>To make it easier to work with the dataset, we will create a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image efficiently.</p>
<p><strong>Create a dictionary that maps image names to file paths</strong></p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dictionary where the keys are the filenames without the file extensions of the files in the 'files' list,</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and the values are the file paths</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>img_dict <span class="op">=</span> {<span class="bu">file</span>.stem : <span class="bu">file</span> <span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> files}</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(img_dict, orient<span class="op">=</span><span class="st">'index'</span>).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
00005c9c-3548-4a8f-9d0b-2dd4aff37fc9
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/hagrid_30k/train_val_call/00005c9c-3548-4a8f-9d0b-2dd4aff37fc9.jpg
</td>
</tr>
<tr>
<th>
0020a3db-82d8-47aa-8642-2715d4744db5
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/hagrid_30k/train_val_call/0020a3db-82d8-47aa-8642-2715d4744db5.jpg
</td>
</tr>
<tr>
<th>
004ac93f-0f7c-49a4-aadc-737e0ad4273c
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/hagrid_30k/train_val_call/004ac93f-0f7c-49a4-aadc-737e0ad4273c.jpg
</td>
</tr>
<tr>
<th>
006cac69-d3f0-47f9-aac9-38702d038ef1
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/hagrid_30k/train_val_call/006cac69-d3f0-47f9-aac9-38702d038ef1.jpg
</td>
</tr>
<tr>
<th>
00973fac-440e-4a56-b60c-2a06d5fb155d
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/hagrid_30k/train_val_call/00973fac-440e-4a56-b60c-2a06d5fb155d.jpg
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p><strong>Get list of annotation file paths</strong></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the 'os' and 'glob' modules</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> glob <span class="im">import</span> glob</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a list of paths to JSON files in the 'annotation_dir' directory</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>annotation_paths <span class="op">=</span> glob(os.path.join(annotation_dir, <span class="st">"*.json"</span>))</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the JSON file paths using a Pandas DataFrame</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(annotation_paths)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/call.json
</td>
</tr>
<tr>
<th>
1
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/palm.json
</td>
</tr>
<tr>
<th>
2
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/rock.json
</td>
</tr>
<tr>
<th>
3
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/stop_inverted.json
</td>
</tr>
<tr>
<th>
4
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/two_up.json
</td>
</tr>
<tr>
<th>
5
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/four.json
</td>
</tr>
<tr>
<th>
6
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/three.json
</td>
</tr>
<tr>
<th>
7
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/stop.json
</td>
</tr>
<tr>
<th>
8
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/one.json
</td>
</tr>
<tr>
<th>
9
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/three2.json
</td>
</tr>
<tr>
<th>
10
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/peace_inverted.json
</td>
</tr>
<tr>
<th>
11
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/ok.json
</td>
</tr>
<tr>
<th>
12
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/like.json
</td>
</tr>
<tr>
<th>
13
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/fist.json
</td>
</tr>
<tr>
<th>
14
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/mute.json
</td>
</tr>
<tr>
<th>
15
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/peace.json
</td>
</tr>
<tr>
<th>
16
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/two_up_inverted.json
</td>
</tr>
<tr>
<th>
17
</th>
<td>
/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/ann_train_val/dislike.json
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p>After getting the list of annotation file paths, we will create an annotation DataFrame that contains all of the annotation data for the dataset. This DataFrame will allow us to manipulate and query the annotations more easily. We’ll then filter out annotations for images not present in the current subsample.</p>
<p><strong>Create annotations dataframe</strong></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a generator that yields Pandas DataFrames containing the data from each JSON file</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>cls_dataframes <span class="op">=</span> (pd.read_json(f).transpose() <span class="cf">for</span> f <span class="kw">in</span> annotation_paths)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Concatenate the DataFrames into a single DataFrame</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>annotation_df <span class="op">=</span> pd.concat(cls_dataframes, ignore_index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep only the rows that correspond to the filenames in the 'img_dict' dictionary</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>annotation_df <span class="op">=</span> annotation_df.loc[<span class="bu">list</span>(img_dict.keys())]</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the first 5 rows of the DataFrame</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>annotation_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
bboxes
</th>
<th>
labels
</th>
<th>
leading_hand
</th>
<th>
leading_conf
</th>
<th>
user_id
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
00005c9c-3548-4a8f-9d0b-2dd4aff37fc9
</th>
<td>
[[0.23925175, 0.28595301, 0.25055143, 0.20777627]]
</td>
<td>
[call]
</td>
<td>
right
</td>
<td>
1
</td>
<td>
5a389ffe1bed6660a59f4586c7d8fe2770785e5bf79b09334aa951f6f119c024
</td>
</tr>
<tr>
<th>
0020a3db-82d8-47aa-8642-2715d4744db5
</th>
<td>
[[0.5801012999999999, 0.53265105, 0.14562138, 0.12286348]]
</td>
<td>
[call]
</td>
<td>
left
</td>
<td>
1
</td>
<td>
0d6da2c87ef8eabeda2dcfee2dc5b5035e878137a91b149c754a59804f3dce32
</td>
</tr>
<tr>
<th>
004ac93f-0f7c-49a4-aadc-737e0ad4273c
</th>
<td>
[[0.46294793, 0.26419774, 0.13834939000000002, 0.10784189]]
</td>
<td>
[call]
</td>
<td>
right
</td>
<td>
1
</td>
<td>
d50f05d9d6ca9771938cec766c3d621ff863612f9665b0e4d991c086ec04acc9
</td>
</tr>
<tr>
<th>
006cac69-d3f0-47f9-aac9-38702d038ef1
</th>
<td>
[[0.38799208, 0.44643898, 0.27068787, 0.18277858]]
</td>
<td>
[call]
</td>
<td>
right
</td>
<td>
1
</td>
<td>
998f6ad69140b3a59cb9823ba680cce62bf2ba678058c2fc497dbbb8b22b29fe
</td>
</tr>
<tr>
<th>
00973fac-440e-4a56-b60c-2a06d5fb155d
</th>
<td>
[[0.40980118, 0.38144198, 0.08338464, 0.06229785], [0.6122035100000001, 0.6780825500000001, 0.04700606, 0.07640522]]
</td>
<td>
[call, no_gesture]
</td>
<td>
right
</td>
<td>
1
</td>
<td>
4bb3ee1748be58e05bd1193939735e57bb3c0ca59a7ee38901744d6b9e94632e
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p>Notice that one of the samples contains a <code>no_gesture</code> label to identify an idle hand in the image.</p>
<p>We can retrieve the annotation data for a specific image file using its name.</p>
<p><strong>Inspect annotation data for sample image</strong></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the filename without the file extension of the first file in the 'files' list</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>file_id <span class="op">=</span> files[<span class="dv">0</span>].stem</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the filename</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>file_id</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'00005c9c-3548-4a8f-9d0b-2dd4aff37fc9'</code></pre>
<p>The image file names are the index values for the annotation DataFrame.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>annotation_df.loc[file_id].to_frame()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
00005c9c-3548-4a8f-9d0b-2dd4aff37fc9
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
bboxes
</th>
<td>
[[0.23925175, 0.28595301, 0.25055143, 0.20777627]]
</td>
</tr>
<tr>
<th>
labels
</th>
<td>
[call]
</td>
</tr>
<tr>
<th>
leading_hand
</th>
<td>
right
</td>
</tr>
<tr>
<th>
leading_conf
</th>
<td>
1
</td>
</tr>
<tr>
<th>
user_id
</th>
<td>
5a389ffe1bed6660a59f4586c7d8fe2770785e5bf79b09334aa951f6f119c024
</td>
</tr>
</tbody>

</table>
</div>
<p>The <code>bboxes</code> entry contains the <code>[top-left-X-position, top-left-Y-position, width, height]</code> information for any bounding boxes. The values are scaled based on the image dimensions. We multiply <code>top-left-X-position</code> and <code>width</code> values by the image width and multiply <code>top-left-Y-position</code> and <code>height</code> values by the image height to obtain the actual values.</p>
<p>We need a font file to annotate the images with class labels. We can download one from <a href="https://fonts.google.com/">Google Fonts</a>.</p>
<p><strong>Download font file</strong></p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the filename of the font file</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>font_file <span class="op">=</span> <span class="st">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># If the font file does not exist, download it</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(font_file): </span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">!</span>wget https:<span class="op">//</span>fonts.gstatic.com<span class="op">/</span>s<span class="op">/</span>roboto<span class="op">/</span>v30<span class="op">/</span>$font_file</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Annotate sample image</strong></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the ImageDraw class from the PIL package</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> ImageDraw</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the width and height of the image</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>width, height <span class="op">=</span> img.size</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a copy of the image</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>annotated_img <span class="op">=</span> img.copy()</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an ImageDraw object for drawing on the image</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>draw <span class="op">=</span> ImageDraw.Draw(annotated_img)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the font size</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>fnt_size <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>annotation <span class="op">=</span> annotation_df.loc[file_id]</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through the bounding boxes and labels in the 'annotation' DataFrame</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(annotation[<span class="st">'labels'</span>])):</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the bounding box coordinates</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>    x, y, w, h <span class="op">=</span> annotation[<span class="st">'bboxes'</span>][i]</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Scale the coordinates to the size of the image</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>    x <span class="op">*=</span> width</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>    y <span class="op">*=</span> height</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>    w <span class="op">*=</span> width</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>    h <span class="op">*=</span> height</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a tuple of coordinates for the bounding box</span></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>    shape <span class="op">=</span> (x, y, x<span class="op">+</span>w, y<span class="op">+</span>h)</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw the bounding box on the image</span></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>    draw.rectangle(shape, outline<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the font file</span></span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>    fnt <span class="op">=</span> PIL.ImageFont.truetype(font_file, fnt_size)</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw the label on the image</span></span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>    draw.multiline_text((x, y<span class="op">-</span>fnt_size<span class="op">-</span><span class="dv">5</span>), <span class="ss">f"</span><span class="sc">{</span>annotation[<span class="st">'labels'</span>][i]<span class="sc">}</span><span class="ss">"</span>, font<span class="op">=</span>fnt, fill<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the dimensions of the image</span></span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(annotated_img.size) </span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the image</span></span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a>annotated_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>(384, 512)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_43_1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>We need to provide IceVision with a class map that maps index values to unique class names.</p>
<p><strong>Create a class map</strong></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a list of unique labels in the 'annotation_df' DataFrame</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> annotation_df[<span class="st">'labels'</span>].explode().unique().tolist()</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display labels using a Pandas DataFrame</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
call
</td>
</tr>
<tr>
<th>
1
</th>
<td>
no_gesture
</td>
</tr>
<tr>
<th>
2
</th>
<td>
dislike
</td>
</tr>
<tr>
<th>
3
</th>
<td>
fist
</td>
</tr>
<tr>
<th>
4
</th>
<td>
four
</td>
</tr>
<tr>
<th>
5
</th>
<td>
like
</td>
</tr>
<tr>
<th>
6
</th>
<td>
mute
</td>
</tr>
<tr>
<th>
7
</th>
<td>
ok
</td>
</tr>
<tr>
<th>
8
</th>
<td>
one
</td>
</tr>
<tr>
<th>
9
</th>
<td>
palm
</td>
</tr>
<tr>
<th>
10
</th>
<td>
peace
</td>
</tr>
<tr>
<th>
11
</th>
<td>
peace_inverted
</td>
</tr>
<tr>
<th>
12
</th>
<td>
rock
</td>
</tr>
<tr>
<th>
13
</th>
<td>
stop
</td>
</tr>
<tr>
<th>
14
</th>
<td>
stop_inverted
</td>
</tr>
<tr>
<th>
15
</th>
<td>
three
</td>
</tr>
<tr>
<th>
16
</th>
<td>
three2
</td>
</tr>
<tr>
<th>
17
</th>
<td>
two_up
</td>
</tr>
<tr>
<th>
18
</th>
<td>
two_up_inverted
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p>IceVision adds an additional <code>background</code> class at index <code>0</code>.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a ClassMap object using the list of labels</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>class_map <span class="op">=</span> ClassMap(labels)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the ClassMap object</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>class_map</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>&lt;ClassMap: {'background': 0, 'call': 1, 'no_gesture': 2, 'dislike': 3, 'fist': 4, 'four': 5, 'like': 6, 'mute': 7, 'ok': 8, 'one': 9, 'palm': 10, 'peace': 11, 'peace_inverted': 12, 'rock': 13, 'stop': 14, 'stop_inverted': 15, 'three': 16, 'three2': 17, 'two_up': 18, 'two_up_inverted': 19}&gt;</code></pre>
<blockquote class="blockquote">
<p><strong>Note:</strong> The <code>background</code> class is not included in the final model.</p>
</blockquote>
</section>
<section id="create-dataset-parser" class="level2">
<h2 class="anchored" data-anchor-id="create-dataset-parser">Create Dataset Parser</h2>
<p>To create a custom dataset parser for object detection, we can use the template for an object detection record and the template for an object detection parser.</p>
<p><strong>View template for an object detection record</strong></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an ObjectDetectionRecord object</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>template_record <span class="op">=</span> ObjectDetectionRecord()</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the ObjectDetectionRecord object</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>template_record</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>BaseRecord

common: 
    - Image size None
    - Record ID: None
    - Filepath: None
    - Img: None
detection: 
    - Class Map: None
    - Labels: []
    - BBoxes: []</code></pre>
<p><strong>View template for an object detection parser</strong></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a template parser for an object detection dataset using the ObjectDetectionRecord object</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>Parser.generate_template(template_record)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>class MyParser(Parser):
    def __init__(self, template_record):
        super().__init__(template_record=template_record)
    def __iter__(self) -&gt; Any:
    def __len__(self) -&gt; int:
    def record_id(self, o: Any) -&gt; Hashable:
    def parse_fields(self, o: Any, record: BaseRecord, is_new: bool):
        record.set_img_size(&lt;ImgSize&gt;)
        record.set_filepath(&lt;Union[str, Path]&gt;)
        record.detection.set_class_map(&lt;ClassMap&gt;)
        record.detection.add_labels(&lt;Sequence[Hashable]&gt;)
        record.detection.add_bboxes(&lt;Sequence[BBox]&gt;)</code></pre>
<p>As mentioned earlier, we need the dimensions for an image to scale the corresponding bounding box information. The dataset contains images with different resolutions, so we need to check for each image.</p>
<p><strong>Define custom parser class</strong></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a subclass of the 'Parser' class</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> HagridParser(Parser):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the constructor</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, template_record, annotations_df, img_dict, class_map):</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Call the parent class constructor</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(template_record<span class="op">=</span>template_record)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store the 'img_dict' and 'annotations_df' objects as instance variables</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_dict <span class="op">=</span> img_dict</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> annotations_df</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store the 'class_map' object as an instance variable</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.class_map <span class="op">=</span> class_map</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the '__iter__' method</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>) <span class="op">-&gt;</span> Any:</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Yield the rows of the 'annotations_df' DataFrame</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> o <span class="kw">in</span> <span class="va">self</span>.df.itertuples(): <span class="cf">yield</span> o</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the '__len__' method</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">int</span>: </span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return the number of rows in the 'annotations_df' DataFrame</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.df)</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the 'record_id' method</span></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> record_id(<span class="va">self</span>, o: Any) <span class="op">-&gt;</span> Hashable:</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return the index of the row</span></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> o.Index</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the 'parse_fields' method</span></span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> parse_fields(<span class="va">self</span>, o: Any, record: BaseRecord, is_new: <span class="bu">bool</span>):</span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the file path for the corresponding image</span></span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a>        filepath <span class="op">=</span> <span class="va">self</span>.img_dict[o.Index]</span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(filepath)</span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Open the image and get its width and height</span></span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a>        width, height <span class="op">=</span> PIL.Image.<span class="bu">open</span>(filepath).convert(<span class="st">'RGB'</span>).size</span>
<span id="cb38-38"><a href="#cb38-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-39"><a href="#cb38-39" aria-hidden="true" tabindex="-1"></a>         <span class="co"># Set the size of the image in the 'record' object</span></span>
<span id="cb38-40"><a href="#cb38-40" aria-hidden="true" tabindex="-1"></a>        record.set_img_size(ImgSize(width<span class="op">=</span>width, height<span class="op">=</span>height))</span>
<span id="cb38-41"><a href="#cb38-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-42"><a href="#cb38-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set the file path of the image in the 'record' object</span></span>
<span id="cb38-43"><a href="#cb38-43" aria-hidden="true" tabindex="-1"></a>        record.set_filepath(filepath)</span>
<span id="cb38-44"><a href="#cb38-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-45"><a href="#cb38-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set the 'class_map' in the 'record' object</span></span>
<span id="cb38-46"><a href="#cb38-46" aria-hidden="true" tabindex="-1"></a>        record.detection.set_class_map(<span class="va">self</span>.class_map)</span>
<span id="cb38-47"><a href="#cb38-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-48"><a href="#cb38-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the labels to the 'record' object</span></span>
<span id="cb38-49"><a href="#cb38-49" aria-hidden="true" tabindex="-1"></a>        record.detection.add_labels(o.labels)</span>
<span id="cb38-50"><a href="#cb38-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-51"><a href="#cb38-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create an empty list for the bounding boxes</span></span>
<span id="cb38-52"><a href="#cb38-52" aria-hidden="true" tabindex="-1"></a>        bbox_list <span class="op">=</span> []</span>
<span id="cb38-53"><a href="#cb38-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-54"><a href="#cb38-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Loop through the labels</span></span>
<span id="cb38-55"><a href="#cb38-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, label <span class="kw">in</span> <span class="bu">enumerate</span>(o.labels):</span>
<span id="cb38-56"><a href="#cb38-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get the bounding box coordinates</span></span>
<span id="cb38-57"><a href="#cb38-57" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> o.bboxes[i][<span class="dv">0</span>]<span class="op">*</span>width</span>
<span id="cb38-58"><a href="#cb38-58" aria-hidden="true" tabindex="-1"></a>            y <span class="op">=</span> o.bboxes[i][<span class="dv">1</span>]<span class="op">*</span>height</span>
<span id="cb38-59"><a href="#cb38-59" aria-hidden="true" tabindex="-1"></a>            w <span class="op">=</span> o.bboxes[i][<span class="dv">2</span>]<span class="op">*</span>width</span>
<span id="cb38-60"><a href="#cb38-60" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> o.bboxes[i][<span class="dv">3</span>]<span class="op">*</span>height</span>
<span id="cb38-61"><a href="#cb38-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create a BBox object and add it to the 'bbox_list'</span></span>
<span id="cb38-62"><a href="#cb38-62" aria-hidden="true" tabindex="-1"></a>            bbox_list.append(BBox.from_xywh(x, y, w, h))</span>
<span id="cb38-63"><a href="#cb38-63" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the bounding boxes to the 'record' object</span></span>
<span id="cb38-64"><a href="#cb38-64" aria-hidden="true" tabindex="-1"></a>        record.detection.add_bboxes(bbox_list)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can then create a parser object using the custom parser class.</p>
<p><strong>Create a custom parser object</strong></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a HagridParser object</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>parser <span class="op">=</span> HagridParser(template_record, annotation_df, img_dict, class_map)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the number of rows in the 'annotation_df' DataFrame</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>num_rows <span class="op">=</span> <span class="bu">len</span>(parser)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the number of rows</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(num_rows)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>31833</code></pre>
<p>We use the parser object to parse annotations and create records.</p>
<p><strong>Parse annotations to create records</strong></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 'RandomSplitter' object</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>data_splitter <span class="op">=</span> RandomSplitter([<span class="fl">0.8</span>, <span class="fl">0.2</span>])</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the 'parse' method to split the data into training and validation sets</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>train_records, valid_records <span class="op">=</span> parser.parse(data_splitter, cache_filepath<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">-cache.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finally, we can inspect the training records to ensure the parser works correctly.</p>
<p><strong>Inspect training records</strong></p>
<div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the first element of the 'train_records'</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_records[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>BaseRecord

common: 
    - Filepath: /mnt/980SSD_1TB_2/Datasets/hagrid-sample-30k-384p/hagrid_30k/train_val_one/2507aacb-43d2-4114-91f1-008e3c7a181c.jpg
    - Img: None
    - Record ID: 2507aacb-43d2-4114-91f1-008e3c7a181c
    - Image size ImgSize(width=640, height=853)
detection: 
    - BBoxes: [&lt;BBox (xmin:153.0572608, ymin:197.40873228, xmax:213.5684992, ymax:320.45228481000004)&gt;, &lt;BBox (xmin:474.20276479999995, ymin:563.67557885, xmax:520.8937472, ymax:657.61167499)&gt;]
    - Class Map: &lt;ClassMap: {'background': 0, 'call': 1, 'no_gesture': 2, 'dislike': 3, 'fist': 4, 'four': 5, 'like': 6, 'mute': 7, 'ok': 8, 'one': 9, 'palm': 10, 'peace': 11, 'peace_inverted': 12, 'rock': 13, 'stop': 14, 'stop_inverted': 15, 'three': 16, 'three2': 17, 'two_up': 18, 'two_up_inverted': 19}&gt;
    - Labels: [9, 2]</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the 'show_record' function to display the first element of the 'train_records' object with annotations</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>show_record(train_records[<span class="dv">0</span>], figsize <span class="op">=</span> (<span class="dv">10</span>,<span class="dv">10</span>), display_label<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_59_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the 'show_records' function to display the second, third, and fourth elements of the 'train_records' list  with annotations</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>show_records(train_records[<span class="dv">1</span>:<span class="dv">4</span>], ncols<span class="op">=</span><span class="dv">3</span>,display_label<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_60_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="define-dataloader-objects" class="level2">
<h2 class="anchored" data-anchor-id="define-dataloader-objects">Define DataLoader Objects</h2>
<p>The YOLOX model examines an input image using the stride values <code>[8, 16, 32]</code> to detect objects of various sizes.</p>
<p>The max number of detections depends on the input resolution and these stride values. Given a <code>384x512</code> image, the model will make <code>(384/8)*(512/8) + (384/16)*(512/16) + (384/32)*(512/32) = 4032</code> predictions. Although, many of those predictions get filtered out during post-processing.</p>
<p>Here, we can see the difference in results when using a single stride value in isolation with a YOLOX model trained on the <a href="https://cocodataset.org/#home">COCO</a> dataset.</p>
<p><strong>Stride 8</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/stride_8_demo.jpg" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Stride 16</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/stride_16_demo.jpg" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Stride 32</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/stride_32_demo.jpg" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Define stride values</strong></p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a list of 'strides'</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>strides <span class="op">=</span> [<span class="dv">8</span>, <span class="dv">16</span>, <span class="dv">32</span>]</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the maximum value in the 'strides' list</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>max_stride <span class="op">=</span> <span class="bu">max</span>(strides)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We need to set the input height and width to multiples of the highest stride value (i.e., 32).</p>
<p><strong>Select a multiple of the max stride value as the input resolution</strong></p>
<div class="sourceCode" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show a list of input resolutions by multiplying the maximum stride by numbers in the range 7-20</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>[max_stride<span class="op">*</span>i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">7</span>,<span class="dv">21</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[224, 256, 288, 320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640] </code></pre>
<p><strong>Define input resolution</strong></p>
<div class="sourceCode" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the size of the image</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>image_size <span class="op">=</span> <span class="dv">384</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the presize of the image</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>presize <span class="op">=</span> <span class="dv">512</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p><strong>Note:</strong> You can lower the image_size to reduce training time at the cost of a potential decrease in accuracy.</p>
</blockquote>
<p>IceVision provides several default methods for data augmentation to help the model generalize. It automatically updates the bounding box information for an image based on the applied augmentations.</p>
<p><strong>Define Transforms</strong></p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the default augmentations included with the 'aug_tfms' function using a Pandas DataFrame</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(tfms.A.aug_tfms(size<span class="op">=</span>image_size, presize<span class="op">=</span>presize))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
SmallestMaxSize(always_apply=False, p=1, max_size=512, interpolation=1)
</td>
</tr>
<tr>
<th>
1
</th>
<td>
HorizontalFlip(always_apply=False, p=0.5)
</td>
</tr>
<tr>
<th>
2
</th>
<td>
ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-15, 15), interpolation=1, border_mode=4, value=None, mask_value=None)
</td>
</tr>
<tr>
<th>
3
</th>
<td>
RGBShift(always_apply=False, p=0.5, r_shift_limit=(-10, 10), g_shift_limit=(-10, 10), b_shift_limit=(-10, 10))
</td>
</tr>
<tr>
<th>
4
</th>
<td>
RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True)
</td>
</tr>
<tr>
<th>
5
</th>
<td>
Blur(always_apply=False, p=0.5, blur_limit=(1, 3))
</td>
</tr>
<tr>
<th>
6
</th>
<td>
OneOrOther([RandomSizedBBoxSafeCrop(always_apply=False, p=0.5, height=384, width=384, erosion_rate=0.0, interpolation=1),LongestMaxSize(always_apply=False, p=1, max_size=384, interpolation=1),], p=0.5)
</td>
</tr>
<tr>
<th>
7
</th>
<td>
PadIfNeeded(always_apply=False, p=1.0, min_height=384, min_width=384, pad_height_divisor=None, pad_width_divisor=None, border_mode=0, value=[124, 116, 104], mask_value=None)
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<div class="sourceCode" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the transforms included with the 'resize_and_pad' function using a Pandas DataFrame</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(tfms.A.resize_and_pad(size<span class="op">=</span>image_size))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
LongestMaxSize(always_apply=False, p=1, max_size=384, interpolation=1)
</td>
</tr>
<tr>
<th>
1
</th>
<td>
PadIfNeeded(always_apply=False, p=1.0, min_height=384, min_width=384, pad_height_divisor=None, pad_width_divisor=None, border_mode=0, value=[124, 116, 104], mask_value=None)
</td>
</tr>
</tbody>

</table>
</div>
<div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the 'train_tfms' adapter using the 'Adapter' method and the 'aug_tfms' function</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>train_tfms <span class="op">=</span> tfms.A.Adapter([<span class="op">*</span>tfms.A.aug_tfms(size<span class="op">=</span>image_size, presize<span class="op">=</span>presize), tfms.A.Normalize()])</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the 'valid_tfms' adapter using the 'Adapter' method and the 'resize_and_pad' function</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>valid_tfms <span class="op">=</span> tfms.A.Adapter([<span class="op">*</span>tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can extract the normalization stats from the <code>tfms.A.Normalize()</code> method for future use. We’ll use these same stats when performing inference with the trained model.</p>
<p><strong>Get normalization stats</strong></p>
<div class="sourceCode" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the mean of the Normalize() transformation</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> tfms.A.Normalize().mean</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the standard deviation of the Normalize() transformation</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> tfms.A.Normalize().std</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the mean and standard deviation</span></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>mean, std</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))</code></pre>
<p>Next, we create dataset objects for the training and validation datasets using the defined transforms and normalization stats.</p>
<p><strong>Define Datasets</strong></p>
<div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Dataset object using the 'train_records' and 'train_tfms' variables</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> Dataset(train_records, train_tfms)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Dataset object using the 'valid_records' and 'valid_tfms' variables</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>valid_ds <span class="op">=</span> Dataset(valid_records, valid_tfms)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the 'train_ds' and 'valid_ds' objects</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>train_ds, valid_ds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>(&lt;Dataset with 25466 items&gt;, &lt;Dataset with 6367 items&gt;)</code></pre>
<p>We can apply the image augmentations to a sample training image to demonstrate the effects of data augmentation.</p>
<p><strong>Apply augmentations to a training sample</strong></p>
<div class="sourceCode" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list of three samples from the 'train_ds' dataset object</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> [train_ds[<span class="dv">0</span>] <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>)]</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the samples using the 'show_samples' function</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>show_samples(samples, ncols<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_76_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Once the datasets are defined, we can specify YOLOX as the model type for training.</p>
<p><strong>Define model type</strong></p>
<div class="sourceCode" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the model type to YOLOX</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>model_type <span class="op">=</span> models.mmdet.yolox</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We’ll use a model pretrained on the COCO dataset rather than train a new model from scratch.</p>
<p><strong>Define backbone</strong></p>
<div class="sourceCode" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a YOLOX Tiny backbone for the model</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>backbone <span class="op">=</span> model_type.backbones.yolox_tiny_8x8(pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the backbone information using a Pandas Dataframe</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame.from_dict(backbone.__dict__, orient<span class="op">=</span><span class="st">'index'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
model_name
</th>
<td>
yolox
</td>
</tr>
<tr>
<th>
config_path
</th>
<td>
/home/innom-dt/.icevision/mmdetection_configs/mmdetection_configs-2.16.0/configs/yolox/yolox_tiny_8x8_300e_coco.py
</td>
</tr>
<tr>
<th>
weights_url
</th>
<td>
https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_tiny_8x8_300e_coco/yolox_tiny_8x8_300e_coco_20210806_234250-4ff3b67e.pth
</td>
</tr>
<tr>
<th>
pretrained
</th>
<td>
True
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Define batch size</strong></p>
<div class="sourceCode" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the batch size</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>bs <span class="op">=</span> <span class="dv">32</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p><strong>Note:</strong> Adjust the batch size based on the available GPU memory.</p>
</blockquote>
<p><strong>Define DataLoaders</strong></p>
<div class="sourceCode" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataLoader for the training set</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>train_dl <span class="op">=</span> model_type.train_dl(train_ds, batch_size<span class="op">=</span>bs, num_workers<span class="op">=</span><span class="dv">2</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataLoader for the validation set</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>valid_dl <span class="op">=</span> model_type.valid_dl(valid_ds, batch_size<span class="op">=</span>bs, num_workers<span class="op">=</span><span class="dv">2</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p><strong>Note:</strong> Be careful when increasing the number of workers. There is a bug that significantly increases system memory usage with more workers.</p>
</blockquote>
</section>
<section id="finetune-the-model" class="level2">
<h2 class="anchored" data-anchor-id="finetune-the-model">Finetune the Model</h2>
<p>To finetune the YOLOX model, we must first instantiate the model and define metrics to track during training.</p>
<p><strong>Instantiate the model</strong></p>
<div class="sourceCode" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a YOLOX Tiny model</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model_type.model(backbone<span class="op">=</span>backbone(pretrained<span class="op">=</span><span class="va">True</span>), num_classes<span class="op">=</span>parser.class_map.num_classes) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define metrics</strong></p>
<div class="sourceCode" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a list of metrics to evaluate the model</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [COCOMetric(metric_type<span class="op">=</span>COCOMetricType.bbox)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can then create a Learner object to find the learning rate and handle the training loop.</p>
<p><strong>Define Learner object</strong></p>
<div class="sourceCode" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a fastai learner object to train and evaluate the YOLOX Tiny model</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> model_type.fastai.learner(dls<span class="op">=</span>[train_dl, valid_dl], model<span class="op">=</span>model, metrics<span class="op">=</span>metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Find learning rate</strong></p>
<div class="sourceCode" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the learning rate finder to find a good learning rate for the YOLOX Tiny model</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>suggested_lrs <span class="op">=</span> learn.lr_find()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_94_2.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Define learning rate</strong></p>
<div class="sourceCode" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the suggested learning rate identified by the learning rate finder</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> suggested_lrs.valley</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>lr</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>0.0008317637839354575</code></pre>
<p><strong>Define number of epochs</strong></p>
<div class="sourceCode" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the number of epochs to train the YOLOX Tiny model</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">20</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After defining the training parameters, we can finetune the model by training it on the training dataset.</p>
<p><strong>Finetune model</strong></p>
<div class="sourceCode" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the YOLOX Tiny model</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(epochs, lr, freeze_epochs<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
epoch
</th>
<th>
train_loss
</th>
<th>
valid_loss
</th>
<th>
COCOMetric
</th>
<th>
time
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
0
</td>
<td>
6.054967
</td>
<td>
5.384349
</td>
<td>
0.357238
</td>
<td>
03:24
</td>
</tr>
</tbody>

</table>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
epoch
</th>
<th>
train_loss
</th>
<th>
valid_loss
</th>
<th>
COCOMetric
</th>
<th>
time
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
0
</td>
<td>
3.794365
</td>
<td>
3.506713
</td>
<td>
0.605573
</td>
<td>
03:40
</td>
</tr>
<tr>
<td>
1
</td>
<td>
3.312004
</td>
<td>
2.977496
</td>
<td>
0.654320
</td>
<td>
03:40
</td>
</tr>
<tr>
<td>
2
</td>
<td>
3.017060
</td>
<td>
3.090266
</td>
<td>
0.606374
</td>
<td>
03:42
</td>
</tr>
<tr>
<td>
3
</td>
<td>
2.881786
</td>
<td>
2.837017
</td>
<td>
0.655119
</td>
<td>
03:48
</td>
</tr>
<tr>
<td>
4
</td>
<td>
2.760416
</td>
<td>
2.978580
</td>
<td>
0.616788
</td>
<td>
03:50
</td>
</tr>
<tr>
<td>
5
</td>
<td>
2.658237
</td>
<td>
2.742451
</td>
<td>
0.660538
</td>
<td>
03:31
</td>
</tr>
<tr>
<td>
6
</td>
<td>
2.595560
</td>
<td>
2.547496
</td>
<td>
0.683073
</td>
<td>
03:34
</td>
</tr>
<tr>
<td>
7
</td>
<td>
2.440215
</td>
<td>
2.707062
</td>
<td>
0.640533
</td>
<td>
03:35
</td>
</tr>
<tr>
<td>
8
</td>
<td>
2.332424
</td>
<td>
2.616575
</td>
<td>
0.658988
</td>
<td>
03:34
</td>
</tr>
<tr>
<td>
9
</td>
<td>
2.292744
</td>
<td>
2.278664
</td>
<td>
0.727411
</td>
<td>
03:33
</td>
</tr>
<tr>
<td>
10
</td>
<td>
2.165260
</td>
<td>
2.263503
</td>
<td>
0.714858
</td>
<td>
03:32
</td>
</tr>
<tr>
<td>
11
</td>
<td>
2.114893
</td>
<td>
2.221797
</td>
<td>
0.724567
</td>
<td>
03:34
</td>
</tr>
<tr>
<td>
12
</td>
<td>
2.048447
</td>
<td>
2.226138
</td>
<td>
0.723726
</td>
<td>
03:33
</td>
</tr>
<tr>
<td>
13
</td>
<td>
1.927701
</td>
<td>
2.126613
</td>
<td>
0.737985
</td>
<td>
03:30
</td>
</tr>
<tr>
<td>
14
</td>
<td>
1.895885
</td>
<td>
2.154254
</td>
<td>
0.733679
</td>
<td>
03:32
</td>
</tr>
<tr>
<td>
15
</td>
<td>
1.869765
</td>
<td>
1.983894
</td>
<td>
0.762880
</td>
<td>
03:33
</td>
</tr>
<tr>
<td>
16
</td>
<td>
1.798780
</td>
<td>
2.019078
</td>
<td>
0.753732
</td>
<td>
03:32
</td>
</tr>
<tr>
<td>
17
</td>
<td>
1.778396
</td>
<td>
2.028802
</td>
<td>
0.751977
</td>
<td>
03:33
</td>
</tr>
<tr>
<td>
18
</td>
<td>
1.748940
</td>
<td>
1.990781
</td>
<td>
0.759491
</td>
<td>
03:36
</td>
</tr>
<tr>
<td>
19
</td>
<td>
1.735546
</td>
<td>
1.973754
</td>
<td>
0.761532
</td>
<td>
03:33
</td>
</tr>
</tbody>

</table>
</div>
</section>
<section id="prepare-model-for-export" class="level2">
<h2 class="anchored" data-anchor-id="prepare-model-for-export">Prepare Model for Export</h2>
<p>Once the model finishes training, we need to modify it before exporting it. First, we’ll prepare an input image to feed to the model.</p>
<p><strong>Define method to convert a PIL Image to a Pytorch Tensor</strong></p>
<div class="sourceCode" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> img_to_tensor(img:PIL.Image, mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]):</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Converts a PIL image to a PyTorch tensor.</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a><span class="co">        img: The input PIL image.</span></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="co">        mean: The mean values for normalization.</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a><span class="co">        std: The standard deviation values for normalization.</span></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a><span class="co">        The normalized tensor.</span></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert image to tensor</span></span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>    img_tensor <span class="op">=</span> torch.Tensor(np.array(img)).permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Scale pixels values from [0,255] to [0,1]</span></span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>    scaled_tensor <span class="op">=</span> img_tensor.<span class="bu">float</span>().div_(<span class="dv">255</span>)</span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prepare normalization tensors</span></span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>    mean_tensor <span class="op">=</span> tensor(mean).view(<span class="dv">1</span>,<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>).permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a>    std_tensor <span class="op">=</span> tensor(std).view(<span class="dv">1</span>,<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>).permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize tensor    </span></span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>    normalized_tensor <span class="op">=</span> (scaled_tensor <span class="op">-</span> mean_tensor) <span class="op">/</span> std_tensor</span>
<span id="cb70-22"><a href="#cb70-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Batch tensor</span></span>
<span id="cb70-23"><a href="#cb70-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> normalized_tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Select a test image</strong></p>
<div class="sourceCode" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>annotation_df.iloc[<span class="dv">4</span>].to_frame()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
00973fac-440e-4a56-b60c-2a06d5fb155d
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
bboxes
</th>
<td>
[[0.40980118, 0.38144198, 0.08338464, 0.06229785], [0.6122035100000001, 0.6780825500000001, 0.04700606, 0.07640522]]
</td>
</tr>
<tr>
<th>
labels
</th>
<td>
[call, no_gesture]
</td>
</tr>
<tr>
<th>
leading_hand
</th>
<td>
right
</td>
</tr>
<tr>
<th>
leading_conf
</th>
<td>
1
</td>
</tr>
<tr>
<th>
user_id
</th>
<td>
4bb3ee1748be58e05bd1193939735e57bb3c0ca59a7ee38901744d6b9e94632e
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Get the test image file path</strong></p>
<div class="sourceCode" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve the image file path associated with the fifth entry in the 'annotation_df' DataFrame object</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>test_file <span class="op">=</span> img_dict[annotation_df.iloc[<span class="dv">4</span>].name]</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the test file path</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>test_file</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Path('/home/innom-dt/.fastai/archive/../data/hagrid-sample-30k-384p/hagrid_30k/train_val_call/00973fac-440e-4a56-b60c-2a06d5fb155d.jpg')</code></pre>
<p><strong>Load the test image</strong></p>
<div class="sourceCode" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Open the test file</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>test_img <span class="op">=</span> PIL.Image.<span class="bu">open</span>(test_file).convert(<span class="st">'RGB'</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the test image</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>test_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_108_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Calculate valid input dimensions</strong></p>
<div class="sourceCode" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the input height and width for the test image</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>input_h <span class="op">=</span> test_img.height <span class="op">-</span> (test_img.height <span class="op">%</span> max_stride)</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>input_w <span class="op">=</span> test_img.width <span class="op">-</span> (test_img.width <span class="op">%</span> max_stride)</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the input height and width</span></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>input_h, input_w</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>(512, 384)</code></pre>
<p><strong>Crop image to supported resolution</strong></p>
<div class="sourceCode" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Crop and pad the test image to match the input height and width</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>test_img <span class="op">=</span> test_img.crop_pad((input_w, input_h))</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the resulting test image</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>test_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_112_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Convert image to a normalized tensor</strong></p>
<div class="sourceCode" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the test image to a tensor</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>test_tensor <span class="op">=</span> img_to_tensor(test_img, mean<span class="op">=</span>mean, std<span class="op">=</span>std)</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shape of the resulting tensor</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_tensor.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>torch.Size([1, 3, 512, 384])</code></pre>
<p>Before making any changes, let’s inspect the current model output.</p>
<p><strong>Inspect raw model output</strong></p>
<div class="sourceCode" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the raw model output using the test tensor</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>model_output <span class="op">=</span> model.cpu().forward_dummy(test_tensor.cpu())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The model currently organizes the output into three tuples. The first tuple contains three tensors storing the object class predictions using the three stride values. Recall that there are 19 object classes, excluding the background class added by IceVision.</p>
<p>The second tuple contains three tensors with the predicted bounding box coordinates and dimensions using the three stride values.</p>
<p>The third tuple contains three tensors with the confidence score for whether an object is present in a given section of the input image using the three stride values.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shape for each tensor in the model output</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> raw_out <span class="kw">in</span> model_output:</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> out <span class="kw">in</span> raw_out:</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(out.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>torch.Size([1, 19, 64, 48])
torch.Size([1, 19, 32, 24])
torch.Size([1, 19, 16, 12])
torch.Size([1, 4, 64, 48])
torch.Size([1, 4, 32, 24])
torch.Size([1, 4, 16, 12])
torch.Size([1, 1, 64, 48])
torch.Size([1, 1, 32, 24])
torch.Size([1, 1, 16, 12])</code></pre>
<ul>
<li><p><code>512/8 = 64</code>, <code>512/16 = 32</code>, <code>512/32 = 16</code></p></li>
<li><p><code>384/8 = 48</code>, <code>384/16 = 24</code>, <code>384/32 = 12</code></p></li>
</ul>
<p>If we examine the end of a model from the official <a href="https://github.com/Megvii-BaseDetection/YOLOX/tree/main/demo/ONNXRuntime">YOLOX repo</a>, we can see the output looks a bit different.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/yolox_official_model.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>The official model first passes the tensors with the object class and “objectness” scores through sigmoid functions. It then combines the three tensors for each stride value into a single tensor before combining the resulting three tensors into a single flat array.</p>
<p>We can apply these same steps to our model by adding a new forward function using <a href="https://machinelearningmastery.com/monkey-patching-python-code/">monkey patching</a>.</p>
<p><strong>Define custom forward function for exporting the model</strong></p>
<div class="sourceCode" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_export(<span class="va">self</span>, input_tensor):</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get raw model output</span></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>    model_output <span class="op">=</span> <span class="va">self</span>.forward_dummy(input_tensor.cpu())</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the classification scores from the model output</span></span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>    cls_scores <span class="op">=</span> model_output[<span class="dv">0</span>]</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the bounding box predictions from the model output</span></span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>    bbox_preds <span class="op">=</span> model_output[<span class="dv">1</span>]</span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the objectness scores from the model output</span></span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a>    objectness <span class="op">=</span> model_output[<span class="dv">2</span>]</span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb83-15"><a href="#cb83-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process the stride 8 output</span></span>
<span id="cb83-16"><a href="#cb83-16" aria-hidden="true" tabindex="-1"></a>    stride_8_cls <span class="op">=</span> torch.sigmoid(cls_scores[<span class="dv">0</span>])</span>
<span id="cb83-17"><a href="#cb83-17" aria-hidden="true" tabindex="-1"></a>    stride_8_bbox <span class="op">=</span> bbox_preds[<span class="dv">0</span>]</span>
<span id="cb83-18"><a href="#cb83-18" aria-hidden="true" tabindex="-1"></a>    stride_8_objectness <span class="op">=</span> torch.sigmoid(objectness[<span class="dv">0</span>])</span>
<span id="cb83-19"><a href="#cb83-19" aria-hidden="true" tabindex="-1"></a>    stride_8_cat <span class="op">=</span> torch.cat((stride_8_bbox, stride_8_objectness, stride_8_cls), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb83-20"><a href="#cb83-20" aria-hidden="true" tabindex="-1"></a>    stride_8_flat <span class="op">=</span> torch.flatten(stride_8_cat, start_dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb83-21"><a href="#cb83-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-22"><a href="#cb83-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process the stride 16 output</span></span>
<span id="cb83-23"><a href="#cb83-23" aria-hidden="true" tabindex="-1"></a>    stride_16_cls <span class="op">=</span> torch.sigmoid(cls_scores[<span class="dv">1</span>])</span>
<span id="cb83-24"><a href="#cb83-24" aria-hidden="true" tabindex="-1"></a>    stride_16_bbox <span class="op">=</span> bbox_preds[<span class="dv">1</span>]</span>
<span id="cb83-25"><a href="#cb83-25" aria-hidden="true" tabindex="-1"></a>    stride_16_objectness <span class="op">=</span> torch.sigmoid(objectness[<span class="dv">1</span>])</span>
<span id="cb83-26"><a href="#cb83-26" aria-hidden="true" tabindex="-1"></a>    stride_16_cat <span class="op">=</span> torch.cat((stride_16_bbox, stride_16_objectness, stride_16_cls), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb83-27"><a href="#cb83-27" aria-hidden="true" tabindex="-1"></a>    stride_16_flat <span class="op">=</span> torch.flatten(stride_16_cat, start_dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb83-28"><a href="#cb83-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-29"><a href="#cb83-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process the stride 32 output</span></span>
<span id="cb83-30"><a href="#cb83-30" aria-hidden="true" tabindex="-1"></a>    stride_32_cls <span class="op">=</span> torch.sigmoid(cls_scores[<span class="dv">2</span>])</span>
<span id="cb83-31"><a href="#cb83-31" aria-hidden="true" tabindex="-1"></a>    stride_32_bbox <span class="op">=</span> bbox_preds[<span class="dv">2</span>]</span>
<span id="cb83-32"><a href="#cb83-32" aria-hidden="true" tabindex="-1"></a>    stride_32_objectness <span class="op">=</span> torch.sigmoid(objectness[<span class="dv">2</span>])</span>
<span id="cb83-33"><a href="#cb83-33" aria-hidden="true" tabindex="-1"></a>    stride_32_cat <span class="op">=</span> torch.cat((stride_32_bbox, stride_32_objectness, stride_32_cls), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb83-34"><a href="#cb83-34" aria-hidden="true" tabindex="-1"></a>    stride_32_flat <span class="op">=</span> torch.flatten(stride_32_cat, start_dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb83-35"><a href="#cb83-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-36"><a href="#cb83-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Concatenate all of the processed outputs</span></span>
<span id="cb83-37"><a href="#cb83-37" aria-hidden="true" tabindex="-1"></a>    full_cat <span class="op">=</span> torch.cat((stride_8_flat, stride_16_flat, stride_32_flat), dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb83-38"><a href="#cb83-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-39"><a href="#cb83-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the concatenated outputs in a permuted form</span></span>
<span id="cb83-40"><a href="#cb83-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> full_cat.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Add custom forward function to model</strong></p>
<div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bind the forward_export method to the model object</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>model.forward_export <span class="op">=</span> forward_export.<span class="fu">__get__</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s verify the new forward function works as intended. The output should have a batch size of 1 and contain 4032 elements, given the input dimensions (calculated earlier), each with 24 values (19 classes + 1 objectness score + 4 bounding box values).</p>
<p><strong>Verify output shape</strong></p>
<div class="sourceCode" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the forward_export method on the model object, passing in the test_tensor as an argument</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and get the shape of the output tensor</span></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>model.forward_export(test_tensor).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>torch.Size([1, 4032, 24])</code></pre>
<p>We need to replace the current forward function before exporting the model. We can create a backup of the original forward function just in case.</p>
<p><strong>Create a backup of the default model forward function</strong></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the original forward method of the model</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>origin_forward <span class="op">=</span> model.forward</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Replace model forward function with custom function</strong></p>
<div class="sourceCode" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace the original forward method of the model with the forward_export method</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>model.forward <span class="op">=</span> model.forward_export</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Verify output shape</strong></p>
<div class="sourceCode" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the forward_export method on the model object, passing in the test_tensor as an argument</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and get the shape of the output tensor</span></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>model(test_tensor).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>torch.Size([1, 4032, 24])</code></pre>
</section>
<section id="export-the-model" class="level2">
<h2 class="anchored" data-anchor-id="export-the-model">Export the Model</h2>
<p>The OpenVINO model conversion script does not support PyTorch models, so we need to export the trained model to ONNX. We can then convert the ONNX model to OpenVINO’s IR format.</p>
<p><strong>Define ONNX file name</strong></p>
<div class="sourceCode" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a filename for the ONNX model</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>onnx_file_name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span><span class="bu">type</span>(model)<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">.onnx"</span></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the filename</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>onnx_file_name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'hagrid-sample-30k-384p-YOLOX.onnx'</code></pre>
<p><strong>Export trained model to ONNX</strong></p>
<div class="sourceCode" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Export the PyTorch model to ONNX format</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>torch.onnx.export(model,</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>                  test_tensor,</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>                  onnx_file_name,</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>                  export_params<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>                  opset_version<span class="op">=</span><span class="dv">11</span>,</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>                  do_constant_folding<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>                  input_names <span class="op">=</span> [<span class="st">'input'</span>],</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>                  output_names <span class="op">=</span> [<span class="st">'output'</span>],</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>                  dynamic_axes<span class="op">=</span>{<span class="st">'input'</span>: {<span class="dv">2</span> : <span class="st">'height'</span>, <span class="dv">3</span> : <span class="st">'width'</span>}}</span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>                 )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Simplify ONNX model</strong></p>
<div class="sourceCode" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the onnx module</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> onnx</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the simplify method from the onnxsim module</span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> onnxsim <span class="im">import</span> simplify</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the ONNX model from the onnx_file_name</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>onnx_model <span class="op">=</span> onnx.load(onnx_file_name)</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simplify the model</span></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>model_simp, check <span class="op">=</span> simplify(onnx_model)</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the simplified model to the onnx_file_name</span></span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>onnx.save(model_simp, onnx_file_name)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p><strong>Note:</strong> As mentioned earlier, this step is entirely optional.</p>
</blockquote>
<p>Now we can export the ONNX model to OpenVINO’s IR format.</p>
<p><strong>Import OpenVINO Dependencies</strong></p>
<div class="sourceCode" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the Core class from the openvino.runtime module</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openvino.runtime <span class="im">import</span> Core</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the Markdown and display classes from the IPython.display module</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Markdown, display</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define export directory</strong></p>
<div class="sourceCode" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Path object representing the current directory</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> Path(<span class="st">'./'</span>)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the output_dir object</span></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>output_dir</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Path('.')</code></pre>
<p>The conversion script generates an XML file containing information about the model architecture and a BIN file that stores the trained weights. We need both files to perform inference. OpenVINO uses the same name for the BIN file as provided for the XML file.</p>
<p><strong>Define path for OpenVINO IR xml model file</strong></p>
<div class="sourceCode" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Path object representing the IR xml file using the ONNX model file name without the file extension</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>ir_path <span class="op">=</span> Path(<span class="ss">f"</span><span class="sc">{</span>onnx_file_name<span class="sc">.</span>split(<span class="st">'.'</span>)[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">.xml"</span>)</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the ir_path object</span></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>ir_path</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Path('hagrid-sample-30k-384p-YOLOX.xml')</code></pre>
<p>OpenVINO provides the option to include the normalization stats in the IR model. That way, we don’t need to account for different normalization stats when performing inference with multiple models. We can also convert the model to FP16 precision to reduce file size and improve inference speed.</p>
<p><strong>Define arguments for model conversion script</strong></p>
<div class="sourceCode" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the Model Optimizer command to convert the ONNX model to OpenVINO</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>mo_command <span class="op">=</span> <span class="ss">f"""mo</span></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --input_model "</span><span class="sc">{</span>onnx_file_name<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --input_shape "[1,3, </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">]"</span></span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --mean_values="</span><span class="sc">{</span>mean<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --scale_values="</span><span class="sc">{</span>std<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb102-7"><a href="#cb102-7" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --data_type FP16</span></span>
<span id="cb102-8"><a href="#cb102-8" aria-hidden="true" tabindex="-1"></a><span class="ss">                 --output_dir "</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb102-9"><a href="#cb102-9" aria-hidden="true" tabindex="-1"></a><span class="ss">                 """</span></span>
<span id="cb102-10"><a href="#cb102-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-11"><a href="#cb102-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove extra whitespace from the command string</span></span>
<span id="cb102-12"><a href="#cb102-12" aria-hidden="true" tabindex="-1"></a>mo_command <span class="op">=</span> <span class="st">" "</span>.join(mo_command.split())</span>
<span id="cb102-13"><a href="#cb102-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-14"><a href="#cb102-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the command and format it as a Bash code block</span></span>
<span id="cb102-15"><a href="#cb102-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model Optimizer command to convert the ONNX model to OpenVINO:"</span>)</span>
<span id="cb102-16"><a href="#cb102-16" aria-hidden="true" tabindex="-1"></a>display(Markdown(<span class="ss">f"```bash</span><span class="ch">\n</span><span class="sc">{</span>mo_command<span class="sc">}</span><span class="ch">\n</span><span class="ss">```"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Model Optimizer command to convert the ONNX model to OpenVINO:</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mo</span> <span class="at">--input_model</span> <span class="st">"hagrid-sample-30k-384p-YOLOX.onnx"</span> <span class="at">--input_shape</span> <span class="st">"[1,3, 384, 384]"</span> <span class="at">--mean_values</span><span class="op">=</span><span class="st">"(0.485, 0.456, 0.406)"</span> <span class="at">--scale_values</span><span class="op">=</span><span class="st">"(0.229, 0.224, 0.225)"</span> <span class="at">--data_type</span> FP16 <span class="at">--output_dir</span> <span class="st">"."</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Convert ONNX model to OpenVINO IR</strong></p>
<div class="sourceCode" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if the IR model file exists</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> ir_path.exists():</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If the IR model file does not exist, export the ONNX model to IR</span></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Exporting ONNX model to IR... This may take a few minutes."</span>)</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>    mo_result <span class="op">=</span> <span class="op">%</span>sx $mo_command</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join(mo_result))</span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If the IR model file already exists, print a message</span></span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"IR model </span><span class="sc">{</span>ir_path<span class="sc">}</span><span class="ss"> already exists."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Exporting ONNX model to IR... This may take a few minutes.
Model Optimizer arguments:
Common parameters:
    - Path to the Input Model:  /media/innom-dt/Samsung_T3/Projects/GitHub/icevision-openvino-unity-tutorial/notebooks/hagrid-sample-30k-384p-YOLOX.onnx
    - Path for generated IR:    /media/innom-dt/Samsung_T3/Projects/GitHub/icevision-openvino-unity-tutorial/notebooks/.
    - IR output name:   hagrid-sample-30k-384p-YOLOX
    - Log level:    ERROR
    - Batch:    Not specified, inherited from the model
    - Input layers:     Not specified, inherited from the model
    - Output layers:    Not specified, inherited from the model
    - Input shapes:     [1,3, 384, 384]
    - Source layout:    Not specified
    - Target layout:    Not specified
    - Layout:   Not specified
    - Mean values:  (0.485, 0.456, 0.406)
    - Scale values:     (0.229, 0.224, 0.225)
    - Scale factor:     Not specified
    - Precision of IR:  FP16
    - Enable fusing:    True
    - User transformations:     Not specified
    - Reverse input channels:   False
    - Enable IR generation for fixed input shape:   False
    - Use the transformations config file:  None
Advanced parameters:
    - Force the usage of legacy Frontend of Model Optimizer for model conversion into IR:   False
    - Force the usage of new Frontend of Model Optimizer for model conversion into IR:  False
OpenVINO runtime found in:  /home/innom-dt/mambaforge/envs/icevision/lib/python3.8/site-packages/openvino
OpenVINO runtime version:   2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version:    2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
    numpy: installed: 1.23.1, required: &lt; 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /media/innom-dt/Samsung_T3/Projects/GitHub/icevision-openvino-unity-tutorial/notebooks/hagrid-sample-30k-384p-YOLOX.xml
[ SUCCESS ] BIN file: /media/innom-dt/Samsung_T3/Projects/GitHub/icevision-openvino-unity-tutorial/notebooks/hagrid-sample-30k-384p-YOLOX.bin
[ SUCCESS ] Total execution time: 0.47 seconds. 
[ SUCCESS ] Memory consumed: 115 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&amp;source=prod&amp;campid=ww_2022_bu_IOTG_OpenVINO-2022-1&amp;content=upg_all&amp;medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai</code></pre>
</section>
<section id="verify-openvino-inference" class="level2">
<h2 class="anchored" data-anchor-id="verify-openvino-inference">Verify OpenVINO Inference</h2>
<p>Now, we can verify the OpenVINO model works as desired using the test image.</p>
<p><strong>Get available OpenVINO compute devices</strong></p>
<div class="sourceCode" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an instance of the Core class</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>ie <span class="op">=</span> Core()</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the list of available devices</span></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a>devices <span class="op">=</span> ie.available_devices</span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate over the available devices</span></span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> device <span class="kw">in</span> devices:</span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the device name</span></span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a>    device_name <span class="op">=</span> ie.get_property(device_name<span class="op">=</span>device, name<span class="op">=</span><span class="st">"FULL_DEVICE_NAME"</span>)</span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the device and its name</span></span>
<span id="cb107-13"><a href="#cb107-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>device_name<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>CPU: 11th Gen Intel(R) Core(TM) i7-11700K @ 3.60GHz</code></pre>
<p><strong>Prepare input image for OpenVINO IR model</strong></p>
<div class="sourceCode" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert image to tensor</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>img_tensor <span class="op">=</span> torch.Tensor(np.array(test_img)).permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale pixels values from [0,255] to [0,1]</span></span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>scaled_tensor <span class="op">=</span> img_tensor.<span class="bu">float</span>().div_(<span class="dv">255</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add an extra dimension to the Tensor</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>input_image <span class="op">=</span> scaled_tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shape of the input image</span></span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a>input_image.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>torch.Size([1, 3, 512, 384])</code></pre>
<p><strong>Test OpenVINO IR model</strong></p>
<div class="sourceCode" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an instance of the Core class</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>ie <span class="op">=</span> Core()</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the IR model file</span></span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a>model_ir <span class="op">=</span> ie.read_model(model<span class="op">=</span>ir_path)</span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-7"><a href="#cb112-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape the model to match the shape of the input image</span></span>
<span id="cb112-8"><a href="#cb112-8" aria-hidden="true" tabindex="-1"></a>model_ir.reshape(input_image.shape)</span>
<span id="cb112-9"><a href="#cb112-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-10"><a href="#cb112-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile the model for the CPU device</span></span>
<span id="cb112-11"><a href="#cb112-11" aria-hidden="true" tabindex="-1"></a>compiled_model_ir <span class="op">=</span> ie.compile_model(model<span class="op">=</span>model_ir, device_name<span class="op">=</span><span class="st">"CPU"</span>)</span>
<span id="cb112-12"><a href="#cb112-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-13"><a href="#cb112-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the input and output layers of the compiled model</span></span>
<span id="cb112-14"><a href="#cb112-14" aria-hidden="true" tabindex="-1"></a>input_layer_ir <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(compiled_model_ir.inputs))</span>
<span id="cb112-15"><a href="#cb112-15" aria-hidden="true" tabindex="-1"></a>output_layer_ir <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(compiled_model_ir.outputs))</span>
<span id="cb112-16"><a href="#cb112-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-17"><a href="#cb112-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the model on the input image and get the output</span></span>
<span id="cb112-18"><a href="#cb112-18" aria-hidden="true" tabindex="-1"></a>res_ir <span class="op">=</span> compiled_model_ir([input_image])[output_layer_ir]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shape of the model output</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>res_ir.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>(1, 4032, 24)</code></pre>
<p>The output shape is correct, meaning we can move on to the post-processing steps.</p>
</section>
<section id="define-post-processing-steps" class="level2">
<h2 class="anchored" data-anchor-id="define-post-processing-steps">Define Post-processing Steps</h2>
<p>To process the model output, we need to iterate through each of the 4032 object proposals and save the ones that meet a user-defined confidence threshold (e.g., 50%). We then filter out the redundant proposals (i.e., detecting the same object multiple times) from that subset using <a href="https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/">Non-Maximum Suppression (NMS)</a>.</p>
<p>We’ll first define a method that generates offset values based on the input dimensions and stride values, which we can use to traverse the output array.</p>
<p><strong>Define method to generate offset values to navigate the raw model output</strong></p>
<div class="sourceCode" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_grid_strides(height, width, strides<span class="op">=</span>[<span class="dv">8</span>, <span class="dv">16</span>, <span class="dv">32</span>]):</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate a list of dictionaries containing grid coordinates and strides for a given height and width.</span></span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a><span class="co">        height (int): The height of the image.</span></span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a><span class="co">        width (int): The width of the image.</span></span>
<span id="cb115-8"><a href="#cb115-8" aria-hidden="true" tabindex="-1"></a><span class="co">        strides (list): A list of strides to use for generating grid coordinates.</span></span>
<span id="cb115-9"><a href="#cb115-9" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb115-10"><a href="#cb115-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb115-11"><a href="#cb115-11" aria-hidden="true" tabindex="-1"></a><span class="co">        list: A list of dictionaries containing grid coordinates and strides.</span></span>
<span id="cb115-12"><a href="#cb115-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb115-13"><a href="#cb115-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb115-14"><a href="#cb115-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create an empty list to store the grid coordinates and strides</span></span>
<span id="cb115-15"><a href="#cb115-15" aria-hidden="true" tabindex="-1"></a>    grid_strides <span class="op">=</span> []</span>
<span id="cb115-16"><a href="#cb115-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-17"><a href="#cb115-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate over the strides</span></span>
<span id="cb115-18"><a href="#cb115-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> stride <span class="kw">in</span> strides:</span>
<span id="cb115-19"><a href="#cb115-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the grid height and width</span></span>
<span id="cb115-20"><a href="#cb115-20" aria-hidden="true" tabindex="-1"></a>        grid_height <span class="op">=</span> height <span class="op">//</span> stride</span>
<span id="cb115-21"><a href="#cb115-21" aria-hidden="true" tabindex="-1"></a>        grid_width <span class="op">=</span> width <span class="op">//</span> stride</span>
<span id="cb115-22"><a href="#cb115-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-23"><a href="#cb115-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Iterate over the grid coordinates</span></span>
<span id="cb115-24"><a href="#cb115-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> g1 <span class="kw">in</span> <span class="bu">range</span>(grid_height):</span>
<span id="cb115-25"><a href="#cb115-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> g0 <span class="kw">in</span> <span class="bu">range</span>(grid_width):</span>
<span id="cb115-26"><a href="#cb115-26" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Append a dictionary containing the grid coordinates and stride to the list</span></span>
<span id="cb115-27"><a href="#cb115-27" aria-hidden="true" tabindex="-1"></a>                grid_strides.append({<span class="st">'grid0'</span>:g0, <span class="st">'grid1'</span>:g1, <span class="st">'stride'</span>:stride })</span>
<span id="cb115-28"><a href="#cb115-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb115-29"><a href="#cb115-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the list of dictionaries</span></span>
<span id="cb115-30"><a href="#cb115-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> grid_strides</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Generate offset values to navigate model output</strong></p>
<div class="sourceCode" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the grid coordinates and strides</span></span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>grid_strides <span class="op">=</span> generate_grid_strides(test_img.height, test_img.width, strides)</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the length of the list of grid coordinates and strides</span></span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(grid_strides)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>4032</code></pre>
<div class="sourceCode" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the first few rows of the list using a DataFrame</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(grid_strides).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
grid0
</th>
<th>
grid1
</th>
<th>
stride
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
0
</td>
<td>
8
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
0
</td>
<td>
8
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
0
</td>
<td>
8
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
0
</td>
<td>
8
</td>
</tr>
<tr>
<th>
4
</th>
<td>
4
</td>
<td>
0
</td>
<td>
8
</td>
</tr>
</tbody>

</table>
</div>
<p>Next, we’ll define a method to iterate through the output array and decode the bounding box information for each object proposal. As mentioned earlier, we’ll only keep the ones with a high enough confidence score. The model predicts the center coordinates of a bounding box, but we’ll store the coordinates for the top-left corner as that is what the <code>ImageDraw.Draw.rectangle()</code> method expects as input.</p>
<p><strong>Define method to generate object detection proposals from the raw model output</strong></p>
<div class="sourceCode" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_yolox_proposals(model_output, proposal_length, grid_strides, bbox_conf_thresh<span class="op">=</span><span class="fl">0.3</span>):</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate a list of bounding box proposals from the model output.</span></span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb119-6"><a href="#cb119-6" aria-hidden="true" tabindex="-1"></a><span class="co">        model_output (numpy array): The output of the YOLOX model.</span></span>
<span id="cb119-7"><a href="#cb119-7" aria-hidden="true" tabindex="-1"></a><span class="co">        proposal_length (int): The length of each proposal in the model output.</span></span>
<span id="cb119-8"><a href="#cb119-8" aria-hidden="true" tabindex="-1"></a><span class="co">        grid_strides (list): A list of dictionaries containing grid coordinates and strides.</span></span>
<span id="cb119-9"><a href="#cb119-9" aria-hidden="true" tabindex="-1"></a><span class="co">        bbox_conf_thresh (float): The confidence threshold for bounding box proposals.</span></span>
<span id="cb119-10"><a href="#cb119-10" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb119-11"><a href="#cb119-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb119-12"><a href="#cb119-12" aria-hidden="true" tabindex="-1"></a><span class="co">        list: A list of bounding box proposals.</span></span>
<span id="cb119-13"><a href="#cb119-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb119-14"><a href="#cb119-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb119-15"><a href="#cb119-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create an empty list to store the bounding box proposals</span></span>
<span id="cb119-16"><a href="#cb119-16" aria-hidden="true" tabindex="-1"></a>    proposals <span class="op">=</span> []</span>
<span id="cb119-17"><a href="#cb119-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb119-18"><a href="#cb119-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the number of classes</span></span>
<span id="cb119-19"><a href="#cb119-19" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> proposal_length <span class="op">-</span> <span class="dv">5</span></span>
<span id="cb119-20"><a href="#cb119-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-21"><a href="#cb119-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate over the grid coordinates and strides</span></span>
<span id="cb119-22"><a href="#cb119-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> anchor_idx <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(grid_strides)):</span>
<span id="cb119-23"><a href="#cb119-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb119-24"><a href="#cb119-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the grid coordinates and stride for the current anchor</span></span>
<span id="cb119-25"><a href="#cb119-25" aria-hidden="true" tabindex="-1"></a>        grid0 <span class="op">=</span> grid_strides[anchor_idx][<span class="st">'grid0'</span>]</span>
<span id="cb119-26"><a href="#cb119-26" aria-hidden="true" tabindex="-1"></a>        grid1 <span class="op">=</span> grid_strides[anchor_idx][<span class="st">'grid1'</span>]</span>
<span id="cb119-27"><a href="#cb119-27" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">=</span> grid_strides[anchor_idx][<span class="st">'stride'</span>]</span>
<span id="cb119-28"><a href="#cb119-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-29"><a href="#cb119-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the starting index for the current anchor in the model output</span></span>
<span id="cb119-30"><a href="#cb119-30" aria-hidden="true" tabindex="-1"></a>        start_idx <span class="op">=</span> anchor_idx <span class="op">*</span> proposal_length</span>
<span id="cb119-31"><a href="#cb119-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-32"><a href="#cb119-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the coordinates for the center of the predicted bounding box</span></span>
<span id="cb119-33"><a href="#cb119-33" aria-hidden="true" tabindex="-1"></a>        x_center <span class="op">=</span> (model_output[start_idx <span class="op">+</span> <span class="dv">0</span>] <span class="op">+</span> grid0) <span class="op">*</span> stride</span>
<span id="cb119-34"><a href="#cb119-34" aria-hidden="true" tabindex="-1"></a>        y_center <span class="op">=</span> (model_output[start_idx <span class="op">+</span> <span class="dv">1</span>] <span class="op">+</span> grid1) <span class="op">*</span> stride</span>
<span id="cb119-35"><a href="#cb119-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-36"><a href="#cb119-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the dimensions for the predicted bounding box</span></span>
<span id="cb119-37"><a href="#cb119-37" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> np.exp(model_output[start_idx <span class="op">+</span> <span class="dv">2</span>]) <span class="op">*</span> stride</span>
<span id="cb119-38"><a href="#cb119-38" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> np.exp(model_output[start_idx <span class="op">+</span> <span class="dv">3</span>]) <span class="op">*</span> stride</span>
<span id="cb119-39"><a href="#cb119-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-40"><a href="#cb119-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the coordinates for the upper left corner of the bounding box</span></span>
<span id="cb119-41"><a href="#cb119-41" aria-hidden="true" tabindex="-1"></a>        x0 <span class="op">=</span> x_center <span class="op">-</span> w <span class="op">*</span> <span class="fl">0.5</span></span>
<span id="cb119-42"><a href="#cb119-42" aria-hidden="true" tabindex="-1"></a>        y0 <span class="op">=</span> y_center <span class="op">-</span> h <span class="op">*</span> <span class="fl">0.5</span></span>
<span id="cb119-43"><a href="#cb119-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-44"><a href="#cb119-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the objectness score for the current anchor</span></span>
<span id="cb119-45"><a href="#cb119-45" aria-hidden="true" tabindex="-1"></a>        box_objectness <span class="op">=</span> model_output[start_idx <span class="op">+</span> <span class="dv">4</span>]</span>
<span id="cb119-46"><a href="#cb119-46" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb119-47"><a href="#cb119-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create an empty dictionary to store the bounding box proposal</span></span>
<span id="cb119-48"><a href="#cb119-48" aria-hidden="true" tabindex="-1"></a>        obj <span class="op">=</span> { <span class="st">'x0'</span>:x0, <span class="st">'y0'</span>:y0, <span class="st">'width'</span>:w, <span class="st">'height'</span>:h, <span class="st">'label'</span>:<span class="dv">0</span>, <span class="st">'prob'</span>:<span class="dv">0</span> }</span>
<span id="cb119-49"><a href="#cb119-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-50"><a href="#cb119-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Iterate over the classes</span></span>
<span id="cb119-51"><a href="#cb119-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> class_idx <span class="kw">in</span> <span class="bu">range</span>(num_classes):</span>
<span id="cb119-52"><a href="#cb119-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-53"><a href="#cb119-53" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate the probability of the current class</span></span>
<span id="cb119-54"><a href="#cb119-54" aria-hidden="true" tabindex="-1"></a>            box_cls_score <span class="op">=</span> model_output[start_idx <span class="op">+</span> <span class="dv">5</span> <span class="op">+</span> class_idx]</span>
<span id="cb119-55"><a href="#cb119-55" aria-hidden="true" tabindex="-1"></a>            box_prob <span class="op">=</span> box_objectness <span class="op">*</span> box_cls_score</span>
<span id="cb119-56"><a href="#cb119-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-57"><a href="#cb119-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the probability is greater than the current maximum, update the proposal dictionary</span></span>
<span id="cb119-58"><a href="#cb119-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> (box_prob <span class="op">&gt;</span> obj[<span class="st">'prob'</span>]):</span>
<span id="cb119-59"><a href="#cb119-59" aria-hidden="true" tabindex="-1"></a>                obj[<span class="st">'label'</span>] <span class="op">=</span> class_idx</span>
<span id="cb119-60"><a href="#cb119-60" aria-hidden="true" tabindex="-1"></a>                obj[<span class="st">'prob'</span>] <span class="op">=</span> box_prob</span>
<span id="cb119-61"><a href="#cb119-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-62"><a href="#cb119-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the bounding box proposal has a probability greater than the specified threshold, add it to the list of proposals</span></span>
<span id="cb119-63"><a href="#cb119-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> obj[<span class="st">'prob'</span>] <span class="op">&gt;</span> bbox_conf_thresh: proposals.append(obj)</span>
<span id="cb119-64"><a href="#cb119-64" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb119-65"><a href="#cb119-65" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort the list of bounding box proposals by probability in descending order</span></span>
<span id="cb119-66"><a href="#cb119-66" aria-hidden="true" tabindex="-1"></a>    proposals.sort(key<span class="op">=</span><span class="kw">lambda</span> x:x[<span class="st">'prob'</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb119-67"><a href="#cb119-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> proposals</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define minimum confidence score for keeping bounding box proposals</strong></p>
<div class="sourceCode" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the bounding box confidence threshold</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>bbox_conf_thresh <span class="op">=</span> <span class="fl">0.5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Process raw model output</strong></p>
<div class="sourceCode" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate proposals from the model output</span></span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>proposals <span class="op">=</span> generate_yolox_proposals(res_ir.flatten(), res_ir.shape[<span class="dv">2</span>], grid_strides, bbox_conf_thresh)</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the proposals to a Pandas DataFrame</span></span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>proposals_df <span class="op">=</span> pd.DataFrame(proposals)</span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the label names to the DataFrame</span></span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a>proposals_df[<span class="st">'label'</span>] <span class="op">=</span> proposals_df[<span class="st">'label'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: labels[x])</span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the proposals Dataframe</span></span>
<span id="cb121-11"><a href="#cb121-11" aria-hidden="true" tabindex="-1"></a>proposals_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
x0
</th>
<th>
y0
</th>
<th>
width
</th>
<th>
height
</th>
<th>
label
</th>
<th>
prob
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
234.084399
</td>
<td>
345.059397
</td>
<td>
19.638884
</td>
<td>
40.022980
</td>
<td>
no_gesture
</td>
<td>
0.887864
</td>
</tr>
<tr>
<th>
1
</th>
<td>
234.122849
</td>
<td>
344.858476
</td>
<td>
19.512623
</td>
<td>
40.319473
</td>
<td>
no_gesture
</td>
<td>
0.887479
</td>
</tr>
<tr>
<th>
2
</th>
<td>
233.998906
</td>
<td>
344.849410
</td>
<td>
19.742203
</td>
<td>
39.664391
</td>
<td>
no_gesture
</td>
<td>
0.879032
</td>
</tr>
<tr>
<th>
3
</th>
<td>
154.565092
</td>
<td>
193.542165
</td>
<td>
35.063389
</td>
<td>
34.609722
</td>
<td>
call
</td>
<td>
0.876051
</td>
</tr>
<tr>
<th>
4
</th>
<td>
154.257556
</td>
<td>
193.482616
</td>
<td>
35.451900
</td>
<td>
34.860138
</td>
<td>
call
</td>
<td>
0.867827
</td>
</tr>
<tr>
<th>
5
</th>
<td>
154.484365
</td>
<td>
193.435712
</td>
<td>
34.926231
</td>
<td>
35.332264
</td>
<td>
call
</td>
<td>
0.866654
</td>
</tr>
<tr>
<th>
6
</th>
<td>
234.141719
</td>
<td>
344.954988
</td>
<td>
19.724554
</td>
<td>
40.226116
</td>
<td>
no_gesture
</td>
<td>
0.865423
</td>
</tr>
<tr>
<th>
7
</th>
<td>
233.691895
</td>
<td>
344.861304
</td>
<td>
20.142962
</td>
<td>
40.653099
</td>
<td>
no_gesture
</td>
<td>
0.857602
</td>
</tr>
<tr>
<th>
8
</th>
<td>
154.580361
</td>
<td>
193.261580
</td>
<td>
34.681351
</td>
<td>
35.288120
</td>
<td>
call
</td>
<td>
0.847856
</td>
</tr>
<tr>
<th>
9
</th>
<td>
233.792754
</td>
<td>
344.441489
</td>
<td>
20.184782
</td>
<td>
40.635910
</td>
<td>
no_gesture
</td>
<td>
0.829289
</td>
</tr>
<tr>
<th>
10
</th>
<td>
154.467418
</td>
<td>
193.468482
</td>
<td>
35.273167
</td>
<td>
34.796146
</td>
<td>
call
</td>
<td>
0.829163
</td>
</tr>
<tr>
<th>
11
</th>
<td>
154.234487
</td>
<td>
193.324329
</td>
<td>
35.518040
</td>
<td>
34.588329
</td>
<td>
call
</td>
<td>
0.816633
</td>
</tr>
<tr>
<th>
12
</th>
<td>
155.282080
</td>
<td>
193.360302
</td>
<td>
34.524830
</td>
<td>
35.269939
</td>
<td>
call
</td>
<td>
0.804335
</td>
</tr>
<tr>
<th>
13
</th>
<td>
233.925717
</td>
<td>
344.809189
</td>
<td>
19.701090
</td>
<td>
40.598907
</td>
<td>
no_gesture
</td>
<td>
0.779452
</td>
</tr>
<tr>
<th>
14
</th>
<td>
233.717521
</td>
<td>
344.739007
</td>
<td>
20.083487
</td>
<td>
40.492405
</td>
<td>
no_gesture
</td>
<td>
0.736652
</td>
</tr>
<tr>
<th>
15
</th>
<td>
154.407403
</td>
<td>
193.529026
</td>
<td>
34.728149
</td>
<td>
33.798748
</td>
<td>
call
</td>
<td>
0.687202
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p>We know the test image contains one call gesture and one idle hand. The model seems pretty confident about the locations of those two hands as the bounding box values are nearly identical across the <code>no_gesture</code> predictions and among the <code>call</code> predictions.</p>
<p>We can filter out the redundant predictions by checking how much the bounding boxes overlap. When two bounding boxes overlap beyond a user-defined threshold, we keep the one with a higher confidence score.</p>
<p><strong>Define function to calculate the union area of two bounding boxes</strong></p>
<div class="sourceCode" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_union_area(a, b):</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the minimum x-coordinate of the two rectangles</span></span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="bu">min</span>(a[<span class="st">'x0'</span>], b[<span class="st">'x0'</span>])</span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the minimum y-coordinate of the two rectangles</span></span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> <span class="bu">min</span>(a[<span class="st">'y0'</span>], b[<span class="st">'y0'</span>])</span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the maximum x-coordinate of the two rectangles</span></span>
<span id="cb122-9"><a href="#cb122-9" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> <span class="bu">max</span>(a[<span class="st">'x0'</span>]<span class="op">+</span>a[<span class="st">'width'</span>], b[<span class="st">'x0'</span>]<span class="op">+</span>b[<span class="st">'width'</span>]) <span class="op">-</span> x</span>
<span id="cb122-10"><a href="#cb122-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb122-11"><a href="#cb122-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the maximum y-coordinate of the two rectangles</span></span>
<span id="cb122-12"><a href="#cb122-12" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="bu">max</span>(a[<span class="st">'y0'</span>]<span class="op">+</span>a[<span class="st">'height'</span>], b[<span class="st">'y0'</span>]<span class="op">+</span>b[<span class="st">'height'</span>]) <span class="op">-</span> y</span>
<span id="cb122-13"><a href="#cb122-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb122-14"><a href="#cb122-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the area of the combined rectangle</span></span>
<span id="cb122-15"><a href="#cb122-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> w<span class="op">*</span>h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define function to calculate the intersection area of two bounding boxes</strong></p>
<div class="sourceCode" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_inter_area(a, b):</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the maximum x-coordinate of the two rectangles</span></span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="bu">max</span>(a[<span class="st">'x0'</span>], b[<span class="st">'x0'</span>])</span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the maximum y-coordinate of the two rectangles</span></span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> <span class="bu">max</span>(a[<span class="st">'y0'</span>], b[<span class="st">'y0'</span>])</span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the minimum x-coordinate of the two rectangles</span></span>
<span id="cb123-9"><a href="#cb123-9" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> <span class="bu">min</span>(a[<span class="st">'x0'</span>]<span class="op">+</span>a[<span class="st">'width'</span>], b[<span class="st">'x0'</span>]<span class="op">+</span>b[<span class="st">'width'</span>]) <span class="op">-</span> x</span>
<span id="cb123-10"><a href="#cb123-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb123-11"><a href="#cb123-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the minimum y-coordinate of the two rectangles</span></span>
<span id="cb123-12"><a href="#cb123-12" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="bu">min</span>(a[<span class="st">'y0'</span>]<span class="op">+</span>a[<span class="st">'height'</span>], b[<span class="st">'y0'</span>]<span class="op">+</span>b[<span class="st">'height'</span>]) <span class="op">-</span> y</span>
<span id="cb123-13"><a href="#cb123-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb123-14"><a href="#cb123-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the area of the intersecting rectangle</span></span>
<span id="cb123-15"><a href="#cb123-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> w<span class="op">*</span>h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define function to sort bounding box proposals using Non-Maximum Suppression</strong></p>
<div class="sourceCode" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> nms_sorted_boxes(nms_thresh<span class="op">=</span><span class="fl">0.45</span>):</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize a list to store the indices of the proposals to keep</span></span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>    proposal_indices <span class="op">=</span> []</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loop over all proposals in the input list</span></span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(proposals)):</span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the ith proposal</span></span>
<span id="cb124-8"><a href="#cb124-8" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> proposals[i]</span>
<span id="cb124-9"><a href="#cb124-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-10"><a href="#cb124-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Assume that we want to keep this proposal by default</span></span>
<span id="cb124-11"><a href="#cb124-11" aria-hidden="true" tabindex="-1"></a>        keep <span class="op">=</span> <span class="va">True</span></span>
<span id="cb124-12"><a href="#cb124-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-13"><a href="#cb124-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Loop over the indices of the proposals that we want to keep</span></span>
<span id="cb124-14"><a href="#cb124-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> proposal_indices:</span>
<span id="cb124-15"><a href="#cb124-15" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get the jth proposal</span></span>
<span id="cb124-16"><a href="#cb124-16" aria-hidden="true" tabindex="-1"></a>            b <span class="op">=</span> proposals[j]</span>
<span id="cb124-17"><a href="#cb124-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-18"><a href="#cb124-18" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute the area of the intersection of the ith and jth proposals</span></span>
<span id="cb124-19"><a href="#cb124-19" aria-hidden="true" tabindex="-1"></a>            inter_area <span class="op">=</span> calc_inter_area(a, b)</span>
<span id="cb124-20"><a href="#cb124-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-21"><a href="#cb124-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute the area of the union of the ith and jth proposals</span></span>
<span id="cb124-22"><a href="#cb124-22" aria-hidden="true" tabindex="-1"></a>            union_area <span class="op">=</span> calc_union_area(a, b)</span>
<span id="cb124-23"><a href="#cb124-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-24"><a href="#cb124-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the intersection of the ith and jth proposals is more than the specified non-max suppression</span></span>
<span id="cb124-25"><a href="#cb124-25" aria-hidden="true" tabindex="-1"></a>            <span class="co"># threshold, we don't want to keep the ith proposal</span></span>
<span id="cb124-26"><a href="#cb124-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> inter_area <span class="op">/</span> union_area <span class="op">&gt;</span> nms_thresh:</span>
<span id="cb124-27"><a href="#cb124-27" aria-hidden="true" tabindex="-1"></a>                keep <span class="op">=</span> <span class="va">False</span></span>
<span id="cb124-28"><a href="#cb124-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-29"><a href="#cb124-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If we want to keep the ith proposal, append its index to the list of proposal indices</span></span>
<span id="cb124-30"><a href="#cb124-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> keep:</span>
<span id="cb124-31"><a href="#cb124-31" aria-hidden="true" tabindex="-1"></a>            proposal_indices.append(i)</span>
<span id="cb124-32"><a href="#cb124-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-33"><a href="#cb124-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the list of proposal indices</span></span>
<span id="cb124-34"><a href="#cb124-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> proposal_indices</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define threshold for sorting bounding box proposals</strong></p>
<div class="sourceCode" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the non-max suppression threshold</span></span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>nms_thresh <span class="op">=</span> <span class="fl">0.45</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Sort bouning box proposals using NMS</strong></p>
<div class="sourceCode" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply non-max suppression to the list of proposals with the specified non-max suppression threshold</span></span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>proposal_indices <span class="op">=</span> nms_sorted_boxes(nms_thresh)</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-4"><a href="#cb126-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the list of proposal indices</span></span>
<span id="cb126-5"><a href="#cb126-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proposal_indices)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[0, 3]</code></pre>
<p><strong>Filter excluded bounding box proposals</strong></p>
<div class="sourceCode" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the rows from the proposals DataFrame that correspond to the indices</span></span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="co"># returned by the non-max suppression algorithm</span></span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a>proposals_df.iloc[proposal_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
x0
</th>
<th>
y0
</th>
<th>
width
</th>
<th>
height
</th>
<th>
label
</th>
<th>
prob
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
234.084399
</td>
<td>
345.059397
</td>
<td>
19.638884
</td>
<td>
40.022980
</td>
<td>
no_gesture
</td>
<td>
0.887864
</td>
</tr>
<tr>
<th>
3
</th>
<td>
154.565092
</td>
<td>
193.542165
</td>
<td>
35.063389
</td>
<td>
34.609722
</td>
<td>
call
</td>
<td>
0.876051
</td>
</tr>
</tbody>

</table>
</div>
<p>Now we have a single prediction for an idle hand and a single prediction for a call sign.</p>
</section>
<section id="generate-colormap" class="level2">
<h2 class="anchored" data-anchor-id="generate-colormap">Generate Colormap</h2>
<p>Before we annotate the input image with the predicted bounding boxes, let’s generate a colormap for the object classes.</p>
<p><strong>Import library for generating color palette</strong></p>
<div class="sourceCode" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the distinctipy module</span></span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> distinctipy <span class="im">import</span> distinctipy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Generate a visually distinct color for each label</strong></p>
<div class="sourceCode" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the distinctipy module to generate a list of colors with a length equal to the number of labels</span></span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> distinctipy.get_colors(<span class="bu">len</span>(labels))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Display the generated color palette</strong></p>
<div class="sourceCode" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the distinctipy module to generate a color swatch using the list of colors</span></span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>distinctipy.color_swatch(colors)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_184_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Set precision for color values</strong></p>
<div class="sourceCode" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the precision to 5 decimal places</span></span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> <span class="dv">5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Round color values to specified precision</strong></p>
<div class="sourceCode" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Round the values in the list of colors to the specified precision</span></span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [[np.<span class="bu">round</span>(ch, precision) <span class="cf">for</span> ch <span class="kw">in</span> color] <span class="cf">for</span> color <span class="kw">in</span> colors]</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the rounded list of colors using a Pandas Dataframe</span></span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(colors)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
<th>
1
</th>
<th>
2
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0.00000
</td>
<td>
1.00000
</td>
<td>
0.00000
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1.00000
</td>
<td>
0.00000
</td>
<td>
1.00000
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0.00000
</td>
<td>
0.50000
</td>
<td>
1.00000
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1.00000
</td>
<td>
0.50000
</td>
<td>
0.00000
</td>
</tr>
<tr>
<th>
4
</th>
<td>
0.50000
</td>
<td>
0.75000
</td>
<td>
0.50000
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0.32114
</td>
<td>
0.03531
</td>
<td>
0.64056
</td>
</tr>
<tr>
<th>
6
</th>
<td>
0.80830
</td>
<td>
0.00115
</td>
<td>
0.02081
</td>
</tr>
<tr>
<th>
7
</th>
<td>
0.02177
</td>
<td>
0.42475
</td>
<td>
0.33483
</td>
</tr>
<tr>
<th>
8
</th>
<td>
0.72261
</td>
<td>
0.47583
</td>
<td>
0.99531
</td>
</tr>
<tr>
<th>
9
</th>
<td>
0.99715
</td>
<td>
0.97599
</td>
<td>
0.25699
</td>
</tr>
<tr>
<th>
10
</th>
<td>
0.00000
</td>
<td>
1.00000
</td>
<td>
1.00000
</td>
</tr>
<tr>
<th>
11
</th>
<td>
0.00000
</td>
<td>
1.00000
</td>
<td>
0.50000
</td>
</tr>
<tr>
<th>
12
</th>
<td>
0.65521
</td>
<td>
0.34251
</td>
<td>
0.38036
</td>
</tr>
<tr>
<th>
13
</th>
<td>
0.96712
</td>
<td>
0.62955
</td>
<td>
0.52852
</td>
</tr>
<tr>
<th>
14
</th>
<td>
0.48445
</td>
<td>
0.84111
</td>
<td>
0.01565
</td>
</tr>
<tr>
<th>
15
</th>
<td>
0.00000
</td>
<td>
0.00000
</td>
<td>
1.00000
</td>
</tr>
<tr>
<th>
16
</th>
<td>
0.54362
</td>
<td>
0.96123
</td>
<td>
0.90460
</td>
</tr>
<tr>
<th>
17
</th>
<td>
0.36779
</td>
<td>
0.44128
</td>
<td>
0.00059
</td>
</tr>
<tr>
<th>
18
</th>
<td>
0.97231
</td>
<td>
0.10181
</td>
<td>
0.49080
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p><strong>Annotate image using bounding box proposals</strong></p>
<div class="sourceCode" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a copy of the test image</span></span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>annotated_img <span class="op">=</span> test_img.copy()</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a drawing context for the annotated image</span></span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>draw <span class="op">=</span> ImageDraw.Draw(annotated_img)</span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the font size for the labels</span></span>
<span id="cb134-8"><a href="#cb134-8" aria-hidden="true" tabindex="-1"></a>fnt_size <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb134-9"><a href="#cb134-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-10"><a href="#cb134-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop over the indices of the proposals that were selected by the non-max suppression algorithm</span></span>
<span id="cb134-11"><a href="#cb134-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> proposal_indices:</span>
<span id="cb134-12"><a href="#cb134-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the bounding box coordinates, label, and confidence score of the ith proposal</span></span>
<span id="cb134-13"><a href="#cb134-13" aria-hidden="true" tabindex="-1"></a>    x, y, w, h, l, p <span class="op">=</span> proposals[i].values()</span>
<span id="cb134-14"><a href="#cb134-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-15"><a href="#cb134-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the shape of the bounding box</span></span>
<span id="cb134-16"><a href="#cb134-16" aria-hidden="true" tabindex="-1"></a>    shape <span class="op">=</span> (x, y, x<span class="op">+</span>w, y<span class="op">+</span>h)</span>
<span id="cb134-17"><a href="#cb134-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-18"><a href="#cb134-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the color for the ith proposal's label</span></span>
<span id="cb134-19"><a href="#cb134-19" aria-hidden="true" tabindex="-1"></a>    color <span class="op">=</span> <span class="bu">tuple</span>([<span class="bu">int</span>(ch<span class="op">*</span><span class="dv">255</span>) <span class="cf">for</span> ch <span class="kw">in</span> colors[proposals[i][<span class="st">'label'</span>]]])</span>
<span id="cb134-20"><a href="#cb134-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-21"><a href="#cb134-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw the bounding box on the annotated image using the computed shape and color</span></span>
<span id="cb134-22"><a href="#cb134-22" aria-hidden="true" tabindex="-1"></a>    draw.rectangle(shape, outline<span class="op">=</span>color)</span>
<span id="cb134-23"><a href="#cb134-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-24"><a href="#cb134-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a font object using the selected font and font size</span></span>
<span id="cb134-25"><a href="#cb134-25" aria-hidden="true" tabindex="-1"></a>    fnt <span class="op">=</span> PIL.ImageFont.truetype(<span class="st">"KFOlCnqEu92Fr1MmEU9vAw.ttf"</span>, fnt_size)</span>
<span id="cb134-26"><a href="#cb134-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-27"><a href="#cb134-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw the label and confidence score on the annotated image using the font, color, and bounding box coordinates</span></span>
<span id="cb134-28"><a href="#cb134-28" aria-hidden="true" tabindex="-1"></a>    draw.multiline_text((x, y<span class="op">-</span>fnt_size<span class="op">*</span><span class="dv">2</span><span class="op">-</span><span class="dv">5</span>), <span class="ss">f"</span><span class="sc">{</span>labels[l]<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>p<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>, font<span class="op">=</span>fnt, fill<span class="op">=</span>color)</span>
<span id="cb134-29"><a href="#cb134-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-30"><a href="#cb134-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the size of the annotated image</span></span>
<span id="cb134-31"><a href="#cb134-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(annotated_img.size) </span>
<span id="cb134-32"><a href="#cb134-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-33"><a href="#cb134-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the annotated image</span></span>
<span id="cb134-34"><a href="#cb134-34" aria-hidden="true" tabindex="-1"></a>annotated_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>(384, 512)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_190_1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Benchmark OpenVINO IR CPU inference speed</strong></p>
<div class="sourceCode" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>timeit</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Time how long it takes to run the compiled model on the input image</span></span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a><span class="co"># and extract the output from the specified layer</span></span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>compiled_model_ir([input_image])[output_layer_ir]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    12 ms ± 42.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</code></pre>
<p>We can export the colormap to a JSON file and import it into the Unity project. That way, we can easily swap colormaps for models trained on different datasets without changing any code.</p>
<p><strong>Create JSON colormap</strong></p>
<div class="sourceCode" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the color map with an empty list of items</span></span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>color_map <span class="op">=</span> {<span class="st">'items'</span>: <span class="bu">list</span>()}</span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Populate the color map with the labels and colors</span></span>
<span id="cb138-5"><a href="#cb138-5" aria-hidden="true" tabindex="-1"></a>color_map[<span class="st">'items'</span>] <span class="op">=</span> [{<span class="st">'label'</span>: label, <span class="st">'color'</span>: color} <span class="cf">for</span> label, color <span class="kw">in</span> <span class="bu">zip</span>(labels, colors)]</span>
<span id="cb138-6"><a href="#cb138-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-7"><a href="#cb138-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the color map</span></span>
<span id="cb138-8"><a href="#cb138-8" aria-hidden="true" tabindex="-1"></a>color_map</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>{'items': [{'label': 'call', 'color': [0.0, 1.0, 0.0]},
  {'label': 'no_gesture', 'color': [1.0, 0.0, 1.0]},
  {'label': 'dislike', 'color': [0.0, 0.5, 1.0]},
  {'label': 'fist', 'color': [1.0, 0.5, 0.0]},
  {'label': 'four', 'color': [0.5, 0.75, 0.5]},
  {'label': 'like', 'color': [0.32114, 0.03531, 0.64056]},
  {'label': 'mute', 'color': [0.8083, 0.00115, 0.02081]},
  {'label': 'ok', 'color': [0.02177, 0.42475, 0.33483]},
  {'label': 'one', 'color': [0.72261, 0.47583, 0.99531]},
  {'label': 'palm', 'color': [0.99715, 0.97599, 0.25699]},
  {'label': 'peace', 'color': [0.0, 1.0, 1.0]},
  {'label': 'peace_inverted', 'color': [0.0, 1.0, 0.5]},
  {'label': 'rock', 'color': [0.65521, 0.34251, 0.38036]},
  {'label': 'stop', 'color': [0.96712, 0.62955, 0.52852]},
  {'label': 'stop_inverted', 'color': [0.48445, 0.84111, 0.01565]},
  {'label': 'three', 'color': [0.0, 0.0, 1.0]},
  {'label': 'three2', 'color': [0.54362, 0.96123, 0.9046]},
  {'label': 'two_up', 'color': [0.36779, 0.44128, 0.00059]},
  {'label': 'two_up_inverted', 'color': [0.97231, 0.10181, 0.4908]}]}</code></pre>
<p><strong>Export colormap</strong></p>
<div class="sourceCode" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the json module</span></span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the name of the file to which the color map will be written</span></span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a>color_map_file_name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>dataset_path<span class="sc">.</span>name<span class="sc">}</span><span class="ss">-colormap.json"</span></span>
<span id="cb140-6"><a href="#cb140-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-7"><a href="#cb140-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Open the file in write mode</span></span>
<span id="cb140-8"><a href="#cb140-8" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(color_map_file_name, <span class="st">"w"</span>) <span class="im">as</span> write_file:</span>
<span id="cb140-9"><a href="#cb140-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Write the color map to the file as JSON</span></span>
<span id="cb140-10"><a href="#cb140-10" aria-hidden="true" tabindex="-1"></a>    json.dump(color_map, write_file)</span>
<span id="cb140-11"><a href="#cb140-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb140-12"><a href="#cb140-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the name of the file that the color map was written to</span></span>
<span id="cb140-13"><a href="#cb140-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(color_map_file_name)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'hagrid-sample-30k-384p-colormap.json'</code></pre>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>We now have a template to train a YOLOX model using IceVision and export it to OpenVINO. We started by setting up a Conda environment and importing the necessary dependencies. Then, we configured the Kaggle API to download the dataset and created a parser to process the data. We defined DataLoader objects and fine-tuned the model before preparing it for export. We implemented post-processing steps for the model output and generated a colormap to visualize model predictions. In part 2, we will learn how to create a dynamic link library (DLL) file in Visual Studio to perform object detection with our YOLOX model using OpenVINO.</p>
<p><strong>Beginner Tutorial:</strong> <a href="../../fastai-to-unity-tutorial/part-1/">Fastai to Unity Beginner Tutorial Pt. 1</a></p>
<p><strong>Next:</strong> <a href="../part-2/">End-to-End Object Detection for Unity With IceVision and OpenVINO Pt. 2</a></p>
<p><strong>Alternative Next:</strong> <a href="../../onnx-directml-unity-tutorial/part-1/">Object Detection for Unity With ONNX Runtime and DirectML Pt. 1</a></p>
<p><strong>Project Resources:</strong> <a href="https://github.com/cj-mills/icevision-openvino-unity-tutorial">GitHub Repository</a></p>


</section>

</main> <!-- /main -->
<!-- Cloudflare Web Analytics --><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;56b8d2f624604c4891327b3c0d9f6703&quot;}"></script><!-- End Cloudflare Web Analytics -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="cj-mills/christianjmills" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2023, Christian J. Mills
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>