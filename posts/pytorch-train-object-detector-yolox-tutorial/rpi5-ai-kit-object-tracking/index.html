<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Christian Mills">
<meta name="dcterms.date" content="2024-10-15">
<meta name="description" content="Learn how to deploy a quantized YOLOX model on the Raspberry Pi 5 for real-time object detection and tracking using the Raspberry Pi AI Kit.">

<title>Deploying YOLOX for Real-Time Object Tracking on the Raspberry Pi AI Kit – Christian Mills</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-07ba0ad10f5680c660e360ac31d2f3b6.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-8b864f0777c60eecff11d75b6b2e1175.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-61f2d351c58b11e1d25c66c489878dfa.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-fb8cbff63e0d11b0ded76255c6f80362.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Deploying YOLOX for Real-Time Object Tracking on the Raspberry Pi AI Kit – Christian Mills">
<meta property="og:description" content="Learn how to deploy a quantized YOLOX model on the Raspberry Pi 5 for real-time object detection and tracking using the Raspberry Pi AI Kit.">
<meta property="og:image" content="https://christianjmills.com/images/default-preview-image-black.png">
<meta property="og:site_name" content="Christian Mills">
<meta property="og:image:height" content="284">
<meta property="og:image:width" content="526">
<meta name="twitter:title" content="Deploying YOLOX for Real-Time Object Tracking on the Raspberry Pi AI Kit – Christian Mills">
<meta name="twitter:description" content="Learn how to deploy a quantized YOLOX model on the Raspberry Pi 5 for real-time object detection and tracking using the Raspberry Pi AI Kit.">
<meta name="twitter:image" content="https://christianjmills.com/images/default-preview-image-black.png">
<meta name="twitter:creator" content="@cdotjdotmills">
<meta name="twitter:site" content="@cdotjdotmills">
<meta name="twitter:image-height" content="284">
<meta name="twitter:image-width" content="526">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Christian Mills</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/tutorials/index.html"> 
<span class="menu-text">Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/notes/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:christian@christianjmills.com"> <i class="bi bi-envelope-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cj-mills"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/cdotjdotmills"> <i class="bi bi-twitter-x" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/christianjmills"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../blog.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#prerequisites" id="toc-prerequisites" class="nav-link" data-scroll-target="#prerequisites">Prerequisites</a>
  <ul>
  <li><a href="#hardware" id="toc-hardware" class="nav-link" data-scroll-target="#hardware">Hardware</a></li>
  <li><a href="#software" id="toc-software" class="nav-link" data-scroll-target="#software">Software</a></li>
  <li><a href="#os" id="toc-os" class="nav-link" data-scroll-target="#os">OS</a></li>
  </ul></li>
  <li><a href="#compiling-our-model" id="toc-compiling-our-model" class="nav-link" data-scroll-target="#compiling-our-model">Compiling Our Model</a>
  <ul>
  <li><a href="#download-the-dataflow-compiler" id="toc-download-the-dataflow-compiler" class="nav-link" data-scroll-target="#download-the-dataflow-compiler">Download the Dataflow Compiler</a></li>
  <li><a href="#setting-up-a-python-environment" id="toc-setting-up-a-python-environment" class="nav-link" data-scroll-target="#setting-up-a-python-environment">Setting Up a Python Environment</a>
  <ul class="collapse">
  <li><a href="#install-mamba-package-manager" id="toc-install-mamba-package-manager" class="nav-link" data-scroll-target="#install-mamba-package-manager">Install Mamba Package Manager</a></li>
  <li><a href="#create-a-python-environment" id="toc-create-a-python-environment" class="nav-link" data-scroll-target="#create-a-python-environment">Create a Python Environment</a></li>
  <li><a href="#install-the-dataflow-compiler" id="toc-install-the-dataflow-compiler" class="nav-link" data-scroll-target="#install-the-dataflow-compiler">Install the Dataflow Compiler</a></li>
  <li><a href="#install-additional-dependencies" id="toc-install-additional-dependencies" class="nav-link" data-scroll-target="#install-additional-dependencies">Install Additional Dependencies</a></li>
  </ul></li>
  <li><a href="#getting-started-with-the-code" id="toc-getting-started-with-the-code" class="nav-link" data-scroll-target="#getting-started-with-the-code">Getting Started with the Code</a></li>
  <li><a href="#importing-the-required-dependencies" id="toc-importing-the-required-dependencies" class="nav-link" data-scroll-target="#importing-the-required-dependencies">Importing the Required Dependencies</a></li>
  <li><a href="#setting-up-the-project" id="toc-setting-up-the-project" class="nav-link" data-scroll-target="#setting-up-the-project">Setting Up the Project</a>
  <ul class="collapse">
  <li><a href="#set-the-directory-paths" id="toc-set-the-directory-paths" class="nav-link" data-scroll-target="#set-the-directory-paths">Set the Directory Paths</a></li>
  <li><a href="#download-a-font-file" id="toc-download-a-font-file" class="nav-link" data-scroll-target="#download-a-font-file">Download a Font File</a></li>
  </ul></li>
  <li><a href="#loading-the-checkpoint-data" id="toc-loading-the-checkpoint-data" class="nav-link" data-scroll-target="#loading-the-checkpoint-data">Loading the Checkpoint Data</a>
  <ul class="collapse">
  <li><a href="#load-the-colormap" id="toc-load-the-colormap" class="nav-link" data-scroll-target="#load-the-colormap">Load the Colormap</a></li>
  <li><a href="#set-model-checkpoint-information" id="toc-set-model-checkpoint-information" class="nav-link" data-scroll-target="#set-model-checkpoint-information">Set Model Checkpoint Information</a></li>
  </ul></li>
  <li><a href="#parsing" id="toc-parsing" class="nav-link" data-scroll-target="#parsing">Parsing</a>
  <ul class="collapse">
  <li><a href="#initialize-a-dataflow-compiler-api-client" id="toc-initialize-a-dataflow-compiler-api-client" class="nav-link" data-scroll-target="#initialize-a-dataflow-compiler-api-client">Initialize a Dataflow Compiler API client</a></li>
  <li><a href="#selecting-an-input-resolution" id="toc-selecting-an-input-resolution" class="nav-link" data-scroll-target="#selecting-an-input-resolution">Selecting an Input Resolution</a></li>
  <li><a href="#parse-the-onnx-model" id="toc-parse-the-onnx-model" class="nav-link" data-scroll-target="#parse-the-onnx-model">Parse the ONNX Model</a></li>
  <li><a href="#inspect-har-output-shape" id="toc-inspect-har-output-shape" class="nav-link" data-scroll-target="#inspect-har-output-shape">Inspect HAR Output Shape</a></li>
  <li><a href="#save-the-hailo-archive" id="toc-save-the-hailo-archive" class="nav-link" data-scroll-target="#save-the-hailo-archive">Save the Hailo Archive</a></li>
  <li><a href="#visualize-the-graph-structure" id="toc-visualize-the-graph-structure" class="nav-link" data-scroll-target="#visualize-the-graph-structure">Visualize the Graph Structure</a></li>
  </ul></li>
  <li><a href="#model-optimization" id="toc-model-optimization" class="nav-link" data-scroll-target="#model-optimization">Model Optimization</a>
  <ul class="collapse">
  <li><a href="#quantization-process" id="toc-quantization-process" class="nav-link" data-scroll-target="#quantization-process">Quantization Process</a></li>
  <li><a href="#set-the-dataset-path" id="toc-set-the-dataset-path" class="nav-link" data-scroll-target="#set-the-dataset-path">Set the Dataset Path</a></li>
  <li><a href="#download-the-dataset" id="toc-download-the-dataset" class="nav-link" data-scroll-target="#download-the-dataset">Download the Dataset</a></li>
  <li><a href="#get-image-file-paths" id="toc-get-image-file-paths" class="nav-link" data-scroll-target="#get-image-file-paths">Get Image File Paths</a></li>
  <li><a href="#select-sample-images" id="toc-select-sample-images" class="nav-link" data-scroll-target="#select-sample-images">Select Sample Images</a></li>
  <li><a href="#define-a-preprocessing-function" id="toc-define-a-preprocessing-function" class="nav-link" data-scroll-target="#define-a-preprocessing-function">Define a Preprocessing Function</a></li>
  <li><a href="#verify-the-preprocessing-function" id="toc-verify-the-preprocessing-function" class="nav-link" data-scroll-target="#verify-the-preprocessing-function">Verify the Preprocessing Function</a></li>
  <li><a href="#generate-a-calibration-dataset" id="toc-generate-a-calibration-dataset" class="nav-link" data-scroll-target="#generate-a-calibration-dataset">Generate a Calibration Dataset</a></li>
  <li><a href="#initialize-a-hailo-dataflow-compiler-api-client" id="toc-initialize-a-hailo-dataflow-compiler-api-client" class="nav-link" data-scroll-target="#initialize-a-hailo-dataflow-compiler-api-client">Initialize a Hailo Dataflow Compiler API Client</a></li>
  <li><a href="#quantize-the-hailo-archive" id="toc-quantize-the-hailo-archive" class="nav-link" data-scroll-target="#quantize-the-hailo-archive">Quantize the Hailo Archive</a></li>
  <li><a href="#save-the-quantized-hailo-archive" id="toc-save-the-quantized-hailo-archive" class="nav-link" data-scroll-target="#save-the-quantized-hailo-archive">Save the Quantized Hailo Archive</a></li>
  <li><a href="#define-functions-to-handle-arbitrary-input-resolutions" id="toc-define-functions-to-handle-arbitrary-input-resolutions" class="nav-link" data-scroll-target="#define-functions-to-handle-arbitrary-input-resolutions">Define Functions to Handle Arbitrary Input Resolutions</a></li>
  <li><a href="#define-postprocessing-functions" id="toc-define-postprocessing-functions" class="nav-link" data-scroll-target="#define-postprocessing-functions">Define Postprocessing Functions</a></li>
  <li><a href="#define-bounding-box-annotation-function" id="toc-define-bounding-box-annotation-function" class="nav-link" data-scroll-target="#define-bounding-box-annotation-function">Define Bounding Box Annotation Function</a></li>
  <li><a href="#initialize-a-hailo-dataflow-compiler-api-client-1" id="toc-initialize-a-hailo-dataflow-compiler-api-client-1" class="nav-link" data-scroll-target="#initialize-a-hailo-dataflow-compiler-api-client-1">Initialize a Hailo Dataflow Compiler API Client</a></li>
  <li><a href="#prepare-the-model-input" id="toc-prepare-the-model-input" class="nav-link" data-scroll-target="#prepare-the-model-input">Prepare the Model Input</a></li>
  <li><a href="#perform-inference-with-the-quantized-model" id="toc-perform-inference-with-the-quantized-model" class="nav-link" data-scroll-target="#perform-inference-with-the-quantized-model">Perform Inference with the Quantized Model</a></li>
  <li><a href="#process-the-model-output" id="toc-process-the-model-output" class="nav-link" data-scroll-target="#process-the-model-output">Process the Model Output</a></li>
  </ul></li>
  <li><a href="#compilation" id="toc-compilation" class="nav-link" data-scroll-target="#compilation">Compilation</a>
  <ul class="collapse">
  <li><a href="#compile-the-quantized-model" id="toc-compile-the-quantized-model" class="nav-link" data-scroll-target="#compile-the-quantized-model">Compile the Quantized Model</a></li>
  <li><a href="#run-the-profiler-tool" id="toc-run-the-profiler-tool" class="nav-link" data-scroll-target="#run-the-profiler-tool">Run the Profiler Tool</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#preparing-the-raspberry-pi" id="toc-preparing-the-raspberry-pi" class="nav-link" data-scroll-target="#preparing-the-raspberry-pi">Preparing the Raspberry Pi</a>
  <ul>
  <li><a href="#hailo-ai-kit-setup" id="toc-hailo-ai-kit-setup" class="nav-link" data-scroll-target="#hailo-ai-kit-setup">Hailo AI Kit Setup</a>
  <ul class="collapse">
  <li><a href="#ensure-the-raspberry-pi-is-fully-updated" id="toc-ensure-the-raspberry-pi-is-fully-updated" class="nav-link" data-scroll-target="#ensure-the-raspberry-pi-is-fully-updated">Ensure the Raspberry Pi is fully updated</a></li>
  <li><a href="#enable-pcie-gen-3.0" id="toc-enable-pcie-gen-3.0" class="nav-link" data-scroll-target="#enable-pcie-gen-3.0">Enable PCIe Gen 3.0</a></li>
  <li><a href="#install-ai-kit-dependencies" id="toc-install-ai-kit-dependencies" class="nav-link" data-scroll-target="#install-ai-kit-dependencies">Install AI Kit Dependencies</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#setting-up-a-python-virtual-environment" id="toc-setting-up-a-python-virtual-environment" class="nav-link" data-scroll-target="#setting-up-a-python-virtual-environment">Setting Up a Python Virtual Environment</a>
  <ul>
  <li><a href="#create-a-python-virtual-environment" id="toc-create-a-python-virtual-environment" class="nav-link" data-scroll-target="#create-a-python-virtual-environment">Create a Python Virtual Environment</a></li>
  <li><a href="#activate-python-virtual-environment" id="toc-activate-python-virtual-environment" class="nav-link" data-scroll-target="#activate-python-virtual-environment">Activate Python Virtual Environment</a></li>
  <li><a href="#install-demo-dependencies" id="toc-install-demo-dependencies" class="nav-link" data-scroll-target="#install-demo-dependencies">Install Demo Dependencies</a></li>
  </ul></li>
  <li><a href="#getting-started-with-the-code-1" id="toc-getting-started-with-the-code-1" class="nav-link" data-scroll-target="#getting-started-with-the-code-1">Getting Started with the Code</a></li>
  <li><a href="#importing-the-required-dependencies-1" id="toc-importing-the-required-dependencies-1" class="nav-link" data-scroll-target="#importing-the-required-dependencies-1">Importing the Required Dependencies</a></li>
  <li><a href="#define-utility-functions" id="toc-define-utility-functions" class="nav-link" data-scroll-target="#define-utility-functions">Define Utility Functions</a>
  <ul>
  <li><a href="#define-functions-to-handle-arbitrary-input-resolutions-1" id="toc-define-functions-to-handle-arbitrary-input-resolutions-1" class="nav-link" data-scroll-target="#define-functions-to-handle-arbitrary-input-resolutions-1">Define Functions to Handle Arbitrary Input Resolutions</a></li>
  <li><a href="#define-postprocessing-functions-1" id="toc-define-postprocessing-functions-1" class="nav-link" data-scroll-target="#define-postprocessing-functions-1">Define Postprocessing Functions</a></li>
  <li><a href="#define-bounding-box-annotation-function-1" id="toc-define-bounding-box-annotation-function-1" class="nav-link" data-scroll-target="#define-bounding-box-annotation-function-1">Define Bounding Box Annotation Function</a></li>
  </ul></li>
  <li><a href="#setting-up-the-project-1" id="toc-setting-up-the-project-1" class="nav-link" data-scroll-target="#setting-up-the-project-1">Setting Up the Project</a>
  <ul>
  <li><a href="#set-the-directory-paths-1" id="toc-set-the-directory-paths-1" class="nav-link" data-scroll-target="#set-the-directory-paths-1">Set the Directory Paths</a></li>
  <li><a href="#download-a-font-file-1" id="toc-download-a-font-file-1" class="nav-link" data-scroll-target="#download-a-font-file-1">Download a Font File</a></li>
  </ul></li>
  <li><a href="#loading-the-inference-resources" id="toc-loading-the-inference-resources" class="nav-link" data-scroll-target="#loading-the-inference-resources">Loading the Inference Resources</a>
  <ul>
  <li><a href="#load-the-colormap-1" id="toc-load-the-colormap-1" class="nav-link" data-scroll-target="#load-the-colormap-1">Load the Colormap</a></li>
  <li><a href="#load-the-compiled-hef-model" id="toc-load-the-compiled-hef-model" class="nav-link" data-scroll-target="#load-the-compiled-hef-model">Load the Compiled HEF Model</a></li>
  </ul></li>
  <li><a href="#tracking-objects-in-a-camera-feed" id="toc-tracking-objects-in-a-camera-feed" class="nav-link" data-scroll-target="#tracking-objects-in-a-camera-feed">Tracking Objects in a Camera Feed</a>
  <ul>
  <li><a href="#define-inference-parameters" id="toc-define-inference-parameters" class="nav-link" data-scroll-target="#define-inference-parameters">Define Inference Parameters</a></li>
  <li><a href="#detect-track-and-annotate-objects" id="toc-detect-track-and-annotate-objects" class="nav-link" data-scroll-target="#detect-track-and-annotate-objects">Detect, Track, and Annotate Objects</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Deploying YOLOX for Real-Time Object Tracking on the Raspberry Pi AI Kit</h1>
  <div class="quarto-categories">
    <div class="quarto-category">onnx</div>
    <div class="quarto-category">raspberry-pi</div>
    <div class="quarto-category">hailo</div>
    <div class="quarto-category">object-detection</div>
    <div class="quarto-category">object-tracking</div>
    <div class="quarto-category">yolox</div>
    <div class="quarto-category">tutorial</div>
  </div>
  </div>

<div>
  <div class="description">
    Learn how to deploy a quantized YOLOX model on the Raspberry Pi 5 for real-time object detection and tracking using the Raspberry Pi AI Kit.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Christian Mills </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 15, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This post is part of the following series:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../series/tutorials/pytorch-train-object-detector-yolox-series.html"><strong>Training YOLOX Models for Real-Time Object Detection in PyTorch</strong></a></li>
</ul>
</div>
</div>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#prerequisites">Prerequisites</a><br>
</li>
<li><a href="#compiling-our-model">Compiling Our Model</a><br>
</li>
<li><a href="#preparing-the-raspberry-pi">Preparing the Raspberry Pi</a><br>
</li>
<li><a href="#setting-up-a-python-virtual-environment">Setting Up a Python Virtual Environment</a><br>
</li>
<li><a href="#getting-started-with-the-code-1">Getting Started with the Code</a></li>
<li><a href="#importing-the-required-dependencies-1">Importing the Required Dependencies</a></li>
<li><a href="#define-utility-functions">Define Utility Functions</a><br>
</li>
<li><a href="#setting-up-the-project-1">Setting Up the Project</a><br>
</li>
<li><a href="#loading-the-inference-resources">Loading the Inference Resources</a><br>
</li>
<li><a href="#tracking-objects-in-a-camera-feed">Tracking Objects in a Camera Feed</a><br>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome back to this series on real-time object detection with YOLOX. So far, this series has covered how to:</p>
<ul>
<li>Finetune a YOLOX model in PyTorch to detect hand signs.</li>
<li>Export the finetuned model to ONNX.</li>
<li>Use the ByteTrack object tracker to track objects across video frames.</li>
</ul>
<p>This post builds on those past tutorials by walking through deploying our model on a <a href="https://www.raspberrypi.com/products/raspberry-pi-5/">Raspberry Pi 5</a> to perform real-time object tracking from a camera feed using the <a href="https://www.raspberrypi.com/products/ai-kit/">Raspberry Pi AI Kit</a>.</p>
<p>Released in June 2024, the AI Kit uses the <a href="https://hailo.ai/products/ai-accelerators/hailo-8l-ai-accelerator-for-ai-light-applications/">Hailo-8L accelerator</a> from <a href="https://hailo.ai/">Hailo AI</a>. The Hailo-8L can perform 13 tera-operations per second (TOPS), making it suitable for lightweight real-time inference on edge devices.</p>
<p>Whether you are working with the pre-trained hand-sign detector used in this series or a custom model, real-time object tracking with the Raspberry Pi AI Kit opens up many possibilities for edge applications.</p>
</section>
<section id="prerequisites" class="level2">
<h2 class="anchored" data-anchor-id="prerequisites">Prerequisites</h2>
<p>Before diving into the tutorial, there are some prerequisites to cover.</p>
<section id="hardware" class="level3">
<h3 class="anchored" data-anchor-id="hardware">Hardware</h3>
<p>The code for this tutorial assumes the Raspberry Pi has an attached <a href="https://en.wikipedia.org/wiki/Camera_Serial_Interface">CSI</a> camera.</p>
<p>The Raspberry Pi 5 has 22-pin MIPI CSI camera connectors. If your CSI camera module uses a 15-pin connector, you will need a 15-pin to 22-pin adapter cable. You can order a pack of 3 on Amazon at the link below:</p>
<ul>
<li><a href="https://www.amazon.com/Arducam-Raspberry-Camera-Ribbon-Extension/dp/B085RW9K13">Arducam for Raspberry Pi Zero Camera Cable Set, 1.5” 2.87” 5.9” Ribbon Flex Extension Cables for Pi Zero&amp;W, Pack of 3</a></li>
</ul>
</section>
<section id="software" class="level3">
<h3 class="anchored" data-anchor-id="software">Software</h3>
<p>This tutorial uses the <a href="https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-dc">Dataflow Compiler</a> (DFC) Python package, available through the <a href="https://hailo.ai/developer-zone/">Hailo AI Developer Zone</a>. At the time of writing, you must create an account to access this Python package and the associated documentation. You can create a Developer Zone account at the link below:</p>
<ul>
<li><a href="https://hailo.ai/developer-zone/request-access/">Hailo AI Developer Zone - Request Access</a></li>
</ul>
</section>
<section id="os" class="level3">
<h3 class="anchored" data-anchor-id="os">OS</h3>
<p>At the time of writing, Hailo AI only supports the Dataflow Compiler Python package on x86 Linux platforms. If you are on Windows, you can run the conversion process through <a href="https://learn.microsoft.com/en-us/windows/wsl/about">WSL</a>.</p>
</section>
</section>
<section id="compiling-our-model" class="level2">
<h2 class="anchored" data-anchor-id="compiling-our-model">Compiling Our Model</h2>
<p>We must first compile our YOLOX model for the Hailo-8L accelerator before running it on the AI Kit. The compilation process consists of the following steps:</p>
<ol type="1">
<li>Convert the ONNX model into a Hailo-compatible representation. (<a href="https://hailo.ai/developer-zone/documentation/v3-29-0/?sp_referrer=tutorials_notebooks%2Fnotebooks%2FDFC_1_Parsing_Tutorial.html">link</a>)</li>
<li>Quantize the Hailo-compatible representation into an 8-bit model. (<a href="https://hailo.ai/developer-zone/documentation/v3-29-0/?page=tutorials_notebooks%2Fnotebooks%2FDFC_2_Model_Optimization_Tutorial.html">link</a>)</li>
<li>Compile the 8-bit model into an HEF binary file for the Hailo-8L accelerator. (<a href="https://hailo.ai/developer-zone/documentation/v3-29-0/?sp_referrer=tutorials_notebooks%2Fnotebooks%2FDFC_3_Compilation_Tutorial.html">link</a>)</li>
</ol>
<p>We use the <a href="https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-dc">Dataflow Compiler</a> package provided by Hailo AI to perform these steps:</p>
<ul>
<li><a href="https://hailo.ai/developer-zone/documentation/v3-29-0/">Developer Zone - Dataflow Compiler User Guide</a></li>
</ul>
<section id="download-the-dataflow-compiler" class="level3">
<h3 class="anchored" data-anchor-id="download-the-dataflow-compiler">Download the Dataflow Compiler</h3>
<p>You can download the Dataflow Compiler Python wheel file from the Software Downloads page in the Hailo AI Developer Zone at the page linked below:</p>
<ul>
<li><a href="https://hailo.ai/developer-zone/software-downloads/">Developer Zone - Software Downloads</a></li>
</ul>
<p>In the selection interface, choose the following options:</p>
<ul>
<li><strong>Select Product:</strong> <code>ACCELERATORS</code></li>
<li><strong>Software Package:</strong> <code>AI Software Suite</code></li>
<li><strong>Software Sub-Package:</strong> <code>Dataflow Compiler</code></li>
<li><strong>Architecture:</strong> <code>x86</code></li>
<li><strong>OS:</strong> <code>Linux</code></li>
<li><strong>Python Version:</strong> <code>3.10</code></li>
</ul>
</section>
<section id="setting-up-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-a-python-environment">Setting Up a Python Environment</h3>
<p>After downloading the Dataflow Compiler, we can set up our Python environment.</p>
<section id="install-mamba-package-manager" class="level4">
<h4 class="anchored" data-anchor-id="install-mamba-package-manager">Install Mamba Package Manager</h4>
<p>As with previous tutorials in this series, we will use the Mamba package manager to create and manage our Python environment.</p>
<p>If you do not have it installed, run the following bash commands to download the latest release, install it, and relaunch the current bash shell to apply the relevant changes:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the latest Miniforge3 installer for the current OS and architecture</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> <span class="st">"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-</span><span class="va">$(</span><span class="fu">uname</span><span class="va">)</span><span class="st">-</span><span class="va">$(</span><span class="fu">uname</span> <span class="at">-m</span><span class="va">)</span><span class="st">.sh"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the Miniforge3 installer silently (-b flag for batch mode)</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span> Miniforge3-<span class="va">$(</span><span class="fu">uname</span><span class="va">)</span>-<span class="va">$(</span><span class="fu">uname</span> <span class="at">-m</span><span class="va">)</span>.sh <span class="at">-b</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize mamba for shell usage</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="ex">~/miniforge3/bin/mamba</span> init</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Restart the shell to apply changes</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="create-a-python-environment" class="level4">
<h4 class="anchored" data-anchor-id="create-a-python-environment">Create a Python Environment</h4>
<p>Next, we will create and activate a Python 3.10 environment.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> create <span class="at">--name</span> hailo-compiler-env python=3.10 <span class="at">-y</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> activate hailo-compiler-env</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="install-the-dataflow-compiler" class="level4">
<h4 class="anchored" data-anchor-id="install-the-dataflow-compiler">Install the Dataflow Compiler</h4>
<p>We can install the Dataflow Compiler package once inside the mamba environment.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install hailo_dataflow_compiler-3.29.0-py3-none-linux_x86_64.whl</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="install-additional-dependencies" class="level4">
<h4 class="anchored" data-anchor-id="install-additional-dependencies">Install Additional Dependencies</h4>
<p>We will install a few additional dependencies for the conversion process to wrap up our environment setup.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install cjm_psl_utils cjm_pil_utils</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="getting-started-with-the-code" class="level3">
<h3 class="anchored" data-anchor-id="getting-started-with-the-code">Getting Started with the Code</h3>
<p>This tutorial walks through the conversion process in a Jupyter Notebook, which is available at the link below:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Jupyter Notebook</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/cj-mills/pytorch-yolox-object-detection-tutorial-code/blob/main/notebooks/pytorch-yolox-object-detector-hailo-export.ipynb">pytorch-yolox-object-detector-hailo-export.ipynb</a></td>
</tr>
</tbody>
</table>
</section>
<section id="importing-the-required-dependencies" class="level3">
<h3 class="anchored" data-anchor-id="importing-the-required-dependencies">Importing the Required Dependencies</h3>
<p>First, we will import the necessary Python packages.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import Python Standard Library dependencies</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> subprocess</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Tuple, Optional, NamedTuple</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Import third-party libraries</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image, ImageDraw, ImageFont</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Import ONNX</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> onnx</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Import Hailo SDK dependencies</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hailo_sdk_client <span class="im">import</span> ClientRunner, InferenceContext, CalibrationDataType</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hailo_sdk_client.exposed_definitions <span class="im">import</span> SUPPORTED_HW_ARCHS</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Import utility functions</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cjm_psl_utils.core <span class="im">import</span> download_file, file_extract</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cjm_pil_utils.core <span class="im">import</span> resize_img, get_img_files</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cjm_pil_utils.annotation <span class="im">import</span> draw_bboxes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="setting-up-the-project" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-the-project">Setting Up the Project</h3>
<section id="set-the-directory-paths" class="level4">
<h4 class="anchored" data-anchor-id="set-the-directory-paths">Set the Directory Paths</h4>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The name for the project</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>project_name <span class="op">=</span> <span class="ss">f"pytorch-yolox-object-detector"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The path for the project folder</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>project_dir <span class="op">=</span> Path(<span class="ss">f"./</span><span class="sc">{</span>project_name<span class="sc">}</span><span class="ss">/"</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the project directory if it does not already exist</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>project_dir.mkdir(parents<span class="op">=</span><span class="va">True</span>, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># The path to the checkpoint folder</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>checkpoint_dir <span class="op">=</span> Path(project_dir<span class="op">/</span><span class="ss">f"2024-09-08_19-22-32"</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>pd.Series({</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Project Directory:"</span>: project_dir,</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Checkpoint Directory:"</span>: checkpoint_dir,</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>}).to_frame().style.hide(axis<span class="op">=</span><span class="st">'columns'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table id="T_982ee">
<thead>
</thead>
<tbody>
<tr>
<th id="T_982ee_level0_row0" class="row_heading level0 row0">
Project Directory:
</th>
<td id="T_982ee_row0_col0" class="data row0 col0">
pytorch-yolox-object-detector
</td>
</tr>
<tr>
<th id="T_982ee_level0_row1" class="row_heading level0 row1">
Checkpoint Directory:
</th>
<td id="T_982ee_row1_col0" class="data row1 col0">
pytorch-yolox-object-detector/2024-09-08_19-22-32
</td>
</tr>
</tbody>
</table>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Sample Files:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Sample Files:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>I made an ONNX model available on Hugging Face Hub with a colormap file in the repository linked below:
<ul>
<li><a href="https://huggingface.co/cj-mills/yolox-hagrid-onnx/tree/main">cj-mills/yolox-hagrid-onnx</a></li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="download-a-font-file" class="level4">
<h4 class="anchored" data-anchor-id="download-a-font-file">Download a Font File</h4>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the name of the font file</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>font_file <span class="op">=</span> <span class="st">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the font file</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>download_file(<span class="ss">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc">{</span>font_file<span class="sc">}</span><span class="ss">"</span>, <span class="st">"./"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="loading-the-checkpoint-data" class="level3">
<h3 class="anchored" data-anchor-id="loading-the-checkpoint-data">Loading the Checkpoint Data</h3>
<section id="load-the-colormap" class="level4">
<h4 class="anchored" data-anchor-id="load-the-colormap">Load the Colormap</h4>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The colormap path</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>colormap_path <span class="op">=</span> <span class="bu">list</span>(checkpoint_dir.glob(<span class="st">'*colormap.json'</span>))[<span class="dv">0</span>]</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the JSON colormap data</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(colormap_path, <span class="st">'r'</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        colormap_json <span class="op">=</span> json.load(<span class="bu">file</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the JSON data to a dictionary        </span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>colormap_dict <span class="op">=</span> {item[<span class="st">'label'</span>]: item[<span class="st">'color'</span>] <span class="cf">for</span> item <span class="kw">in</span> colormap_json[<span class="st">'items'</span>]}</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the class names from the colormap</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> <span class="bu">list</span>(colormap_dict.keys())</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a copy of the colormap in integer format</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>int_colors <span class="op">=</span> [<span class="bu">tuple</span>(<span class="bu">int</span>(c<span class="op">*</span><span class="dv">255</span>) <span class="cf">for</span> c <span class="kw">in</span> color) <span class="cf">for</span> color <span class="kw">in</span> colormap_dict.values()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="set-model-checkpoint-information" class="level4">
<h4 class="anchored" data-anchor-id="set-model-checkpoint-information">Set Model Checkpoint Information</h4>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The onnx model path</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>onnx_file_path <span class="op">=</span> <span class="bu">list</span>(checkpoint_dir.glob(<span class="st">'*.onnx'</span>))[<span class="dv">0</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set max stride value for processing output</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>max_stride <span class="op">=</span> <span class="dv">32</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="parsing" class="level3">
<h3 class="anchored" data-anchor-id="parsing">Parsing</h3>
<p>The first step in the conversion process is to parse our ONNX model to the Hailo Archive (HAR) format. This HAR file will contain the graph structure and weights for the model used by the Hailo Runtime (<a href="https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-hailort">HailoRT</a>).</p>
<section id="initialize-a-dataflow-compiler-api-client" class="level4">
<h4 class="anchored" data-anchor-id="initialize-a-dataflow-compiler-api-client">Initialize a Dataflow Compiler API client</h4>
<p>We parse the ONNX model using a Dataflow Compiler API client. We must specify the target Hailo accelerator when initializing the client. The SUPPORTED_HW_ARCHS constant stores the list of valid hardware architecture names.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display supported hardware architectures</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>SUPPORTED_HW_ARCHS</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>['hailo8',
 'hailo8r',
 'hailo8l',
 'hailo15h',
 'hailo15m',
 'hailo15l',
 'hailo10h']</code></pre>
<p>For the Hailo-8L, we pass in hailo8l for the hardware architecture parameter.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a Dataflow Compiler API client</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>runner <span class="op">=</span> ClientRunner(hw_arch<span class="op">=</span><span class="st">"hailo8l"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="selecting-an-input-resolution" class="level4">
<h4 class="anchored" data-anchor-id="selecting-an-input-resolution">Selecting an Input Resolution</h4>
<p>HailoRT does not support dynamic input resolutions, so we must specify one when parsing the model.</p>
<p>I will use the <a href="https://www.raspberrypi.com/products/camera-module-3/">Raspberry Pi Camera Module 3</a> for the demo, which has a <code>16:9</code> aspect ratio. Also, remember that the YOLOX model expects the input dimensions to be multiples of <code>32</code>.</p>
<p>Based on those constraints, I will use a resolution of <code>height:512 x width:288</code> for the input.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the input resolution for the model</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>input_sz <span class="op">=</span> (<span class="dv">512</span>, <span class="dv">288</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="parse-the-onnx-model" class="level4">
<h4 class="anchored" data-anchor-id="parse-the-onnx-model">Parse the ONNX Model</h4>
<p>After deciding on an input resolution, we can parse the ONNX model using the <a href="https://hailo.ai/developer-zone/documentation/v3-29-0/?sp_referrer=api%2Fbuild_api.html#hailo_sdk_client.runner.client_runner.ClientRunner.translate_onnx_model"><code>translate_onnx_model</code></a> method. We specify the path to the ONNX model, model name, input and output nodes, and input shape in <code>[batch_size, channels, height, width]</code> format.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parse the ONNX Model</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This step translates the ONNX model to a format compatible with Hailo hardware</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>hn, npz <span class="op">=</span> runner.translate_onnx_model(</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">str</span>(onnx_file_path),</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    onnx_file_path.stem,  <span class="co"># Use the filename (without extension) as the model name</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    start_node_names<span class="op">=</span>[<span class="st">"input"</span>],  <span class="co"># Specify the input node name</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    end_node_names<span class="op">=</span>[<span class="st">'output'</span>],  <span class="co"># Specify the output node name</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    net_input_shapes<span class="op">=</span>{<span class="st">"input"</span>: [<span class="dv">1</span>, <span class="dv">3</span>, <span class="op">*</span>input_sz[::<span class="op">-</span><span class="dv">1</span>]]},  <span class="co"># Define input shape: [batch_size, channels, height, width]</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[info] Translation started on ONNX model hagrid-sample-30k-384p-yolox_tiny
[info] Restored ONNX model hagrid-sample-30k-384p-yolox_tiny (completion time: 00:00:00.06)
[info] Extracted ONNXRuntime meta-data for Hailo model (completion time: 00:00:00.19)
[info] NMS structure of yolox (or equivalent architecture) was detected.
[info] In order to use HailoRT post-processing capabilities, these end node names should be used: /Sigmoid /Sigmoid_1 /model/bbox_head/multi_level_conv_reg.0/Conv /Sigmoid_2 /Sigmoid_3 /model/bbox_head/multi_level_conv_reg.1/Conv /Sigmoid_4 /Sigmoid_5 /model/bbox_head/multi_level_conv_reg.2/Conv.
[info] Start nodes mapped from original model: 'input': 'hagrid-sample-30k-384p-yolox_tiny/input_layer1'.
[info] End nodes mapped from original model: '/Transpose'.
[info] Translation completed on ONNX model hagrid-sample-30k-384p-yolox_tiny (completion time: 00:00:00.72)</code></pre>
</section>
<section id="inspect-har-output-shape" class="level4">
<h4 class="anchored" data-anchor-id="inspect-har-output-shape">Inspect HAR Output Shape</h4>
<p>If we compare the input and output shapes of the Hailo Archive to the original ONNX model, we can see the <code>translate_onnx_model</code> method converted the model to a channels-last format. We must account for this when processing the model output during inference.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get input and output shapes from the Hailo Archive (HAR)</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>har_input_shape <span class="op">=</span> runner.get_hn_dict()[<span class="st">'layers'</span>][<span class="st">'hagrid-sample-30k-384p-yolox_tiny/input_layer1'</span>][<span class="st">'input_shapes'</span>][<span class="dv">0</span>]</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>har_output_shape <span class="op">=</span> runner.get_hn_dict()[<span class="st">'layers'</span>][<span class="st">'hagrid-sample-30k-384p-yolox_tiny/output_layer1'</span>][<span class="st">'output_shapes'</span>][<span class="dv">0</span>]</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the original ONNX model</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>onnx_model <span class="op">=</span> onnx.load_model(onnx_file_path)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract input and output shapes from the ONNX model</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>onnx_input_shape <span class="op">=</span> [dim.dim_value <span class="cf">for</span> dim <span class="kw">in</span> onnx_model.graph.<span class="bu">input</span>[<span class="dv">0</span>].<span class="bu">type</span>.tensor_type.shape.dim]</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>onnx_output_shape <span class="op">=</span> [dim.dim_value <span class="cf">for</span> dim <span class="kw">in</span> onnx_model.graph.output[<span class="dv">0</span>].<span class="bu">type</span>.tensor_type.shape.dim]</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame to compare ONNX and HAR shapes</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">"ONNX"</span>: {<span class="st">"input_shape:"</span>:onnx_input_shape, <span class="st">"output_shape:"</span>: onnx_output_shape},</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>              <span class="st">"HAR"</span>: {<span class="st">"input_shape:"</span>:har_input_shape, <span class="st">"output_shape:"</span>: har_output_shape}})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
ONNX
</th>
<th>
HAR
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
input_shape:
</th>
<td>
[1, 3, 0, 0]
</td>
<td>
[-1, 288, 512, 3]
</td>
</tr>
<tr>
<th>
output_shape:
</th>
<td>
[1, 0, 24]
</td>
<td>
[-1, 1, 24, 3024]
</td>
</tr>
</tbody>
</table>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The zeros in the onnx shapes indicate dynamic axes.</p>
</div>
</div>
</section>
<section id="save-the-hailo-archive" class="level4">
<h4 class="anchored" data-anchor-id="save-the-hailo-archive">Save the Hailo Archive</h4>
<p>We can then save the Hailo Archive using the <a href="https://hailo.ai/developer-zone/documentation/v3-29-0/?sp_referrer=api%2Fbuild_api.html#hailo_sdk_client.runner.client_runner.ClientRunner.save_har"><code>save_har</code></a> method.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the Hailo Archive (HAR) file</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>hailo_model_har_name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>onnx_file_path<span class="sc">.</span>stem<span class="sc">}</span><span class="ss">_hailo_model.har"</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>hailo_model_har_path <span class="op">=</span> onnx_file_path.parent<span class="op">/</span>hailo_model_har_name</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>runner.save_har(hailo_model_har_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[info] Saved HAR to: /mnt/ACASIS_4TB/Projects/GitHub/pytorch-yolox-object-detection-tutorial-code/notebooks/pytorch-yolox-object-detector/2024-09-08_19-22-32/hagrid-sample-30k-384p-yolox_tiny_hailo_model.har</code></pre>
</section>
<section id="visualize-the-graph-structure" class="level4">
<h4 class="anchored" data-anchor-id="visualize-the-graph-structure">Visualize the Graph Structure</h4>
<p>After saving the HAR file, we can visualize its graph structure using the Hailo visualizer tool. The visualizer tool creates an SVG of the graph that we can optionally view in the browser.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the Graph Structure</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>hailo visualizer {hailo_model_har_path} <span class="op">--</span>no<span class="op">-</span>browser</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[[32minfo[0m] Current Time: 12:00:34, 10/14/24
[[32minfo[0m] CPU: Architecture: x86_64, Model: 11th Gen Intel(R) Core(TM) i7-11700K @ 3.60GHz, Number Of Cores: 16, Utilization: 5.2%
[[32minfo[0m] Memory: Total: 31GB, Available: 20GB
[[32minfo[0m] System info: OS: Linux, Kernel: 6.8.0-45-generic
[[32minfo[0m] Hailo DFC Version: 3.29.0
[[32minfo[0m] HailoRT Version: Not Installed
[[32minfo[0m] PCIe: No Hailo PCIe device was found
[[32minfo[0m] Running `hailo visualizer pytorch-yolox-object-detector/2024-09-08_19-22-32/hagrid-sample-30k-384p-yolox_tiny_hailo_model.har --no-browser`</code></pre>
<p>Now that we have our Hailo Archive file, we can move on to the optimization step.</p>
</section>
</section>
<section id="model-optimization" class="level3">
<h3 class="anchored" data-anchor-id="model-optimization">Model Optimization</h3>
<p>The optimization process involves converting our full-precision HAR file to a quantized 8-bit HAR file.</p>
<section id="quantization-process" class="level4">
<h4 class="anchored" data-anchor-id="quantization-process">Quantization Process</h4>
<p>Quantizing our model involves converting the original 32-bit floating point (float32) values to 8-bit integer (int8) values. Float32 precision allows for a significantly greater range of possible values versus int8. To find the optimal mapping from float32 to int8, we must compute the range of float32 values present in the model.</p>
<p>The float32 values in our model fall into two categories:</p>
<ol type="1">
<li>Model weights: Static values that do not change after training.</li>
<li>Activation values: Dynamic values that depend on the input fed to the model and change during inference.</li>
</ol>
<p>To accurately quantize both weights and activations, we need to:</p>
<ol type="1">
<li>Analyze the range of weight values across the entire model.</li>
<li>Estimate a suitable range for activation values by feeding sample inputs through the model and recording the resulting activations. This process generates what we call calibration data.</li>
</ol>
<p>The Dataflow Compiler handles this process for us. It determines the best way to map the original float32 values to int8, aiming to preserve model accuracy while reducing its size and computational requirements. All we need to provide is the calibration data.</p>
<p>We will use a subset of images from the original training dataset to generate this calibration data. This approach ensures that our quantized model can handle the types of inputs it is likely to encounter in real-world usage.</p>
<p>By quantizing our model in this way, we can significantly reduce its memory footprint and increase its inference speed, often with minimal loss in accuracy.</p>
</section>
<section id="set-the-dataset-path" class="level4">
<h4 class="anchored" data-anchor-id="set-the-dataset-path">Set the Dataset Path</h4>
<p>We first need to construct the name for the Hugging Face Hub dataset and define where to download and extract the dataset.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define path to store datasets</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>dataset_dir <span class="op">=</span> Path(<span class="st">"/mnt/Storage/Datasets"</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the dataset directory if it does not exist</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>dataset_dir.mkdir(parents<span class="op">=</span><span class="va">True</span>, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define path to store archive files</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>archive_dir <span class="op">=</span> dataset_dir<span class="op">/</span><span class="st">'../Archive'</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the archive directory if it does not exist</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>archive_dir.mkdir(parents<span class="op">=</span><span class="va">True</span>, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the name of the dataset</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>dataset_name <span class="op">=</span> <span class="st">'hagrid-sample-30k-384p'</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct the HuggingFace Hub dataset name by combining the username and dataset name</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>hf_dataset <span class="op">=</span> <span class="ss">f'cj-mills/</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the path to the zip file that contains the dataset</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>archive_path <span class="op">=</span> Path(<span class="ss">f'</span><span class="sc">{</span>archive_dir<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">.zip'</span>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the path to the directory where the dataset will be extracted</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>dataset_path <span class="op">=</span> Path(<span class="ss">f'</span><span class="sc">{</span>dataset_dir<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>pd.Series({</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"HuggingFace Dataset:"</span>: hf_dataset, </span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Archive Path:"</span>: archive_path, </span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Dataset Path:"</span>: dataset_path</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>}).to_frame().style.hide(axis<span class="op">=</span><span class="st">'columns'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<style type="text/css">
</style>
<table id="T_dcb5a">
<thead>
</thead>
<tbody>
<tr>
<th id="T_dcb5a_level0_row0" class="row_heading level0 row0">
HuggingFace Dataset:
</th>
<td id="T_dcb5a_row0_col0" class="data row0 col0">
cj-mills/hagrid-sample-30k-384p
</td>
</tr>
<tr>
<th id="T_dcb5a_level0_row1" class="row_heading level0 row1">
Archive Path:
</th>
<td id="T_dcb5a_row1_col0" class="data row1 col0">
/mnt/Storage/Datasets/../Archive/hagrid-sample-30k-384p.zip
</td>
</tr>
<tr>
<th id="T_dcb5a_level0_row2" class="row_heading level0 row2">
Dataset Path:
</th>
<td id="T_dcb5a_row2_col0" class="data row2 col0">
/mnt/Storage/Datasets/hagrid-sample-30k-384p
</td>
</tr>
</tbody>
</table>
</section>
<section id="download-the-dataset" class="level4">
<h4 class="anchored" data-anchor-id="download-the-dataset">Download the Dataset</h4>
<p>We can now download the dataset archive file and extract the dataset. We can delete the archive afterward to save space.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct the HuggingFace Hub dataset URL</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>dataset_url <span class="op">=</span> <span class="ss">f"https://huggingface.co/datasets/</span><span class="sc">{</span>hf_dataset<span class="sc">}</span><span class="ss">/resolve/main/</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">.zip"</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"HuggingFace Dataset URL: </span><span class="sc">{</span>dataset_url<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Set whether to delete the archive file after extracting the dataset</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>delete_archive <span class="op">=</span> <span class="va">True</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the dataset if not present</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dataset_path.is_dir():</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Dataset folder already exists"</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Downloading dataset..."</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    download_file(dataset_url, archive_dir)    </span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Extracting dataset..."</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    file_extract(fname<span class="op">=</span>archive_path, dest<span class="op">=</span>dataset_dir)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Delete the archive if specified</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> delete_archive: archive_path.unlink()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>HuggingFace Dataset URL: https://huggingface.co/datasets/cj-mills/hagrid-sample-30k-384p/resolve/main/hagrid-sample-30k-384p.zip
Dataset folder already exists</code></pre>
</section>
<section id="get-image-file-paths" class="level4">
<h4 class="anchored" data-anchor-id="get-image-file-paths">Get Image File Paths</h4>
<p>Once downloaded, we can get the paths to the images in the dataset.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a list of all JPG image files in the dataset</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>img_file_paths <span class="op">=</span> <span class="bu">list</span>(dataset_path.glob(<span class="st">"./**/*.jpg"</span>))</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the number of image files</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of Images: </span><span class="sc">{</span><span class="bu">len</span>(img_file_paths)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first five entries from the dictionary using a Pandas DataFrame</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(img_file_paths).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Number of Images: 31833</code></pre>
<div style="overflow-x:auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
/mnt/Storage/Datasets/hagrid-sample-30k-384p/hagrid_30k/train_val_call/00005c9c-3548-4a8f-9d0b-2dd4aff37fc9.jpg
</td>
</tr>
<tr>
<th>
1
</th>
<td>
/mnt/Storage/Datasets/hagrid-sample-30k-384p/hagrid_30k/train_val_call/0020a3db-82d8-47aa-8642-2715d4744db5.jpg
</td>
</tr>
<tr>
<th>
2
</th>
<td>
/mnt/Storage/Datasets/hagrid-sample-30k-384p/hagrid_30k/train_val_call/004ac93f-0f7c-49a4-aadc-737e0ad4273c.jpg
</td>
</tr>
<tr>
<th>
3
</th>
<td>
/mnt/Storage/Datasets/hagrid-sample-30k-384p/hagrid_30k/train_val_call/006cac69-d3f0-47f9-aac9-38702d038ef1.jpg
</td>
</tr>
<tr>
<th>
4
</th>
<td>
/mnt/Storage/Datasets/hagrid-sample-30k-384p/hagrid_30k/train_val_call/00973fac-440e-4a56-b60c-2a06d5fb155d.jpg
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="select-sample-images" class="level4">
<h4 class="anchored" data-anchor-id="select-sample-images">Select Sample Images</h4>
<p>Using every image in the dataset for the calibration process would be unnecessary and time-consuming, so we’ll select a random subset. The Dataflow Compiler documentation recommends at least <code>1024</code> samples.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">1234</span>) <span class="co"># Set random seed for consistency </span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>sample_img_paths <span class="op">=</span> random.sample(img_file_paths, <span class="dv">1024</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="define-a-preprocessing-function" class="level4">
<h4 class="anchored" data-anchor-id="define-a-preprocessing-function">Define a Preprocessing Function</h4>
<p>Now that we have our sample images, we will create a function to ensure they are in the expected format for the optimization process.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preproc(image, output_height, output_width, resize_side):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co">    This function resizes the input image while maintaining its aspect ratio,</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co">    crops (or pads) it to the desired output size, and normalizes pixel values</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">    to the range [0, 1].</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co">        image (PIL.Image.Image or np.ndarray): The input image to preprocess.</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">        output_height (int): The desired output height of the image.</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co">        output_width (int): The desired output width of the image.</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co">        resize_side (int): The size to which the smallest side of the image is resized.</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co">        np.ndarray: The preprocessed image as a NumPy array of shape (output_height, output_width, 3),</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co">                    with pixel values normalized to the range [0, 1].</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure the image is a NumPy array</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(image, Image.Image):</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert PIL Image to NumPy array</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> np.array(image)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the original image dimensions</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>    h, w <span class="op">=</span> image.shape[:<span class="dv">2</span>]  <span class="co"># h = height, w = width</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the scaling factor to resize the image</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We want the smallest side to be 'resize_side' pixels</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    scale <span class="op">=</span> resize_side <span class="op">/</span> <span class="bu">min</span>(h, w)</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the new image dimensions after resizing</span></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>    new_h <span class="op">=</span> <span class="bu">int</span>(h <span class="op">*</span> scale)</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    new_w <span class="op">=</span> <span class="bu">int</span>(w <span class="op">*</span> scale)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resize the image using bilinear interpolation for smoother results</span></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the NumPy array back to a PIL Image for resizing</span></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>    resized_image <span class="op">=</span> Image.fromarray(image).resize((new_w, new_h), Image.BILINEAR)</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the resized image back to a NumPy array</span></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>    resized_image <span class="op">=</span> np.array(resized_image)</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate coordinates for center cropping</span></span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We want to crop the center 'output_height' x 'output_width' area</span></span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>    top <span class="op">=</span> (new_h <span class="op">-</span> output_height) <span class="op">//</span> <span class="dv">2</span>  <span class="co"># Starting y-coordinate</span></span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>    left <span class="op">=</span> (new_w <span class="op">-</span> output_width) <span class="op">//</span> <span class="dv">2</span>  <span class="co"># Starting x-coordinate</span></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>    bottom <span class="op">=</span> top <span class="op">+</span> output_height        <span class="co"># Ending y-coordinate</span></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>    right <span class="op">=</span> left <span class="op">+</span> output_width         <span class="co"># Ending x-coordinate</span></span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if we need to pad the image (if the crop area extends beyond the image boundaries)</span></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> top <span class="op">&lt;</span> <span class="dv">0</span> <span class="kw">or</span> left <span class="op">&lt;</span> <span class="dv">0</span>:</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate how much padding is needed on each side</span></span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>        pad_top <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, <span class="op">-</span>top)                <span class="co"># Positive value indicates padding needed</span></span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>        pad_bottom <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, bottom <span class="op">-</span> new_h)   <span class="co"># Padding needed at the bottom</span></span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>        pad_left <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, <span class="op">-</span>left)              <span class="co"># Padding needed on the left</span></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>        pad_right <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, right <span class="op">-</span> new_w)     <span class="co"># Padding needed on the right</span></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pad the image with zeros (black pixels) on each side</span></span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The padding tuple format is ((top, bottom), (left, right), (channel_start, channel_end))</span></span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>        resized_image <span class="op">=</span> np.pad(</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a>            resized_image,</span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>            pad_width<span class="op">=</span>((pad_top, pad_bottom), (pad_left, pad_right), (<span class="dv">0</span>, <span class="dv">0</span>)),</span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a>            mode<span class="op">=</span><span class="st">'constant'</span>,</span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>            constant_values<span class="op">=</span><span class="dv">0</span></span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># After padding, update the crop coordinates to the padded image</span></span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>        top <span class="op">=</span> pad_top</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a>        left <span class="op">=</span> pad_left</span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a>        bottom <span class="op">=</span> top <span class="op">+</span> output_height</span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a>        right <span class="op">=</span> left <span class="op">+</span> output_width</span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Crop the image to the desired output size</span></span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This will extract the central region of the image</span></span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a>    cropped_image <span class="op">=</span> resized_image[top:bottom, left:right]</span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize pixel values to the range [0, 1]</span></span>
<span id="cb27-76"><a href="#cb27-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert pixel values to float32 and divide by 255</span></span>
<span id="cb27-77"><a href="#cb27-77" aria-hidden="true" tabindex="-1"></a>    normalized_image <span class="op">=</span> cropped_image.astype(np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb27-78"><a href="#cb27-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-79"><a href="#cb27-79" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the preprocessed image</span></span>
<span id="cb27-80"><a href="#cb27-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> normalized_image</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="verify-the-preprocessing-function" class="level4">
<h4 class="anchored" data-anchor-id="verify-the-preprocessing-function">Verify the Preprocessing Function</h4>
<p>We can test the preprocessing function on one of the sample images.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select a sample image</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>sample_img <span class="op">=</span> Image.<span class="bu">open</span>(sample_img_paths[<span class="dv">0</span>])</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>sample_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images//output_60_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Process the sample image</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>img_preproc_np <span class="op">=</span> preproc(sample_img, output_height<span class="op">=</span>input_sz[<span class="dv">1</span>], output_width<span class="op">=</span>input_sz[<span class="dv">0</span>], resize_side<span class="op">=</span>input_sz[<span class="dv">0</span>])</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"processed_inp.shape: </span><span class="sc">{</span>img_preproc_np<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the processed sample image</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>Image.fromarray((img_preproc_np<span class="op">*</span><span class="dv">255</span>).astype(np.uint8))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>processed_inp.shape: (288, 512, 3)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images//output_61_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="generate-a-calibration-dataset" class="level4">
<h4 class="anchored" data-anchor-id="generate-a-calibration-dataset">Generate a Calibration Dataset</h4>
<p>Next, we will generate our dataset of preprocessing input samples and store it in a NumPy array.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an empty numpy array to store the calibration dataset</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Shape: (number of images, height, width, color channels)</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>calib_dataset <span class="op">=</span> np.zeros((<span class="bu">len</span>(sample_img_paths), input_sz[<span class="dv">1</span>], input_sz[<span class="dv">0</span>], <span class="dv">3</span>), dtype<span class="op">=</span>np.float32)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through each image path in the sample_img_paths list</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, img_path <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(sample_img_paths)):</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Open and read the image file</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> np.array(Image.<span class="bu">open</span>(img_path))</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocess the image</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    img_preproc_np <span class="op">=</span> preproc(img, output_height<span class="op">=</span>input_sz[<span class="dv">1</span>], output_width<span class="op">=</span>input_sz[<span class="dv">0</span>], resize_side<span class="op">=</span>input_sz[<span class="dv">0</span>])</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Store the preprocessed image in the calibration dataset</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    calib_dataset[idx, :, :, :] <span class="op">=</span> img_preproc_np</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="initialize-a-hailo-dataflow-compiler-api-client" class="level4">
<h4 class="anchored" data-anchor-id="initialize-a-hailo-dataflow-compiler-api-client">Initialize a Hailo Dataflow Compiler API Client</h4>
<p>After generating the calibration dataset, we will initialize a DFC API client with the Hailo Archive file.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># By default it uses the hw_arch that is saved on the HAR. For overriding, use the hw_arch flag.</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>runner <span class="op">=</span> ClientRunner(har<span class="op">=</span><span class="bu">str</span>(hailo_model_har_path))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="quantize-the-hailo-archive" class="level4">
<h4 class="anchored" data-anchor-id="quantize-the-hailo-archive">Quantize the Hailo Archive</h4>
<p>We use the <code>optimize</code> method to quantize the Hailo Archive using the calibration data.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Input Normalization">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Input Normalization
</div>
</div>
<div class="callout-body-container callout-body">
<p>Our ONNX model includes the required input normalization step. Those following along with an ONNX model that does not perform input normalization can create a model script to add this step to the Hailo Archive.</p>
</div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Default</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Add Normalization Step</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call Optimize to perform the optimization process</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>runner.optimize(calib_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a model script that tells the compiler to add a normalization on the beginning of the model</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>alls <span class="op">=</span> <span class="st">"normalization1 = normalization([0.5, 0.5, 0.5], [1.0, 1.0, 1.0])</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the model script to ClientRunner so it will be considered on optimization</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>runner.load_model_script(alls)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Call optimize to perform the optimization process</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>runner.optimize(calib_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Model Optimization Console Output">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Model Optimization Console Output
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div style="overflow-x:auto; max-height:500px">
<pre class="text"><code>[info] Starting Model Optimization


2024-10-14 16:40:58.891458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-10-14 16:40:58.919769: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-10-14 16:40:59.068703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-10-14 16:40:59.091439: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...


[warning] Reducing optimization level to 0 (the accuracy won't be optimized and compression won't be used) because there's no available GPU
[warning] Running model optimization with zero level of optimization is not recommended for production use and might lead to suboptimal accuracy results
[info] Model received quantization params from the hn
[info] Starting Mixed Precision
[info] Mixed Precision is done (completion time is 00:00:00.43)
[info] LayerNorm Decomposition skipped
[info] Starting Statistics Collector
[info] Using dataset with 64 entries for calibration


Calibration:   0%|                                                            | 0/64 [00:00&lt;?, ?entries/s]2024-10-14 16:41:06.120679: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:06.137874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:   2%|▊                                                   | 1/64 [00:18&lt;19:28, 18.54s/entries]2024-10-14 16:41:21.430751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:21.471131: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:21.511112: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:   6%|███▎                                                | 4/64 [00:18&lt;03:32,  3.54s/entries]2024-10-14 16:41:21.550471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:21.591526: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:21.632570: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  11%|█████▋                                              | 7/64 [00:18&lt;01:34,  1.66s/entries]2024-10-14 16:41:21.674128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:21.713795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:21.754394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  16%|███████▉                                           | 10/64 [00:18&lt;00:51,  1.04entries/s]2024-10-14 16:41:21.797370: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:21.839853: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:21.881414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  20%|██████████▎                                        | 13/64 [00:19&lt;00:31,  1.64entries/s]2024-10-14 16:41:21.924537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:21.966733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.006793: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  25%|████████████▊                                      | 16/64 [00:19&lt;00:19,  2.45entries/s]2024-10-14 16:41:22.046813: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.088094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.128298: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  30%|███████████████▏                                   | 19/64 [00:19&lt;00:12,  3.52entries/s]2024-10-14 16:41:22.167066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.209148: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.249356: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  34%|█████████████████▌                                 | 22/64 [00:19&lt;00:08,  4.87entries/s]2024-10-14 16:41:22.288732: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.326467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.366214: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  39%|███████████████████▉                               | 25/64 [00:19&lt;00:05,  6.54entries/s]2024-10-14 16:41:22.408393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.448734: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.487582: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  44%|██████████████████████▎                            | 28/64 [00:19&lt;00:04,  8.50entries/s]2024-10-14 16:41:22.526808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.567167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.606615: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  48%|████████████████████████▋                          | 31/64 [00:19&lt;00:03, 10.67entries/s]2024-10-14 16:41:22.646712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.687785: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.728979: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  53%|███████████████████████████                        | 34/64 [00:19&lt;00:02, 12.89entries/s]2024-10-14 16:41:22.769389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.810197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.848900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  58%|█████████████████████████████▍                     | 37/64 [00:20&lt;00:01, 15.12entries/s]2024-10-14 16:41:22.889144: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.928209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:22.966166: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  62%|███████████████████████████████▉                   | 40/64 [00:20&lt;00:01, 17.18entries/s]2024-10-14 16:41:23.009711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.050717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.091871: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  67%|██████████████████████████████████▎                | 43/64 [00:20&lt;00:01, 18.88entries/s]2024-10-14 16:41:23.131485: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.173946: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.214569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  72%|████████████████████████████████████▋              | 46/64 [00:20&lt;00:00, 20.27entries/s]2024-10-14 16:41:23.254185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.295213: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.335322: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  77%|███████████████████████████████████████            | 49/64 [00:20&lt;00:00, 21.53entries/s]2024-10-14 16:41:23.373498: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.413181: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.452769: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  81%|█████████████████████████████████████████▍         | 52/64 [00:20&lt;00:00, 22.51entries/s]2024-10-14 16:41:23.492637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.532348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.572460: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  86%|███████████████████████████████████████████▊       | 55/64 [00:20&lt;00:00, 23.19entries/s]2024-10-14 16:41:23.613164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.655717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.702068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  91%|██████████████████████████████████████████████▏    | 58/64 [00:20&lt;00:00, 23.12entries/s]2024-10-14 16:41:23.743654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.784390: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.826286: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration:  95%|████████████████████████████████████████████████▌  | 61/64 [00:20&lt;00:00, 23.45entries/s]2024-10-14 16:41:23.867680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.909671: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
2024-10-14 16:41:23.952654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,288,512,3]
     [[{{node Placeholder/_0}}]]
Calibration: 100%|███████████████████████████████████████████████████| 64/64 [00:21&lt;00:00,  3.03entries/s]

[info] Statistics Collector is done (completion time is 00:00:22.37)
[info] Starting Fix zp_comp Encoding
[info] Fix zp_comp Encoding is done (completion time is 00:00:00.00)
[info] Matmul Equalization skipped
[info] No shifts available for layer hagrid-sample-30k-384p-yolox_tiny/conv79/conv_op, using max shift instead. delta=0.0653
[info] No shifts available for layer hagrid-sample-30k-384p-yolox_tiny/conv79/conv_op, using max shift instead. delta=0.0327
[info] Finetune encoding skipped
[info] Bias Correction skipped
[info] Adaround skipped
[info] Quantization-Aware Fine-Tuning skipped
[info] Layer Noise Analysis skipped
[info] The calibration set seems to not be normalized, because the values range is [(0.0, 1.0), (0.0, 1.0), (0.0, 1.0)].
Since the neural core works in 8-bit (between 0 to 255), a quantization will occur on the CPU of the runtime platform.
Add a normalization layer to the model to offload the normalization to the neural core.
Refer to the user guide Hailo Dataflow Compiler user guide / Model Optimization / Optimization Related Model Script Commands / model_modification_commands / normalization for details.
[info] Model Optimization is done</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="save-the-quantized-hailo-archive" class="level4">
<h4 class="anchored" data-anchor-id="save-the-quantized-hailo-archive">Save the Quantized Hailo Archive</h4>
<p>After the optimization process finishes, we can save the quantized Hailo Archive using the <code>save_har</code> method.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the result state to a Quantized HAR file</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>quantized_model_har_path <span class="op">=</span> onnx_file_path.parent<span class="op">/</span><span class="ss">f"</span><span class="sc">{</span>onnx_file_path<span class="sc">.</span>stem<span class="sc">}</span><span class="ss">_quantized_model.har"</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>runner.save_har(quantized_model_har_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[info] Saved HAR to: /mnt/ACASIS_4TB/Projects/GitHub/pytorch-yolox-object-detection-tutorial-code/notebooks/pytorch-yolox-object-detector/2024-09-08_19-22-32/hagrid-sample-30k-384p-yolox_tiny_quantized_model.har</code></pre>
<p>As a final step, we should perform inference with the quantized model to verify it maintains sufficient accuracy.</p>
</section>
<section id="define-functions-to-handle-arbitrary-input-resolutions" class="level4">
<h4 class="anchored" data-anchor-id="define-functions-to-handle-arbitrary-input-resolutions">Define Functions to Handle Arbitrary Input Resolutions</h4>
<p>The images fed to the model during inference may not always be the target resolution or aspect ratio. Therefore, we will create some utility functions to handle arbitrary input resolutions.</p>
<p>We will keep track of the offset and scaling values to adjust the predicted bounding boxes to the source image.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ImageTransformData(NamedTuple):</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co">    A data class that stores transformation information applied to an image.</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Attributes:</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co">        offset (Tuple[int, int]): The (x, y) offset where the resized image was pasted.</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co">        scale (float): The scaling factor applied to the original image.</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    offset: Tuple[<span class="bu">int</span>, <span class="bu">int</span>]</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    scale: <span class="bu">float</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> resize_and_pad(</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    image: Image.Image,</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    target_sz: Tuple[<span class="bu">int</span>, <span class="bu">int</span>],</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    return_transform_data: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    fill_color: Tuple[<span class="bu">int</span>, <span class="bu">int</span>, <span class="bu">int</span>] <span class="op">=</span> (<span class="dv">255</span>, <span class="dv">255</span>, <span class="dv">255</span>)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Tuple[Image.Image, Optional[ImageTransformData]]:</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Resize an image while maintaining its aspect ratio and pad it to fit the target size.</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co">        image (Image.Image): The original PIL Image to be resized and padded.</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co">        target_sz (Tuple[int, int]): The desired size (width, height) for the output image.</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="co">        return_transform_data (bool, optional): If True, returns transformation data (offset and scale).</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="co">        fill_color (Tuple[int, int, int], optional): The color to use for padding (default is white).</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Tuple[Image.Image, Optional[ImageTransformData]]: The resized and padded image,</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="co">        and optionally the transformation data.</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Unpack the target size into width and height</span></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>    target_width, target_height <span class="op">=</span> target_sz</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the original image size</span></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>    orig_width, orig_height <span class="op">=</span> image.size</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the aspect ratios of the original and target images</span></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>    aspect_ratio <span class="op">=</span> orig_width <span class="op">/</span> orig_height</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>    target_aspect_ratio <span class="op">=</span> target_width <span class="op">/</span> target_height</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Determine new size while maintaining aspect ratio</span></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> aspect_ratio <span class="op">&gt;</span> target_aspect_ratio:</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the original image is wider than the target aspect ratio, limit by width</span></span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>        new_width <span class="op">=</span> target_width</span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>        new_height <span class="op">=</span> <span class="bu">int</span>(new_width <span class="op">/</span> aspect_ratio)</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> target_width <span class="op">/</span> orig_width</span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the original image is taller than the target aspect ratio, limit by height</span></span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>        new_height <span class="op">=</span> target_height</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a>        new_width <span class="op">=</span> <span class="bu">int</span>(new_height <span class="op">*</span> aspect_ratio)</span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> target_height <span class="op">/</span> orig_height</span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resize the image to the new dimensions using high-quality downsampling filter</span></span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a>    resized_image <span class="op">=</span> image.resize((new_width, new_height), Image.LANCZOS)</span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a new image with the target size and fill it with the fill color</span></span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>    padded_image <span class="op">=</span> Image.new(<span class="st">'RGB'</span>, target_sz, fill_color)  <span class="co"># White background by default</span></span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the position to paste the resized image onto the padded image to center it</span></span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a>    paste_x <span class="op">=</span> (target_width <span class="op">-</span> new_width) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a>    paste_y <span class="op">=</span> (target_height <span class="op">-</span> new_height) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Paste the resized image onto the center of the padded image</span></span>
<span id="cb39-53"><a href="#cb39-53" aria-hidden="true" tabindex="-1"></a>    padded_image.paste(resized_image, (paste_x, paste_y))</span>
<span id="cb39-54"><a href="#cb39-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-55"><a href="#cb39-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> return_transform_data:</span>
<span id="cb39-56"><a href="#cb39-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If requested, create transformation data to return</span></span>
<span id="cb39-57"><a href="#cb39-57" aria-hidden="true" tabindex="-1"></a>        transform_data <span class="op">=</span> ImageTransformData(offset<span class="op">=</span>(paste_x, paste_y), scale<span class="op">=</span>scale)</span>
<span id="cb39-58"><a href="#cb39-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> padded_image, transform_data</span>
<span id="cb39-59"><a href="#cb39-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb39-60"><a href="#cb39-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> padded_image, <span class="va">None</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> adjust_bbox(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    bbox: Tuple[<span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>],</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    transform_data: ImageTransformData</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Tuple[<span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>]:</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Adjust a bounding box according to the transformation data (offset and scale).</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co">        bbox (Tuple[float, float, float, float]): The original bounding box as (x, y, width, height).</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co">        transform_data (ImageTransformData): The transformation data containing offset and scale.</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="co">        Tuple[float, float, float, float]: The adjusted bounding box.</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Unpack the bounding box coordinates and size</span></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>    x, y, w, h <span class="op">=</span> bbox</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Unpack the transformation data</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>    offset_x, offset_y <span class="op">=</span> transform_data.offset</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>    scale <span class="op">=</span> transform_data.scale</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adjust the coordinates by subtracting the offset and dividing by the scale</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>    adjusted_x <span class="op">=</span> (x <span class="op">-</span> offset_x) <span class="op">/</span> scale</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>    adjusted_y <span class="op">=</span> (y <span class="op">-</span> offset_y) <span class="op">/</span> scale</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adjust the size by dividing by the scale</span></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>    adjusted_w <span class="op">=</span> w <span class="op">/</span> scale</span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>    adjusted_h <span class="op">=</span> h <span class="op">/</span> scale</span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (adjusted_x, adjusted_y, adjusted_w, adjusted_h)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="define-postprocessing-functions" class="level4">
<h4 class="anchored" data-anchor-id="define-postprocessing-functions">Define Postprocessing Functions</h4>
<p>Next, we will redefine the same utility functions from the previous tutorial.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_output_grids_np(height, width, strides<span class="op">=</span>[<span class="dv">8</span>,<span class="dv">16</span>,<span class="dv">32</span>]):</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate a numpy array containing grid coordinates and strides for a given height and width.</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co">        height (int): The height of the image.</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co">        width (int): The width of the image.</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co">        np.ndarray: A numpy array containing grid coordinates and strides.</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>    all_coordinates <span class="op">=</span> []</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> stride <span class="kw">in</span> strides:</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the grid height and width</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>        grid_height <span class="op">=</span> height <span class="op">//</span> stride</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>        grid_width <span class="op">=</span> width <span class="op">//</span> stride</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate grid coordinates</span></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>        g1, g0 <span class="op">=</span> np.meshgrid(np.arange(grid_height), np.arange(grid_width), indexing<span class="op">=</span><span class="st">'ij'</span>)</span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create an array of strides</span></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a>        s <span class="op">=</span> np.full((grid_height, grid_width), stride)</span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stack the coordinates along with the stride</span></span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a>        coordinates <span class="op">=</span> np.stack((g0.flatten(), g1.flatten(), s.flatten()), axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append to the list</span></span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a>        all_coordinates.append(coordinates)</span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Concatenate all arrays in the list along the first dimension</span></span>
<span id="cb41-33"><a href="#cb41-33" aria-hidden="true" tabindex="-1"></a>    output_grids <span class="op">=</span> np.concatenate(all_coordinates, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb41-34"><a href="#cb41-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-35"><a href="#cb41-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output_grids</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_boxes_and_probs(model_output:np.ndarray, output_grids:np.ndarray) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Calculate the bounding boxes and their probabilities.</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co">    model_output (numpy.ndarray): The output of the model.</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="co">    output_grids (numpy.ndarray): The output grids.</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="co">    numpy.ndarray: The array containing the bounding box coordinates, class labels, and maximum probabilities.</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the bounding box coordinates</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>    box_centroids <span class="op">=</span> (model_output[..., :<span class="dv">2</span>] <span class="op">+</span> output_grids[..., :<span class="dv">2</span>]) <span class="op">*</span> output_grids[..., <span class="dv">2</span>:]</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>    box_sizes <span class="op">=</span> np.exp(model_output[..., <span class="dv">2</span>:<span class="dv">4</span>]) <span class="op">*</span> output_grids[..., <span class="dv">2</span>:]</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    x0, y0 <span class="op">=</span> [t.squeeze(axis<span class="op">=</span><span class="dv">2</span>) <span class="cf">for</span> t <span class="kw">in</span> np.split(box_centroids <span class="op">-</span> box_sizes <span class="op">/</span> <span class="dv">2</span>, <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">2</span>)]</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    w, h <span class="op">=</span> [t.squeeze(axis<span class="op">=</span><span class="dv">2</span>) <span class="cf">for</span> t <span class="kw">in</span> np.split(box_sizes, <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">2</span>)]</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the probabilities for each class</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>    box_objectness <span class="op">=</span> model_output[..., <span class="dv">4</span>]</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>    box_cls_scores <span class="op">=</span> model_output[..., <span class="dv">5</span>:]</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>    box_probs <span class="op">=</span> np.expand_dims(box_objectness, <span class="op">-</span><span class="dv">1</span>) <span class="op">*</span> box_cls_scores</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the maximum probability and corresponding class for each proposal</span></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>    max_probs <span class="op">=</span> np.<span class="bu">max</span>(box_probs, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> np.argmax(box_probs, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([x0, y0, w, h, labels, max_probs]).transpose((<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_outputs(outputs:np.ndarray, input_dims:<span class="bu">tuple</span>, bbox_conf_thresh:<span class="bu">float</span>):</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Process the model outputs to generate bounding box proposals filtered by confidence threshold.</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - outputs (numpy.ndarray): The raw output from the model, which will be processed to calculate boxes and probabilities.</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - input_dims (tuple of int): Dimensions (height, width) of the input image to the model.</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - bbox_conf_thresh (float): Threshold for the bounding box confidence/probability. Bounding boxes with a confidence</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="co">                                score below this threshold will be discarded.</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a><span class="co">    - numpy.array: An array of proposals where each proposal is an array containing bounding box coordinates</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="co">                   and its associated probability, sorted in descending order by probability.</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process the model output</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> calculate_boxes_and_probs(outputs, generate_output_grids_np(<span class="op">*</span>input_dims))</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter the proposals based on the confidence threshold</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>    max_probs <span class="op">=</span> outputs[:, :, <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> max_probs <span class="op">&gt;</span> bbox_conf_thresh</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>    proposals <span class="op">=</span> outputs[mask]</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort the proposals by probability in descending order</span></span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>    proposals <span class="op">=</span> proposals[proposals[..., <span class="op">-</span><span class="dv">1</span>].argsort()][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> proposals</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_iou(proposals:np.ndarray) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Calculates the Intersection over Union (IoU) for all pairs of bounding boxes (x,y,w,h) in 'proposals'.</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co">    The IoU is a measure of overlap between two bounding boxes. It is calculated as the area of</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co">    intersection divided by the area of union of the two boxes.</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="co">    proposals (2D np.array): A NumPy array of bounding boxes, where each box is an array [x, y, width, height].</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="co">    iou (2D np.array): The IoU matrix where each element i,j represents the IoU of boxes i and j.</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate coordinates for the intersection rectangles</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    x1 <span class="op">=</span> np.maximum(proposals[:, <span class="dv">0</span>], proposals[:, <span class="dv">0</span>][:, <span class="va">None</span>])</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>    y1 <span class="op">=</span> np.maximum(proposals[:, <span class="dv">1</span>], proposals[:, <span class="dv">1</span>][:, <span class="va">None</span>])</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>    x2 <span class="op">=</span> np.minimum(proposals[:, <span class="dv">0</span>] <span class="op">+</span> proposals[:, <span class="dv">2</span>], (proposals[:, <span class="dv">0</span>] <span class="op">+</span> proposals[:, <span class="dv">2</span>])[:, <span class="va">None</span>])</span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>    y2 <span class="op">=</span> np.minimum(proposals[:, <span class="dv">1</span>] <span class="op">+</span> proposals[:, <span class="dv">3</span>], (proposals[:, <span class="dv">1</span>] <span class="op">+</span> proposals[:, <span class="dv">3</span>])[:, <span class="va">None</span>])</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate intersection areas</span></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>    intersections <span class="op">=</span> np.maximum(x2 <span class="op">-</span> x1, <span class="dv">0</span>) <span class="op">*</span> np.maximum(y2 <span class="op">-</span> y1, <span class="dv">0</span>)</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate union areas</span></span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>    areas <span class="op">=</span> proposals[:, <span class="dv">2</span>] <span class="op">*</span> proposals[:, <span class="dv">3</span>]</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>    unions <span class="op">=</span> areas[:, <span class="va">None</span>] <span class="op">+</span> areas <span class="op">-</span> intersections</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate IoUs</span></span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>    iou <span class="op">=</span> intersections <span class="op">/</span> unions</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the iou matrix</span></span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> iou</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> nms_sorted_boxes(iou:np.ndarray, iou_thresh:<span class="bu">float</span><span class="op">=</span><span class="fl">0.45</span>) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Applies non-maximum suppression (NMS) to sorted bounding boxes.</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co">    It suppresses boxes that have high overlap (as defined by the IoU threshold) with a box that </span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="co">    has a higher score.</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co">    iou (np.ndarray): An IoU matrix where each element i,j represents the IoU of boxes i and j.</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="co">    iou_thresh (float): The IoU threshold for suppression. Boxes with IoU &gt; iou_thresh are suppressed.</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="co">    keep (np.ndarray): The indices of the boxes to keep after applying NMS.</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a boolean mask to keep track of boxes</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> np.ones(iou.shape[<span class="dv">0</span>], dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply non-max suppression</span></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iou.shape[<span class="dv">0</span>]):</span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mask[i]:</span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Suppress boxes with higher index and IoU &gt; threshold</span></span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>            mask[(iou[i] <span class="op">&gt;</span> iou_thresh) <span class="op">&amp;</span> (np.arange(iou.shape[<span class="dv">0</span>]) <span class="op">&gt;</span> i)] <span class="op">=</span> <span class="va">False</span></span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the indices of the boxes to keep</span></span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.arange(iou.shape[<span class="dv">0</span>])[mask]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="define-bounding-box-annotation-function" class="level4">
<h4 class="anchored" data-anchor-id="define-bounding-box-annotation-function">Define Bounding Box Annotation Function</h4>
<p>Lastly, we will define a function for annotating the source image with the predicted bounding boxes.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_bboxes_pil(image, boxes, labels, colors, font, width:<span class="bu">int</span><span class="op">=</span><span class="dv">2</span>, font_size:<span class="bu">int</span><span class="op">=</span><span class="dv">18</span>, probs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Annotates an image with bounding boxes, labels, and optional probability scores.</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co">    This function draws bounding boxes on the provided image using the given box coordinates, </span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co">    colors, and labels. If probabilities are provided, they will be added to the labels.</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="co">    image (PIL.Image): The input image on which annotations will be drawn.</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="co">    boxes (list of tuples): A list of bounding box coordinates where each tuple is (x, y, w, h).</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="co">    labels (list of str): A list of labels corresponding to each bounding box.</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="co">    colors (list of str): A list of colors for each bounding box and its corresponding label.</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="co">    font (str): Path to the font file to be used for displaying the labels.</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a><span class="co">    width (int, optional): Width of the bounding box lines. Defaults to 2.</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="co">    font_size (int, optional): Size of the font for the labels. Defaults to 25.</span></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a><span class="co">    probs (list of float, optional): A list of probability scores corresponding to each label. Defaults to None.</span></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a><span class="co">    annotated_image (PIL.Image): The image annotated with bounding boxes, labels, and optional probability scores.</span></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define a reference diagonal</span></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>    REFERENCE_DIAGONAL <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Scale the font size using the hypotenuse of the image</span></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>    font_size <span class="op">=</span> <span class="bu">int</span>(font_size <span class="op">*</span> (np.hypot(<span class="op">*</span>image.size) <span class="op">/</span> REFERENCE_DIAGONAL))</span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add probability scores to labels</span></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> probs <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> [<span class="ss">f"</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>prob<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span> <span class="cf">for</span> label, prob <span class="kw">in</span> <span class="bu">zip</span>(labels, probs)]</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a copy of the image</span></span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a>    annotated_image <span class="op">=</span> image.copy()</span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create an ImageDraw object for drawing on the image</span></span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a>    draw <span class="op">=</span> ImageDraw.Draw(annotated_image)</span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loop through the bounding boxes and labels in the 'annotation' DataFrame</span></span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(labels)):</span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the bounding box coordinates</span></span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a>        x, y, w, h <span class="op">=</span> boxes[i]</span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a tuple of coordinates for the bounding box</span></span>
<span id="cb46-44"><a href="#cb46-44" aria-hidden="true" tabindex="-1"></a>        shape <span class="op">=</span> (x, y, x<span class="op">+</span>w, y<span class="op">+</span>h)</span>
<span id="cb46-45"><a href="#cb46-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Draw the bounding box on the image</span></span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a>        draw.rectangle(shape, outline<span class="op">=</span>colors[i], width<span class="op">=</span>width)</span>
<span id="cb46-48"><a href="#cb46-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb46-49"><a href="#cb46-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Load the font file</span></span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a>        fnt <span class="op">=</span> ImageFont.truetype(font, font_size)</span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Draw the label box on the image</span></span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a>        label_w, label_h <span class="op">=</span> draw.textbbox(xy<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">0</span>), text<span class="op">=</span>labels[i], font<span class="op">=</span>fnt)[<span class="dv">2</span>:]</span>
<span id="cb46-54"><a href="#cb46-54" aria-hidden="true" tabindex="-1"></a>        draw.rectangle((x, y<span class="op">-</span>label_h, x<span class="op">+</span>label_w, y), outline<span class="op">=</span>colors[i], fill<span class="op">=</span>colors[i], width<span class="op">=</span>width)</span>
<span id="cb46-55"><a href="#cb46-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-56"><a href="#cb46-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Draw the label on the image</span></span>
<span id="cb46-57"><a href="#cb46-57" aria-hidden="true" tabindex="-1"></a>        draw.multiline_text((x, y<span class="op">-</span>label_h), labels[i], font<span class="op">=</span>fnt, fill<span class="op">=</span><span class="st">'black'</span> <span class="cf">if</span> np.mean(colors[i]) <span class="op">&gt;</span> <span class="fl">127.5</span> <span class="cf">else</span> <span class="st">'white'</span>)</span>
<span id="cb46-58"><a href="#cb46-58" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb46-59"><a href="#cb46-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> annotated_image</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="initialize-a-hailo-dataflow-compiler-api-client-1" class="level4">
<h4 class="anchored" data-anchor-id="initialize-a-hailo-dataflow-compiler-api-client-1">Initialize a Hailo Dataflow Compiler API Client</h4>
<p>With our utility functions implemented, we can initialize a new DFC API client with the quantized HAR file.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>runner <span class="op">=</span> ClientRunner(har<span class="op">=</span><span class="bu">str</span>(quantized_model_har_path))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="prepare-the-model-input" class="level4">
<h4 class="anchored" data-anchor-id="prepare-the-model-input">Prepare the Model Input</h4>
<p>Next, we will prepare the model input using our <code>resized_and_pad</code> image.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Resize and pad the sample image to the desired input size, retrieving transformation data.</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>input_img, transform_data <span class="op">=</span> resize_and_pad(sample_img, input_sz, <span class="va">True</span>)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the resized and padded image into a NumPy array suitable for model input.</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>input_tensor_np <span class="op">=</span> np.array(input_img, dtype<span class="op">=</span>np.float32)[<span class="va">None</span>] <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the transformation data to understand how the image was resized and where it was placed.</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"transform_data: </span><span class="sc">{</span>transform_data<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shape of the input tensor to verify it matches the expected input shape for the model.</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a><span class="co"># The shape is expected to be (batch_size, height, width, channels).</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"input_tensor_np.shape: </span><span class="sc">{</span>input_tensor_np<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the resized and padded image.</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>input_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>transform_data: ImageTransformData(offset=(64, 0), scale=0.75)
input_tensor_np.shape: (1, 288, 512, 3)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images//output_86_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="perform-inference-with-the-quantized-model" class="level4">
<h4 class="anchored" data-anchor-id="perform-inference-with-the-quantized-model">Perform Inference with the Quantized Model</h4>
<p>We perform inference with the quantized model using the <code>infer_context</code> method with the <code>SDK_QUANTIZED</code> inference context.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an inference context for quantized model execution</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> runner.infer_context(InferenceContext.SDK_QUANTIZED) <span class="im">as</span> ctx:</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform inference using the quantized model</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># input_tensor_np is assumed to be a pre-processed input image as a numpy array</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    quantized_res <span class="op">=</span> runner.infer(ctx, input_tensor_np)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shape of the inference results</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(quantized_res.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Inference: 0entries [00:00, ?entries/s]2024-10-14 16:41:47.043075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32
     [[{{node Placeholder/_0}}]]
Inference: 8entries [00:31,  3.97s/entries]

(1, 1, 24, 3024)</code></pre>
</section>
<section id="process-the-model-output" class="level4">
<h4 class="anchored" data-anchor-id="process-the-model-output">Process the Model Output</h4>
<p>At last, we can process the model output and visualize the bounding box predictions.</p>
<p>Since our postprocessing methods are for the channels-first ONNX model, we must first convert the output from the channels-last Hailo Archive.</p>
<p>After processing the bounding box predictions from the raw model output, we can use the transformation data to offset and scale them to the source image.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transpose and extract the first element of the quantized results</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> quantized_res.transpose(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)[<span class="dv">0</span>]</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Process the outputs to generate initial object proposals</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>proposals <span class="op">=</span> process_outputs(outputs, input_sz[::<span class="op">-</span><span class="dv">1</span>], <span class="fl">0.3</span>)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply non-max suppression (NMS) to remove overlapping bounding boxes</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Intersection over Union (IoU) for the proposals</span></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>iou_matrix <span class="op">=</span> calc_iou(proposals[:, :<span class="op">-</span><span class="dv">2</span>])</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply NMS with a threshold of 0.45 to get indices of kept proposals</span></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>proposal_indices <span class="op">=</span> nms_sorted_boxes(iou_matrix, <span class="fl">0.45</span>)</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep only the proposals that passed NMS</span></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>proposals <span class="op">=</span> proposals[proposal_indices]</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare lists for bounding boxes, labels, and probabilities</span></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>bbox_list <span class="op">=</span> [adjust_bbox(bbox, transform_data) <span class="cf">for</span> bbox <span class="kw">in</span> proposals[:,:<span class="dv">4</span>]]</span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>label_list <span class="op">=</span> [class_names[<span class="bu">int</span>(idx)] <span class="cf">for</span> idx <span class="kw">in</span> proposals[:,<span class="dv">4</span>]]</span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>probs_list <span class="op">=</span> proposals[:,<span class="dv">5</span>]</span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw bounding boxes on the image</span></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a>annotated_img <span class="op">=</span> draw_bboxes_pil(</span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a>    image<span class="op">=</span>sample_img,          <span class="co"># The original image</span></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a>    boxes<span class="op">=</span>bbox_list,           <span class="co"># List of bounding boxes</span></span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>label_list,         <span class="co"># List of class labels for each box</span></span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>    probs<span class="op">=</span>probs_list,          <span class="co"># List of probabilities for each box</span></span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a>    colors<span class="op">=</span>[int_colors[class_names.index(i)] <span class="cf">for</span> i <span class="kw">in</span> label_list],  <span class="co"># Colors for each box based on class</span></span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a>    font<span class="op">=</span>font_file,            <span class="co"># Font file for text on the image</span></span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the annotated image</span></span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a>display(annotated_img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images//output_90_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>That completes the optimization process. All that is left is to compile the quantized Hailo Archive for the target Hailo-8L accelerator.</p>
</section>
</section>
<section id="compilation" class="level3">
<h3 class="anchored" data-anchor-id="compilation">Compilation</h3>
<p>To compile the model, we only need to initialize a DFC API client with the quantized HAR file, call the compile method, and save the result as a binary Hailo Executable Format (HEF) file.</p>
<section id="compile-the-quantized-model" class="level4">
<h4 class="anchored" data-anchor-id="compile-the-quantized-model">Compile the Quantized Model</h4>
<div class="sourceCode" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a Hailo Dataflow Compiler API Client</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This creates a runner object that will be used to compile the model</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>runner <span class="op">=</span> ClientRunner(har<span class="op">=</span><span class="bu">str</span>(quantized_model_har_path))</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile the quantized model for the target Hailo hardware</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="co"># This step converts the model into a format that can run on Hailo accelerators</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>hef <span class="op">=</span> runner.<span class="bu">compile</span>()</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the path for the compiled model</span></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="co"># We use the same directory and name as the original ONNX file, but change the extension to .hef</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 'hef' stands for Hailo Executable Format</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>compiled_model_hef_path <span class="op">=</span> onnx_file_path.parent <span class="op">/</span> <span class="ss">f"</span><span class="sc">{</span>onnx_file_path<span class="sc">.</span>stem<span class="sc">}</span><span class="ss">.hef"</span></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Write the compiled model to a file</span></span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a><span class="co"># We open the file in binary write mode ('wb') because HEF is a binary format</span></span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(compiled_model_hef_path, <span class="st">"wb"</span>) <span class="im">as</span> f:</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>    f.write(hef)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled" title="Model Compilation Console Output">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Model Compilation Console Output
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div style="overflow-x:auto; max-height:500px">
<pre class="text"><code>[info] To achieve optimal performance, set the compiler_optimization_level to "max" by adding performance_param(compiler_optimization_level=max) to the model script. Note that this may increase compilation time.
[info] Loading network parameters
[info] Starting Hailo allocation and compilation flow
[info] Finding the best partition to contexts...
[?25l[info] Iteration #1 - Contexts: 4
[info] Iteration #2 - Contexts: 4
[info] Iteration #3 - Contexts: 4
[info] Iteration #4 - Contexts: 4
[info] Iteration #5 - Contexts: 4
[info] Iteration #6 - Contexts: 4
[info] Iteration #7 - Contexts: 4
[info] Iteration #8 - Contexts: 4
[info] Iteration #9 - Contexts: 4
[info] Iteration #10 - Contexts: 4
[info] Iteration #11 - Contexts: 4
[info] Iteration #12 - Contexts: 4
[info] Iteration #13 - Contexts: 4
[info] Iteration #14 - Contexts: 4
[info] Iteration #15 - Contexts: 4
[info] Iteration #16 - Contexts: 4
[info] Iteration #17 - Contexts: 4
[info] Iteration #18 - Contexts: 4
[info] Iteration #19 - Contexts: 4
[info] Iteration #20 - Contexts: 4
[info] Iteration #21 - Contexts: 4
[info] Iteration #22 - Contexts: 4
[info] Iteration #23 - Contexts: 4
[info] Iteration #24 - Contexts: 4
[info] Iteration #25 - Contexts: 4
[info] Iteration #26 - Contexts: 4
[info] Iteration #27 - Contexts: 4
[info] Iteration #28 - Contexts: 4
[info] Iteration #29 - Contexts: 4
[info] Iteration #30 - Contexts: 4
[info] Iteration #31 - Contexts: 4
[info] Iteration #32 - Contexts: 4
[info] Iteration #33 - Contexts: 4
[info] Iteration #34 - Contexts: 4
[info] Iteration #35 - Contexts: 4
[info] Iteration #36 - Contexts: 4
[info] Iteration #37 - Contexts: 4
[info] Iteration #38 - Contexts: 4
[info] Iteration #39 - Contexts: 4
[info] Iteration #40 - Contexts: 4
[info] Iteration #41 - Contexts: 4
[info] Iteration #42 - Contexts: 4
[info] Iteration #43 - Contexts: 4
[info] Iteration #44 - Contexts: 4
[info] Iteration #45 - Contexts: 4
[info] Iteration #46 - Contexts: 4
[info] Iteration #47 - Contexts: 4
[info] Iteration #48 - Contexts: 4
[info] Iteration #49 - Contexts: 4
[info] Iteration #50 - Contexts: 4
[info] Iteration #51 - Contexts: 4
[info] Iteration #52 - Contexts: 4
[info] Iteration #53 - Contexts: 4
[info] Iteration #54 - Contexts: 4
[info] Iteration #55 - Contexts: 4
[info] Iteration #56 - Contexts: 4
[info] Iteration #57 - Contexts: 4
[info] Iteration #58 - Contexts: 4
[info] Iteration #59 - Contexts: 4
[info] Iteration #60 - Contexts: 4
[info] Iteration #61 - Contexts: 4
[info] Iteration #62 - Contexts: 4
[info] Iteration #63 - Contexts: 4
[info] Iteration #64 - Contexts: 4
[info] Iteration #65 - Contexts: 4
[info] Iteration #66 - Contexts: 4
[info] Iteration #67 - Contexts: 4
[info] Iteration #68 - Contexts: 4
[info] Iteration #69 - Contexts: 4
[info] Iteration #70 - Contexts: 4
[info] Iteration #71 - Contexts: 4
[info] Iteration #72 - Contexts: 4
[info] Iteration #73 - Contexts: 4
[info] Iteration #74 - Contexts: 4
[info] Iteration #75 - Contexts: 4
[info] Iteration #76 - Contexts: 4
[info] Iteration #77 - Contexts: 4
[info] Iteration #78 - Contexts: 4
[info] Iteration #79 - Contexts: 4
[info] Iteration #80 - Contexts: 4
[info] Iteration #81 - Contexts: 4
[info] Iteration #82 - Contexts: 5
[info] Iteration #83 - Contexts: 5
[info] Iteration #84 - Contexts: 5
[info] Iteration #85 - Contexts: 5
[info] Iteration #86 - Contexts: 5
[info] Iteration #87 - Contexts: 5
[info] Iteration #88 - Contexts: 5
[info] Iteration #89 - Contexts: 5
[info] Iteration #90 - Contexts: 5
[info] Iteration #91 - Contexts: 5
[info] Iteration #92 - Contexts: 5
[info] Iteration #93 - Contexts: 5
[info] Iteration #94 - Contexts: 5
[info] Iteration #95 - Contexts: 5
[info] Iteration #96 - Contexts: 5
[info] Iteration #97 - Contexts: 5
[info] Iteration #98 - Contexts: 5
[info] Iteration #99 - Contexts: 5
[info] Iteration #100 - Contexts: 5
[info] Iteration #101 - Contexts: 5
[info] Iteration #102 - Contexts: 5
[info] Iteration #103 - Contexts: 5
[info] Iteration #104 - Contexts: 5
[info] Iteration #105 - Contexts: 5
[info] Iteration #106 - Contexts: 5
[info] Iteration #107 - Contexts: 5
[info] Iteration #108 - Contexts: 5
[info] Iteration #109 - Contexts: 5
[info] Iteration #110 - Contexts: 5
[info] Iteration #111 - Contexts: 5
[info] Iteration #112 - Contexts: 5
[info] Iteration #113 - Contexts: 5
[info] Iteration #114 - Contexts: 5
[info] Iteration #115 - Contexts: 5
[info] Iteration #116 - Contexts: 5
[info] Iteration #117 - Contexts: 5
[info] Iteration #118 - Contexts: 5
[info] Iteration #119 - Contexts: 5
[info] Iteration #120 - Contexts: 5
[info] Iteration #121 - Contexts: 5
[info] Iteration #122 - Contexts: 5
[info] Iteration #123 - Contexts: 5
[info] Iteration #124 - Contexts: 5
[info] Iteration #125 - Contexts: 5
[info] Iteration #126 - Contexts: 5
[info] Iteration #127 - Contexts: 5
[info] Iteration #128 - Contexts: 5
[info] Iteration #129 - Contexts: 5
[info] Iteration #130 - Contexts: 5
[info] Iteration #131 - Contexts: 5
[info] Iteration #132 - Contexts: 5
[info] Iteration #133 - Contexts: 5
[info] Iteration #134 - Contexts: 5
[info] Iteration #135 - Contexts: 5
[info] Iteration #136 - Contexts: 5
[info] Iteration #137 - Contexts: 5
[info] Iteration #138 - Contexts: 5
[info] Iteration #139 - Contexts: 5
[info] Iteration #140 - Contexts: 5
[info] Iteration #141 - Contexts: 5
[info] Iteration #142 - Contexts: 5
[info] Iteration #143 - Contexts: 5
[info] Iteration #144 - Contexts: 5
[info] Iteration #145 - Contexts: 5
[info] Iteration #146 - Contexts: 5
[info] Iteration #147 - Contexts: 5
[info] Iteration #148 - Contexts: 5
[info] Iteration #149 - Contexts: 5
[info] Iteration #150 - Contexts: 5
[info] Iteration #151 - Contexts: 5
[info] Iteration #152 - Contexts: 5
[info] Iteration #153 - Contexts: 6
[info] Iteration #154 - Contexts: 6
[info] Iteration #155 - Contexts: 6
[info] Iteration #156 - Contexts: 6
[info] Iteration #157 - Contexts: 6
[info] Iteration #158 - Contexts: 6
[info] Iteration #159 - Contexts: 6
[info] Iteration #160 - Contexts: 6
[info] Iteration #161 - Contexts: 6
[info] Iteration #162 - Contexts: 6
[info] Iteration #163 - Contexts: 6
[info] Iteration #164 - Contexts: 6
[info] Iteration #165 - Contexts: 6
[info] Iteration #166 - Contexts: 6
[info] Iteration #167 - Contexts: 6
[info] Iteration #168 - Contexts: 6
[info] Iteration #169 - Contexts: 6
[info] Iteration #170 - Contexts: 6
[info] Iteration #171 - Contexts: 6
[info] Iteration #172 - Contexts: 6
[?25h
[info] Using Multi-context flow
[info] Resources optimization guidelines: Strategy -&gt; GREEDY Objective -&gt; MAX_FPS
[info] Resources optimization params: max_control_utilization=60%, max_compute_utilization=60%, max_compute_16bit_utilization=60%, max_memory_utilization (weights)=60%, max_input_aligner_utilization=60%, max_apu_utilization=60%
[info] input_layer1: Pass
[info] concat1: Pass
[info] space_to_depth1: Pass
[info] ew_add1: Pass
[info] conv3: Pass
[info] ew_add2: Pass
[info] mul_and_add1: Pass
[info] conv10: Pass
[info] conv13: Pass
[info] conv5: Pass
[info] auto_reshape_from_input_layer1_to_mul_and_add1: Pass
[info] conv4: Pass
[info] conv11: Pass
[info] conv18_dc: Pass
[info] conv12: Pass
[info] context_0_to_context_1_21: Pass
[info] conv6: Pass
[info] conv7: Pass
[info] ew_add3: Pass
[info] conv15: Pass
[info] conv1_sd1: Pass
[info] conv14: Pass
[info] conv17: Pass
[info] conv18_d0: Pass
[info] conv2_ws: Pass
[info] context_0_to_context_2_0: Pass
[info] conv2_sdc: Pass
[info] conv2_sd0: Pass
[info] context_0_to_context_1_2: Pass
[info] conv16: Pass
[info] conv2_sd2: Pass
[info] conv19: Pass
[info] conv1_sd0: Pass
[info] ew_add4: Pass
[info] conv8_sdc: Pass
[info] conv9: Pass
[info] conv8_ws: Pass
[info] concat2: Pass
[info] conv2_sd1: Pass
[info] conv18_d1: Pass
[info] conv1_sdc: Pass
[info] conv1_ws: Pass
[info] conv8_sd0: Pass
[info] conv8_sd1: Pass
[info] conv25: Pass
[info] ew_add6: Pass
[info] ew_add5: Pass
[info] conv23: Pass
[info] conv21: Pass
[info] conv20: Pass
[info] concat4: Pass
[info] maxpool1: Pass
[info] conv29: Pass
[info] ew_add7: Pass
[info] conv22: Pass
[info] conv24: Pass
[info] conv26: Pass
[info] concat3: Pass
[info] conv27: Pass
[info] conv30: Pass
[info] conv33: Pass
[info] conv37: Pass
[info] maxpool2_d1: Pass
[info] maxpool2_dc: Pass
[info] context_0_to_context_1_in_3: Pass
[info] context_1_to_context_2_9: Pass
[info] conv35: Pass
[info] conv38: Pass
[info] context_1_to_context_2_7: Pass
[info] context_0_to_context_1_in_22: Pass
[info] conv36: Pass
[info] maxpool3_d0: Pass
[info] maxpool3_d2: Pass
[info] conv28_d0: Pass
[info] maxpool3_fs: Pass
[info] context_1_to_context_3_5: Pass
[info] concat5: Pass
[info] resize1: Pass
[info] conv28_dc: Pass
[info] maxpool3_dc: Pass
[info] conv31: Pass
[info] context_0_to_context_1_in_4: Pass
[info] concat6: Pass
[info] conv32: Pass
[info] maxpool2_fs: Pass
[info] maxpool2_d0: Pass
[info] maxpool3_d1: Pass
[info] conv28_d1: Pass
[info] conv34: Pass
[info] concat9: Pass
[info] conv45: Pass
[info] conv39: Pass
[info] resize2: Pass
[info] conv42: Pass
[info] concat7: Pass
[info] conv41: Pass
[info] conv43: Pass
[info] conv40: Pass
[info] conv46: Pass
[info] conv47: Pass
[info] concat8: Pass
[info] conv44: Pass
[info] conv48: Pass
[info] conv49: Pass
[info] conv58: Pass
[info] conv59: Pass
[info] concat10: Pass
[info] conv57: Pass
[info] conv54: Pass
[info] conv55: Pass
[info] conv56: Pass
[info] conv53_d1: Pass
[info] conv53_d2: Pass
[info] conv52_d0: Pass
[info] conv52_dc: Pass
[info] conv53_d0: Pass
[info] conv52_d1: Pass
[info] conv53_dc: Pass
[info] conv51_d0: Pass
[info] conv52_d2: Pass
[info] conv51_d2: Pass
[info] conv51_dc: Pass
[info] context_2_to_context_3_13: Pass
[info] context_2_to_context_3_11: Pass
[info] context_2_to_context_3_15: Pass
[info] context_2_to_context_3_17: Pass
[info] context_2_to_context_3_19: Pass
[info] context_1_to_context_2_in_10: Pass
[info] conv50_d0: Pass
[info] context_0_to_context_2_in_1: Pass
[info] conv51_d1: Pass
[info] context_1_to_context_2_in_8: Pass
[info] conv50_dc: Pass
[info] conv50_d2: Pass
[info] conv50_d1: Pass
[info] sh_from_conv49_to_conv50_d0-2_conv51_d0: Pass
[info] output_layer1: Pass
[info] conv75: Pass
[info] conv61: Pass
[info] conv73: Pass
[info] concat15: Pass
[info] conv76: Pass
[info] conv72: Pass
[info] conv71: Pass
[info] conv79: Pass
[info] concat13: Pass
[info] concat12: Pass
[info] conv77: Pass
[info] conv60: Pass
[info] conv81: Pass
[info] conv82: Pass
[info] conv80: Pass
[info] conv78: Pass
[info] conv69: Pass
[info] conv83: Pass
[info] conv70: Pass
[info] concat14: Pass
[info] conv64: Pass
[info] concat16: Pass
[info] conv68: Pass
[info] format_conversion3: Pass
[info] conv63: Pass
[info] conv67: Pass
[info] conv66: Pass
[info] concat11: Pass
[info] format_conversion2: Pass
[info] conv65: Pass
[info] format_conversion4: Pass
[info] format_conversion1: Pass
[info] concat17: Pass
[info] conv74_d0: Pass
[info] conv62_dc: Pass
[info] conv74_dc: Pass
[info] auto_reshape_from_format_conversion4_to_output_layer1: Pass
[info] context_2_to_context_3_in_12: Pass
[info] context_1_to_context_3_in_6: Pass
[info] conv74_d1: Pass
[info] conv62_d0: Pass
[info] context_2_to_context_3_in_14: Pass
[info] context_2_to_context_3_in_16: Pass
[info] context_2_to_context_3_in_18: Pass
[info] context_2_to_context_3_in_20: Pass
[info] conv62_d1: Pass
[info] Solving the allocation (Mapping), time per context: 59m 59s


    
    [info] Context:0/0 Iteration 0: Mapping prepost...          
              cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
     worker0  *          *          *          *          *          *          *          *          V       
     worker1                                                                                                  
     worker2                                                                                                  
     worker3                                                                                                  
    
  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2                                                                                                  
 worker3                                                                                                  

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2  *          *          *          *          *          *          *          *          V       
 worker3                                                                                                  

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          V          *          *          V          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          V          *          *          V          V          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00
[info] Context:0/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:00


    
    [info] Context:1/3 Iteration 0: Trying parallel splits...   
              cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
     worker0                                                                                                  
     worker1                                                                                                  
     worker2                                                                                                  
     worker3                                                                                                  
    
  00:00
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2                                                                                                  
 worker3  *          *          *          *          *          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  *          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01
[info] Context:1/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          V          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          *          *          *          V          *          *          *          V       

  00:01


    
    [info] Context:2/3 Iteration 0: Trying parallel splits...   
              cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
     worker0                                                                                                  
     worker1                                                                                                  
     worker2                                                                                                  
     worker3                                                                                                  
    
  00:02
[info] Context:2/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2                                                                                                  
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1                                                                                                  
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          V          V          *          *          V       
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          V          V          *          *          V       
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          V          *          *          V          V          *          *          V       
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          V          *          *          V          V          *          *          V       
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          V          *          *          V          V          *          *          V       
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          V          *          *          V          V          *          *          V       
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          V          *          *          V          V          *          *          V       
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          V          *          *          V          V          *          *          V       
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          V          *          *          V          V          *          *          V       
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:02
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  *          *          *          *          V          *          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:04
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  *          V          *          *          *          *          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:04
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  *          *          *          *          *          *          *          *          V       

  00:04
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  *          V          *          *          V          V          *          *          V       

  00:04
[info] Context:2/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:04


    
    [info] Context:3/3 Iteration 0: Trying parallel splits...   
              cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
     worker0                                                                                                  
     worker1                                                                                                  
     worker2                                                                                                  
     worker3                                                                                                  
    
  00:05
[info] Context:3/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2                                                                                                  
 worker3                                                                                                  

  00:05
[info] Context:3/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          *          *          *          *          *          *          *          V       
 worker3                                                                                                  

  00:05
[info] Context:3/3 Iteration 0: Trying parallel splits...   
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0                                                                                                  
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          *          *          *          *          *          *          *          V       
 worker3                                                                                                  

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  *          *          *          *          *          *          *          *          V       
 worker2  *          *          *          *          *          *          *          *          V       
 worker3                                                                                                  

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  *          *          *          *          *          V          *          *          V       
 worker2  *          *          *          *          *          *          *          *          V       
 worker3                                                                                                  

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  *          *          *          *          *          *          *          *          V       
 worker3                                                                                                  

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  *          *          *          *          *          *          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  *          *          *          *          *          *          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:05
[info] Context:3/3 Iteration 4: Trying parallel mapping...  
          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost 
 worker0  V          V          *          *          V          V          *          *          V       
 worker1  V          *          *          *          V          V          *          *          V       
 worker2  V          V          *          *          V          V          *          *          V       
 worker3  V          V          *          *          V          V          *          *          V       

  00:06

[info] context_0 (context_0):
Iterations: 4
Reverts on cluster mapping: 0
Reverts on inter-cluster connectivity: 0
Reverts on pre-mapping validation: 0
Reverts on split failed: 0
[info] context_1 (context_1):
Iterations: 4
Reverts on cluster mapping: 0
Reverts on inter-cluster connectivity: 0
Reverts on pre-mapping validation: 0
Reverts on split failed: 0
[info] context_2 (context_2):
Iterations: 4
Reverts on cluster mapping: 0
Reverts on inter-cluster connectivity: 0
Reverts on pre-mapping validation: 0
Reverts on split failed: 0
[info] context_3 (context_3):
Iterations: 4
Reverts on cluster mapping: 0
Reverts on inter-cluster connectivity: 0
Reverts on pre-mapping validation: 0
Reverts on split failed: 0
[info] context_0 utilization: 
[info] +-----------+---------------------+---------------------+--------------------+
[info] | Cluster   | Control Utilization | Compute Utilization | Memory Utilization |
[info] +-----------+---------------------+---------------------+--------------------+
[info] | cluster_0 | 100%                | 76.6%               | 57.8%              |
[info] | cluster_1 | 31.3%               | 15.6%               | 13.3%              |
[info] | cluster_4 | 62.5%               | 34.4%               | 34.4%              |
[info] | cluster_5 | 50%                 | 23.4%               | 21.1%              |
[info] +-----------+---------------------+---------------------+--------------------+
[info] | Total     | 60.9%               | 37.5%               | 31.6%              |
[info] +-----------+---------------------+---------------------+--------------------+
[info] context_1 utilization: 
[info] +-----------+---------------------+---------------------+--------------------+
[info] | Cluster   | Control Utilization | Compute Utilization | Memory Utilization |
[info] +-----------+---------------------+---------------------+--------------------+
[info] | cluster_0 | 100%                | 39.1%               | 44.5%              |
[info] | cluster_1 | 25%                 | 25%                 | 22.7%              |
[info] | cluster_4 | 100%                | 67.2%               | 55.5%              |
[info] | cluster_5 | 18.8%               | 12.5%               | 7%                 |
[info] +-----------+---------------------+---------------------+--------------------+
[info] | Total     | 60.9%               | 35.9%               | 32.4%              |
[info] +-----------+---------------------+---------------------+--------------------+
[info] context_2 utilization: 
[info] +-----------+---------------------+---------------------+--------------------+
[info] | Cluster   | Control Utilization | Compute Utilization | Memory Utilization |
[info] +-----------+---------------------+---------------------+--------------------+
[info] | cluster_0 | 56.3%               | 73.4%               | 44.5%              |
[info] | cluster_1 | 50%                 | 40.6%               | 35.2%              |
[info] | cluster_4 | 87.5%               | 59.4%               | 53.1%              |
[info] | cluster_5 | 50%                 | 60.9%               | 36.7%              |
[info] +-----------+---------------------+---------------------+--------------------+
[info] | Total     | 60.9%               | 58.6%               | 42.4%              |
[info] +-----------+---------------------+---------------------+--------------------+
[info] context_3 utilization: 
[info] +-----------+---------------------+---------------------+--------------------+
[info] | Cluster   | Control Utilization | Compute Utilization | Memory Utilization |
[info] +-----------+---------------------+---------------------+--------------------+
[info] | cluster_0 | 50%                 | 39.1%               | 33.6%              |
[info] | cluster_1 | 75%                 | 57.8%               | 42.2%              |
[info] | cluster_4 | 50%                 | 32.8%               | 28.1%              |
[info] | cluster_5 | 68.8%               | 48.4%               | 35.9%              |
[info] +-----------+---------------------+---------------------+--------------------+
[info] | Total     | 60.9%               | 44.5%               | 35%                |
[info] +-----------+---------------------+---------------------+--------------------+
[info] Successful Mapping (allocation time: 3m 55s)
[info] Compiling context_0...
[info] Compiling context_1...
[info] Compiling context_2...
[info] Compiling context_3...
[info] Bandwidth of model inputs: 3.375 Mbps, outputs: 0.553711 Mbps (for a single frame)
[info] Bandwidth of DDR buffers: 0.0 Mbps (for a single frame)
[info] Bandwidth of inter context tensors: 10.9688 Mbps (for a single frame)
[info] Compiling context_0...
[info] Compiling context_1...
[info] Compiling context_2...
[info] Compiling context_3...
[info] Bandwidth of model inputs: 3.375 Mbps, outputs: 0.553711 Mbps (for a single frame)
[info] Bandwidth of DDR buffers: 0.0 Mbps (for a single frame)
[info] Bandwidth of inter context tensors: 10.9688 Mbps (for a single frame)
[info] Building HEF...
[info] Successful Compilation (compilation time: 7s)
</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="run-the-profiler-tool" class="level4">
<h4 class="anchored" data-anchor-id="run-the-profiler-tool">Run the Profiler Tool</h4>
<p>After compiling the model, we can run the Hailo profiler tool, which will open an HTML report in the browser.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the path for the compiled model HAR file</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>compiled_model_har_path <span class="op">=</span> onnx_file_path.parent <span class="op">/</span> <span class="ss">f"</span><span class="sc">{</span>onnx_file_path<span class="sc">.</span>stem<span class="sc">}</span><span class="ss">_compiled_model.har"</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the compiled model as a HAR file</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>runner.save_har(compiled_model_har_path)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the Hailo profiler on the compiled model</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>subprocess.run([<span class="st">"hailo"</span>, <span class="st">"profiler"</span>, <span class="bu">str</span>(compiled_model_har_path)], check<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled" title="Profiler Console Output">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Profiler Console Output
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<pre class="text"><code>[info] Saved HAR to: /mnt/ACASIS_4TB/Projects/GitHub/pytorch-yolox-object-detection-tutorial-code/notebooks/pytorch-yolox-object-detector/2024-09-08_19-22-32/hagrid-sample-30k-384p-yolox_tiny_compiled_model.har
[info] Current Time: 18:24:13, 10/14/24
[info] CPU: Architecture: x86_64, Model: 11th Gen Intel(R) Core(TM) i7-11700K @ 3.60GHz, Number Of Cores: 16, Utilization: 1.8%
[info] Memory: Total: 31GB, Available: 14GB
[info] System info: OS: Linux, Kernel: 6.8.0-45-generic
[info] Hailo DFC Version: 3.29.0
[info] HailoRT Version: Not Installed
[info] PCIe: No Hailo PCIe device was found
[info] Running `hailo profiler pytorch-yolox-object-detector/2024-09-08_19-22-32/hagrid-sample-30k-384p-yolox_tiny_compiled_model.har`
[info] Running profile for hagrid-sample-30k-384p-yolox_tiny in state compiled_model
[info] 
Model Details
--------------------------------  ----------
Input Tensors Shapes              288x512x3
Operations per Input Tensor       5.43 GOPs
Operations per Input Tensor       2.72 GMACs
Pure Operations per Input Tensor  5.43 GOPs
Pure Operations per Input Tensor  2.72 GMACs
Model Parameters                  5.09 M
--------------------------------  ----------

Profiler Input Settings
-----------------  -----------------
Optimization Goal  Reach Highest FPS
Profiler Mode      Compiled
-----------------  -----------------

Performance Summary
----------------------  ---
Number of Devices       1
Number of Contexts      4
Throughput              N/A
Latency                 N/A
Operations per Second   N/A
MACs per Second         N/A
Total Input Bandwidth   N/A
Total Output Bandwidth  N/A
Context Switch Configs  N/A
----------------------  ---
[info] Saved Profiler HTML Report to: /mnt/ACASIS_4TB/Projects/GitHub/pytorch-yolox-object-detection-tutorial-code/notebooks/hagrid-sample-30k-384p-yolox_tiny_compiled_model.html
CompletedProcess(args=['hailo', 'profiler', 'pytorch-yolox-object-detector/2024-09-08_19-22-32/hagrid-sample-30k-384p-yolox_tiny_compiled_model.har'], returncode=0)</code></pre>
</div>
</div>
</div>
<p>At last, we have completed the compilation process. Now, we can load our compiled model onto the Raspberry Pi and perform real-time object tracking.</p>
</section>
</section>
</section>
<section id="preparing-the-raspberry-pi" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-raspberry-pi">Preparing the Raspberry Pi</h2>
<p>This tutorial continues on a Raspberry Pi 5 with a freshly installed operating system, and it assumes a CSI camera module and an AI Kit are connected.</p>
<p>If you do not have a Raspberry Pi prepared, you can go through the following sections from the official Raspberry Pi documentation:</p>
<ul>
<li><a href="https://www.raspberrypi.com/documentation/computers/getting-started.html">Getting started with your Raspberry Pi</a></li>
<li><a href="https://www.raspberrypi.com/documentation/accessories/camera.html#install-a-raspberry-pi-camera">Install a Raspberry Pi camera</a></li>
<li><a href="https://www.raspberrypi.com/documentation/accessories/ai-kit.html">AI Kit - Install</a></li>
</ul>
<section id="hailo-ai-kit-setup" class="level3">
<h3 class="anchored" data-anchor-id="hailo-ai-kit-setup">Hailo AI Kit Setup</h3>
<p>After logging into the Raspberry Pi, we can set it up to use the AI Kit.</p>
<section id="ensure-the-raspberry-pi-is-fully-updated" class="level4">
<h4 class="anchored" data-anchor-id="ensure-the-raspberry-pi-is-fully-updated">Ensure the Raspberry Pi is fully updated</h4>
<p>To start, we should verify the Raspberry Pi is fully updated.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt update <span class="kw">&amp;&amp;</span> <span class="fu">sudo</span> apt full-upgrade <span class="at">-y</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="enable-pcie-gen-3.0" class="level4">
<h4 class="anchored" data-anchor-id="enable-pcie-gen-3.0">Enable PCIe Gen 3.0</h4>
<p>Next, the official documentation recommends enabling PCIe Gen 3.0 for the best performance.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> raspi-config</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol type="1">
<li>Select <code>Advanced Options</code>.</li>
<li>Select <code>PCIe Speed</code>.</li>
<li>Choose <code>Yes</code> to enable PCIe Gen 3 mode.</li>
<li>Select <code>Finish</code> to exit.</li>
<li>Reboot for the changes to take effect.</li>
</ol>
</section>
<section id="install-ai-kit-dependencies" class="level4">
<h4 class="anchored" data-anchor-id="install-ai-kit-dependencies">Install AI Kit Dependencies</h4>
<p>After the reboot, we can install the hailo-all package, which includes all the dependencies needed to use the AI Kit.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install hailo-all <span class="at">-y</span> <span class="kw">&amp;&amp;</span> <span class="fu">sudo</span> reboot</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Installs the following dependencies:</p>
<ul>
<li>Hailo kernel device driver and firmware</li>
<li>HailoRT middleware software</li>
<li>Hailo Tappas core post-processing libraries</li>
<li>The <code>rpicam-apps</code> Hailo post-processing software demo stages</li>
</ul>
</section>
</section>
</section>
<section id="setting-up-a-python-virtual-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-a-python-virtual-environment">Setting Up a Python Virtual Environment</h2>
<p>While we can install the Mamba package manager on the Raspberry Pi, a standard Python <a href="https://docs.python.org/3/library/venv.html">virtual environment</a> provides a more streamlined setup process for our needs.</p>
<section id="create-a-python-virtual-environment" class="level4">
<h4 class="anchored" data-anchor-id="create-a-python-virtual-environment">Create a Python Virtual Environment</h4>
<p>When creating the virtual environment, we will use the <code>--system-site-packages</code> option to give the virtual environment access to the system <code>site-packages</code> directory.</p>
<p>That will allow us to access the <code>hailort</code>, <code>numpy</code>, <code>opencv-python</code>, and <code>picamera2</code> packages already installed on the Raspberry Pi.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a venv that can access the system Python packages</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> <span class="at">-m</span> venv <span class="at">--system-site-packages</span> object-tracking-env</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="activate-python-virtual-environment" class="level4">
<h4 class="anchored" data-anchor-id="activate-python-virtual-environment">Activate Python Virtual Environment</h4>
<div class="sourceCode" id="cb61"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Activate the object-tracking-env venv</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> ./object-tracking-env/bin/activate</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="install-demo-dependencies" class="level4">
<h4 class="anchored" data-anchor-id="install-demo-dependencies">Install Demo Dependencies</h4>
<p>With the virtual environment active, we will install a few additional packages for our demo code.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install cjm_byte_track cjm_psl_utils cjm_pil_utils jupyter</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>With our environment set up, we can dive into the demo code.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Move Inference Resources to Raspberry Pi">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Move Inference Resources to Raspberry Pi
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before continuing, copy the compiled HEF file and the JSON colormap file to same folder on the Raspberry Pi where you created the virtual environment.</p>
</div>
</div>
</section>
</section>
<section id="getting-started-with-the-code-1" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-the-code-1">Getting Started with the Code</h2>
<p>This tutorial walks through the demo as a Jupyter Notebook, but the code is also available as a Python script.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Jupyter Notebook</th>
<th>Python Script</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/cj-mills/pytorch-yolox-object-detection-tutorial-code/blob/main/notebooks/yolox-hailo-bytetrack-rpi.ipynb">yolox-hailo-bytetrack-rpi.ipynb</a></td>
<td><a href="https://github.com/cj-mills/pytorch-yolox-object-detection-tutorial-code/blob/main/scripts/yolox-hailo-bytetrack-rpi.py">yolox-hailo-bytetrack-rpi.py</a></td>
</tr>
</tbody>
</table>
</section>
<section id="importing-the-required-dependencies-1" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-required-dependencies-1">Importing the Required Dependencies</h2>
<p>First, we will import the necessary Python packages.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import Python Standard Library dependencies</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Tuple, Optional, NamedTuple</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ByteTrack package for object tracking</span></span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cjm_byte_track.core <span class="im">import</span> BYTETracker</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cjm_byte_track.matching <span class="im">import</span> match_detections_with_tracks</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Utility functions</span></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cjm_psl_utils.core <span class="im">import</span> download_file  <span class="co"># For downloading files</span></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cjm_pil_utils.core <span class="im">import</span> resize_img  <span class="co"># For resizing images</span></span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a><span class="co"># OpenCV for computer vision tasks</span></span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a><span class="co"># NumPy for numerical operations</span></span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a><span class="co"># PIL (Python Imaging Library) for image processing</span></span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image, ImageDraw, ImageFont</span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Import Hailo Runtime dependencies</span></span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hailo_platform <span class="im">import</span> (</span>
<span id="cb63-26"><a href="#cb63-26" aria-hidden="true" tabindex="-1"></a>    HEF,</span>
<span id="cb63-27"><a href="#cb63-27" aria-hidden="true" tabindex="-1"></a>    ConfigureParams,</span>
<span id="cb63-28"><a href="#cb63-28" aria-hidden="true" tabindex="-1"></a>    FormatType,</span>
<span id="cb63-29"><a href="#cb63-29" aria-hidden="true" tabindex="-1"></a>    HailoSchedulingAlgorithm,</span>
<span id="cb63-30"><a href="#cb63-30" aria-hidden="true" tabindex="-1"></a>    HailoStreamInterface,</span>
<span id="cb63-31"><a href="#cb63-31" aria-hidden="true" tabindex="-1"></a>    InferVStreams,</span>
<span id="cb63-32"><a href="#cb63-32" aria-hidden="true" tabindex="-1"></a>    InputVStreamParams,</span>
<span id="cb63-33"><a href="#cb63-33" aria-hidden="true" tabindex="-1"></a>    OutputVStreamParams,</span>
<span id="cb63-34"><a href="#cb63-34" aria-hidden="true" tabindex="-1"></a>    VDevice</span>
<span id="cb63-35"><a href="#cb63-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb63-36"><a href="#cb63-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-37"><a href="#cb63-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Import Picamera2</span></span>
<span id="cb63-38"><a href="#cb63-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2, Preview</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="define-utility-functions" class="level2">
<h2 class="anchored" data-anchor-id="define-utility-functions">Define Utility Functions</h2>
<p>Next, we will add all the utility functions we implemented for the optimization step.</p>
<section id="define-functions-to-handle-arbitrary-input-resolutions-1" class="level4">
<h4 class="anchored" data-anchor-id="define-functions-to-handle-arbitrary-input-resolutions-1">Define Functions to Handle Arbitrary Input Resolutions</h4>
<p>The original <code>resize_and_pad</code> function ended up being a performance bottleneck on the Raspberry Pi, so I updated it to use NumPy and the OpenCV <code>resize</code> method instead of PIL.</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ImageTransformData(NamedTuple):</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co">    A data class that stores transformation information applied to an image.</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Attributes:</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="co">        offset (Tuple[int, int]): The (x, y) offset where the resized image was pasted.</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a><span class="co">        scale (float): The scaling factor applied to the original image.</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>    offset: Tuple[<span class="bu">int</span>, <span class="bu">int</span>]</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>    scale: <span class="bu">float</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> resize_and_pad(</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    image: np.ndarray,</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    target_sz: Tuple[<span class="bu">int</span>, <span class="bu">int</span>],</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>    return_transform_data: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    fill_color: Tuple[<span class="bu">int</span>, <span class="bu">int</span>, <span class="bu">int</span>] <span class="op">=</span> (<span class="dv">255</span>, <span class="dv">255</span>, <span class="dv">255</span>)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Tuple[np.ndarray, Optional[ImageTransformData]]:</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Resize an image while maintaining its aspect ratio and pad it to fit the target size.</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a><span class="co">        image (np.ndarray): The original image as a numpy array.</span></span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a><span class="co">        target_sz (Tuple[int, int]): The desired size (width, height) for the output image.</span></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a><span class="co">        return_transform_data (bool, optional): If True, returns transformation data (offset and scale).</span></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a><span class="co">        fill_color (Tuple[int, int, int], optional): The color to use for padding (default is white).</span></span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Tuple[np.ndarray, Optional[ImageTransformData]]: The resized and padded image,</span></span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a><span class="co">        and optionally the transformation data.</span></span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a>    target_width, target_height <span class="op">=</span> target_sz</span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>    orig_height, orig_width <span class="op">=</span> image.shape[:<span class="dv">2</span>]</span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a>    aspect_ratio <span class="op">=</span> orig_width <span class="op">/</span> orig_height</span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a>    target_aspect_ratio <span class="op">=</span> target_width <span class="op">/</span> target_height</span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> aspect_ratio <span class="op">&gt;</span> target_aspect_ratio:</span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a>        new_width <span class="op">=</span> target_width</span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a>        new_height <span class="op">=</span> <span class="bu">int</span>(new_width <span class="op">/</span> aspect_ratio)</span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> target_width <span class="op">/</span> orig_width</span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a>        new_height <span class="op">=</span> target_height</span>
<span id="cb65-32"><a href="#cb65-32" aria-hidden="true" tabindex="-1"></a>        new_width <span class="op">=</span> <span class="bu">int</span>(new_height <span class="op">*</span> aspect_ratio)</span>
<span id="cb65-33"><a href="#cb65-33" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> target_height <span class="op">/</span> orig_height</span>
<span id="cb65-34"><a href="#cb65-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-35"><a href="#cb65-35" aria-hidden="true" tabindex="-1"></a>    resized_image <span class="op">=</span> cv2.resize(image, (new_width, new_height), interpolation<span class="op">=</span>cv2.INTER_NEAREST)</span>
<span id="cb65-36"><a href="#cb65-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-37"><a href="#cb65-37" aria-hidden="true" tabindex="-1"></a>    paste_x <span class="op">=</span> (target_width <span class="op">-</span> new_width) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb65-38"><a href="#cb65-38" aria-hidden="true" tabindex="-1"></a>    paste_y <span class="op">=</span> (target_height <span class="op">-</span> new_height) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb65-39"><a href="#cb65-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-40"><a href="#cb65-40" aria-hidden="true" tabindex="-1"></a>    padded_image <span class="op">=</span> np.full((target_height, target_width, <span class="dv">3</span>), fill_color, dtype<span class="op">=</span>np.uint8)</span>
<span id="cb65-41"><a href="#cb65-41" aria-hidden="true" tabindex="-1"></a>    padded_image[paste_y:paste_y<span class="op">+</span>new_height, paste_x:paste_x<span class="op">+</span>new_width] <span class="op">=</span> resized_image</span>
<span id="cb65-42"><a href="#cb65-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-43"><a href="#cb65-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> return_transform_data:</span>
<span id="cb65-44"><a href="#cb65-44" aria-hidden="true" tabindex="-1"></a>        transform_data <span class="op">=</span> ImageTransformData(offset<span class="op">=</span>(paste_x, paste_y), scale<span class="op">=</span>scale)</span>
<span id="cb65-45"><a href="#cb65-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> padded_image, transform_data</span>
<span id="cb65-46"><a href="#cb65-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb65-47"><a href="#cb65-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> padded_image, <span class="va">None</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> adjust_bbox(</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>    bbox: Tuple[<span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>],</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>    transform_data: ImageTransformData</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Tuple[<span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>]:</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Adjust a bounding box according to the transformation data (offset and scale).</span></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a><span class="co">        bbox (Tuple[float, float, float, float]): The original bounding box as (x, y, width, height).</span></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a><span class="co">        transform_data (ImageTransformData): The transformation data containing offset and scale.</span></span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a><span class="co">        Tuple[float, float, float, float]: The adjusted bounding box.</span></span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Unpack the bounding box coordinates and size</span></span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>    x, y, w, h <span class="op">=</span> bbox</span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Unpack the transformation data</span></span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a>    offset_x, offset_y <span class="op">=</span> transform_data.offset</span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>    scale <span class="op">=</span> transform_data.scale</span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adjust the coordinates by subtracting the offset and dividing by the scale</span></span>
<span id="cb66-23"><a href="#cb66-23" aria-hidden="true" tabindex="-1"></a>    adjusted_x <span class="op">=</span> (x <span class="op">-</span> offset_x) <span class="op">/</span> scale</span>
<span id="cb66-24"><a href="#cb66-24" aria-hidden="true" tabindex="-1"></a>    adjusted_y <span class="op">=</span> (y <span class="op">-</span> offset_y) <span class="op">/</span> scale</span>
<span id="cb66-25"><a href="#cb66-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-26"><a href="#cb66-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adjust the size by dividing by the scale</span></span>
<span id="cb66-27"><a href="#cb66-27" aria-hidden="true" tabindex="-1"></a>    adjusted_w <span class="op">=</span> w <span class="op">/</span> scale</span>
<span id="cb66-28"><a href="#cb66-28" aria-hidden="true" tabindex="-1"></a>    adjusted_h <span class="op">=</span> h <span class="op">/</span> scale</span>
<span id="cb66-29"><a href="#cb66-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-30"><a href="#cb66-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (adjusted_x, adjusted_y, adjusted_w, adjusted_h)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="define-postprocessing-functions-1" class="level4">
<h4 class="anchored" data-anchor-id="define-postprocessing-functions-1">Define Postprocessing Functions</h4>
<div class="sourceCode" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_output_grids_np(height, width, strides<span class="op">=</span>[<span class="dv">8</span>,<span class="dv">16</span>,<span class="dv">32</span>]):</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate a numpy array containing grid coordinates and strides for a given height and width.</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a><span class="co">        height (int): The height of the image.</span></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a><span class="co">        width (int): The width of the image.</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a><span class="co">        np.ndarray: A numpy array containing grid coordinates and strides.</span></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>    all_coordinates <span class="op">=</span> []</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> stride <span class="kw">in</span> strides:</span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the grid height and width</span></span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a>        grid_height <span class="op">=</span> height <span class="op">//</span> stride</span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a>        grid_width <span class="op">=</span> width <span class="op">//</span> stride</span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate grid coordinates</span></span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a>        g1, g0 <span class="op">=</span> np.meshgrid(np.arange(grid_height), np.arange(grid_width), indexing<span class="op">=</span><span class="st">'ij'</span>)</span>
<span id="cb67-22"><a href="#cb67-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-23"><a href="#cb67-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create an array of strides</span></span>
<span id="cb67-24"><a href="#cb67-24" aria-hidden="true" tabindex="-1"></a>        s <span class="op">=</span> np.full((grid_height, grid_width), stride)</span>
<span id="cb67-25"><a href="#cb67-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-26"><a href="#cb67-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stack the coordinates along with the stride</span></span>
<span id="cb67-27"><a href="#cb67-27" aria-hidden="true" tabindex="-1"></a>        coordinates <span class="op">=</span> np.stack((g0.flatten(), g1.flatten(), s.flatten()), axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb67-28"><a href="#cb67-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-29"><a href="#cb67-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append to the list</span></span>
<span id="cb67-30"><a href="#cb67-30" aria-hidden="true" tabindex="-1"></a>        all_coordinates.append(coordinates)</span>
<span id="cb67-31"><a href="#cb67-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-32"><a href="#cb67-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Concatenate all arrays in the list along the first dimension</span></span>
<span id="cb67-33"><a href="#cb67-33" aria-hidden="true" tabindex="-1"></a>    output_grids <span class="op">=</span> np.concatenate(all_coordinates, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb67-34"><a href="#cb67-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-35"><a href="#cb67-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output_grids</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_boxes_and_probs(model_output:np.ndarray, output_grids:np.ndarray) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Calculate the bounding boxes and their probabilities.</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="co">    model_output (numpy.ndarray): The output of the model.</span></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="co">    output_grids (numpy.ndarray): The output grids.</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a><span class="co">    numpy.ndarray: The array containing the bounding box coordinates, class labels, and maximum probabilities.</span></span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the bounding box coordinates</span></span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>    box_centroids <span class="op">=</span> (model_output[..., :<span class="dv">2</span>] <span class="op">+</span> output_grids[..., :<span class="dv">2</span>]) <span class="op">*</span> output_grids[..., <span class="dv">2</span>:]</span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a>    box_sizes <span class="op">=</span> np.exp(model_output[..., <span class="dv">2</span>:<span class="dv">4</span>]) <span class="op">*</span> output_grids[..., <span class="dv">2</span>:]</span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a>    x0, y0 <span class="op">=</span> [t.squeeze(axis<span class="op">=</span><span class="dv">2</span>) <span class="cf">for</span> t <span class="kw">in</span> np.split(box_centroids <span class="op">-</span> box_sizes <span class="op">/</span> <span class="dv">2</span>, <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">2</span>)]</span>
<span id="cb68-17"><a href="#cb68-17" aria-hidden="true" tabindex="-1"></a>    w, h <span class="op">=</span> [t.squeeze(axis<span class="op">=</span><span class="dv">2</span>) <span class="cf">for</span> t <span class="kw">in</span> np.split(box_sizes, <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">2</span>)]</span>
<span id="cb68-18"><a href="#cb68-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-19"><a href="#cb68-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the probabilities for each class</span></span>
<span id="cb68-20"><a href="#cb68-20" aria-hidden="true" tabindex="-1"></a>    box_objectness <span class="op">=</span> model_output[..., <span class="dv">4</span>]</span>
<span id="cb68-21"><a href="#cb68-21" aria-hidden="true" tabindex="-1"></a>    box_cls_scores <span class="op">=</span> model_output[..., <span class="dv">5</span>:]</span>
<span id="cb68-22"><a href="#cb68-22" aria-hidden="true" tabindex="-1"></a>    box_probs <span class="op">=</span> np.expand_dims(box_objectness, <span class="op">-</span><span class="dv">1</span>) <span class="op">*</span> box_cls_scores</span>
<span id="cb68-23"><a href="#cb68-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-24"><a href="#cb68-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the maximum probability and corresponding class for each proposal</span></span>
<span id="cb68-25"><a href="#cb68-25" aria-hidden="true" tabindex="-1"></a>    max_probs <span class="op">=</span> np.<span class="bu">max</span>(box_probs, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb68-26"><a href="#cb68-26" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> np.argmax(box_probs, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb68-27"><a href="#cb68-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-28"><a href="#cb68-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([x0, y0, w, h, labels, max_probs]).transpose((<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_outputs(outputs:np.ndarray, input_dims:<span class="bu">tuple</span>, bbox_conf_thresh:<span class="bu">float</span>):</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Process the model outputs to generate bounding box proposals filtered by confidence threshold.</span></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - outputs (numpy.ndarray): The raw output from the model, which will be processed to calculate boxes and probabilities.</span></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - input_dims (tuple of int): Dimensions (height, width) of the input image to the model.</span></span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - bbox_conf_thresh (float): Threshold for the bounding box confidence/probability. Bounding boxes with a confidence</span></span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a><span class="co">                                score below this threshold will be discarded.</span></span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a><span class="co">    - numpy.array: An array of proposals where each proposal is an array containing bounding box coordinates</span></span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a><span class="co">                   and its associated probability, sorted in descending order by probability.</span></span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process the model output</span></span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> calculate_boxes_and_probs(outputs, generate_output_grids_np(<span class="op">*</span>input_dims))</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter the proposals based on the confidence threshold</span></span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a>    max_probs <span class="op">=</span> outputs[:, :, <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> max_probs <span class="op">&gt;</span> bbox_conf_thresh</span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a>    proposals <span class="op">=</span> outputs[mask]</span>
<span id="cb69-23"><a href="#cb69-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort the proposals by probability in descending order</span></span>
<span id="cb69-24"><a href="#cb69-24" aria-hidden="true" tabindex="-1"></a>    proposals <span class="op">=</span> proposals[proposals[..., <span class="op">-</span><span class="dv">1</span>].argsort()][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb69-25"><a href="#cb69-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> proposals</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_iou(proposals:np.ndarray) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Calculates the Intersection over Union (IoU) for all pairs of bounding boxes (x,y,w,h) in 'proposals'.</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="co">    The IoU is a measure of overlap between two bounding boxes. It is calculated as the area of</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a><span class="co">    intersection divided by the area of union of the two boxes.</span></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a><span class="co">    proposals (2D np.array): A NumPy array of bounding boxes, where each box is an array [x, y, width, height].</span></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a><span class="co">    iou (2D np.array): The IoU matrix where each element i,j represents the IoU of boxes i and j.</span></span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate coordinates for the intersection rectangles</span></span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>    x1 <span class="op">=</span> np.maximum(proposals[:, <span class="dv">0</span>], proposals[:, <span class="dv">0</span>][:, <span class="va">None</span>])</span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>    y1 <span class="op">=</span> np.maximum(proposals[:, <span class="dv">1</span>], proposals[:, <span class="dv">1</span>][:, <span class="va">None</span>])</span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>    x2 <span class="op">=</span> np.minimum(proposals[:, <span class="dv">0</span>] <span class="op">+</span> proposals[:, <span class="dv">2</span>], (proposals[:, <span class="dv">0</span>] <span class="op">+</span> proposals[:, <span class="dv">2</span>])[:, <span class="va">None</span>])</span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a>    y2 <span class="op">=</span> np.minimum(proposals[:, <span class="dv">1</span>] <span class="op">+</span> proposals[:, <span class="dv">3</span>], (proposals[:, <span class="dv">1</span>] <span class="op">+</span> proposals[:, <span class="dv">3</span>])[:, <span class="va">None</span>])</span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate intersection areas</span></span>
<span id="cb70-22"><a href="#cb70-22" aria-hidden="true" tabindex="-1"></a>    intersections <span class="op">=</span> np.maximum(x2 <span class="op">-</span> x1, <span class="dv">0</span>) <span class="op">*</span> np.maximum(y2 <span class="op">-</span> y1, <span class="dv">0</span>)</span>
<span id="cb70-23"><a href="#cb70-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-24"><a href="#cb70-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate union areas</span></span>
<span id="cb70-25"><a href="#cb70-25" aria-hidden="true" tabindex="-1"></a>    areas <span class="op">=</span> proposals[:, <span class="dv">2</span>] <span class="op">*</span> proposals[:, <span class="dv">3</span>]</span>
<span id="cb70-26"><a href="#cb70-26" aria-hidden="true" tabindex="-1"></a>    unions <span class="op">=</span> areas[:, <span class="va">None</span>] <span class="op">+</span> areas <span class="op">-</span> intersections</span>
<span id="cb70-27"><a href="#cb70-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-28"><a href="#cb70-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate IoUs</span></span>
<span id="cb70-29"><a href="#cb70-29" aria-hidden="true" tabindex="-1"></a>    iou <span class="op">=</span> intersections <span class="op">/</span> unions</span>
<span id="cb70-30"><a href="#cb70-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-31"><a href="#cb70-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the iou matrix</span></span>
<span id="cb70-32"><a href="#cb70-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> iou</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> nms_sorted_boxes(iou:np.ndarray, iou_thresh:<span class="bu">float</span><span class="op">=</span><span class="fl">0.45</span>) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Applies non-maximum suppression (NMS) to sorted bounding boxes.</span></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a><span class="co">    It suppresses boxes that have high overlap (as defined by the IoU threshold) with a box that </span></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a><span class="co">    has a higher score.</span></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a><span class="co">    iou (np.ndarray): An IoU matrix where each element i,j represents the IoU of boxes i and j.</span></span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a><span class="co">    iou_thresh (float): The IoU threshold for suppression. Boxes with IoU &gt; iou_thresh are suppressed.</span></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a><span class="co">    keep (np.ndarray): The indices of the boxes to keep after applying NMS.</span></span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a boolean mask to keep track of boxes</span></span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> np.ones(iou.shape[<span class="dv">0</span>], dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply non-max suppression</span></span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iou.shape[<span class="dv">0</span>]):</span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mask[i]:</span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Suppress boxes with higher index and IoU &gt; threshold</span></span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a>            mask[(iou[i] <span class="op">&gt;</span> iou_thresh) <span class="op">&amp;</span> (np.arange(iou.shape[<span class="dv">0</span>]) <span class="op">&gt;</span> i)] <span class="op">=</span> <span class="va">False</span></span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the indices of the boxes to keep</span></span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.arange(iou.shape[<span class="dv">0</span>])[mask]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="define-bounding-box-annotation-function-1" class="level4">
<h4 class="anchored" data-anchor-id="define-bounding-box-annotation-function-1">Define Bounding Box Annotation Function</h4>
<div class="sourceCode" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_bboxes_pil(image, boxes, labels, colors, font, width:<span class="bu">int</span><span class="op">=</span><span class="dv">2</span>, font_size:<span class="bu">int</span><span class="op">=</span><span class="dv">18</span>, probs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Annotates an image with bounding boxes, labels, and optional probability scores.</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a><span class="co">    This function draws bounding boxes on the provided image using the given box coordinates, </span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a><span class="co">    colors, and labels. If probabilities are provided, they will be added to the labels.</span></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a><span class="co">    image (PIL.Image): The input image on which annotations will be drawn.</span></span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a><span class="co">    boxes (list of tuples): A list of bounding box coordinates where each tuple is (x, y, w, h).</span></span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a><span class="co">    labels (list of str): A list of labels corresponding to each bounding box.</span></span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a><span class="co">    colors (list of str): A list of colors for each bounding box and its corresponding label.</span></span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a><span class="co">    font (str): Path to the font file to be used for displaying the labels.</span></span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a><span class="co">    width (int, optional): Width of the bounding box lines. Defaults to 2.</span></span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a><span class="co">    font_size (int, optional): Size of the font for the labels. Defaults to 25.</span></span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a><span class="co">    probs (list of float, optional): A list of probability scores corresponding to each label. Defaults to None.</span></span>
<span id="cb72-17"><a href="#cb72-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-18"><a href="#cb72-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb72-19"><a href="#cb72-19" aria-hidden="true" tabindex="-1"></a><span class="co">    annotated_image (PIL.Image): The image annotated with bounding boxes, labels, and optional probability scores.</span></span>
<span id="cb72-20"><a href="#cb72-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb72-21"><a href="#cb72-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-22"><a href="#cb72-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define a reference diagonal</span></span>
<span id="cb72-23"><a href="#cb72-23" aria-hidden="true" tabindex="-1"></a>    REFERENCE_DIAGONAL <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb72-24"><a href="#cb72-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-25"><a href="#cb72-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Scale the font size using the hypotenuse of the image</span></span>
<span id="cb72-26"><a href="#cb72-26" aria-hidden="true" tabindex="-1"></a>    font_size <span class="op">=</span> <span class="bu">int</span>(font_size <span class="op">*</span> (np.hypot(<span class="op">*</span>image.size) <span class="op">/</span> REFERENCE_DIAGONAL))</span>
<span id="cb72-27"><a href="#cb72-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-28"><a href="#cb72-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add probability scores to labels</span></span>
<span id="cb72-29"><a href="#cb72-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> probs <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb72-30"><a href="#cb72-30" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> [<span class="ss">f"</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>prob<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span> <span class="cf">for</span> label, prob <span class="kw">in</span> <span class="bu">zip</span>(labels, probs)]</span>
<span id="cb72-31"><a href="#cb72-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-32"><a href="#cb72-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a copy of the image</span></span>
<span id="cb72-33"><a href="#cb72-33" aria-hidden="true" tabindex="-1"></a>    annotated_image <span class="op">=</span> image.copy()</span>
<span id="cb72-34"><a href="#cb72-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-35"><a href="#cb72-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create an ImageDraw object for drawing on the image</span></span>
<span id="cb72-36"><a href="#cb72-36" aria-hidden="true" tabindex="-1"></a>    draw <span class="op">=</span> ImageDraw.Draw(annotated_image)</span>
<span id="cb72-37"><a href="#cb72-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-38"><a href="#cb72-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loop through the bounding boxes and labels in the 'annotation' DataFrame</span></span>
<span id="cb72-39"><a href="#cb72-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(labels)):</span>
<span id="cb72-40"><a href="#cb72-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the bounding box coordinates</span></span>
<span id="cb72-41"><a href="#cb72-41" aria-hidden="true" tabindex="-1"></a>        x, y, w, h <span class="op">=</span> boxes[i]</span>
<span id="cb72-42"><a href="#cb72-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-43"><a href="#cb72-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a tuple of coordinates for the bounding box</span></span>
<span id="cb72-44"><a href="#cb72-44" aria-hidden="true" tabindex="-1"></a>        shape <span class="op">=</span> (x, y, x<span class="op">+</span>w, y<span class="op">+</span>h)</span>
<span id="cb72-45"><a href="#cb72-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-46"><a href="#cb72-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Draw the bounding box on the image</span></span>
<span id="cb72-47"><a href="#cb72-47" aria-hidden="true" tabindex="-1"></a>        draw.rectangle(shape, outline<span class="op">=</span>colors[i], width<span class="op">=</span>width)</span>
<span id="cb72-48"><a href="#cb72-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb72-49"><a href="#cb72-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Load the font file</span></span>
<span id="cb72-50"><a href="#cb72-50" aria-hidden="true" tabindex="-1"></a>        fnt <span class="op">=</span> ImageFont.truetype(font, font_size)</span>
<span id="cb72-51"><a href="#cb72-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb72-52"><a href="#cb72-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Draw the label box on the image</span></span>
<span id="cb72-53"><a href="#cb72-53" aria-hidden="true" tabindex="-1"></a>        label_w, label_h <span class="op">=</span> draw.textbbox(xy<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">0</span>), text<span class="op">=</span>labels[i], font<span class="op">=</span>fnt)[<span class="dv">2</span>:]</span>
<span id="cb72-54"><a href="#cb72-54" aria-hidden="true" tabindex="-1"></a>        draw.rectangle((x, y<span class="op">-</span>label_h, x<span class="op">+</span>label_w, y), outline<span class="op">=</span>colors[i], fill<span class="op">=</span>colors[i], width<span class="op">=</span>width)</span>
<span id="cb72-55"><a href="#cb72-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-56"><a href="#cb72-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Draw the label on the image</span></span>
<span id="cb72-57"><a href="#cb72-57" aria-hidden="true" tabindex="-1"></a>        draw.multiline_text((x, y<span class="op">-</span>label_h), labels[i], font<span class="op">=</span>fnt, fill<span class="op">=</span><span class="st">'black'</span> <span class="cf">if</span> np.mean(colors[i]) <span class="op">&gt;</span> <span class="fl">127.5</span> <span class="cf">else</span> <span class="st">'white'</span>)</span>
<span id="cb72-58"><a href="#cb72-58" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb72-59"><a href="#cb72-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> annotated_image</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="setting-up-the-project-1" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-the-project-1">Setting Up the Project</h2>
<p>Next, we will set the folder location for the HEF model and JSON colormap file.</p>
<section id="set-the-directory-paths-1" class="level3">
<h3 class="anchored" data-anchor-id="set-the-directory-paths-1">Set the Directory Paths</h3>
<div class="sourceCode" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The path to the checkpoint folder</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>checkpoint_dir <span class="op">=</span> Path(<span class="st">"./"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="download-a-font-file-1" class="level3">
<h3 class="anchored" data-anchor-id="download-a-font-file-1">Download a Font File</h3>
<p>We should also ensure we have a font file for annotating images.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the name of the font file</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>font_file <span class="op">=</span> <span class="st">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the font file</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>download_file(<span class="ss">f"https://fonts.gstatic.com/s/roboto/v30/</span><span class="sc">{</span>font_file<span class="sc">}</span><span class="ss">"</span>, <span class="st">"./"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="loading-the-inference-resources" class="level2">
<h2 class="anchored" data-anchor-id="loading-the-inference-resources">Loading the Inference Resources</h2>
<p>Next, we will load the colormap and the compiled HEF model.</p>
<section id="load-the-colormap-1" class="level3">
<h3 class="anchored" data-anchor-id="load-the-colormap-1">Load the Colormap</h3>
<div class="sourceCode" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The colormap path</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>colormap_path <span class="op">=</span> <span class="bu">list</span>(checkpoint_dir.glob(<span class="st">'*colormap.json'</span>))[<span class="dv">0</span>]</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the JSON colormap data</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(colormap_path, <span class="st">'r'</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>        colormap_json <span class="op">=</span> json.load(<span class="bu">file</span>)</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the JSON data to a dictionary        </span></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>colormap_dict <span class="op">=</span> {item[<span class="st">'label'</span>]: item[<span class="st">'color'</span>] <span class="cf">for</span> item <span class="kw">in</span> colormap_json[<span class="st">'items'</span>]}</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the class names from the colormap</span></span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> <span class="bu">list</span>(colormap_dict.keys())</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a copy of the colormap in integer format</span></span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>int_colors <span class="op">=</span> [<span class="bu">tuple</span>(<span class="bu">int</span>(c<span class="op">*</span><span class="dv">255</span>) <span class="cf">for</span> c <span class="kw">in</span> color) <span class="cf">for</span> color <span class="kw">in</span> colormap_dict.values()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="load-the-compiled-hef-model" class="level3">
<h3 class="anchored" data-anchor-id="load-the-compiled-hef-model">Load the Compiled HEF Model</h3>
<div class="sourceCode" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The HEF (Hailo Executable Format) model path</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>hef_file_path <span class="op">=</span> <span class="bu">list</span>(checkpoint_dir.glob(<span class="st">'*.hef'</span>))[<span class="dv">0</span>]</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the compiled HEF to Hailo device</span></span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>hef <span class="op">=</span> HEF(<span class="bu">str</span>(hef_file_path))</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Set VDevice (Virtual Device) params to disable the HailoRT service feature</span></span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> VDevice.create_params()</span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>params.scheduling_algorithm <span class="op">=</span> HailoSchedulingAlgorithm.NONE</span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Hailo virtual device with the specified parameters</span></span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> VDevice(params<span class="op">=</span>params)</span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the "network groups" (connectivity groups, aka. "different networks") information from the .hef</span></span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure the device with the HEF and PCIe interface</span></span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a>configure_params <span class="op">=</span> ConfigureParams.create_from_hef(hef<span class="op">=</span>hef, interface<span class="op">=</span>HailoStreamInterface.PCIe)</span>
<span id="cb76-17"><a href="#cb76-17" aria-hidden="true" tabindex="-1"></a>network_groups <span class="op">=</span> target.configure(hef, configure_params)</span>
<span id="cb76-18"><a href="#cb76-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-19"><a href="#cb76-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Select the first network group (there's only one in this case)</span></span>
<span id="cb76-20"><a href="#cb76-20" aria-hidden="true" tabindex="-1"></a>network_group <span class="op">=</span> network_groups[<span class="dv">0</span>]</span>
<span id="cb76-21"><a href="#cb76-21" aria-hidden="true" tabindex="-1"></a>network_group_params <span class="op">=</span> network_group.create_params()</span>
<span id="cb76-22"><a href="#cb76-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-23"><a href="#cb76-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Create input and output virtual streams params</span></span>
<span id="cb76-24"><a href="#cb76-24" aria-hidden="true" tabindex="-1"></a><span class="co"># These specify the format of the input and output data (in this case, 32-bit float)</span></span>
<span id="cb76-25"><a href="#cb76-25" aria-hidden="true" tabindex="-1"></a>input_vstreams_params <span class="op">=</span> InputVStreamParams.make(network_group, format_type<span class="op">=</span>FormatType.FLOAT32)</span>
<span id="cb76-26"><a href="#cb76-26" aria-hidden="true" tabindex="-1"></a>output_vstreams_params <span class="op">=</span> OutputVStreamParams.make(network_group, format_type<span class="op">=</span>FormatType.FLOAT32)</span>
<span id="cb76-27"><a href="#cb76-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-28"><a href="#cb76-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Get information about the input and output virtual streams</span></span>
<span id="cb76-29"><a href="#cb76-29" aria-hidden="true" tabindex="-1"></a>input_vstream_info <span class="op">=</span> hef.get_input_vstream_infos()[<span class="dv">0</span>]</span>
<span id="cb76-30"><a href="#cb76-30" aria-hidden="true" tabindex="-1"></a>output_vstream_info <span class="op">=</span> hef.get_output_vstream_infos()[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="tracking-objects-in-a-camera-feed" class="level2">
<h2 class="anchored" data-anchor-id="tracking-objects-in-a-camera-feed">Tracking Objects in a Camera Feed</h2>
<p>Next, we will define the dimensions for the camera feed preview and inference parameters for processing the model output.</p>
<section id="define-inference-parameters" class="level3">
<h3 class="anchored" data-anchor-id="define-inference-parameters">Define Inference Parameters</h3>
<div class="sourceCode" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the desired preview size</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>preview_width, preview_height <span class="op">=</span> <span class="dv">960</span>, <span class="dv">540</span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>bbox_conf_thresh <span class="op">=</span> <span class="fl">0.35</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>iou_thresh <span class="op">=</span> <span class="fl">0.45</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="detect-track-and-annotate-objects" class="level3">
<h3 class="anchored" data-anchor-id="detect-track-and-annotate-objects">Detect, Track, and Annotate Objects</h3>
<p>At last, we can set up a Picamera2 for video capture, initialize our object tracker, and implement our video processing loop.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up window title for display</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>window_title <span class="op">=</span> <span class="st">"Camera Feed - Press 'q' to Quit"</span></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Picamera2 object</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> Picamera2()</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print available sensor modes</span></span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Available sensor modes:"</span>)</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, mode <span class="kw">in</span> <span class="bu">enumerate</span>(picam2.sensor_modes):</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mode </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>mode[<span class="st">'size'</span>]<span class="sc">}</span><span class="ss">x</span><span class="sc">{</span>mode[<span class="st">'fps'</span>]<span class="sc">}</span><span class="ss">fps"</span>)</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose a mode (let's say we want the second mode, index 1)</span></span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>chosen_mode <span class="op">=</span> picam2.sensor_modes[<span class="dv">0</span>]</span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a configuration using the chosen mode</span></span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> picam2.create_preview_configuration(</span>
<span id="cb78-17"><a href="#cb78-17" aria-hidden="true" tabindex="-1"></a>    main<span class="op">=</span>{</span>
<span id="cb78-18"><a href="#cb78-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">"size"</span>: chosen_mode[<span class="st">"size"</span>],</span>
<span id="cb78-19"><a href="#cb78-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"format"</span>: <span class="st">"RGB888"</span></span>
<span id="cb78-20"><a href="#cb78-20" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb78-21"><a href="#cb78-21" aria-hidden="true" tabindex="-1"></a>    controls<span class="op">=</span>{</span>
<span id="cb78-22"><a href="#cb78-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"FrameRate"</span>: chosen_mode[<span class="st">"fps"</span>]</span>
<span id="cb78-23"><a href="#cb78-23" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb78-24"><a href="#cb78-24" aria-hidden="true" tabindex="-1"></a>    sensor<span class="op">=</span>{</span>
<span id="cb78-25"><a href="#cb78-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">"output_size"</span>: chosen_mode[<span class="st">"size"</span>],</span>
<span id="cb78-26"><a href="#cb78-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">"bit_depth"</span>: chosen_mode[<span class="st">"bit_depth"</span>]</span>
<span id="cb78-27"><a href="#cb78-27" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb78-28"><a href="#cb78-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-29"><a href="#cb78-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-30"><a href="#cb78-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure the camera</span></span>
<span id="cb78-31"><a href="#cb78-31" aria-hidden="true" tabindex="-1"></a>picam2.configure(config)</span>
<span id="cb78-32"><a href="#cb78-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-33"><a href="#cb78-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Start the camera</span></span>
<span id="cb78-34"><a href="#cb78-34" aria-hidden="true" tabindex="-1"></a>picam2.start()</span>
<span id="cb78-35"><a href="#cb78-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-36"><a href="#cb78-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the ByteTracker for object tracking</span></span>
<span id="cb78-37"><a href="#cb78-37" aria-hidden="true" tabindex="-1"></a>tracker <span class="op">=</span> BYTETracker(track_thresh<span class="op">=</span><span class="fl">0.25</span>, track_buffer<span class="op">=</span><span class="dv">30</span>, match_thresh<span class="op">=</span><span class="fl">0.8</span>, frame_rate<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb78-38"><a href="#cb78-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-39"><a href="#cb78-39" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb78-40"><a href="#cb78-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb78-41"><a href="#cb78-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Main processing loop</span></span>
<span id="cb78-42"><a href="#cb78-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb78-43"><a href="#cb78-43" aria-hidden="true" tabindex="-1"></a>        start_time <span class="op">=</span> time.perf_counter()</span>
<span id="cb78-44"><a href="#cb78-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb78-45"><a href="#cb78-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Capture a frame</span></span>
<span id="cb78-46"><a href="#cb78-46" aria-hidden="true" tabindex="-1"></a>        frame <span class="op">=</span> picam2.capture_array()</span>
<span id="cb78-47"><a href="#cb78-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-48"><a href="#cb78-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Resize and pad the sample image to the desired input size, retrieving transformation data.</span></span>
<span id="cb78-49"><a href="#cb78-49" aria-hidden="true" tabindex="-1"></a>        input_img_np, transform_data <span class="op">=</span> resize_and_pad(frame, input_vstream_info.shape[::<span class="op">-</span><span class="dv">1</span>][<span class="dv">1</span>:], <span class="va">True</span>)</span>
<span id="cb78-50"><a href="#cb78-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb78-51"><a href="#cb78-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert the input image to NumPy format for the model</span></span>
<span id="cb78-52"><a href="#cb78-52" aria-hidden="true" tabindex="-1"></a>        input_tensor_np <span class="op">=</span> np.array(input_img_np, dtype<span class="op">=</span>np.float32)[<span class="va">None</span>]<span class="op">/</span><span class="dv">255</span></span>
<span id="cb78-53"><a href="#cb78-53" aria-hidden="true" tabindex="-1"></a>        input_tensor_np <span class="op">=</span> np.ascontiguousarray(input_tensor_np)</span>
<span id="cb78-54"><a href="#cb78-54" aria-hidden="true" tabindex="-1"></a>                        </span>
<span id="cb78-55"><a href="#cb78-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Run inference</span></span>
<span id="cb78-56"><a href="#cb78-56" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> {input_vstream_info.name: input_tensor_np}</span>
<span id="cb78-57"><a href="#cb78-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> InferVStreams(network_group, input_vstreams_params, output_vstreams_params) <span class="im">as</span> infer_pipeline:</span>
<span id="cb78-58"><a href="#cb78-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> network_group.activate(network_group_params):</span>
<span id="cb78-59"><a href="#cb78-59" aria-hidden="true" tabindex="-1"></a>                infer_results <span class="op">=</span> infer_pipeline.infer(input_data)</span>
<span id="cb78-60"><a href="#cb78-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-61"><a href="#cb78-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transpose and extract the first element of the quantized results</span></span>
<span id="cb78-62"><a href="#cb78-62" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> infer_results[output_vstream_info.name].transpose(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)[<span class="dv">0</span>]</span>
<span id="cb78-63"><a href="#cb78-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb78-64"><a href="#cb78-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Process the model output to get object proposals</span></span>
<span id="cb78-65"><a href="#cb78-65" aria-hidden="true" tabindex="-1"></a>        proposals <span class="op">=</span> process_outputs(outputs, input_vstream_info.shape[:<span class="op">-</span><span class="dv">1</span>], bbox_conf_thresh)</span>
<span id="cb78-66"><a href="#cb78-66" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb78-67"><a href="#cb78-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply non-max suppression to filter overlapping proposals</span></span>
<span id="cb78-68"><a href="#cb78-68" aria-hidden="true" tabindex="-1"></a>        proposal_indices <span class="op">=</span> nms_sorted_boxes(calc_iou(proposals[:, :<span class="op">-</span><span class="dv">2</span>]), iou_thresh)</span>
<span id="cb78-69"><a href="#cb78-69" aria-hidden="true" tabindex="-1"></a>        proposals <span class="op">=</span> proposals[proposal_indices]</span>
<span id="cb78-70"><a href="#cb78-70" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb78-71"><a href="#cb78-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract bounding boxes, labels, and probabilities from proposals</span></span>
<span id="cb78-72"><a href="#cb78-72" aria-hidden="true" tabindex="-1"></a>        bbox_list <span class="op">=</span> [adjust_bbox(bbox, transform_data) <span class="cf">for</span> bbox <span class="kw">in</span> proposals[:,:<span class="dv">4</span>]]</span>
<span id="cb78-73"><a href="#cb78-73" aria-hidden="true" tabindex="-1"></a>        label_list <span class="op">=</span> [class_names[<span class="bu">int</span>(idx)] <span class="cf">for</span> idx <span class="kw">in</span> proposals[:,<span class="dv">4</span>]]</span>
<span id="cb78-74"><a href="#cb78-74" aria-hidden="true" tabindex="-1"></a>        probs_list <span class="op">=</span> proposals[:,<span class="dv">5</span>]</span>
<span id="cb78-75"><a href="#cb78-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-76"><a href="#cb78-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize track IDs for detected objects</span></span>
<span id="cb78-77"><a href="#cb78-77" aria-hidden="true" tabindex="-1"></a>        track_ids <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>]<span class="op">*</span><span class="bu">len</span>(bbox_list)</span>
<span id="cb78-78"><a href="#cb78-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-79"><a href="#cb78-79" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert bounding boxes to top-left bottom-right (tlbr) format</span></span>
<span id="cb78-80"><a href="#cb78-80" aria-hidden="true" tabindex="-1"></a>        tlbr_boxes <span class="op">=</span> np.array(bbox_list).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">4</span>).copy()</span>
<span id="cb78-81"><a href="#cb78-81" aria-hidden="true" tabindex="-1"></a>        tlbr_boxes[:, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">+=</span> tlbr_boxes[:, :<span class="dv">2</span>]</span>
<span id="cb78-82"><a href="#cb78-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-83"><a href="#cb78-83" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update tracker with detections</span></span>
<span id="cb78-84"><a href="#cb78-84" aria-hidden="true" tabindex="-1"></a>        tracks <span class="op">=</span> tracker.update(</span>
<span id="cb78-85"><a href="#cb78-85" aria-hidden="true" tabindex="-1"></a>            output_results<span class="op">=</span>np.concatenate([tlbr_boxes, probs_list[:, np.newaxis]], axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb78-86"><a href="#cb78-86" aria-hidden="true" tabindex="-1"></a>            img_info<span class="op">=</span>frame.shape[::<span class="op">-</span><span class="dv">1</span>][<span class="dv">1</span>:],</span>
<span id="cb78-87"><a href="#cb78-87" aria-hidden="true" tabindex="-1"></a>            img_size<span class="op">=</span>frame.shape[::<span class="op">-</span><span class="dv">1</span>][<span class="dv">1</span>:])</span>
<span id="cb78-88"><a href="#cb78-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-89"><a href="#cb78-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(tlbr_boxes) <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> <span class="bu">len</span>(tracks) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb78-90"><a href="#cb78-90" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Match detections with tracks</span></span>
<span id="cb78-91"><a href="#cb78-91" aria-hidden="true" tabindex="-1"></a>            track_ids <span class="op">=</span> match_detections_with_tracks(tlbr_boxes<span class="op">=</span>tlbr_boxes, track_ids<span class="op">=</span>track_ids, tracks<span class="op">=</span>tracks)</span>
<span id="cb78-92"><a href="#cb78-92" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb78-93"><a href="#cb78-93" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Filter object detections based on tracking results</span></span>
<span id="cb78-94"><a href="#cb78-94" aria-hidden="true" tabindex="-1"></a>            bbox_list, label_list, probs_list, track_ids <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>[(bbox, label, prob, track_id) </span>
<span id="cb78-95"><a href="#cb78-95" aria-hidden="true" tabindex="-1"></a>                                                                <span class="cf">for</span> bbox, label, prob, track_id </span>
<span id="cb78-96"><a href="#cb78-96" aria-hidden="true" tabindex="-1"></a>                                                                <span class="kw">in</span> <span class="bu">zip</span>(bbox_list, label_list, probs_list, track_ids) <span class="cf">if</span> track_id <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb78-97"><a href="#cb78-97" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb78-98"><a href="#cb78-98" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(bbox_list) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb78-99"><a href="#cb78-99" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Annotate the current frame with bounding boxes and tracking IDs</span></span>
<span id="cb78-100"><a href="#cb78-100" aria-hidden="true" tabindex="-1"></a>                annotated_img <span class="op">=</span> draw_bboxes_pil(</span>
<span id="cb78-101"><a href="#cb78-101" aria-hidden="true" tabindex="-1"></a>                    image<span class="op">=</span>Image.fromarray(frame), </span>
<span id="cb78-102"><a href="#cb78-102" aria-hidden="true" tabindex="-1"></a>                    boxes<span class="op">=</span>bbox_list, </span>
<span id="cb78-103"><a href="#cb78-103" aria-hidden="true" tabindex="-1"></a>                    labels<span class="op">=</span>[<span class="ss">f"</span><span class="sc">{</span>track_id<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> track_id, label <span class="kw">in</span> <span class="bu">zip</span>(track_ids, label_list)],</span>
<span id="cb78-104"><a href="#cb78-104" aria-hidden="true" tabindex="-1"></a>                    probs<span class="op">=</span>probs_list,</span>
<span id="cb78-105"><a href="#cb78-105" aria-hidden="true" tabindex="-1"></a>                    colors<span class="op">=</span>[int_colors[class_names.index(i)] <span class="cf">for</span> i <span class="kw">in</span> label_list],  </span>
<span id="cb78-106"><a href="#cb78-106" aria-hidden="true" tabindex="-1"></a>                    font<span class="op">=</span>font_file,</span>
<span id="cb78-107"><a href="#cb78-107" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb78-108"><a href="#cb78-108" aria-hidden="true" tabindex="-1"></a>                annotated_frame <span class="op">=</span> cv2.resize(np.array(annotated_img), (preview_width, preview_height))</span>
<span id="cb78-109"><a href="#cb78-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb78-110"><a href="#cb78-110" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If no detections, use the original frame</span></span>
<span id="cb78-111"><a href="#cb78-111" aria-hidden="true" tabindex="-1"></a>            annotated_frame <span class="op">=</span> cv2.resize(frame, (preview_width, preview_height))</span>
<span id="cb78-112"><a href="#cb78-112" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb78-113"><a href="#cb78-113" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate and display FPS</span></span>
<span id="cb78-114"><a href="#cb78-114" aria-hidden="true" tabindex="-1"></a>        end_time <span class="op">=</span> time.perf_counter()</span>
<span id="cb78-115"><a href="#cb78-115" aria-hidden="true" tabindex="-1"></a>        processing_time <span class="op">=</span> end_time <span class="op">-</span> start_time</span>
<span id="cb78-116"><a href="#cb78-116" aria-hidden="true" tabindex="-1"></a>        fps <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> processing_time</span>
<span id="cb78-117"><a href="#cb78-117" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb78-118"><a href="#cb78-118" aria-hidden="true" tabindex="-1"></a>        fps_text <span class="op">=</span> <span class="ss">f"FPS: </span><span class="sc">{</span>fps<span class="sc">:.2f}</span><span class="ss">"</span></span>
<span id="cb78-119"><a href="#cb78-119" aria-hidden="true" tabindex="-1"></a>        cv2.putText(annotated_frame, fps_text, (<span class="dv">10</span>, <span class="dv">30</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="dv">1</span>, (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb78-120"><a href="#cb78-120" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb78-121"><a href="#cb78-121" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Display the annotated frame</span></span>
<span id="cb78-122"><a href="#cb78-122" aria-hidden="true" tabindex="-1"></a>        cv2.imshow(window_title, annotated_frame)</span>
<span id="cb78-123"><a href="#cb78-123" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb78-124"><a href="#cb78-124" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for 'q' key press to exit the loop</span></span>
<span id="cb78-125"><a href="#cb78-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cv2.waitKey(<span class="dv">1</span>) <span class="op">&amp;</span> <span class="bn">0xFF</span> <span class="op">==</span> <span class="bu">ord</span>(<span class="st">'q'</span>):</span>
<span id="cb78-126"><a href="#cb78-126" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb78-127"><a href="#cb78-127" aria-hidden="true" tabindex="-1"></a><span class="cf">finally</span>:</span>
<span id="cb78-128"><a href="#cb78-128" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stop the camera and close the preview window</span></span>
<span id="cb78-129"><a href="#cb78-129" aria-hidden="true" tabindex="-1"></a>    cv2.destroyAllWindows()</span>
<span id="cb78-130"><a href="#cb78-130" aria-hidden="true" tabindex="-1"></a>    picam2.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[1:30:25.480652426] [128869][1;32m INFO[1;37mCamera[1;34mcamera_manager.cpp:325[0mlibcamera v0.3.2+27-7330f29b
[1:30:25.488873181] [128898][1;32m INFO[1;37mRPI[1;34mpisp.cpp:695[0mlibpisp version v1.0.7 28196ed6edcf 29-08-2024 (16:33:32)
[1:30:25.500040780] [128898][1;32m INFO[1;37mRPI[1;34mpisp.cpp:1154[0mRegistered camera /base/axi/pcie@120000/rp1/i2c@80000/imx708@1a to CFE device /dev/media0 and ISP device /dev/media1 using PiSP variant BCM2712_C0
[1:30:25.504580397] [128869][1;32m INFO[1;37mCamera[1;34mcamera.cpp:1197[0mconfiguring streams: (0) 640x480-XBGR8888 (1) 1536x864-BGGR_PISP_COMP1
[1:30:25.504707471] [128898][1;32m INFO[1;37mRPI[1;34mpisp.cpp:1450[0mSensor: /base/axi/pcie@120000/rp1/i2c@80000/imx708@1a - Selected sensor format: 1536x864-SBGGR10_1X10 - Selected CFE format: 1536x864-PC1B
[1:30:25.509482661] [128869][1;32m INFO[1;37mCamera[1;34mcamera.cpp:1197[0mconfiguring streams: (0) 640x480-XBGR8888 (1) 2304x1296-BGGR_PISP_COMP1
[1:30:25.509651716] [128898][1;32m INFO[1;37mRPI[1;34mpisp.cpp:1450[0mSensor: /base/axi/pcie@120000/rp1/i2c@80000/imx708@1a - Selected sensor format: 2304x1296-SBGGR10_1X10 - Selected CFE format: 2304x1296-PC1B
[1:30:25.515647718] [128869][1;32m INFO[1;37mCamera[1;34mcamera.cpp:1197[0mconfiguring streams: (0) 640x480-XBGR8888 (1) 4608x2592-BGGR_PISP_COMP1
[1:30:25.515820199] [128898][1;32m INFO[1;37mRPI[1;34mpisp.cpp:1450[0mSensor: /base/axi/pcie@120000/rp1/i2c@80000/imx708@1a - Selected sensor format: 4608x2592-SBGGR10_1X10 - Selected CFE format: 4608x2592-PC1B
[1:30:25.527309279] [128869][1;32m INFO[1;37mCamera[1;34mcamera.cpp:1197[0mconfiguring streams: (0) 1536x864-RGB888 (1) 1536x864-BGGR_PISP_COMP1
[1:30:25.527468649] [128898][1;32m INFO[1;37mRPI[1;34mpisp.cpp:1450[0mSensor: /base/axi/pcie@120000/rp1/i2c@80000/imx708@1a - Selected sensor format: 1536x864-SBGGR10_1X10 - Selected CFE format: 1536x864-PC1B


Available sensor modes:
Mode 0: (1536, 864)x120.13fps
Mode 1: (2304, 1296)x56.03fps
Mode 2: (4608, 2592)x14.35fps


libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile</code></pre>
<p>A new window should pop up displaying the camera feed. I got approximately 30fps in my testing.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/20241007_10h26m55s_grim.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Congratulations on completing this comprehensive tutorial. You’ve successfully learned how to deploy a YOLOX object detection model on a Raspberry Pi 5 using the Hailo-8L AI accelerator for real-time object tracking from a camera feed. This tutorial covered several aspects:</p>
<ol type="1">
<li>Setting up the Raspberry Pi 5 with the Hailo AI Kit and necessary software dependencies</li>
<li>Preparing and optimizing a YOLOX model for the Hailo-8L accelerator using the Dataflow Compiler</li>
<li>Compiling the optimized model into a Hailo Executable Format (HEF) file</li>
<li>Implementing efficient frame capture and processing using Picamera2</li>
<li>Integrating the ByteTrack algorithm for robust object tracking</li>
<li>Creating a real-time video processing pipeline that detects, tracks, and annotates objects</li>
</ol>
<p>This project provides a solid foundation for numerous real-world applications in edge AI and computer vision.</p>
<p>Some potential next steps to consider:</p>
<ol type="1">
<li>Experiment with different YOLOX model sizes or custom-trained models for specific use cases</li>
<li>Implement additional features like object counting, activity recognition, or anomaly detection</li>
<li>Integrate the system with other IoT devices or cloud services for more complex applications</li>
<li>Investigate power consumption optimization techniques for battery-powered deployments</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Questions:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Questions:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
</ul>
</div>
</div>
<hr>
<div class="callout callout-style-default callout-tip callout-titled" title="About Me:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About Me:
</div>
</div>
<div class="callout-body-container callout-body">
<p>I’m Christian Mills, a deep learning consultant specializing in practical AI implementations. I help clients leverage cutting-edge AI technologies to solve real-world problems.</p>
<p>Interested in working together? Fill out my <a href="https://docs.google.com/forms/d/e/1FAIpQLScKDKPJF9Be47LA3nrEDXTVpzH2UMLz8SzHMHM9hWT5qlvjkw/viewform?usp=sf_link">Quick AI Project Assessment</a> form or learn more <a href="../../../about.html">about me</a>.</p>
</div>
</div>


</section>

</main> <!-- /main -->
<!-- Cloudflare Web Analytics --><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;56b8d2f624604c4891327b3c0d9f6703&quot;}"></script><!-- End Cloudflare Web Analytics -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/christianjmills\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="cj-mills/christianjmills" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
<p>Content licensed under CC BY-NC-SA 4.0</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
<p>© 2024 Christian J. Mills</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://opensource.org/licenses/MIT">
<p>Code samples licensed under the MIT License</p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>