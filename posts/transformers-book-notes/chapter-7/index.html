<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-04-12">
<meta name="description" content="Chapter 7 covers building a question-answering model that finds answers to questions in customer reviews.">

<title>Christian Mills - Notes on Transformers Book Ch. 7</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Christian Mills - Notes on Transformers Book Ch. 7">
<meta property="og:description" content="Chapter 7 covers building a question-answering model that finds answers to questions in customer reviews.">
<meta property="og:image" content="christianjmills.com/images/logo.png">
<meta property="og:site-name" content="Christian Mills">
<meta property="og:image:height" content="295">
<meta property="og:image:width" content="300">
<meta name="twitter:title" content="Christian Mills - Notes on Transformers Book Ch. 7">
<meta name="twitter:description" content="Chapter 7 covers building a question-answering model that finds answers to questions in customer reviews.">
<meta name="twitter:image" content="christianjmills.com/images/logo.png">
<meta name="twitter:creator" content="@cdotjdotmills">
<meta name="twitter:site" content="@cdotjdotmills">
<meta name="twitter:image-height" content="295">
<meta name="twitter:image-width" content="300">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Christian Mills</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:christian@christianjmills.com"><i class="bi bi-envelope-fill" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cj-mills"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/cdotjdotmills"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../index.xml"><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Notes on Transformers Book Ch. 7</h1>
  <div class="quarto-categories">
    <div class="quarto-category">ai</div>
    <div class="quarto-category">huggingface</div>
    <div class="quarto-category">nlp</div>
    <div class="quarto-category">notes</div>
  </div>
  </div>

<div>
  <div class="description">
    Chapter 7 covers building a question-answering model that finds answers to questions in customer reviews.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 12, 2022</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#project-build-a-review-based-qa-system">Project: Build a Review-Based QA System</a></li>
<li><a href="#improving-our-qa-pipeline">Improving Our QA Pipeline</a></li>
<li><a href="#going-beyond-extractive-qa">Going Beyond Extractive QA</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references">References</a></li>
</ul>
<hr>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datasets</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Only print error messages</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>transformers.logging.set_verbosity_error()</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>datasets.logging.set_verbosity_error()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>transformers.__version__, datasets.__version__</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    ('4.6.1', '1.11.0')</code></pre>
<hr>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'max_colwidth'</span>, <span class="va">None</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_rows'</span>, <span class="va">None</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ast</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://astor.readthedocs.io/en/latest/</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> astor</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> inspect</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> textwrap</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_source(obj, exclude_doc<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get source code</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    source <span class="op">=</span> inspect.getsource(obj)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove any common leading whitespace from every line</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    cleaned_source <span class="op">=</span> textwrap.dedent(source)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Parse the source into an AST node.</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    parsed <span class="op">=</span> ast.parse(cleaned_source)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> node <span class="kw">in</span> ast.walk(parsed):</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Skip any nodes that are not class or function definitions</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(node, (ast.FunctionDef, ast.ClassDef, ast.AsyncFunctionDef)):</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> exclude_doc <span class="kw">and</span> <span class="bu">len</span>(node.body) <span class="op">&gt;</span> <span class="dv">1</span>: node.body <span class="op">=</span> node.body[<span class="dv">1</span>:]</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(astor.to_source(parsed))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Disable Tokenizers Parallelism</strong></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>env TOKENIZERS_PARALLELISM<span class="op">=</span>false</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    env: TOKENIZERS_PARALLELISM=false</code></pre>
<hr>
<p><strong>Suppress Haystack logging</strong></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> module <span class="kw">in</span> [<span class="st">"farm.utils"</span>, <span class="st">"farm.infer"</span>, <span class="st">"haystack.reader.farm.FARMReader"</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>              <span class="st">"farm.modeling.prediction_head"</span>, <span class="st">"elasticsearch"</span>, <span class="st">"haystack.eval"</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>               <span class="st">"haystack.document_store.base"</span>, <span class="st">"haystack.retriever.base"</span>, </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>              <span class="st">"farm.data_handler.dataset"</span>]:</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    module_logger <span class="op">=</span> logging.getLogger(module)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    module_logger.setLevel(logging.ERROR)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li>Extractive question answering is the most common form and requires the answer to be available as a span of text in a document.</li>
<li>Community question answering involves gathering question-answer pairs generated by users. We then use semantic similarity search to find the closest matching answer to a new question.</li>
<li>Long-form question answering aims to generate complex paragraph-length answers to open-ended questions.</li>
<li>It is also possible to perform question answering over tables.
<ul>
<li>Transformer models like <a href="https://huggingface.co/google/tapas-base-finetuned-wtq">TAPAS</a> can perform aggregations to produce the final answer.</li>
</ul></li>
<li>The domain of data a QA system has access to usually determines how it is categorized.
<ul>
<li>Closed-domain QA deals with questions about a narrow topic like a single product category.</li>
<li>Open-domain QA deals with questions about almost anything.</li>
</ul></li>
</ul>
</section>
<section id="project-build-a-review-based-qa-system" class="level2">
<h2 class="anchored" data-anchor-id="project-build-a-review-based-qa-system">Project: Build a Review-Based QA System</h2>
<ul>
<li>The goal is to build a question-answering model that finds answers to questions in customer reviews.</li>
</ul>
<section id="the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="the-dataset">The Dataset</h3>
<ul>
<li><a href="https://arxiv.org/abs/2004.14283">SubjQA: A Dataset for Subjectivity and Review Comprehension</a></li>
<li><a href="https://github.com/megagonlabs/SubjQA">GitHub Repository</a></li>
<li><a href="https://huggingface.co/datasets/subjqa">Hugging Face Dataset Card</a></li>
<li>SubjQA is a question answering dataset that focuses on subjective (as opposed to factual) questions and answers.</li>
<li>The dataset contains approximately 10,000 questions over reviews from six domains, including books, movies, grocery, electronics, TripAdvisor, and restaurants.</li>
<li>Each question is associated with a review that contains the answer.</li>
<li>The dataset includes unanswerable questions designed to produce more robust models.</li>
<li>The subjectivity of the questions and answers makes the task potentially more challenging than if they were factual.</li>
</ul>
<hr>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> get_dataset_config_names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Get the names of the domains in the SubjQA dataset</strong></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>domains <span class="op">=</span> get_dataset_config_names(<span class="st">"subjqa"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>domains</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    ['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']</code></pre>
<hr>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Load the electronics subset of the SubjQA dataset</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>subjqa <span class="op">=</span> load_dataset(<span class="st">"subjqa"</span>, name<span class="op">=</span><span class="st">"electronics"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>subjqa</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    DatasetDict({
        train: Dataset({
            features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],
            num_rows: 1295
        })
        test: Dataset({
            features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],
            num_rows: 358
        })
        validation: Dataset({
            features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],
            num_rows: 255
        })
    })</code></pre>
<p><strong>Note:</strong> SubjQA stores the answers to each question as a nested dictionary.</p>
<hr>
<p><strong>Inspect an answer from the dataset</strong></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(subjqa[<span class="st">"train"</span>][<span class="st">"answers"</span>][<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
text
</th>
<th>
answer_start
</th>
<th>
answer_subj_level
</th>
<th>
ans_subj_score
</th>
<th>
is_ans_subjective
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
Bass is weak as expected
</td>
<td>
1302
</td>
<td>
1
</td>
<td>
0.508333
</td>
<td>
True
</td>
</tr>
<tr>
<th>
1
</th>
<td>
Bass is weak as expected, even with EQ adjusted up
</td>
<td>
1302
</td>
<td>
1
</td>
<td>
0.508333
</td>
<td>
True
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p><strong>Convert each split to a Pandas DataFrame</strong></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>dfs <span class="op">=</span> {split: dset.to_pandas() <span class="cf">for</span> split, dset <span class="kw">in</span> subjqa.flatten().items()}</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> split, df <span class="kw">in</span> dfs.items():</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Number of questions in </span><span class="sc">{</span>split<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>df[<span class="st">'id'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Number of questions in train: 1295
    Number of questions in test: 358
    Number of questions in validation: 255</code></pre>
<p><strong>Note:</strong> * The dataset is relatively small, with 1,908 total examples. * Real-world QA datasets are likely to be small as it is expensive and labor-intensive to have domain experts label extractive QA datasets. * The <a href="https://arxiv.org/abs/2103.06268">CUAD</a> dataset for extractive QA on legal contracts has an estimated value of two million dollars to account for the legal expertise needed to annotate its 13,000 examples.</p>
<hr>
<section id="columns-of-interest" class="level4">
<h4 class="anchored" data-anchor-id="columns-of-interest">Columns of Interest</h4>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="header">
<th>Column Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>title</td>
<td>The Amazon Standard Identification Number (ASIN) associated with each product</td>
</tr>
<tr class="even">
<td>question</td>
<td>The question</td>
</tr>
<tr class="odd">
<td>answers.answer_text</td>
<td>The span of text in the reivew labeled by the annotator</td>
</tr>
<tr class="even">
<td>answers.answer_start</td>
<td>The start character index of the answer span</td>
</tr>
<tr class="odd">
<td>context</td>
<td>The customer review</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>Inspect some random training examples</strong></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>qa_cols <span class="op">=</span> [<span class="st">"title"</span>, <span class="st">"question"</span>, <span class="st">"answers.text"</span>, <span class="st">"answers.answer_start"</span>, <span class="st">"context"</span>]</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>sample_df <span class="op">=</span> dfs[<span class="st">"train"</span>][qa_cols].sample(<span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>sample_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
title
</th>
<th>
question
</th>
<th>
answers.text
</th>
<th>
answers.answer_start
</th>
<th>
context
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
791
</th>
<td>
B005DKZTMG
</td>
<td>
Does the keyboard lightweight?
</td>
<td>
[this keyboard is compact]
</td>
<td>
[215]
</td>
<td>
I really like this keyboard. I give it 4 stars because it doesn’t have a CAPS LOCK key so I never know if my caps are on. But for the price, it really suffices as a wireless keyboard. I have very large hands and this keyboard is compact, but I have no complaints.
</td>
</tr>
<tr>
<th>
1159
</th>
<td>
B00AAIPT76
</td>
<td>
How is the battery?
</td>
<td>
[]
</td>
<td>
[]
</td>
<td>
I bought this after the first spare gopro battery I bought wouldn’t hold a charge. I have very realistic expectations of this sort of product, I am skeptical of amazing stories of charge time and battery life but I do expect the batteries to hold a charge for a couple of weeks at least and for the charger to work like a charger. In this I was not disappointed. I am a river rafter and found that the gopro burns through power in a hurry so this purchase solved that issue. the batteries held a charge, on shorter trips the extra two batteries were enough and on longer trips I could use my friends JOOS Orange to recharge them.I just bought a newtrent xtreme powerpak and expect to be able to charge these with that so I will not run out of power again.
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>The questions are not grammatically correct.</li>
<li>An empty text entry denotes an “unanswerable” question whose answer is not present in the review.</li>
<li>We can use the start index and length of the answer span to slice out the span of text in the review that corresponds to the answer.</li>
</ul>
<hr>
<p><strong>Slice out a span of text that corresponds to the answer</strong></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>start_idx <span class="op">=</span> sample_df[<span class="st">"answers.answer_start"</span>].iloc[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>end_idx <span class="op">=</span> start_idx <span class="op">+</span> <span class="bu">len</span>(sample_df[<span class="st">"answers.text"</span>].iloc[<span class="dv">0</span>][<span class="dv">0</span>])</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>sample_df[<span class="st">"context"</span>].iloc[<span class="dv">0</span>][start_idx:end_idx]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    'this keyboard is compact'</code></pre>
<hr>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Count the questions that begin with common starting words</strong></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> {}</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>question_types <span class="op">=</span> [<span class="st">"What"</span>, <span class="st">"How"</span>, <span class="st">"Is"</span>, <span class="st">"Does"</span>, <span class="st">"Do"</span>, <span class="st">"Was"</span>, <span class="st">"Where"</span>, <span class="st">"Why"</span>]</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> q <span class="kw">in</span> question_types:</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    counts[q] <span class="op">=</span> dfs[<span class="st">"train"</span>][<span class="st">"question"</span>].<span class="bu">str</span>.startswith(q).value_counts()[<span class="va">True</span>]</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>pd.Series(counts).sort_values().plot.barh()</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Frequency of Question Types"</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_31_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Note:</strong> Questions that begin with “How,” “What,” and “Is” are the most common.</p>
<hr>
<p><strong>Look at examples with the most common starting words</strong></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> question_type <span class="kw">in</span> [<span class="st">"How"</span>, <span class="st">"What"</span>, <span class="st">"Is"</span>]:</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> question <span class="kw">in</span> (</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>        dfs[<span class="st">"train"</span>][dfs[<span class="st">"train"</span>].question.<span class="bu">str</span>.startswith(question_type)]</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        .sample(n<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)[<span class="st">'question'</span>]):</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(question)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    How is the camera?
    How do you like the control?
    How fast is the charger?
    What is direction?
    What is the quality of the construction of the bag?
    What is your impression of the product?
    Is this how zoom works?
    Is sound clear?
    Is it a wireless keyboard?</code></pre>
<hr>
</section>
</section>
<section id="the-stanford-question-answering-dataset-squad" class="level3">
<h3 class="anchored" data-anchor-id="the-stanford-question-answering-dataset-squad">The Stanford Question Answering Dataset (SQuAD)</h3>
<ul>
<li><a href="https://arxiv.org/abs/1606.05250">SQuAD: 100,000+ Questions for Machine Comprehension of Text</a></li>
<li><a href="https://arxiv.org/abs/1806.03822">Know What You Don’t Know: Unanswerable Questions for SQuAD</a></li>
<li>The Standford Question Answering Dataset is a famous dataset for testing the ability of machines to read a passage of text and answer questions about it.</li>
<li>The dataset pioneered the (question, review, [answer sentences]) format used in SubjQA.</li>
<li>The creators sampled several hundred English articles from Wikipedia and asked crowd workers to generate a set of questions and answers for each paragraph.</li>
<li>Most models since 2019 surpass human performance on this dataset.
<ul>
<li>This superhuman performance does not reflect genuine reading comprehension since models can identify answers to the “unanswerable” questions through patterns in the passages like antonyms.</li>
</ul></li>
<li>Google released the <a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00267/43495/What-You-Say-and-How-You-Say-it-Joint-Modeling-of">Natural Questions (NQ) dataset</a>, which involves fact-seeking questions obtained from Google Search users.
<ul>
<li>The answers in NQ are much longer than in SQuAD and present a more challenging benchmark.</li>
</ul></li>
</ul>
</section>
<section id="extracting-answers-from-text" class="level3">
<h3 class="anchored" data-anchor-id="extracting-answers-from-text">Extracting Answers from Text</h3>
<ul>
<li>We need a way to identify a potential answer as a span of text in a customer review.
<ul>
<li>Frame the supervised learning problems.</li>
<li>Tokenize and encode text for QA tasks.</li>
<li>Deal with long passages that exceed a model’s maximum context size.</li>
</ul></li>
</ul>
<section id="span-classification" class="level4">
<h4 class="anchored" data-anchor-id="span-classification">Span classification</h4>
<ul>
<li>The model needs to predict the start and end tokens of an answer.</li>
<li>This approach is the most common way to extract answers from a text.</li>
</ul>
</section>
<section id="transfer-learning" class="level4">
<h4 class="anchored" data-anchor-id="transfer-learning">Transfer Learning</h4>
<ul>
<li>We can compensate for a relatively small dataset by starting with a language model fine-tuned on a large-scale QA dataset like SQuAD.</li>
<li>These models typically have strong reading comprehension capabilities and serve as a good baseline.</li>
<li><a href="https://huggingface.co/models?dataset=dataset:squad&amp;sort=downloads">Hugging Face Hub models trained on SQuAD</a></li>
</ul>
<p><strong>Baseline transformer models fine-tuned on SQuAD 2.0</strong></p>
<table class="table">
<thead>
<tr class="header">
<th>Transformer</th>
<th>Description</th>
<th>Numbers of parameters</th>
<th><span class="math inline">\(F_{1}\)</span>-score on SQUAD 2.0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://huggingface.co/deepset/minilm-uncased-squad2">MiniLM</a></td>
<td>A distilled version of BERT-base that preserves 99% of the performance while being twice as fast.</td>
<td>66M</td>
<td>79.5</td>
</tr>
<tr class="even">
<td><a href="https://huggingface.co/roberta-base">RoBERTa-base</a></td>
<td>RoBERTa models have better performance than their BERT counterparts and can fine-tune on most QA datasets using a single GPU.</td>
<td>125M</td>
<td>83.0</td>
</tr>
<tr class="odd">
<td><a href="https://huggingface.co/models?pipeline_tag=question-answering&amp;sort=downloads&amp;search=albert-xxl">ALBERT-XXL</a></td>
<td>State-of-the-art performance on SQuAD 2.0, but computationally intensive and difficult to deploy.</td>
<td>235M</td>
<td>88.1</td>
</tr>
<tr class="even">
<td><a href="https://huggingface.co/models?search=xlm-roberta-large">XLM-RoBERTa-large</a></td>
<td>Multilingual model for 100 languages with strong zero-shot performance.</td>
<td>570M</td>
<td>83.8</td>
</tr>
</tbody>
</table>
</section>
<section id="tokenizing-text-for-qa" class="level4">
<h4 class="anchored" data-anchor-id="tokenizing-text-for-qa">Tokenizing text for QA</h4>
<hr>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Instantiate a tokenizer for the MiniLM model</strong></p>
<ul>
<li><a href="https://huggingface.co/deepset/minilm-uncased-squad2">MiniLM Hugging Face Model Card</a></li>
<li><a href="https://arxiv.org/abs/2002.10957">MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers</a></li>
</ul>
<hr>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>model_ckpt <span class="op">=</span> <span class="st">"deepset/minilm-uncased-squad2"</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_ckpt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Tokenize a question-context pair</strong></p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">"How much music can this hold?"</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>context <span class="op">=</span> <span class="st">"""An MP3 is about 1 MB/minute, so about 6000 hours depending on </span><span class="ch">\</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="st">file size."""</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tokenizer(question, context, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Inspect tokenized inputs</strong></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>input_df <span class="op">=</span> pd.DataFrame.from_dict(tokenizer(question, context), orient<span class="op">=</span><span class="st">"index"</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>input_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
<th>
1
</th>
<th>
2
</th>
<th>
3
</th>
<th>
4
</th>
<th>
5
</th>
<th>
6
</th>
<th>
7
</th>
<th>
8
</th>
<th>
9
</th>
<th>
10
</th>
<th>
11
</th>
<th>
12
</th>
<th>
13
</th>
<th>
14
</th>
<th>
15
</th>
<th>
16
</th>
<th>
17
</th>
<th>
18
</th>
<th>
19
</th>
<th>
20
</th>
<th>
21
</th>
<th>
22
</th>
<th>
23
</th>
<th>
24
</th>
<th>
25
</th>
<th>
26
</th>
<th>
27
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
input_ids
</th>
<td>
101
</td>
<td>
2129
</td>
<td>
2172
</td>
<td>
2189
</td>
<td>
2064
</td>
<td>
2023
</td>
<td>
2907
</td>
<td>
1029
</td>
<td>
102
</td>
<td>
2019
</td>
<td>
23378
</td>
<td>
2003
</td>
<td>
2055
</td>
<td>
1015
</td>
<td>
16914
</td>
<td>
1013
</td>
<td>
3371
</td>
<td>
1010
</td>
<td>
2061
</td>
<td>
2055
</td>
<td>
25961
</td>
<td>
2847
</td>
<td>
5834
</td>
<td>
2006
</td>
<td>
5371
</td>
<td>
2946
</td>
<td>
1012
</td>
<td>
102
</td>
</tr>
<tr>
<th>
token_type_ids
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
attention_mask
</th>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>The token_type_ids tensor indicates which part of the inputs corresponds to the question and context.
<ul>
<li>A 0 indicates a question token.</li>
<li>A 1 indicates a context token.</li>
</ul></li>
<li>The token_type_ids are not present in all transformer models.</li>
<li>BERT-like models use token_type_ids during pretraining to incorporate the next sentence prediction task.</li>
</ul>
<hr>
<p><strong>Decode the input_ids tensor</strong></p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokenizer.decode(inputs[<span class="st">"input_ids"</span>][<span class="dv">0</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    [CLS] how much music can this hold? [SEP] an mp3 is about 1 mb / minute, so about 6000 hours depending on file size. [SEP]</code></pre>
<p><strong>Note:</strong> The token_type_ids tensor determines the location of the first <code>[SEP]</code> token.</p>
<hr>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForQuestionAnswering</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="automodelforquestionanswering" class="level4">
<h4 class="anchored" data-anchor-id="automodelforquestionanswering"><code>AutoModelForQuestionAnswering</code></h4>
<ul>
<li><a href="https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForQuestionAnswering">Documentation</a></li>
</ul>
<hr>
<p><strong>Instantiate the MiniLM model with a QA head</strong></p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForQuestionAnswering.from_pretrained(model_ckpt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    transformers.models.bert.modeling_bert.BertForQuestionAnswering</code></pre>
<hr>
</section>
<section id="bertforquestionanswering" class="level4">
<h4 class="anchored" data-anchor-id="bertforquestionanswering"><code>BertForQuestionAnswering</code></h4>
<ul>
<li><a href="https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">Documentation</a></li>
<li>Create a BERT Model with a span classification head on top for extractive question-answering tasks.</li>
</ul>
<hr>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>[child[<span class="dv">0</span>] <span class="cf">for</span> child <span class="kw">in</span> <span class="bu">list</span>(model.named_children())]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    ['bert', 'qa_outputs']</code></pre>
<hr>
<div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(model.named_children())[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    ('qa_outputs', Linear(in_features=384, out_features=2, bias=True))</code></pre>
<hr>
<p><strong>Note:</strong></p>
<ul>
<li>We treat QA as a form of token classification.</li>
<li>The QA head takes the hidden states from the encoder and computes the logits for the start and end spans.</li>
</ul>
<hr>
<p><strong>Run inputs through the forward pass</strong></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(outputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-0.9862, -4.7750, -5.4025, -5.2378, -5.2863, -5.5117, -4.9819, -6.1880,
             -0.9862,  0.2596, -0.2144, -1.7136,  3.7806,  4.8561, -1.0546, -3.9097,
             -1.7374, -4.5944, -1.4278,  3.9949,  5.0391, -0.2018, -3.0193, -4.8549,
             -2.3107, -3.5110, -3.5713, -0.9862]]), end_logits=tensor([[-0.9623, -5.4733, -5.0326, -5.1639, -5.4278, -5.5151, -5.1749, -4.6233,
             -0.9623, -3.7855, -0.8715, -3.7745, -3.0161, -1.1780,  0.1758, -2.7365,
              4.8934,  0.3047, -3.1761, -3.2762,  0.8937,  5.6606, -0.3623, -4.9554,
             -3.2531, -0.0914,  1.6211, -0.9623]]), hidden_states=None, attentions=None)</code></pre>
<hr>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(outputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    transformers.modeling_outputs.QuestionAnsweringModelOutput</code></pre>
<hr>
</section>
<section id="questionansweringmodeloutput" class="level4">
<h4 class="anchored" data-anchor-id="questionansweringmodeloutput"><code>QuestionAnsweringModelOutput</code></h4>
<ul>
<li><a href="https://huggingface.co/docs/transformers/main/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput">Documentation</a></li>
</ul>
<hr>
<div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>print_source(transformers.modeling_outputs.QuestionAnsweringModelOutput)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    @dataclass
    class QuestionAnsweringModelOutput(ModelOutput):
        loss: Optional[torch.FloatTensor] = None
        start_logits: torch.FloatTensor = None
        end_logits: torch.FloatTensor = None
        hidden_states: Optional[Tuple[torch.FloatTensor]] = None
        attentions: Optional[Tuple[torch.FloatTensor]] = None</code></pre>
<hr>
<p><strong>Get the logits for the start and end tokens</strong></p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>start_logits <span class="op">=</span> outputs.start_logits</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>end_logits <span class="op">=</span> outputs.end_logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>torch.argmax(start_logits), start_logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    (tensor(20),
     tensor([[-0.9862, -4.7750, -5.4025, -5.2378, -5.2863, -5.5117, -4.9819, -6.1880,
              -0.9862,  0.2596, -0.2144, -1.7136,  3.7806,  4.8561, -1.0546, -3.9097,
              -1.7374, -4.5944, -1.4278,  3.9949,  5.0391, -0.2018, -3.0193, -4.8549,
              -2.3107, -3.5110, -3.5713, -0.9862]]))</code></pre>
<hr>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>torch.argmax(end_logits), end_logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    (tensor(21),
     tensor([[-0.9623, -5.4733, -5.0326, -5.1639, -5.4278, -5.5151, -5.1749, -4.6233,
              -0.9623, -3.7855, -0.8715, -3.7745, -3.0161, -1.1780,  0.1758, -2.7365,
               4.8934,  0.3047, -3.1761, -3.2762,  0.8937,  5.6606, -0.3623, -4.9554,
              -3.2531, -0.0914,  1.6211, -0.9623]]))</code></pre>
<p><strong>Note:</strong> The larger, positive values correspond to more likely candidates for the start and end tokens.</p>
<hr>
<p><strong>Compare the logit shapes to the input IDs</strong></p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Input IDs shape: </span><span class="sc">{</span>inputs<span class="sc">.</span>input_ids<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Start logits shape: </span><span class="sc">{</span>start_logits<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"End logits shape: </span><span class="sc">{</span>end_logits<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Input IDs shape: torch.Size([1, 28])
    Start logits shape: torch.Size([1, 28])
    End logits shape: torch.Size([1, 28])</code></pre>
<p><strong>Note:</strong> There is a start and end logit associated with each input token.</p>
<hr>
<div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>tokenizer.decode(inputs.input_ids[<span class="dv">0</span>][torch.argmax(start_logits):torch.argmax(end_logits)<span class="op">+</span><span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    '6000 hours'</code></pre>
<hr>
<div class="sourceCode" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Visualize the predicted logits for the start and end tokens</strong></p>
<ul>
<li><a href="https://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/">Question Answering with a Fine-Tuned BERT</a></li>
</ul>
<hr>
<div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>s_scores <span class="op">=</span> start_logits.detach().numpy().flatten()</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>e_scores <span class="op">=</span> end_logits.detach().numpy().flatten()</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> tokenizer.convert_ids_to_tokens(inputs[<span class="st">"input_ids"</span>][<span class="dv">0</span>])</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">"C0"</span> <span class="cf">if</span> s <span class="op">!=</span> np.<span class="bu">max</span>(s_scores) <span class="cf">else</span> <span class="st">"C1"</span> <span class="cf">for</span> s <span class="kw">in</span> s_scores]</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>ax1.bar(x<span class="op">=</span>tokens, height<span class="op">=</span>s_scores, color<span class="op">=</span>colors)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">"Start Scores"</span>)</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">"C0"</span> <span class="cf">if</span> s <span class="op">!=</span> np.<span class="bu">max</span>(e_scores) <span class="cf">else</span> <span class="st">"C1"</span> <span class="cf">for</span> s <span class="kw">in</span> e_scores]</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>ax2.bar(x<span class="op">=</span>tokens, height<span class="op">=</span>e_scores, color<span class="op">=</span>colors)</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">"End Scores"</span>)</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="st">"vertical"</span>)</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_76_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<hr>
<p><strong>Extract the answer using the most likely start and end candidates</strong></p>
<div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>start_idx <span class="op">=</span> torch.argmax(start_logits)  </span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>end_idx <span class="op">=</span> torch.argmax(end_logits) <span class="op">+</span> <span class="dv">1</span>  </span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>answer_span <span class="op">=</span> inputs[<span class="st">"input_ids"</span>][<span class="dv">0</span>][start_idx:end_idx]</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>answer <span class="op">=</span> tokenizer.decode(answer_span)</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Question: </span><span class="sc">{</span>question<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Answer: </span><span class="sc">{</span>answer<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Question: How much music can this hold?
    Answer: 6000 hours</code></pre>
<p><strong>Note:</strong> * Using the indices with the max values of the start and end logits can produce out-of-scope answers by selecting tokens that belong to the question instead of the context. * A question answering pipeline computes the best combination of start and end indices using various constraints such as being in-scope, requiring the start indices to precede the end indices.</p>
<hr>
<div class="sourceCode" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Instantiate a question answering pipeline with the MiniML model</strong></p>
<div class="sourceCode" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(<span class="st">"question-answering"</span>, model<span class="op">=</span>model, tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(pipe)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    transformers.pipelines.question_answering.QuestionAnsweringPipeline</code></pre>
<hr>
</section>
<section id="questionansweringpipeline" class="level4">
<h4 class="anchored" data-anchor-id="questionansweringpipeline"><code>QuestionAnsweringPipeline</code></h4>
<ul>
<li><a href="https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.QuestionAnsweringPipeline">Documentation</a></li>
<li>Create a question anwering pipeline</li>
</ul>
<hr>
<p><strong>Get the top 3 most likely answers to the question</strong></p>
<div class="sourceCode" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>pipe(question<span class="op">=</span>question, context<span class="op">=</span>context, topk<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    [{'score': 0.2651616930961609, 'start': 38, 'end': 48, 'answer': '6000 hours'},
     {'score': 0.2208297997713089,
      'start': 16,
      'end': 48,
      'answer': '1 MB/minute, so about 6000 hours'},
     {'score': 0.10253523290157318,
      'start': 16,
      'end': 27,
      'answer': '1 MB/minute'}]</code></pre>
<p><strong>Note:</strong> * The score field contains the model’s probability estimate for each answer. * The model assigns a high start and end score to the <code>[CLS]</code> token when there is no answer to a question, and the pipeline maps this output to an empty string.</p>
<hr>
<p><strong>Ask an unanswerable question</strong></p>
<div class="sourceCode" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>pipe(question<span class="op">=</span><span class="st">"Why is there no data?"</span>, context<span class="op">=</span>context, handle_impossible_answer<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    {'score': 0.9068416357040405, 'start': 0, 'end': 0, 'answer': ''}</code></pre>
<hr>
</section>
<section id="dealing-with-long-passages" class="level4">
<h4 class="anchored" data-anchor-id="dealing-with-long-passages">Dealing with long passages</h4>
<ul>
<li>The context often contains more tokens than the maximum sequence length of the model.</li>
<li>A decent portion of the SubjQA training set contains question-context pairs that won’t fit within MiniLM’s context size of 512 tokens.</li>
<li>Truncating long texts is problematic for QA tasks as the answer could be near the end of the context.</li>
<li>The standard way to deal with long texts for QA is to apply a sliding window across the inputs, where each window contains a passage of tokens that fit in the model’s context.</li>
</ul>
<p><strong>Distribution of tokens for each question-context pair in the SubjQA training set</strong></p>
<div class="sourceCode" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_input_length(row):</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tokenizer(row[<span class="st">"question"</span>], row[<span class="st">"context"</span>])</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(inputs[<span class="st">"input_ids"</span>])</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>dfs[<span class="st">"train"</span>][<span class="st">"n_tokens"</span>] <span class="op">=</span> dfs[<span class="st">"train"</span>].<span class="bu">apply</span>(compute_input_length, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>dfs[<span class="st">"train"</span>][<span class="st">"n_tokens"</span>].hist(bins<span class="op">=</span><span class="dv">100</span>, grid<span class="op">=</span><span class="va">False</span>, ec<span class="op">=</span><span class="st">"C0"</span>, ax<span class="op">=</span>ax)</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of tokens in question-context pair"</span>)</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>ax.axvline(x<span class="op">=</span><span class="dv">512</span>, ymin<span class="op">=</span><span class="dv">0</span>, ymax<span class="op">=</span><span class="dv">1</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, color<span class="op">=</span><span class="st">"C1"</span>, </span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="st">"Maximum sequence length"</span>)</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Count"</span>)</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_91_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<hr>
<p><strong>Enable the sliding window for the tokenizer</strong></p>
<div class="sourceCode" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>example <span class="op">=</span> dfs[<span class="st">"train"</span>].iloc[<span class="dv">0</span>][[<span class="st">"question"</span>, <span class="st">"context"</span>]]</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>tokenized_example <span class="op">=</span> tokenizer(example[<span class="st">"question"</span>], example[<span class="st">"context"</span>], </span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>                              return_overflowing_tokens<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>                              stride<span class="op">=</span><span class="dv">25</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note:</strong> We now get a list containing input_ids for each window.</p>
<hr>
<p><strong>Get the number of tokens in each window</strong></p>
<div class="sourceCode" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, window <span class="kw">in</span> <span class="bu">enumerate</span>(tokenized_example[<span class="st">"input_ids"</span>]):</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Window #</span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss"> has </span><span class="sc">{</span><span class="bu">len</span>(window)<span class="sc">}</span><span class="ss"> tokens"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Window #0 has 100 tokens
    Window #1 has 88 tokens</code></pre>
<hr>
<p><strong>View where the windows overlap</strong></p>
<div class="sourceCode" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> window <span class="kw">in</span> tokenized_example[<span class="st">"input_ids"</span>]:</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>tokenizer<span class="sc">.</span>decode(window)<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    [CLS] how is the bass? [SEP] i have had koss headphones in the past, pro 4aa and
    qz - 99. the koss portapro is portable and has great bass response. the work
    great with my android phone and can be " rolled up " to be carried in my
    motorcycle jacket or computer bag without getting crunched. they are very light
    and don't feel heavy or bear down on your ears even after listening to music
    with them on all day. the sound is [SEP]
    
    [CLS] how is the bass? [SEP] and don't feel heavy or bear down on your ears even
    after listening to music with them on all day. the sound is night and day better
    than any ear - bud could be and are almost as good as the pro 4aa. they are "
    open air " headphones so you cannot match the bass to the sealed types, but it
    comes close. for $ 32, you cannot go wrong. [SEP]</code></pre>
<hr>
</section>
</section>
<section id="using-haystack-to-build-a-qa-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="using-haystack-to-build-a-qa-pipeline">Using Haystack to Build a QA Pipeline</h3>
<ul>
<li>Real-world users will only provide a question about a product rather than a question-context pair.</li>
<li>We need a way of selecting relevant passages from among all the reviews in our corpus.</li>
<li>We could concatenate all the reviews of a given product and feed them to the model as a single context.</li>
<li>This approach can introduce unacceptable latency for our user’s queries when the context gets too long.</li>
<li>Modern QA systems typically use the retriever-reader architecture.</li>
</ul>
<section id="retriever-reader-architecture" class="level4">
<h4 class="anchored" data-anchor-id="retriever-reader-architecture">Retriever-Reader Architecture</h4>
<ul>
<li>The retriever is responsible for retrieving relevant documents for a given query.</li>
<li>Retrievers can be either sparse or dense.
<ul>
<li>Sparse retrievers use word frequencies to represent each document and query as a vector where most elements are zero.
<ul>
<li>The retriever computes the inner dot product of a query vector and a document vector to determine their relevance.</li>
</ul></li>
<li>Dense retrievers use encoders to represent the query and document as contextualized embeddings.
<ul>
<li>These embeddings encode semantic meaning and allow dense retrievers to improve search accuracy by understanding the content of the query.</li>
</ul></li>
</ul></li>
<li>The reader is responsible for extracting an answer from the documents provided by the retriever.</li>
<li>The reader is usually a reading comprehension model.</li>
<li>There can also be other components that apply postprocessing to the documents fetched by the retriever or to the answers extracted by the reader.</li>
<li>The retrieved documents may need reranking to eliminate noisy or irrelevant ones that might confuse the reader.</li>
<li>The reader’s answers might require postprocessing when the correct answer comes from various passages in a lengthy document.</li>
</ul>
</section>
<section id="haystack" class="level4">
<h4 class="anchored" data-anchor-id="haystack">Haystack</h4>
<ul>
<li><a href="https://haystack.deepset.ai/overview/intro">Homepage</a></li>
<li>Haystack is an open-source framework for building search systems that work over massive document collectors.</li>
<li>Haystack integrates tightly with Hugging Face Transformers.</li>
<li>Haystack builds on the retriever-reader architecture by adding a document store and a pipeline component.</li>
<li>The document store component is a document-oriented database that stores the documents and metadata provided to the retriever at query time.</li>
<li>The pipeline combines all the components of a QA system to enable custom query flows, merging documents from multiple retrievers, etc.</li>
</ul>
</section>
<section id="initializing-a-document-store" class="level4">
<h4 class="anchored" data-anchor-id="initializing-a-document-store">Initializing a document store</h4>
<ul>
<li>Haystack provides various document stores to choose from, and we can pair each one with a dedicated set of retrievers.</li>
</ul>
<p><strong>Compatibility of Haystack retreivers and document stores</strong></p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>In memory</th>
<th>Elasticsearch</th>
<th>FAISS</th>
<th>Milvus</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://haystack.deepset.ai/docs/v0.4.0/retrievermd#tf-idf">TF-IDF</a></td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="even">
<td><a href="https://haystack.deepset.ai/docs/v0.4.0/retrievermd#bm25-recommended">BM25</a></td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="odd">
<td><a href="https://haystack.deepset.ai/docs/v0.4.0/retrievermd#embedding-retrieval">Embedding</a></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td><a href="https://haystack.deepset.ai/docs/v0.4.0/retrievermd#dense-passage-retrieval-recommended">DPR</a></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="elasticsearch" class="level4">
<h4 class="anchored" data-anchor-id="elasticsearch">Elasticsearch</h4>
<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/targz.html">Installation Guide</a></li>
<li>Elasticsearch is a search engine that can handle textual, numerical, geospatial, structured, and unstructured data.</li>
<li>Elasticsearch can store huge volumes of data and quickly filter it with full-text search features.</li>
<li>It is the industry standard for infrastructure analytics.</li>
</ul>
<p><strong>Download and unpack Elasticsearch</strong></p>
<div class="sourceCode" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"""https://artifacts.elastic.co/downloads/elasticsearch/</span><span class="ch">\</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="st">elasticsearch-7.9.2-linux-x86_64.tar.gz"""</span></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget <span class="op">-</span>nc <span class="op">-</span>q {url}</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>tar <span class="op">-</span>xzf elasticsearch<span class="op">-</span><span class="fl">7.9.2</span><span class="op">-</span>linux<span class="op">-</span>x86_64.tar.gz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> subprocess <span class="im">import</span> Popen, PIPE, STDOUT</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="popen" class="level4">
<h4 class="anchored" data-anchor-id="popen"><code>Popen</code></h4>
<ul>
<li><a href="https://docs.python.org/3/library/subprocess.html#subprocess.Popen">Documentation</a></li>
<li>Execute a child program in a new process.</li>
</ul>
</section>
<section id="pipe" class="level4">
<h4 class="anchored" data-anchor-id="pipe"><code>Pipe</code></h4>
<ul>
<li><a href="https://docs.python.org/3/library/subprocess.html#subprocess.PIPE">Documentation</a></li>
</ul>
</section>
<section id="stdout" class="level4">
<h4 class="anchored" data-anchor-id="stdout"><code>STDOUT</code></h4>
<ul>
<li><a href="https://docs.python.org/3/library/subprocess.html#subprocess.STDOUT">Documentation</a></li>
</ul>
<p><strong>Start the Elasticsearch server</strong></p>
<div class="sourceCode" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>es_dir <span class="op">=</span> <span class="st">"elasticsearch-7.9.2"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>echo `pwd`<span class="op">/</span>$es_dir</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<pre class="text"><code>    /media/innom-dt/Samsung_T3/Projects/Current_Projects/nlp-with-transformers-book/notebooks/elasticsearch-7.9.2</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run Elasticsearch as a background process</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pkexec chown <span class="op">-</span>R daemon:daemon `pwd`<span class="op">/</span>$es_dir</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>es_server <span class="op">=</span> Popen(args<span class="op">=</span>[<span class="st">'elasticsearch-7.9.2/bin/elasticsearch'</span>],</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>                  stdout<span class="op">=</span>PIPE, stderr<span class="op">=</span>STDOUT)</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Wait until Elasticsearch has started</span></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>sleep <span class="dv">30</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>lsof <span class="op">-</span>i :<span class="dv">9200</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    COMMAND   PID     USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
    python   5323 innom-dt   67u  IPv4 146772      0t0  TCP localhost:41918-&gt;localhost:9200 (ESTABLISHED)
    java    11790 innom-dt  243u  IPv6 147757      0t0  TCP localhost:9200-&gt;localhost:41918 (ESTABLISHED)
    java    11790 innom-dt  295u  IPv6 126562      0t0  TCP ip6-localhost:9200 (LISTEN)
    java    11790 innom-dt  296u  IPv6 126563      0t0  TCP localhost:9200 (LISTEN)</code></pre>
<hr>
<div class="sourceCode" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative if Docker is installed</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="co"># from haystack.utils import launch_es</span></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="co"># launch_es()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Test the connection to the local Elasticsearch</strong></p>
<div class="sourceCode" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>curl <span class="op">-</span>X GET <span class="st">"localhost:9200/?pretty"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    {
      "name" : "innomdt",
      "cluster_name" : "elasticsearch",
      "cluster_uuid" : "qci_PXdYR4uva2XnE7o-4Q",
      "version" : {
        "number" : "7.9.2",
        "build_flavor" : "default",
        "build_type" : "tar",
        "build_hash" : "d34da0ea4a966c4e49417f2da2f244e3e97b4e6e",
        "build_date" : "2020-09-23T00:45:33.626720Z",
        "build_snapshot" : false,
        "lucene_version" : "8.6.2",
        "minimum_wire_compatibility_version" : "6.8.0",
        "minimum_index_compatibility_version" : "6.0.0-beta1"
      },
      "tagline" : "You Know, for Search"
    }</code></pre>
<hr>
<div class="sourceCode" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack.document_store.elasticsearch <span class="im">import</span> ElasticsearchDocumentStore</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="elasticsearchdocumentstore" class="level4">
<h4 class="anchored" data-anchor-id="elasticsearchdocumentstore"><code>ElasticsearchDocumentStore</code></h4>
<ul>
<li><a href="https://haystack.deepset.ai/reference/document-store#elasticsearchdocumentstore">Documentation</a></li>
<li>Create a DocumentStore using Elasticsearch to store and query the documents for our search.</li>
</ul>
<p><strong>Instantiate the document store</strong></p>
<div class="sourceCode" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Return the document embedding for later use with dense retriever </span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>document_store <span class="op">=</span> ElasticsearchDocumentStore(return_embedding<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note:</strong> ElasticsearchDocumentStore creates an index called document for storing documents and an index called label for storing the annotated answer spans.</p>
<hr>
<p><strong>Flush Elasticsearch with each notebook restart</strong></p>
<div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(document_store.get_all_documents()) <span class="kw">or</span> <span class="bu">len</span>(document_store.get_all_labels()) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>    document_store.delete_documents(<span class="st">"document"</span>)</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>    document_store.delete_documents(<span class="st">"label"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Populate the document index with the SubjQA reviews</strong></p>
<div class="sourceCode" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> split, df <span class="kw">in</span> dfs.items():</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Exclude duplicate reviews</span></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    docs <span class="op">=</span> [{<span class="st">"text"</span>: row[<span class="st">"context"</span>], </span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>             <span class="st">"meta"</span>:{<span class="st">"item_id"</span>: row[<span class="st">"title"</span>], <span class="st">"question_id"</span>: row[<span class="st">"id"</span>], </span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"split"</span>: split}} </span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _,row <span class="kw">in</span> df.drop_duplicates(subset<span class="op">=</span><span class="st">"context"</span>).iterrows()]</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>    document_store.write_documents(docs, index<span class="op">=</span><span class="st">"document"</span>)</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loaded </span><span class="sc">{</span>document_store<span class="sc">.</span>get_document_count()<span class="sc">}</span><span class="ss"> documents"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Loaded 1615 documents</code></pre>
<hr>
</section>
<section id="initializing-a-retriever" class="level4">
<h4 class="anchored" data-anchor-id="initializing-a-retriever">Initializing a retriever</h4>
<div class="sourceCode" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack.retriever.sparse <span class="im">import</span> ElasticsearchRetriever</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="elasticsearchretriever" class="level4">
<h4 class="anchored" data-anchor-id="elasticsearchretriever"><code>ElasticsearchRetriever</code></h4>
<ul>
<li><a href="https://haystack.deepset.ai/reference/retriever#elasticsearchretriever">Documentation</a></li>
<li>The ElasticsearchRetriever uses the BM25 retriever by default.</li>
</ul>
<p><strong>Initialize a sparse retriever based on BM25</strong> * BM25 is an improved version of the Term Frequency-Inverse Document Frequency (TF-IDF) algorithm and represents the question and context as sparse vectors. * BM25 improves on TF-IDF by saturating TF (how many times words in the query occur in a document) values after a set number of occurrences of the given term. It also normalizes the document length to favor short documents over long ones. * <a href="https://web.stanford.edu/~jurafsky/slp3/23.pdf">TF-IDF and BM25 Explanation</a></p>
<hr>
<div class="sourceCode" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>es_retriever <span class="op">=</span> ElasticsearchRetriever(document_store<span class="op">=</span>document_store)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Examine a simple query for a single electronics product</strong></p>
<ul>
<li>For review-based QA systems, it is crucial to restrict the queries to a single item.
<ul>
<li>Otherwise, the retriever would source reviews about products unrelated to the user’s query.</li>
</ul></li>
<li>We can decipher ASIN values with online tools like amazon ASIN or by appending the value of item_id to the <a href="www.amazon.com/dp/">www.amazon.com/dp/</a> URL.</li>
</ul>
<hr>
<div class="sourceCode" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>item_id <span class="op">=</span> <span class="st">"B0074BW614"</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"Is it good for reading?"</span></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>retrieved_docs <span class="op">=</span> es_retriever.retrieve(</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>    query<span class="op">=</span>query, top_k<span class="op">=</span><span class="dv">3</span>, filters<span class="op">=</span>{<span class="st">"item_id"</span>:[item_id], <span class="st">"split"</span>:[<span class="st">"train"</span>]})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note:</strong></p>
<ul>
<li>The top_k argument specifies how many documents to return.</li>
<li>The specified filters ensure we only receive documents from the training set about the desired product.</li>
<li>Each element of retrieved_docs is a Haystack Document object used to represent documents and includes the retriever’s query score and other metadata.</li>
</ul>
<hr>
<p><strong>Examine one of the retrieved documents</strong></p>
<div class="sourceCode" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(retrieved_docs[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    {'text': 'This is a gift to myself.  I have been a kindle user for 4 years and this is my third one.  I never thought I would want a fire for I mainly use it for book reading.  I decided to try the fire for when I travel I take my laptop, my phone and my iPod classic.  I love my iPod but watching movies on the plane with it can be challenging because it is so small. Laptops battery life is not as good as the Kindle.  So the Fire combines for me what I needed all three to do. So far so good.', 'score': 6.243799, 'probability': 0.6857824513476455, 'question': None, 'meta': {'item_id': 'B0074BW614', 'question_id': '868e311275e26dbafe5af70774a300f3', 'split': 'train'}, 'embedding': None, 'id': '252e83e25d52df7311d597dc89eef9f6'}</code></pre>
<hr>
<div class="sourceCode" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>sample_doc <span class="op">=</span> retrieved_docs[<span class="dv">0</span>].to_dict()</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>sample_doc.update(sample_doc[<span class="st">'meta'</span>])</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span> sample_doc[<span class="st">'meta'</span>]</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(sample_doc.items()).T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
<th>
1
</th>
<th>
2
</th>
<th>
3
</th>
<th>
4
</th>
<th>
5
</th>
<th>
6
</th>
<th>
7
</th>
<th>
8
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
text
</td>
<td>
score
</td>
<td>
probability
</td>
<td>
question
</td>
<td>
embedding
</td>
<td>
id
</td>
<td>
item_id
</td>
<td>
question_id
</td>
<td>
split
</td>
</tr>
<tr>
<th>
1
</th>
<td>
This is a gift to myself. I have been a kindle user for 4 years and this is my third one. I never thought I would want a fire for I mainly use it for book reading. I decided to try the fire for when I travel I take my laptop, my phone and my iPod classic. I love my iPod but watching movies on the plane with it can be challenging because it is so small. Laptops battery life is not as good as the Kindle. So the Fire combines for me what I needed all three to do. So far so good.
</td>
<td>
6.243799
</td>
<td>
0.685782
</td>
<td>
None
</td>
<td>
None
</td>
<td>
252e83e25d52df7311d597dc89eef9f6
</td>
<td>
B0074BW614
</td>
<td>
868e311275e26dbafe5af70774a300f3
</td>
<td>
train
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>A larger scorer implies a document is a better match for the query.</li>
<li>Elasticsearch relies on <a href="https://lucene.apache.org/">Apache Lucene</a> for indexing and search.</li>
<li>Elasticsearch uses <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/practical-scoring-function.html">Lucene’s practical scoring function</a> by default.
<ul>
<li>The scoring function first filters the candidate documents by applying a Boolean test (does the document match the query?).</li>
<li>The scoring function then applies a similarity metric by representing the document and the query as vectors.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="initializing-a-reader" class="level4">
<h4 class="anchored" data-anchor-id="initializing-a-reader">Initializing a reader</h4>
<ul>
<li>Haystack provides two types of readers to extract answers from a given context.</li>
<li>The FARMReader reader builds on Deepset’s FARM framework for fine-tuning and deploying transformers.</li>
<li>FARMreader is compatible with Hugging Face Transformers and can load models directly from the Hugging Face Hub.</li>
<li>The TransformersReader builds on the QA pipeline from Hugging Face Transformers and is only suitable for running inference.</li>
<li>Both readers handle a model’s weights the same way but convert predictions to answers differently.</li>
<li>The Hugging Face QA pipeline normalizes the starting and ending logits with a softmax in each passage, so it is only meaningful to compare answers scores from the same section.</li>
<li>FARM does not normalize logits, meaning we can compare inter-passage answers.</li>
<li>The TransformersReader sometimes predicts the same answer twice with different scores when the answer lies across two overlapping windows.</li>
<li>FARM removes the duplicate answers.</li>
</ul>
<hr>
<div class="sourceCode" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack.reader.farm <span class="im">import</span> FARMReader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="farmreader" class="level4">
<h4 class="anchored" data-anchor-id="farmreader"><code>FARMReader</code></h4>
<ul>
<li><a href="https://haystack.deepset.ai/reference/v0.4.0/reader#farmreader">Documentation</a></li>
</ul>
<p><strong>Initialize a FARMReader with the MiniLM model</strong></p>
<div class="sourceCode" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>model_ckpt <span class="op">=</span> <span class="st">"deepset/minilm-uncased-squad2"</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>max_seq_length, doc_stride <span class="op">=</span> <span class="dv">384</span>, <span class="dv">128</span></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>reader <span class="op">=</span> FARMReader(model_name_or_path<span class="op">=</span>model_ckpt, progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>                    max_seq_len<span class="op">=</span>max_seq_length, doc_stride<span class="op">=</span>doc_stride, </span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>                    return_no_answer<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    04/11/2022 17:30:41 - INFO - farm.utils -   Using device: CUDA 
    04/11/2022 17:30:41 - INFO - farm.utils -   Number of GPUs: 1
    04/11/2022 17:30:41 - INFO - farm.utils -   Distributed Training: False
    04/11/2022 17:30:41 - INFO - farm.utils -   Automatic Mixed Precision: None
    Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertModel: ['qa_outputs.bias', 'qa_outputs.weight']
    - This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
    - This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
    04/11/2022 17:30:49 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.
    04/11/2022 17:30:49 - INFO - farm.utils -   Using device: CUDA 
    04/11/2022 17:30:49 - INFO - farm.utils -   Number of GPUs: 1
    04/11/2022 17:30:49 - INFO - farm.utils -   Distributed Training: False
    04/11/2022 17:30:49 - INFO - farm.utils -   Automatic Mixed Precision: None
    04/11/2022 17:30:49 - INFO - farm.infer -   Got ya 15 parallel workers to do inference ...
    04/11/2022 17:30:49 - INFO - farm.infer -    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
    04/11/2022 17:30:49 - INFO - farm.infer -   /w\  /w\  /w\  /w\  /w\  /w\  /w\  /|\  /w\  /w\  /w\  /w\  /w\  /w\  /|\
    04/11/2022 17:30:49 - INFO - farm.infer -   /'\  / \  /'\  /'\  / \  / \  /'\  /'\  /'\  /'\  /'\  /'\  / \  /'\  /'\
    04/11/2022 17:30:49 - INFO - farm.infer -                               </code></pre>
<p><strong>Note:</strong> * We can also fine-tune a reading comprehension model directly with Hugging Face Transformers and load it in TransformersReader to run inference. * <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb">Tutorial Link</a></p>
<hr>
<p><strong>Test the reader</strong></p>
<div class="sourceCode" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(reader.predict_on_texts(question<span class="op">=</span>question, texts<span class="op">=</span>[context], top_k<span class="op">=</span><span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    {'query': 'How much music can this hold?', 'no_ans_gap': 12.648084878921509, 'answers': [{'answer': '6000 hours', 'score': 10.69961929321289, 'probability': 0.3988136053085327, 'context': 'An MP3 is about 1 MB/minute, so about 6000 hours depending on file size.', 'offset_start': 38, 'offset_end': 48, 'offset_start_in_doc': 38, 'offset_end_in_doc': 48, 'document_id': 'e344757014e804eff50faa3ecf1c9c75'}]}</code></pre>
<hr>
<div class="sourceCode" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> (reader.predict_on_texts(question<span class="op">=</span>question, texts<span class="op">=</span>[context], top_k<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>result.update(result[<span class="st">'answers'</span>][<span class="dv">0</span>])</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span> result[<span class="st">'answers'</span>]</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(result.items())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
<th>
1
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
query
</td>
<td>
How much music can this hold?
</td>
</tr>
<tr>
<th>
1
</th>
<td>
no_ans_gap
</td>
<td>
12.648085
</td>
</tr>
<tr>
<th>
2
</th>
<td>
answer
</td>
<td>
6000 hours
</td>
</tr>
<tr>
<th>
3
</th>
<td>
score
</td>
<td>
10.699619
</td>
</tr>
<tr>
<th>
4
</th>
<td>
probability
</td>
<td>
0.398814
</td>
</tr>
<tr>
<th>
5
</th>
<td>
context
</td>
<td>
An MP3 is about 1 MB/minute, so about 6000 hours depending on file size.
</td>
</tr>
<tr>
<th>
6
</th>
<td>
offset_start
</td>
<td>
38
</td>
</tr>
<tr>
<th>
7
</th>
<td>
offset_end
</td>
<td>
48
</td>
</tr>
<tr>
<th>
8
</th>
<td>
offset_start_in_doc
</td>
<td>
38
</td>
</tr>
<tr>
<th>
9
</th>
<td>
offset_end_in_doc
</td>
<td>
48
</td>
</tr>
<tr>
<th>
10
</th>
<td>
document_id
</td>
<td>
e344757014e804eff50faa3ecf1c9c75
</td>
</tr>
</tbody>

</table>
</div>
<hr>
</section>
<section id="putting-it-all-together" class="level4">
<h4 class="anchored" data-anchor-id="putting-it-all-together">Putting it all together</h4>
<ul>
<li>Haystack provides a Pipeline abstraction that allows us to combine retrievers, readers, and other components as a customizable graph.</li>
<li>There are predefined pipelines specialized for QA systems.</li>
</ul>
<hr>
<div class="sourceCode" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack.pipeline <span class="im">import</span> ExtractiveQAPipeline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note:</strong> The ExtractiveQAPipeline takes a single retriever-reader pair as its arguments.</p>
<hr>
<p><strong>Create an extractive QA pipeline</strong></p>
<div class="sourceCode" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> ExtractiveQAPipeline(reader, es_retriever)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note:</strong> Each pipeline has a run method that specifies how the query flow will execute.</p>
<hr>
<p><strong>Run a simple example</strong></p>
<div class="sourceCode" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>n_answers <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> pipe.run(query<span class="op">=</span>query, top_k_retriever<span class="op">=</span><span class="dv">3</span>, top_k_reader<span class="op">=</span>n_answers,</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>                 filters<span class="op">=</span>{<span class="st">"item_id"</span>: [item_id], <span class="st">"split"</span>:[<span class="st">"train"</span>]})</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Question: </span><span class="sc">{</span>preds[<span class="st">'query'</span>]<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(n_answers):</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Answer </span><span class="sc">{</span>idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>preds[<span class="st">'answers'</span>][idx][<span class="st">'answer'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Review snippet: ...</span><span class="sc">{</span>preds[<span class="st">'answers'</span>][idx][<span class="st">'context'</span>]<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Question: Is it good for reading? 
    
    Answer 1: I mainly use it for book reading
    Review snippet: ... is my third one.  I never thought I would want a fire for I mainly use it for book reading.  I decided to try the fire for when I travel I take my la...


​    
​    
    Answer 2: the larger screen compared to the Kindle makes for easier reading
    Review snippet: ...ght enough that I can hold it to read, but the larger screen compared to the Kindle makes for easier reading. I love the color, something I never thou...


​    
​    
    Answer 3: it is great for reading books when no light is available
    Review snippet: ...ecoming addicted to hers! Our son LOVES it and it is great for reading books when no light is available. Amazing sound but I suggest good headphones t...


​    
​    </code></pre>
<p><strong>Note:</strong> The second and third answers are closer to what the question is asking.</p>
<hr>
</section>
</section>
</section>
<section id="improving-our-qa-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="improving-our-qa-pipeline">Improving Our QA Pipeline</h2>
<ul>
<li>The retriever sets an upper bound on the performance of the whole QA system.</li>
</ul>
<section id="evaluating-the-retriever" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-the-retriever">Evaluating the Retriever</h3>
<ul>
<li>The recall metric measures the fraction of all relevant documents retrieved and is a prevalent method for evaluating retrievers.</li>
<li>A document is relevant if it contains the answer.</li>
<li>We can compute recall for a given set of questions by counting the number of times an answer appears in the top-k documents returned by the retriever.</li>
<li>There are two ways to evaluate retrievers in Haystack.
<ul>
<li>We can use the retriever’s built-in eval() method for open and closed domain QA, but not for datasets like SubjQA.</li>
<li>We can build a custom Pipeline that combines a retriever with the EvalRetriever class, enabling us to implement custom metrics and query flows.</li>
</ul></li>
<li>Mean average precision (mAP) rewards retrievers that can place the correct answers higher up in the document ranking and is a complementary metric to recall.</li>
</ul>
<hr>
<div class="sourceCode" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack.<span class="bu">eval</span> <span class="im">import</span> EvalDocuments</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Define a custom pipeline</strong></p>
<ul>
<li>Each node in the Pipeline graph represents a class that takes some inputs and produces some outputs via a run() method.</li>
<li>An outgoing_edges attribute indicates the number of outputs from the node.</li>
<li>The EvalRetreiver class keeps track of which documents have answers that match the ground truth.</li>
</ul>
<hr>
<div class="sourceCode" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EvalRetrieverPipeline:</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, retriever):</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.retriever <span class="op">=</span> retriever</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.eval_retriever <span class="op">=</span> EvalDocuments()</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>        pipe <span class="op">=</span> Pipeline()</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>        pipe.add_node(component<span class="op">=</span><span class="va">self</span>.retriever, name<span class="op">=</span><span class="st">"ESRetriever"</span>, </span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>                      inputs<span class="op">=</span>[<span class="st">"Query"</span>])</span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a>        pipe.add_node(component<span class="op">=</span><span class="va">self</span>.eval_retriever, name<span class="op">=</span><span class="st">"EvalRetriever"</span>, </span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a>                      inputs<span class="op">=</span>[<span class="st">"ESRetriever"</span>])</span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pipeline <span class="op">=</span> pipe</span>
<span id="cb104-11"><a href="#cb104-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-12"><a href="#cb104-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-13"><a href="#cb104-13" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> EvalRetrieverPipeline(es_retriever)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note:</strong> Each node has a name and a list of inputs.</p>
<hr>
<div class="sourceCode" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack <span class="im">import</span> Label</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note:</strong> Haystack provides a Label object that represents the answer spans and their metadata in a standardized fashion.</p>
<hr>
<p><strong>Create a list of Label objects</strong></p>
<div class="sourceCode" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> []</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, row <span class="kw">in</span> dfs[<span class="st">"test"</span>].iterrows():</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Metadata used for filtering in the Retriever</span></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>    meta <span class="op">=</span> {<span class="st">"item_id"</span>: row[<span class="st">"title"</span>], <span class="st">"question_id"</span>: row[<span class="st">"id"</span>]}</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Populate labels for questions with answers</span></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(row[<span class="st">"answers.text"</span>]):</span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> answer <span class="kw">in</span> row[<span class="st">"answers.text"</span>]:</span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>            label <span class="op">=</span> Label(</span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a>                question<span class="op">=</span>row[<span class="st">"question"</span>], answer<span class="op">=</span>answer, <span class="bu">id</span><span class="op">=</span>i, origin<span class="op">=</span>row[<span class="st">"id"</span>],</span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a>                meta<span class="op">=</span>meta, is_correct_answer<span class="op">=</span><span class="va">True</span>, is_correct_document<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a>                no_answer<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a>            labels.append(label)</span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Populate labels for questions without answers</span></span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb106-15"><a href="#cb106-15" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> Label(</span>
<span id="cb106-16"><a href="#cb106-16" aria-hidden="true" tabindex="-1"></a>            question<span class="op">=</span>row[<span class="st">"question"</span>], answer<span class="op">=</span><span class="st">""</span>, <span class="bu">id</span><span class="op">=</span>i, origin<span class="op">=</span>row[<span class="st">"id"</span>],</span>
<span id="cb106-17"><a href="#cb106-17" aria-hidden="true" tabindex="-1"></a>            meta<span class="op">=</span>meta, is_correct_answer<span class="op">=</span><span class="va">True</span>, is_correct_document<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb106-18"><a href="#cb106-18" aria-hidden="true" tabindex="-1"></a>            no_answer<span class="op">=</span><span class="va">True</span>)  </span>
<span id="cb106-19"><a href="#cb106-19" aria-hidden="true" tabindex="-1"></a>        labels.append(label)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    {'id': 'e28f5e62-85e8-41b2-8a34-fbff63b7a466', 'created_at': None, 'updated_at':
    None, 'question': 'What is the tonal balance of these headphones?', 'answer': 'I
    have been a headphone fanatic for thirty years', 'is_correct_answer': True,
    'is_correct_document': True, 'origin': 'd0781d13200014aa25860e44da9d5ea7',
    'document_id': None, 'offset_start_in_doc': None, 'no_answer': False,
    'model_id': None, 'meta': {'item_id': 'B00001WRSJ', 'question_id':
    'd0781d13200014aa25860e44da9d5ea7'}}</code></pre>
<hr>
<div class="sourceCode" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(labels[<span class="dv">0</span>].to_dict().items())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
<th>
1
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
id
</td>
<td>
7c4e950b-2c60-4721-8068-823605241c34
</td>
</tr>
<tr>
<th>
1
</th>
<td>
created_at
</td>
<td>
None
</td>
</tr>
<tr>
<th>
2
</th>
<td>
updated_at
</td>
<td>
None
</td>
</tr>
<tr>
<th>
3
</th>
<td>
question
</td>
<td>
What is the tonal balance of these headphones?
</td>
</tr>
<tr>
<th>
4
</th>
<td>
answer
</td>
<td>
I have been a headphone fanatic for thirty years
</td>
</tr>
<tr>
<th>
5
</th>
<td>
is_correct_answer
</td>
<td>
True
</td>
</tr>
<tr>
<th>
6
</th>
<td>
is_correct_document
</td>
<td>
True
</td>
</tr>
<tr>
<th>
7
</th>
<td>
origin
</td>
<td>
d0781d13200014aa25860e44da9d5ea7
</td>
</tr>
<tr>
<th>
8
</th>
<td>
document_id
</td>
<td>
None
</td>
</tr>
<tr>
<th>
9
</th>
<td>
offset_start_in_doc
</td>
<td>
None
</td>
</tr>
<tr>
<th>
10
</th>
<td>
no_answer
</td>
<td>
False
</td>
</tr>
<tr>
<th>
11
</th>
<td>
model_id
</td>
<td>
None
</td>
</tr>
<tr>
<th>
12
</th>
<td>
meta
</td>
<td>
{‘item_id’: ‘B00001WRSJ’, ‘question_id’: ‘d0781d13200014aa25860e44da9d5ea7’}
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>The origin field contains the unique question ID, meaning we can filter the document store per question.</li>
<li>The item_id meta subfield allows us to filter the labels by product.</li>
</ul>
<hr>
<p><strong>Add answers to a dedicated <code>label</code> index</strong></p>
<div class="sourceCode" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>document_store.write_labels(labels, index<span class="op">=</span><span class="st">"label"</span>)</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"""Loaded </span><span class="sc">{</span>document_store<span class="sc">.</span>get_label_count(index<span class="op">=</span><span class="st">"label"</span>)<span class="sc">}</span><span class="ss"> </span><span class="ch">\</span></span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a><span class="ss">question-answer pairs"""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Loaded 358 question-answer pairs</code></pre>
<hr>
<p><strong>Aggregate all question-answer pairs associated with a unique ID</strong></p>
<div class="sourceCode" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>labels_agg <span class="op">=</span> document_store.get_all_labels_aggregated(</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span><span class="st">"label"</span>,</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>    open_domain<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>    aggregate_by_meta<span class="op">=</span>[<span class="st">"item_id"</span>]</span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(labels_agg))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    330</code></pre>
<hr>
<div class="sourceCode" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels_agg[<span class="dv">109</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    {'question': 'How does the fan work?', 'multiple_answers': ["the fan itself isn't super loud. There is an adjustable dial to change fan speed", 'the fan is really really good'], 'is_correct_answer': True, 'is_correct_document': True, 'origin': 'f20dae56410f31632d6a9f8f8284657a', 'multiple_document_ids': [None, None], 'multiple_offset_start_in_docs': [None, None], 'no_answer': False, 'model_id': None, 'meta': {'item_id': 'B002MU1ZRS'}}</code></pre>
<hr>
<div class="sourceCode" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(labels_agg[<span class="dv">109</span>].to_dict().items())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
<th>
1
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
question
</td>
<td>
How does the fan work?
</td>
</tr>
<tr>
<th>
1
</th>
<td>
multiple_answers
</td>
<td>
[the fan itself isn’t super loud. There is an adjustable dial to change fan speed, the fan is really really good]
</td>
</tr>
<tr>
<th>
2
</th>
<td>
is_correct_answer
</td>
<td>
True
</td>
</tr>
<tr>
<th>
3
</th>
<td>
is_correct_document
</td>
<td>
True
</td>
</tr>
<tr>
<th>
4
</th>
<td>
origin
</td>
<td>
f20dae56410f31632d6a9f8f8284657a
</td>
</tr>
<tr>
<th>
5
</th>
<td>
multiple_document_ids
</td>
<td>
[None, None]
</td>
</tr>
<tr>
<th>
6
</th>
<td>
multiple_offset_start_in_docs
</td>
<td>
[None, None]
</td>
</tr>
<tr>
<th>
7
</th>
<td>
no_answer
</td>
<td>
False
</td>
</tr>
<tr>
<th>
8
</th>
<td>
model_id
</td>
<td>
None
</td>
</tr>
<tr>
<th>
9
</th>
<td>
meta
</td>
<td>
{‘item_id’: ‘B002MU1ZRS’}
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Note:</strong> The multiple_answers field aggregates all the answers associated with a given question.</p>
<hr>
<p><strong>Define a function that feeds each question-answer pair associated with each product to the evaluation pipeline and tracks the correct retrievals</strong></p>
<div class="sourceCode" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_pipeline(pipeline, top_k_retriever<span class="op">=</span><span class="dv">10</span>, top_k_reader<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> labels_agg:</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>        _ <span class="op">=</span> pipeline.pipeline.run(</span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>            query<span class="op">=</span>l.question,</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>            top_k_retriever<span class="op">=</span>top_k_retriever,</span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a>            top_k_reader<span class="op">=</span>top_k_reader,</span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a>            top_k_eval_documents<span class="op">=</span>top_k_retriever,    </span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>l,</span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a>            filters<span class="op">=</span>{<span class="st">"item_id"</span>: [l.meta[<span class="st">"item_id"</span>]], <span class="st">"split"</span>: [<span class="st">"test"</span>]})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>run_pipeline(pipe, top_k_retriever<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall@3: </span><span class="sc">{</span>pipe<span class="sc">.</span>eval_retriever<span class="sc">.</span>recall<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Recall@3: 0.95</code></pre>
<p><strong>Note:</strong> Increasing the top_k_retriever value improves the recall at the expense of providing more documents to the reader and slowing down the end-to-end pipeline.</p>
<hr>
<p><strong>Create a function to evaluate several <span class="math inline">\(k\)</span> values on the test set</strong></p>
<div class="sourceCode" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_retriever(retriever, topk_values <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">10</span>,<span class="dv">20</span>]):</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>    topk_results <span class="op">=</span> {}</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> topk <span class="kw">in</span> topk_values:</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create Pipeline</span></span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> EvalRetrieverPipeline(retriever)</span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Loop over each question-answers pair in test set</span></span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a>        run_pipeline(p, top_k_retriever<span class="op">=</span>topk)</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get metrics</span></span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a>        topk_results[topk] <span class="op">=</span> {<span class="st">"recall"</span>: p.eval_retriever.recall}</span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb120-12"><a href="#cb120-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame.from_dict(topk_results, orient<span class="op">=</span><span class="st">"index"</span>)</span>
<span id="cb120-13"><a href="#cb120-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-14"><a href="#cb120-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-15"><a href="#cb120-15" aria-hidden="true" tabindex="-1"></a>es_topk_df <span class="op">=</span> evaluate_retriever(es_retriever)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Plot the results</strong></p>
<div class="sourceCode" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_retriever_eval(dfs, retriever_names):</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> df, retriever_name <span class="kw">in</span> <span class="bu">zip</span>(dfs, retriever_names):</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>        df.plot(y<span class="op">=</span><span class="st">"recall"</span>, ax<span class="op">=</span>ax, label<span class="op">=</span>retriever_name)</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>    plt.xticks(df.index)</span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Top-k Recall"</span>)</span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"k"</span>)</span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a>plot_retriever_eval([es_topk_df], [<span class="st">"BM25"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_182_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>There is an inflection point around k=5, and we get almost perfect recall from k=10 onwards.</li>
<li>We want to use smaller k values when possible to reduce overall latency.</li>
</ul>
<hr>
<section id="dense-passage-retrieval" class="level4">
<h4 class="anchored" data-anchor-id="dense-passage-retrieval">Dense Passage Retrieval</h4>
<ul>
<li><a href="https://arxiv.org/abs/2004.04906">Dense Passage Retrieval for Open-Domain Question Answering</a></li>
<li>Sparse retrievers might not capture the relevant documents if the query contains terms not found in the review.</li>
<li>Dense Pattern Retrieval (DPR) uses two BERT models as encoders for the question and the passage.</li>
<li>These encoders map the input text into a d-dimensional vector representation of the <code>[CLS]</code> token.</li>
<li>We then calculate the dot-product similarity for the two vectors.</li>
<li>The encoders train on a dataset of relevant and irrelevant passages to learn that relevant question-passage pairs are more similar.</li>
</ul>
<hr>
<div class="sourceCode" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack.retriever.dense <span class="im">import</span> DensePassageRetriever</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="densepassageretriever" class="level4">
<h4 class="anchored" data-anchor-id="densepassageretriever"><code>DensePassageRetriever</code></h4>
<ul>
<li><a href="https://haystack.deepset.ai/reference/v0.4.0/retriever#densepassageretriever">Documentation</a></li>
</ul>
<p><strong>Initialize a dense retriever using encoders trained on the NQ corpus</strong></p>
<div class="sourceCode" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>dpr_retriever <span class="op">=</span> DensePassageRetriever(document_store<span class="op">=</span>document_store,</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>    query_embedding_model<span class="op">=</span><span class="st">"facebook/dpr-question_encoder-single-nq-base"</span>,</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a>    passage_embedding_model<span class="op">=</span><span class="st">"facebook/dpr-ctx_encoder-single-nq-base"</span>,</span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Don't include the title in the embedding</span></span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a>    embed_title<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Iterate over the indexed documents and apply the encoders to update the embedding representation</strong></p>
<div class="sourceCode" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>document_store.update_embeddings(retriever<span class="op">=</span>dpr_retriever)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    04/11/2022 20:56:41 - INFO - haystack.document_store.elasticsearch -   Updating embeddings for all 1615 docs ...



    Updating embeddings:   0%|          | 0/1615 [00:00&lt;?, ? Docs/s]



    Create embeddings:   0%|          | 0/1616 [00:00&lt;?, ? Docs/s]</code></pre>
<hr>
<p><strong>Evaluate the dense retriever</strong></p>
<div class="sourceCode" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>dpr_topk_df <span class="op">=</span> evaluate_retriever(dpr_retriever)</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>plot_retriever_eval([es_topk_df, dpr_topk_df], [<span class="st">"BM25"</span>, <span class="st">"DPR"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_192_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Note:</strong> * The DPR does not provide a boost in recall over BM25 and saturates around k=3. * We can speed up the search of the embeddings by using <a href="https://haystack.deepset.ai/docs/latest/apidatabasemd#Class-FAISSDocumentStore">Facebook’s FAISS library</a> as the document store. * <a href="https://haystack.deepset.ai/tutorials/train-dpr">Tutorial Link</a></p>
<hr>
</section>
</section>
<section id="evaluating-the-reader" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-the-reader">Evaluating the Reader</h3>
<ul>
<li>There are two primary metrics to evaluate readers in extractive QA.</li>
<li>Exact Match (EM) is a binary metric that gives EM = 1 if the characters in the predicted and ground-truth answers match exactly and EM = 0 otherwise.</li>
<li><span class="math inline">\(F_{1}\)</span>-score measures the harmonic mean of the precision and recall.</li>
</ul>
<hr>
<div class="sourceCode" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> farm.evaluation.squad_evaluation <span class="im">import</span> compute_f1, compute_exact</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Compute Exact Match and <span class="math inline">\(F_{1}\)</span>-score</strong></p>
<div class="sourceCode" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> <span class="st">"about 6000 hours"</span></span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>label <span class="op">=</span> <span class="st">"6000 hours"</span></span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"EM: </span><span class="sc">{</span>compute_exact(label, pred)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1: </span><span class="sc">{</span>compute_f1(label, pred)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    EM: 0
    F1: 0.8</code></pre>
<p><strong>Note:</strong> * These functions first normalize the prediction and label by removing punctuation, fixing whitespace, and converting to lowercase. * They then tokenize the normalized strings as a bag of words before computing the metric at the token level. * The EM is a much stricter metric than the <span class="math inline">\(F_{1}\)</span>-score, but the <span class="math inline">\(F_{1}\)</span>-score does not always catch truly incorrect answers.</p>
<hr>
<div class="sourceCode" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> <span class="st">"about 6000 dollars"</span></span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"EM: </span><span class="sc">{</span>compute_exact(label, pred)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1: </span><span class="sc">{</span>compute_f1(label, pred)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    EM: 0
    F1: 0.4</code></pre>
<p><strong>Note:</strong> * Tracking both metrics is an effective strategy to balance the trade-off between underestimating and overestimating model performance. * There are often multiple valid answers per question. * We calculate the metrics for each question-answer pair in the evaluation set and select the best score over all possible answers. * We obtain the overall scores by averaging the individual scores of each question-answer pair.</p>
<hr>
<div class="sourceCode" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack.<span class="bu">eval</span> <span class="im">import</span> EvalAnswers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a new pipeline to evaluate the reader</strong></p>
<div class="sourceCode" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_reader(reader):</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>    score_keys <span class="op">=</span> [<span class="st">'top_1_em'</span>, <span class="st">'top_1_f1'</span>]</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>    eval_reader <span class="op">=</span> EvalAnswers(skip_incorrect_retrieval<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a>    pipe <span class="op">=</span> Pipeline()</span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a>    pipe.add_node(component<span class="op">=</span>reader, name<span class="op">=</span><span class="st">"QAReader"</span>, inputs<span class="op">=</span>[<span class="st">"Query"</span>])</span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a>    pipe.add_node(component<span class="op">=</span>eval_reader, name<span class="op">=</span><span class="st">"EvalReader"</span>, inputs<span class="op">=</span>[<span class="st">"QAReader"</span>])</span>
<span id="cb133-7"><a href="#cb133-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-8"><a href="#cb133-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> labels_agg:</span>
<span id="cb133-9"><a href="#cb133-9" aria-hidden="true" tabindex="-1"></a>        doc <span class="op">=</span> document_store.query(l.question, </span>
<span id="cb133-10"><a href="#cb133-10" aria-hidden="true" tabindex="-1"></a>                                   filters<span class="op">=</span>{<span class="st">"question_id"</span>:[l.origin]})</span>
<span id="cb133-11"><a href="#cb133-11" aria-hidden="true" tabindex="-1"></a>        _ <span class="op">=</span> pipe.run(query<span class="op">=</span>l.question, documents<span class="op">=</span>doc, labels<span class="op">=</span>l)</span>
<span id="cb133-12"><a href="#cb133-12" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb133-13"><a href="#cb133-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {k:v <span class="cf">for</span> k,v <span class="kw">in</span> eval_reader.__dict__.items() <span class="cf">if</span> k <span class="kw">in</span> score_keys}</span>
<span id="cb133-14"><a href="#cb133-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-15"><a href="#cb133-15" aria-hidden="true" tabindex="-1"></a>reader_eval <span class="op">=</span> {}</span>
<span id="cb133-16"><a href="#cb133-16" aria-hidden="true" tabindex="-1"></a>reader_eval[<span class="st">"Fine-tune on SQuAD"</span>] <span class="op">=</span> evaluate_reader(reader)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note:</strong> The skip_incorrect_retrieval=False argument ensures the retriever always passes the context to the reader.</p>
<hr>
<p><strong>Plot the results</strong></p>
<div class="sourceCode" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_reader_eval(reader_eval):</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame.from_dict(reader_eval)</span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>    df.plot(kind<span class="op">=</span><span class="st">"bar"</span>, ylabel<span class="op">=</span><span class="st">"Score"</span>, rot<span class="op">=</span><span class="dv">0</span>, ax<span class="op">=</span>ax)</span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>    ax.set_xticklabels([<span class="st">"EM"</span>, <span class="st">"F1"</span>])</span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a>    plt.legend(loc<span class="op">=</span><span class="st">'upper left'</span>)</span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb134-8"><a href="#cb134-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-9"><a href="#cb134-9" aria-hidden="true" tabindex="-1"></a>plot_reader_eval(reader_eval)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_206_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Note:</strong> * The fine-tuned model performs significantly worse on SubjQA than on SQuAD 2.0. * The MiniLM model achieves EM and F1 scores of 76.1 and 79.5, respectively, on SQuAD 2.0. * Customer reviews are quite different from the Wikipedia articles in the SQuAD 2.0 dataset. * The inherent subjectivity of the SubjQA dataset might also be affecting performance.</p>
<hr>
</section>
<section id="domain-adaptation" class="level3">
<h3 class="anchored" data-anchor-id="domain-adaptation">Domain Adaptation</h3>
<ul>
<li><a href="https://arxiv.org/abs/1901.11373">Learning and Evaluating General Linguistic Intelligence</a>
<ul>
<li>Transformer models are particularly adept at overfitting to SQuAD</li>
</ul></li>
<li>The most straightforward way to improve readers is by fine-tuning the MiniLM model further on the SubjQA training set.
<ul>
<li>We need to convert the data to SQuAD JSON format.</li>
</ul></li>
</ul>
<p><strong>Define a function to create the paragraphs array associated with each product ID.</strong> * Each element in this array contains a single context and a qas array of question-answer pairs</p>
<hr>
<div class="sourceCode" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_paragraphs(df):</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>    paragraphs <span class="op">=</span> []</span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>    id2context <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(df[<span class="st">"review_id"</span>], df[<span class="st">"context"</span>]))</span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> review_id, review <span class="kw">in</span> id2context.items():</span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a>        qas <span class="op">=</span> []</span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Filter for all question-answer pairs about a specific context</span></span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a>        review_df <span class="op">=</span> df.query(<span class="ss">f"review_id == '</span><span class="sc">{</span>review_id<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a>        id2question <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(review_df[<span class="st">"id"</span>], review_df[<span class="st">"question"</span>]))</span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Build up the qas array</span></span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> qid, question <span class="kw">in</span> id2question.items():</span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Filter for a single question ID</span></span>
<span id="cb135-12"><a href="#cb135-12" aria-hidden="true" tabindex="-1"></a>            question_df <span class="op">=</span> df.query(<span class="ss">f"id == '</span><span class="sc">{</span>qid<span class="sc">}</span><span class="ss">'"</span>).to_dict(orient<span class="op">=</span><span class="st">"list"</span>)</span>
<span id="cb135-13"><a href="#cb135-13" aria-hidden="true" tabindex="-1"></a>            ans_start_idxs <span class="op">=</span> question_df[<span class="st">"answers.answer_start"</span>][<span class="dv">0</span>].tolist()</span>
<span id="cb135-14"><a href="#cb135-14" aria-hidden="true" tabindex="-1"></a>            ans_text <span class="op">=</span> question_df[<span class="st">"answers.text"</span>][<span class="dv">0</span>].tolist()</span>
<span id="cb135-15"><a href="#cb135-15" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fill answerable questions</span></span>
<span id="cb135-16"><a href="#cb135-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(ans_start_idxs):</span>
<span id="cb135-17"><a href="#cb135-17" aria-hidden="true" tabindex="-1"></a>                answers <span class="op">=</span> [</span>
<span id="cb135-18"><a href="#cb135-18" aria-hidden="true" tabindex="-1"></a>                    {<span class="st">"text"</span>: text, <span class="st">"answer_start"</span>: answer_start}</span>
<span id="cb135-19"><a href="#cb135-19" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> text, answer_start <span class="kw">in</span> <span class="bu">zip</span>(ans_text, ans_start_idxs)]</span>
<span id="cb135-20"><a href="#cb135-20" aria-hidden="true" tabindex="-1"></a>                is_impossible <span class="op">=</span> <span class="va">False</span></span>
<span id="cb135-21"><a href="#cb135-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb135-22"><a href="#cb135-22" aria-hidden="true" tabindex="-1"></a>                answers <span class="op">=</span> []</span>
<span id="cb135-23"><a href="#cb135-23" aria-hidden="true" tabindex="-1"></a>                is_impossible <span class="op">=</span> <span class="va">True</span></span>
<span id="cb135-24"><a href="#cb135-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add question-answer pairs to qas</span></span>
<span id="cb135-25"><a href="#cb135-25" aria-hidden="true" tabindex="-1"></a>            qas.append({<span class="st">"question"</span>: question, <span class="st">"id"</span>: qid, </span>
<span id="cb135-26"><a href="#cb135-26" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"is_impossible"</span>: is_impossible, <span class="st">"answers"</span>: answers})</span>
<span id="cb135-27"><a href="#cb135-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add context and question-answer pairs to paragraphs</span></span>
<span id="cb135-28"><a href="#cb135-28" aria-hidden="true" tabindex="-1"></a>        paragraphs.append({<span class="st">"qas"</span>: qas, <span class="st">"context"</span>: review})</span>
<span id="cb135-29"><a href="#cb135-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> paragraphs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Test on rows associated with a single product ID</strong></p>
<div class="sourceCode" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>product <span class="op">=</span> dfs[<span class="st">"train"</span>].query(<span class="st">"title == 'B00001P4ZH'"</span>)</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>create_paragraphs(product)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    [{'qas': [{'question': 'How is the bass?',
        'id': '2543d296da9766d8d17d040ecc781699',
        'is_impossible': True,
        'answers': []}],
      'context': 'I have had Koss headphones in the past, Pro 4AA and QZ-99.  The Koss Portapro is portable AND has great bass response.  The work great with my Android phone and can be "rolled up" to be carried in my motorcycle jacket or computer bag without getting crunched.  They are very light and do not feel heavy or bear down on your ears even after listening to music with them on all day.  The sound is night and day better than any ear-bud could be and are almost as good as the Pro 4AA.  They are "open air" headphones so you cannot match the bass to the sealed types, but it comes close. For $32, you cannot go wrong.'},
     {'qas': [{'question': 'Is this music song have a goo bass?',
        'id': 'd476830bf9282e2b9033e2bb44bbb995',
        'is_impossible': False,
        'answers': [{'text': 'Bass is weak as expected', 'answer_start': 1302},
         {'text': 'Bass is weak as expected, even with EQ adjusted up',
          'answer_start': 1302}]}],
      'context': 'To anyone who hasn\'t tried all the various types of headphones, it is important to remember exactly what these are: cheap portable on-ear headphones. They give a totally different sound then in-ears or closed design phones, but for what they are I would say they\'re good. I currently own six pairs of phones, from stock apple earbuds to Sennheiser HD 518s. Gave my Portapros a run on both my computer\'s sound card and mp3 player, using 256 kbps mp3s or better. The clarity is good and they\'re very lightweight. The folding design is simple but effective. The look is certainly retro and unique, although I didn\'t find it as comfortable as many have claimed. Earpads are *very* thin and made my ears sore after 30 minutes of listening, although this can be remedied to a point by adjusting the "comfort zone" feature (tightening the temple pads while loosening the ear pads). The cord seems to be an average thickness, but I wouldn\'t get too rough with these. The steel headband adjusts smoothly and easily, just watch out that the slider doesn\'t catch your hair. Despite the sore ears, the phones are very lightweight overall.Back to the sound: as you would expect, it\'s good for a portable phone, but hardly earth shattering. At flat EQ the clarity is good, although the highs can sometimes be harsh. Bass is weak as expected, even with EQ adjusted up. To be fair, a portable on-ear would have a tough time comparing to the bass of an in-ear with a good seal or a pair with larger drivers. No sound isolation offered if you\'re into that sort of thing. Cool 80s phones, though I\'ve certainly owned better portable on-ears (Sony makes excellent phones in this category). Soundstage is very narrow and lacks body. A good value if you can get them for under thirty, otherwise I\'d rather invest in a nicer pair of phones. If we\'re talking about value, they\'re a good buy compared to new stock apple buds. If you\'re trying to compare the sound quality of this product to serious headphones, there\'s really no comparison at all.Update: After 100 hours of burn-in time the sound has not been affected in any appreciable way. Highs are still harsh, and bass is still underwhelming. I sometimes use these as a convenience but they have been largely replaced in my collection.'},
     {'qas': [{'question': 'How is the bass?',
        'id': '455575557886d6dfeea5aa19577e5de4',
        'is_impossible': False,
        'answers': [{'text': 'The only fault in the sound is the bass',
          'answer_start': 650}]}],
      'context': "I have had many sub-$100 headphones from $5 Panasonic to $100 Sony, with Sennheiser HD 433, 202, PX100 II (I really wanted to like these PX100-II, they were so very well designed), and even a Grado SR60 for awhile.  And what it basically comes down to is value.  I have never heard sound as good as these headphones in the $35 range, easily the best under $75.  I can't believe they're over 25 years old.It's hard to describe how much detail these headphones bring out without making it too harsh or dull.  I listen to every type of music from classical to hip hop to electronic to country, and these headphones are suitable for all types of music.  The only fault in the sound is the bass.  It's just a *slight* bit boomy, but you get to like it after a while to be honest.The design is from the 80s as you all have probably figured out.  It could use a update but it seems like Koss has tried to perfect this formula and failed in the past.  I don't really care about the looks or the way it folds up or the fact that my hair gets caught up in it (I have very short hair, even for a male).But despite it's design flaws, it's the most comfortable headphones I have ever worn, and the best part is that it's also the best sounding pair of headphones I have ever heard under $75.If you can get over the design flaws or if sound is the most important feature of headphones for you, there is nothing even close to this at this price range.This one is an absolute GEM.  I loved these so much I ordered two of the 25th Anniversary ones for a bit more.Update: I read some reviews about the PX100-II being much improved and better sounding than the PortaPro.  Since the PX100-II is relatively new, I thought I'd give it another listen.  This time I noticed something different.  The sound is warm, mellow, and neutral, but it loses a lot of detail at the expense of these attributes.  I still prefer higher-detail Portapro, but some may prefer the more mellow sound of the PX100-II.Oh by the way the Portapro comes in the straight plug now, not the angled plug anymore.  It's supposed to be for better compatibility with the iPods and iPhones out there."}]</code></pre>
<hr>
<div class="sourceCode" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Apply the create_paragraphs() function each product ID in the DataFrame of each split</strong></p>
<div class="sourceCode" id="cb139"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_to_squad(dfs):</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> split, df <span class="kw">in</span> dfs.items():</span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>        subjqa_data <span class="op">=</span> {}</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create `paragraphs` for each product ID</span></span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a>        groups <span class="op">=</span> (df.groupby(<span class="st">"title"</span>).<span class="bu">apply</span>(create_paragraphs)</span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a>            .to_frame(name<span class="op">=</span><span class="st">"paragraphs"</span>).reset_index())</span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a>        subjqa_data[<span class="st">"data"</span>] <span class="op">=</span> groups.to_dict(orient<span class="op">=</span><span class="st">"records"</span>)</span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save the result to disk</span></span>
<span id="cb139-9"><a href="#cb139-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(<span class="ss">f"electronics-</span><span class="sc">{</span>split<span class="sc">}</span><span class="ss">.json"</span>, <span class="st">"w+"</span>, encoding<span class="op">=</span><span class="st">"utf-8"</span>) <span class="im">as</span> f:</span>
<span id="cb139-10"><a href="#cb139-10" aria-hidden="true" tabindex="-1"></a>            json.dump(subjqa_data, f)</span>
<span id="cb139-11"><a href="#cb139-11" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb139-12"><a href="#cb139-12" aria-hidden="true" tabindex="-1"></a>convert_to_squad(dfs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Fine-tune the reader on the train and validation splits</strong></p>
<div class="sourceCode" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>train_filename <span class="op">=</span> <span class="st">"electronics-train.json"</span></span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>dev_filename <span class="op">=</span> <span class="st">"electronics-validation.json"</span></span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a>reader.train(data_dir<span class="op">=</span><span class="st">"."</span>, use_gpu<span class="op">=</span><span class="va">True</span>, n_epochs<span class="op">=</span><span class="dv">1</span>, batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a>             train_filename<span class="op">=</span>train_filename, dev_filename<span class="op">=</span>dev_filename)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    04/11/2022 22:17:08 - INFO - farm.utils -   Using device: CUDA 
    04/11/2022 22:17:08 - INFO - farm.utils -   Number of GPUs: 1
    04/11/2022 22:17:08 - INFO - farm.utils -   Distributed Training: False
    04/11/2022 22:17:08 - INFO - farm.utils -   Automatic Mixed Precision: None
    Preprocessing Dataset electronics-train.json:   1%|                            | 17/1265 [00:00&lt;00:12, 96.90 Dicts/s]04/11/2022 22:17:08 - WARNING - farm.data_handler.processor -   Answer using start/end indices is '  Operation of the menus and contro' while gold label text is 'Operation of the menus and controls'.
    Example will not be converted for training/evaluation.
    04/11/2022 22:17:08 - WARNING - farm.data_handler.processor -   Answer using start/end indices is '  This camera performs like the pros.  Fast accurate and easy to operat' while gold label text is 'This camera performs like the pros.  Fast accurate and easy to operated'.
    Example will not be converted for training/evaluation.
    Preprocessing Dataset electronics-train.json: 100%|| 1265/1265 [00:00&lt;00:00, 1899.15 Dicts/s]
    04/11/2022 22:17:09 - ERROR - farm.data_handler.processor -   Unable to convert 2 samples to features. Their ids are : 595-0-0, 572-0-0
    Preprocessing Dataset electronics-validation.json: 100%|| 252/252 [00:00&lt;00:00, 529.53 Dicts/s]
    04/11/2022 22:17:10 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'
    04/11/2022 22:17:10 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'
    04/11/2022 22:17:10 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_training_steps': 164, 'num_warmup_steps': 32}'
    04/11/2022 22:17:38 - INFO - haystack.reader.farm -   Saving reader model to ../../saved_models/deepset/minilm-uncased-squad2</code></pre>
<hr>
<p><strong>Compare performance to baseline model</strong></p>
<div class="sourceCode" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>reader_eval[<span class="st">"Fine-tune on SQuAD + SubjQA"</span>] <span class="op">=</span> evaluate_reader(reader)</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>plot_reader_eval(reader_eval)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_219_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Note:</strong> Domain adaptation increased the EM score by 6x and the F1 score over 2x.</p>
<hr>
<p><strong>Load the model with FARMReader</strong></p>
<div class="sourceCode" id="cb143"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>minilm_ckpt <span class="op">=</span> <span class="st">"microsoft/MiniLM-L12-H384-uncased"</span></span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>minilm_reader <span class="op">=</span> FARMReader(model_name_or_path<span class="op">=</span>minilm_ckpt, progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>                           max_seq_len<span class="op">=</span>max_seq_length, doc_stride<span class="op">=</span>doc_stride,</span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a>                           return_no_answer<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    04/11/2022 22:25:29 - INFO - farm.utils -   Using device: CUDA 
    04/11/2022 22:25:29 - INFO - farm.utils -   Number of GPUs: 1
    04/11/2022 22:25:29 - INFO - farm.utils -   Distributed Training: False
    04/11/2022 22:25:29 - INFO - farm.utils -   Automatic Mixed Precision: None

    04/11/2022 22:25:38 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.
    04/11/2022 22:25:38 - INFO - farm.utils -   Using device: CUDA 
    04/11/2022 22:25:38 - INFO - farm.utils -   Number of GPUs: 1
    04/11/2022 22:25:38 - INFO - farm.utils -   Distributed Training: False
    04/11/2022 22:25:38 - INFO - farm.utils -   Automatic Mixed Precision: None
    04/11/2022 22:25:38 - INFO - farm.infer -   Got ya 15 parallel workers to do inference ...
    04/11/2022 22:25:38 - INFO - farm.infer -    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
    04/11/2022 22:25:38 - INFO - farm.infer -   /w\  /w\  /w\  /w\  /w\  /w\  /w\  /|\  /w\  /w\  /w\  /w\  /w\  /w\  /|\
    04/11/2022 22:25:38 - INFO - farm.infer -   /'\  / \  /'\  /'\  / \  / \  /'\  /'\  /'\  /'\  /'\  /'\  / \  /'\  /'\
    04/11/2022 22:25:38 - INFO - farm.infer -                               </code></pre>
<hr>
<p><strong>Fine-tune directly on the SubjQA training set</strong></p>
<div class="sourceCode" id="cb145"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>minilm_reader.train(data_dir<span class="op">=</span><span class="st">"."</span>, use_gpu<span class="op">=</span><span class="va">True</span>, n_epochs<span class="op">=</span><span class="dv">1</span>, batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a>             train_filename<span class="op">=</span>train_filename, dev_filename<span class="op">=</span>dev_filename)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    04/11/2022 22:25:38 - INFO - farm.utils -   Using device: CUDA 
    04/11/2022 22:25:38 - INFO - farm.utils -   Number of GPUs: 1
    04/11/2022 22:25:38 - INFO - farm.utils -   Distributed Training: False
    04/11/2022 22:25:38 - INFO - farm.utils -   Automatic Mixed Precision: None</code></pre>
<hr>
<p><strong>Compare the results</strong></p>
<div class="sourceCode" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>reader_eval[<span class="st">"Fine-tune on SubjQA"</span>] <span class="op">=</span> evaluate_reader(minilm_reader)</span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>plot_reader_eval(reader_eval)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_226_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Note:</strong></p>
<ul>
<li>The model fine-tuned directly on the SubjQA dataset results in significantly worse performance than the model fine-tuned on SQuAD and SubjQA.</li>
<li>Use cross-validation when evaluating transformers with small datasets.
<ul>
<li><a href="https://github.com/deepset-ai/FARM/blob/master/examples/question_answering_crossvalidation.py">Example</a></li>
</ul></li>
</ul>
<hr>
</section>
<section id="evaluating-the-whole-qa-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-the-whole-qa-pipeline">Evaluating the Whole QA Pipeline</h3>
<p><strong>Augment the retriever pipeline with nodes for the reader and its evaluation</strong></p>
<div class="sourceCode" id="cb148"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize retriever pipeline</span></span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> EvalRetrieverPipeline(es_retriever)</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Add nodes for reader</span></span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>eval_reader <span class="op">=</span> EvalAnswers()</span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>pipe.pipeline.add_node(component<span class="op">=</span>reader, name<span class="op">=</span><span class="st">"QAReader"</span>, </span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a>              inputs<span class="op">=</span>[<span class="st">"EvalRetriever"</span>])</span>
<span id="cb148-7"><a href="#cb148-7" aria-hidden="true" tabindex="-1"></a>pipe.pipeline.add_node(component<span class="op">=</span>eval_reader, name<span class="op">=</span><span class="st">"EvalReader"</span>, </span>
<span id="cb148-8"><a href="#cb148-8" aria-hidden="true" tabindex="-1"></a>              inputs<span class="op">=</span>[<span class="st">"QAReader"</span>])</span>
<span id="cb148-9"><a href="#cb148-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate!</span></span>
<span id="cb148-10"><a href="#cb148-10" aria-hidden="true" tabindex="-1"></a>run_pipeline(pipe)</span>
<span id="cb148-11"><a href="#cb148-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract metrics from reader</span></span>
<span id="cb148-12"><a href="#cb148-12" aria-hidden="true" tabindex="-1"></a>reader_eval[<span class="st">"QA Pipeline (top-1)"</span>] <span class="op">=</span> {</span>
<span id="cb148-13"><a href="#cb148-13" aria-hidden="true" tabindex="-1"></a>    k:v <span class="cf">for</span> k,v <span class="kw">in</span> eval_reader.__dict__.items()</span>
<span id="cb148-14"><a href="#cb148-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> k <span class="kw">in</span> [<span class="st">"top_1_em"</span>, <span class="st">"top_1_f1"</span>]}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Compare the EM and <span class="math inline">\(F_{1}\)</span>-scores for the reader against the whole QA pipeline</strong></p>
<div class="sourceCode" id="cb149"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>plot_reader_eval({<span class="st">"Reader"</span>: reader_eval[<span class="st">"Fine-tune on SQuAD + SubjQA"</span>], </span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"QA pipeline (top-1)"</span>: reader_eval[<span class="st">"QA Pipeline (top-1)"</span>]})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_232_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Note:</strong> * There is an overall degradation compared to matching the question-context pairs as is done in the SQuAD-style evaluation. * We can circumvent this by increasing the number of possible answers the reader is allowed to predict.</p>
<hr>
</section>
</section>
<section id="going-beyond-extractive-qa" class="level2">
<h2 class="anchored" data-anchor-id="going-beyond-extractive-qa">Going Beyond Extractive QA</h2>
<ul>
<li>Abstractive/Generative QA generates answers with a pretrained model rather than extracting them as spans of text.</li>
<li>Generative QA can potentially produce better-phrased answers that synthesize evidence across multiple passages.</li>
<li>Generative QA is a less mature but fast-moving field of research.</li>
</ul>
<section id="retrieval-augmented-generation-rag" class="level3">
<h3 class="anchored" data-anchor-id="retrieval-augmented-generation-rag">Retrieval-augmented generation (RAG)</h3>
<ul>
<li>Retrieval-augmented generation (RAG) is the current state-of-the-art.</li>
<li>RAG extends the classic retriever-reader architecture by swapping the reader for a generator and using DPR as the retriever.</li>
<li>The generator is a pretrained sequence-to-sequence transformer like T5 or BART that receives latent vectors of documents from DPR and then iteratively generates an answer based on the query and these documents.</li>
<li>We can fine-tune the whole process end-to-end.</li>
<li>There are two types of RAG models available.
<ul>
<li>RAG-Sequence uses the same retrieved document to generate the complete answer.</li>
<li>RAG-Token can use a different document to generate each token in the answer, allowing the generator to synthesize evidence from multiple sources.</li>
<li>RAG-Token models tend to perform better than RAG-Sequence models.</li>
</ul></li>
</ul>
<hr>
<div class="sourceCode" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack.generator.transformers <span class="im">import</span> RAGenerator</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Instantiate the generator</strong></p>
<div class="sourceCode" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> RAGenerator(model_name_or_path<span class="op">=</span><span class="st">"facebook/rag-token-nq"</span>,</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>                        embed_title<span class="op">=</span><span class="va">False</span>, num_beams<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<div class="sourceCode" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> haystack.pipeline <span class="im">import</span> GenerativeQAPipeline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Create a pipeline that ties together the generator and retriever</strong></p>
<div class="sourceCode" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> GenerativeQAPipeline(generator<span class="op">=</span>generator, retriever<span class="op">=</span>dpr_retriever)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong>Define a function that takes a query and prints the top answsers</strong></p>
<div class="sourceCode" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_answers(query, top_k_generator<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> pipe.run(query<span class="op">=</span>query, top_k_generator<span class="op">=</span>top_k_generator, </span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>                     top_k_retriever<span class="op">=</span><span class="dv">5</span>, filters<span class="op">=</span>{<span class="st">"item_id"</span>:[<span class="st">"B0074BW614"</span>]})  </span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Question: </span><span class="sc">{</span>preds[<span class="st">'query'</span>]<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(top_k_generator):</span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Answer </span><span class="sc">{</span>idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>preds[<span class="st">'answers'</span>][idx][<span class="st">'answer'</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>generate_answers(query)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    /home/innom-dt/miniconda3/envs/transformer-book-chapter7/lib/python3.9/site-packages/transformers/models/rag/tokenization_rag.py:92: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of Hugging Face Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details
      warnings.warn(
    /home/innom-dt/miniconda3/envs/transformer-book-chapter7/lib/python3.9/site-packages/transformers/generation_utils.py:1712: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList(MaxLengthCriteria(max_length=max_length))` instead.
      warnings.warn(


    Question: Is it good for reading? 
    
    Answer 1:  the screen is absolutely beautiful
    Answer 2:  the Screen is absolutely beautiful
    Answer 3:  Kindle fire</code></pre>
<p><strong>Note:</strong> The results suggest that the subjective nature of the question is confusing the generator.</p>
<hr>
<p><strong>Try a more factual question</strong></p>
<div class="sourceCode" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>generate_answers(<span class="st">"What is the main drawback?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Question: What is the main drawback? 
    
    Answer 1:  the price
    Answer 2:  no flash support
    Answer 3:  the cost</code></pre>
<p><strong>Note:</strong> * These results are more sensible. * We could get better results by fine-tuning RAG end-to-end on SubjQA. * <a href="https://github.com/huggingface/transformers/tree/main/examples/research_projects/rag">Starter scripts</a></p>
<hr>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<ul>
<li>The techniques in this chapter can generalize to open-domain QA.
<ul>
<li><a href="https://qa.fastforwardlabs.com/">Cloudera’s Fast Forward QA series</a></li>
</ul></li>
<li>Deploying QA systems in the wild can be tricky.</li>
<li>A significant part of the value comes from providing end-users with helpful search capabilities, followed by an extractive component.</li>
<li>We can use the reader in novel ways beyond answering on-demand user queries.
<ul>
<li>Researchers at Grid Dynamics used a reader to automatically extract a set of pros and cons for each product in a client’s catalog and to extract named entities in a zero-shot fashion by creating queries like “What kind of camera?”</li>
<li><a href="https://blog.griddynamics.com/question-answering-system-using-bert/">Finding a needle in a haystack: building a question answering system for online store</a></li>
</ul></li>
<li>Generative QA is still in its infancy, so only explore after trying extractive and search methods.</li>
<li>Multimodal QA involves question answering over multiple modalities like text, tables, and images.
<ul>
<li>Multimodel QA systems could enable users to answer complex questions that integrate information across different modalities.</li>
<li><a href="https://arxiv.org/abs/2104.06039">MultiModalQA: Complex Question Answering over Text, Tables and Images</a></li>
</ul></li>
<li>Another area with practical business applications is QA over a knowledge graph, where the graph nodes correspond to real-world entities.
<ul>
<li>One can use the graph to answer questions about a missing element by encoding factoids as (subject, predicate, * object) triples.</li>
<li><a href="https://haystack.deepset.ai/docs/latest/tutorial10md">Question Answering on a Knowledge Graph Tutorial</a></li>
</ul></li>
<li>Automatic question generation is a way to do unsupervised/weakly supervised training using unlabeled data or data augmentation.
<ul>
<li><a href="https://arxiv.org/abs/2102.07033">PAQ: 65 Million Probably-Asked Questions and What You Can Do With Them</a></li>
<li><a href="https://arxiv.org/abs/2010.12643">Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering</a></li>
</ul></li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://transformersbook.com/">Natural Language Processing with Transformers Book</a></li>
<li><a href="https://github.com/nlp-with-transformers/notebooks">The Transformers book GitHub Repository</a></li>
</ul>
<p><strong>Previous:</strong> <a href="../chapter-6/">Notes on Transformers Book Ch. 6</a></p>
<p><strong>Next:</strong> <a href="../chapter-8/">Notes on Transformers Book Ch. 8</a></p>
<!-- Cloudflare Web Analytics -->
<script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;56b8d2f624604c4891327b3c0d9f6703&quot;}"></script>
<!-- End Cloudflare Web Analytics -->


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="cj-mills/christianjmills" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">
        <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2022, Christian J. Mills
  </li>  
</ul>
      </div>
  </div>
</footer>



</body></html>