<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Christian Mills">
<meta name="dcterms.date" content="2022-12-02">
<meta name="description" content="Train a Mask R-CNN model on a custom dataset using the IceVision library and perform inference with ONNX Runtime.">

<title>Christian Mills - Training a Mask R-CNN Model on a Custom Dataset With IceVision</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Christian Mills - Training a Mask R-CNN Model on a Custom Dataset With IceVision">
<meta property="og:description" content="Train a Mask R-CNN model on a custom dataset using the IceVision library and perform inference with ONNX Runtime.">
<meta property="og:image" content="christianjmills.com/posts/icevision-mask-rcnn-tutorial/social-media/cover.jpg">
<meta property="og:site-name" content="Christian Mills">
<meta name="twitter:title" content="Christian Mills - Training a Mask R-CNN Model on a Custom Dataset With IceVision">
<meta name="twitter:description" content="Train a Mask R-CNN model on a custom dataset using the IceVision library and perform inference with ONNX Runtime.">
<meta name="twitter:image" content="christianjmills.com/posts/icevision-mask-rcnn-tutorial/social-media/cover.jpg">
<meta name="twitter:creator" content="@cdotjdotmills">
<meta name="twitter:site" content="@cdotjdotmills">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Christian Mills</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/tutorials/index.html" rel="" target="">
 <span class="menu-text">Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/notes/index.html" rel="" target="">
 <span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../services.html" rel="" target="">
 <span class="menu-text">Services</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:christian@christianjmills.com" rel="" target=""><i class="bi bi-envelope-fill" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cj-mills" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/cdotjdotmills" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../blog.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tutorial-links" id="toc-tutorial-links" class="nav-link active" data-scroll-target="#tutorial-links">Tutorial Links</a></li>
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#setup-conda-environment" id="toc-setup-conda-environment" class="nav-link" data-scroll-target="#setup-conda-environment">Setup Conda Environment</a></li>
  <li><a href="#import-dependencies" id="toc-import-dependencies" class="nav-link" data-scroll-target="#import-dependencies">Import Dependencies</a></li>
  <li><a href="#download-the-dataset" id="toc-download-the-dataset" class="nav-link" data-scroll-target="#download-the-dataset">Download the Dataset</a></li>
  <li><a href="#inspect-the-dataset" id="toc-inspect-the-dataset" class="nav-link" data-scroll-target="#inspect-the-dataset">Inspect the Dataset</a></li>
  <li><a href="#create-dataset-parser" id="toc-create-dataset-parser" class="nav-link" data-scroll-target="#create-dataset-parser">Create Dataset Parser</a></li>
  <li><a href="#define-dataloader-objects" id="toc-define-dataloader-objects" class="nav-link" data-scroll-target="#define-dataloader-objects">Define DataLoader Objects</a></li>
  <li><a href="#finetune-the-model" id="toc-finetune-the-model" class="nav-link" data-scroll-target="#finetune-the-model">Finetune the Model</a></li>
  <li><a href="#save-model-checkpoint" id="toc-save-model-checkpoint" class="nav-link" data-scroll-target="#save-model-checkpoint">Save Model Checkpoint</a></li>
  <li><a href="#perform-inference-with-checkpoint" id="toc-perform-inference-with-checkpoint" class="nav-link" data-scroll-target="#perform-inference-with-checkpoint">Perform Inference with Checkpoint</a></li>
  <li><a href="#inspect-raw-model-output" id="toc-inspect-raw-model-output" class="nav-link" data-scroll-target="#inspect-raw-model-output">Inspect Raw Model Output</a></li>
  <li><a href="#export-model-to-onnx" id="toc-export-model-to-onnx" class="nav-link" data-scroll-target="#export-model-to-onnx">Export Model to ONNX</a></li>
  <li><a href="#verify-onnx-inference" id="toc-verify-onnx-inference" class="nav-link" data-scroll-target="#verify-onnx-inference">Verify ONNX Inference</a></li>
  <li><a href="#define-post-processing-steps" id="toc-define-post-processing-steps" class="nav-link" data-scroll-target="#define-post-processing-steps">Define Post-processing Steps</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Training a Mask R-CNN Model on a Custom Dataset With IceVision</h1>
  <div class="quarto-categories">
    <div class="quarto-category">icevision</div>
    <div class="quarto-category">mask-rcnn</div>
    <div class="quarto-category">object-detection</div>
    <div class="quarto-category">instance-segmentation</div>
    <div class="quarto-category">tutorial</div>
  </div>
  </div>

<div>
  <div class="description">
    Train a Mask R-CNN model on a custom dataset using the IceVision library and perform inference with ONNX Runtime.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Christian Mills </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 2, 2022</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#setup-conda-environment">Setup Conda Environment</a></li>
<li><a href="#import-dependencies">Import Dependencies</a></li>
<li><a href="#download-the-dataset">Download the Dataset</a></li>
<li><a href="#inspect-the-dataset">Inspect the Dataset</a></li>
<li><a href="#create-dataset-parser">Create Dataset Parser</a></li>
<li><a href="#define-dataloader-objects">Define DataLoader Objects</a></li>
<li><a href="#finetune-the-model">Finetune the Model</a></li>
<li><a href="#save-model-checkpoint">Save Model Checkpoint</a></li>
<li><a href="#perform-inference-with-checkpoint">Perform Inference with Checkpoint</a></li>
<li><a href="#inspect-raw-model-output">Inspect Raw Model Output</a></li>
<li><a href="#export-model-to-onnx">Export Model to ONNX</a></li>
<li><a href="#verify-onnx-inference">Verify ONNX Inference</a></li>
<li><a href="#define-post-processing-steps">Define Post-processing Steps</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<section id="tutorial-links" class="level2">
<h2 class="anchored" data-anchor-id="tutorial-links">Tutorial Links</h2>
<ul>
<li><a href="../part-1/">Part 1</a>: Train a <a href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a> model on a custom dataset using the <a href="https://airctic.com/0.11.0/">IceVision</a> library and perform inference with <a href="https://onnxruntime.ai/">ONNX Runtime</a>.</li>
<li><a href="https://github.com/cj-mills/icevision-mask-rcnn-tutorial">GitHub Repository</a></li>
</ul>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>This tutorial shows how to train a <a href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a> model on a custom dataset using the <a href="https://airctic.com/0.11.0/">IceVision</a> library. It also demonstrates how to export the trained model to the <a href="https://onnx.ai/">ONNX</a> format and perform inference using <a href="https://onnxruntime.ai/">ONNX Runtime</a>.</p>
<p>We will use a pre-existing dataset of annotated student ID card images for training. I plan to show how to create a custom dataset from scratch in a future post, including how to annotate the images and prepare them for training.</p>
<ul>
<li><strong>Dataset Source:</strong> <a href="https://github.com/MbassiJaphet/pytorch-for-information-extraction">pytorch-for-information-extraction</a></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/student-id-sample-annotation.jpg" class="img-fluid figure-img"></p>
</figure>
</div>
<p>You can find links to view the training code and run it on <a href="https://colab.research.google.com/?utm_source=scs-index">Google Colab</a> and <a href="https://www.kaggle.com/docs/notebooks">Kaggle</a> below.</p>
<table class="table">
<thead>
<tr class="header">
<th>Jupyter Notebook</th>
<th>Colab</th>
<th>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kaggle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/cj-mills/icevision-mask-rcnn-tutorial/blob/main/notebooks/Icevision_Mask_RCNN_Student_ID.ipynb">GitHub Repository</a></td>
<td><a href="https://colab.research.google.com/github/cj-mills/icevision-mask-rcnn-tutorial/blob/main/notebooks/Icevision_Mask_RCNN_Student_ID_Colab.ipynb">Open In Colab</a></td>
<td><a href="https://kaggle.com/kernels/welcome?src=https://github.com/cj-mills/icevision-mask-rcnn-tutorial/blob/main/notebooks/Icevision_Mask_RCNN_Student_ID_Kaggle.ipynb">Kaggle</a></td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p><strong>Update <code>May 17, 2023</code>:</strong> Google Colab and Kaggle Notebooks now use an updated Python version that conflicts with this tutorial’s package versions. Please create a local conda environment to run the tutorial code.</p>
</blockquote>
</section>
<section id="setup-conda-environment" class="level2">
<h2 class="anchored" data-anchor-id="setup-conda-environment">Setup Conda Environment</h2>
<p>I recommend using a dedicated <a href="https://docs.python.org/3/tutorial/venv.html">virtual environment</a> when working with the IceVision library, as it has specific dependency requirements that can conflict with other libraries or versions. The easiest way to create a virtual environment for IceVision is using <a href="https://docs.conda.io/en/latest/">Conda</a>. Below are the steps to create a Conda environment and activate it. Be sure to follow these steps in the provided order to ensure the environment works for IceVision.</p>
<blockquote class="blockquote">
<p><strong>Important:</strong> IceVision currently only supports Linux/macOS. Try using <a href="https://docs.microsoft.com/en-us/windows/wsl/install">WSL</a> (Windows Subsystem for Linux) if training locally on Windows.</p>
</blockquote>
<p><strong>Install CUDA Toolkit</strong></p>
<p>If you plan to run the training code on your local machine, you might need to install the CUDA Toolkit. CUDA requires an Nvidia GPU, and version 11.1.0 of the toolkit is available at the link below. Google Colab and Kaggle Notebooks already have CUDA installed.</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-11.1.0-download-archive">CUDA Toolkit 11.1.0</a></li>
<li><a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA Toolkit Archive</a></li>
</ul>
<p><strong>Conda environment setup steps</strong></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new conda environment</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> create <span class="at">--name</span> icevision python==3.8</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># activate the environment</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate icevision</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># install PyTorch and torchvision</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install torch==1.10.0+cu111 torchvision==0.11.1+cu111 <span class="at">-f</span> https://download.pytorch.org/whl/torch_stable.html</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># install mmcv-full</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install mmcv-full==1.3.17 <span class="at">-f</span> https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># install mmdet</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install mmdet==2.17.0</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># install icevision</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install icevision==0.11.0</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># install icedata</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install icedata==0.5.1</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># install setuptools</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install setuptools==59.5.0</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># install jupyter</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install jupyter</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># install onnxruntime</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install onnxruntime</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <a href="https://pypi.org/project/icevision/"><code>icevision</code></a> package provides the necessary functionality for data curation, data transforms, and training loops that we will use to train the model. Additionally, the <a href="https://airctic.github.io/icedata/"><code>icedata</code></a> package provides the functionality we need to create a custom parser for reading the dataset.</p>
<p><strong>Colab and Kaggle Setup Requirements</strong></p>
<p>When running the training code on Google Colab and Kaggle Notebooks, it is necessary to uninstall specific packages to avoid conflicts with IceVision and its dependencies. The platform-specific setup steps are at the top of the notebooks linked above. Follow these instructions before running the code to ensure it runs smoothly on these platforms.</p>
</section>
<section id="import-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="import-dependencies">Import Dependencies</h2>
<p>We will start by importing the IceVision library and configuring Pandas. When you import the IceVision library for the first time, it will automatically download some additional resources that it needs to function correctly.</p>
<p><strong>Import IceVision library</strong></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import all the necessary modules from the icevision package</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> icevision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Import and configure Pandas</strong></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the pandas package</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the max column width to None</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'max_colwidth'</span>, <span class="va">None</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the max number of rows and columns to None</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_rows'</span>, <span class="va">None</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="download-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="download-the-dataset">Download the Dataset</h2>
<p>The sample dataset we will use for training is available on GitHub, so all you need to do is clone the repository to access it.</p>
<p><strong>Clone dataset repository</strong></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Clone the dataset repository from GitHub</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>git clone https:<span class="op">//</span>github.com<span class="op">/</span>MbassiJaphet<span class="op">/</span>pytorch<span class="op">-</span><span class="cf">for</span><span class="op">-</span>information<span class="op">-</span>extraction.git</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="inspect-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="inspect-the-dataset">Inspect the Dataset</h2>
<p>After the dataset finishes downloading, you can inspect its contents by navigating to the <code>code/datasets/detection/student-id/</code> subfolder, where you will find the image and annotation files. In this step, we will get the file paths for the images and annotations and inspect one of the training images. That will give us a better understanding of the dataset and its structure.</p>
<p><strong>Define path to dataset</strong></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the path to the dataset directory</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> Path(<span class="st">'./pytorch-for-information-extraction/code/datasets/detection/student-id'</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the dataset name</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>dataset_name <span class="op">=</span> data_dir.name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Each image in the dataset has a corresponding JSON file that contains its annotation data.</p>
<p><strong>Inspect dataset contents</strong></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a list of the files in the dataset directory and display them using a DataFrame</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(<span class="bu">list</span>(data_dir.ls())).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10001.jpg
</td>
</tr>
<tr>
<th>
1
</th>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10001.json
</td>
</tr>
<tr>
<th>
2
</th>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10002.jpg
</td>
</tr>
<tr>
<th>
3
</th>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10002.json
</td>
</tr>
<tr>
<th>
4
</th>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10003.jpg
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Get image file paths</strong></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the file paths for all the images in the dataset</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>files <span class="op">=</span> get_image_files(data_dir)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the number of files</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(files)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>150</code></pre>
<p><strong>Inspect one of the training images</strong></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the PIL package</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Open the first image in the dataset</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> PIL.Image.<span class="bu">open</span>(files[<span class="dv">0</span>]).convert(<span class="st">'RGB'</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the dimensions of the image</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Image Dims: </span><span class="sc">{</span>img<span class="sc">.</span>size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the image</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Image Dims: (480, 640)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_16_1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>To make it easier to work with the dataset, we will create a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image efficiently.</p>
<p><strong>Create a dictionary that maps image names to file paths</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dictionary that maps image names to file paths</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>img_dict <span class="op">=</span> {<span class="bu">file</span>.name.split(<span class="st">'.'</span>)[<span class="dv">0</span>] : <span class="bu">file</span> <span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> files}</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first item in the dictionary as a DataFrame</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(<span class="bu">list</span>(img_dict.items())[<span class="dv">0</span>]).transpose()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
<th>
1
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
10001
</td>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10001.jpg
</td>
</tr>
</tbody>

</table>
</div>
<p><strong>Get list of annotation file paths</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the os and glob modules</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> glob <span class="im">import</span> glob</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a list of the annotation file paths in the dataset directory</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>annotation_paths <span class="op">=</span> glob(os.path.join(data_dir, <span class="st">"*.json"</span>))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the list of annotation file paths as a DataFrame</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(annotation_paths).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10001.json
</td>
</tr>
<tr>
<th>
1
</th>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10002.json
</td>
</tr>
<tr>
<th>
2
</th>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10003.json
</td>
</tr>
<tr>
<th>
3
</th>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10004.json
</td>
</tr>
<tr>
<th>
4
</th>
<td>
pytorch-for-information-extraction/code/datasets/detection/student-id/10005.json
</td>
</tr>
</tbody>

</table>
</div>
<p>After getting the list of annotation file paths, we will create an annotation DataFrame that contains all of the annotation data for the dataset. This DataFrame will allow us to manipulate and query the annotations more easily.</p>
<p><strong>Create annotation dataframe</strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the JSON files using Pandas and concatenate the resulting dataframes</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># into a single dataframe</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>cls_dataframes <span class="op">=</span> (pd.read_json(f, orient<span class="op">=</span><span class="st">'index'</span>).transpose() <span class="cf">for</span> f <span class="kw">in</span> annotation_paths)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>annotation_df <span class="op">=</span> pd.concat(cls_dataframes, ignore_index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign the image file name as the index for each row</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>annotation_df[<span class="st">'index'</span>] <span class="op">=</span> annotation_df.<span class="bu">apply</span>(<span class="kw">lambda</span> row: row[<span class="st">'imagePath'</span>].split(<span class="st">'.'</span>)[<span class="dv">0</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>annotation_df <span class="op">=</span> annotation_df.set_index(<span class="st">'index'</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep only the rows that have corresponding image files</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>annotation_df <span class="op">=</span> annotation_df.loc[<span class="bu">list</span>(img_dict.keys())]</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># View the first few rows of the dataframe</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>annotation_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
version
</th>
<th>
flags
</th>
<th>
shapes
</th>
<th>
lineColor
</th>
<th>
fillColor
</th>
<th>
imagePath
</th>
<th>
imageData
</th>
<th>
imageHeight
</th>
<th>
imageWidth
</th>
</tr>
<tr>
<th>
index
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
10001
</th>
<td>
3.21.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘student_id’, ‘line_color’: None, ‘fill_color’: None, ‘points’: [[19.190476190476204, 244.76190476190476], [23.0, 233.33333333333331], [385.8571428571428, 132.38095238095238], [400.1428571428571, 135.23809523809524], [468.71428571428567, 353.3333333333333], [466.80952380952374, 362.85714285714283], [97.28571428571428, 478.0952380952381], [81.09523809523807, 474.2857142857143]], ‘shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
<td>
[0, 255, 0, 128]
</td>
<td>
[255, 0, 0, 128]
</td>
<td>
10001.jpg
</td>
<td>
</td>
<td>
640
</td>
<td>
480
</td>
</tr>
<tr>
<th>
10002
</th>
<td>
3.21.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘student_id’, ‘line_color’: None, ‘fill_color’: None, ‘points’: [[21.095238095238102, 183.33333333333334], [231.41269841269843, 88.09523809523809], [450.46031746031747, 347.6190476190476], [475.06349206349205, 376.1904761904762], [478.2380952380952, 388.8888888888889], [301.25396825396825, 532.5396825396825], [271.0952380952381, 556.3492063492064], [255.22222222222223, 541.2698412698413], [242.52380952380952, 534.9206349206349], [25.85714285714286, 199.20634920634922]], ‘shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
<td>
[0, 255, 0, 128]
</td>
<td>
[255, 0, 0, 128]
</td>
<td>
10002.jpg
</td>
<td>
</td>
<td>
640
</td>
<td>
480
</td>
</tr>
<tr>
<th>
10003
</th>
<td>
3.21.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘student_id’, ‘line_color’: None, ‘fill_color’: None, ‘points’: [[138.23809523809524, 71.42857142857143], [407.7619047619047, 31.428571428571427], [418.2380952380952, 39.047619047619044], [422.04761904761904, 539.047619047619], [407.7619047619047, 552.3809523809524], [112.52380952380952, 519.047619047619], [98.23809523809524, 505.71428571428567]], ‘shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
<td>
[0, 255, 0, 128]
</td>
<td>
[255, 0, 0, 128]
</td>
<td>
10003.jpg
</td>
<td>
</td>
<td>
640
</td>
<td>
480
</td>
</tr>
<tr>
<th>
10004
</th>
<td>
3.21.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘student_id’, ‘line_color’: None, ‘fill_color’: None, ‘points’: [[119.20529801324503, 218.54304635761588], [440.3973509933775, 184.7682119205298], [445.0331125827814, 190.72847682119206], [391.3907284768212, 366.2251655629139], [384.7682119205298, 372.18543046357615], [250.33112582781456, 401.3245033112583], [82.11920529801324, 446.3576158940397], [76.82119205298014, 441.72185430463577], [49.66887417218544, 239.73509933774835], [107.28476821192052, 228.47682119205297]], ‘shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
<td>
[0, 255, 0, 128]
</td>
<td>
[255, 0, 0, 128]
</td>
<td>
10004.jpg
</td>
<td>
</td>
<td>
640
</td>
<td>
480
</td>
</tr>
<tr>
<th>
10005
</th>
<td>
3.21.1
</td>
<td>
{}
</td>
<td>
[{‘label’: ‘student_id’, ‘line_color’: None, ‘fill_color’: None, ‘points’: [[41.18840579710144, 218.8405797101449], [41.18840579710144, 209.42028985507244], [52.78260869565216, 201.44927536231882], [224.52173913043475, 142.75362318840578], [359.30434782608694, 89.85507246376811], [367.99999999999994, 92.02898550724638], [462.2028985507246, 275.3623188405797], [369.4492753623188, 348.5507246376811], [199.88405797101444, 472.463768115942], [191.91304347826082, 471.01449275362313]], ‘shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
<td>
[0, 255, 0, 128]
</td>
<td>
[255, 0, 0, 128]
</td>
<td>
10005.jpg
</td>
<td>
</td>
<td>
640
</td>
<td>
480
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p>We can retrieve the annotation data for a specific image file using its name.</p>
<p><strong>Inspect annotation data for sample image</strong></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the file ID for the image we want to inspect</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>file_id <span class="op">=</span> files[<span class="dv">56</span>].name.split(<span class="st">'.'</span>)[<span class="dv">0</span>]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the file ID</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>file_id</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'10057'</code></pre>
<p>The <code>shapes</code> entry contains the point coordinates to draw the image masks. We will also use this information to construct the associated bounding boxes. This particular entry has point coordinates for two image masks.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the annotation data for the specified image file</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>annotation_df.loc[file_id].to_frame()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
10057
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
version
</th>
<td>
3.21.1
</td>
</tr>
<tr>
<th>
flags
</th>
<td>
{}
</td>
</tr>
<tr>
<th>
shapes
</th>
<td>
[{‘label’: ‘student_id’, ‘line_color’: None, ‘fill_color’: None, ‘points’: [[4.703296703296701, 186.8131868131868], [172.28571428571428, 91.20879120879121], [177.23076923076923, 89.56043956043956], [183.82417582417582, 92.85714285714285], [260.19780219780216, 161.53846153846152], [248.65934065934067, 173.07692307692307], [99.75824175824175, 273.6263736263736], [88.2197802197802, 280.7692307692308], [83.27472527472527, 280.7692307692308], [35.472527472527474, 225.82417582417582]], ‘shape_type’: ‘polygon’, ‘flags’: {}}, {‘label’: ‘student_id’, ‘line_color’: None, ‘fill_color’: None, ‘points’: [[245.36263736263737, 134.06593406593407], [346.46153846153845, 100.0], [352.5054945054945, 101.64835164835165], [465.1428571428571, 248.9010989010989], [461.8461538461538, 252.1978021978022], [356.35164835164835, 300.5494505494505], [350.3076923076923, 297.8021978021978]], ‘shape_type’: ‘polygon’, ‘flags’: {}}, {‘label’: ‘student_id’, ‘line_color’: None, ‘fill_color’: None, ‘points’: [[33.27472527472527, 489.010989010989], [159.64835164835165, 281.3186813186813], [166.7912087912088, 271.97802197802196], [172.28571428571428, 270.3296703296703], [297.010989010989, 330.2197802197802], [300.3076923076923, 335.16483516483515], [299.2087912087912, 340.65934065934067], [223.38461538461536, 506.5934065934066], [192.6153846153846, 571.4285714285714], [184.9230769230769, 574.1758241758241], [172.28571428571428, 569.2307692307692], [47.56043956043956, 501.0989010989011], [36.021978021978015, 496.15384615384613]], ‘shape_type’: ‘polygon’, ‘flags’: {}}]
</td>
</tr>
<tr>
<th>
lineColor
</th>
<td>
[0, 255, 0, 128]
</td>
</tr>
<tr>
<th>
fillColor
</th>
<td>
[255, 0, 0, 128]
</td>
</tr>
<tr>
<th>
imagePath
</th>
<td>
10057.jpg
</td>
</tr>
<tr>
<th>
imageData
</th>
<td>
</td>
</tr>
<tr>
<th>
imageHeight
</th>
<td>
640
</td>
</tr>
<tr>
<th>
imageWidth
</th>
<td>
480
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p>We need a font file to annotate the images with class labels. We can download one from <a href="https://fonts.google.com/">Google Fonts</a>.</p>
<p><strong>Download font file</strong></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the font file name</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>font_file <span class="op">=</span> <span class="st">'KFOlCnqEu92Fr1MmEU9vAw.ttf'</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># If the font file doesn't exist, download it</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(font_file): </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">!</span>wget https:<span class="op">//</span>fonts.gstatic.com<span class="op">/</span>s<span class="op">/</span>roboto<span class="op">/</span>v30<span class="op">/</span>$font_file</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Annotate sample image</strong></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the ImageDraw class from the PIL package</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> ImageDraw</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Open the image file</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> PIL.Image.<span class="bu">open</span>(img_dict[file_id]).convert(<span class="st">'RGB'</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the dimensions of the image</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>width, height <span class="op">=</span> img.size</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a copy of the image to annotate</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>annotated_img <span class="op">=</span> img.copy()</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a blank image to store the mask</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>mask_img <span class="op">=</span> PIL.Image.new(<span class="st">'L'</span>, img.size, <span class="dv">0</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a drawing object for the annotated image</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>draw <span class="op">=</span> ImageDraw.Draw(annotated_img)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the font size for the object labels</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>fnt_size <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the annotation data for the specified image</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>annotation <span class="op">=</span> annotation_df.loc[file_id]</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through annotations for sample image</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(annotation[<span class="st">'shapes'</span>])):</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract mask polygon coords</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    points <span class="op">=</span> np.array(annotation[<span class="st">'shapes'</span>][i][<span class="st">'points'</span>])</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract bounding box coords</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    x_min, y_min <span class="op">=</span> points.<span class="bu">min</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>    x_max, y_max <span class="op">=</span> points.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw bounding box on sample image</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>    shape <span class="op">=</span> (x_min, y_min, x_max, y_max)</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>    draw.rectangle(shape, outline<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw segmentation mask on sample image</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>    xy <span class="op">=</span> [(p[<span class="dv">0</span>],p[<span class="dv">1</span>]) <span class="cf">for</span> p <span class="kw">in</span> points]</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>    ImageDraw.Draw(annotated_img, <span class="st">'RGBA'</span>).polygon(xy, fill<span class="op">=</span>(<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">125</span>), outline <span class="op">=</span><span class="st">"red"</span>)</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw segmentation mask on blank image</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>    ImageDraw.Draw(mask_img, <span class="st">'L'</span>).polygon(xy, fill<span class="op">=</span>(<span class="dv">255</span>))</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw object label on sample image</span></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>    fnt <span class="op">=</span> PIL.ImageFont.truetype(font_file, fnt_size)</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>    label <span class="op">=</span> annotation[<span class="st">'shapes'</span>][i][<span class="st">'label'</span>]</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>    draw.multiline_text((x_min, y_min<span class="op">-</span>fnt_size<span class="op">-</span><span class="dv">5</span>), <span class="ss">f"</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">"</span>, font<span class="op">=</span>fnt, fill<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the dimensions of the annotated image</span></span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(annotated_img.size)</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the annotated image</span></span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>annotated_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>(480, 640)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_30_1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Display segmentation mask</strong></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>mask_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_32_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>We need to provide IceVision with a class map that maps index values to unique class names.</p>
<p><strong>Create a class map</strong></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Explode the 'shapes' column in the annotation_df dataframe</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the resulting series to a dataframe and rename the 'shapes' column to 'shapes'</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the pandas Series function to the 'shapes' column of the dataframe</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>shapes_df <span class="op">=</span> annotation_df[<span class="st">'shapes'</span>].explode().to_frame().shapes.<span class="bu">apply</span>(pd.Series)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># View the first few rows of the resulting dataframe</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>shapes_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
label
</th>
<th>
line_color
</th>
<th>
fill_color
</th>
<th>
points
</th>
<th>
shape_type
</th>
<th>
flags
</th>
</tr>
<tr>
<th>
index
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
10001
</th>
<td>
student_id
</td>
<td>
None
</td>
<td>
None
</td>
<td>
[[19.190476190476204, 244.76190476190476], [23.0, 233.33333333333331], [385.8571428571428, 132.38095238095238], [400.1428571428571, 135.23809523809524], [468.71428571428567, 353.3333333333333], [466.80952380952374, 362.85714285714283], [97.28571428571428, 478.0952380952381], [81.09523809523807, 474.2857142857143]]
</td>
<td>
polygon
</td>
<td>
{}
</td>
</tr>
<tr>
<th>
10002
</th>
<td>
student_id
</td>
<td>
None
</td>
<td>
None
</td>
<td>
[[21.095238095238102, 183.33333333333334], [231.41269841269843, 88.09523809523809], [450.46031746031747, 347.6190476190476], [475.06349206349205, 376.1904761904762], [478.2380952380952, 388.8888888888889], [301.25396825396825, 532.5396825396825], [271.0952380952381, 556.3492063492064], [255.22222222222223, 541.2698412698413], [242.52380952380952, 534.9206349206349], [25.85714285714286, 199.20634920634922]]
</td>
<td>
polygon
</td>
<td>
{}
</td>
</tr>
<tr>
<th>
10003
</th>
<td>
student_id
</td>
<td>
None
</td>
<td>
None
</td>
<td>
[[138.23809523809524, 71.42857142857143], [407.7619047619047, 31.428571428571427], [418.2380952380952, 39.047619047619044], [422.04761904761904, 539.047619047619], [407.7619047619047, 552.3809523809524], [112.52380952380952, 519.047619047619], [98.23809523809524, 505.71428571428567]]
</td>
<td>
polygon
</td>
<td>
{}
</td>
</tr>
<tr>
<th>
10004
</th>
<td>
student_id
</td>
<td>
None
</td>
<td>
None
</td>
<td>
[[119.20529801324503, 218.54304635761588], [440.3973509933775, 184.7682119205298], [445.0331125827814, 190.72847682119206], [391.3907284768212, 366.2251655629139], [384.7682119205298, 372.18543046357615], [250.33112582781456, 401.3245033112583], [82.11920529801324, 446.3576158940397], [76.82119205298014, 441.72185430463577], [49.66887417218544, 239.73509933774835], [107.28476821192052, 228.47682119205297]]
</td>
<td>
polygon
</td>
<td>
{}
</td>
</tr>
<tr>
<th>
10005
</th>
<td>
student_id
</td>
<td>
None
</td>
<td>
None
</td>
<td>
[[41.18840579710144, 218.8405797101449], [41.18840579710144, 209.42028985507244], [52.78260869565216, 201.44927536231882], [224.52173913043475, 142.75362318840578], [359.30434782608694, 89.85507246376811], [367.99999999999994, 92.02898550724638], [462.2028985507246, 275.3623188405797], [369.4492753623188, 348.5507246376811], [199.88405797101444, 472.463768115942], [191.91304347826082, 471.01449275362313]]
</td>
<td>
polygon
</td>
<td>
{}
</td>
</tr>
</tbody>

</table>
</div>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list of unique labels from the 'label' column of the shapes_df dataframe</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> shapes_df[<span class="st">'label'</span>].unique().tolist()</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the list of labels</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>labels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>['student_id']</code></pre>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a ClassMap object with the list of labels</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>class_map <span class="op">=</span> ClassMap(labels)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the ClassMap object</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>class_map</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>&lt;ClassMap: {'background': 0, 'student_id': 1}&gt;</code></pre>
</section>
<section id="create-dataset-parser" class="level2">
<h2 class="anchored" data-anchor-id="create-dataset-parser">Create Dataset Parser</h2>
<p>To create a custom dataset parser for instance segmentation, we can use the template for an instance segmentation record and the template for an instance segmentation parser.</p>
<p><strong>View template for an instance segmentation record</strong></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an InstanceSegmentationRecord object</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>template_record <span class="op">=</span> InstanceSegmentationRecord()</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the InstanceSegmentationRecord object</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>template_record</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>BaseRecord

common: 
    - Image size None
    - Filepath: None
    - Img: None
    - Record ID: None
detection: 
    - Class Map: None
    - Labels: []
    - BBoxes: []
    - masks: []
    - mask_array: None</code></pre>
<p><strong>View template for an instance segmentation parser</strong></p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a template record for an instance segmentation dataset using the InstanceSegmentationRecord object</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>Parser.generate_template(template_record)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>class MyParser(Parser):
    def __init__(self, template_record):
        super().__init__(template_record=template_record)
    def __iter__(self) -&gt; Any:
    def __len__(self) -&gt; int:
    def record_id(self, o: Any) -&gt; Hashable:
    def parse_fields(self, o: Any, record: BaseRecord, is_new: bool):
        record.set_img_size(&lt;ImgSize&gt;)
        record.set_filepath(&lt;Union[str, Path]&gt;)
        record.detection.set_class_map(&lt;ClassMap&gt;)
        record.detection.add_labels(&lt;Sequence[Hashable]&gt;)
        record.detection.add_bboxes(&lt;Sequence[BBox]&gt;)
        record.detection.add_masks(&lt;Sequence[Mask]&gt;)</code></pre>
<p><strong>Define custom parser class</strong></p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> StudentIDParser(Parser):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize a StudentIDParser object</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, template_record, annotations_df, img_dict, class_map):</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Call the __init__ method of the parent class</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(template_record<span class="op">=</span>template_record)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set the instance variables to the values of the corresponding arguments</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_dict <span class="op">=</span> img_dict</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> annotations_df</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.class_map <span class="op">=</span> class_map</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return an iterator over the rows of the DataFrame</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>):</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> o <span class="kw">in</span> <span class="va">self</span>.df.itertuples(): <span class="cf">yield</span> o</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the number of rows in the DataFrame</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.df)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the index of the current row of the DataFrame</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> record_id(<span class="va">self</span>, o: Any) <span class="op">-&gt;</span> Hashable:</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> o.Index</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the image width and height</span></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> image_width_height(<span class="va">self</span>, o) <span class="op">-&gt;</span> Tuple[<span class="bu">int</span>, <span class="bu">int</span>]:</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>._size[:<span class="dv">2</span>]</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Parse the data from the DataFrame and populate the record object</span></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> parse_fields(<span class="va">self</span>, o, record, is_new):</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the file path of the image from the img_dict dictionary</span></span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>        filepath <span class="op">=</span> <span class="va">self</span>.img_dict[o.Index]</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Open the image and get its width and height</span></span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>        width, height <span class="op">=</span> PIL.Image.<span class="bu">open</span>(filepath).convert(<span class="st">'RGB'</span>).size</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set the image size and file path of the record object</span></span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>        record.set_img_size([width, height])</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>        record.set_filepath(Path(filepath))</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set the class map of the record object's detection attribute</span></span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>        record.detection.set_class_map(<span class="va">self</span>.class_map)</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize empty lists for labels, bounding boxes, and masks</span></span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> []</span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>        bbox_list <span class="op">=</span> []</span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>        mask_list <span class="op">=</span> []</span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Iterate over the shapes in the current row of the DataFrame</span></span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(o.shapes)):</span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get the points of the shape</span></span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>            points <span class="op">=</span> np.array(o.shapes[i][<span class="st">'points'</span>])</span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate the minimum and maximum x- and y-coordinates of the points</span></span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a>            x_min, y_min <span class="op">=</span> points.<span class="bu">min</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a>            x_max, y_max <span class="op">=</span> points.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add the label to the labels list</span></span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a>            labels.append(o.shapes[i][<span class="st">'label'</span>])</span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create a bounding box object from the coordinates and add it to the bbox_list</span></span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a>            bbox_list.append(BBox.from_xyxy(x_min, y_min, x_max, y_max))</span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create a mask image and draw the shape on it</span></span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>            mask_img <span class="op">=</span> PIL.Image.new(<span class="st">'L'</span>, (width, height), <span class="dv">0</span>)</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>            xy <span class="op">=</span> [(p[<span class="dv">0</span>],p[<span class="dv">1</span>]) <span class="cf">for</span> p <span class="kw">in</span> points]</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>            ImageDraw.Draw(mask_img, <span class="st">'L'</span>).polygon(xy, fill<span class="op">=</span>(<span class="dv">1</span>))</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Convert the mask image to a numpy array and add it to the mask_list</span></span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a>            mask_array <span class="op">=</span> np.array(mask_img).clip(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a>            mask_list.append(MaskArray(mask_array))</span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-72"><a href="#cb32-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the labels, bounding boxes, and masks to the record object</span></span>
<span id="cb32-73"><a href="#cb32-73" aria-hidden="true" tabindex="-1"></a>        record.detection.add_labels(labels)</span>
<span id="cb32-74"><a href="#cb32-74" aria-hidden="true" tabindex="-1"></a>        record.detection.add_bboxes(bbox_list)</span>
<span id="cb32-75"><a href="#cb32-75" aria-hidden="true" tabindex="-1"></a>        record.detection.add_masks(mask_list)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can then create a parser object using the custom parser class.</p>
<p><strong>Create a custom parser object</strong></p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a StudentIDParser object</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>parser <span class="op">=</span> StudentIDParser(template_record, annotation_df, img_dict, class_map)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Return the length of the parser object, which is the number of rows in the DataFrame</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(parser)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>150</code></pre>
<p>We use the parser object to parse annotations and create records.</p>
<p><strong>Parse annotations to create records</strong></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a RandomSplitter object</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>data_splitter <span class="op">=</span> RandomSplitter([<span class="fl">0.8</span>, <span class="fl">0.2</span>])</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the RandomSplitter to split the data into training and validation sets</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>train_records, valid_records <span class="op">=</span> parser.parse(data_splitter)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co"># train_records, valid_records = parser.parse(data_splitter, cache_filepath=f'{dataset_name}-cache.pkl')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s save the class labels to use later during inference.</p>
<p><strong>Export class labels</strong></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the json module</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dictionary containing the class labels</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> {<span class="st">"classes"</span>: parser.class_map.get_classes()}</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a file name for the class labels file</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>class_labels_file_name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>data_dir<span class="sc">.</span>name<span class="sc">}</span><span class="ss">-classes.json"</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Open the class labels file for writing and write the class labels to it</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(class_labels_file_name, <span class="st">"w"</span>) <span class="im">as</span> write_file:</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    json.dump(class_labels, write_file)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Return the class labels and file name</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>class_labels, class_labels_file_name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>({'classes': ['background', 'student_id']}, 'student-id-classes.json')</code></pre>
<p>Finally, we can inspect the training records to ensure the parser works correctly.</p>
<p><strong>Inspect training records</strong></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the first element of the train_records object</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>train_records[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>BaseRecord

common: 
    - Image size [640, 480]
    - Filepath: pytorch-for-information-extraction/code/datasets/detection/student-id/10115.jpg
    - Img: None
    - Record ID: 10115
detection: 
    - Class Map: &lt;ClassMap: {'background': 0, 'student_id': 1}&gt;
    - Labels: [1, 1]
    - BBoxes: [&lt;BBox (xmin:281.57142857142856, ymin:1.428571428571428, xmax:504.42857142857133, ymax:326.4285714285714)&gt;, &lt;BBox (xmin:185.1428571428571, ymin:124.28571428571428, xmax:382.99999999999994, ymax:448.57142857142856)&gt;]
    - masks: [&lt;icevision.core.mask.MaskArray object at 0x7f521f95df10&gt;, &lt;icevision.core.mask.MaskArray object at 0x7f521f95da90&gt;]
    - mask_array: None</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Annotate the first sample of the train_records object</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>show_record(train_records[<span class="dv">0</span>], figsize <span class="op">=</span> (<span class="dv">10</span>,<span class="dv">10</span>), display_label<span class="op">=</span><span class="va">True</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_51_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Annotate the second to fourth samples of the train_records list</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>show_records(train_records[<span class="dv">1</span>:<span class="dv">4</span>], ncols<span class="op">=</span><span class="dv">3</span>,display_label<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_52_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="define-dataloader-objects" class="level2">
<h2 class="anchored" data-anchor-id="define-dataloader-objects">Define DataLoader Objects</h2>
<p>To define DataLoader objects for our task, we must first set the desired input resolution for the model.</p>
<p><strong>Define input resolution</strong></p>
<div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the image size to 512</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>image_size <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the presize to 1024</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>presize <span class="op">=</span> <span class="dv">1024</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Next, we create a list of transformations to apply to the input images, such as resizing, padding, and normalization. IceVision also applies augmentations, such as horizontal flipping, to improve model performance.</p>
<p><strong>Define Transforms</strong></p>
<div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the data transforms for the training and validation sets</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>train_tfms <span class="op">=</span> tfms.A.Adapter([<span class="op">*</span>tfms.A.aug_tfms(size<span class="op">=</span>image_size, presize<span class="op">=</span>presize), tfms.A.Normalize()])</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>valid_tfms <span class="op">=</span> tfms.A.Adapter([<span class="op">*</span>tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We then get the mean and standard deviation of the dataset used to train the original model to normalize the input images.</p>
<p><strong>Get normalization stats</strong></p>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the mean of the Normalize() transformation</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> tfms.A.Normalize().mean</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the standard deviation of the Normalize() transformation</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> tfms.A.Normalize().std</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the mean and standard deviation</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>mean, std</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))</code></pre>
<p>Next, we create dataset objects for the training and validation datasets using the defined transforms and normalization stats.</p>
<p><strong>Define Datasets</strong></p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Dataset object for the training set</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> Dataset(train_records, train_tfms)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Dataset object for the validation set</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>valid_ds <span class="op">=</span> Dataset(valid_records, valid_tfms)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Return the Dataset objects</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>train_ds, valid_ds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>(&lt;Dataset with 120 items&gt;, &lt;Dataset with 30 items&gt;)</code></pre>
<p>We can apply the image augmentations to a sample training image to demonstrate the effects of data augmentation.</p>
<p><strong>Apply augmentations to a training sample</strong></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get three samples from the training set</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> [train_ds[<span class="dv">0</span>] <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>)]</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the samples</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>show_samples(samples, ncols<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_62_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Once the datasets are defined, we can specify Mask R-CNN as the model type for training and inference.</p>
<p><strong>Define model type</strong></p>
<div class="sourceCode" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the model type to Mask R-CNN</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>model_type <span class="op">=</span> models.torchvision.mask_rcnn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define backbone</strong></p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a ResNet50-FPN backbone for the model</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>backbone <span class="op">=</span> model_type.backbones.resnet50_fpn()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define batch size</strong></p>
<div class="sourceCode" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the batch size</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>bs <span class="op">=</span> <span class="dv">4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p><strong>Note:</strong> Adjust the batch size based on the available GPU memory.</p>
</blockquote>
<p>Finally, we create DataLoader objects for the training and validation datasets using the defined batch size. We use these objects to load batches of data for training and evaluation.</p>
<p><strong>Define DataLoaders</strong></p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataLoader for the training set</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>train_dl <span class="op">=</span> model_type.train_dl(train_ds, batch_size<span class="op">=</span>bs, num_workers<span class="op">=</span><span class="dv">2</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataLoader for the validation set</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>valid_dl <span class="op">=</span> model_type.valid_dl(valid_ds, batch_size<span class="op">=</span>bs, num_workers<span class="op">=</span><span class="dv">2</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p><strong>Note:</strong> Be careful when increasing the number of workers. There is a bug that significantly increases system memory usage with more workers.</p>
</blockquote>
<div class="sourceCode" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the first mini-batch from the validation set</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>valid_batch <span class="op">=</span> first(valid_dl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Unpack the data from the first mini-batch of the validation set</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>(valid_images, valid_labels), valid_records <span class="op">=</span> valid_batch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show a mini-batch of data from the validation set</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>model_type.show_batch(first(valid_dl), ncols<span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_74_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="finetune-the-model" class="level2">
<h2 class="anchored" data-anchor-id="finetune-the-model">Finetune the Model</h2>
<p>To finetune the Mask-RCNN model, we must first instantiate the model and define metrics to track during training.</p>
<p><strong>Instantiate the model</strong></p>
<div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Mask R-CNN model</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model_type.model(backbone<span class="op">=</span>backbone, num_classes<span class="op">=</span>parser.class_map.num_classes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define metrics</strong></p>
<div class="sourceCode" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a list of metrics to evaluate the model</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [COCOMetric(metric_type<span class="op">=</span>COCOMetricType.mask)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can then create a Learner object to find the learning rate and handle the training loop.</p>
<p><strong>Define Learner object</strong></p>
<div class="sourceCode" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a fastai learner object to train and evaluate the Mask R-CNN model</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> model_type.fastai.learner(dls<span class="op">=</span>[train_dl, valid_dl], model<span class="op">=</span>model, metrics<span class="op">=</span>metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Find learning rate</strong></p>
<div class="sourceCode" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the learning rate finder to find a good learning rate for the Mask R-CNN model</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>suggested_lrs <span class="op">=</span> learn.lr_find()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_82_3.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><strong>Define learning rate</strong></p>
<div class="sourceCode" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the optimal learning rate identified by the learning rate finder</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> suggested_lrs.valley<span class="op">*</span><span class="dv">3</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>lr</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    0.00039547700725961477</code></pre>
<p><strong>Define number of epochs</strong></p>
<div class="sourceCode" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the number of epochs to train the Mask R-CNN model</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">60</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After defining the training parameters, we can finetune the model by training it on the training dataset and evaluating it on the validation dataset.</p>
<p><strong>Finetune model</strong></p>
<div class="sourceCode" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the Mask R-CNN model</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(epochs, lr, freeze_epochs<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
epoch
</th>
<th>
train_loss
</th>
<th>
valid_loss
</th>
<th>
COCOMetric
</th>
<th>
time
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
0
</td>
<td>
1.526101
</td>
<td>
1.136230
</td>
<td>
0.000000
</td>
<td>
00:05
</td>
</tr>
</tbody>

</table>
</div>
<div style="overflow-x:auto; max-height:500px">

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
epoch
</th>
<th>
train_loss
</th>
<th>
valid_loss
</th>
<th>
COCOMetric
</th>
<th>
time
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
0
</td>
<td>
1.113099
</td>
<td>
0.948657
</td>
<td>
0.000000
</td>
<td>
00:10
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0.879729
</td>
<td>
0.561887
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
2
</td>
<td>
0.661906
</td>
<td>
0.404916
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
3
</td>
<td>
0.528782
</td>
<td>
0.345191
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
4
</td>
<td>
0.464688
</td>
<td>
0.352018
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
5
</td>
<td>
0.418978
</td>
<td>
0.320372
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
6
</td>
<td>
0.376626
</td>
<td>
0.295002
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
7
</td>
<td>
0.340059
</td>
<td>
0.309611
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
8
</td>
<td>
0.316866
</td>
<td>
0.267806
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
9
</td>
<td>
0.295634
</td>
<td>
0.275406
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
10
</td>
<td>
0.282974
</td>
<td>
0.263774
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
11
</td>
<td>
0.275979
</td>
<td>
0.254877
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
12
</td>
<td>
0.266656
</td>
<td>
0.237095
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
13
</td>
<td>
0.260437
</td>
<td>
0.239515
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
14
</td>
<td>
0.245464
</td>
<td>
0.222481
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
15
</td>
<td>
0.237604
</td>
<td>
0.221115
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
16
</td>
<td>
0.233022
</td>
<td>
0.245855
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
17
</td>
<td>
0.224769
</td>
<td>
0.277205
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
18
</td>
<td>
0.214686
</td>
<td>
0.242116
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
19
</td>
<td>
0.207307
</td>
<td>
0.229408
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
20
</td>
<td>
0.202318
</td>
<td>
0.217142
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
21
</td>
<td>
0.190885
</td>
<td>
0.209915
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
22
</td>
<td>
0.190565
</td>
<td>
0.202563
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
23
</td>
<td>
0.189903
</td>
<td>
0.199876
</td>
<td>
0.000000
</td>
<td>
00:09
</td>
</tr>
<tr>
<td>
24
</td>
<td>
0.186624
</td>
<td>
0.213171
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
25
</td>
<td>
0.178527
</td>
<td>
0.207296
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
26
</td>
<td>
0.179156
</td>
<td>
0.246541
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
27
</td>
<td>
0.174455
</td>
<td>
0.186960
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
28
</td>
<td>
0.162381
</td>
<td>
0.183744
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
29
</td>
<td>
0.157665
</td>
<td>
0.181943
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
30
</td>
<td>
0.152987
</td>
<td>
0.181777
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
31
</td>
<td>
0.149362
</td>
<td>
0.163883
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
32
</td>
<td>
0.143986
</td>
<td>
0.185762
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
33
</td>
<td>
0.147537
</td>
<td>
0.170019
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
34
</td>
<td>
0.139731
</td>
<td>
0.165259
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
35
</td>
<td>
0.136252
</td>
<td>
0.166419
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
36
</td>
<td>
0.134750
</td>
<td>
0.165301
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
37
</td>
<td>
0.131968
</td>
<td>
0.157560
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
38
</td>
<td>
0.129044
</td>
<td>
0.162093
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
39
</td>
<td>
0.121755
</td>
<td>
0.159642
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
40
</td>
<td>
0.118404
</td>
<td>
0.154801
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
41
</td>
<td>
0.118744
</td>
<td>
0.157296
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
42
</td>
<td>
0.113328
</td>
<td>
0.156315
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
43
</td>
<td>
0.114840
</td>
<td>
0.153378
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
44
</td>
<td>
0.113884
</td>
<td>
0.146661
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
45
</td>
<td>
0.112758
</td>
<td>
0.162629
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
46
</td>
<td>
0.110688
</td>
<td>
0.157740
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
47
</td>
<td>
0.107804
</td>
<td>
0.156558
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
48
</td>
<td>
0.104166
</td>
<td>
0.155466
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
49
</td>
<td>
0.102735
</td>
<td>
0.159387
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
50
</td>
<td>
0.100563
</td>
<td>
0.157396
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
51
</td>
<td>
0.101158
</td>
<td>
0.151178
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
52
</td>
<td>
0.100735
</td>
<td>
0.148203
</td>
<td>
0.000000
</td>
<td>
00:08
</td>
</tr>
<tr>
<td>
53
</td>
<td>
0.098154
</td>
<td>
0.165008
</td>
<td>
0.000000
</td>
<td>
00:07
</td>
</tr>
<tr>
<td>
54
</td>
<td>
0.098391
</td>
<td>
0.163613
</td>
<td>
0.000000
</td>
<td>
00:07
</td>
</tr>
<tr>
<td>
55
</td>
<td>
0.100913
</td>
<td>
0.161389
</td>
<td>
0.000000
</td>
<td>
00:07
</td>
</tr>
<tr>
<td>
56
</td>
<td>
0.098609
</td>
<td>
0.155590
</td>
<td>
0.000000
</td>
<td>
00:07
</td>
</tr>
<tr>
<td>
57
</td>
<td>
0.098285
</td>
<td>
0.154783
</td>
<td>
0.000000
</td>
<td>
00:07
</td>
</tr>
<tr>
<td>
58
</td>
<td>
0.097906
</td>
<td>
0.156959
</td>
<td>
0.000000
</td>
<td>
00:07
</td>
</tr>
<tr>
<td>
59
</td>
<td>
0.097475
</td>
<td>
0.160197
</td>
<td>
0.000000
</td>
<td>
00:07
</td>
</tr>
</tbody>

</table>
</div>
<hr>
<p>Finally, we can display the results of the finetuned model on the validation set.</p>
<p><strong>Show results on validation set</strong></p>
<div class="sourceCode" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the results of the predictions on the validation set</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>model_type.show_results(model, valid_ds, detection_threshold<span class="op">=</span><span class="fl">.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_90_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="save-model-checkpoint" class="level2">
<h2 class="anchored" data-anchor-id="save-model-checkpoint">Save Model Checkpoint</h2>
<p>We can save the trained PyTorch model and use it to finetune the model further or perform inference using IceVision in the future.</p>
<p><strong>Define model checkpoint file path</strong></p>
<div class="sourceCode" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a path to save the trained model</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>checkpoint_path <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>data_dir<span class="sc">.</span>name<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span><span class="bu">type</span>(model)<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">.pth"</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>checkpoint_path</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'student-id-MaskRCNN.pth'</code></pre>
<p><strong>Save model checkpoint</strong></p>
<div class="sourceCode" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the trained model to the specified path</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>torch.save(model.state_dict(), checkpoint_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="perform-inference-with-checkpoint" class="level2">
<h2 class="anchored" data-anchor-id="perform-inference-with-checkpoint">Perform Inference with Checkpoint</h2>
<p>We must first load the class labels and the model checkpoint to use the saved model for inference.</p>
<p><strong>Load class labels</strong></p>
<div class="sourceCode" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Open the class labels file</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(class_labels_file_name, <span class="st">"r"</span>) <span class="im">as</span> read_file:</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the class labels from the file</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>    classes <span class="op">=</span> json.loads(read_file.read())</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the list of class labels</span></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classes[<span class="st">'classes'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>['background', 'student_id']</code></pre>
<p><strong>Load model checkpoint</strong></p>
<div class="sourceCode" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the model from the checkpoint file</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>checkpoint_and_model <span class="op">=</span> models.model_from_checkpoint(</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Path to the checkpoint file</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>    checkpoint_path, </span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Name of the model class</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    model_name<span class="op">=</span><span class="st">'torchvision.mask_rcnn'</span>, </span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Name of the backbone to use for the model</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>    backbone_name<span class="op">=</span><span class="st">'resnet50_fpn'</span>,</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Image size for the model</span></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    img_size<span class="op">=</span><span class="dv">512</span>, </span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># List of class labels for the model</span></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>    classes<span class="op">=</span>classes[<span class="st">'classes'</span>],</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Verify class map</strong></p>
<div class="sourceCode" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View the class map for the model</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>checkpoint_and_model[<span class="st">"class_map"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    &lt;ClassMap: {'background': 0, 'student_id': 1}&gt;</code></pre>
<p><strong>Get model and device</strong></p>
<div class="sourceCode" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve the trained model from the dictionary</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> checkpoint_and_model[<span class="st">"model"</span>]</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve the inference device from the dictionary</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>device<span class="op">=</span><span class="bu">next</span>(model.parameters()).device</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>device</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>device(type='cpu')</code></pre>
<p>Then, we define the inference preprocessing steps and select a test image.</p>
<p><strong>Define inference preprocessing steps</strong></p>
<div class="sourceCode" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the image size from the checkpoint dictionary</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>img_size <span class="op">=</span> checkpoint_and_model[<span class="st">"img_size"</span>]</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the validation transforms: resize and pad to match img_size, normalize</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>valid_tfms <span class="op">=</span> tfms.A.Adapter([<span class="op">*</span>tfms.A.resize_and_pad(img_size), tfms.A.Normalize()])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Select a test image</strong></p>
<div class="sourceCode" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Open the 10th file in the files list</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>test_img <span class="op">=</span> open_img(files[<span class="dv">9</span>])</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the test image</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>test_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_106_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>We create an inference DataLoader and use it to perform inference.</p>
<p><strong>Define inference dataloader</strong></p>
<div class="sourceCode" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the inference transforms: normalize</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>infer_tfms <span class="op">=</span> tfms.A.Adapter([tfms.A.Normalize()])</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an inference dataset from the test image</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>infer_ds <span class="op">=</span> Dataset.from_images([test_img], infer_tfms)</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data loader for the inference dataset</span></span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>infer_dl <span class="op">=</span> model_type.infer_dl(infer_ds, batch_size<span class="op">=</span><span class="dv">1</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Perform inference</strong></p>
<div class="sourceCode" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test image using the model</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> model_type.predict_from_dl(model, infer_dl, keep_images<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Once the inference is complete, we can inspect the source image information and the model prediction.</p>
<p><strong>Inspect source image</strong></p>
<div class="sourceCode" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Access the ground truth information for the first prediction</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>preds[<span class="dv">0</span>].ground_truth</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    BaseRecord
    
    common: 
        - Record ID: 0
        - Img: 480x640x3 &lt;np.ndarray&gt; Image
        - Image size ImgSize(width=480, height=640)
    detection: 
        - Class Map: None</code></pre>
<p><strong>Inspect model prediction</strong></p>
<div class="sourceCode" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Access the predicted information for the first prediction</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>preds[<span class="dv">0</span>].pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    BaseRecord
    
    common: 
        - Record ID: 0
        - Img: 480x640x3 &lt;np.ndarray&gt; Image
        - Image size ImgSize(width=480, height=640)
    detection: 
        - Scores: [0.9997528 0.9996158]
        - BBoxes: [&lt;BBox (xmin:34.445037841796875, ymin:300.6217041015625, xmax:468.1103210449219, ymax:625.0744018554688)&gt;, &lt;BBox (xmin:13.5184326171875, ymin:21.899276733398438, xmax:405.33990478515625, ymax:296.6339111328125)&gt;]
        - masks: []
        - mask_array: &lt;icevision.core.mask.MaskArray object at 0x7f5115cc7280&gt;
        - Class Map: None
        - Labels: [1, 1]</code></pre>
<p>Finally, we annotate the image with the model prediction.</p>
<p><strong>Annotate image with model prediction</strong></p>
<div class="sourceCode" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the predictions for the test image</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>show_preds(preds<span class="op">=</span>preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_116_0.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="inspect-raw-model-output" class="level2">
<h2 class="anchored" data-anchor-id="inspect-raw-model-output">Inspect Raw Model Output</h2>
<p>Next, we’ll inspect the raw model output to determine the required post-processing steps when using ONNX Runtime. We first define a method to convert a PIL Image to a normalized Pytorch Tensor.</p>
<p><strong>Define method to convert a PIL Image to a Pytorch Tensor</strong></p>
<div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> img_to_tensor(img:PIL.Image, mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]):</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Converts a PIL image to a PyTorch tensor.</span></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a><span class="co">        img: The input PIL image.</span></span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a><span class="co">        mean: The mean values for normalization.</span></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a><span class="co">        std: The standard deviation values for normalization.</span></span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a><span class="co">        The normalized tensor.</span></span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert image to tensor</span></span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a>    img_tensor <span class="op">=</span> torch.Tensor(np.array(img)).permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Scale pixels values from [0,255] to [0,1]</span></span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a>    scaled_tensor <span class="op">=</span> img_tensor.<span class="bu">float</span>().div_(<span class="dv">255</span>)</span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prepare normalization tensors</span></span>
<span id="cb84-18"><a href="#cb84-18" aria-hidden="true" tabindex="-1"></a>    mean_tensor <span class="op">=</span> tensor(mean).view(<span class="dv">1</span>,<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>).permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb84-19"><a href="#cb84-19" aria-hidden="true" tabindex="-1"></a>    std_tensor <span class="op">=</span> tensor(std).view(<span class="dv">1</span>,<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>).permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb84-20"><a href="#cb84-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize tensor    </span></span>
<span id="cb84-21"><a href="#cb84-21" aria-hidden="true" tabindex="-1"></a>    normalized_tensor <span class="op">=</span> (scaled_tensor <span class="op">-</span> mean_tensor) <span class="op">/</span> std_tensor</span>
<span id="cb84-22"><a href="#cb84-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Batch tensor</span></span>
<span id="cb84-23"><a href="#cb84-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> normalized_tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Convert image to a normalized tensor</strong></p>
<div class="sourceCode" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the test image to a tensor</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>input_tensor <span class="op">=</span> img_to_tensor(test_img)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the shape of the tensor</span></span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>input_tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>torch.Size([1, 3, 640, 480])</code></pre>
<p>Then, we’ll inspect the raw model output and benchmark PyTorch CPU inference to compare with ONNX Runtime.</p>
<p><strong>Inspect raw model output</strong></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test image using the model</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> model(input_tensor)</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="co"># display the predictions</span></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>preds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    [{'boxes': tensor([[ 34.4450, 300.6217, 468.1104, 625.0743],
              [ 13.5184,  21.8993, 405.3399, 296.6339]]),
      'labels': tensor([1, 1]),
      'scores': tensor([0.9998, 0.9996]),
      'masks': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
                [0., 0., 0.,  ..., 0., 0., 0.],
                [0., 0., 0.,  ..., 0., 0., 0.],
                ...,
                [0., 0., 0.,  ..., 0., 0., 0.],
                [0., 0., 0.,  ..., 0., 0., 0.],
                [0., 0., 0.,  ..., 0., 0., 0.]]],


​      
​              [[[0., 0., 0.,  ..., 0., 0., 0.],
​                [0., 0., 0.,  ..., 0., 0., 0.],
​                [0., 0., 0.,  ..., 0., 0., 0.],
​                ...,
​                [0., 0., 0.,  ..., 0., 0., 0.],
​                [0., 0., 0.,  ..., 0., 0., 0.],
​                [0., 0., 0.,  ..., 0., 0., 0.]]]])}]</code></pre>
<p>The model output stores predictions for bounding boxes, labels, confidence scores, and image masks in separate tensors.</p>
<p><strong>Benckmark PyTorch CPU inference</strong></p>
<div class="sourceCode" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>timeit</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Measure the time it takes to make predictions on the input tensor</span></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model(input_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>432 ms ± 845 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</section>
<section id="export-model-to-onnx" class="level2">
<h2 class="anchored" data-anchor-id="export-model-to-onnx">Export Model to ONNX</h2>
<p>To export the trained model to ONNX, we first need to define an ONNX file name. Then, we can use PyTorch’s built-in conversion method to export the trained model to ONNX. We can use the exported model with other applications or frameworks that support ONNX models.</p>
<p><strong>Define ONNX file name</strong></p>
<div class="sourceCode" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a filename for the ONNX model</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>onnx_file_name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span><span class="bu">type</span>(model)<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">.onnx"</span></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the filename</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>onnx_file_name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>'student-id-MaskRCNN.onnx'</code></pre>
<p><strong>Export trained model to ONNX</strong></p>
<div class="sourceCode" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Export the PyTorch model to ONNX format</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>torch.onnx.export(model,</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>                  input_tensor,</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>                  onnx_file_name,</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>                  export_params<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>                  opset_version<span class="op">=</span><span class="dv">12</span>,</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>                  do_constant_folding<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>                  input_names <span class="op">=</span> [<span class="st">'input'</span>],</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>                  output_names <span class="op">=</span> [<span class="st">'boxes'</span>, <span class="st">'labels'</span>, <span class="st">'scores'</span>, <span class="st">'masks'</span>],</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>                  dynamic_axes<span class="op">=</span>{<span class="st">'input'</span>: {<span class="dv">2</span> : <span class="st">'height'</span>, <span class="dv">3</span> : <span class="st">'width'</span>}}</span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>                 )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="verify-onnx-inference" class="level2">
<h2 class="anchored" data-anchor-id="verify-onnx-inference">Verify ONNX Inference</h2>
<p>To verify ONNX inference, we first need to import ONNX Runtime.</p>
<p><strong>Import ONNX Runtime</strong></p>
<div class="sourceCode" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the onnxruntime library</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> onnxruntime <span class="im">as</span> ort</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then, we can get the available ONNX Runtime <a href="https://onnxruntime.ai/docs/execution-providers/">execution providers</a> and select one to use. We did not install any additional execution providers, so only the default CPU provider is available.</p>
<p><strong>Get available ONNX Runtime execution providers</strong></p>
<div class="sourceCode" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the list of available providers for onnxruntime</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>available_providers <span class="op">=</span> ort.get_available_providers()</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the available providers</span></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>available_providers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>['CPUExecutionProvider']</code></pre>
<p><strong>Select execution provider</strong></p>
<div class="sourceCode" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the first available provider for onnxruntime</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>providers <span class="op">=</span> [available_providers[<span class="dv">0</span>]]</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the selected provider</span></span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>providers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>['CPUExecutionProvider']</code></pre>
<p>We initialize an inference session with the selected execution provider and perform inference using the ONNX model.</p>
<p><strong>Initialize inference session with selected execution provider</strong></p>
<div class="sourceCode" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an inference session for the ONNX model</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>ort_sess <span class="op">=</span> ort.InferenceSession(onnx_file_name, providers<span class="op">=</span>providers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Perform inference using ONNX model</strong></p>
<div class="sourceCode" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the input tensor using the ONNX model</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> ort_sess.run(output_names<span class="op">=</span><span class="va">None</span>, input_feed<span class="op">=</span>{<span class="st">"input"</span>:input_tensor.numpy()})</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the predictions</span></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>outputs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    [array([[ 34.445053, 300.62167 , 468.11035 , 625.07434 ],
            [ 13.518433,  21.899261, 405.33997 , 296.6339  ]], dtype=float32),
     array([1, 1], dtype=int64),
     array([0.9997528, 0.9996158], dtype=float32),
     array([[[[0., 0., 0., ..., 0., 0., 0.],
              [0., 0., 0., ..., 0., 0., 0.],
              [0., 0., 0., ..., 0., 0., 0.],
              ...,
              [0., 0., 0., ..., 0., 0., 0.],
              [0., 0., 0., ..., 0., 0., 0.],
              [0., 0., 0., ..., 0., 0., 0.]]],


​     
​            [[[0., 0., 0., ..., 0., 0., 0.],
​              [0., 0., 0., ..., 0., 0., 0.],
​              [0., 0., 0., ..., 0., 0., 0.],
​              ...,
​              [0., 0., 0., ..., 0., 0., 0.],
​              [0., 0., 0., ..., 0., 0., 0.],
​              [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)]</code></pre>
<p>Finally, we benchmark the ONNX Runtime CPU inference speed to measure its performance.</p>
<p><strong>Benchmark ONNX Runtime CPU inference speed</strong></p>
<div class="sourceCode" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>timeit</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Measure the time it takes to make predictions on the input tensor</span></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>ort_sess.run(<span class="va">None</span>, {<span class="st">'input'</span>: input_tensor.numpy()})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>320 ms ± 1.25 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</section>
<section id="define-post-processing-steps" class="level2">
<h2 class="anchored" data-anchor-id="define-post-processing-steps">Define Post-processing Steps</h2>
<p>The Mask R-CNN model includes the object detection post-processing steps internally. However, there are a few extra steps to annotate the input image with the model predictions.</p>
<p>The predicted image masks have values in the range [0,1], representing shades of gray from black to white. To use them to annotate the input image, we need to binarize the masks by applying a threshold value to convert them to either 0 or 1.</p>
<p>We can convert the binarized masks to RGBA images, which allows us to paste them on top of the input image to show the predicted object locations and segmentations. That provides a visual representation of the model’s predictions.</p>
<p><strong>Define annotation values</strong></p>
<div class="sourceCode" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the mask threshold</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>mask_threshold <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the mask color</span></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>mask_rgba <span class="op">=</span> [<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">100</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Annotate sample image</strong></p>
<div class="sourceCode" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a copy of the test image</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>annotated_img <span class="op">=</span> test_img.copy()</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the image to RGBA format</span></span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>annotated_img.convert(<span class="st">'RGBA'</span>)</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a drawing context for the image</span></span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>draw <span class="op">=</span> ImageDraw.Draw(annotated_img)</span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the font size for the labels</span></span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>fnt_size <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through annotations for sample image</span></span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(outputs[<span class="dv">0</span>])):</span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb105-16"><a href="#cb105-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract mask array</span></span>
<span id="cb105-17"><a href="#cb105-17" aria-hidden="true" tabindex="-1"></a>    mask_array <span class="op">=</span> outputs[<span class="op">-</span><span class="dv">1</span>][i][<span class="dv">0</span>]</span>
<span id="cb105-18"><a href="#cb105-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Binarize mask values</span></span>
<span id="cb105-19"><a href="#cb105-19" aria-hidden="true" tabindex="-1"></a>    mask_array[mask_array <span class="op">&gt;</span> mask_threshold] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb105-20"><a href="#cb105-20" aria-hidden="true" tabindex="-1"></a>    mask_array[mask_array <span class="op">&lt;=</span> mask_threshold] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb105-21"><a href="#cb105-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Scale mask values</span></span>
<span id="cb105-22"><a href="#cb105-22" aria-hidden="true" tabindex="-1"></a>    mask_array <span class="op">*=</span> <span class="dv">255</span></span>
<span id="cb105-23"><a href="#cb105-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert mask from 1-channel to 4-channel</span></span>
<span id="cb105-24"><a href="#cb105-24" aria-hidden="true" tabindex="-1"></a>    mask_array <span class="op">=</span> np.tile(mask_array[:, :, <span class="va">None</span>], [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">4</span>])</span>
<span id="cb105-25"><a href="#cb105-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update mask color</span></span>
<span id="cb105-26"><a href="#cb105-26" aria-hidden="true" tabindex="-1"></a>    mask_array[:,:,<span class="dv">0</span>][mask_array[:,:,<span class="dv">0</span>] <span class="op">==</span> <span class="dv">255</span>] <span class="op">=</span> mask_rgba[<span class="dv">0</span>]</span>
<span id="cb105-27"><a href="#cb105-27" aria-hidden="true" tabindex="-1"></a>    mask_array[:,:,<span class="dv">1</span>][mask_array[:,:,<span class="dv">1</span>] <span class="op">==</span> <span class="dv">255</span>] <span class="op">=</span> mask_rgba[<span class="dv">1</span>]</span>
<span id="cb105-28"><a href="#cb105-28" aria-hidden="true" tabindex="-1"></a>    mask_array[:,:,<span class="dv">2</span>][mask_array[:,:,<span class="dv">2</span>] <span class="op">==</span> <span class="dv">255</span>] <span class="op">=</span> mask_rgba[<span class="dv">2</span>]</span>
<span id="cb105-29"><a href="#cb105-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update mask transparency</span></span>
<span id="cb105-30"><a href="#cb105-30" aria-hidden="true" tabindex="-1"></a>    mask_array[:,:,<span class="dv">3</span>][mask_array[:,:,<span class="dv">0</span>] <span class="op">==</span> <span class="dv">255</span>] <span class="op">=</span> mask_rgba[<span class="dv">3</span>]</span>
<span id="cb105-31"><a href="#cb105-31" aria-hidden="true" tabindex="-1"></a>    mask_array[:,:,<span class="dv">3</span>][mask_array[:,:,<span class="dv">1</span>] <span class="op">==</span> <span class="dv">255</span>] <span class="op">=</span> mask_rgba[<span class="dv">3</span>]</span>
<span id="cb105-32"><a href="#cb105-32" aria-hidden="true" tabindex="-1"></a>    mask_array[:,:,<span class="dv">3</span>][mask_array[:,:,<span class="dv">2</span>] <span class="op">==</span> <span class="dv">255</span>] <span class="op">=</span> mask_rgba[<span class="dv">3</span>]</span>
<span id="cb105-33"><a href="#cb105-33" aria-hidden="true" tabindex="-1"></a>    mask_array[:,:,<span class="dv">3</span>][mask_array[:,:,<span class="dv">0</span>] <span class="op">!=</span> <span class="dv">255</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb105-34"><a href="#cb105-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert mask array to PIL image</span></span>
<span id="cb105-35"><a href="#cb105-35" aria-hidden="true" tabindex="-1"></a>    mask_img <span class="op">=</span> PIL.Image.fromarray(mask_array.astype(np.uint8)).convert(<span class="st">'RGBA'</span>)</span>
<span id="cb105-36"><a href="#cb105-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb105-37"><a href="#cb105-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw segmentation mask on sample image</span></span>
<span id="cb105-38"><a href="#cb105-38" aria-hidden="true" tabindex="-1"></a>    annotated_img.paste(mask_img, (<span class="dv">0</span>,<span class="dv">0</span>), mask<span class="op">=</span>mask_img)</span>
<span id="cb105-39"><a href="#cb105-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb105-40"><a href="#cb105-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw bounding box on sample image</span></span>
<span id="cb105-41"><a href="#cb105-41" aria-hidden="true" tabindex="-1"></a>    shape <span class="op">=</span> <span class="bu">list</span>(outputs[<span class="dv">0</span>][i])</span>
<span id="cb105-42"><a href="#cb105-42" aria-hidden="true" tabindex="-1"></a>    draw.rectangle(shape, outline<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb105-43"><a href="#cb105-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb105-44"><a href="#cb105-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw object label on sample image</span></span>
<span id="cb105-45"><a href="#cb105-45" aria-hidden="true" tabindex="-1"></a>    fnt <span class="op">=</span> PIL.ImageFont.truetype(font_file, fnt_size)</span>
<span id="cb105-46"><a href="#cb105-46" aria-hidden="true" tabindex="-1"></a>    label <span class="op">=</span> class_map.get_classes()[outputs[<span class="dv">1</span>][i]]</span>
<span id="cb105-47"><a href="#cb105-47" aria-hidden="true" tabindex="-1"></a>    draw.multiline_text((shape[<span class="dv">0</span>], shape[<span class="dv">1</span>]<span class="op">-</span>fnt_size<span class="op">-</span><span class="dv">5</span>), <span class="ss">f"</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">"</span>, font<span class="op">=</span>fnt, fill<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb105-48"><a href="#cb105-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb105-49"><a href="#cb105-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the size of the annotated image</span></span>
<span id="cb105-50"><a href="#cb105-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(annotated_img.size)</span>
<span id="cb105-51"><a href="#cb105-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-52"><a href="#cb105-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the annotated image</span></span>
<span id="cb105-53"><a href="#cb105-53" aria-hidden="true" tabindex="-1"></a>annotated_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>(480, 640)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_144_1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>This tutorial demonstrated how to train a Mask R-CNN model on a custom dataset using the IceVision library. We showed how to create a custom dataset parser, train the model, and evaluate its performance. Additionally, we explained how to export the trained model to the ONNX format and perform inference using ONNX Runtime. You can follow the steps outlined in this tutorial to train a Mask R-CNN model on your custom dataset and use it for multiple applications.</p>
<p><strong>Project Resources:</strong> <a href="https://github.com/cj-mills/icevision-mask-rcnn-tutorial">GitHub Repository</a></p>


</section>

</main> <!-- /main -->
<!-- Cloudflare Web Analytics --><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;56b8d2f624604c4891327b3c0d9f6703&quot;}"></script><!-- End Cloudflare Web Analytics -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="cj-mills/christianjmills" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2023, Christian J. Mills
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>