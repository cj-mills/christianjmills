<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Christian Mills">
<meta name="dcterms.date" content="2023-06-02">
<meta name="description" content="This tutorial provides a step-by-step guide to setting up Intel’s PyTorch extension on Ubuntu to train models with Arc GPUs.">

<title>Christian Mills - Getting Started with Intel’s PyTorch Extension for Arc GPUs on Ubuntu</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Christian Mills - Getting Started with Intel’s PyTorch Extension for Arc GPUs on Ubuntu">
<meta property="og:description" content="This tutorial provides a step-by-step guide to setting up Intel’s PyTorch extension on Ubuntu to train models with Arc GPUs.">
<meta property="og:image" content="christianjmills.com/posts/intel-pytorch-extension-tutorial/social-media/cover.jpg">
<meta property="og:site-name" content="Christian Mills">
<meta name="twitter:title" content="Christian Mills - Getting Started with Intel’s PyTorch Extension for Arc GPUs on Ubuntu">
<meta name="twitter:description" content="This tutorial provides a step-by-step guide to setting up Intel’s PyTorch extension on Ubuntu to train models with Arc GPUs.">
<meta name="twitter:image" content="christianjmills.com/posts/intel-pytorch-extension-tutorial/social-media/cover.jpg">
<meta name="twitter:creator" content="@cdotjdotmills">
<meta name="twitter:site" content="@cdotjdotmills">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Christian Mills</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/tutorials/index.html" rel="" target="">
 <span class="menu-text">Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/notes/index.html" rel="" target="">
 <span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../services.html" rel="" target="">
 <span class="menu-text">Services</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:christian@christianjmills.com" rel="" target=""><i class="bi bi-envelope-fill" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cj-mills" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/cdotjdotmills" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../blog.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#enable-resizable-bar-in-bios" id="toc-enable-resizable-bar-in-bios" class="nav-link" data-scroll-target="#enable-resizable-bar-in-bios">Enable Resizable BAR in BIOS</a></li>
  <li><a href="#install-ubuntu" id="toc-install-ubuntu" class="nav-link" data-scroll-target="#install-ubuntu">Install Ubuntu</a></li>
  <li><a href="#update-the-linux-kernel" id="toc-update-the-linux-kernel" class="nav-link" data-scroll-target="#update-the-linux-kernel">Update the Linux Kernel</a>
  <ul>
  <li><a href="#install-the-tool" id="toc-install-the-tool" class="nav-link" data-scroll-target="#install-the-tool">Install the tool</a></li>
  <li><a href="#install-kernel-6.2-or-newer" id="toc-install-kernel-6.2-or-newer" class="nav-link" data-scroll-target="#install-kernel-6.2-or-newer">Install Kernel 6.2 or newer</a></li>
  </ul></li>
  <li><a href="#verify-resizable-bar" id="toc-verify-resizable-bar" class="nav-link" data-scroll-target="#verify-resizable-bar">Verify Resizable BAR</a></li>
  <li><a href="#install-drivers" id="toc-install-drivers" class="nav-link" data-scroll-target="#install-drivers">Install Drivers</a>
  <ul>
  <li><a href="#add-intel-graphics-drivers-repository" id="toc-add-intel-graphics-drivers-repository" class="nav-link" data-scroll-target="#add-intel-graphics-drivers-repository">Add Intel Graphics drivers Repository</a></li>
  <li><a href="#install-packages" id="toc-install-packages" class="nav-link" data-scroll-target="#install-packages">Install packages</a></li>
  <li><a href="#verify-the-installations" id="toc-verify-the-installations" class="nav-link" data-scroll-target="#verify-the-installations">Verify the Installations</a>
  <ul class="collapse">
  <li><a href="#verify-the-device-is-working-with-the-i915-driver" id="toc-verify-the-device-is-working-with-the-i915-driver" class="nav-link" data-scroll-target="#verify-the-device-is-working-with-the-i915-driver">Verify the device is working with the <code>i915</code> driver</a></li>
  <li><a href="#verify-media-drivers-installation" id="toc-verify-media-drivers-installation" class="nav-link" data-scroll-target="#verify-media-drivers-installation">Verify Media drivers installation</a></li>
  <li><a href="#verify-computing-drivers-installation" id="toc-verify-computing-drivers-installation" class="nav-link" data-scroll-target="#verify-computing-drivers-installation">Verify Computing drivers installation</a></li>
  <li><a href="#verify-3d-drivers-installation" id="toc-verify-3d-drivers-installation" class="nav-link" data-scroll-target="#verify-3d-drivers-installation">Verify 3D drivers installation</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#install-oneapi-base-toolkit" id="toc-install-oneapi-base-toolkit" class="nav-link" data-scroll-target="#install-oneapi-base-toolkit">Install oneAPI Base Toolkit</a></li>
  <li><a href="#update-the-bash-run-commands-file" id="toc-update-the-bash-run-commands-file" class="nav-link" data-scroll-target="#update-the-bash-run-commands-file">Update the Bash Run Commands File</a></li>
  <li><a href="#apply-oneapi-patch" id="toc-apply-oneapi-patch" class="nav-link" data-scroll-target="#apply-oneapi-patch">Apply OneAPI Patch</a></li>
  <li><a href="#set-up-a-python-environment" id="toc-set-up-a-python-environment" class="nav-link" data-scroll-target="#set-up-a-python-environment">Set Up a Python Environment</a>
  <ul>
  <li><a href="#install-mamba-package-manager" id="toc-install-mamba-package-manager" class="nav-link" data-scroll-target="#install-mamba-package-manager">Install Mamba Package Manager</a></li>
  <li><a href="#create-a-python-environment" id="toc-create-a-python-environment" class="nav-link" data-scroll-target="#create-a-python-environment">Create a Python Environment</a></li>
  <li><a href="#install-pytorch-and-intels-pytorch-extension" id="toc-install-pytorch-and-intels-pytorch-extension" class="nav-link" data-scroll-target="#install-pytorch-and-intels-pytorch-extension">Install PyTorch and Intel’s PyTorch extension</a></li>
  <li><a href="#install-additional-depenencies" id="toc-install-additional-depenencies" class="nav-link" data-scroll-target="#install-additional-depenencies">Install additional depenencies</a></li>
  </ul></li>
  <li><a href="#modify-pytorch-code" id="toc-modify-pytorch-code" class="nav-link" data-scroll-target="#modify-pytorch-code">Modify PyTorch Code</a>
  <ul>
  <li><a href="#import-pytorch-extension" id="toc-import-pytorch-extension" class="nav-link" data-scroll-target="#import-pytorch-extension">Import PyTorch Extension</a></li>
  <li><a href="#update-pytorch-imports" id="toc-update-pytorch-imports" class="nav-link" data-scroll-target="#update-pytorch-imports">Update PyTorch Imports</a></li>
  <li><a href="#verify-arc-gpu-availability" id="toc-verify-arc-gpu-availability" class="nav-link" data-scroll-target="#verify-arc-gpu-availability">Verify Arc GPU Availability</a></li>
  <li><a href="#update-the-device-name" id="toc-update-the-device-name" class="nav-link" data-scroll-target="#update-the-device-name">Update the Device Name</a></li>
  <li><a href="#update-the-autocast-context-manager" id="toc-update-the-autocast-context-manager" class="nav-link" data-scroll-target="#update-the-autocast-context-manager">Update the <code>autocast()</code> context manager</a></li>
  <li><a href="#optimize-the-model-and-optimizer-objects" id="toc-optimize-the-model-and-optimizer-objects" class="nav-link" data-scroll-target="#optimize-the-model-and-optimizer-objects">Optimize the <code>model</code> and <code>optimizer</code> Objects</a></li>
  <li><a href="#train-the-model" id="toc-train-the-model" class="nav-link" data-scroll-target="#train-the-model">Train the Model</a></li>
  <li><a href="#update-the-inference-code" id="toc-update-the-inference-code" class="nav-link" data-scroll-target="#update-the-inference-code">Update the Inference Code</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Getting Started with Intel’s PyTorch Extension for Arc GPUs on Ubuntu</h1>
  <div class="quarto-categories">
    <div class="quarto-category">pytorch</div>
    <div class="quarto-category">ubuntu</div>
    <div class="quarto-category">image-classification</div>
  </div>
  </div>

<div>
  <div class="description">
    This tutorial provides a step-by-step guide to setting up Intel’s PyTorch extension on Ubuntu to train models with Arc GPUs.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Christian Mills </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 2, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#enable-resizable-bar-in-bios">Enable Resizable BAR in BIOS</a></li>
<li><a href="#install-ubuntu">Install Ubuntu</a></li>
<li><a href="#update-the-linux-kernel">Update the Linux Kernel</a></li>
<li><a href="#verify-resizable-bar">Verify Resizable BAR</a></li>
<li><a href="#install-drivers">Install Drivers</a></li>
<li><a href="#install-oneapi-base-toolkit">Install oneAPI Base Toolkit</a></li>
<li><a href="#update-the-bash-run-commands-file">Update the Bash Run Commands File</a></li>
<li><a href="#apply-oneapi-patch">Apply OneAPI Patch</a></li>
<li><a href="#set-up-a-python-environment">Set Up a Python Environment</a></li>
<li><a href="#modify-pytorch-code">Modify PyTorch Code</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In this tutorial, I’ll guide you through setting up Intel’s <a href="https://github.com/intel/intel-extension-for-pytorch">PyTorch extension</a> on <a href="https://ubuntu.com/download/desktop">Ubuntu</a> to train models with their <a href="https://www.intel.com/content/www/us/en/products/docs/discrete-gpus/arc/desktop/a-series/overview.html">Arc GPUs</a>. The extension provides Intel’s latest feature optimizations and hardware support before they get added to PyTorch. Most importantly for our case, it now includes <code>experimental</code> support for Intel’s Arc GPUs and optimizations to take advantage of their Xe Matrix Extensions (XMX).</p>
<p>The XMX engines are dedicated hardware for performing matrix operations like those in deep-learning workloads. Intel’s PyTorch extension allows us to leverage this hardware with minimal changes to existing PyTorch code.</p>
<p>To illustrate this, we’ll adapt the training code from my <a href="https://christianjmills.com/posts/pytorch-train-image-classifier-timm-hf-tutorial/">beginner-level PyTorch tutorial</a>, where we fine-tune an image classification model from the <a href="https://github.com/huggingface/pytorch-image-models">timm library</a> for hand gesture recognition. By the end of this tutorial, you’ll know all steps required to set up Ubuntu for training PyTorch models using Arc GPUs.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The current setup process is for version <a href="https://intel.github.io/intel-extension-for-pytorch/xpu/1.13.120+xpu/"><code>1.13.120+xpu</code></a> of Intel’s PyTorch extension.</p>
</div>
</div>
</section>
<section id="enable-resizable-bar-in-bios" class="level2">
<h2 class="anchored" data-anchor-id="enable-resizable-bar-in-bios">Enable Resizable BAR in BIOS</h2>
<p>If you have an Arc GPU, one of the first things you should do is enable Resizable BAR. Resizable BAR allows a computer’s processor to access the graphics card’s entire memory instead of in small chunks. The Arc GPUs currently require this feature to perform as intended. You can enable the feature in your motherboard’s BIOS.</p>
<p>Here are links on how to do this for some of the popular motherboard manufacturers:</p>
<ul>
<li><a href="https://www.asrock.com/support/faq.asp?id=498">ASRock</a></li>
<li><a href="https://www.asus.com/support/FAQ/1046107/">Asus</a></li>
<li><a href="https://www.evga.com/support/faq/FAQdetails.aspx?faqid=59772">EVGA</a></li>
<li><a href="https://www.gigabyte.com/WebPage/785/NVIDIA_resizable_bar.html">Gigabyte</a></li>
<li><a href="https://www.msi.com/blog/unlock-system-performance-to-extreme-resizable-bar">MSI</a></li>
</ul>
</section>
<section id="install-ubuntu" class="level2">
<h2 class="anchored" data-anchor-id="install-ubuntu">Install Ubuntu</h2>
<p>Intel’s <a href="https://dgpu-docs.intel.com/driver/client/overview.html#client-install-options">documentation</a> recommends <a href="https://discourse.ubuntu.com/t/jammy-jellyfish-release-notes/24668">Ubuntu 22.04 LTS</a> or <a href="https://discourse.ubuntu.com/t/lunar-lobster-release-notes/31910">Ubuntu 23.04</a> (or newer). If possible, go with Ubuntu 23.04 (or newer). That version comes with a more recent Linux kernel that supports the Arc GPUs out of the box.</p>
<ul>
<li><a href="https://ubuntu.com/download/desktop">Ubuntu Desktop Download Page</a></li>
</ul>
<p>The Ubuntu website provides <a href="https://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview">a step-by-step guide</a> to installing Ubuntu on your PC, and you can install it alongside an existing operating system.</p>
<ul>
<li><a href="https://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview">Install Ubuntu with a Bootable USB Stick</a></li>
</ul>
<p>That tutorial calls for at least 25GB of free storage space, but I recommend at least 80 GB for our case. The <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html#gs.ztyvfm">oneAPI Base Toolkit</a> used by Intel’s PyTorch extension alone takes up approximately 15GB. Additional packages, applications, models, and datasets can quickly fill space.</p>
<p>If you already have Ubuntu 22.04 LTS installed and want to stick with it, follow the instructions in the “Update the Linux Kernel” section to update the kernel to 6.2 or newer to use the Arc GPU. Wait until you update the kernel before switching to the Arc GPU.</p>
</section>
<section id="update-the-linux-kernel" class="level2">
<h2 class="anchored" data-anchor-id="update-the-linux-kernel">Update the Linux Kernel</h2>
<p>You can skip this section if you are on Ubuntu 23.04 or newer. Those versions will already have a supported kernel. Those running Ubuntu 22.04 LTS can update the kernel using the <a href="https://github.com/bkw777/mainline">Ubuntu Mainline Installer</a> tool.</p>
<p>Generally, you should not install a mainline kernel on an Ubuntu <a href="https://ubuntu.com/blog/what-is-an-ubuntu-lts-release">LTS</a> release.</p>
<section id="install-the-tool" class="level3">
<h3 class="anchored" data-anchor-id="install-the-tool">Install the tool</h3>
<p>Open a terminal (<code>Ctrl+Alt+T</code>) and run the following commands to add the PPA (<a href="https://launchpad.net/ubuntu/+ppas">Personal Package Archive</a>) and install the Mainline tool:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> add-apt-repository ppa:cappelikan/ppa</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt update</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install <span class="at">-y</span> mainline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="install-kernel-6.2-or-newer" class="level3">
<h3 class="anchored" data-anchor-id="install-kernel-6.2-or-newer">Install Kernel 6.2 or newer</h3>
<p>Press the Super key (i.e., Windows Key or Command Key) to enter the <a href="https://help.ubuntu.com/stable/ubuntu-help/shell-introduction.html.en#activities">Activities</a> overview. Type <code>Mainline</code> into the search bar and press <code>Enter</code> to launch the application. Select the latest 6.2 version (or newer) on the list and click the <code>Install</code> button.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/ubuntu-mainline-kernel-installer-install-6.2-kernel.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Once the installation completes, shut down the computer and switch to the Arc GPU. You can then restart the computer and log back into Ubuntu.</p>
</section>
</section>
<section id="verify-resizable-bar" class="level2">
<h2 class="anchored" data-anchor-id="verify-resizable-bar">Verify Resizable BAR</h2>
<p>Once you log into Ubuntu, you can verify Resizable BAR is active by opening a terminal (<code>Ctrl+Alt+T</code>) and running the following command:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lspci</span> <span class="at">-v</span> <span class="kw">|</span><span class="fu">grep</span> <span class="at">-A8</span> VGA</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here is the output for the Arc A770 16GB card:</p>
<pre class="text"><code>$ lspci -v |grep -A8 VGA
00:02.0 VGA compatible controller: Intel Corporation RocketLake-S GT1 [UHD Graphics 750] (rev 04) (prog-if 00 [VGA controller])
    Subsystem: ASRock Incorporation RocketLake-S GT1 [UHD Graphics 750]
    Flags: bus master, fast devsel, latency 0, IRQ 172
    Memory at 6401000000 (64-bit, non-prefetchable) [size=16M]
    Memory at 4000000000 (64-bit, prefetchable) [size=256M]
    I/O ports at 3000 [size=64]
    Expansion ROM at 000c0000 [virtual] [disabled] [size=128K]
    Capabilities: &lt;access denied&gt;
    Kernel driver in use: i915
--
03:00.0 VGA compatible controller: Intel Corporation DG2 [Arc A770] (rev 08) (prog-if 00 [VGA controller])
    Subsystem: Intel Corporation DG2 [Arc A770]
    Flags: bus master, fast devsel, latency 0, IRQ 173
    Memory at a1000000 (64-bit, non-prefetchable) [size=16M]
    Memory at 6000000000 (64-bit, prefetchable) [size=16G]
    Expansion ROM at a2000000 [disabled] [size=2M]
    Capabilities: &lt;access denied&gt;
    Kernel driver in use: i915
    Kernel modules: i915</code></pre>
<hr>
<p>Note that the <code>[size=16GB]</code> matches the total memory for the GPU. If you have the A750 8GB variant, it should read <code>[size=8GB]</code> for your GPU.</p>
</section>
<section id="install-drivers" class="level2">
<h2 class="anchored" data-anchor-id="install-drivers">Install Drivers</h2>
<p>Next, we will install the compute, media, and display runtimes.</p>
<section id="add-intel-graphics-drivers-repository" class="level3">
<h3 class="anchored" data-anchor-id="add-intel-graphics-drivers-repository">Add Intel Graphics drivers Repository</h3>
<p>Run the following bash commands to add the Intel Graphics drivers repository:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> <span class="at">-v</span> <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> <span class="at">-qO</span> <span class="at">-</span> https://repositories.intel.com/graphics/intel-graphics.key <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sudo</span> gpg <span class="at">--dearmor</span> <span class="at">--output</span> /usr/share/keyrings/intel-graphics.gpg <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"deb [arch=amd64,i386 signed-by=/usr/share/keyrings/intel-graphics.gpg] https://repositories.intel.com/graphics/ubuntu jammy arc"</span> <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sudo</span> tee /etc/apt/sources.list.d/intel-gpu-jammy.list <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt-get update</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The above bash commands perform the following steps:</p>
<ol type="1">
<li>Refresh sudo access to avoid multiple password prompts.</li>
<li>Download the Intel graphics repository’s public key.</li>
<li>Convert the downloaded key to binary and save it.</li>
<li>Add the Intel graphics repository to the APT’s list of package sources.</li>
<li>Update the package list from all configured repositories, including the newly added Intel repository.</li>
</ol>
</section>
<section id="install-packages" class="level3">
<h3 class="anchored" data-anchor-id="install-packages">Install packages</h3>
<p>Now we can install the required packages.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt-get install <span class="at">-y</span> <span class="dt">\</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  intel-opencl-icd intel-level-zero-gpu level-zero <span class="dt">\</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  intel-media-va-driver-non-free libmfx1 libmfxgen1 libvpl2 <span class="dt">\</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  libegl-mesa0 libegl1-mesa libegl1-mesa-dev libgbm1 libgl1-mesa-dev libgl1-mesa-dri <span class="dt">\</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  libglapi-mesa libgles2-mesa-dev libglx-mesa0 libigdgmm12 libxatracker2 mesa-va-drivers <span class="dt">\</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  mesa-vdpau-drivers mesa-vulkan-drivers va-driver-all vainfo hwinfo clinfo mesa-utils</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="verify-the-installations" class="level3">
<h3 class="anchored" data-anchor-id="verify-the-installations">Verify the Installations</h3>
<p>We can verify everything is installed correctly by running the following commands.</p>
<section id="verify-the-device-is-working-with-the-i915-driver" class="level4">
<h4 class="anchored" data-anchor-id="verify-the-device-is-working-with-the-i915-driver">Verify the device is working with the <code>i915</code> driver</h4>
<p>Run the following command to confirm the device is using Intel’s graphics driver:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hwinfo</span> <span class="at">--display</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here is the expected output for the A770:</p>
<pre class="text"><code>$ hwinfo --display
06: PCI 300.0: 0300 VGA compatible controller (VGA)             
  [Created at pci.386]
  Unique ID: svHJ.nDfmnmUHKH4
  Parent ID: GA8e.mr2N3fBJq5F
  SysFS ID: /devices/pci0000:00/0000:00:01.0/0000:01:00.0/0000:02:01.0/0000:03:00.0
  SysFS BusID: 0000:03:00.0
  Hardware Class: graphics card
  Model: "Intel VGA compatible controller"
  Vendor: pci 0x8086 "Intel Corporation"
  Device: pci 0x56a0 
  SubVendor: pci 0x8086 "Intel Corporation"
  SubDevice: pci 0x1020 
  Revision: 0x08
  Driver: "i915"
  Driver Modules: "i915"
  Memory Range: 0xa1000000-0xa1ffffff (rw,non-prefetchable)
  Memory Range: 0x6000000000-0x63ffffffff (ro,non-prefetchable)
  Memory Range: 0xa2000000-0xa21fffff (ro,non-prefetchable,disabled)
  IRQ: 173 (701506 events)
  Module Alias: "pci:v00008086d000056A0sv00008086sd00001020bc03sc00i00"
  Driver Info #0:
    Driver Status: i915 is active
    Driver Activation Cmd: "modprobe i915"
  Config Status: cfg=new, avail=yes, need=no, active=unknown
  Attached to: #25 (PCI bridge)</code></pre>
<hr>
</section>
<section id="verify-media-drivers-installation" class="level4">
<h4 class="anchored" data-anchor-id="verify-media-drivers-installation">Verify Media drivers installation</h4>
<p>Run the following commands to verify the media drivers installation:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">DISPLAY</span><span class="op">=</span>:0.0<span class="kw">;</span> <span class="ex">vainfo</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here is a snippet of the expected output for the A770:</p>
<pre class="text"><code>$ export DISPLAY=:0.0; vainfo
Trying display: wayland
libva info: VA-API version 1.18.0
libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/iHD_drv_video.so
libva info: Found init function __vaDriverInit_1_18
libva info: va_openDriver() returns 0
vainfo: VA-API version: 1.18 (libva 2.17.0)
vainfo: Driver version: Intel iHD driver for Intel(R) Gen Graphics - 23.1.4 (12e141d)
vainfo: Supported profile and entrypoints
      VAProfileNone                   : VAEntrypointVideoProc
      VAProfileNone                   : VAEntrypointStats
...</code></pre>
<hr>
</section>
<section id="verify-computing-drivers-installation" class="level4">
<h4 class="anchored" data-anchor-id="verify-computing-drivers-installation">Verify Computing drivers installation</h4>
<p>Run the following command to get a list of available OpenCL platforms and devices:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="ex">clinfo</span> <span class="at">-l</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The Arc GPU should show as one of the available devices. On my computer, the Arc GPU is device 0 for platform 2:</p>
<pre class="text"><code>$ clinfo -l
Platform #0: Intel(R) FPGA Emulation Platform for OpenCL(TM)
 `-- Device #0: Intel(R) FPGA Emulation Device
Platform #1: Intel(R) OpenCL
 `-- Device #0: 11th Gen Intel(R) Core(TM) i7-11700K @ 3.60GHz
Platform #2: Intel(R) OpenCL HD Graphics
 `-- Device #0: Intel(R) Arc(TM) A770 Graphics
Platform #3: Intel(R) OpenCL HD Graphics
 `-- Device #0: Intel(R) UHD Graphics 750</code></pre>
<hr>
<p>We can run the following command to get the properties for that device:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ex">clinfo</span> <span class="at">-d</span> 2:0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The command will output a lot of information. Here is the top section of the output for the A770:</p>
<pre class="text"><code>$ clinfo -d 2:0
  Platform Name                                   Intel(R) OpenCL HD Graphics
  Device Name                                     Intel(R) Arc(TM) A770 Graphics
  Device Vendor                                   Intel(R) Corporation
  Device Vendor ID                                0x8086
  Device Version                                  OpenCL 3.0 NEO 
  Device UUID                                     8680a056-0800-0000-0300-000000000000
  Driver UUID                                     32332e30-352e-3235-3539-332e31380000
  Valid Device LUID                               No
  Device LUID                                     400f-ca04fd7f0000
  Device Node Mask                                0
  Device Numeric Version                          0xc00000 (3.0.0)
  Driver Version                                  23.05.25593.18
  Device OpenCL C Version                         OpenCL C 1.2 
  Device OpenCL C all versions                    OpenCL C                                 
...</code></pre>
<hr>
</section>
<section id="verify-3d-drivers-installation" class="level4">
<h4 class="anchored" data-anchor-id="verify-3d-drivers-installation">Verify 3D drivers installation</h4>
<p>Lastly, we can run the following command to verify the 3D drivers’ installation:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ex">glxinfo</span> <span class="kw">|</span> <span class="fu">grep</span> OpenGL</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here is the output for the A770:</p>
<pre class="text"><code>$ glxinfo |grep OpenGL
OpenGL vendor string: Intel
OpenGL renderer string: Mesa Intel(R) Arc(tm) A770 Graphics (DG2)
OpenGL core profile version string: 4.6 (Core Profile) Mesa 23.1.0-devel (git-722bcd7973)
OpenGL core profile shading language version string: 4.60
OpenGL core profile context flags: (none)
OpenGL core profile profile mask: core profile
OpenGL core profile extensions:
OpenGL version string: 4.6 (Compatibility Profile) Mesa 23.1.0-devel (git-722bcd7973)
OpenGL shading language version string: 4.60
OpenGL context flags: (none)
OpenGL profile mask: compatibility profile
OpenGL extensions:
OpenGL ES profile version string: OpenGL ES 3.2 Mesa 23.1.0-devel (git-722bcd7973)
OpenGL ES profile shading language version string: OpenGL ES GLSL ES 3.20
OpenGL ES profile extensions:</code></pre>
<hr>
</section>
</section>
</section>
<section id="install-oneapi-base-toolkit" class="level2">
<h2 class="anchored" data-anchor-id="install-oneapi-base-toolkit">Install oneAPI Base Toolkit</h2>
<p>Next, we install the <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html#gs.ztyvfm">oneAPI Base Toolkit</a>, which Intel’s PyTorch extension depends on. As mentioned earlier, the toolkit will take up approximately 15GB of disk space. We’ll install the toolkit using the APT package manager.</p>
<p>Run the following commands to add the package repository and install the toolkit:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> <span class="at">-v</span> <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> <span class="at">-O-</span> https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB <span class="dt">\ </span><span class="kw">|</span> <span class="ex">gpg</span> <span class="at">--dearmor</span> <span class="kw">|</span> <span class="fu">sudo</span> tee /usr/share/keyrings/oneapi-archive-keyring.gpg <span class="op">&gt;</span> /dev/null <span class="dt">\</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>echo <span class="st">"deb [signed-by=/usr/share/keyrings/oneapi-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main"</span> <span class="kw">|</span> <span class="fu">sudo</span> tee /etc/apt/sources.list.d/oneAPI.list <span class="dt">\</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>sudo apt update <span class="dt">\</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>sudo apt install intel-basekit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The above bash commands perform the following steps:</p>
<ol type="1">
<li>Refresh sudo access to avoid multiple password prompts.</li>
<li>Download the system keyring for the repository.</li>
<li>Add the signed entry to APT sources and configure the APT client to use the Intel repository.</li>
<li>Update the list of available packages.</li>
<li>Install the toolkit.</li>
</ol>
</section>
<section id="update-the-bash-run-commands-file" class="level2">
<h2 class="anchored" data-anchor-id="update-the-bash-run-commands-file">Update the Bash Run Commands File</h2>
<p>We need to add the following lines to the end of the bash run commands file (<code>.bashrc</code>) for Intel’s extension to use the oneAPI toolkit:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">ONEAPI_ROOT</span><span class="op">=</span>/opt/intel/oneapi</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">DPCPPROOT</span><span class="op">=</span><span class="va">${ONEAPI_ROOT}</span>/compiler/latest</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">MKLROOT</span><span class="op">=</span><span class="va">${ONEAPI_ROOT}</span>/mkl/latest</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">IPEX_XPU_ONEDNN_LAYOUT</span><span class="op">=</span>1</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> <span class="va">${ONEAPI_ROOT}</span>/setvars.sh <span class="op">&gt;</span> /dev/null</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The above lines perform the following steps:</p>
<ol type="1">
<li>Add the installation location for the oneAPI toolkit as an environment variable.</li>
<li>Add the installation location for the DPC++ Compiler as an environment variable.</li>
<li>Add the installation for the Math Kernel Library as an environment variable.</li>
<li>Set the oneDNN memory layout to improve training speed.</li>
<li>Initialize the oneAPI environment.</li>
</ol>
<p>You can run the following commands to add the above lines to the <code>.bashrc</code> file and apply the changes to the current shell:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="at">-e</span> <span class="st">"\nexport ONEAPI_ROOT=/opt/intel/oneapi\nexport DPCPPROOT=</span><span class="dt">\$</span><span class="st">{ONEAPI_ROOT}/compiler/latest\nexport MKLROOT=</span><span class="dt">\$</span><span class="st">{ONEAPI_ROOT}/mkl/latest\nexport IPEX_XPU_ONEDNN_LAYOUT=1\nsource </span><span class="dt">\$</span><span class="st">{ONEAPI_ROOT}/setvars.sh &gt; /dev/null"</span> <span class="op">&gt;&gt;</span> ~/.bashrc <span class="dt">\</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>source ~/.bashrc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="apply-oneapi-patch" class="level2">
<h2 class="anchored" data-anchor-id="apply-oneapi-patch">Apply OneAPI Patch</h2>
<p>The <a href="https://intel.github.io/intel-extension-for-pytorch/xpu/1.13.120+xpu/tutorials/installation.html#install-oneapi-base-toolkit">installation instructions</a> for the current version of Intel’s PyTorch extension say that we need to apply a patch to the DPC++ compiler in the oneAPI Basekit.</p>
<p>You can run the following bash commands to download the patch and apply it to the oneAPI toolkit installation:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> <span class="at">-v</span> <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install unzip <span class="at">-y</span> <span class="dt">\</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>wget https://registrationcenter-download.intel.com/akdlm/IRC_NAS/89283df8-c667-47b0-b7e1-c4573e37bd3e/2023.1-linux-hotfix.zip <span class="dt">\</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>unzip 2023.1-linux-hotfix.zip <span class="dt">\</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>cd 2023.1-linux-hotfix <span class="dt">\</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>sed <span class="at">-i</span> <span class="st">'2iONEAPI_ROOT=/opt/intel/oneapi'</span> installpatch.sh <span class="dt">\</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>sudo bash installpatch.sh</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The above commands perform the following steps:</p>
<ol type="1">
<li>Refresh sudo access to avoid multiple password prompts.</li>
<li>Install the unzip package used to unzip the patch package</li>
<li>Download the patch package.</li>
<li>Unzip the patch package.</li>
<li>Enter the patch package folder.</li>
<li>Add the installation location for the oneAPI toolkit to the install patch script.</li>
<li>Apply the patch.</li>
</ol>
</section>
<section id="set-up-a-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="set-up-a-python-environment">Set Up a Python Environment</h2>
<p>Now we can create a Python environment to run the training code. We’ll install a patched version of PyTorch needed for Intel’s extension, the extension itself, and the other dependencies for the training code.</p>
<section id="install-mamba-package-manager" class="level3">
<h3 class="anchored" data-anchor-id="install-mamba-package-manager">Install Mamba Package Manager</h3>
<p>We’ll use the <a href="https://mamba.readthedocs.io/en/latest/">Mamba</a> package manager to create the Python environment. You can learn more about it in my <a href="https://christianjmills.com/posts/mamba-getting-started-tutorial-windows/">getting started</a> tutorial.</p>
<p>The following bash commands will download the latest release, install it, and relaunch the current bash shell to apply the relevant changes:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> <span class="st">"https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-</span><span class="va">$(</span><span class="fu">uname</span><span class="va">)</span><span class="st">-</span><span class="va">$(</span><span class="fu">uname</span> <span class="at">-m</span><span class="va">)</span><span class="st">.sh"</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span> Mambaforge-<span class="va">$(</span><span class="fu">uname</span><span class="va">)</span>-<span class="va">$(</span><span class="fu">uname</span> <span class="at">-m</span><span class="va">)</span>.sh <span class="at">-b</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="create-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="create-a-python-environment">Create a Python Environment</h3>
<p>Next, we’ll create a Python environment and activate it. The current version of the extension does not yet support Python 3.11, so we’ll use Python 3.10.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> create <span class="at">--name</span> pytorch-arc python=3.10 <span class="at">-y</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> activate pytorch-arc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="install-pytorch-and-intels-pytorch-extension" class="level3">
<h3 class="anchored" data-anchor-id="install-pytorch-and-intels-pytorch-extension">Install PyTorch and Intel’s PyTorch extension</h3>
<p>The following command will install the required versions of PyTorch and torchvision, along with the extension itself:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> pip install torch==1.13.0a0+git6c9b55e torchvision==0.14.1a0 intel_extension_for_pytorch==1.13.120+xpu <span class="at">-f</span> https://developer.intel.com/ipex-whl-stable-xpu</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="install-additional-depenencies" class="level3">
<h3 class="anchored" data-anchor-id="install-additional-depenencies">Install additional depenencies</h3>
<p>Lastly, we’ll install the other training code dependencies. You can learn about these dependencies (<a href="https://christianjmills.com/posts/pytorch-train-image-classifier-timm-hf-tutorial/#installing-additional-libraries">here</a>).</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install additional dependencies</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install datasets jupyter matplotlib pandas pillow timm torcheval tqdm</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Install older pyzmq and jupyter client versions</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">--upgrade</span> <span class="st">"jupyter_client&lt;8"</span> <span class="st">"pyzmq&lt;25"</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Install utility packages</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install cjm_pandas_utils cjm_pil_utils cjm_pytorch_utils</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="modify-pytorch-code" class="level2">
<h2 class="anchored" data-anchor-id="modify-pytorch-code">Modify PyTorch Code</h2>
<p>It’s finally time to train a model. The Jupyter Notebooks with the original and modified training code are available on GitHub at the links below.</p>
<ul>
<li><a href="https://github.com/cj-mills/pytorch-timm-gesture-recognition-tutorial-code/blob/main/notebooks/pytorch-timm-image-classifier-training.ipynb">pytorch-timm-image-classifier-training.ipynb</a></li>
<li><a href="https://github.com/cj-mills/pytorch-timm-gesture-recognition-tutorial-code/blob/main/notebooks/intel-arc-pytorch-timm-image-classifier-training.ipynb">intel-arc-pytorch-timm-image-classifier-training.ipynb</a></li>
</ul>
<p>You can also download the notebooks to the current directory by running the following commands:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://raw.githubusercontent.com/cj-mills/pytorch-timm-gesture-recognition-tutorial-code/main/notebooks/pytorch-timm-image-classifier-training.ipynb <span class="dt">\</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>wget https://raw.githubusercontent.com/cj-mills/pytorch-timm-gesture-recognition-tutorial-code/main/notebooks/intel-arc-pytorch-timm-image-classifier-training.ipynb</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Once downloaded, run the following command to launch the Jupyter Notebook Environment:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="import-pytorch-extension" class="level3">
<h3 class="anchored" data-anchor-id="import-pytorch-extension">Import PyTorch Extension</h3>
<p>We import Intel’s PyTorch extension with the following code:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="ex">import</span> torch</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="ex">import</span> intel_extension_for_pytorch as ipex</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="ex">print</span><span class="er">(</span><span class="ex">f</span><span class="st">'PyTorch Version: {torch.__version__}'</span><span class="kw">)</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="ex">print</span><span class="er">(</span><span class="ex">f</span><span class="st">'Intel PyTorch Extension Version: {ipex.__version__}'</span><span class="kw">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Note that we need to import PyTorch before the extension. Also, if you get the following user warning, don’t worry. It’s normal.</p>
<pre class="text"><code>UserWarning: Failed to load image Python extension: 
  warn(f"Failed to load image Python extension: {e}")</code></pre>
<hr>
</section>
<section id="update-pytorch-imports" class="level3">
<h3 class="anchored" data-anchor-id="update-pytorch-imports">Update PyTorch Imports</h3>
<p>Unlike the original training code, we import the <code>autocast()</code> context manager from <code>torch.xpu.amp</code> instead of <code>torch.amp</code>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Modified</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Original</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import PyTorch dependencies</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.xpu.amp <span class="im">import</span> autocast</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.cuda.amp <span class="im">import</span> GradScaler</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms.functional <span class="im">as</span> TF</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torcheval.tools <span class="im">import</span> get_module_summary</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torcheval.metrics <span class="im">import</span> MulticlassAccuracy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import PyTorch dependencies</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.amp <span class="im">import</span> autocast</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.cuda.amp <span class="im">import</span> GradScaler</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms.functional <span class="im">as</span> TF</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torcheval.tools <span class="im">import</span> get_module_summary</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torcheval.metrics <span class="im">import</span> MulticlassAccuracy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="verify-arc-gpu-availability" class="level3">
<h3 class="anchored" data-anchor-id="verify-arc-gpu-availability">Verify Arc GPU Availability</h3>
<p>We can double-check that the extension can use the Arc GPU by getting the properties of the available <code>xpu</code> devices.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_public_properties(obj):</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>        prop: <span class="bu">getattr</span>(obj, prop)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> prop <span class="kw">in</span> <span class="bu">dir</span>(obj)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> prop.startswith(<span class="st">"__"</span>) <span class="kw">and</span> <span class="kw">not</span> <span class="bu">callable</span>(<span class="bu">getattr</span>(obj, prop))</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>xpu_device_count <span class="op">=</span> torch.xpu.device_count()</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>dict_properties_list <span class="op">=</span> [get_public_properties(torch.xpu.get_device_properties(i)) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(xpu_device_count)]</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(dict_properties_list)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div>

<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
dev_type
</th>
<th>
max_compute_units
</th>
<th>
name
</th>
<th>
platform_name
</th>
<th>
support_fp64
</th>
<th>
total_memory
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
gpu
</td>
<td>
512
</td>
<td>
Intel(R) Arc(TM) A770 Graphics
</td>
<td>
Intel(R) Level-Zero
</td>
<td>
False
</td>
<td>
16225243136
</td>
</tr>
<tr>
<th>
1
</th>
<td>
gpu
</td>
<td>
32
</td>
<td>
Intel(R) UHD Graphics 750
</td>
<td>
Intel(R) Level-Zero
</td>
<td>
False
</td>
<td>
26589642752
</td>
</tr>
</tbody>

</table>
</div>
<p>In this case, the A770 is the default <code>xpu</code> device, and the integrated graphics on the CPU is available as the second device. The <code>total_memory</code> value for the integrated graphics is higher because it uses system memory.</p>
</section>
<section id="update-the-device-name" class="level3">
<h3 class="anchored" data-anchor-id="update-the-device-name">Update the Device Name</h3>
<p>Next, we’ll manually set the device name to <code>xpu</code>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Modified</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Original</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'xpu'</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>dtype <span class="op">=</span> torch.float32</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>device, dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> get_torch_device()</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>dtype <span class="op">=</span> torch.float32</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>device, dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="update-the-autocast-context-manager" class="level3">
<h3 class="anchored" data-anchor-id="update-the-autocast-context-manager">Update the <code>autocast()</code> context manager</h3>
<p>We don’t pass the device name to the <code>xpu</code> version of the <code>autocast()</code> context manager, so we need to update that in the <code>run_epoch</code> function.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Modified</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Original</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Enables gradient calculation if 'is_training' is True</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.set_grad_enabled(is_training):</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Automatic Mixed Precision (AMP) context manager for improved performance</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> autocast():</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(inputs) <span class="co"># Forward pass</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> torch.nn.functional.cross_entropy(outputs, targets) <span class="co"># Compute loss</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Enables gradient calculation if 'is_training' is True</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.set_grad_enabled(is_training):</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Automatic Mixed Precision (AMP) context manager for improved performance</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> autocast(device):</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(inputs) <span class="co"># Forward pass</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> torch.nn.functional.cross_entropy(outputs, targets) <span class="co"># Compute loss</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="optimize-the-model-and-optimizer-objects" class="level3">
<h3 class="anchored" data-anchor-id="optimize-the-model-and-optimizer-objects">Optimize the <code>model</code> and <code>optimizer</code> Objects</h3>
<p>Before we run the <code>train_loop</code> function, we’ll use Intel’s PyTorch extension to apply optimizations to the model and optimizer objects. We’ll also cast the model to the <code>bfloat16</code> data type, so we can train using mixed precision. Intel’s PyTorch extension only supports the <code>bloat16</code> data type for mixed-precision training currently.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model, optimizer <span class="op">=</span> ipex.optimize(model, optimizer<span class="op">=</span>optimizer, dtype<span class="op">=</span>torch.bfloat16)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If you get the following warning message, don’t worry. It is normal.</p>
<pre class="text"><code>UserWarning: Weight Prepack and Sample Input are both disabled on XPU. The Onednn Layout is automatically applied.
  warnings.warn(</code></pre>
<hr>
</section>
<section id="train-the-model" class="level3">
<h3 class="anchored" data-anchor-id="train-the-model">Train the Model</h3>
<p>That’s it for the required changes to the training code. The Arc-specific training notebook linked above has some additional changes, but none are essential. We can now run the <code>train_loop</code> function. With the A770 and the dataset on an SSD, training takes between twelve and twelve and a half minutes to complete.</p>
<p><img src="./images/arc-a770-pytorch-training-session-ubuntu.png" class="img-fluid"></p>
</section>
<section id="update-the-inference-code" class="level3">
<h3 class="anchored" data-anchor-id="update-the-inference-code">Update the Inference Code</h3>
<p>Since we cast the model to <code>bloat16</code>, we must ensure input data use the same type. We can update the inference code using the auto-cast context manager as shown below:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">Modified</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Original</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a prediction with the model</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.xpu.amp.autocast(enabled<span class="op">=</span><span class="va">True</span>, dtype<span class="op">=</span>torch.bfloat16, cache_enabled<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> model(img_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a prediction with the model</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    pred <span class="op">=</span> model(img_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we set up Intel’s PyTorch extension on Ubuntu and trained an image classification model using an Arc GPU. The exact setup steps may change with new versions, so check the <a href="https://intel.github.io/intel-extension-for-pytorch/xpu/latest/tutorials/installation.html">documentation</a> for the latest version to see if there are any changes. I’ll try to keep this tutorial updated with any significant changes to the process.</p>


</section>

</main> <!-- /main -->
<!-- Cloudflare Web Analytics --><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;56b8d2f624604c4891327b3c0d9f6703&quot;}"></script><!-- End Cloudflare Web Analytics -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="cj-mills/christianjmills" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2023, Christian J. Mills
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>