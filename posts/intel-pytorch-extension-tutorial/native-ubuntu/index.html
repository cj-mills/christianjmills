<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Christian Mills">
<meta name="dcterms.date" content="2024-09-22">
<meta name="description" content="This tutorial provides a step-by-step guide to setting up Intel’s PyTorch extension on Ubuntu to train computer vision models and run local large language models with Arc GPUs.">

<title>Getting Started with Intel’s PyTorch Extension for Arc GPUs on Ubuntu – Christian Mills</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-2486e1f0a3ee9ee1fc393803a1361cdb.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-6561bbde787c299e21493071c8edc6ff.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-89d229de977f041b86c4df3322a16784.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Getting Started with Intel’s PyTorch Extension for Arc GPUs on Ubuntu – Christian Mills">
<meta property="og:description" content="This tutorial provides a step-by-step guide to setting up Intel’s PyTorch extension on Ubuntu to train computer vision models and run local large language models with Arc GPUs.">
<meta property="og:image" content="https://christianjmills.com/images/default-preview-image-black.png">
<meta property="og:site_name" content="Christian Mills">
<meta property="og:image:height" content="284">
<meta property="og:image:width" content="526">
<meta name="twitter:title" content="Getting Started with Intel’s PyTorch Extension for Arc GPUs on Ubuntu – Christian Mills">
<meta name="twitter:description" content="This tutorial provides a step-by-step guide to setting up Intel’s PyTorch extension on Ubuntu to train computer vision models and run local large language models with Arc GPUs.">
<meta name="twitter:image" content="https://christianjmills.com/images/default-preview-image-black.png">
<meta name="twitter:creator" content="@cdotjdotmills">
<meta name="twitter:site" content="@cdotjdotmills">
<meta name="twitter:image-height" content="284">
<meta name="twitter:image-width" content="526">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Christian Mills</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/tutorials/index.html"> 
<span class="menu-text">Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/notes/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:christian@christianjmills.com"> <i class="bi bi-envelope-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cj-mills"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/cdotjdotmills"> <i class="bi bi-twitter-x" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/christianjmills"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../blog.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#enable-resizable-bar-in-bios" id="toc-enable-resizable-bar-in-bios" class="nav-link" data-scroll-target="#enable-resizable-bar-in-bios">Enable Resizable BAR in BIOS</a></li>
  <li><a href="#install-ubuntu" id="toc-install-ubuntu" class="nav-link" data-scroll-target="#install-ubuntu">Install Ubuntu</a></li>
  <li><a href="#verify-resizable-bar" id="toc-verify-resizable-bar" class="nav-link" data-scroll-target="#verify-resizable-bar">Verify Resizable BAR</a></li>
  <li><a href="#install-drivers" id="toc-install-drivers" class="nav-link" data-scroll-target="#install-drivers">Install Drivers</a>
  <ul>
  <li><a href="#add-intel-graphics-drivers-repository" id="toc-add-intel-graphics-drivers-repository" class="nav-link" data-scroll-target="#add-intel-graphics-drivers-repository">Add Intel Graphics drivers Repository</a></li>
  <li><a href="#install-packages" id="toc-install-packages" class="nav-link" data-scroll-target="#install-packages">Install packages</a></li>
  </ul></li>
  <li><a href="#set-up-a-python-environment" id="toc-set-up-a-python-environment" class="nav-link" data-scroll-target="#set-up-a-python-environment">Set Up a Python Environment</a>
  <ul>
  <li><a href="#install-mamba-package-manager" id="toc-install-mamba-package-manager" class="nav-link" data-scroll-target="#install-mamba-package-manager">Install Mamba Package Manager</a></li>
  <li><a href="#create-a-python-environment" id="toc-create-a-python-environment" class="nav-link" data-scroll-target="#create-a-python-environment">Create a Python Environment</a></li>
  <li><a href="#install-pytorch-and-intels-pytorch-extension" id="toc-install-pytorch-and-intels-pytorch-extension" class="nav-link" data-scroll-target="#install-pytorch-and-intels-pytorch-extension">Install PyTorch and Intel’s PyTorch extension</a></li>
  <li><a href="#install-additional-dependencies" id="toc-install-additional-dependencies" class="nav-link" data-scroll-target="#install-additional-dependencies">Install additional dependencies</a></li>
  </ul></li>
  <li><a href="#modify-pytorch-code" id="toc-modify-pytorch-code" class="nav-link" data-scroll-target="#modify-pytorch-code">Modify PyTorch Code</a>
  <ul>
  <li><a href="#set-environment-variables" id="toc-set-environment-variables" class="nav-link" data-scroll-target="#set-environment-variables">Set Environment Variables</a></li>
  <li><a href="#import-pytorch-extension" id="toc-import-pytorch-extension" class="nav-link" data-scroll-target="#import-pytorch-extension">Import PyTorch Extension</a></li>
  <li><a href="#update-pytorch-imports" id="toc-update-pytorch-imports" class="nav-link" data-scroll-target="#update-pytorch-imports">Update PyTorch Imports</a></li>
  <li><a href="#verify-arc-gpu-availability" id="toc-verify-arc-gpu-availability" class="nav-link" data-scroll-target="#verify-arc-gpu-availability">Verify Arc GPU Availability</a></li>
  <li><a href="#update-the-device-name" id="toc-update-the-device-name" class="nav-link" data-scroll-target="#update-the-device-name">Update the Device Name</a></li>
  <li><a href="#optimize-the-model-and-optimizer-objects" id="toc-optimize-the-model-and-optimizer-objects" class="nav-link" data-scroll-target="#optimize-the-model-and-optimizer-objects">Optimize the <code>model</code> and <code>optimizer</code> Objects</a></li>
  <li><a href="#train-the-model" id="toc-train-the-model" class="nav-link" data-scroll-target="#train-the-model">Train the Model</a></li>
  <li><a href="#update-the-inference-code" id="toc-update-the-inference-code" class="nav-link" data-scroll-target="#update-the-inference-code">Update the Inference Code</a></li>
  </ul></li>
  <li><a href="#local-llm-inference-with-ipex-llm" id="toc-local-llm-inference-with-ipex-llm" class="nav-link" data-scroll-target="#local-llm-inference-with-ipex-llm">Local LLM Inference with <code>IPEX-LLM</code></a>
  <ul>
  <li><a href="#install-oneapi-packages" id="toc-install-oneapi-packages" class="nav-link" data-scroll-target="#install-oneapi-packages">Install oneAPI Packages</a>
  <ul class="collapse">
  <li><a href="#set-the-oneapi-environment-variables" id="toc-set-the-oneapi-environment-variables" class="nav-link" data-scroll-target="#set-the-oneapi-environment-variables">Set the oneAPI Environment Variables</a></li>
  </ul></li>
  <li><a href="#create-a-new-python-environment" id="toc-create-a-new-python-environment" class="nav-link" data-scroll-target="#create-a-new-python-environment">Create a New Python Environment</a></li>
  <li><a href="#install-pip-packages" id="toc-install-pip-packages" class="nav-link" data-scroll-target="#install-pip-packages">Install PIP Packages</a></li>
  <li><a href="#set-environment-variables-1" id="toc-set-environment-variables-1" class="nav-link" data-scroll-target="#set-environment-variables-1">Set Environment Variables</a></li>
  <li><a href="#import-the-required-dependencies" id="toc-import-the-required-dependencies" class="nav-link" data-scroll-target="#import-the-required-dependencies">Import the Required Dependencies</a></li>
  <li><a href="#define-a-function-to-prepare-the-prompt" id="toc-define-a-function-to-prepare-the-prompt" class="nav-link" data-scroll-target="#define-a-function-to-prepare-the-prompt">Define a Function to Prepare the Prompt</a></li>
  <li><a href="#load-the-model-in-int4" id="toc-load-the-model-in-int4" class="nav-link" data-scroll-target="#load-the-model-in-int4">Load the Model in INT4</a></li>
  <li><a href="#define-inference-parameters" id="toc-define-inference-parameters" class="nav-link" data-scroll-target="#define-inference-parameters">Define Inference Parameters</a></li>
  <li><a href="#perform-inference" id="toc-perform-inference" class="nav-link" data-scroll-target="#perform-inference">Perform Inference</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Getting Started with Intel’s PyTorch Extension for Arc GPUs on Ubuntu</h1>
  <div class="quarto-categories">
    <div class="quarto-category">pytorch</div>
    <div class="quarto-category">ubuntu</div>
    <div class="quarto-category">image-classification</div>
    <div class="quarto-category">arc-gpu</div>
    <div class="quarto-category">getting-started</div>
  </div>
  </div>

<div>
  <div class="description">
    This tutorial provides a step-by-step guide to setting up Intel’s PyTorch extension on Ubuntu to train computer vision models and run local large language models with Arc GPUs.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Christian Mills </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 22, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#enable-resizable-bar-in-bios">Enable Resizable BAR in BIOS</a></li>
<li><a href="#install-ubuntu">Install Ubuntu</a></li>
<li><a href="#verify-resizable-bar">Verify Resizable BAR</a></li>
<li><a href="#install-drivers">Install Drivers</a><br>
</li>
<li><a href="#set-up-a-python-environment">Set Up a Python Environment</a><br>
</li>
<li><a href="#modify-pytorch-code">Modify PyTorch Code</a><br>
</li>
<li><a href="#local-llm-inference-with-ipex-llm">Local LLM Inference with <code>IPEX-LLM</code></a><br>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In this tutorial, I’ll guide you through setting up Intel’s <a href="https://github.com/intel/intel-extension-for-pytorch">PyTorch extension</a> on <a href="https://ubuntu.com/download/desktop">Ubuntu</a> to train models with their <a href="https://www.intel.com/content/www/us/en/products/docs/discrete-gpus/arc/desktop/a-series/overview.html">Arc GPUs</a>. The extension provides Intel’s latest feature optimizations and hardware support before they get added to PyTorch. Most importantly for our case, it includes support for Intel’s Arc GPUs and optimizations to take advantage of their Xe Matrix Extensions (XMX).</p>
<p>The XMX engines are dedicated hardware for performing matrix operations like those in deep-learning workloads. Intel’s PyTorch extension allows us to leverage this hardware with minimal changes to existing PyTorch code.</p>
<p>To illustrate this, we will walk through two use cases. First, we’ll adapt the training code from my beginner-level PyTorch tutorial, where we fine-tune an image classification model from the <a href="https://github.com/huggingface/pytorch-image-models">timm library</a> for hand gesture recognition. Second, we will use the <a href="https://github.com/intel-analytics/ipex-llm"><code>ipex-llm</code></a> library, which builds on Intel’s PyTorch extension, to perform inference with the <a href="https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct">LLaMA 3.1 8B Instruct</a> model.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The current setup process is for version <a href="https://intel.github.io/intel-extension-for-pytorch/xpu/2.3.110+xpu/"><code>2.3.110+xpu</code></a> of Intel’s PyTorch extension.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="WSL">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
WSL
</div>
</div>
<div class="callout-body-container callout-body">
<p>The following setup process also works for WSL (Windows Subsystem for Linux). If you are working in WSL, skip to the following section after enabling Resizable BAR:</p>
<ul>
<li><a href="#install-drivers">Install Drivers</a></li>
</ul>
<p>Follow the steps in the linked section below to deactivate the Integrated Graphics. This step is required to use the extension on Windows.</p>
<ul>
<li><a href="../../../posts/intel-pytorch-extension-tutorial/native-windows/#disable-integrated-graphics">Getting Started with Intel’s PyTorch Extension for Arc GPUs on Windows - Disable Integrated Graphics</a></li>
</ul>
</div>
</div>
</section>
<section id="enable-resizable-bar-in-bios" class="level2">
<h2 class="anchored" data-anchor-id="enable-resizable-bar-in-bios">Enable Resizable BAR in BIOS</h2>
<p>If you have an Arc GPU, one of the first things you should do is enable Resizable BAR. Resizable BAR allows a computer’s processor to access the graphics card’s entire memory instead of in small chunks. The Arc GPUs currently require this feature to perform as intended. You can enable the feature in your motherboard’s BIOS.</p>
<p>Here are links on how to do this for some of the popular motherboard manufacturers:</p>
<ul>
<li><a href="https://www.asrock.com/support/faq.asp?id=498">ASRock</a></li>
<li><a href="https://www.asus.com/support/FAQ/1046107/">Asus</a></li>
<li><a href="https://www.evga.com/support/faq/FAQdetails.aspx?faqid=59772">EVGA</a></li>
<li><a href="https://www.gigabyte.com/WebPage/785/NVIDIA_resizable_bar.html">Gigabyte</a></li>
<li><a href="https://www.msi.com/blog/unlock-system-performance-to-extreme-resizable-bar">MSI</a></li>
</ul>
</section>
<section id="install-ubuntu" class="level2">
<h2 class="anchored" data-anchor-id="install-ubuntu">Install Ubuntu</h2>
<p>Intel’s <a href="https://dgpu-docs.intel.com/driver/client/overview.html#client-install-options">documentation</a> recommends Ubuntu 22.04 LTS or newer. I verified the following steps in both Ubuntu 22.04 and 24.04. If you already have Ubuntu 22.04 LTS or newer installed, ensure it’s fully updated.</p>
<ul>
<li><a href="https://ubuntu.com/download/desktop">Download Ubuntu Desktop Download Page</a></li>
</ul>
<p>The Ubuntu website provides <a href="https://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview">a step-by-step guide</a> to installing Ubuntu on your PC, and you can install it alongside an existing operating system.</p>
<ul>
<li><strong>Tutorial:</strong> <a href="https://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview">Install Ubuntu with a Bootable USB Stick</a></li>
</ul>
<p>That tutorial calls for at least 25GB of free storage space, but I recommend at least 80 GB for our case.</p>
</section>
<section id="verify-resizable-bar" class="level2">
<h2 class="anchored" data-anchor-id="verify-resizable-bar">Verify Resizable BAR</h2>
<p>Once you log into Ubuntu, you can verify Resizable BAR is active by opening a terminal (<code>Ctrl+Alt+T</code>) and running the following command:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">lspci</span> <span class="at">-v</span> <span class="kw">|</span><span class="fu">grep</span> <span class="at">-A8</span> VGA</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here is the output for the Arc A770 16GB card:</p>
<pre class="text"><code>$ lspci -v |grep -A8 VGA
00:02.0 VGA compatible controller: Intel Corporation RocketLake-S GT1 [UHD Graphics 750] (rev 04) (prog-if 00 [VGA controller])
    Subsystem: ASRock Incorporation RocketLake-S GT1 [UHD Graphics 750]
    Flags: bus master, fast devsel, latency 0, IRQ 172
    Memory at 6401000000 (64-bit, non-prefetchable) [size=16M]
    Memory at 4000000000 (64-bit, prefetchable) [size=256M]
    I/O ports at 3000 [size=64]
    Expansion ROM at 000c0000 [virtual] [disabled] [size=128K]
    Capabilities: &lt;access denied&gt;
    Kernel driver in use: i915
--
03:00.0 VGA compatible controller: Intel Corporation DG2 [Arc A770] (rev 08) (prog-if 00 [VGA controller])
    Subsystem: Intel Corporation DG2 [Arc A770]
    Flags: bus master, fast devsel, latency 0, IRQ 173
    Memory at a1000000 (64-bit, non-prefetchable) [size=16M]
    Memory at 6000000000 (64-bit, prefetchable) [size=16G]
    Expansion ROM at a2000000 [disabled] [size=2M]
    Capabilities: &lt;access denied&gt;
    Kernel driver in use: i915
    Kernel modules: i915</code></pre>
<hr>
<p>Note that the <code>[size=16G]</code> matches the total memory for the GPU. If you have the A750 8GB variant, it should read <code>[size=8G]</code> for your GPU.</p>
</section>
<section id="install-drivers" class="level2">
<h2 class="anchored" data-anchor-id="install-drivers">Install Drivers</h2>
<p>Next, we will install the compute, media, and display runtimes.</p>
<section id="add-intel-graphics-drivers-repository" class="level3">
<h3 class="anchored" data-anchor-id="add-intel-graphics-drivers-repository">Add Intel Graphics drivers Repository</h3>
<p>Run the following bash commands to add the Intel Graphics drivers repository:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> <span class="at">-qO</span> <span class="at">-</span> https://repositories.intel.com/gpu/intel-graphics.key <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> gpg <span class="at">--yes</span> <span class="at">--dearmor</span> <span class="at">--output</span> /usr/share/keyrings/intel-graphics.gpg</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"deb [arch=amd64 signed-by=/usr/share/keyrings/intel-graphics.gpg] https://repositories.intel.com/gpu/ubuntu jammy/lts/2350 unified"</span> <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> tee /etc/apt/sources.list.d/intel-gpu-jammy.list</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt update</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The above bash commands perform the following steps:</p>
<ol type="1">
<li>Download the Intel graphics repository’s public key.</li>
<li>Convert the downloaded key to binary and save it.</li>
<li>Add the Intel graphics repository to the APT’s list of package sources.</li>
<li>Update the package list from all configured repositories, including the newly added Intel repository.</li>
</ol>
</section>
<section id="install-packages" class="level3">
<h3 class="anchored" data-anchor-id="install-packages">Install packages</h3>
<p>Now we can install the required packages.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install <span class="at">-y</span> <span class="dt">\</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    intel-opencl-icd intel-level-zero-gpu level-zero <span class="dt">\</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    intel-media-va-driver-non-free libmfx1 libmfxgen1 libvpl2 <span class="dt">\</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    libegl-mesa0 libegl1-mesa libegl1-mesa-dev libgbm1 libgl1-mesa-dev libgl1-mesa-dri <span class="dt">\</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    libglapi-mesa libgles2-mesa-dev libglx-mesa0 libigdgmm12 libxatracker2 mesa-va-drivers <span class="dt">\</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    mesa-vdpau-drivers mesa-vulkan-drivers va-driver-all vainfo hwinfo clinfo</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="set-up-a-python-environment" class="level2">
<h2 class="anchored" data-anchor-id="set-up-a-python-environment">Set Up a Python Environment</h2>
<p>Next, we can create a Python environment to run the training code. We’ll install a patched version of PyTorch needed for Intel’s extension, the extension itself, and the other dependencies for the training code.</p>
<section id="install-mamba-package-manager" class="level3">
<h3 class="anchored" data-anchor-id="install-mamba-package-manager">Install Mamba Package Manager</h3>
<p>We’ll use the <a href="https://mamba.readthedocs.io/en/latest/">Mamba</a> package manager to create the Python environment. You can learn more about it in my <a href="../../../posts/mamba-getting-started-tutorial-windows/">getting started</a> tutorial.</p>
<p>The following bash commands will download the latest release, install it, and relaunch the current bash shell to apply the relevant changes:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the latest Miniforge3 installer for the current OS and architecture</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> <span class="st">"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-</span><span class="va">$(</span><span class="fu">uname</span><span class="va">)</span><span class="st">-</span><span class="va">$(</span><span class="fu">uname</span> <span class="at">-m</span><span class="va">)</span><span class="st">.sh"</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the Miniforge3 installer silently (-b flag for batch mode)</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span> Miniforge3-<span class="va">$(</span><span class="fu">uname</span><span class="va">)</span>-<span class="va">$(</span><span class="fu">uname</span> <span class="at">-m</span><span class="va">)</span>.sh <span class="at">-b</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize mamba for shell usage</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="ex">~/miniforge3/bin/mamba</span> init</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Restart the shell to apply changes</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="create-a-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="create-a-python-environment">Create a Python Environment</h3>
<p>Next, we’ll create a Python environment and activate it. The current version of the extension supports Python 3.11, so we’ll use that.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> create <span class="at">--name</span> pytorch-arc python=3.11 <span class="at">-y</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> activate pytorch-arc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="install-pytorch-and-intels-pytorch-extension" class="level3">
<h3 class="anchored" data-anchor-id="install-pytorch-and-intels-pytorch-extension">Install PyTorch and Intel’s PyTorch extension</h3>
<p>The following command will install the required versions of PyTorch and torchvision, along with the extension itself:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install torch==2.3.1+cxx11.abi torchvision==0.18.1+cxx11.abi torchaudio==2.3.1+cxx11.abi intel-extension-for-pytorch==2.3.110+xpu oneccl_bind_pt==2.3.100+xpu <span class="at">--extra-index-url</span> https://pytorch-extension.intel.com/release-whl/stable/xpu/us/</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="install-additional-dependencies" class="level3">
<h3 class="anchored" data-anchor-id="install-additional-dependencies">Install additional dependencies</h3>
<p>Lastly, we’ll install the other training code dependencies. You can learn about these dependencies (<a href="../../../posts/pytorch-train-image-classifier-timm-hf-tutorial/#installing-additional-libraries">here</a>).</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install jupyter matplotlib pandas pillow timm torcheval torchtnt tqdm</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install cjm_pandas_utils cjm_psl_utils cjm_pil_utils cjm_pytorch_utils cjm_torchvision_tfms</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-important callout-titled" title="oneDNN Memory Layout">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
oneDNN Memory Layout
</div>
</div>
<div class="callout-body-container callout-body">
<p>The previous version of this tutorial set an environment variable for the oneDNN memory layout to improve training speed. The performance improvement from this step is no longer significant and even prevents successful training for other model types.</p>
<p>If you followed the previous version of this tutorial, run the following command to remove the environment variable from the <code>.bashrc</code> file and apply the changes to the current shell:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sed</span> <span class="at">-i</span> <span class="st">'/export IPEX_XPU_ONEDNN_LAYOUT=1/d'</span> ~/.bashrc <span class="kw">&amp;&amp;</span> <span class="bu">source</span> ~/.bashrc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
</section>
<section id="modify-pytorch-code" class="level2">
<h2 class="anchored" data-anchor-id="modify-pytorch-code">Modify PyTorch Code</h2>
<p>It’s finally time to train a model. The Jupyter Notebooks with the original and modified training code are available on GitHub at the links below.</p>
<ul>
<li><a href="https://github.com/cj-mills/pytorch-timm-gesture-recognition-tutorial-code/blob/main/notebooks/pytorch-timm-image-classifier-training.ipynb">pytorch-timm-image-classifier-training.ipynb</a></li>
<li><a href="https://github.com/cj-mills/pytorch-timm-gesture-recognition-tutorial-code/blob/main/notebooks/intel-arc-pytorch-timm-image-classifier-training.ipynb">intel-arc-pytorch-timm-image-classifier-training.ipynb</a></li>
</ul>
<p>You can also download the notebooks to the current directory by running the following commands:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://raw.githubusercontent.com/cj-mills/pytorch-timm-gesture-recognition-tutorial-code/main/notebooks/pytorch-timm-image-classifier-training.ipynb <span class="dt">\</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>wget https://raw.githubusercontent.com/cj-mills/pytorch-timm-gesture-recognition-tutorial-code/main/notebooks/intel-arc-pytorch-timm-image-classifier-training.ipynb</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Once downloaded, run the following command to launch the Jupyter Notebook Environment:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="set-environment-variables" class="level3">
<h3 class="anchored" data-anchor-id="set-environment-variables">Set Environment Variables</h3>
<p>First, we need to set the following environment variables:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'OCL_ICD_VENDORS'</span>] <span class="op">=</span> <span class="st">'/etc/OpenCL/vendors'</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'CCL_ROOT'</span>] <span class="op">=</span> os.environ.get(<span class="st">'CONDA_PREFIX'</span>, <span class="st">''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="import-pytorch-extension" class="level3">
<h3 class="anchored" data-anchor-id="import-pytorch-extension">Import PyTorch Extension</h3>
<p>Next, we import Intel’s PyTorch extension with the following code:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ex">import</span> torch</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="ex">import</span> intel_extension_for_pytorch as ipex</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="ex">print</span><span class="er">(</span><span class="ex">f</span><span class="st">'PyTorch Version: {torch.__version__}'</span><span class="kw">)</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="ex">print</span><span class="er">(</span><span class="ex">f</span><span class="st">'Intel PyTorch Extension Version: {ipex.__version__}'</span><span class="kw">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Note that we need to import PyTorch before the extension. Also, if you get the following user warning, don’t worry. It’s normal.</p>
<pre class="text"><code>PyTorch Version: 2.3.1+cxx11.abi
Intel PyTorch Extension Version: 2.3.110+xpu

/home/innom-dt/mambaforge/envs/pytorch-arc/lib/python3.11/site-packages/intel_extension_for_pytorch/llm/__init__.py:9: UserWarning: failed to use huggingface generation fuctions due to: No module named 'transformers'.
  warnings.warn(f"failed to use huggingface generation fuctions due to: {e}.")</code></pre>
<hr>
</section>
<section id="update-pytorch-imports" class="level3">
<h3 class="anchored" data-anchor-id="update-pytorch-imports">Update PyTorch Imports</h3>
<p>We don’t want to re-import <code>torch</code> after the extension, so we’ll remove that line from the <code>Import PyTorch dependencies</code> section.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Modified</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Original</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import PyTorch dependencies</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.amp <span class="im">import</span> autocast</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.cuda.amp <span class="im">import</span> GradScaler</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import PyTorch dependencies</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.amp <span class="im">import</span> autocast</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.cuda.amp <span class="im">import</span> GradScaler</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="verify-arc-gpu-availability" class="level3">
<h3 class="anchored" data-anchor-id="verify-arc-gpu-availability">Verify Arc GPU Availability</h3>
<p>We can double-check that the extension can use the Arc GPU by getting the properties of the available <code>xpu</code> devices.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_public_properties(obj):</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Extract all public properties from an object.</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">    obj: The object to extract properties from.</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">    dict: A dictionary containing the object's public properties and their values.</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        prop: <span class="bu">getattr</span>(obj, prop)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> prop <span class="kw">in</span> <span class="bu">dir</span>(obj)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> prop.startswith(<span class="st">"__"</span>) <span class="kw">and</span> <span class="kw">not</span> <span class="bu">callable</span>(<span class="bu">getattr</span>(obj, prop))</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the number of available XPU devices</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>xpu_device_count <span class="op">=</span> torch.xpu.device_count()</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list of dictionaries containing properties for each XPU device</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>dict_properties_list <span class="op">=</span> [</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>    get_public_properties(torch.xpu.get_device_properties(i))</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(xpu_device_count)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the list of dictionaries to a pandas DataFrame for easy viewing</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(dict_properties_list)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto;">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
driver_version
</th>
<th>
gpu_eu_count
</th>
<th>
gpu_subslice_count
</th>
<th>
has_atomic64
</th>
<th>
has_fp16
</th>
<th>
has_fp64
</th>
<th>
max_compute_units
</th>
<th>
max_num_sub_groups
</th>
<th>
max_work_group_size
</th>
<th>
name
</th>
<th>
platform_name
</th>
<th>
sub_group_sizes
</th>
<th>
total_memory
</th>
<th>
type
</th>
<th>
vendor
</th>
<th>
version
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1.3.27642
</td>
<td>
512
</td>
<td>
32
</td>
<td>
True
</td>
<td>
True
</td>
<td>
False
</td>
<td>
512
</td>
<td>
128
</td>
<td>
1024
</td>
<td>
Intel(R) Arc(TM) A770 Graphics
</td>
<td>
Intel(R) Level-Zero
</td>
<td>
[8, 16, 32]
</td>
<td>
16225243136
</td>
<td>
gpu
</td>
<td>
Intel(R) Corporation
</td>
<td>
1.3
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1.3.27642
</td>
<td>
32
</td>
<td>
2
</td>
<td>
True
</td>
<td>
True
</td>
<td>
False
</td>
<td>
32
</td>
<td>
64
</td>
<td>
512
</td>
<td>
Intel(R) UHD Graphics 750
</td>
<td>
Intel(R) Level-Zero
</td>
<td>
[8, 16, 32]
</td>
<td>
30791524352
</td>
<td>
gpu
</td>
<td>
Intel(R) Corporation
</td>
<td>
1.3
</td>
</tr>
</tbody>
</table>
</div>
<p>In this case, the A770 is the default device, and the integrated graphics on the CPU is available as the second device. The <code>total_memory</code> value for the integrated graphics is higher because it uses system memory.</p>
</section>
<section id="update-the-device-name" class="level3">
<h3 class="anchored" data-anchor-id="update-the-device-name">Update the Device Name</h3>
<p>Next, we’ll manually set the device name to <code>xpu</code>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Modified</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Original</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'xpu'</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>dtype <span class="op">=</span> torch.float32</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>device, dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> get_torch_device()</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>dtype <span class="op">=</span> torch.float32</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>device, dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="optimize-the-model-and-optimizer-objects" class="level3">
<h3 class="anchored" data-anchor-id="optimize-the-model-and-optimizer-objects">Optimize the <code>model</code> and <code>optimizer</code> Objects</h3>
<p>Before we run the <code>train_loop</code> function, we’ll use Intel’s PyTorch extension to apply optimizations to the model and optimizer objects. We’ll also cast the model to the <code>bfloat16</code> data type, so we can train using mixed precision.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Modified</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Original</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rate for the model</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">1e-3</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of training epochs</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># AdamW optimizer; includes weight decay for regularization</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>lr, eps<span class="op">=</span><span class="fl">1e-5</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimize the model and optimizer objects</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>model, optimizer <span class="op">=</span> ipex.optimize(model, optimizer<span class="op">=</span>optimizer, dtype<span class="op">=</span>torch.bfloat16)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rate scheduler; adjusts the learning rate during training</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>lr_scheduler <span class="op">=</span> torch.optim.lr_scheduler.OneCycleLR(optimizer, </span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>                                                   max_lr<span class="op">=</span>lr, </span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>                                                   total_steps<span class="op">=</span>epochs<span class="op">*</span><span class="bu">len</span>(train_dataloader))</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Performance metric: Multiclass Accuracy</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>metric <span class="op">=</span> MulticlassAccuracy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rate for the model</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">1e-3</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of training epochs</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># AdamW optimizer; includes weight decay for regularization</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>lr, eps<span class="op">=</span><span class="fl">1e-5</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rate scheduler; adjusts the learning rate during training</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>lr_scheduler <span class="op">=</span> torch.optim.lr_scheduler.OneCycleLR(optimizer, </span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>                                                   max_lr<span class="op">=</span>lr, </span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>                                                   total_steps<span class="op">=</span>epochs<span class="op">*</span><span class="bu">len</span>(train_dataloader))</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Performance metric: Multiclass Accuracy</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>metric <span class="op">=</span> MulticlassAccuracy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="train-the-model" class="level3">
<h3 class="anchored" data-anchor-id="train-the-model">Train the Model</h3>
<p>That’s it for the required changes to the training code. We can now run the <code>train_loop</code> function.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">Current</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Previous</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<pre class="text"><code>Epochs: 100% |█████████| 3/3 [18:31&lt;00:00, 369.74s/it]
Train: 100% |█████████| 4324/4324 [05:56&lt;00:00, 12.48it/s, accuracy=0.843, avg_loss=0.542, loss=0.592, lr=0.000994]
Eval: 100% |█████████| 481/481 [00:19&lt;00:00, 43.79it/s, accuracy=0.957, avg_loss=0.147, loss=0.133, lr=]
Train: 100% |█████████| 4324/4324 [05:53&lt;00:00, 12.37it/s, accuracy=0.905, avg_loss=0.309, loss=0.321, lr=0.000462]
Eval: 100% |█████████| 481/481 [00:13&lt;00:00, 44.92it/s, accuracy=0.97, avg_loss=0.092, loss=0.0842, lr=]
Train: 100% |█████████| 4324/4324 [05:54&lt;00:00, 12.62it/s, accuracy=0.953, avg_loss=0.151, loss=0.0595, lr=4.03e-9]
Eval: 100% |█████████| 481/481 [00:13&lt;00:00, 43.28it/s, accuracy=0.988, avg_loss=0.0389, loss=0.0422, lr=]</code></pre>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p><img src="./images/arc-a770-pytorch-training-session-ubuntu.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>In my testing, the training speed is significantly slower with this extension than the one used for the previous version of this tutorial, with the total run taking 18 minutes 31 seconds versus 12 minutes 46 seconds.</p>
</section>
<section id="update-the-inference-code" class="level3">
<h3 class="anchored" data-anchor-id="update-the-inference-code">Update the Inference Code</h3>
<p>Since we cast the model to <code>bloat16</code>, we must ensure input data use the same type. We can update the inference code using the auto-cast context manager as shown below:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Modified</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Original</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a prediction with the model</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(), autocast(torch.device(device).<span class="bu">type</span>):</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    pred <span class="op">=</span> model(img_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a prediction with the model</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    pred <span class="op">=</span> model(img_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="local-llm-inference-with-ipex-llm" class="level2">
<h2 class="anchored" data-anchor-id="local-llm-inference-with-ipex-llm">Local LLM Inference with <code>IPEX-LLM</code></h2>
<p>To close out this tutorial, we will cover how to perform local LLM inference using Intel’s <a href="https://github.com/intel-analytics/ipex-llm"><code>ipex-llm</code></a> library. This library allows us to run many popular LLMs in INT4 precision on our Arc GPU.</p>
<section id="install-oneapi-packages" class="level3">
<h3 class="anchored" data-anchor-id="install-oneapi-packages">Install oneAPI Packages</h3>
<p>The <code>ipex-llm</code> library requires packages from the oneAPI toolkit. Run the following commands to install them:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Refresh sudo credentials without running a command</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> <span class="at">-v</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Download Intel's GPG key, convert it to a format for the package manager, and save it</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> <span class="at">-O-</span> https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB <span class="kw">|</span> <span class="ex">gpg</span> <span class="at">--dearmor</span> <span class="kw">|</span> <span class="fu">sudo</span> tee /usr/share/keyrings/oneapi-archive-keyring.gpg <span class="op">&gt;</span> /dev/null</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Add Intel's repository to the system's package sources</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"deb [signed-by=/usr/share/keyrings/oneapi-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main"</span> <span class="kw">|</span> <span class="fu">sudo</span> tee /etc/apt/sources.list.d/oneAPI.list</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Update the package list to include Intel's repository</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt update</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Install specific versions of Intel oneAPI components</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install intel-oneapi-common-vars=2024.0.0-49406 <span class="dt">\</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-common-oneapi-vars=2024.0.0-49406 <span class="dt">\</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-diagnostics-utility=2024.0.0-49093 <span class="dt">\</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-compiler-dpcpp-cpp=2024.0.2-49895 <span class="dt">\</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-dpcpp-ct=2024.0.0-49381 <span class="dt">\</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-mkl=2024.0.0-49656 <span class="dt">\</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-mkl-devel=2024.0.0-49656 <span class="dt">\</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-mpi=2021.11.0-49493 <span class="dt">\</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-mpi-devel=2021.11.0-49493 <span class="dt">\</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-dal=2024.0.1-25 <span class="dt">\</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-dal-devel=2024.0.1-25 <span class="dt">\</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-ippcp=2021.9.1-5 <span class="dt">\</span></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-ippcp-devel=2021.9.1-5 <span class="dt">\</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-ipp=2021.10.1-13 <span class="dt">\</span></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-ipp-devel=2021.10.1-13 <span class="dt">\</span></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-tlt=2024.0.0-352 <span class="dt">\</span></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-ccl=2021.11.2-5 <span class="dt">\</span></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-ccl-devel=2021.11.2-5 <span class="dt">\</span></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-dnnl-devel=2024.0.0-49521 <span class="dt">\</span></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-dnnl=2024.0.0-49521 <span class="dt">\</span></span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>  intel-oneapi-tcm-1.0=1.0.0-435</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="set-the-oneapi-environment-variables" class="level4">
<h4 class="anchored" data-anchor-id="set-the-oneapi-environment-variables">Set the oneAPI Environment Variables</h4>
<p>You will need to run the following command to activate the oneAPI environment variables after starting a new shell:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the oneAPI environment variables for the current shell session</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> /opt/intel/oneapi/setvars.sh</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Alternatively, you can run the following command to add it to the <code>.bashrc</code> file:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">'source /opt/intel/oneapi/setvars.sh &gt; /dev/null 2&gt;&amp;1'</span> <span class="op">&gt;&gt;</span> ~/.bashrc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="create-a-new-python-environment" class="level3">
<h3 class="anchored" data-anchor-id="create-a-new-python-environment">Create a New Python Environment</h3>
<p>Each library version depends on specific versions of Intel’s PyTorch extension. The most recent release of <code>ipex-llm</code> still depends on version <code>2.1.10+xpu</code> of the extension.</p>
<p>We can create a dedicated mamba environment for this library to avoid dependency conflicts:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> create <span class="at">--name</span> ipex-llm-env python=3.11 <span class="at">-y</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> activate ipex-llm-env</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="install-pip-packages" class="level3">
<h3 class="anchored" data-anchor-id="install-pip-packages">Install PIP Packages</h3>
<p>We will use the LLaMA 3.1 8B Instruct model for demonstration purposes, which requires <a href="https://github.com/huggingface/transformers"><code>transformers</code></a> <code>4.43.1</code> or newer. We also need the <a href="https://huggingface.co/docs/trl/en/index"><code>trl</code></a> (Transformer Reinforcement Learning) package.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Installs intel_extension_for_pytorch==2.1.10+xpu as default</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">--pre</span> <span class="at">--upgrade</span> ipex-llm<span class="pp">[</span><span class="ss">xpu</span><span class="pp">]</span> <span class="at">--extra-index-url</span> https://pytorch-extension.intel.com/release-whl/stable/xpu/us/</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install jupyter transformers==4.43.1 trl</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can launch a new Jupyter Notebook environment once the dependencies finish installing.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="set-environment-variables-1" class="level3">
<h3 class="anchored" data-anchor-id="set-environment-variables-1">Set Environment Variables</h3>
<p>With our environment set up, we can dive into the code. First, we need to set the following environment variables:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'OCL_ICD_VENDORS'</span>] <span class="op">=</span> <span class="st">'/etc/OpenCL/vendors'</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'CCL_ROOT'</span>] <span class="op">=</span> os.environ.get(<span class="st">'CONDA_PREFIX'</span>, <span class="st">''</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'USE_XETLA'</span>] <span class="op">=</span> <span class="st">'OFF'</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'SYCL_CACHE_PERSISTENT'</span>] <span class="op">=</span> <span class="st">'1'</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'SYCL_PI_LEVEL_ZERO_USE_IMMEDIATE_COMMANDLISTS'</span>] <span class="op">=</span> <span class="st">'1'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="import-the-required-dependencies" class="level3">
<h3 class="anchored" data-anchor-id="import-the-required-dependencies">Import the Required Dependencies</h3>
<p>Next, we will import the necessary Python packages into our Jupyter Notebook.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> argparse</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ipex_llm.transformers <span class="im">import</span> AutoModelForCausalLM</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Markdown</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can use the <code>Markdown</code> class from IPython to render Markdown output from the model inside the notebook.</p>
</section>
<section id="define-a-function-to-prepare-the-prompt" class="level3">
<h3 class="anchored" data-anchor-id="define-a-function-to-prepare-the-prompt">Define a Function to Prepare the Prompt</h3>
<p>We can use the following function from this <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HuggingFace/LLM/llama3.1/generate.py">example script</a> to prepare prompts for the LLama 3.1 model:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_prompt(user_input: <span class="bu">str</span>, chat_history: <span class="bu">list</span>[<span class="bu">tuple</span>[<span class="bu">str</span>, <span class="bu">str</span>]], system_prompt: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate a formatted prompt for a LLaMA 3.1 chatbot conversation.</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">    This function takes the user's input, chat history, and system prompt,</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co">    and combines them into a single formatted string for use in a LLaMA 3.1 chatbot system.</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co">    user_input (str): The current input from the user.</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co">    chat_history (list[tuple[str, str]]): A list of tuples containing previous </span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co">                                          (user_input, assistant_response) pairs.</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co">    system_prompt (str): Initial instructions or context for the LLaMA 3.1 chatbot.</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="co">    str: A formatted string containing the entire conversation history and current input.</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start the prompt with a special token</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    prompt_texts <span class="op">=</span> [<span class="st">'&lt;|begin_of_text|&gt;'</span>]</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add system prompt if it's not empty</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> system_prompt <span class="op">!=</span> <span class="st">''</span>:</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        prompt_texts.append(<span class="ss">f'&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;</span><span class="ch">\n\n</span><span class="sc">{</span>system_prompt<span class="sc">}</span><span class="ss">&lt;|eot_id|&gt;'</span>)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add each pair of user input and assistant response from the chat history</span></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> history_input, history_response <span class="kw">in</span> chat_history:</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>        prompt_texts.append(<span class="ss">f'&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;</span><span class="ch">\n\n</span><span class="sc">{</span>history_input<span class="sc">.</span>strip()<span class="sc">}</span><span class="ss">&lt;|eot_id|&gt;'</span>)</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>        prompt_texts.append(<span class="ss">f'&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;</span><span class="ch">\n\n</span><span class="sc">{</span>history_response<span class="sc">.</span>strip()<span class="sc">}</span><span class="ss">&lt;|eot_id|&gt;'</span>)</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add the current user input and prepare for assistant's response</span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>    prompt_texts.append(<span class="ss">f'&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;</span><span class="ch">\n\n</span><span class="sc">{</span>user_input<span class="sc">.</span>strip()<span class="sc">}</span><span class="ss">&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;</span><span class="ch">\n\n</span><span class="ss">'</span>)</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Join all parts of the prompt into a single string</span></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>.join(prompt_texts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="load-the-model-in-int4" class="level3">
<h3 class="anchored" data-anchor-id="load-the-model-in-int4">Load the Model in INT4</h3>
<p>Next, we can load the LLaMA 3.1 8B Instruct model in 4-bit precision.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>You will need to accept Meta’s license agreement through the model’s HuggingFace Hub page to access the model:</p>
<ul>
<li><a href="https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct">meta-llama/Meta-Llama-3.1-8B-Instruct</a></li>
</ul>
</div>
</div>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"meta-llama/Meta-Llama-3.1-8B-Instruct"</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load model in 4 bit, which converts the relevant layers in the model into INT4 format</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(model_path,</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>                                             load_in_4bit<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>                                             optimize_model<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>                                             trust_remote_code<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>                                             use_cache<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.half().to(<span class="st">'xpu'</span>)</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Load tokenizer</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_path, trust_remote_code<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="define-inference-parameters" class="level3">
<h3 class="anchored" data-anchor-id="define-inference-parameters">Define Inference Parameters</h3>
<p>Before running the model, we must define our prompts and the maximum number of tokens the model should generate.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>DEFAULT_SYSTEM_PROMPT <span class="op">=</span> <span class="st">"""</span><span class="ch">\</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>prompt_str <span class="op">=</span> <span class="st">"Provide a clear, concise, and intuitive description of AI for beginners."</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>max_new_tokens <span class="op">=</span> <span class="dv">512</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="perform-inference" class="level3">
<h3 class="anchored" data-anchor-id="perform-inference">Perform Inference</h3>
<p>Finally, we can run the model.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Disable gradient computation for inference</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.inference_mode():</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate the input prompt using a custom function</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> get_prompt(prompt_str, [], system_prompt<span class="op">=</span>DEFAULT_SYSTEM_PROMPT)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Encode the prompt into token IDs and move to the XPU (Intel's GPU)</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> tokenizer.encode(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(<span class="st">'xpu'</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform a warmup run to optimize the model</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This run's output is discarded</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> model.generate(input_ids, max_new_tokens<span class="op">=</span>max_new_tokens)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start the actual inference</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    st <span class="op">=</span> time.time()  <span class="co"># Record the start time</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate the output using the language model</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> model.generate(input_ids, max_new_tokens<span class="op">=</span>max_new_tokens)</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure all XPU operations are completed before recording end time</span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>    torch.xpu.synchronize()</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>    end <span class="op">=</span> time.time()  <span class="co"># Record the end time</span></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Move the output back to CPU for further processing</span></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> output.cpu()</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Decode the output tokens into a human-readable string</span></span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># skip_special_tokens=False means we keep all special tokens in the output</span></span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>    output_str <span class="op">=</span> tokenizer.decode(output[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the inference time</span></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Inference time: </span><span class="sc">{</span>end<span class="op">-</span>st<span class="sc">:.2f}</span><span class="ss"> seconds'</span>)</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the original prompt</span></span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">20</span>, <span class="st">'Prompt'</span>, <span class="st">'-'</span><span class="op">*</span><span class="dv">20</span>)</span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(prompt)</span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the model's response</span></span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">20</span>, <span class="st">'Response (skip_special_tokens=False)'</span>, <span class="st">'-'</span><span class="op">*</span><span class="dv">20</span>)</span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the actual response from the output string</span></span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a><span class="co"># This assumes the response is between the last '&lt;|end_header_id|&gt;\n\n' and '&lt;|eot_id|&gt;'</span></span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> output_str.split(<span class="st">'&lt;|end_header_id|&gt;</span><span class="ch">\n\n</span><span class="st">'</span>)[<span class="op">-</span><span class="dv">1</span>].split(<span class="st">'&lt;|eot_id|&gt;'</span>)[<span class="dv">0</span>]</span>
<span id="cb36-44"><a href="#cb36-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-45"><a href="#cb36-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the response using Markdown formatting</span></span>
<span id="cb36-46"><a href="#cb36-46" aria-hidden="true" tabindex="-1"></a>Markdown(response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>Inference time: 51.17 seconds
-------------------- Prompt --------------------
&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;

Provide a clear, concise, and intuitive description of AI for beginners.&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;


-------------------- Response (skip_special_tokens=False) --------------------</code></pre>
<div class="callout callout-style-default callout-note callout-titled" title="Model Response:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Model Response:
</div>
</div>
<div class="callout-body-container callout-body">
<p>Here’s a clear, concise, and intuitive description of AI for beginners:</p>
<p><strong>What is AI?</strong></p>
<p>Artificial Intelligence (AI) is a type of computer technology that allows machines to think and learn like humans. It’s a way to create intelligent systems that can perform tasks that typically require human intelligence, such as:</p>
<ul>
<li>Recognizing images and objects</li>
<li>Understanding natural language</li>
<li>Making decisions</li>
<li>Solving problems</li>
<li>Learning from data</li>
</ul>
<p><strong>How does AI work?</strong></p>
<p>AI uses a combination of algorithms, data, and computer power to mimic human thought processes. Here’s a simplified overview:</p>
<ol type="1">
<li><strong>Data collection</strong>: Large amounts of data are gathered from various sources, such as images, text, or sensor readings.</li>
<li><strong>Pattern recognition</strong>: AI algorithms analyze the data to identify patterns, relationships, and trends.</li>
<li><strong>Machine learning</strong>: The AI system uses this analysis to make predictions, classify data, or make decisions.</li>
<li><strong>Improvement</strong>: The AI system learns from its experiences and adjusts its performance over time.</li>
</ol>
<p><strong>Types of AI</strong></p>
<p>There are several types of AI, including:</p>
<ul>
<li><strong>Narrow or Weak AI</strong>: Designed to perform a specific task, like facial recognition or language translation.</li>
<li><strong>Strong or General AI</strong>: A hypothetical AI that can perform any intellectual task that humans can.</li>
<li><strong>Superintelligence</strong>: A hypothetical AI that surpasses human intelligence in all domains.</li>
</ul>
<p><strong>Key benefits of AI</strong></p>
<p>AI has many benefits, including:</p>
<ul>
<li><strong>Improved efficiency</strong>: AI can automate repetitive tasks, freeing up human time for more complex and creative work.</li>
<li><strong>Enhanced decision-making</strong>: AI can analyze vast amounts of data to make informed decisions.</li>
<li><strong>Personalization</strong>: AI can tailor experiences to individual preferences and needs.</li>
</ul>
<p><strong>Key concepts</strong></p>
<p>Some key concepts to keep in mind:</p>
<ul>
<li><strong>Machine learning</strong>: A type of AI that improves over time based on data experience.</li>
<li><strong>Deep learning</strong>: A type of machine learning that uses neural networks to analyze complex data.</li>
<li><strong>Natural language processing</strong>: A type of AI that enables computers to understand and generate human-like language.</li>
</ul>
<p>That’s a basic introduction to AI for beginners! I hope this helps you understand the basics of this exciting and rapidly evolving field.</p>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we set up Intel’s PyTorch extension on Ubuntu to train an image classification model and run a local Large Language Model using an Arc GPU. The exact setup steps may change with new versions, so check the <a href="https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu&amp;version=v2.3.110%2bxpu&amp;os=linux%2fwsl2&amp;package=pip">documentation</a> for the latest version to see if there are any changes. I’ll try to keep this tutorial updated with any significant changes to the process.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Questions:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Questions:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Feel free to post questions or problems related to this tutorial in the comments below. I try to make time to address them on Thursdays and Fridays.</li>
</ul>
</div>
</div>
<hr>
<div class="callout callout-style-default callout-tip callout-titled" title="About Me:">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About Me:
</div>
</div>
<div class="callout-body-container callout-body">
<p>I’m Christian Mills, a deep learning consultant specializing in practical AI implementations. I help clients leverage cutting-edge AI technologies to solve real-world problems.</p>
<p>Interested in working together? Fill out my <a href="https://docs.google.com/forms/d/e/1FAIpQLScKDKPJF9Be47LA3nrEDXTVpzH2UMLz8SzHMHM9hWT5qlvjkw/viewform?usp=sf_link">Quick AI Project Assessment</a> form or learn more <a href="../../../about.html">about me</a>.</p>
</div>
</div>


</section>

</main> <!-- /main -->
<!-- Cloudflare Web Analytics --><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;56b8d2f624604c4891327b3c0d9f6703&quot;}"></script><!-- End Cloudflare Web Analytics -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/christianjmills\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="cj-mills/christianjmills" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
<p>Content licensed under CC BY-NC-SA 4.0</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
<p>© 2024 Christian J. Mills</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://opensource.org/licenses/MIT">
<p>Code samples licensed under the MIT License</p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>