<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.555">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Christian Mills">
<meta name="dcterms.date" content="2022-06-06">
<meta name="description" content="Train an image classifier using the fastai library and export it to ONNX.">

<title>Christian Mills - Fastai to Unity Beginner Tutorial Pt. 1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Christian Mills - Fastai to Unity Beginner Tutorial Pt. 1">
<meta property="og:description" content="Train an image classifier using the fastai library and export it to ONNX.">
<meta property="og:image" content="christianjmills.com/images/empty.gif">
<meta property="og:site_name" content="Christian Mills">
<meta name="twitter:title" content="Christian Mills - Fastai to Unity Beginner Tutorial Pt. 1">
<meta name="twitter:description" content="Train an image classifier using the fastai library and export it to ONNX.">
<meta name="twitter:image" content="christianjmills.com/images/empty.gif">
<meta name="twitter:creator" content="@cdotjdotmills">
<meta name="twitter:site" content="@cdotjdotmills">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Christian Mills</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/tutorials/index.html"> 
<span class="menu-text">Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../series/notes/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:christian@christianjmills.com"> <i class="bi bi-envelope-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cj-mills"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/christianjmills"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#install-dependencies" id="toc-install-dependencies" class="nav-link" data-scroll-target="#install-dependencies">Install Dependencies</a></li>
  <li><a href="#configure-kaggle-api" id="toc-configure-kaggle-api" class="nav-link" data-scroll-target="#configure-kaggle-api">Configure Kaggle API</a></li>
  <li><a href="#download-dataset" id="toc-download-dataset" class="nav-link" data-scroll-target="#download-dataset">Download Dataset</a></li>
  <li><a href="#inspect-dataset" id="toc-inspect-dataset" class="nav-link" data-scroll-target="#inspect-dataset">Inspect Dataset</a></li>
  <li><a href="#define-dataloaders" id="toc-define-dataloaders" class="nav-link" data-scroll-target="#define-dataloaders">Define Dataloaders</a></li>
  <li><a href="#define-learner" id="toc-define-learner" class="nav-link" data-scroll-target="#define-learner">Define Learner</a></li>
  <li><a href="#inspect-trained-model" id="toc-inspect-trained-model" class="nav-link" data-scroll-target="#inspect-trained-model">Inspect Trained Model</a></li>
  <li><a href="#implement-processing-steps" id="toc-implement-processing-steps" class="nav-link" data-scroll-target="#implement-processing-steps">Implement Processing Steps</a></li>
  <li><a href="#export-the-model" id="toc-export-the-model" class="nav-link" data-scroll-target="#export-the-model">Export the Model</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Fastai to Unity Beginner Tutorial Pt. 1</h1>
  <div class="quarto-categories">
    <div class="quarto-category">fastai</div>
    <div class="quarto-category">unity</div>
    <div class="quarto-category">barracuda</div>
    <div class="quarto-category">tutorial</div>
  </div>
  </div>

<div>
  <div class="description">
    Train an image classifier using the fastai library and export it to <a href="https://onnx.ai/">ONNX</a>.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Christian Mills </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 6, 2022</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#overview">Overview</a></li>
<li><a href="#install-dependencies">Install Dependencies</a></li>
<li><a href="#configure-kaggle-api">Configure Kaggle API</a></li>
<li><a href="#download-dataset">Download Dataset</a></li>
<li><a href="#inspect-dataset">Inspect Dataset</a></li>
<li><a href="#define-dataloaders">Define Dataloaders</a></li>
<li><a href="#define-learner">Define Learner</a></li>
<li><a href="#inspect-trained-model">Inspect Trained Model</a></li>
<li><a href="#implement-processing-steps">Implement Processing Steps</a></li>
<li><a href="#export-the-model">Export the Model</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In this tutorial series, we will walk through training an image classifier using the <a href="https://docs.fast.ai/">fastai library</a> and implementing it in a <a href="https://unity.com/">Unity</a> game engine project using the <a href="https://docs.unity3d.com/Packages/com.unity.barracuda@3.0/manual/index.html">Barracuda</a> inference library. Check out <a href="../../deep-learning-unity-intro/">this post</a> for more information about Barracuda. We will then build the Unity project to run in a web browser and host it using <a href="https://pages.github.com/">GitHub Pages</a>.</p>
<p>The tutorial uses this&nbsp;<a href="https://www.kaggle.com/datasets/belalelwikel/asl-and-some-words">American Sign Language (ASL) dataset</a>&nbsp;from Kaggle but feel free to follow along with a different dataset. The dataset contains sample images for digits 1-9, letters A-Z, and some common words. One could use a model trained on this dataset to map hand gestures to user input or make an ASL education game.</p>
<p><strong>In-Browser Demo:</strong> <a href="https://cj-mills.github.io/Fastai-ASL-Classification-WebGL-Demo/">ASL Classifier</a></p>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>Part 1 covers how to finetune a ResNet model for image classification using the fastai library and export it to ONNX format. The training code is available in the Jupyter notebook linked below, and links for running the notebook on Google Colab and Kaggle are below as well.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Jupyter Notebook</th>
<th>Colab</th>
<th>Kaggle</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/cj-mills/fastai-to-unity-tutorial/blob/main/notebooks/Fastai-to-Unity-Tutorial.ipynb">GitHub Repository</a></td>
<td><a href="https://colab.research.google.com/github/cj-mills/fastai-to-unity-tutorial/blob/main/notebooks/Fastai-to-Unity-Tutorial.ipynb">Open In Colab</a></td>
<td><a href="https://kaggle.com/kernels/welcome?src=https://github.com/cj-mills/fastai-to-unity-tutorial/blob/main/notebooks/Fastai-to-Unity-Tutorial.ipynb">Open in Kaggle</a></td>
</tr>
</tbody>
</table>
</section>
<section id="install-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="install-dependencies">Install Dependencies</h2>
<p>The training code requires <a href="https://pytorch.org/">PyTorch</a> for the fastai library, the fastai library itself for training, and the <a href="https://github.com/Kaggle/kaggle-api">Kaggle API Python package</a> for downloading the dataset. Google Colab uses an older version of <a href="https://pillow.readthedocs.io/en/stable/">Pillow</a>, so update that package when training there.</p>
<p><strong>Uncomment the cell below if running on Google Colab or Kaggle</strong></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %%capture</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U torch torchvision torchaudio</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U fastai</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U kaggle</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install -U Pillow</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Note for Colab:</strong> You must restart the runtime in order to use newly installed version of Pillow.</p>
<p><strong>Import all fastai computer vision functionality</strong></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="configure-kaggle-api" class="level2">
<h2 class="anchored" data-anchor-id="configure-kaggle-api">Configure Kaggle API</h2>
<p>The Kaggle API tool requires an API Key for a Kaggle account. Sign in or create a Kaggle account using the link below, then click the Create New API Token button.</p>
<ul>
<li><strong>Kaggle Account Settings:</strong> <a href="https://www.kaggle.com/me/account">https://www.kaggle.com/me/account</a></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/kaggle-create-new-api-token.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Kaggle will generate and download a <code>kaggle.json</code> file containing your username and new API token. Paste the values for each in the code cell below.</p>
<p><strong>Enter Kaggle username and API token</strong></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>creds <span class="op">=</span> <span class="st">'{"username":"","key":""}'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Save Kaggle credentials if none are present</strong> * <strong>Source:</strong> <a href="https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb">https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb</a></p>
<hr>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>cred_path <span class="op">=</span> Path(<span class="st">'~/.kaggle/kaggle.json'</span>).expanduser()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Save API key to a json file if it does not already exist</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> cred_path.exists():</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    cred_path.parent.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    cred_path.write_text(creds)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    cred_path.chmod(<span class="bn">0o600</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Import Kaggle API</strong></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> kaggle <span class="im">import</span> api</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>(Optional) Define method to display default function arguments</strong></p>
<p>The code cell below defines a method to display the default arguments for a specified function. It’s not required, but I find it convenient for creating quick references in notebooks.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> inspect</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'max_colwidth'</span>, <span class="va">None</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_rows'</span>, <span class="va">None</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="va">None</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> inspect_default_args(target, annotations: <span class="bu">bool</span><span class="op">=</span><span class="va">False</span>):</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the argument names</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    args <span class="op">=</span> inspect.getfullargspec(target).args</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the default values</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    defaults <span class="op">=</span> inspect.getfullargspec(target).defaults</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> [<span class="st">"Default Value"</span>]</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pad defaults</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    defaults <span class="op">=</span> [<span class="va">None</span>]<span class="op">*</span>(<span class="bu">len</span>(args)<span class="op">-</span><span class="bu">len</span>(defaults)) <span class="op">+</span> <span class="bu">list</span>(defaults)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> annotations:</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        index.append(<span class="st">"Annotation"</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        annotations <span class="op">=</span> inspect.getfullargspec(target).annotations.values()</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pad annotations</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        annotations <span class="op">=</span> [<span class="va">None</span>]<span class="op">*</span>(<span class="bu">len</span>(args)<span class="op">-</span><span class="bu">len</span>(annotations)) <span class="op">+</span> <span class="bu">list</span>(annotations)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        default_args <span class="op">=</span> {arg:[df, annot] <span class="cf">for</span> arg,df,annot <span class="kw">in</span> <span class="bu">zip</span>(args, defaults, annotations)}</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>        default_args <span class="op">=</span> {arg:[default] <span class="cf">for</span> arg,default <span class="kw">in</span> <span class="bu">zip</span>(args, defaults)}</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(default_args, index<span class="op">=</span>index).T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="download-dataset" class="level2">
<h2 class="anchored" data-anchor-id="download-dataset">Download Dataset</h2>
<p>Now that we have our Kaggle credentials set, we need to define the dataset and where to store it.</p>
<p><strong>Define path to dataset</strong></p>
<p>We’ll use the default archive and data folders for the fastai library to store the compressed and uncompressed datasets.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>kaggle_dataset <span class="op">=</span> <span class="st">'belalelwikel/asl-and-some-words'</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>archive_dir <span class="op">=</span> URLs.path()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>dataset_dir <span class="op">=</span> archive_dir<span class="op">/</span><span class="st">'../data'</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>dataset_name <span class="op">=</span> <span class="st">'asl-and-some-words'</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>archive_path <span class="op">=</span> Path(<span class="ss">f'</span><span class="sc">{</span>archive_dir<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">.zip'</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>dataset_path <span class="op">=</span> Path(<span class="ss">f'</span><span class="sc">{</span>dataset_dir<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define method to extract the dataset from an archive file</strong></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> file_extract(fname, dest<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Extract `fname` to `dest` using `tarfile` or `zipfile`."</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dest <span class="kw">is</span> <span class="va">None</span>: dest <span class="op">=</span> Path(fname).parent</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    fname <span class="op">=</span> <span class="bu">str</span>(fname)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>   fname.endswith(<span class="st">'gz'</span>):  tarfile.<span class="bu">open</span>(fname, <span class="st">'r:gz'</span>).extractall(dest)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> fname.endswith(<span class="st">'zip'</span>): zipfile.ZipFile(fname     ).extractall(dest)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: <span class="cf">raise</span> <span class="pp">Exception</span>(<span class="ss">f'Unrecognized archive: </span><span class="sc">{</span>fname<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Download the dataset if it is not present</strong></p>
<p>The archive file is over 2GB, so we don’t want to download it more than necessary.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> archive_path.exists():</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    api.dataset_download_cli(kaggle_dataset, path<span class="op">=</span>archive_dir)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    file_extract(fname<span class="op">=</span>archive_path, dest<span class="op">=</span>dataset_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="inspect-dataset" class="level2">
<h2 class="anchored" data-anchor-id="inspect-dataset">Inspect Dataset</h2>
<p>We can start inspecting the dataset once it finishes downloading.</p>
<p><strong>Inspect the dataset path</strong></p>
<p>The training data is in a subfolder named ASL, and there are over 200,000 samples.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>dataset_path.ls()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    (#1) [Path('/home/innom-dt/.fastai/archive/../data/asl-and-some-words/ASL')]</code></pre>
<p><strong>Get image file paths</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>files <span class="op">=</span> get_image_files(dataset_path<span class="op">/</span><span class="st">"ASL"</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(files)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    203000</code></pre>
<p><strong>Inspect files</strong></p>
<p>The dataset indicates the object class in both the folder and file names.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>files[<span class="dv">0</span>], files[<span class="op">-</span><span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    (Path('/home/innom-dt/.fastai/archive/../data/asl-and-some-words/ASL/J/J1491.jpg'),
     Path('/home/innom-dt/.fastai/archive/../data/asl-and-some-words/ASL/E/E1063.jpg'))</code></pre>
<p><strong>Inspect class folder names</strong></p>
<p>There are 51 class folders, and the dataset does not predefine a training-validation split.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>folder_names <span class="op">=</span> [path.name <span class="cf">for</span> path <span class="kw">in</span> Path(dataset_path<span class="op">/</span><span class="st">'ASL'</span>).ls()]</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>folder_names.sort()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Num classes: </span><span class="sc">{</span><span class="bu">len</span>(folder_names)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(folder_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Num classes: 51</code></pre>
<div style="overflow-x:auto; overflow-y: auto; max-height:500px">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
3
</td>
</tr>
<tr>
<th>
2
</th>
<td>
4
</td>
</tr>
<tr>
<th>
3
</th>
<td>
5
</td>
</tr>
<tr>
<th>
4
</th>
<td>
7
</td>
</tr>
<tr>
<th>
5
</th>
<td>
8
</td>
</tr>
<tr>
<th>
6
</th>
<td>
9
</td>
</tr>
<tr>
<th>
7
</th>
<td>
A
</td>
</tr>
<tr>
<th>
8
</th>
<td>
B
</td>
</tr>
<tr>
<th>
9
</th>
<td>
Baby
</td>
</tr>
<tr>
<th>
10
</th>
<td>
Brother
</td>
</tr>
<tr>
<th>
11
</th>
<td>
C
</td>
</tr>
<tr>
<th>
12
</th>
<td>
D
</td>
</tr>
<tr>
<th>
13
</th>
<td>
Dont_like
</td>
</tr>
<tr>
<th>
14
</th>
<td>
E
</td>
</tr>
<tr>
<th>
15
</th>
<td>
F
</td>
</tr>
<tr>
<th>
16
</th>
<td>
Friend
</td>
</tr>
<tr>
<th>
17
</th>
<td>
G
</td>
</tr>
<tr>
<th>
18
</th>
<td>
H
</td>
</tr>
<tr>
<th>
19
</th>
<td>
Help
</td>
</tr>
<tr>
<th>
20
</th>
<td>
House
</td>
</tr>
<tr>
<th>
21
</th>
<td>
I
</td>
</tr>
<tr>
<th>
22
</th>
<td>
J
</td>
</tr>
<tr>
<th>
23
</th>
<td>
K
</td>
</tr>
<tr>
<th>
24
</th>
<td>
L
</td>
</tr>
<tr>
<th>
25
</th>
<td>
Like
</td>
</tr>
<tr>
<th>
26
</th>
<td>
Love
</td>
</tr>
<tr>
<th>
27
</th>
<td>
M
</td>
</tr>
<tr>
<th>
28
</th>
<td>
Make
</td>
</tr>
<tr>
<th>
29
</th>
<td>
More
</td>
</tr>
<tr>
<th>
30
</th>
<td>
N
</td>
</tr>
<tr>
<th>
31
</th>
<td>
Name
</td>
</tr>
<tr>
<th>
32
</th>
<td>
No
</td>
</tr>
<tr>
<th>
33
</th>
<td>
O_OR_0
</td>
</tr>
<tr>
<th>
34
</th>
<td>
P
</td>
</tr>
<tr>
<th>
35
</th>
<td>
Pay
</td>
</tr>
<tr>
<th>
36
</th>
<td>
Play
</td>
</tr>
<tr>
<th>
37
</th>
<td>
Q
</td>
</tr>
<tr>
<th>
38
</th>
<td>
R
</td>
</tr>
<tr>
<th>
39
</th>
<td>
S
</td>
</tr>
<tr>
<th>
40
</th>
<td>
Stop
</td>
</tr>
<tr>
<th>
41
</th>
<td>
T
</td>
</tr>
<tr>
<th>
42
</th>
<td>
U
</td>
</tr>
<tr>
<th>
43
</th>
<td>
V_OR_2
</td>
</tr>
<tr>
<th>
44
</th>
<td>
W_OR_6
</td>
</tr>
<tr>
<th>
45
</th>
<td>
With
</td>
</tr>
<tr>
<th>
46
</th>
<td>
X
</td>
</tr>
<tr>
<th>
47
</th>
<td>
Y
</td>
</tr>
<tr>
<th>
48
</th>
<td>
Yes
</td>
</tr>
<tr>
<th>
49
</th>
<td>
Z
</td>
</tr>
<tr>
<th>
50
</th>
<td>
nothing
</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Inspect one of the training images</strong></p>
<p>The sample images all have a resolution of 200x200.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> PIL.Image.<span class="bu">open</span>(files[<span class="dv">0</span>])</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Image Dims: </span><span class="sc">{</span>img<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Image Dims: (200, 200)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_28_1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="define-dataloaders" class="level2">
<h2 class="anchored" data-anchor-id="define-dataloaders">Define Dataloaders</h2>
<p>Next, we need to define the <a href="https://docs.fast.ai/vision.augment.html">Transforms</a> for the <a href="https://docs.fast.ai/vision.data.html#ImageDataLoaders">DataLoaders</a> object.</p>
<p><strong>Define target input dimensions</strong></p>
<p>The Unity project will take input from a webcam, and most webcams don’t have a square aspect ratio like the training samples. We will need to account for this to get more accurate predictions.</p>
<p>We can train with a square aspect ratio and crop the webcam input in Unity, but that might make users feel cramped when using the application.</p>
<p>Alternatively, we can expand the training images to a more typical aspect ratio like 4:3 or 16:9. This approach will allow us to use the entire webcam input, so we’ll go with this one.</p>
<p>I have a <a href="../../crop-images-on-gpu-tutorial/">separate tutorial</a> for cropping images on the GPU in Unity for anyone that wants to try the other approach.</p>
<p>Below are some sample input dimensions in different aspect ratios.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># size_1_1 = (224, 224)</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># size_3_2 = (224, 336)</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># size_4_3 = (216, 288)</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>size_16_9 <span class="op">=</span> (<span class="dv">216</span>, <span class="dv">384</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># size_16_9_l = (288, 512)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define Transforms</strong></p>
<p>Something else to consider is that the webcam input in Unity mirrors the actual image. Mirrored input would likely not be an issue for something like a pet classifier, but hand orientation matters for ASL. We either need to flip the input image each time in Unity, or we can train the model with pre-flipped images. It is easier to mirror the training images, so we’ll use the <a href="https://docs.fast.ai/vision.augment.html#FlipItem">FlipItem</a> transform with a probability of 1.0 to flip every training sample.</p>
<p>I have a <a href="../../flip-image-compute-shader-tutorial/">separate tutorial</a> covering how to flip images on the GPU in Unity for anyone that wants to try that approach.</p>
<p>Since we are resizing to a different aspect ratio, we need to choose a padding method. The default reflection padding might add more fingers, changing an image’s meaning. The zeros padding option might work, but most user backgrounds will not be pure black. Therefore, we’ll go with border padding.</p>
<p>We can add some batch transforms like tweaking the contrast, saturation, hue, zoom, brightness, and warping to help crappify the images. However, we need to disable the <code>do_flip</code> and <code>max_rotate</code> options in <code>aug_transforms</code>.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>inspect_default_args(aug_transforms)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; overflow-y:auto">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Default Value
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
mult
</th>
<td>
1.0
</td>
</tr>
<tr>
<th>
do_flip
</th>
<td>
True
</td>
</tr>
<tr>
<th>
flip_vert
</th>
<td>
False
</td>
</tr>
<tr>
<th>
max_rotate
</th>
<td>
10.0
</td>
</tr>
<tr>
<th>
min_zoom
</th>
<td>
1.0
</td>
</tr>
<tr>
<th>
max_zoom
</th>
<td>
1.1
</td>
</tr>
<tr>
<th>
max_lighting
</th>
<td>
0.2
</td>
</tr>
<tr>
<th>
max_warp
</th>
<td>
0.2
</td>
</tr>
<tr>
<th>
p_affine
</th>
<td>
0.75
</td>
</tr>
<tr>
<th>
p_lighting
</th>
<td>
0.75
</td>
</tr>
<tr>
<th>
xtra_tfms
</th>
<td>
None
</td>
</tr>
<tr>
<th>
size
</th>
<td>
None
</td>
</tr>
<tr>
<th>
mode
</th>
<td>
bilinear
</td>
</tr>
<tr>
<th>
pad_mode
</th>
<td>
reflection
</td>
</tr>
<tr>
<th>
align_corners
</th>
<td>
True
</td>
</tr>
<tr>
<th>
batch
</th>
<td>
False
</td>
</tr>
<tr>
<th>
min_scale
</th>
<td>
1.0
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>item_tfms <span class="op">=</span> [FlipItem(p<span class="op">=</span><span class="fl">1.0</span>), Resize(size_16_9, method<span class="op">=</span>ResizeMethod.Pad, pad_mode<span class="op">=</span>PadMode.Border)]</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>batch_tfms <span class="op">=</span> [</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    Contrast(max_lighting<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    Saturation(max_lighting<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    Hue(max_hue<span class="op">=</span><span class="fl">0.05</span>),</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">*</span>aug_transforms(</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        size<span class="op">=</span>size_16_9, </span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        mult<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>        do_flip<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        flip_vert<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        max_rotate<span class="op">=</span><span class="fl">0.0</span>,</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>        min_zoom<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>        max_zoom<span class="op">=</span><span class="fl">1.5</span>,</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>        max_lighting<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>        max_warp<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>        p_affine<span class="op">=</span><span class="fl">0.0</span>,</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>        pad_mode<span class="op">=</span>PadMode.Border)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define batch size</strong></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>bs <span class="op">=</span> <span class="dv">128</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define DataLoaders object</strong></p>
<p>We can use the <a href="https://docs.fast.ai/vision.data.html#ImageDataLoaders.from_folder">from_folder</a> method to instantiate the DataLoaders object.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>inspect_default_args(ImageDataLoaders.from_folder)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; overflow-y:auto">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Default Value
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
cls
</th>
<td>
None
</td>
</tr>
<tr>
<th>
path
</th>
<td>
None
</td>
</tr>
<tr>
<th>
train
</th>
<td>
train
</td>
</tr>
<tr>
<th>
valid
</th>
<td>
valid
</td>
</tr>
<tr>
<th>
valid_pct
</th>
<td>
None
</td>
</tr>
<tr>
<th>
seed
</th>
<td>
None
</td>
</tr>
<tr>
<th>
vocab
</th>
<td>
None
</td>
</tr>
<tr>
<th>
item_tfms
</th>
<td>
None
</td>
</tr>
<tr>
<th>
batch_tfms
</th>
<td>
None
</td>
</tr>
<tr>
<th>
bs
</th>
<td>
64
</td>
</tr>
<tr>
<th>
val_bs
</th>
<td>
None
</td>
</tr>
<tr>
<th>
shuffle
</th>
<td>
True
</td>
</tr>
<tr>
<th>
device
</th>
<td>
None
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> ImageDataLoaders.from_folder(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    path<span class="op">=</span>dataset_path<span class="op">/</span><span class="st">'ASL'</span>, </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    valid_pct<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    bs<span class="op">=</span>bs, </span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    item_tfms<span class="op">=</span>item_tfms, </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    batch_tfms<span class="op">=</span>batch_tfms</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Verify DataLoaders object</strong></p>
<p>Let’s verify the DataLoaders object works as expected before training a model.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>dls.train.show_batch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_40_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We can see that the DataLoaders object applies the transforms to the training split, including mirroring the image. However, it does not appear to mirror images from the validation split.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>dls.valid.show_batch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_41_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We can get around this by using a solution provided on the <a href="https://forums.fast.ai/t/how-to-apply-aug-transforms-to-validation-set-while-training/79417/10?u=cjmills">fastai forums</a> to apply the training split transforms to the validation split. It is not strictly necessary to mirror the validation split, but the accuracy metrics would be confusing during training without it.</p>
<p><strong>Apply training split transforms to validation split</strong></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> dls.valid.dataset.set_split_idx(<span class="dv">0</span>): dls[<span class="dv">1</span>].show_batch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_43_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="define-learner" class="level2">
<h2 class="anchored" data-anchor-id="define-learner">Define Learner</h2>
<p>Now we need to define the Learner object for training the model.</p>
<p><strong>Inspect Learner parameters</strong></p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>inspect_default_args(vision_learner)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; overflow-y:auto">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Default Value
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
dls
</th>
<td>
None
</td>
</tr>
<tr>
<th>
arch
</th>
<td>
None
</td>
</tr>
<tr>
<th>
normalize
</th>
<td>
True
</td>
</tr>
<tr>
<th>
n_out
</th>
<td>
None
</td>
</tr>
<tr>
<th>
pretrained
</th>
<td>
True
</td>
</tr>
<tr>
<th>
loss_func
</th>
<td>
None
</td>
</tr>
<tr>
<th>
opt_func
</th>
<td>
&lt;function Adam at 0x7fa5e274a560&gt;
</td>
</tr>
<tr>
<th>
lr
</th>
<td>
0.001
</td>
</tr>
<tr>
<th>
splitter
</th>
<td>
None
</td>
</tr>
<tr>
<th>
cbs
</th>
<td>
None
</td>
</tr>
<tr>
<th>
metrics
</th>
<td>
None
</td>
</tr>
<tr>
<th>
path
</th>
<td>
None
</td>
</tr>
<tr>
<th>
model_dir
</th>
<td>
models
</td>
</tr>
<tr>
<th>
wd
</th>
<td>
None
</td>
</tr>
<tr>
<th>
wd_bn_bias
</th>
<td>
False
</td>
</tr>
<tr>
<th>
train_bn
</th>
<td>
True
</td>
</tr>
<tr>
<th>
moms
</th>
<td>
(0.95, 0.85, 0.95)
</td>
</tr>
<tr>
<th>
cut
</th>
<td>
None
</td>
</tr>
<tr>
<th>
n_in
</th>
<td>
3
</td>
</tr>
<tr>
<th>
init
</th>
<td>
&lt;function kaiming_normal_ at 0x7fa60b397be0&gt;
</td>
</tr>
<tr>
<th>
custom_head
</th>
<td>
None
</td>
</tr>
<tr>
<th>
concat_pool
</th>
<td>
True
</td>
</tr>
<tr>
<th>
lin_ftrs
</th>
<td>
None
</td>
</tr>
<tr>
<th>
ps
</th>
<td>
0.5
</td>
</tr>
<tr>
<th>
pool
</th>
<td>
True
</td>
</tr>
<tr>
<th>
first_bn
</th>
<td>
True
</td>
</tr>
<tr>
<th>
bn_final
</th>
<td>
False
</td>
</tr>
<tr>
<th>
lin_first
</th>
<td>
False
</td>
</tr>
<tr>
<th>
y_range
</th>
<td>
None
</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Define model</strong></p>
<p>I recommend sticking with a ResNet18 or ResNet34 model, as the larger models can significantly lower frame rates.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> resnet18</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define <a href="https://docs.fast.ai/metrics.html">metrics</a></strong></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [error_rate, accuracy]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define Learner object</strong></p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, model, metrics<span class="op">=</span>metrics).to_fp16()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Find learning rate</strong></p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>inspect_default_args(learn.lr_find)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; overflow-y:auto">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Default Value
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
self
</th>
<td>
None
</td>
</tr>
<tr>
<th>
start_lr
</th>
<td>
0.0
</td>
</tr>
<tr>
<th>
end_lr
</th>
<td>
10
</td>
</tr>
<tr>
<th>
num_it
</th>
<td>
100
</td>
</tr>
<tr>
<th>
stop_div
</th>
<td>
True
</td>
</tr>
<tr>
<th>
show_plot
</th>
<td>
True
</td>
</tr>
<tr>
<th>
suggest_funcs
</th>
<td>
&lt;function valley at 0x7fa5e24996c0&gt;
</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Define <a href="https://docs.fast.ai/callback.schedule.html#Suggestion-Methods">suggestion methods</a></strong></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>suggest_funcs <span class="op">=</span> [valley, minimum, steep]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> dls.valid.dataset.set_split_idx(<span class="dv">0</span>): learn.lr_find(suggest_funcs<span class="op">=</span>suggest_funcs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_56_2.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p><strong>Define learning rate</strong></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">2e-3</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>lr</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    0.002</code></pre>
<p><strong>Define number of epochs</strong></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Fine tune model</strong></p>
<p>After picking a learning rate, we can train the model for a few epochs. Training can take a while on Google Colab and Kaggle.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>inspect_default_args(learn.fine_tune)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; overflow-y:auto">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
</th>
<th>
Default Value
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
self
</th>
<td>
None
</td>
</tr>
<tr>
<th>
epochs
</th>
<td>
None
</td>
</tr>
<tr>
<th>
base_lr
</th>
<td>
0.002
</td>
</tr>
<tr>
<th>
freeze_epochs
</th>
<td>
1
</td>
</tr>
<tr>
<th>
lr_mult
</th>
<td>
100
</td>
</tr>
<tr>
<th>
pct_start
</th>
<td>
0.3
</td>
</tr>
<tr>
<th>
div
</th>
<td>
5.0
</td>
</tr>
<tr>
<th>
lr_max
</th>
<td>
None
</td>
</tr>
<tr>
<th>
div_final
</th>
<td>
100000.0
</td>
</tr>
<tr>
<th>
wd
</th>
<td>
None
</td>
</tr>
<tr>
<th>
moms
</th>
<td>
None
</td>
</tr>
<tr>
<th>
cbs
</th>
<td>
None
</td>
</tr>
<tr>
<th>
reset_opt
</th>
<td>
False
</td>
</tr>
</tbody>
</table>
</div>
<hr>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> dls.valid.dataset.set_split_idx(<span class="dv">0</span>): learn.fine_tune(epochs, base_lr<span class="op">=</span>lr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="overflow-x:auto; overflow-y:auto">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
epoch
</th>
<th>
train_loss
</th>
<th>
valid_loss
</th>
<th>
error_rate
</th>
<th>
accuracy
</th>
<th>
time
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
0
</td>
<td>
0.365705
</td>
<td>
0.175888
</td>
<td>
0.056305
</td>
<td>
0.943695
</td>
<td>
04:52
</td>
</tr>
</tbody>
</table>
</div>
<div style="overflow-x:auto; overflow-y:auto">
<table class="dataframe table table-sm table-striped small">
<thead>
<tr>
<th>
epoch
</th>
<th>
train_loss
</th>
<th>
valid_loss
</th>
<th>
error_rate
</th>
<th>
accuracy
</th>
<th>
time
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
0
</td>
<td>
0.038334
</td>
<td>
0.021014
</td>
<td>
0.008103
</td>
<td>
0.991897
</td>
<td>
04:56
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0.012614
</td>
<td>
0.011383
</td>
<td>
0.004236
</td>
<td>
0.995764
</td>
<td>
04:59
</td>
</tr>
<tr>
<td>
2
</td>
<td>
0.006508
</td>
<td>
0.006591
</td>
<td>
0.003325
</td>
<td>
0.996675
</td>
<td>
04:55
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inspect-trained-model" class="level2">
<h2 class="anchored" data-anchor-id="inspect-trained-model">Inspect Trained Model</h2>
<p>Once the model finishes training, we can test it on a sample image and see where it struggles.</p>
<p><strong>Select a test image</strong></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>test_file <span class="op">=</span> files[<span class="dv">0</span>]</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>test_file.name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    'J1491.jpg'</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>test_img <span class="op">=</span> PIL.Image.<span class="bu">open</span>(test_file)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>test_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_67_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p><strong>Make a prediction on a single image using a <a href="https://docs.fast.ai/vision.core.html#PILImage">fastai.vision.core.PILImage</a></strong></p>
<p>Remember that we need to flip the test image before feeding it to the model.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>learn.predict(PILImage(test_img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    ('J',
     TensorBase(22),
     TensorBase([9.6170e-14, 7.7060e-13, 2.5787e-13, 1.1222e-13, 1.5709e-10, 3.6805e-11,
             1.7642e-11, 2.3571e-13, 3.5861e-15, 9.8273e-13, 4.1524e-14, 1.3218e-12,
             7.3592e-14, 3.8404e-14, 4.9230e-12, 8.4399e-12, 2.0167e-11, 3.2757e-13,
             4.0114e-10, 2.3624e-11, 8.3717e-14, 1.9143e-07, 1.0000e+00, 9.7685e-14,
             9.4480e-15, 3.3952e-15, 9.4246e-12, 2.3079e-12, 1.6612e-15, 6.6745e-14,
             3.9778e-14, 2.2675e-11, 1.7859e-14, 1.7659e-11, 5.1701e-11, 8.4209e-14,
             4.6891e-11, 1.3487e-11, 1.0827e-11, 1.0881e-10, 2.6260e-09, 4.2682e-13,
             3.1842e-13, 7.4326e-13, 4.8983e-13, 2.0801e-13, 9.1052e-14, 1.0467e-08,
             2.3752e-14, 1.0124e-09, 6.7431e-11]))</code></pre>
<p><strong>Make predictions for a group of images</strong></p>
<div class="sourceCode" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> dls.valid.dataset.set_split_idx(<span class="dv">0</span>): learn.show_results()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_71_2.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p><strong>Define an Interpretation object</strong></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> dls.valid.dataset.set_split_idx(<span class="dv">0</span>): interp <span class="op">=</span> Interpretation.from_learner(learn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Plot top losses</strong></p>
<div class="sourceCode" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> dls.valid.dataset.set_split_idx(<span class="dv">0</span>): interp.plot_top_losses(k<span class="op">=</span><span class="dv">9</span>, figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_75_2.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="implement-processing-steps" class="level2">
<h2 class="anchored" data-anchor-id="implement-processing-steps">Implement Processing Steps</h2>
<p>When we are satisfied with the model, we can start preparing for implementing it in Unity. We will need to apply the same preprocessing and post-processing in Unity that fastai applies automatically. We will verify we understand the processing steps by implementing them in Python first.</p>
<p><strong>Inspect the <code>after_item</code> pipeline</strong></p>
<p>We don’t need to worry about flipping or padding the image in Unity with the current training approach.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>learn.dls.after_item</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Pipeline: FlipItem -- {'p': 1.0} -&gt; Resize -- {'size': (384, 216), 'method': 'pad', 'pad_mode': 'border', 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, 0), 'p': 1.0} -&gt; ToTensor</code></pre>
<p><strong>Inspect the <code>after_batch</code> pipeline</strong></p>
<p>The <code>after_batch</code> pipeline first scales the image color channel values from <span class="math inline">\([0,255]\)</span> to <span class="math inline">\([0,1]\)</span>. Unity already uses the range <span class="math inline">\([0,1]\)</span>, so we don’t need to implement this step. We also don’t need to implement any of the image augmentations. However, we do need to normalize the image using the ImageNet stats.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>learn.dls.after_batch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -&gt; Warp -- {'magnitude': 0.2, 'p': 1.0, 'draw_x': None, 'draw_y': None, 'size': (216, 384), 'mode': 'bilinear', 'pad_mode': 'border', 'batch': False, 'align_corners': True, 'mode_mask': 'nearest'} -&gt; Contrast -- {'max_lighting': 0.25, 'p': 1.0, 'draw': None, 'batch': False} -&gt; Saturation -- {'max_lighting': 0.25, 'p': 1.0, 'draw': None, 'batch': False} -&gt; Hue -- {'p': 1.0} -&gt; Brightness -- {'max_lighting': 0.5, 'p': 1.0, 'draw': None, 'batch': False} -&gt; Normalize -- {'mean': tensor([[[[0.4850]],
    
             [[0.4560]],
    
             [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],
    
             [[0.2240]],
    
             [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}</code></pre>
<p><strong>Reset test image</strong></p>
<div class="sourceCode" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>test_img <span class="op">=</span> PIL.Image.<span class="bu">open</span>(test_file)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>test_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_81_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>test_img <span class="op">=</span> test_img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>test_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_82_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>test_img.size</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    (200, 200)</code></pre>
<hr>
<div class="sourceCode" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="bu">min</span>(test_img.size)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    200</code></pre>
<hr>
<div class="sourceCode" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>min_dim <span class="op">=</span> test_img.size.index(<span class="bu">min</span>(test_img.size))</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>max_dim <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> min_dim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>target_dim <span class="op">=</span> <span class="dv">224</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Set input dims</strong></p>
<div class="sourceCode" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>inp_dims <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">0</span>]</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>inp_dims[min_dim] <span class="op">=</span> target_dim</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>inp_dims[max_dim] <span class="op">=</span> <span class="bu">int</span>(test_img.size[max_dim] <span class="op">/</span> (test_img.size[min_dim]<span class="op">/</span>target_dim))</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>inp_dims</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    [224, 224]</code></pre>
<hr>
<div class="sourceCode" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>resized_img <span class="op">=</span> test_img.resize(inp_dims)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>resized_img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/output_89_0.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p><strong>Convert image to tensor</strong></p>
<div class="sourceCode" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>img_tensor <span class="op">=</span> tensor(resized_img).permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>img_tensor.shape, img_tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    (torch.Size([3, 224, 224]),
     tensor([[[  0,   0,   0,  ...,   1,   0,   0],
              [  0,   4,   2,  ...,   9,   2,   0],
              [  5,  82,  99,  ...,  74,   8,   0],
              ...,
              [  3, 127, 154,  ..., 141,   0,   3],
              [  3, 102, 125,  ..., 120,   0,   0],
              [  0,   0,   4,  ...,   0,   1,   0]],
     
             [[  4,   1,   2,  ...,   0,   2,   5],
              [  2,   1,   0,  ...,   0,   0,   5],
              [  0,  75,  91,  ...,  63,   1,   1],
              ...,
              [  3, 126, 150,  ..., 151,   0,   0],
              [  7, 105, 122,  ..., 127,   1,   0],
              [  8,   5,   3,  ...,   4,   6,   2]],
     
             [[253, 254, 255,  ..., 253, 255, 254],
              [244, 220, 199,  ..., 209, 237, 255],
              [212, 222, 180,  ..., 188, 211, 251],
              ...,
              [196, 225, 171,  ..., 238, 204, 255],
              [207, 247, 222,  ..., 242, 218, 255],
              [223, 203, 193,  ..., 219, 247, 254]]], dtype=torch.uint8))</code></pre>
<p><strong>Scale tensor values</strong></p>
<div class="sourceCode" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>scaled_tensor <span class="op">=</span> img_tensor.<span class="bu">float</span>().div_(<span class="dv">255</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Prepare imagenet mean values</strong></p>
<div class="sourceCode" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>mean_tensor <span class="op">=</span> tensor(imagenet_stats[<span class="dv">0</span>]).view(<span class="dv">1</span>,<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>).permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>mean_tensor.shape, mean_tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    (torch.Size([3, 1, 1]),
     tensor([[[0.4850]],
     
             [[0.4560]],
     
             [[0.4060]]]))</code></pre>
<p><strong>Prepare imagenet std values</strong></p>
<div class="sourceCode" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>std_tensor <span class="op">=</span> tensor(imagenet_stats[<span class="dv">1</span>]).view(<span class="dv">1</span>,<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>).permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>std_tensor.shape, std_tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    (torch.Size([3, 1, 1]),
     tensor([[[0.2290]],
     
             [[0.2240]],
     
             [[0.2250]]]))</code></pre>
<p><strong>Normalize and batch image tensor</strong></p>
<div class="sourceCode" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>normalized_tensor <span class="op">=</span> (scaled_tensor <span class="op">-</span> mean_tensor) <span class="op">/</span> std_tensor</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>batched_tensor <span class="op">=</span> normalized_tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>batched_tensor.shape, batched_tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    (torch.Size([1, 3, 224, 224]),
     tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1008, -2.1179, -2.1179],
               [-2.1179, -2.0494, -2.0837,  ..., -1.9638, -2.0837, -2.1179],
               [-2.0323, -0.7137, -0.4226,  ..., -0.8507, -1.9809, -2.1179],
               ...,
               [-2.0665,  0.0569,  0.5193,  ...,  0.2967, -2.1179, -2.0665],
               [-2.0665, -0.3712,  0.0227,  ..., -0.0629, -2.1179, -2.1179],
               [-2.1179, -2.1179, -2.0494,  ..., -2.1179, -2.1008, -2.1179]],
     
              [[-1.9657, -2.0182, -2.0007,  ..., -2.0357, -2.0007, -1.9482],
               [-2.0007, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -1.9482],
               [-2.0357, -0.7227, -0.4426,  ..., -0.9328, -2.0182, -2.0182],
               ...,
               [-1.9832,  0.1702,  0.5903,  ...,  0.6078, -2.0357, -2.0357],
               [-1.9132, -0.1975,  0.1001,  ...,  0.1877, -2.0182, -2.0357],
               [-1.8957, -1.9482, -1.9832,  ..., -1.9657, -1.9307, -2.0007]],
     
              [[ 2.6051,  2.6226,  2.6400,  ...,  2.6051,  2.6400,  2.6226],
               [ 2.4483,  2.0300,  1.6640,  ...,  1.8383,  2.3263,  2.6400],
               [ 1.8905,  2.0648,  1.3328,  ...,  1.4722,  1.8731,  2.5703],
               ...,
               [ 1.6117,  2.1171,  1.1759,  ...,  2.3437,  1.7511,  2.6400],
               [ 1.8034,  2.5006,  2.0648,  ...,  2.4134,  1.9951,  2.6400],
               [ 2.0823,  1.7337,  1.5594,  ...,  2.0125,  2.5006,  2.6226]]]]))</code></pre>
<p><strong>Pass tensor to model</strong></p>
<div class="sourceCode" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> learn.model(batched_tensor.cuda())</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>preds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    TensorBase([[-4.9931e+00, -1.9711e+00, -3.3677e+00, -3.0452e+00,  3.9567e+00,
              3.9293e+00,  3.1657e+00, -5.3549e+00, -7.9026e+00, -1.5491e+00,
             -2.4086e+00, -2.6251e+00, -4.0321e+00, -7.3666e+00, -1.0557e+00,
             -3.2344e-01,  4.7887e+00, -4.8819e+00,  6.5188e+00,  1.1152e+00,
             -5.9519e-01,  1.1730e+01,  3.0779e+01, -4.4505e+00, -1.0000e+01,
             -9.1124e+00, -3.7176e-01, -4.2437e+00, -8.6924e+00, -1.5119e+00,
             -8.4118e+00,  9.1559e-01, -7.6669e+00,  1.7187e+00,  2.0639e+00,
             -4.0788e+00,  9.0079e+00, -2.8547e-02,  1.1223e+00, -3.2541e-02,
              8.9209e+00, -4.2307e+00, -3.6343e+00, -9.8461e-01, -4.2557e+00,
             -2.2238e+00, -5.9167e+00,  7.0386e+00, -7.7322e+00,  4.3321e+00,
             -3.1247e-01]], device='cuda:0')</code></pre>
<p><strong>Process model output</strong></p>
<div class="sourceCode" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>torch.nn.functional.softmax(preds, dim<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    TensorBase([[2.9133e-16, 5.9815e-15, 1.4800e-15, 2.0433e-15, 2.2450e-12, 2.1844e-12,
             1.0179e-12, 2.0287e-16, 1.5878e-17, 9.1219e-15, 3.8617e-15, 3.1101e-15,
             7.6160e-16, 2.7138e-17, 1.4940e-14, 3.1072e-14, 5.1585e-12, 3.2557e-16,
             2.9103e-11, 1.3097e-13, 2.3678e-14, 5.3343e-09, 1.0000e+00, 5.0120e-16,
             1.9486e-18, 4.7354e-18, 2.9607e-14, 6.1632e-16, 7.2077e-18, 9.4674e-15,
             9.5424e-18, 1.0727e-13, 2.0099e-17, 2.3949e-13, 3.3822e-13, 7.2685e-16,
             3.5069e-10, 4.1729e-14, 1.3190e-13, 4.1563e-14, 3.2148e-10, 6.2438e-16,
             1.1337e-15, 1.6041e-14, 6.0902e-16, 4.6457e-15, 1.1568e-16, 4.8942e-11,
             1.8828e-17, 3.2679e-12, 3.1415e-14]], device='cuda:0')</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>preds.argmax()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    TensorBase(22, device='cuda:0')</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>torch.nn.functional.softmax(preds, dim<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>][preds.argmax()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    TensorBase(1., device='cuda:0')</code></pre>
<p><strong>Get the class labels</strong></p>
<div class="sourceCode" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>learn.dls.vocab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    ['1', '3', '4', '5', '7', '8', '9', 'A', 'B', 'Baby', 'Brother', 'C', 'D', 'Dont_like', 'E', 'F', 'Friend', 'G', 'H', 'Help', 'House', 'I', 'J', 'K', 'L', 'Like', 'Love', 'M', 'Make', 'More', 'N', 'Name', 'No', 'O_OR_0', 'P', 'Pay', 'Play', 'Q', 'R', 'S', 'Stop', 'T', 'U', 'V_OR_2', 'W_OR_6', 'With', 'X', 'Y', 'Yes', 'Z', 'nothing']</code></pre>
<p><strong>Get the predicted class label</strong></p>
<div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>learn.dls.vocab[torch.nn.functional.softmax(preds, dim<span class="op">=</span><span class="dv">1</span>).argmax()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    'J'</code></pre>
</section>
<section id="export-the-model" class="level2">
<h2 class="anchored" data-anchor-id="export-the-model">Export the Model</h2>
<p>The last step is to export the trained model to ONNX format.</p>
<p><strong>Define ONNX file name</strong></p>
<div class="sourceCode" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>onnx_file_name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>dataset_path<span class="sc">.</span>name<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>learn<span class="sc">.</span>arch<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">.onnx"</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>onnx_file_name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>    'asl-and-some-words-resnet18.onnx'</code></pre>
<p><strong>Export trained model to ONNX</strong></p>
<p>We’ll use an older <a href="https://github.com/onnx/onnx/blob/main/docs/Versioning.md#operator-sets">opset_version</a> to ensure the model is compatible with the Barracuda library. We will also unlock the input dimensions for the model to give ourselves more flexibility in Unity. Although, we’ll want to stick close to the training resolution for the best accuracy.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>torch.onnx.export(learn.model.cpu(),</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>                  batched_tensor,</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>                  onnx_file_name,</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>                  export_params<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>                  opset_version<span class="op">=</span><span class="dv">9</span>,</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>                  do_constant_folding<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>                  input_names <span class="op">=</span> [<span class="st">'input'</span>],</span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>                  output_names <span class="op">=</span> [<span class="st">'output'</span>],</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>                  dynamic_axes<span class="op">=</span>{<span class="st">'input'</span>: {<span class="dv">2</span> : <span class="st">'height'</span>, <span class="dv">3</span> : <span class="st">'width'</span>}}</span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>                 )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Export class labels</strong></p>
<p>We can export the list of class labels to a JSON file and import it into the Unity project. That way, we don’t have to hardcode them, and we can easily swap in models trained on different datasets.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> {<span class="st">"classes"</span>: <span class="bu">list</span>(learn.dls.vocab)}</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>class_labels_file_name <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>dataset_path<span class="sc">.</span>name<span class="sc">}</span><span class="ss">-classes.json"</span></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(class_labels_file_name, <span class="st">"w"</span>) <span class="im">as</span> write_file:</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>    json.dump(class_labels, write_file)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>In this post, we walked through how to finetune a ResNet model for image classification using the fastai library and export it to ONNX format. Part 2 will cover implementing the trained model in a Unity project using the Barracuda library.</p>
<p><strong>Previous:</strong> <a href="../../deep-learning-unity-intro/">Getting Started With Deep Learning in Unity</a></p>
<p><strong>Next:</strong> <a href="../part-2/">Fastai to Unity Tutorial Pt. 2</a></p>
<p><strong>Project Resources:</strong> <a href="https://github.com/cj-mills/fastai-to-unity-tutorial">GitHub Repository</a></p>


</section>

</main> <!-- /main -->
<!-- Cloudflare Web Analytics --><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;56b8d2f624604c4891327b3c0d9f6703&quot;}"></script><!-- End Cloudflare Web Analytics -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("christianjmills\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="cj-mills/christianjmills" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024, Christian J. Mills
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>